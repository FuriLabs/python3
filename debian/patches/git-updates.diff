Description: Updates from the 3.12 branch (until 2023-11-09).
 We pick the latest updates from the maintainance branch, and carry them in a
 patch, rather than creating and uploading uploading a new .orig tarball.

# git diff --no-renames 0fb18b02c8ad56299d6a2910be0bab8ad601ef24 4f976c3b9a6b3606c12924a1adadd12f9d5f0388 | filterdiff -x ?/.hgignore -x ?/.hgeol -x ?/.hgtags -x ?/.hgtouch -x ?/.gitignore -x ?/.gitattributes -x '?/.github/*' -x '?/.git*' -x ?/.codecov.yml -x ?/.travis.yml -x ?/configure --remove-timestamps

diff --git a/.editorconfig b/.editorconfig
index 81445d2d79..0169eed951 100644
--- a/.editorconfig
+++ b/.editorconfig
@@ -8,5 +8,8 @@ indent_style = space
 [*.{py,c,cpp,h}]
 indent_size = 4
 
+[*.rst]
+indent_size = 3
+
 [*.yml]
 indent_size = 2
diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 19f6a03745..35d9c64a8c 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -1,28 +1,36 @@
 repos:
   - repo: https://github.com/astral-sh/ruff-pre-commit
-    rev: v0.0.288
+    rev: v0.1.2
     hooks:
       - id: ruff
         name: Run Ruff on Lib/test/
         args: [--exit-non-zero-on-fix]
         files: ^Lib/test/
+      - id: ruff
+        name: Run Ruff on Argument Clinic
+        args: [--exit-non-zero-on-fix, --config=Tools/clinic/.ruff.toml]
+        files: ^Tools/clinic/|Lib/test/test_clinic.py
 
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.4.0
+    rev: v4.5.0
     hooks:
       - id: check-toml
         exclude: ^Lib/test/test_tomllib/
       - id: check-yaml
       - id: end-of-file-fixer
         types: [python]
-        exclude: Lib/test/coding20731.py
+        exclude: Lib/test/tokenizedata/coding20731.py
       - id: trailing-whitespace
-        types_or: [c, python, rst]
+        types_or: [c, inc, python, rst]
 
   - repo: https://github.com/sphinx-contrib/sphinx-lint
-    rev: v0.6.8
+    rev: v0.8.1
     hooks:
       - id: sphinx-lint
         args: [--enable=default-role]
         files: ^Doc/|^Misc/NEWS.d/next/
-        types: [rst]
+
+  - repo: meta
+    hooks:
+      - id: check-hooks-apply
+      - id: check-useless-excludes
diff --git a/Doc/Makefile b/Doc/Makefile
index 2269189506..78ee4271e2 100644
--- a/Doc/Makefile
+++ b/Doc/Makefile
@@ -7,7 +7,6 @@
 PYTHON       = python3
 VENVDIR      = ./venv
 SPHINXBUILD  = PATH=$(VENVDIR)/bin:$$PATH sphinx-build
-SPHINXLINT   = PATH=$(VENVDIR)/bin:$$PATH sphinx-lint
 BLURB        = PATH=$(VENVDIR)/bin:$$PATH blurb
 JOBS         = auto
 PAPER        =
diff --git a/Doc/bugs.rst b/Doc/bugs.rst
index d98192b369..908987cf41 100644
--- a/Doc/bugs.rst
+++ b/Doc/bugs.rst
@@ -38,7 +38,7 @@ though it may take a while to be processed.
    `Helping with Documentation <https://devguide.python.org/docquality/#helping-with-documentation>`_
       Comprehensive guide for individuals that are interested in contributing to Python documentation.
 
-   `Documentation Translations <https://devguide.python.org/documenting/#translating>`_
+   `Documentation Translations <https://devguide.python.org/documentation/translating/>`_
       A list of GitHub pages for documentation translation and their primary contacts.
 
 
diff --git a/Doc/c-api/call.rst b/Doc/c-api/call.rst
index f4e401442c..855e10e9a5 100644
--- a/Doc/c-api/call.rst
+++ b/Doc/c-api/call.rst
@@ -108,6 +108,8 @@ This is a pointer to a function with the following signature:
    Doing so will allow callables such as bound methods to make their onward
    calls (which include a prepended *self* argument) very efficiently.
 
+   .. versionadded:: 3.8
+
 To call an object that implements vectorcall, use a :ref:`call API <capi-call>`
 function as with any other callable.
 :c:func:`PyObject_Vectorcall` will usually be most efficient.
diff --git a/Doc/c-api/exceptions.rst b/Doc/c-api/exceptions.rst
index 6e2ac0a40a..f27e2bbfef 100644
--- a/Doc/c-api/exceptions.rst
+++ b/Doc/c-api/exceptions.rst
@@ -88,9 +88,17 @@ Printing and clearing
    The function is called with a single argument *obj* that identifies the context
    in which the unraisable exception occurred. If possible,
    the repr of *obj* will be printed in the warning message.
+   If *obj* is ``NULL``, only the traceback is printed.
 
    An exception must be set when calling this function.
 
+   .. versionchanged:: 3.4
+      Print a traceback. Print only traceback if *obj* is ``NULL``.
+
+   .. versionchanged:: 3.8
+      Use :func:`sys.unraisablehook`.
+
+
 .. c:function:: void PyErr_DisplayException(PyObject *exc)
 
    Print the standard traceback display of ``exc`` to ``sys.stderr``, including
@@ -786,7 +794,7 @@ Exception Objects
 
    Implement part of the interpreter's implementation of :keyword:`!except*`.
    *orig* is the original exception that was caught, and *excs* is the list of
-   the exceptions that need to be raised. This list contains the the unhandled
+   the exceptions that need to be raised. This list contains the unhandled
    part of *orig*, if any, as well as the exceptions that were raised from the
    :keyword:`!except*` clauses (so they have a different traceback from *orig*) and
    those that were reraised (and have the same traceback as *orig*).
diff --git a/Doc/c-api/memory.rst b/Doc/c-api/memory.rst
index 1df8c2b911..52ef4170e8 100644
--- a/Doc/c-api/memory.rst
+++ b/Doc/c-api/memory.rst
@@ -491,18 +491,18 @@ Customize Memory Allocators
 
        :c:func:`PyMem_SetAllocator` does have the following contract:
 
-        * It can be called after :c:func:`Py_PreInitialize` and before
-          :c:func:`Py_InitializeFromConfig` to install a custom memory
-          allocator. There are no restrictions over the installed allocator
-          other than the ones imposed by the domain (for instance, the Raw
-          Domain allows the allocator to be called without the GIL held). See
-          :ref:`the section on allocator domains <allocator-domains>` for more
-          information.
-
-        * If called after Python has finish initializing (after
-          :c:func:`Py_InitializeFromConfig` has been called) the allocator
-          **must** wrap the existing allocator. Substituting the current
-          allocator for some other arbitrary one is **not supported**.
+       * It can be called after :c:func:`Py_PreInitialize` and before
+         :c:func:`Py_InitializeFromConfig` to install a custom memory
+         allocator. There are no restrictions over the installed allocator
+         other than the ones imposed by the domain (for instance, the Raw
+         Domain allows the allocator to be called without the GIL held). See
+         :ref:`the section on allocator domains <allocator-domains>` for more
+         information.
+
+       * If called after Python has finish initializing (after
+         :c:func:`Py_InitializeFromConfig` has been called) the allocator
+         **must** wrap the existing allocator. Substituting the current
+         allocator for some other arbitrary one is **not supported**.
 
    .. versionchanged:: 3.12
       All allocators must be thread-safe.
@@ -626,7 +626,8 @@ The pymalloc allocator
 
 Python has a *pymalloc* allocator optimized for small objects (smaller or equal
 to 512 bytes) with a short lifetime. It uses memory mappings called "arenas"
-with a fixed size of 256 KiB. It falls back to :c:func:`PyMem_RawMalloc` and
+with a fixed size of either 256 KiB on 32-bit platforms or 1 MiB on 64-bit
+platforms. It falls back to :c:func:`PyMem_RawMalloc` and
 :c:func:`PyMem_RawRealloc` for allocations larger than 512 bytes.
 
 *pymalloc* is the :ref:`default allocator <default-memory-allocators>` of the
diff --git a/Doc/c-api/set.rst b/Doc/c-api/set.rst
index 1e8a095090..09c0fb6b9c 100644
--- a/Doc/c-api/set.rst
+++ b/Doc/c-api/set.rst
@@ -163,4 +163,6 @@ subtypes but not for instances of :class:`frozenset` or its subtypes.
 
 .. c:function:: int PySet_Clear(PyObject *set)
 
-   Empty an existing set of all elements.
+   Empty an existing set of all elements. Return ``0`` on
+   success. Return ``-1`` and raise :exc:`SystemError` if *set* is not an instance of
+   :class:`set` or its subtype.
diff --git a/Doc/c-api/structures.rst b/Doc/c-api/structures.rst
index 747cfa6229..25cb4ed40f 100644
--- a/Doc/c-api/structures.rst
+++ b/Doc/c-api/structures.rst
@@ -406,7 +406,11 @@ Accessing attributes of extension types
 .. c:type:: PyMemberDef
 
    Structure which describes an attribute of a type which corresponds to a C
-   struct member.  Its fields are, in order:
+   struct member.
+   When defining a class, put a NULL-terminated array of these
+   structures in the :c:member:`~PyTypeObject.tp_members` slot.
+
+   Its fields are, in order:
 
    .. c:member:: const char* name
 
diff --git a/Doc/c-api/type.rst b/Doc/c-api/type.rst
index 0f58326f6c..5aaa8147dd 100644
--- a/Doc/c-api/type.rst
+++ b/Doc/c-api/type.rst
@@ -461,21 +461,34 @@ The following functions and structs are used to create
       * ``Py_nb_add`` to set :c:member:`PyNumberMethods.nb_add`
       * ``Py_sq_length`` to set :c:member:`PySequenceMethods.sq_length`
 
-      The following fields cannot be set at all using :c:type:`PyType_Spec` and
-      :c:type:`PyType_Slot`:
-
-      * :c:member:`~PyTypeObject.tp_dict`
-      * :c:member:`~PyTypeObject.tp_mro`
-      * :c:member:`~PyTypeObject.tp_cache`
-      * :c:member:`~PyTypeObject.tp_subclasses`
-      * :c:member:`~PyTypeObject.tp_weaklist`
+      The following “offset” fields cannot be set using :c:type:`PyType_Slot`:
+
+         * :c:member:`~PyTypeObject.tp_weaklistoffset`
+           (use :c:macro:`Py_TPFLAGS_MANAGED_WEAKREF` instead if possible)
+         * :c:member:`~PyTypeObject.tp_dictoffset`
+           (use :c:macro:`Py_TPFLAGS_MANAGED_DICT` instead if possible)
+         * :c:member:`~PyTypeObject.tp_vectorcall_offset`
+           (use ``"__vectorcalloffset__"`` in
+           :ref:`PyMemberDef <pymemberdef-offsets>`)
+
+         If it is not possible to switch to a ``MANAGED`` flag (for example,
+         for vectorcall or to support Python older than 3.12), specify the
+         offset in :c:member:`Py_tp_members <PyTypeObject.tp_members>`.
+         See :ref:`PyMemberDef documentation <pymemberdef-offsets>`
+         for details.
+
+      The following fields cannot be set at all when creating a heap type:
+
       * :c:member:`~PyTypeObject.tp_vectorcall`
-      * :c:member:`~PyTypeObject.tp_weaklistoffset`
-        (use :c:macro:`Py_TPFLAGS_MANAGED_WEAKREF` instead)
-      * :c:member:`~PyTypeObject.tp_dictoffset`
-        (use :c:macro:`Py_TPFLAGS_MANAGED_DICT` instead)
-      * :c:member:`~PyTypeObject.tp_vectorcall_offset`
-        (see :ref:`PyMemberDef <pymemberdef-offsets>`)
+        (use :c:member:`~PyTypeObject.tp_new` and/or
+        :c:member:`~PyTypeObject.tp_init`)
+
+      * Internal fields:
+        :c:member:`~PyTypeObject.tp_dict`,
+        :c:member:`~PyTypeObject.tp_mro`,
+        :c:member:`~PyTypeObject.tp_cache`,
+        :c:member:`~PyTypeObject.tp_subclasses`, and
+        :c:member:`~PyTypeObject.tp_weaklist`.
 
       Setting :c:data:`Py_tp_bases` or :c:data:`Py_tp_base` may be
       problematic on some platforms.
diff --git a/Doc/glossary.rst b/Doc/glossary.rst
index f3d5c5eede..cd34d190c6 100644
--- a/Doc/glossary.rst
+++ b/Doc/glossary.rst
@@ -248,7 +248,7 @@ Glossary
 
    context manager
       An object which controls the environment seen in a :keyword:`with`
-      statement by defining :meth:`__enter__` and :meth:`__exit__` methods.
+      statement by defining :meth:`~object.__enter__` and :meth:`~object.__exit__` methods.
       See :pep:`343`.
 
    context variable
@@ -645,7 +645,7 @@ Glossary
       iterables include all sequence types (such as :class:`list`, :class:`str`,
       and :class:`tuple`) and some non-sequence types like :class:`dict`,
       :term:`file objects <file object>`, and objects of any classes you define
-      with an :meth:`__iter__` method or with a :meth:`__getitem__` method
+      with an :meth:`__iter__` method or with a :meth:`~object.__getitem__` method
       that implements :term:`sequence` semantics.
 
       Iterables can be
@@ -1087,17 +1087,17 @@ Glossary
 
    sequence
       An :term:`iterable` which supports efficient element access using integer
-      indices via the :meth:`__getitem__` special method and defines a
+      indices via the :meth:`~object.__getitem__` special method and defines a
       :meth:`__len__` method that returns the length of the sequence.
       Some built-in sequence types are :class:`list`, :class:`str`,
       :class:`tuple`, and :class:`bytes`. Note that :class:`dict` also
-      supports :meth:`__getitem__` and :meth:`__len__`, but is considered a
+      supports :meth:`~object.__getitem__` and :meth:`__len__`, but is considered a
       mapping rather than a sequence because the lookups use arbitrary
       :term:`immutable` keys rather than integers.
 
       The :class:`collections.abc.Sequence` abstract base class
       defines a much richer interface that goes beyond just
-      :meth:`__getitem__` and :meth:`__len__`, adding :meth:`count`,
+      :meth:`~object.__getitem__` and :meth:`__len__`, adding :meth:`count`,
       :meth:`index`, :meth:`__contains__`, and
       :meth:`__reversed__`. Types that implement this expanded
       interface can be registered explicitly using
@@ -1132,6 +1132,11 @@ Glossary
       an :term:`expression` or one of several constructs with a keyword, such
       as :keyword:`if`, :keyword:`while` or :keyword:`for`.
 
+   static type checker
+      An external tool that reads Python code and analyzes it, looking for
+      issues such as incorrect types. See also :term:`type hints <type hint>`
+      and the :mod:`typing` module.
+
    strong reference
       In Python's C API, a strong reference is a reference to an object
       which is owned by the code holding the reference.  The strong
@@ -1208,8 +1213,8 @@ Glossary
       attribute, or a function parameter or return value.
 
       Type hints are optional and are not enforced by Python but
-      they are useful to static type analysis tools, and aid IDEs with code
-      completion and refactoring.
+      they are useful to :term:`static type checkers <static type checker>`.
+      They can also aid IDEs with code completion and refactoring.
 
       Type hints of global variables, class attributes, and functions,
       but not local variables, can be accessed using
diff --git a/Doc/howto/clinic.rst b/Doc/howto/clinic.rst
index e8e6aace35..0609772461 100644
--- a/Doc/howto/clinic.rst
+++ b/Doc/howto/clinic.rst
@@ -1,1900 +1,14 @@
-.. highlight:: c
+:orphan:
 
-.. _howto-clinic:
+.. This page is retained solely for existing links to /howto/clinic.html.
+   Direct readers to the devguide.
 
 **********************
 Argument Clinic How-To
 **********************
 
-:author: Larry Hastings
-
-**Source code:** :source:`Tools/clinic/clinic.py`.
-
-.. topic:: Abstract
-
-  Argument Clinic is a preprocessor for CPython C files.
-  It was introduced in Python 3.4 with :pep:`436`,
-  in order to provide introspection signatures,
-  and to generate performant and tailor-made boilerplate code
-  for argument parsing in CPython builtins,
-  module level functions, and class methods.
-  This document is divided in four major sections:
-
-  * :ref:`clinic-background` talks about the basic concepts and goals of
-    Argument Clinic.
-  * :ref:`clinic-reference` describes the command-line interface and Argument
-    Clinic terminology.
-  * :ref:`clinic-tutorial` guides you through all the steps required to
-    adapt an existing C function to Argument Clinic.
-  * :ref:`clinic-howtos` details how to handle specific tasks.
-
-
-.. note::
-
-  Argument Clinic is considered internal-only
-  for CPython.  Its use is not supported for files outside
-  CPython, and no guarantees are made regarding backwards
-  compatibility for future versions.  In other words: if you
-  maintain an external C extension for CPython, you're welcome
-  to experiment with Argument Clinic in your own code.  But the
-  version of Argument Clinic that ships with the next version
-  of CPython *could* be totally incompatible and break all your code.
-
-
-.. _clinic-background:
-
-Background
-==========
-
-Basic concepts
---------------
-
-When Argument Clinic is run on a file, either via the :ref:`clinic-cli`
-or via ``make clinic``, it will scan over the input files looking for
-:term:`start lines <start line>`:
-
-.. code-block:: none
-
-    /*[clinic input]
-
-When it finds one, it reads everything up to the :term:`end line`:
-
-.. code-block:: none
-
-    [clinic start generated code]*/
-
-Everything in between these two lines is Argument Clinic :term:`input`.
-When Argument Clinic parses input, it generates :term:`output`.
-The output is rewritten into the C file immediately after the input,
-followed by a :term:`checksum line`.
-All of these lines, including the :term:`start line` and :term:`checksum line`,
-are collectively called an Argument Clinic :term:`block`:
-
-.. code-block:: none
-
-    /*[clinic input]
-    ... clinic input goes here ...
-    [clinic start generated code]*/
-    ... clinic output goes here ...
-    /*[clinic end generated code: ...]*/
-
-If you run Argument Clinic on the same file a second time, Argument Clinic
-will discard the old :term:`output` and write out the new output with a fresh
-:term:`checksum line`.
-If the :term:`input` hasn't changed, the output won't change either.
 
 .. note::
 
-   You should never modify the output of an Argument Clinic block,
-   as any change will be lost in future Argument Clinic runs;
-   Argument Clinic will detect an output checksum mismatch and regenerate the
-   correct output.
-   If you are not happy with the generated output,
-   you should instead change the input until it produces the output you want.
-
-
-.. _clinic-reference:
-
-Reference
-=========
-
-
-.. _clinic-terminology:
-
-Terminology
------------
-
-.. glossary::
-
-   start line
-      The line ``/*[clinic input]``.
-      This line marks the beginning of Argument Clinic input.
-      Note that the *start line* opens a C block comment.
-
-   end line
-      The line ``[clinic start generated code]*/``.
-      The *end line* marks the _end_ of Argument Clinic :term:`input`,
-      but at the same time marks the _start_ of Argument Clinic :term:`output`,
-      thus the text *"clinic start start generated code"*
-      Note that the *end line* closes the C block comment opened
-      by the *start line*.
-
-   checksum
-      A hash to distinguish unique :term:`inputs <input>`
-      and :term:`outputs <output>`.
-
-   checksum line
-      A line that looks like ``/*[clinic end generated code: ...]*/``.
-      The three dots will be replaced by a :term:`checksum` generated from the
-      :term:`input`, and a :term:`checksum` generated from the :term:`output`.
-      The checksum line marks the end of Argument Clinic generated code,
-      and is used by Argument Clinic to determine if it needs to regenerate
-      output.
-
-   input
-      The text between the :term:`start line` and the :term:`end line`.
-      Note that the start and end lines open and close a C block comment;
-      the *input* is thus a part of that same C block comment.
-
-   output
-      The text between the :term:`end line` and the :term:`checksum line`.
-
-   block
-      All text from the :term:`start line` to the :term:`checksum line` inclusively.
-
-
-.. _clinic-cli:
-
-Command-line interface
-----------------------
-
-The Argument Clinic :abbr:`CLI (Command-Line Interface)` is typically used to
-process a single source file, like this:
-
-.. code-block:: shell-session
-
-    $ python3 ./Tools/clinic/clinic.py foo.c
-
-The CLI supports the following options:
-
-.. program:: ./Tools/clinic/clinic.py [-h] [-f] [-o OUTPUT] [-v] \
-             [--converters] [--make] [--srcdir SRCDIR] [FILE ...]
-
-.. option:: -h, --help
-
-   Print CLI usage.
-
-.. option:: -f, --force
-
-   Force output regeneration.
-
-.. option:: -o, --output OUTPUT
-
-   Redirect file output to OUTPUT
-
-.. option:: -v, --verbose
-
-   Enable verbose mode.
-
-.. option:: --converters
-
-   Print a list of all supported converters and return converters.
-
-.. option:: --make
-
-   Walk :option:`--srcdir` to run over all relevant files.
-
-.. option:: --srcdir SRCDIR
-
-   The directory tree to walk in :option:`--make` mode.
-
-.. option:: FILE ...
-
-   The list of files to process.
-
-
-.. _clinic-classes:
-
-Classes for extending Argument Clinic
--------------------------------------
-
-.. module:: clinic
-
-.. class:: CConverter
-
-   The base class for all converters.
-   See :ref:`clinic-howto-custom-converter` for how to subclass this class.
-
-   .. attribute:: type
-
-      The C type to use for this variable.
-      :attr:`!type` should be a Python string specifying the type,
-      e.g. ``'int'``.
-      If this is a pointer type, the type string should end with ``' *'``.
-
-   .. attribute:: default
-
-      The Python default value for this parameter, as a Python value.
-      Or the magic value ``unspecified`` if there is no default.
-
-   .. attribute:: py_default
-
-      :attr:`!default` as it should appear in Python code,
-      as a string.
-      Or ``None`` if there is no default.
-
-   .. attribute:: c_default
-
-      :attr:`!default` as it should appear in C code,
-      as a string.
-      Or ``None`` if there is no default.
-
-   .. attribute:: c_ignored_default
-
-      The default value used to initialize the C variable when
-      there is no default, but not specifying a default may
-      result in an "uninitialized variable" warning.  This can
-      easily happen when using option groups—although
-      properly written code will never actually use this value,
-      the variable does get passed in to the impl, and the
-      C compiler will complain about the "use" of the
-      uninitialized value.  This value should always be a
-      non-empty string.
-
-   .. attribute:: converter
-
-      The name of the C converter function, as a string.
-
-   .. attribute:: impl_by_reference
-
-      A boolean value.  If true,
-      Argument Clinic will add a ``&`` in front of the name of
-      the variable when passing it into the impl function.
-
-   .. attribute:: parse_by_reference
-
-      A boolean value.  If true,
-      Argument Clinic will add a ``&`` in front of the name of
-      the variable when passing it into :c:func:`PyArg_ParseTuple`.
-
-
-.. _clinic-tutorial:
-
-Tutorial
-========
-
-The best way to get a sense of how Argument Clinic works is to
-convert a function to work with it.  Here, then, are the bare
-minimum steps you'd need to follow to convert a function to
-work with Argument Clinic.  Note that for code you plan to
-check in to CPython, you really should take the conversion farther,
-using some of the :ref:`advanced concepts <clinic-howtos>`
-you'll see later on in the document,
-like :ref:`clinic-howto-return-converters`
-and :ref:`clinic-howto-self-converter`.
-But we'll keep it simple for this walkthrough so you can learn.
-
-First, make sure you're working with a freshly updated checkout
-of the CPython trunk.
-
-Next, find a Python builtin that calls either :c:func:`PyArg_ParseTuple`
-or :c:func:`PyArg_ParseTupleAndKeywords`, and hasn't been converted
-to work with Argument Clinic yet.
-For this tutorial, we'll be using
-:py:meth:`_pickle.Pickler.dump <pickle.Pickler.dump>`.
-
-If the call to the :c:func:`!PyArg_Parse*` function uses any of the
-following format units...:
-
-   .. code-block:: none
-
-       O&
-       O!
-       es
-       es#
-       et
-       et#
-
-... or if it has multiple calls to :c:func:`PyArg_ParseTuple`,
-you should choose a different function.
-(See :ref:`clinic-howto-advanced-converters` for those scenarios.)
-
-Also, if the function has multiple calls to :c:func:`!PyArg_ParseTuple`
-or :c:func:`PyArg_ParseTupleAndKeywords` where it supports different
-types for the same argument, or if the function uses something besides
-:c:func:`!PyArg_Parse*` functions to parse its arguments, it probably
-isn't suitable for conversion to Argument Clinic.  Argument Clinic
-doesn't support generic functions or polymorphic parameters.
-
-Next, add the following boilerplate above the function,
-creating our input block::
-
-    /*[clinic input]
-    [clinic start generated code]*/
-
-Cut the docstring and paste it in between the ``[clinic]`` lines,
-removing all the junk that makes it a properly quoted C string.
-When you're done you should have just the text, based at the left
-margin, with no line wider than 80 characters.
-Argument Clinic will preserve indents inside the docstring.
-
-If the old docstring had a first line that looked like a function
-signature, throw that line away; The docstring doesn't need it anymore ---
-when you use :py:func:`help` on your builtin in the future,
-the first line will be built automatically based on the function's signature.
-
-Example docstring summary line::
-
-   /*[clinic input]
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-If your docstring doesn't have a "summary" line, Argument Clinic will
-complain, so let's make sure it has one.  The "summary" line should
-be a paragraph consisting of a single 80-column line
-at the beginning of the docstring.
-(See :pep:`257` regarding docstring conventions.)
-
-Our example docstring consists solely of a summary line, so the sample
-code doesn't have to change for this step.
-
-Now, above the docstring, enter the name of the function, followed
-by a blank line.  This should be the Python name of the function,
-and should be the full dotted path to the function ---
-it should start with the name of the module,
-include any sub-modules, and if the function is a method on
-a class it should include the class name too.
-
-In our example, :mod:`!_pickle` is the module, :py:class:`!Pickler` is the class,
-and :py:meth:`!dump` is the method, so the name becomes
-:py:meth:`!_pickle.Pickler.dump`::
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-If this is the first time that module or class has been used with Argument
-Clinic in this C file,
-you must declare the module and/or class.  Proper Argument Clinic hygiene
-prefers declaring these in a separate block somewhere near the
-top of the C file, in the same way that include files and statics go at
-the top.
-In our sample code we'll just show the two blocks next to each other.
-
-The name of the class and module should be the same as the one
-seen by Python.  Check the name defined in the :c:type:`PyModuleDef`
-or :c:type:`PyTypeObject` as appropriate.
-
-When you declare a class, you must also specify two aspects of its type
-in C: the type declaration you'd use for a pointer to an instance of
-this class, and a pointer to the :c:type:`!PyTypeObject` for this class::
-
-   /*[clinic input]
-   module _pickle
-   class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
-   [clinic start generated code]*/
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-Declare each of the parameters to the function.  Each parameter
-should get its own line.  All the parameter lines should be
-indented from the function name and the docstring.
-The general form of these parameter lines is as follows:
-
-.. code-block:: none
-
-    name_of_parameter: converter
-
-If the parameter has a default value, add that after the
-converter:
-
-.. code-block:: none
-
-    name_of_parameter: converter = default_value
-
-Argument Clinic's support for "default values" is quite sophisticated;
-see :ref:`clinic-howto-default-values` for more information.
-
-Next, add a blank line below the parameters.
-
-What's a "converter"?
-It establishes both the type of the variable used in C,
-and the method to convert the Python value into a C value at runtime.
-For now you're going to use what's called a "legacy converter" ---
-a convenience syntax intended to make porting old code into Argument
-Clinic easier.
-
-For each parameter, copy the "format unit" for that
-parameter from the :c:func:`PyArg_Parse` format argument and
-specify *that* as its converter, as a quoted string.
-The "format unit" is the formal name for the one-to-three
-character substring of the *format* parameter that tells
-the argument parsing function what the type of the variable
-is and how to convert it.
-For more on format units please see :ref:`arg-parsing`.
-
-For multicharacter format units like ``z#``,
-use the entire two-or-three character string.
-
-Sample::
-
-   /*[clinic input]
-   module _pickle
-   class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
-   [clinic start generated code]*/
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-       obj: 'O'
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-If your function has ``|`` in the format string,
-meaning some parameters have default values, you can ignore it.
-Argument Clinic infers which parameters are optional
-based on whether or not they have default values.
-
-If your function has ``$`` in the format string,
-meaning it takes keyword-only arguments,
-specify ``*`` on a line by itself before the first keyword-only argument,
-indented the same as the parameter lines.
-
-:py:meth:`!_pickle.Pickler.dump` has neither, so our sample is unchanged.
-
-Next, if the existing C function calls :c:func:`PyArg_ParseTuple`
-(as opposed to :c:func:`PyArg_ParseTupleAndKeywords`), then all its
-arguments are positional-only.
-
-To mark parameters as positional-only in Argument Clinic,
-add a ``/`` on a line by itself after the last positional-only parameter,
-indented the same as the parameter lines.
-
-Sample::
-
-   /*[clinic input]
-   module _pickle
-   class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
-   [clinic start generated code]*/
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-       obj: 'O'
-       /
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-It can be helpful to write a per-parameter docstring for each parameter.
-Since per-parameter docstrings are optional,
-you can skip this step if you prefer.
-
-Nevertheless, here's how to add a per-parameter docstring.
-The first line of the per-parameter docstring
-must be indented further than the parameter definition.
-The left margin of this first line establishes
-the left margin for the whole per-parameter docstring;
-all the text you write will be outdented by this amount.
-You can write as much text as you like, across multiple lines if you wish.
-
-Sample::
-
-   /*[clinic input]
-   module _pickle
-   class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
-   [clinic start generated code]*/
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-       obj: 'O'
-           The object to be pickled.
-       /
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-Save and close the file, then run ``Tools/clinic/clinic.py`` on it.
-With luck everything worked---your block now has output,
-and a :file:`.c.h` file has been generated!
-Reload the file in your text editor to see the generated code::
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-       obj: 'O'
-           The object to be pickled.
-       /
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-   static PyObject *
-   _pickle_Pickler_dump(PicklerObject *self, PyObject *obj)
-   /*[clinic end generated code: output=87ecad1261e02ac7 input=552eb1c0f52260d9]*/
-
-Obviously, if Argument Clinic didn't produce any output,
-it's because it found an error in your input.
-Keep fixing your errors and retrying until Argument Clinic processes your file
-without complaint.
-
-For readability, most of the glue code has been generated to a :file:`.c.h`
-file.  You'll need to include that in your original :file:`.c` file,
-typically right after the clinic module block::
-
-   #include "clinic/_pickle.c.h"
-
-Double-check that the argument-parsing code Argument Clinic generated
-looks basically the same as the existing code.
-
-First, ensure both places use the same argument-parsing function.
-The existing code must call either
-:c:func:`PyArg_ParseTuple` or :c:func:`PyArg_ParseTupleAndKeywords`;
-ensure that the code generated by Argument Clinic calls the
-*exact* same function.
-
-Second, the format string passed in to :c:func:`!PyArg_ParseTuple` or
-:c:func:`!PyArg_ParseTupleAndKeywords` should be *exactly* the same
-as the hand-written one in the existing function,
-up to the colon or semi-colon.
-
-Argument Clinic always generates its format strings
-with a ``:`` followed by the name of the function.
-If the existing code's format string ends with ``;``,
-to provide usage help, this change is harmless --- don't worry about it.
-
-Third, for parameters whose format units require two arguments,
-like a length variable, an encoding string, or a pointer
-to a conversion function, ensure that the second argument is
-*exactly* the same between the two invocations.
-
-Fourth, inside the output portion of the block,
-you'll find a preprocessor macro defining the appropriate static
-:c:type:`PyMethodDef` structure for this builtin::
-
-   #define __PICKLE_PICKLER_DUMP_METHODDEF    \
-   {"dump", (PyCFunction)__pickle_Pickler_dump, METH_O, __pickle_Pickler_dump__doc__},
-
-This static structure should be *exactly* the same as the existing static
-:c:type:`!PyMethodDef` structure for this builtin.
-
-If any of these items differ in *any way*,
-adjust your Argument Clinic function specification and rerun
-``Tools/clinic/clinic.py`` until they *are* the same.
-
-Notice that the last line of its output is the declaration
-of your "impl" function.  This is where the builtin's implementation goes.
-Delete the existing prototype of the function you're modifying, but leave
-the opening curly brace.  Now delete its argument parsing code and the
-declarations of all the variables it dumps the arguments into.
-Notice how the Python arguments are now arguments to this impl function;
-if the implementation used different names for these variables, fix it.
-
-Let's reiterate, just because it's kind of weird.
-Your code should now look like this::
-
-   static return_type
-   your_function_impl(...)
-   /*[clinic end generated code: input=..., output=...]*/
-   {
-   ...
-
-Argument Clinic generated the checksum line and the function prototype just
-above it.  You should write the opening and closing curly braces for the
-function, and the implementation inside.
-
-Sample::
-
-   /*[clinic input]
-   module _pickle
-   class _pickle.Pickler "PicklerObject *" "&Pickler_Type"
-   [clinic start generated code]*/
-   /*[clinic end generated code: checksum=da39a3ee5e6b4b0d3255bfef95601890afd80709]*/
-
-   /*[clinic input]
-   _pickle.Pickler.dump
-
-       obj: 'O'
-           The object to be pickled.
-       /
-
-   Write a pickled representation of obj to the open file.
-   [clinic start generated code]*/
-
-   PyDoc_STRVAR(__pickle_Pickler_dump__doc__,
-   "Write a pickled representation of obj to the open file.\n"
-   "\n"
-   ...
-   static PyObject *
-   _pickle_Pickler_dump_impl(PicklerObject *self, PyObject *obj)
-   /*[clinic end generated code: checksum=3bd30745bf206a48f8b576a1da3d90f55a0a4187]*/
-   {
-       /* Check whether the Pickler was initialized correctly (issue3664).
-          Developers often forget to call __init__() in their subclasses, which
-          would trigger a segfault without this check. */
-       if (self->write == NULL) {
-           PyErr_Format(PicklingError,
-                        "Pickler.__init__() was not called by %s.__init__()",
-                        Py_TYPE(self)->tp_name);
-           return NULL;
-       }
-
-       if (_Pickler_ClearBuffer(self) < 0) {
-           return NULL;
-       }
-
-       ...
-
-Remember the macro with the :c:type:`PyMethodDef` structure for this function?
-Find the existing :c:type:`!PyMethodDef` structure for this
-function and replace it with a reference to the macro.  If the builtin
-is at module scope, this will probably be very near the end of the file;
-if the builtin is a class method, this will probably be below but relatively
-near to the implementation.
-
-Note that the body of the macro contains a trailing comma; when you
-replace the existing static :c:type:`!PyMethodDef` structure with the macro,
-*don't* add a comma to the end.
-
-Sample::
-
-   static struct PyMethodDef Pickler_methods[] = {
-       __PICKLE_PICKLER_DUMP_METHODDEF
-       __PICKLE_PICKLER_CLEAR_MEMO_METHODDEF
-       {NULL, NULL}                /* sentinel */
-   };
-
-Argument Clinic may generate new instances of ``_Py_ID``. For example::
-
-   &_Py_ID(new_unique_py_id)
-
-If it does, you'll have to run ``make regen-global-objects``
-to regenerate the list of precompiled identifiers at this point.
-
-Finally, compile, then run the relevant portions of the regression-test suite.
-This change should not introduce any new compile-time warnings or errors,
-and there should be no externally visible change to Python's behavior,
-except for one difference: :py:func:`inspect.signature` run on your function
-should now provide a valid signature!
-
-Congratulations, you've ported your first function to work with Argument Clinic!
-
-
-.. _clinic-howtos:
-
-How-to guides
-=============
-
-
-How to rename C functions and variables generated by Argument Clinic
---------------------------------------------------------------------
-
-Argument Clinic automatically names the functions it generates for you.
-Occasionally this may cause a problem, if the generated name collides with
-the name of an existing C function.  There's an easy solution: override the names
-used for the C functions.  Just add the keyword ``"as"``
-to your function declaration line, followed by the function name you wish to use.
-Argument Clinic will use that function name for the base (generated) function,
-then add ``"_impl"`` to the end and use that for the name of the impl function.
-
-For example, if we wanted to rename the C function names generated for
-:py:meth:`pickle.Pickler.dump`, it'd look like this::
-
-    /*[clinic input]
-    pickle.Pickler.dump as pickler_dumper
-
-    ...
-
-The base function would now be named :c:func:`!pickler_dumper`,
-and the impl function would now be named :c:func:`!pickler_dumper_impl`.
-
-
-Similarly, you may have a problem where you want to give a parameter
-a specific Python name, but that name may be inconvenient in C.  Argument
-Clinic allows you to give a parameter different names in Python and in C,
-using the same ``"as"`` syntax::
-
-    /*[clinic input]
-    pickle.Pickler.dump
-
-        obj: object
-        file as file_obj: object
-        protocol: object = NULL
-        *
-        fix_imports: bool = True
-
-Here, the name used in Python (in the signature and the ``keywords``
-array) would be *file*, but the C variable would be named ``file_obj``.
-
-You can use this to rename the *self* parameter too!
-
-
-How to convert functions using ``PyArg_UnpackTuple``
-----------------------------------------------------
-
-To convert a function parsing its arguments with :c:func:`PyArg_UnpackTuple`,
-simply write out all the arguments, specifying each as an ``object``.  You
-may specify the *type* argument to cast the type as appropriate.  All
-arguments should be marked positional-only (add a ``/`` on a line by itself
-after the last argument).
-
-Currently the generated code will use :c:func:`PyArg_ParseTuple`, but this
-will change soon.
-
-
-How to use optional groups
---------------------------
-
-Some legacy functions have a tricky approach to parsing their arguments:
-they count the number of positional arguments, then use a ``switch`` statement
-to call one of several different :c:func:`PyArg_ParseTuple` calls depending on
-how many positional arguments there are.  (These functions cannot accept
-keyword-only arguments.)  This approach was used to simulate optional
-arguments back before :c:func:`PyArg_ParseTupleAndKeywords` was created.
-
-While functions using this approach can often be converted to
-use :c:func:`!PyArg_ParseTupleAndKeywords`, optional arguments, and default values,
-it's not always possible.  Some of these legacy functions have
-behaviors :c:func:`!PyArg_ParseTupleAndKeywords` doesn't directly support.
-The most obvious example is the builtin function :py:func:`range`, which has
-an optional argument on the *left* side of its required argument!
-Another example is :py:meth:`curses.window.addch`, which has a group of two
-arguments that must always be specified together.  (The arguments are
-called *x* and *y*; if you call the function passing in *x*,
-you must also pass in *y* — and if you don't pass in *x* you may not
-pass in *y* either.)
-
-In any case, the goal of Argument Clinic is to support argument parsing
-for all existing CPython builtins without changing their semantics.
-Therefore Argument Clinic supports
-this alternate approach to parsing, using what are called *optional groups*.
-Optional groups are groups of arguments that must all be passed in together.
-They can be to the left or the right of the required arguments.  They
-can *only* be used with positional-only parameters.
-
-.. note:: Optional groups are *only* intended for use when converting
-          functions that make multiple calls to :c:func:`PyArg_ParseTuple`!
-          Functions that use *any* other approach for parsing arguments
-          should *almost never* be converted to Argument Clinic using
-          optional groups.  Functions using optional groups currently
-          cannot have accurate signatures in Python, because Python just
-          doesn't understand the concept.  Please avoid using optional
-          groups wherever possible.
-
-To specify an optional group, add a ``[`` on a line by itself before
-the parameters you wish to group together, and a ``]`` on a line by itself
-after these parameters.  As an example, here's how :py:meth:`curses.window.addch`
-uses optional groups to make the first two parameters and the last
-parameter optional::
-
-    /*[clinic input]
-
-    curses.window.addch
-
-        [
-        x: int
-          X-coordinate.
-        y: int
-          Y-coordinate.
-        ]
-
-        ch: object
-          Character to add.
-
-        [
-        attr: long
-          Attributes for the character.
-        ]
-        /
-
-    ...
-
-
-Notes:
-
-* For every optional group, one additional parameter will be passed into the
-  impl function representing the group.  The parameter will be an int named
-  ``group_{direction}_{number}``,
-  where ``{direction}`` is either ``right`` or ``left`` depending on whether the group
-  is before or after the required parameters, and ``{number}`` is a monotonically
-  increasing number (starting at 1) indicating how far away the group is from
-  the required parameters.  When the impl is called, this parameter will be set
-  to zero if this group was unused, and set to non-zero if this group was used.
-  (By used or unused, I mean whether or not the parameters received arguments
-  in this invocation.)
-
-* If there are no required arguments, the optional groups will behave
-  as if they're to the right of the required arguments.
-
-* In the case of ambiguity, the argument parsing code
-  favors parameters on the left (before the required parameters).
-
-* Optional groups can only contain positional-only parameters.
-
-* Optional groups are *only* intended for legacy code.  Please do not
-  use optional groups for new code.
-
-
-How to use real Argument Clinic converters, instead of "legacy converters"
---------------------------------------------------------------------------
-
-To save time, and to minimize how much you need to learn
-to achieve your first port to Argument Clinic, the walkthrough above tells
-you to use "legacy converters".  "Legacy converters" are a convenience,
-designed explicitly to make porting existing code to Argument Clinic
-easier.  And to be clear, their use is acceptable when porting code for
-Python 3.4.
-
-However, in the long term we probably want all our blocks to
-use Argument Clinic's real syntax for converters.  Why?  A couple
-reasons:
-
-* The proper converters are far easier to read and clearer in their intent.
-* There are some format units that are unsupported as "legacy converters",
-  because they require arguments, and the legacy converter syntax doesn't
-  support specifying arguments.
-* In the future we may have a new argument parsing library that isn't
-  restricted to what :c:func:`PyArg_ParseTuple` supports; this flexibility
-  won't be available to parameters using legacy converters.
-
-Therefore, if you don't mind a little extra effort, please use the normal
-converters instead of legacy converters.
-
-In a nutshell, the syntax for Argument Clinic (non-legacy) converters
-looks like a Python function call.  However, if there are no explicit
-arguments to the function (all functions take their default values),
-you may omit the parentheses.  Thus ``bool`` and ``bool()`` are exactly
-the same converters.
-
-All arguments to Argument Clinic converters are keyword-only.
-All Argument Clinic converters accept the following arguments:
-
-  *c_default*
-    The default value for this parameter when defined in C.
-    Specifically, this will be the initializer for the variable declared
-    in the "parse function".  See :ref:`the section on default values <default_values>`
-    for how to use this.
-    Specified as a string.
-
-  *annotation*
-    The annotation value for this parameter.  Not currently supported,
-    because :pep:`8` mandates that the Python library may not use
-    annotations.
-
-  *unused*
-    Wrap the argument with :c:macro:`Py_UNUSED` in the impl function signature.
-
-In addition, some converters accept additional arguments.  Here is a list
-of these arguments, along with their meanings:
-
-  *accept*
-    A set of Python types (and possibly pseudo-types);
-    this restricts the allowable Python argument to values of these types.
-    (This is not a general-purpose facility; as a rule it only supports
-    specific lists of types as shown in the legacy converter table.)
-
-    To accept ``None``, add ``NoneType`` to this set.
-
-  *bitwise*
-    Only supported for unsigned integers.  The native integer value of this
-    Python argument will be written to the parameter without any range checking,
-    even for negative values.
-
-  *converter*
-    Only supported by the ``object`` converter.  Specifies the name of a
-    :ref:`C "converter function" <o_ampersand>`
-    to use to convert this object to a native type.
-
-  *encoding*
-    Only supported for strings.  Specifies the encoding to use when converting
-    this string from a Python str (Unicode) value into a C ``char *`` value.
-
-
-  *subclass_of*
-    Only supported for the ``object`` converter.  Requires that the Python
-    value be a subclass of a Python type, as expressed in C.
-
-  *type*
-    Only supported for the ``object`` and ``self`` converters.  Specifies
-    the C type that will be used to declare the variable.  Default value is
-    ``"PyObject *"``.
-
-  *zeroes*
-    Only supported for strings.  If true, embedded NUL bytes (``'\\0'``) are
-    permitted inside the value.  The length of the string will be passed in
-    to the impl function, just after the string parameter, as a parameter named
-    ``<parameter_name>_length``.
-
-Please note, not every possible combination of arguments will work.
-Usually these arguments are implemented by specific :c:func:`PyArg_ParseTuple`
-*format units*, with specific behavior.  For example, currently you cannot
-call ``unsigned_short`` without also specifying ``bitwise=True``.
-Although it's perfectly reasonable to think this would work, these semantics don't
-map to any existing format unit.  So Argument Clinic doesn't support it.  (Or, at
-least, not yet.)
-
-Below is a table showing the mapping of legacy converters into real
-Argument Clinic converters.  On the left is the legacy converter,
-on the right is the text you'd replace it with.
-
-=========   =================================================================================
-``'B'``     ``unsigned_char(bitwise=True)``
-``'b'``     ``unsigned_char``
-``'c'``     ``char``
-``'C'``     ``int(accept={str})``
-``'d'``     ``double``
-``'D'``     ``Py_complex``
-``'es'``    ``str(encoding='name_of_encoding')``
-``'es#'``   ``str(encoding='name_of_encoding', zeroes=True)``
-``'et'``    ``str(encoding='name_of_encoding', accept={bytes, bytearray, str})``
-``'et#'``   ``str(encoding='name_of_encoding', accept={bytes, bytearray, str}, zeroes=True)``
-``'f'``     ``float``
-``'h'``     ``short``
-``'H'``     ``unsigned_short(bitwise=True)``
-``'i'``     ``int``
-``'I'``     ``unsigned_int(bitwise=True)``
-``'k'``     ``unsigned_long(bitwise=True)``
-``'K'``     ``unsigned_long_long(bitwise=True)``
-``'l'``     ``long``
-``'L'``     ``long long``
-``'n'``     ``Py_ssize_t``
-``'O'``     ``object``
-``'O!'``    ``object(subclass_of='&PySomething_Type')``
-``'O&'``    ``object(converter='name_of_c_function')``
-``'p'``     ``bool``
-``'S'``     ``PyBytesObject``
-``'s'``     ``str``
-``'s#'``    ``str(zeroes=True)``
-``'s*'``    ``Py_buffer(accept={buffer, str})``
-``'U'``     ``unicode``
-``'u'``     ``wchar_t``
-``'u#'``    ``wchar_t(zeroes=True)``
-``'w*'``    ``Py_buffer(accept={rwbuffer})``
-``'Y'``     ``PyByteArrayObject``
-``'y'``     ``str(accept={bytes})``
-``'y#'``    ``str(accept={robuffer}, zeroes=True)``
-``'y*'``    ``Py_buffer``
-``'Z'``     ``wchar_t(accept={str, NoneType})``
-``'Z#'``    ``wchar_t(accept={str, NoneType}, zeroes=True)``
-``'z'``     ``str(accept={str, NoneType})``
-``'z#'``    ``str(accept={str, NoneType}, zeroes=True)``
-``'z*'``    ``Py_buffer(accept={buffer, str, NoneType})``
-=========   =================================================================================
-
-As an example, here's our sample ``pickle.Pickler.dump`` using the proper
-converter::
-
-    /*[clinic input]
-    pickle.Pickler.dump
-
-        obj: object
-            The object to be pickled.
-        /
-
-    Write a pickled representation of obj to the open file.
-    [clinic start generated code]*/
-
-One advantage of real converters is that they're more flexible than legacy
-converters.  For example, the ``unsigned_int`` converter (and all the
-``unsigned_`` converters) can be specified without ``bitwise=True``.  Their
-default behavior performs range checking on the value, and they won't accept
-negative numbers.  You just can't do that with a legacy converter!
-
-Argument Clinic will show you all the converters it has
-available.  For each converter it'll show you all the parameters
-it accepts, along with the default value for each parameter.
-Just run ``Tools/clinic/clinic.py --converters`` to see the full list.
-
-
-How to use the ``Py_buffer`` converter
---------------------------------------
-
-When using the ``Py_buffer`` converter
-(or the ``'s*'``, ``'w*'``, ``'*y'``, or ``'z*'`` legacy converters),
-you *must* not call :c:func:`PyBuffer_Release` on the provided buffer.
-Argument Clinic generates code that does it for you (in the parsing function).
-
-
-.. _clinic-howto-advanced-converters:
-
-How to use advanced converters
-------------------------------
-
-Remember those format units you skipped for your first
-time because they were advanced?  Here's how to handle those too.
-
-The trick is, all those format units take arguments—either
-conversion functions, or types, or strings specifying an encoding.
-(But "legacy converters" don't support arguments.  That's why we
-skipped them for your first function.)  The argument you specified
-to the format unit is now an argument to the converter; this
-argument is either *converter* (for ``O&``), *subclass_of* (for ``O!``),
-or *encoding* (for all the format units that start with ``e``).
-
-When using *subclass_of*, you may also want to use the other
-custom argument for ``object()``: *type*, which lets you set the type
-actually used for the parameter.  For example, if you want to ensure
-that the object is a subclass of :c:var:`PyUnicode_Type`, you probably want
-to use the converter ``object(type='PyUnicodeObject *', subclass_of='&PyUnicode_Type')``.
-
-One possible problem with using Argument Clinic: it takes away some possible
-flexibility for the format units starting with ``e``.  When writing a
-:c:func:`!PyArg_Parse*` call by hand, you could theoretically decide at runtime what
-encoding string to pass to that call.   But now this string must
-be hard-coded at Argument-Clinic-preprocessing-time.  This limitation is deliberate;
-it made supporting this format unit much easier, and may allow for future optimizations.
-This restriction doesn't seem unreasonable; CPython itself always passes in static
-hard-coded encoding strings for parameters whose format units start with ``e``.
-
-
-.. _clinic-howto-default-values:
-.. _default_values:
-
-How to assign default values to parameter
------------------------------------------
-
-Default values for parameters can be any of a number of values.
-At their simplest, they can be string, int, or float literals:
-
-.. code-block:: none
-
-    foo: str = "abc"
-    bar: int = 123
-    bat: float = 45.6
-
-They can also use any of Python's built-in constants:
-
-.. code-block:: none
-
-    yep:  bool = True
-    nope: bool = False
-    nada: object = None
-
-There's also special support for a default value of ``NULL``, and
-for simple expressions, documented in the following sections.
-
-
-The ``NULL`` default value
-^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-For string and object parameters, you can set them to ``None`` to indicate
-that there's no default.  However, that means the C variable will be
-initialized to ``Py_None``.  For convenience's sakes, there's a special
-value called ``NULL`` for just this reason: from Python's perspective it
-behaves like a default value of ``None``, but the C variable is initialized
-with ``NULL``.
-
-
-Symbolic default values
-^^^^^^^^^^^^^^^^^^^^^^^
-
-The default value you provide for a parameter can't be any arbitrary
-expression.  Currently the following are explicitly supported:
-
-* Numeric constants (integer and float)
-* String constants
-* ``True``, ``False``, and ``None``
-* Simple symbolic constants like :py:data:`sys.maxsize`, which must
-  start with the name of the module
-
-(In the future, this may need to get even more elaborate,
-to allow full expressions like ``CONSTANT - 1``.)
-
-
-Expressions as default values
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-The default value for a parameter can be more than just a literal value.
-It can be an entire expression, using math operators and looking up attributes
-on objects.  However, this support isn't exactly simple, because of some
-non-obvious semantics.
-
-Consider the following example:
-
-.. code-block:: none
-
-    foo: Py_ssize_t = sys.maxsize - 1
-
-:py:data:`sys.maxsize` can have different values on different platforms.  Therefore
-Argument Clinic can't simply evaluate that expression locally and hard-code it
-in C.  So it stores the default in such a way that it will get evaluated at
-runtime, when the user asks for the function's signature.
-
-What namespace is available when the expression is evaluated?  It's evaluated
-in the context of the module the builtin came from.  So, if your module has an
-attribute called :py:attr:`!max_widgets`, you may simply use it:
-
-.. code-block:: none
-
-    foo: Py_ssize_t = max_widgets
-
-If the symbol isn't found in the current module, it fails over to looking in
-:py:data:`sys.modules`.  That's how it can find :py:data:`sys.maxsize` for example.
-(Since you don't know in advance what modules the user will load into their interpreter,
-it's best to restrict yourself to modules that are preloaded by Python itself.)
-
-Evaluating default values only at runtime means Argument Clinic can't compute
-the correct equivalent C default value.  So you need to tell it explicitly.
-When you use an expression, you must also specify the equivalent expression
-in C, using the *c_default* parameter to the converter:
-
-.. code-block:: none
-
-    foo: Py_ssize_t(c_default="PY_SSIZE_T_MAX - 1") = sys.maxsize - 1
-
-Another complication: Argument Clinic can't know in advance whether or not the
-expression you supply is valid.  It parses it to make sure it looks legal, but
-it can't *actually* know.  You must be very careful when using expressions to
-specify values that are guaranteed to be valid at runtime!
-
-Finally, because expressions must be representable as static C values, there
-are many restrictions on legal expressions.  Here's a list of Python features
-you're not permitted to use:
-
-* Function calls.
-* Inline if statements (``3 if foo else 5``).
-* Automatic sequence unpacking (``*[1, 2, 3]``).
-* List/set/dict comprehensions and generator expressions.
-* Tuple/list/set/dict literals.
-
-
-.. _clinic-howto-return-converters:
-
-How to use return converters
-----------------------------
-
-By default, the impl function Argument Clinic generates for you returns
-:c:type:`PyObject * <PyObject>`.
-But your C function often computes some C type,
-then converts it into the :c:type:`!PyObject *`
-at the last moment.  Argument Clinic handles converting your inputs from Python types
-into native C types—why not have it convert your return value from a native C type
-into a Python type too?
-
-That's what a "return converter" does.  It changes your impl function to return
-some C type, then adds code to the generated (non-impl) function to handle converting
-that value into the appropriate :c:type:`!PyObject *`.
-
-The syntax for return converters is similar to that of parameter converters.
-You specify the return converter like it was a return annotation on the
-function itself, using ``->`` notation.
-
-For example:
-
-.. code-block:: c
-
-   /*[clinic input]
-   add -> int
-
-       a: int
-       b: int
-       /
-
-   [clinic start generated code]*/
-
-Return converters behave much the same as parameter converters;
-they take arguments, the arguments are all keyword-only, and if you're not changing
-any of the default arguments you can omit the parentheses.
-
-(If you use both ``"as"`` *and* a return converter for your function,
-the ``"as"`` should come before the return converter.)
-
-There's one additional complication when using return converters: how do you
-indicate an error has occurred?  Normally, a function returns a valid (non-``NULL``)
-pointer for success, and ``NULL`` for failure.  But if you use an integer return converter,
-all integers are valid.  How can Argument Clinic detect an error?  Its solution: each return
-converter implicitly looks for a special value that indicates an error.  If you return
-that value, and an error has been set (c:func:`PyErr_Occurred` returns a true
-value), then the generated code will propagate the error.  Otherwise it will
-encode the value you return like normal.
-
-Currently Argument Clinic supports only a few return converters:
-
-.. code-block:: none
-
-    bool
-    double
-    float
-    int
-    long
-    Py_ssize_t
-    size_t
-    unsigned int
-    unsigned long
-
-None of these take parameters.
-For all of these, return ``-1`` to indicate error.
-
-To see all the return converters Argument Clinic supports, along with
-their parameters (if any),
-just run ``Tools/clinic/clinic.py --converters`` for the full list.
-
-
-How to clone existing functions
--------------------------------
-
-If you have a number of functions that look similar, you may be able to
-use Clinic's "clone" feature.  When you clone an existing function,
-you reuse:
-
-* its parameters, including
-
-  * their names,
-
-  * their converters, with all parameters,
-
-  * their default values,
-
-  * their per-parameter docstrings,
-
-  * their *kind* (whether they're positional only,
-    positional or keyword, or keyword only), and
-
-* its return converter.
-
-The only thing not copied from the original function is its docstring;
-the syntax allows you to specify a new docstring.
-
-Here's the syntax for cloning a function::
-
-    /*[clinic input]
-    module.class.new_function [as c_basename] = module.class.existing_function
-
-    Docstring for new_function goes here.
-    [clinic start generated code]*/
-
-(The functions can be in different modules or classes.  I wrote
-``module.class`` in the sample just to illustrate that you must
-use the full path to *both* functions.)
-
-Sorry, there's no syntax for partially cloning a function, or cloning a function
-then modifying it.  Cloning is an all-or nothing proposition.
-
-Also, the function you are cloning from must have been previously defined
-in the current file.
-
-
-How to call Python code
------------------------
-
-The rest of the advanced topics require you to write Python code
-which lives inside your C file and modifies Argument Clinic's
-runtime state.  This is simple: you simply define a Python block.
-
-A Python block uses different delimiter lines than an Argument
-Clinic function block.  It looks like this::
-
-    /*[python input]
-    # python code goes here
-    [python start generated code]*/
-
-All the code inside the Python block is executed at the
-time it's parsed.  All text written to stdout inside the block
-is redirected into the "output" after the block.
-
-As an example, here's a Python block that adds a static integer
-variable to the C code::
-
-    /*[python input]
-    print('static int __ignored_unused_variable__ = 0;')
-    [python start generated code]*/
-    static int __ignored_unused_variable__ = 0;
-    /*[python checksum:...]*/
-
-
-.. _clinic-howto-self-converter:
-
-How to use the "self converter"
--------------------------------
-
-Argument Clinic automatically adds a "self" parameter for you
-using a default converter.  It automatically sets the ``type``
-of this parameter to the "pointer to an instance" you specified
-when you declared the type.  However, you can override
-Argument Clinic's converter and specify one yourself.
-Just add your own *self* parameter as the first parameter in a
-block, and ensure that its converter is an instance of
-:class:`!self_converter` or a subclass thereof.
-
-What's the point?  This lets you override the type of ``self``,
-or give it a different default name.
-
-How do you specify the custom type you want to cast ``self`` to?
-If you only have one or two functions with the same type for ``self``,
-you can directly use Argument Clinic's existing ``self`` converter,
-passing in the type you want to use as the *type* parameter::
-
-    /*[clinic input]
-
-    _pickle.Pickler.dump
-
-      self: self(type="PicklerObject *")
-      obj: object
-      /
-
-    Write a pickled representation of the given object to the open file.
-    [clinic start generated code]*/
-
-On the other hand, if you have a lot of functions that will use the same
-type for ``self``, it's best to create your own converter, subclassing
-:class:`!self_converter` but overwriting the :py:attr:`!type` member::
-
-    /*[python input]
-    class PicklerObject_converter(self_converter):
-        type = "PicklerObject *"
-    [python start generated code]*/
-
-    /*[clinic input]
-
-    _pickle.Pickler.dump
-
-      self: PicklerObject
-      obj: object
-      /
-
-    Write a pickled representation of the given object to the open file.
-    [clinic start generated code]*/
-
-
-How to use the "defining class" converter
------------------------------------------
-
-Argument Clinic facilitates gaining access to the defining class of a method.
-This is useful for :ref:`heap type <heap-types>` methods that need to fetch
-module level state.  Use :c:func:`PyType_FromModuleAndSpec` to associate a new
-heap type with a module.  You can now use :c:func:`PyType_GetModuleState` on
-the defining class to fetch the module state, for example from a module method.
-
-Example from :source:`Modules/zlibmodule.c`.
-First, ``defining_class`` is added to the clinic input::
-
-    /*[clinic input]
-    zlib.Compress.compress
-
-      cls: defining_class
-      data: Py_buffer
-        Binary data to be compressed.
-      /
-
-
-After running the Argument Clinic tool, the following function signature is
-generated::
-
-    /*[clinic start generated code]*/
-    static PyObject *
-    zlib_Compress_compress_impl(compobject *self, PyTypeObject *cls,
-                                Py_buffer *data)
-    /*[clinic end generated code: output=6731b3f0ff357ca6 input=04d00f65ab01d260]*/
-
-
-The following code can now use ``PyType_GetModuleState(cls)`` to fetch the
-module state::
-
-    zlibstate *state = PyType_GetModuleState(cls);
-
-
-Each method may only have one argument using this converter, and it must appear
-after ``self``, or, if ``self`` is not used, as the first argument.  The argument
-will be of type ``PyTypeObject *``.  The argument will not appear in the
-:py:attr:`!__text_signature__`.
-
-The ``defining_class`` converter is not compatible with :py:meth:`!__init__`
-and :py:meth:`!__new__` methods, which cannot use the :c:macro:`METH_METHOD`
-convention.
-
-It is not possible to use ``defining_class`` with slot methods.  In order to
-fetch the module state from such methods, use :c:func:`PyType_GetModuleByDef`
-to look up the module and then :c:func:`PyModule_GetState` to fetch the module
-state.  Example from the ``setattro`` slot method in
-:source:`Modules/_threadmodule.c`::
-
-    static int
-    local_setattro(localobject *self, PyObject *name, PyObject *v)
-    {
-        PyObject *module = PyType_GetModuleByDef(Py_TYPE(self), &thread_module);
-        thread_module_state *state = get_thread_state(module);
-        ...
-    }
-
-
-See also :pep:`573`.
-
-
-.. _clinic-howto-custom-converter:
-
-How to write a custom converter
--------------------------------
-
-A converter is a Python class that inherits from :py:class:`CConverter`.
-The main purpose of a custom converter, is for parameters parsed with
-the ``O&`` format unit --- parsing such a parameter means calling
-a :c:func:`PyArg_ParseTuple` "converter function".
-
-Your converter class should be named :samp:`{ConverterName}_converter`.
-By following this convention, your converter class will be automatically
-registered with Argument Clinic, with its *converter name* being the name of
-your converter class with the ``_converter`` suffix stripped off.
-
-Instead of subclassing :py:meth:`!CConverter.__init__`,
-write a :py:meth:`!converter_init` method.
-:py:meth:`!converter_init` always accepts a *self* parameter.
-After *self*, all additional parameters **must** be keyword-only.
-Any arguments passed to the converter in Argument Clinic
-will be passed along to your :py:meth:`!converter_init` method.
-See :py:class:`CConverter` for a list of members you may wish to specify in
-your subclass.
-
-Here's the simplest example of a custom converter, from :source:`Modules/zlibmodule.c`::
-
-    /*[python input]
-
-    class ssize_t_converter(CConverter):
-        type = 'Py_ssize_t'
-        converter = 'ssize_t_converter'
-
-    [python start generated code]*/
-    /*[python end generated code: output=da39a3ee5e6b4b0d input=35521e4e733823c7]*/
-
-This block adds a converter named ``ssize_t`` to Argument Clinic.
-Parameters declared as ``ssize_t`` will be declared with type :c:type:`Py_ssize_t`,
-and will be parsed by the ``'O&'`` format unit,
-which will call the :c:func:`!ssize_t_converter` converter C function.
-``ssize_t`` variables automatically support default values.
-
-More sophisticated custom converters can insert custom C code to
-handle initialization and cleanup.
-You can see more examples of custom converters in the CPython
-source tree; grep the C files for the string ``CConverter``.
-
-
-How to write a custom return converter
---------------------------------------
-
-Writing a custom return converter is much like writing
-a custom converter.  Except it's somewhat simpler, because return
-converters are themselves much simpler.
-
-Return converters must subclass :py:class:`!CReturnConverter`.
-There are no examples yet of custom return converters,
-because they are not widely used yet.  If you wish to
-write your own return converter, please read :source:`Tools/clinic/clinic.py`,
-specifically the implementation of :py:class:`!CReturnConverter` and
-all its subclasses.
-
-
-How to convert ``METH_O`` and ``METH_NOARGS`` functions
--------------------------------------------------------
-
-To convert a function using :c:macro:`METH_O`, make sure the function's
-single argument is using the ``object`` converter, and mark the
-arguments as positional-only::
-
-    /*[clinic input]
-    meth_o_sample
-
-         argument: object
-         /
-    [clinic start generated code]*/
-
-
-To convert a function using :c:macro:`METH_NOARGS`, just don't specify
-any arguments.
-
-You can still use a self converter, a return converter, and specify
-a *type* argument to the object converter for :c:macro:`METH_O`.
-
-
-How to convert ``tp_new`` and ``tp_init`` functions
----------------------------------------------------
-
-You can convert :c:member:`~PyTypeObject.tp_new` and
-:c:member:`~PyTypeObject.tp_init` functions.
-Just name them ``__new__`` or ``__init__`` as appropriate.  Notes:
-
-* The function name generated for ``__new__`` doesn't end in ``__new__``
-  like it would by default.  It's just the name of the class, converted
-  into a valid C identifier.
-
-* No :c:type:`PyMethodDef` ``#define`` is generated for these functions.
-
-* ``__init__`` functions return ``int``, not ``PyObject *``.
-
-* Use the docstring as the class docstring.
-
-* Although ``__new__`` and ``__init__`` functions must always
-  accept both the ``args`` and ``kwargs`` objects, when converting
-  you may specify any signature for these functions that you like.
-  (If your function doesn't support keywords, the parsing function
-  generated will throw an exception if it receives any.)
-
-
-How to change and redirect Clinic's output
-------------------------------------------
-
-It can be inconvenient to have Clinic's output interspersed with
-your conventional hand-edited C code.  Luckily, Clinic is configurable:
-you can buffer up its output for printing later (or earlier!), or write
-its output to a separate file.  You can also add a prefix or suffix to
-every line of Clinic's generated output.
-
-While changing Clinic's output in this manner can be a boon to readability,
-it may result in Clinic code using types before they are defined, or
-your code attempting to use Clinic-generated code before it is defined.
-These problems can be easily solved by rearranging the declarations in your file,
-or moving where Clinic's generated code goes.  (This is why the default behavior
-of Clinic is to output everything into the current block; while many people
-consider this hampers readability, it will never require rearranging your
-code to fix definition-before-use problems.)
-
-Let's start with defining some terminology:
-
-*field*
-  A field, in this context, is a subsection of Clinic's output.
-  For example, the ``#define`` for the :c:type:`PyMethodDef` structure
-  is a field, called ``methoddef_define``.  Clinic has seven
-  different fields it can output per function definition:
-
-  .. code-block:: none
-
-      docstring_prototype
-      docstring_definition
-      methoddef_define
-      impl_prototype
-      parser_prototype
-      parser_definition
-      impl_definition
-
-  All the names are of the form ``"<a>_<b>"``,
-  where ``"<a>"`` is the semantic object represented (the parsing function,
-  the impl function, the docstring, or the methoddef structure) and ``"<b>"``
-  represents what kind of statement the field is.  Field names that end in
-  ``"_prototype"``
-  represent forward declarations of that thing, without the actual body/data
-  of the thing; field names that end in ``"_definition"`` represent the actual
-  definition of the thing, with the body/data of the thing.  (``"methoddef"``
-  is special, it's the only one that ends with ``"_define"``, representing that
-  it's a preprocessor #define.)
-
-*destination*
-  A destination is a place Clinic can write output to.  There are
-  five built-in destinations:
-
-  ``block``
-    The default destination: printed in the output section of
-    the current Clinic block.
-
-  ``buffer``
-    A text buffer where you can save text for later.  Text sent
-    here is appended to the end of any existing text.  It's an
-    error to have any text left in the buffer when Clinic finishes
-    processing a file.
-
-  ``file``
-    A separate "clinic file" that will be created automatically by Clinic.
-    The filename chosen for the file is ``{basename}.clinic{extension}``,
-    where ``basename`` and ``extension`` were assigned the output
-    from ``os.path.splitext()`` run on the current file.  (Example:
-    the ``file`` destination for :file:`_pickle.c` would be written to
-    :file:`_pickle.clinic.c`.)
-
-    **Important: When using a** ``file`` **destination, you**
-    *must check in* **the generated file!**
-
-  ``two-pass``
-    A buffer like ``buffer``.  However, a two-pass buffer can only
-    be dumped once, and it prints out all text sent to it during
-    all processing, even from Clinic blocks *after* the dumping point.
-
-  ``suppress``
-    The text is suppressed—thrown away.
-
-
-Clinic defines five new directives that let you reconfigure its output.
-
-The first new directive is ``dump``:
-
-.. code-block:: none
-
-   dump <destination>
-
-This dumps the current contents of the named destination into the output of
-the current block, and empties it.  This only works with ``buffer`` and
-``two-pass`` destinations.
-
-The second new directive is ``output``.  The most basic form of ``output``
-is like this:
-
-.. code-block:: none
-
-    output <field> <destination>
-
-This tells Clinic to output *field* to *destination*.  ``output`` also
-supports a special meta-destination, called ``everything``, which tells
-Clinic to output *all* fields to that *destination*.
-
-``output`` has a number of other functions:
-
-.. code-block:: none
-
-    output push
-    output pop
-    output preset <preset>
-
-
-``output push`` and ``output pop`` allow you to push and pop
-configurations on an internal configuration stack, so that you
-can temporarily modify the output configuration, then easily restore
-the previous configuration.  Simply push before your change to save
-the current configuration, then pop when you wish to restore the
-previous configuration.
-
-``output preset`` sets Clinic's output to one of several built-in
-preset configurations, as follows:
-
-  ``block``
-    Clinic's original starting configuration.  Writes everything
-    immediately after the input block.
-
-    Suppress the ``parser_prototype``
-    and ``docstring_prototype``, write everything else to ``block``.
-
-  ``file``
-    Designed to write everything to the "clinic file" that it can.
-    You then ``#include`` this file near the top of your file.
-    You may need to rearrange your file to make this work, though
-    usually this just means creating forward declarations for various
-    ``typedef`` and ``PyTypeObject`` definitions.
-
-    Suppress the ``parser_prototype``
-    and ``docstring_prototype``, write the ``impl_definition`` to
-    ``block``, and write everything else to ``file``.
-
-    The default filename is ``"{dirname}/clinic/{basename}.h"``.
-
-  ``buffer``
-    Save up most of the output from Clinic, to be written into
-    your file near the end.  For Python files implementing modules
-    or builtin types, it's recommended that you dump the buffer
-    just above the static structures for your module or
-    builtin type; these are normally very near the end.  Using
-    ``buffer`` may require even more editing than ``file``, if
-    your file has static ``PyMethodDef`` arrays defined in the
-    middle of the file.
-
-    Suppress the ``parser_prototype``, ``impl_prototype``,
-    and ``docstring_prototype``, write the ``impl_definition`` to
-    ``block``, and write everything else to ``file``.
-
-  ``two-pass``
-    Similar to the ``buffer`` preset, but writes forward declarations to
-    the ``two-pass`` buffer, and definitions to the ``buffer``.
-    This is similar to the ``buffer`` preset, but may require
-    less editing than ``buffer``.  Dump the ``two-pass`` buffer
-    near the top of your file, and dump the ``buffer`` near
-    the end just like you would when using the ``buffer`` preset.
-
-    Suppresses the ``impl_prototype``, write the ``impl_definition``
-    to ``block``, write ``docstring_prototype``, ``methoddef_define``,
-    and ``parser_prototype`` to ``two-pass``, write everything else
-    to ``buffer``.
-
-  ``partial-buffer``
-    Similar to the ``buffer`` preset, but writes more things to ``block``,
-    only writing the really big chunks of generated code to ``buffer``.
-    This avoids the definition-before-use problem of ``buffer`` completely,
-    at the small cost of having slightly more stuff in the block's output.
-    Dump the ``buffer`` near the end, just like you would when using
-    the ``buffer`` preset.
-
-    Suppresses the ``impl_prototype``, write the ``docstring_definition``
-    and ``parser_definition`` to ``buffer``, write everything else to ``block``.
-
-The third new directive is ``destination``:
-
-.. code-block:: none
-
-    destination <name> <command> [...]
-
-This performs an operation on the destination named ``name``.
-
-There are two defined subcommands: ``new`` and ``clear``.
-
-The ``new`` subcommand works like this:
-
-.. code-block:: none
-
-    destination <name> new <type>
-
-This creates a new destination with name ``<name>`` and type ``<type>``.
-
-There are five destination types:
-
-    ``suppress``
-        Throws the text away.
-
-    ``block``
-        Writes the text to the current block.  This is what Clinic
-        originally did.
-
-    ``buffer``
-        A simple text buffer, like the "buffer" builtin destination above.
-
-    ``file``
-        A text file.  The file destination takes an extra argument,
-        a template to use for building the filename, like so:
-
-            destination <name> new <type> <file_template>
-
-        The template can use three strings internally that will be replaced
-        by bits of the filename:
-
-            {path}
-                The full path to the file, including directory and full filename.
-            {dirname}
-                The name of the directory the file is in.
-            {basename}
-                Just the name of the file, not including the directory.
-            {basename_root}
-                Basename with the extension clipped off
-                (everything up to but not including the last '.').
-            {basename_extension}
-                The last '.' and everything after it.  If the basename
-                does not contain a period, this will be the empty string.
-
-        If there are no periods in the filename, {basename} and {filename}
-        are the same, and {extension} is empty.  "{basename}{extension}"
-        is always exactly the same as "{filename}"."
-
-    ``two-pass``
-        A two-pass buffer, like the "two-pass" builtin destination above.
-
-
-The ``clear`` subcommand works like this:
-
-.. code-block:: none
-
-    destination <name> clear
-
-It removes all the accumulated text up to this point in the destination.
-(I don't know what you'd need this for, but I thought maybe it'd be
-useful while someone's experimenting.)
-
-The fourth new directive is ``set``:
-
-.. code-block:: none
-
-    set line_prefix "string"
-    set line_suffix "string"
-
-``set`` lets you set two internal variables in Clinic.
-``line_prefix`` is a string that will be prepended to every line of Clinic's output;
-``line_suffix`` is a string that will be appended to every line of Clinic's output.
-
-Both of these support two format strings:
-
-  ``{block comment start}``
-    Turns into the string ``/*``, the start-comment text sequence for C files.
-
-  ``{block comment end}``
-    Turns into the string ``*/``, the end-comment text sequence for C files.
-
-The final new directive is one you shouldn't need to use directly,
-called ``preserve``:
-
-.. code-block:: none
-
-    preserve
-
-This tells Clinic that the current contents of the output should be kept, unmodified.
-This is used internally by Clinic when dumping output into ``file`` files; wrapping
-it in a Clinic block lets Clinic use its existing checksum functionality to ensure
-the file was not modified by hand before it gets overwritten.
-
-
-How to use the ``#ifdef`` trick
--------------------------------
-
-If you're converting a function that isn't available on all platforms,
-there's a trick you can use to make life a little easier.  The existing
-code probably looks like this::
-
-    #ifdef HAVE_FUNCTIONNAME
-    static module_functionname(...)
-    {
-    ...
-    }
-    #endif /* HAVE_FUNCTIONNAME */
-
-And then in the ``PyMethodDef`` structure at the bottom the existing code
-will have:
-
-.. code-block:: none
-
-    #ifdef HAVE_FUNCTIONNAME
-    {'functionname', ... },
-    #endif /* HAVE_FUNCTIONNAME */
-
-In this scenario, you should enclose the body of your impl function inside the ``#ifdef``,
-like so::
-
-    #ifdef HAVE_FUNCTIONNAME
-    /*[clinic input]
-    module.functionname
-    ...
-    [clinic start generated code]*/
-    static module_functionname(...)
-    {
-    ...
-    }
-    #endif /* HAVE_FUNCTIONNAME */
-
-Then, remove those three lines from the :c:type:`PyMethodDef` structure,
-replacing them with the macro Argument Clinic generated:
-
-.. code-block:: none
-
-    MODULE_FUNCTIONNAME_METHODDEF
-
-(You can find the real name for this macro inside the generated code.
-Or you can calculate it yourself: it's the name of your function as defined
-on the first line of your block, but with periods changed to underscores,
-uppercased, and ``"_METHODDEF"`` added to the end.)
-
-Perhaps you're wondering: what if ``HAVE_FUNCTIONNAME`` isn't defined?
-The ``MODULE_FUNCTIONNAME_METHODDEF`` macro won't be defined either!
-
-Here's where Argument Clinic gets very clever.  It actually detects that the
-Argument Clinic block might be deactivated by the ``#ifdef``.  When that
-happens, it generates a little extra code that looks like this::
-
-    #ifndef MODULE_FUNCTIONNAME_METHODDEF
-        #define MODULE_FUNCTIONNAME_METHODDEF
-    #endif /* !defined(MODULE_FUNCTIONNAME_METHODDEF) */
-
-That means the macro always works.  If the function is defined, this turns
-into the correct structure, including the trailing comma.  If the function is
-undefined, this turns into nothing.
-
-However, this causes one ticklish problem: where should Argument Clinic put this
-extra code when using the "block" output preset?  It can't go in the output block,
-because that could be deactivated by the ``#ifdef``.  (That's the whole point!)
-
-In this situation, Argument Clinic writes the extra code to the "buffer" destination.
-This may mean that you get a complaint from Argument Clinic:
-
-.. code-block:: none
-
-    Warning in file "Modules/posixmodule.c" on line 12357:
-    Destination buffer 'buffer' not empty at end of file, emptying.
-
-When this happens, just open your file, find the ``dump buffer`` block that
-Argument Clinic added to your file (it'll be at the very bottom), then
-move it above the :c:type:`PyMethodDef` structure where that macro is used.
-
-
-How to use Argument Clinic in Python files
-------------------------------------------
-
-It's actually possible to use Argument Clinic to preprocess Python files.
-There's no point to using Argument Clinic blocks, of course, as the output
-wouldn't make any sense to the Python interpreter.  But using Argument Clinic
-to run Python blocks lets you use Python as a Python preprocessor!
-
-Since Python comments are different from C comments, Argument Clinic
-blocks embedded in Python files look slightly different.  They look like this:
-
-.. code-block:: python3
-
-    #/*[python input]
-    #print("def foo(): pass")
-    #[python start generated code]*/
-    def foo(): pass
-    #/*[python checksum:...]*/
+   The Argument Clinic How-TO has been moved to the `Python Developer's Guide
+   <https://devguide.python.org/development-tools/clinic/>`__.
diff --git a/Doc/howto/descriptor.rst b/Doc/howto/descriptor.rst
index 1d9424cb73..0a72636146 100644
--- a/Doc/howto/descriptor.rst
+++ b/Doc/howto/descriptor.rst
@@ -943,6 +943,10 @@ it can be updated:
     >>> Movie('Star Wars').director
     'J.J. Abrams'
 
+.. testcleanup::
+
+   conn.close()
+
 
 Pure Python Equivalents
 ^^^^^^^^^^^^^^^^^^^^^^^
diff --git a/Doc/howto/enum.rst b/Doc/howto/enum.rst
index 28749754a5..0830fb630d 100644
--- a/Doc/howto/enum.rst
+++ b/Doc/howto/enum.rst
@@ -483,6 +483,7 @@ Dataclass support
 When inheriting from a :class:`~dataclasses.dataclass`,
 the :meth:`~Enum.__repr__` omits the inherited class' name.  For example::
 
+    >>> from dataclasses import dataclass, field
     >>> @dataclass
     ... class CreatureDataMixin:
     ...     size: str
@@ -527,7 +528,8 @@ It is possible to modify how enum members are pickled/unpickled by defining
 :meth:`__reduce_ex__` in the enumeration class.  The default method is by-value,
 but enums with complicated values may want to use by-name::
 
-    >>> class MyEnum(Enum):
+    >>> import enum
+    >>> class MyEnum(enum.Enum):
     ...     __reduce_ex__ = enum.pickle_by_enum_name
 
 .. note::
@@ -770,7 +772,7 @@ be combined with them (but may lose :class:`IntFlag` membership::
     >>> Perm.X | 4
     <Perm.R|X: 5>
 
-    >>> Perm.X | 8
+    >>> Perm.X + 8
     9
 
 .. note::
@@ -1156,13 +1158,14 @@ the following are true:
 There is a new boundary mechanism that controls how out-of-range / invalid
 bits are handled: ``STRICT``, ``CONFORM``, ``EJECT``, and ``KEEP``:
 
-  * STRICT --> raises an exception when presented with invalid values
-  * CONFORM --> discards any invalid bits
-  * EJECT --> lose Flag status and become a normal int with the given value
-  * KEEP --> keep the extra bits
-           - keeps Flag status and extra bits
-           - extra bits do not show up in iteration
-           - extra bits do show up in repr() and str()
+* STRICT --> raises an exception when presented with invalid values
+* CONFORM --> discards any invalid bits
+* EJECT --> lose Flag status and become a normal int with the given value
+* KEEP --> keep the extra bits
+
+  - keeps Flag status and extra bits
+  - extra bits do not show up in iteration
+  - extra bits do show up in repr() and str()
 
 The default for Flag is ``STRICT``, the default for ``IntFlag`` is ``EJECT``,
 and the default for ``_convert_`` is ``KEEP`` (see ``ssl.Options`` for an
@@ -1434,8 +1437,9 @@ alias::
     ...     GRENE = 2
     ...
     Traceback (most recent call last):
-    ...
+      ...
     ValueError: aliases not allowed in DuplicateFreeEnum:  'GRENE' --> 'GREEN'
+    Error calling __set_name__ on '_proto_member' instance 'GRENE' in 'Color'
 
 .. note::
 
diff --git a/Doc/howto/index.rst b/Doc/howto/index.rst
index f521276a5a..6280f05771 100644
--- a/Doc/howto/index.rst
+++ b/Doc/howto/index.rst
@@ -28,7 +28,6 @@ Currently, the HOWTOs are:
    urllib2.rst
    argparse.rst
    ipaddress.rst
-   clinic.rst
    instrumentation.rst
    perf_profiling.rst
    annotations.rst
diff --git a/Doc/howto/instrumentation.rst b/Doc/howto/instrumentation.rst
index 875f846aad..9c99fcecce 100644
--- a/Doc/howto/instrumentation.rst
+++ b/Doc/howto/instrumentation.rst
@@ -13,9 +13,9 @@ DTrace and SystemTap are monitoring tools, each providing a way to inspect
 what the processes on a computer system are doing.  They both use
 domain-specific languages allowing a user to write scripts which:
 
-  - filter which processes are to be observed
-  - gather data from the processes of interest
-  - generate reports on the data
+- filter which processes are to be observed
+- gather data from the processes of interest
+- generate reports on the data
 
 As of Python 3.6, CPython can be built with embedded "markers", also
 known as "probes", that can be observed by a DTrace or SystemTap script,
@@ -246,11 +246,9 @@ The output looks like this:
 
 where the columns are:
 
-  - time in microseconds since start of script
-
-  - name of executable
-
-  - PID of process
+- time in microseconds since start of script
+- name of executable
+- PID of process
 
 and the remainder indicates the call/return hierarchy as the script executes.
 
diff --git a/Doc/howto/perf_profiling.rst b/Doc/howto/perf_profiling.rst
index 61812c19ae..af7b67d204 100644
--- a/Doc/howto/perf_profiling.rst
+++ b/Doc/howto/perf_profiling.rst
@@ -162,8 +162,7 @@ the :option:`!-X` option takes precedence over the environment variable.
 
 Example, using the environment variable::
 
-   $ PYTHONPERFSUPPORT=1
-   $ python script.py
+   $ PYTHONPERFSUPPORT=1 python script.py
    $ perf report -g -i perf.data
 
 Example, using the :option:`!-X` option::
diff --git a/Doc/howto/pyporting.rst b/Doc/howto/pyporting.rst
index 6c30a0dd7d..501b16d82d 100644
--- a/Doc/howto/pyporting.rst
+++ b/Doc/howto/pyporting.rst
@@ -39,7 +39,8 @@ are:
 #. Once your dependencies are no longer blocking you, use continuous integration
    to make sure you stay compatible with Python 2 and 3 (tox_ can help test
    against multiple versions of Python; ``python -m pip install tox``)
-#. Consider using optional static type checking to make sure your type usage
+#. Consider using optional :term:`static type checking <static type checker>`
+   to make sure your type usage
    works in both Python 2 and 3 (e.g. use mypy_ to check your typing under both
    Python 2 and Python 3; ``python -m pip install mypy``).
 
@@ -395,7 +396,7 @@ comparisons occur, making the mistake much easier to track down.
 Consider using optional static type checking
 --------------------------------------------
 
-Another way to help port your code is to use a static type checker like
+Another way to help port your code is to use a :term:`static type checker` like
 mypy_ or pytype_ on your code. These tools can be used to analyze your code as
 if it's being run under Python 2, then you can run the tool a second time as if
 your code is running under Python 3. By running a static type checker twice like
diff --git a/Doc/howto/regex.rst b/Doc/howto/regex.rst
index c19c48301f..5e2f9a9d18 100644
--- a/Doc/howto/regex.rst
+++ b/Doc/howto/regex.rst
@@ -245,6 +245,9 @@ You can omit either *m* or *n*; in that case, a reasonable value is assumed for
 the missing value.  Omitting *m* is interpreted as a lower limit of 0, while
 omitting *n* results in an upper bound of infinity.
 
+The simplest case ``{m}`` matches the preceding item exactly *m* times.
+For example, ``a/{2}b`` will only match ``'a//b'``.
+
 Readers of a reductionist bent may notice that the three other quantifiers can
 all be expressed using this notation.  ``{0,}`` is the same as ``*``, ``{1,}``
 is equivalent to ``+``, and ``{0,1}`` is the same as ``?``.  It's better to use
diff --git a/Doc/library/__main__.rst b/Doc/library/__main__.rst
index d378e40b39..24a32b30bb 100644
--- a/Doc/library/__main__.rst
+++ b/Doc/library/__main__.rst
@@ -54,45 +54,45 @@ The top-level code environment can be:
 
 * the scope of an interactive prompt::
 
-    >>> __name__
-    '__main__'
+   >>> __name__
+   '__main__'
 
 * the Python module passed to the Python interpreter as a file argument:
 
-    .. code-block:: shell-session
+  .. code-block:: shell-session
 
-       $ python helloworld.py
-       Hello, world!
+     $ python helloworld.py
+     Hello, world!
 
 * the Python module or package passed to the Python interpreter with the
   :option:`-m` argument:
 
-    .. code-block:: shell-session
+  .. code-block:: shell-session
 
-       $ python -m tarfile
-       usage: tarfile.py [-h] [-v] (...)
+     $ python -m tarfile
+     usage: tarfile.py [-h] [-v] (...)
 
 * Python code read by the Python interpreter from standard input:
 
-    .. code-block:: shell-session
+  .. code-block:: shell-session
 
-       $ echo "import this" | python
-       The Zen of Python, by Tim Peters
+     $ echo "import this" | python
+     The Zen of Python, by Tim Peters
 
-       Beautiful is better than ugly.
-       Explicit is better than implicit.
-       ...
+     Beautiful is better than ugly.
+     Explicit is better than implicit.
+     ...
 
 * Python code passed to the Python interpreter with the :option:`-c` argument:
 
-    .. code-block:: shell-session
+  .. code-block:: shell-session
 
-       $ python -c "import this"
-       The Zen of Python, by Tim Peters
+     $ python -c "import this"
+     The Zen of Python, by Tim Peters
 
-       Beautiful is better than ugly.
-       Explicit is better than implicit.
-       ...
+     Beautiful is better than ugly.
+     Explicit is better than implicit.
+     ...
 
 In each of these situations, the top-level module's ``__name__`` is set to
 ``'__main__'``.
@@ -102,9 +102,9 @@ top-level environment by checking its own ``__name__``, which allows a common
 idiom for conditionally executing code when the module is not initialized from
 an import statement::
 
-    if __name__ == '__main__':
-        # Execute when the module is not initialized from an import statement.
-        ...
+   if __name__ == '__main__':
+       # Execute when the module is not initialized from an import statement.
+       ...
 
 .. seealso::
 
diff --git a/Doc/library/_thread.rst b/Doc/library/_thread.rst
index 0442c298c1..d7c61c3d7e 100644
--- a/Doc/library/_thread.rst
+++ b/Doc/library/_thread.rst
@@ -208,7 +208,7 @@ In addition to these methods, lock objects can also be used via the
 
 **Caveats:**
 
-  .. index:: pair: module; signal
+.. index:: pair: module; signal
 
 * Threads interact strangely with interrupts: the :exc:`KeyboardInterrupt`
   exception will be received by an arbitrary thread.  (When the :mod:`signal`
diff --git a/Doc/library/abc.rst b/Doc/library/abc.rst
index 274b2d69f0..fb4f9da169 100644
--- a/Doc/library/abc.rst
+++ b/Doc/library/abc.rst
@@ -154,7 +154,7 @@ a helper class :class:`ABC` to alternatively define ABCs through inheritance:
    Finally, the last line makes ``Foo`` a virtual subclass of ``MyIterable``,
    even though it does not define an :meth:`~iterator.__iter__` method (it uses
    the old-style iterable protocol, defined in terms of :meth:`__len__` and
-   :meth:`__getitem__`).  Note that this will not make ``get_iterator``
+   :meth:`~object.__getitem__`).  Note that this will not make ``get_iterator``
    available as a method of ``Foo``, so it is provided separately.
 
 
diff --git a/Doc/library/ast.rst b/Doc/library/ast.rst
index a7fa807449..274d831f4d 100644
--- a/Doc/library/ast.rst
+++ b/Doc/library/ast.rst
@@ -2477,26 +2477,26 @@ The following options are accepted:
 
 .. program:: ast
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    Show the help message and exit.
 
-.. cmdoption:: -m <mode>
-               --mode <mode>
+.. option:: -m <mode>
+            --mode <mode>
 
    Specify what kind of code must be compiled, like the *mode* argument
    in :func:`parse`.
 
-.. cmdoption:: --no-type-comments
+.. option:: --no-type-comments
 
    Don't parse type comments.
 
-.. cmdoption:: -a, --include-attributes
+.. option:: -a, --include-attributes
 
    Include attributes such as line numbers and column offsets.
 
-.. cmdoption:: -i <indent>
-               --indent <indent>
+.. option:: -i <indent>
+            --indent <indent>
 
    Indentation of nodes in AST (number of spaces).
 
diff --git a/Doc/library/asyncio-eventloop.rst b/Doc/library/asyncio-eventloop.rst
index 04af53b980..78704d9bb2 100644
--- a/Doc/library/asyncio-eventloop.rst
+++ b/Doc/library/asyncio-eventloop.rst
@@ -243,9 +243,9 @@ Scheduling callbacks
    See the :ref:`concurrency and multithreading <asyncio-multithreading>`
    section of the documentation.
 
-.. versionchanged:: 3.7
-   The *context* keyword-only parameter was added. See :pep:`567`
-   for more details.
+   .. versionchanged:: 3.7
+      The *context* keyword-only parameter was added. See :pep:`567`
+      for more details.
 
 .. _asyncio-pass-keywords:
 
@@ -509,7 +509,7 @@ Opening network connections
 
    .. versionchanged:: 3.6
 
-      The socket option :py:const:`~socket.TCP_NODELAY` is set by default
+      The socket option :ref:`socket.TCP_NODELAY <socket-unix-constants>` is set by default
       for all TCP connections.
 
    .. versionchanged:: 3.7
@@ -581,7 +581,7 @@ Opening network connections
    * *reuse_port* tells the kernel to allow this endpoint to be bound to the
      same port as other existing endpoints are bound to, so long as they all
      set this flag when being created. This option is not supported on Windows
-     and some Unixes. If the :py:const:`~socket.SO_REUSEPORT` constant is not
+     and some Unixes. If the :ref:`socket.SO_REUSEPORT <socket-unix-constants>` constant is not
      defined then this capability is unsupported.
 
    * *allow_broadcast* tells the kernel to allow this endpoint to send
@@ -607,7 +607,8 @@ Opening network connections
 
    .. versionchanged:: 3.8.1
       The *reuse_address* parameter is no longer supported, as using
-      :py:const:`~sockets.SO_REUSEADDR` poses a significant security concern for
+      :ref:`socket.SO_REUSEADDR <socket-unix-constants>`
+      poses a significant security concern for
       UDP. Explicitly passing ``reuse_address=True`` will raise an exception.
 
       When multiple processes with differing UIDs assign sockets to an
@@ -616,7 +617,8 @@ Opening network connections
 
       For supported platforms, *reuse_port* can be used as a replacement for
       similar functionality. With *reuse_port*,
-      :py:const:`~sockets.SO_REUSEPORT` is used instead, which specifically
+      :ref:`socket.SO_REUSEPORT <socket-unix-constants>`
+      is used instead, which specifically
       prevents processes with differing UIDs from assigning sockets to the same
       socket address.
 
@@ -661,6 +663,8 @@ Opening network connections
 Creating network servers
 ^^^^^^^^^^^^^^^^^^^^^^^^
 
+.. _loop_create_server:
+
 .. coroutinemethod:: loop.create_server(protocol_factory, \
                         host=None, port=None, *, \
                         family=socket.AF_UNSPEC, \
@@ -756,7 +760,7 @@ Creating network servers
    .. versionchanged:: 3.6
 
       Added *ssl_handshake_timeout* and *start_serving* parameters.
-      The socket option :py:const:`~socket.TCP_NODELAY` is set by default
+      The socket option :ref:`socket.TCP_NODELAY <socket-unix-constants>` is set by default
       for all TCP connections.
 
    .. versionchanged:: 3.11
@@ -1191,6 +1195,8 @@ Working with pipes
 Unix signals
 ^^^^^^^^^^^^
 
+.. _loop_add_signal_handler:
+
 .. method:: loop.add_signal_handler(signum, callback, *args)
 
    Set *callback* as the handler for the *signum* signal.
@@ -1391,6 +1397,14 @@ Enabling debug mode
       The new :ref:`Python Development Mode <devmode>` can now also be used
       to enable the debug mode.
 
+.. attribute:: loop.slow_callback_duration
+
+   This attribute can be used to set the
+   minimum execution duration in seconds that is considered "slow".
+   When debug mode is enabled, "slow" callbacks are logged.
+
+   Default value is 100 milliseconds.
+
 .. seealso::
 
    The :ref:`debug mode of asyncio <asyncio-debug-mode>`.
@@ -1411,6 +1425,8 @@ async/await code consider using the high-level
    :ref:`Subprocess Support on Windows <asyncio-windows-subprocess>` for
    details.
 
+.. _loop_subprocess_exec:
+
 .. coroutinemethod:: loop.subprocess_exec(protocol_factory, *args, \
                       stdin=subprocess.PIPE, stdout=subprocess.PIPE, \
                       stderr=subprocess.PIPE, **kwargs)
@@ -1605,8 +1621,9 @@ Do not instantiate the :class:`Server` class directly.
       The sockets that represent existing incoming client connections
       are left open.
 
-      The server is closed asynchronously, use the :meth:`wait_closed`
-      coroutine to wait until the server is closed.
+      The server is closed asynchronously; use the :meth:`wait_closed`
+      coroutine to wait until the server is closed (and no more
+      connections are active).
 
    .. method:: get_loop()
 
@@ -1664,7 +1681,8 @@ Do not instantiate the :class:`Server` class directly.
 
    .. coroutinemethod:: wait_closed()
 
-      Wait until the :meth:`close` method completes.
+      Wait until the :meth:`close` method completes and all active
+      connections have finished.
 
    .. attribute:: sockets
 
@@ -1872,7 +1890,7 @@ Set signal handlers for SIGINT and SIGTERM
 
 (This ``signals`` example only works on Unix.)
 
-Register handlers for signals :py:data:`SIGINT` and :py:data:`SIGTERM`
+Register handlers for signals :const:`~signal.SIGINT` and :const:`~signal.SIGTERM`
 using the :meth:`loop.add_signal_handler` method::
 
     import asyncio
diff --git a/Doc/library/asyncio-llapi-index.rst b/Doc/library/asyncio-llapi-index.rst
index 9ce48a2444..67136ba69e 100644
--- a/Doc/library/asyncio-llapi-index.rst
+++ b/Doc/library/asyncio-llapi-index.rst
@@ -484,19 +484,19 @@ Protocol classes can implement the following **callback methods**:
     :widths: 50 50
     :class: full-width-table
 
-    * - ``callback`` :meth:`pipe_data_received()
-        <SubprocessProtocol.pipe_data_received>`
+    * - ``callback`` :meth:`~SubprocessProtocol.pipe_data_received`
       - Called when the child process writes data into its
         *stdout* or *stderr* pipe.
 
-    * - ``callback`` :meth:`pipe_connection_lost()
-        <SubprocessProtocol.pipe_connection_lost>`
+    * - ``callback`` :meth:`~SubprocessProtocol.pipe_connection_lost`
       - Called when one of the pipes communicating with
         the child process is closed.
 
     * - ``callback`` :meth:`process_exited()
         <SubprocessProtocol.process_exited>`
-      - Called when the child process has exited.
+      - Called when the child process has exited. It can be called before
+        :meth:`~SubprocessProtocol.pipe_data_received` and
+        :meth:`~SubprocessProtocol.pipe_connection_lost` methods.
 
 
 Event Loop Policies
diff --git a/Doc/library/asyncio-protocol.rst b/Doc/library/asyncio-protocol.rst
index 7bc906eaaf..48fa02937b 100644
--- a/Doc/library/asyncio-protocol.rst
+++ b/Doc/library/asyncio-protocol.rst
@@ -708,6 +708,9 @@ factories passed to the :meth:`loop.subprocess_exec` and
 
    Called when the child process has exited.
 
+   It can be called before :meth:`~SubprocessProtocol.pipe_data_received` and
+   :meth:`~SubprocessProtocol.pipe_connection_lost` methods.
+
 
 Examples
 ========
@@ -1003,12 +1006,26 @@ The subprocess is created by the :meth:`loop.subprocess_exec` method::
         def __init__(self, exit_future):
             self.exit_future = exit_future
             self.output = bytearray()
+            self.pipe_closed = False
+            self.exited = False
+
+        def pipe_connection_lost(self, fd, exc):
+            self.pipe_closed = True
+            self.check_for_exit()
 
         def pipe_data_received(self, fd, data):
             self.output.extend(data)
 
         def process_exited(self):
-            self.exit_future.set_result(True)
+            self.exited = True
+            # process_exited() method can be called before
+            # pipe_connection_lost() method: wait until both methods are
+            # called.
+            self.check_for_exit()
+
+        def check_for_exit(self):
+            if self.pipe_closed and self.exited:
+                self.exit_future.set_result(True)
 
     async def get_date():
         # Get a reference to the event loop as we plan to use
diff --git a/Doc/library/asyncio-task.rst b/Doc/library/asyncio-task.rst
index f488aa73a6..a3ea050c07 100644
--- a/Doc/library/asyncio-task.rst
+++ b/Doc/library/asyncio-task.rst
@@ -764,9 +764,6 @@ Timeouts
 
    If the wait is cancelled, the future *aw* is also cancelled.
 
-   .. versionchanged:: 3.10
-      Removed the *loop* parameter.
-
    .. _asyncio_example_waitfor:
 
    Example::
@@ -797,6 +794,9 @@ Timeouts
    .. versionchanged:: 3.10
       Removed the *loop* parameter.
 
+   .. versionchanged:: 3.11
+      Raises :exc:`TimeoutError` instead of :exc:`asyncio.TimeoutError`.
+
 
 Waiting Primitives
 ==================
diff --git a/Doc/library/asyncio.rst b/Doc/library/asyncio.rst
index c6a046f534..5f33c6813e 100644
--- a/Doc/library/asyncio.rst
+++ b/Doc/library/asyncio.rst
@@ -46,9 +46,9 @@ Additionally, there are **low-level** APIs for
 *library and framework developers* to:
 
 * create and manage :ref:`event loops <asyncio-event-loop>`, which
-  provide asynchronous APIs for :meth:`networking <loop.create_server>`,
-  running :meth:`subprocesses <loop.subprocess_exec>`,
-  handling :meth:`OS signals <loop.add_signal_handler>`, etc;
+  provide asynchronous APIs for :ref:`networking <loop_create_server>`,
+  running :ref:`subprocesses <loop_subprocess_exec>`,
+  handling :ref:`OS signals <loop_add_signal_handler>`, etc;
 
 * implement efficient protocols using
   :ref:`transports <asyncio-transports-protocols>`;
@@ -56,6 +56,8 @@ Additionally, there are **low-level** APIs for
 * :ref:`bridge <asyncio-futures>` callback-based libraries and code
   with async/await syntax.
 
+.. _asyncio-cli:
+
 You can experiment with an ``asyncio`` concurrent context in the REPL:
 
 .. code-block:: pycon
diff --git a/Doc/library/binascii.rst b/Doc/library/binascii.rst
index 21960cb797..d065fa3506 100644
--- a/Doc/library/binascii.rst
+++ b/Doc/library/binascii.rst
@@ -58,10 +58,11 @@ The :mod:`binascii` module defines the following functions:
    data will raise :exc:`binascii.Error`.
 
    Valid base64:
-      * Conforms to :rfc:`3548`.
-      * Contains only characters from the base64 alphabet.
-      * Contains no excess data after padding (including excess padding, newlines, etc.).
-      * Does not start with a padding.
+
+   * Conforms to :rfc:`3548`.
+   * Contains only characters from the base64 alphabet.
+   * Contains no excess data after padding (including excess padding, newlines, etc.).
+   * Does not start with a padding.
 
    .. versionchanged:: 3.11
       Added the *strict_mode* parameter.
diff --git a/Doc/library/bz2.rst b/Doc/library/bz2.rst
index ec4aeaa043..6a95a4a6e8 100644
--- a/Doc/library/bz2.rst
+++ b/Doc/library/bz2.rst
@@ -91,7 +91,7 @@ The :mod:`bz2` module contains:
    and :meth:`~io.IOBase.truncate`.
    Iteration and the :keyword:`with` statement are supported.
 
-   :class:`BZ2File` also provides the following method:
+   :class:`BZ2File` also provides the following methods:
 
    .. method:: peek([n])
 
@@ -106,14 +106,52 @@ The :mod:`bz2` module contains:
 
       .. versionadded:: 3.3
 
+   .. method:: fileno()
+
+      Return the file descriptor for the underlying file.
+
+      .. versionadded:: 3.3
+
+   .. method:: readable()
+
+      Return whether the file was opened for reading.
+
+      .. versionadded:: 3.3
+
+   .. method:: seekable()
+
+      Return whether the file supports seeking.
+
+      .. versionadded:: 3.3
+
+   .. method:: writable()
+
+      Return whether the file was opened for writing.
+
+      .. versionadded:: 3.3
+
+   .. method:: read1(size=-1)
+
+      Read up to *size* uncompressed bytes, while trying to avoid
+      making multiple reads from the underlying stream. Reads up to a
+      buffer's worth of data if size is negative.
+
+      Returns ``b''`` if the file is at EOF.
+
+      .. versionadded:: 3.3
+
+   .. method:: readinto(b)
+
+      Read bytes into *b*.
+
+      Returns the number of bytes read (0 for EOF).
+
+      .. versionadded:: 3.3
+
 
    .. versionchanged:: 3.1
       Support for the :keyword:`with` statement was added.
 
-   .. versionchanged:: 3.3
-      The :meth:`fileno`, :meth:`readable`, :meth:`seekable`, :meth:`writable`,
-      :meth:`read1` and :meth:`readinto` methods were added.
-
    .. versionchanged:: 3.3
       Support was added for *filename* being a :term:`file object` instead of an
       actual filename.
diff --git a/Doc/library/cmdline.rst b/Doc/library/cmdline.rst
new file mode 100644
index 0000000000..b2379befef
--- /dev/null
+++ b/Doc/library/cmdline.rst
@@ -0,0 +1,57 @@
+++++++++++++++++++++++++++++++++++++
+Modules command-line interface (CLI)
+++++++++++++++++++++++++++++++++++++
+
+The following modules have a command-line interface.
+
+* :ref:`ast <ast-cli>`
+* :ref:`asyncio <asyncio-cli>`
+* :mod:`base64`
+* :ref:`calendar <calendar-cli>`
+* :mod:`code`
+* :ref:`compileall <compileall-cli>`
+* :mod:`cProfile`: see :ref:`profile <profile-cli>`
+* :ref:`difflib <difflib-interface>`
+* :ref:`dis <dis-cli>`
+* :mod:`doctest`
+* :mod:`!encodings.rot_13`
+* :mod:`ensurepip`
+* :mod:`filecmp`
+* :mod:`fileinput`
+* :mod:`ftplib`
+* :ref:`gzip <gzip-cli>`
+* :ref:`http.server <http-server-cli>`
+* :mod:`!idlelib`
+* :ref:`inspect <inspect-module-cli>`
+* :ref:`json.tool <json-commandline>`
+* :mod:`mimetypes`
+* :mod:`pdb`
+* :mod:`pickle`
+* :ref:`pickletools <pickletools-cli>`
+* :mod:`platform`
+* :mod:`poplib`
+* :ref:`profile <profile-cli>`
+* :mod:`pstats`
+* :ref:`py_compile <py_compile-cli>`
+* :mod:`pyclbr`
+* :mod:`pydoc`
+* :mod:`quopri`
+* :mod:`runpy`
+* :ref:`site <site-commandline>`
+* :ref:`sqlite3 <sqlite3-cli>`
+* :ref:`sysconfig <sysconfig-cli>`
+* :mod:`tabnanny`
+* :ref:`tarfile <tarfile-commandline>`
+* :mod:`!this`
+* :ref:`timeit <timeit-command-line-interface>`
+* :ref:`tokenize <tokenize-cli>`
+* :ref:`trace <trace-cli>`
+* :mod:`turtledemo`
+* :ref:`unittest <unittest-command-line-interface>`
+* :ref:`uuid <uuid-cli>`
+* :mod:`venv`
+* :mod:`webbrowser`
+* :ref:`zipapp <zipapp-command-line-interface>`
+* :ref:`zipfile <zipfile-commandline>`
+
+See also the :ref:`Python command-line interface <using-on-general>`.
diff --git a/Doc/library/codecs.rst b/Doc/library/codecs.rst
index 2db4a67d19..9ce5848747 100644
--- a/Doc/library/codecs.rst
+++ b/Doc/library/codecs.rst
@@ -520,44 +520,46 @@ The base :class:`Codec` class defines these methods which also define the
 function interfaces of the stateless encoder and decoder:
 
 
-.. method:: Codec.encode(input, errors='strict')
+.. class:: Codec
 
-   Encodes the object *input* and returns a tuple (output object, length consumed).
-   For instance, :term:`text encoding` converts
-   a string object to a bytes object using a particular
-   character set encoding (e.g., ``cp1252`` or ``iso-8859-1``).
+   .. method:: encode(input, errors='strict')
 
-   The *errors* argument defines the error handling to apply.
-   It defaults to ``'strict'`` handling.
+      Encodes the object *input* and returns a tuple (output object, length consumed).
+      For instance, :term:`text encoding` converts
+      a string object to a bytes object using a particular
+      character set encoding (e.g., ``cp1252`` or ``iso-8859-1``).
 
-   The method may not store state in the :class:`Codec` instance. Use
-   :class:`StreamWriter` for codecs which have to keep state in order to make
-   encoding efficient.
+      The *errors* argument defines the error handling to apply.
+      It defaults to ``'strict'`` handling.
 
-   The encoder must be able to handle zero length input and return an empty object
-   of the output object type in this situation.
+      The method may not store state in the :class:`Codec` instance. Use
+      :class:`StreamWriter` for codecs which have to keep state in order to make
+      encoding efficient.
 
+      The encoder must be able to handle zero length input and return an empty object
+      of the output object type in this situation.
 
-.. method:: Codec.decode(input, errors='strict')
 
-   Decodes the object *input* and returns a tuple (output object, length
-   consumed). For instance, for a :term:`text encoding`, decoding converts
-   a bytes object encoded using a particular
-   character set encoding to a string object.
+   .. method:: decode(input, errors='strict')
 
-   For text encodings and bytes-to-bytes codecs,
-   *input* must be a bytes object or one which provides the read-only
-   buffer interface -- for example, buffer objects and memory mapped files.
+      Decodes the object *input* and returns a tuple (output object, length
+      consumed). For instance, for a :term:`text encoding`, decoding converts
+      a bytes object encoded using a particular
+      character set encoding to a string object.
 
-   The *errors* argument defines the error handling to apply.
-   It defaults to ``'strict'`` handling.
+      For text encodings and bytes-to-bytes codecs,
+      *input* must be a bytes object or one which provides the read-only
+      buffer interface -- for example, buffer objects and memory mapped files.
 
-   The method may not store state in the :class:`Codec` instance. Use
-   :class:`StreamReader` for codecs which have to keep state in order to make
-   decoding efficient.
+      The *errors* argument defines the error handling to apply.
+      It defaults to ``'strict'`` handling.
 
-   The decoder must be able to handle zero length input and return an empty object
-   of the output object type in this situation.
+      The method may not store state in the :class:`Codec` instance. Use
+      :class:`StreamReader` for codecs which have to keep state in order to make
+      decoding efficient.
+
+      The decoder must be able to handle zero length input and return an empty object
+      of the output object type in this situation.
 
 
 Incremental Encoding and Decoding
@@ -705,7 +707,7 @@ Stream Encoding and Decoding
 
 The :class:`StreamWriter` and :class:`StreamReader` classes provide generic
 working interfaces which can be used to implement new encoding submodules very
-easily. See :mod:`encodings.utf_8` for an example of how this is done.
+easily. See :mod:`!encodings.utf_8` for an example of how this is done.
 
 
 .. _stream-writer-objects:
@@ -895,9 +897,10 @@ The design is such that one can use the factory functions returned by the
 .. class:: StreamRecoder(stream, encode, decode, Reader, Writer, errors='strict')
 
    Creates a :class:`StreamRecoder` instance which implements a two-way conversion:
-   *encode* and *decode* work on the frontend — the data visible to
-   code calling :meth:`read` and :meth:`write`, while *Reader* and *Writer*
-   work on the backend — the data in *stream*.
+   *encode* and *decode* work on the frontend — the data visible to
+   code calling :meth:`~StreamReader.read` and :meth:`~StreamWriter.write`,
+   while *Reader* and *Writer*
+   work on the backend — the data in *stream*.
 
    You can use these objects to do transparent transcodings, e.g., from Latin-1
    to UTF-8 and back.
@@ -1417,8 +1420,10 @@ to :class:`bytes` mappings. They are not supported by :meth:`bytes.decode`
 |                      | quotedprintable, | quoted printable.            | ``quotetabs=True`` /         |
 |                      | quoted_printable |                              | :meth:`quopri.decode`        |
 +----------------------+------------------+------------------------------+------------------------------+
-| uu_codec             | uu               | Convert the operand using    | :meth:`uu.encode` /          |
-|                      |                  | uuencode.                    | :meth:`uu.decode`            |
+| uu_codec             | uu               | Convert the operand using    | :meth:`!uu.encode` /         |
+|                      |                  | uuencode.                    | :meth:`!uu.decode`           |
+|                      |                  |                              | (Note: :mod:`uu` is          |
+|                      |                  |                              | deprecated.)                 |
 +----------------------+------------------+------------------------------+------------------------------+
 | zlib_codec           | zip, zlib        | Compress the operand using   | :meth:`zlib.compress` /      |
 |                      |                  | gzip.                        | :meth:`zlib.decompress`      |
diff --git a/Doc/library/collections.abc.rst b/Doc/library/collections.abc.rst
index 43a3286ba8..edc0789532 100644
--- a/Doc/library/collections.abc.rst
+++ b/Doc/library/collections.abc.rst
@@ -192,7 +192,7 @@ ABC                            Inherits from          Abstract Methods        Mi
 .. [2] Checking ``isinstance(obj, Iterable)`` detects classes that are
    registered as :class:`Iterable` or that have an :meth:`__iter__`
    method, but it does not detect classes that iterate with the
-   :meth:`__getitem__` method.  The only reliable way to determine
+   :meth:`~object.__getitem__` method.  The only reliable way to determine
    whether an object is :term:`iterable` is to call ``iter(obj)``.
 
 
@@ -222,7 +222,7 @@ Collections Abstract Base Classes -- Detailed Descriptions
 
    Checking ``isinstance(obj, Iterable)`` detects classes that are registered
    as :class:`Iterable` or that have an :meth:`__iter__` method, but it does
-   not detect classes that iterate with the :meth:`__getitem__` method.
+   not detect classes that iterate with the :meth:`~object.__getitem__` method.
    The only reliable way to determine whether an object is :term:`iterable`
    is to call ``iter(obj)``.
 
@@ -262,8 +262,8 @@ Collections Abstract Base Classes -- Detailed Descriptions
 
    Implementation note: Some of the mixin methods, such as
    :meth:`__iter__`, :meth:`__reversed__` and :meth:`index`, make
-   repeated calls to the underlying :meth:`__getitem__` method.
-   Consequently, if :meth:`__getitem__` is implemented with constant
+   repeated calls to the underlying :meth:`~object.__getitem__` method.
+   Consequently, if :meth:`~object.__getitem__` is implemented with constant
    access speed, the mixin methods will have linear performance;
    however, if the underlying method is linear (as it would be with a
    linked list), the mixins will have quadratic performance and will
diff --git a/Doc/library/collections.rst b/Doc/library/collections.rst
index bb46782c06..eec2330ca9 100644
--- a/Doc/library/collections.rst
+++ b/Doc/library/collections.rst
@@ -120,26 +120,26 @@ The class can be used to simulate nested scopes and is useful in templating.
 
 .. seealso::
 
-    * The `MultiContext class
-      <https://github.com/enthought/codetools/blob/4.0.0/codetools/contexts/multi_context.py>`_
-      in the Enthought `CodeTools package
-      <https://github.com/enthought/codetools>`_ has options to support
-      writing to any mapping in the chain.
+   * The `MultiContext class
+     <https://github.com/enthought/codetools/blob/4.0.0/codetools/contexts/multi_context.py>`_
+     in the Enthought `CodeTools package
+     <https://github.com/enthought/codetools>`_ has options to support
+     writing to any mapping in the chain.
 
-    * Django's `Context class
-      <https://github.com/django/django/blob/main/django/template/context.py>`_
-      for templating is a read-only chain of mappings.  It also features
-      pushing and popping of contexts similar to the
-      :meth:`~collections.ChainMap.new_child` method and the
-      :attr:`~collections.ChainMap.parents` property.
+   * Django's `Context class
+     <https://github.com/django/django/blob/main/django/template/context.py>`_
+     for templating is a read-only chain of mappings.  It also features
+     pushing and popping of contexts similar to the
+     :meth:`~collections.ChainMap.new_child` method and the
+     :attr:`~collections.ChainMap.parents` property.
 
-    * The `Nested Contexts recipe
-      <https://code.activestate.com/recipes/577434/>`_ has options to control
-      whether writes and other mutations apply only to the first mapping or to
-      any mapping in the chain.
+   * The `Nested Contexts recipe
+     <https://code.activestate.com/recipes/577434/>`_ has options to control
+     whether writes and other mutations apply only to the first mapping or to
+     any mapping in the chain.
 
-    * A `greatly simplified read-only version of Chainmap
-      <https://code.activestate.com/recipes/305268/>`_.
+   * A `greatly simplified read-only version of Chainmap
+     <https://code.activestate.com/recipes/305268/>`_.
 
 
 :class:`ChainMap` Examples and Recipes
@@ -429,22 +429,22 @@ or subtracting from an empty counter.
 
 .. seealso::
 
-    * `Bag class <https://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html>`_
-      in Smalltalk.
+   * `Bag class <https://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html>`_
+     in Smalltalk.
 
-    * Wikipedia entry for `Multisets <https://en.wikipedia.org/wiki/Multiset>`_.
+   * Wikipedia entry for `Multisets <https://en.wikipedia.org/wiki/Multiset>`_.
 
-    * `C++ multisets <http://www.java2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm>`_
-      tutorial with examples.
+   * `C++ multisets <http://www.java2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm>`_
+     tutorial with examples.
 
-    * For mathematical operations on multisets and their use cases, see
-      *Knuth, Donald. The Art of Computer Programming Volume II,
-      Section 4.6.3, Exercise 19*.
+   * For mathematical operations on multisets and their use cases, see
+     *Knuth, Donald. The Art of Computer Programming Volume II,
+     Section 4.6.3, Exercise 19*.
 
-    * To enumerate all distinct multisets of a given size over a given set of
-      elements, see :func:`itertools.combinations_with_replacement`::
+   * To enumerate all distinct multisets of a given size over a given set of
+     elements, see :func:`itertools.combinations_with_replacement`::
 
-          map(Counter, combinations_with_replacement('ABC', 2)) # --> AA AB AC BB BC CC
+        map(Counter, combinations_with_replacement('ABC', 2)) # --> AA AB AC BB BC CC
 
 
 :class:`deque` objects
@@ -743,12 +743,12 @@ stack manipulations such as ``dup``, ``drop``, ``swap``, ``over``, ``pick``,
         If calling :attr:`default_factory` raises an exception this exception is
         propagated unchanged.
 
-        This method is called by the :meth:`__getitem__` method of the
+        This method is called by the :meth:`~object.__getitem__` method of the
         :class:`dict` class when the requested key is not found; whatever it
-        returns or raises is then returned or raised by :meth:`__getitem__`.
+        returns or raises is then returned or raised by :meth:`~object.__getitem__`.
 
         Note that :meth:`__missing__` is *not* called for any operations besides
-        :meth:`__getitem__`. This means that :meth:`get` will, like normal
+        :meth:`~object.__getitem__`. This means that :meth:`get` will, like normal
         dictionaries, return ``None`` as a default rather than using
         :attr:`default_factory`.
 
@@ -1060,20 +1060,20 @@ fields:
 
 .. seealso::
 
-    * See :class:`typing.NamedTuple` for a way to add type hints for named
-      tuples.  It also provides an elegant notation using the :keyword:`class`
-      keyword::
+   * See :class:`typing.NamedTuple` for a way to add type hints for named
+     tuples.  It also provides an elegant notation using the :keyword:`class`
+     keyword::
 
-          class Component(NamedTuple):
-              part_number: int
-              weight: float
-              description: Optional[str] = None
+         class Component(NamedTuple):
+             part_number: int
+             weight: float
+             description: Optional[str] = None
 
-    * See :meth:`types.SimpleNamespace` for a mutable namespace based on an
-      underlying dictionary instead of a tuple.
+   * See :meth:`types.SimpleNamespace` for a mutable namespace based on an
+     underlying dictionary instead of a tuple.
 
-    * The :mod:`dataclasses` module provides a decorator and functions for
-      automatically adding generated special methods to user-defined classes.
+   * The :mod:`dataclasses` module provides a decorator and functions for
+     automatically adding generated special methods to user-defined classes.
 
 
 :class:`OrderedDict` objects
diff --git a/Doc/library/compileall.rst b/Doc/library/compileall.rst
index 75b97d6ff4..6d16734ddc 100644
--- a/Doc/library/compileall.rst
+++ b/Doc/library/compileall.rst
@@ -16,6 +16,8 @@ have write permission to the library directories.
 
 .. include:: ../includes/wasm-notavail.rst
 
+.. _compileall-cli:
+
 Command-line use
 ----------------
 
@@ -24,28 +26,28 @@ compile Python sources.
 
 .. program:: compileall
 
-.. cmdoption:: directory ...
-               file ...
+.. option:: directory ...
+            file ...
 
    Positional arguments are files to compile or directories that contain
    source files, traversed recursively.  If no argument is given, behave as if
    the command line was :samp:`-l {<directories from sys.path>}`.
 
-.. cmdoption:: -l
+.. option:: -l
 
    Do not recurse into subdirectories, only compile source code files directly
    contained in the named or implied directories.
 
-.. cmdoption:: -f
+.. option:: -f
 
    Force rebuild even if timestamps are up-to-date.
 
-.. cmdoption:: -q
+.. option:: -q
 
    Do not print the list of files compiled. If passed once, error messages will
    still be printed. If passed twice (``-qq``), all output is suppressed.
 
-.. cmdoption:: -d destdir
+.. option:: -d destdir
 
    Directory prepended to the path to each file being compiled.  This will
    appear in compilation time tracebacks, and is also compiled in to the
@@ -53,45 +55,45 @@ compile Python sources.
    cases where the source file does not exist at the time the byte-code file is
    executed.
 
-.. cmdoption:: -s strip_prefix
-.. cmdoption:: -p prepend_prefix
+.. option:: -s strip_prefix
+.. option:: -p prepend_prefix
 
    Remove (``-s``) or append (``-p``) the given prefix of paths
    recorded in the ``.pyc`` files.
    Cannot be combined with ``-d``.
 
-.. cmdoption:: -x regex
+.. option:: -x regex
 
    regex is used to search the full path to each file considered for
    compilation, and if the regex produces a match, the file is skipped.
 
-.. cmdoption:: -i list
+.. option:: -i list
 
    Read the file ``list`` and add each line that it contains to the list of
    files and directories to compile.  If ``list`` is ``-``, read lines from
    ``stdin``.
 
-.. cmdoption:: -b
+.. option:: -b
 
    Write the byte-code files to their legacy locations and names, which may
    overwrite byte-code files created by another version of Python.  The default
    is to write files to their :pep:`3147` locations and names, which allows
    byte-code files from multiple versions of Python to coexist.
 
-.. cmdoption:: -r
+.. option:: -r
 
    Control the maximum recursion level for subdirectories.
    If this is given, then ``-l`` option will not be taken into account.
    :program:`python -m compileall <directory> -r 0` is equivalent to
    :program:`python -m compileall <directory> -l`.
 
-.. cmdoption:: -j N
+.. option:: -j N
 
    Use *N* workers to compile the files within the given directory.
    If ``0`` is used, then the result of :func:`os.cpu_count()`
    will be used.
 
-.. cmdoption:: --invalidation-mode [timestamp|checked-hash|unchecked-hash]
+.. option:: --invalidation-mode [timestamp|checked-hash|unchecked-hash]
 
    Control how the generated byte-code files are invalidated at runtime.
    The ``timestamp`` value, means that ``.pyc`` files with the source timestamp
@@ -104,17 +106,17 @@ compile Python sources.
    variable is not set, and ``checked-hash`` if the ``SOURCE_DATE_EPOCH``
    environment variable is set.
 
-.. cmdoption:: -o level
+.. option:: -o level
 
    Compile with the given optimization level. May be used multiple times
    to compile for multiple levels at a time (for example,
    ``compileall -o 1 -o 2``).
 
-.. cmdoption:: -e dir
+.. option:: -e dir
 
    Ignore symlinks pointing outside the given directory.
 
-.. cmdoption:: --hardlink-dupes
+.. option:: --hardlink-dupes
 
    If two ``.pyc`` files with different optimization level have
    the same content, use hard links to consolidate duplicate files.
diff --git a/Doc/library/concurrent.futures.rst b/Doc/library/concurrent.futures.rst
index 6503d1fcf7..163f170927 100644
--- a/Doc/library/concurrent.futures.rst
+++ b/Doc/library/concurrent.futures.rst
@@ -29,83 +29,83 @@ Executor Objects
    An abstract class that provides methods to execute calls asynchronously.  It
    should not be used directly, but through its concrete subclasses.
 
-    .. method:: submit(fn, /, *args, **kwargs)
+   .. method:: submit(fn, /, *args, **kwargs)
 
-       Schedules the callable, *fn*, to be executed as ``fn(*args, **kwargs)``
-       and returns a :class:`Future` object representing the execution of the
-       callable. ::
+      Schedules the callable, *fn*, to be executed as ``fn(*args, **kwargs)``
+      and returns a :class:`Future` object representing the execution of the
+      callable. ::
 
-          with ThreadPoolExecutor(max_workers=1) as executor:
-              future = executor.submit(pow, 323, 1235)
-              print(future.result())
+         with ThreadPoolExecutor(max_workers=1) as executor:
+             future = executor.submit(pow, 323, 1235)
+             print(future.result())
 
-    .. method:: map(func, *iterables, timeout=None, chunksize=1)
+   .. method:: map(func, *iterables, timeout=None, chunksize=1)
 
-       Similar to :func:`map(func, *iterables) <map>` except:
+      Similar to :func:`map(func, *iterables) <map>` except:
 
-       * the *iterables* are collected immediately rather than lazily;
+      * the *iterables* are collected immediately rather than lazily;
 
-       * *func* is executed asynchronously and several calls to
-         *func* may be made concurrently.
+      * *func* is executed asynchronously and several calls to
+        *func* may be made concurrently.
 
-       The returned iterator raises a :exc:`TimeoutError`
-       if :meth:`~iterator.__next__` is called and the result isn't available
-       after *timeout* seconds from the original call to :meth:`Executor.map`.
-       *timeout* can be an int or a float.  If *timeout* is not specified or
-       ``None``, there is no limit to the wait time.
+      The returned iterator raises a :exc:`TimeoutError`
+      if :meth:`~iterator.__next__` is called and the result isn't available
+      after *timeout* seconds from the original call to :meth:`Executor.map`.
+      *timeout* can be an int or a float.  If *timeout* is not specified or
+      ``None``, there is no limit to the wait time.
 
-       If a *func* call raises an exception, then that exception will be
-       raised when its value is retrieved from the iterator.
+      If a *func* call raises an exception, then that exception will be
+      raised when its value is retrieved from the iterator.
 
-       When using :class:`ProcessPoolExecutor`, this method chops *iterables*
-       into a number of chunks which it submits to the pool as separate
-       tasks.  The (approximate) size of these chunks can be specified by
-       setting *chunksize* to a positive integer.  For very long iterables,
-       using a large value for *chunksize* can significantly improve
-       performance compared to the default size of 1.  With
-       :class:`ThreadPoolExecutor`, *chunksize* has no effect.
+      When using :class:`ProcessPoolExecutor`, this method chops *iterables*
+      into a number of chunks which it submits to the pool as separate
+      tasks.  The (approximate) size of these chunks can be specified by
+      setting *chunksize* to a positive integer.  For very long iterables,
+      using a large value for *chunksize* can significantly improve
+      performance compared to the default size of 1.  With
+      :class:`ThreadPoolExecutor`, *chunksize* has no effect.
 
-       .. versionchanged:: 3.5
-          Added the *chunksize* argument.
+      .. versionchanged:: 3.5
+         Added the *chunksize* argument.
 
-    .. method:: shutdown(wait=True, *, cancel_futures=False)
+   .. method:: shutdown(wait=True, *, cancel_futures=False)
 
-       Signal the executor that it should free any resources that it is using
-       when the currently pending futures are done executing.  Calls to
-       :meth:`Executor.submit` and :meth:`Executor.map` made after shutdown will
-       raise :exc:`RuntimeError`.
+      Signal the executor that it should free any resources that it is using
+      when the currently pending futures are done executing.  Calls to
+      :meth:`Executor.submit` and :meth:`Executor.map` made after shutdown will
+      raise :exc:`RuntimeError`.
 
-       If *wait* is ``True`` then this method will not return until all the
-       pending futures are done executing and the resources associated with the
-       executor have been freed.  If *wait* is ``False`` then this method will
-       return immediately and the resources associated with the executor will be
-       freed when all pending futures are done executing.  Regardless of the
-       value of *wait*, the entire Python program will not exit until all
-       pending futures are done executing.
+      If *wait* is ``True`` then this method will not return until all the
+      pending futures are done executing and the resources associated with the
+      executor have been freed.  If *wait* is ``False`` then this method will
+      return immediately and the resources associated with the executor will be
+      freed when all pending futures are done executing.  Regardless of the
+      value of *wait*, the entire Python program will not exit until all
+      pending futures are done executing.
 
-       If *cancel_futures* is ``True``, this method will cancel all pending
-       futures that the executor has not started running. Any futures that
-       are completed or running won't be cancelled, regardless of the value
-       of *cancel_futures*.
+      If *cancel_futures* is ``True``, this method will cancel all pending
+      futures that the executor has not started running. Any futures that
+      are completed or running won't be cancelled, regardless of the value
+      of *cancel_futures*.
 
-       If both *cancel_futures* and *wait* are ``True``, all futures that the
-       executor has started running will be completed prior to this method
-       returning. The remaining futures are cancelled.
+      If both *cancel_futures* and *wait* are ``True``, all futures that the
+      executor has started running will be completed prior to this method
+      returning. The remaining futures are cancelled.
 
-       You can avoid having to call this method explicitly if you use the
-       :keyword:`with` statement, which will shutdown the :class:`Executor`
-       (waiting as if :meth:`Executor.shutdown` were called with *wait* set to
-       ``True``)::
+      You can avoid having to call this method explicitly if you use the
+      :keyword:`with` statement, which will shutdown the :class:`Executor`
+      (waiting as if :meth:`Executor.shutdown` were called with *wait* set to
+      ``True``)::
 
-          import shutil
-          with ThreadPoolExecutor(max_workers=4) as e:
-              e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
-              e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
-              e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
-              e.submit(shutil.copy, 'src4.txt', 'dest4.txt')
+         import shutil
+         with ThreadPoolExecutor(max_workers=4) as e:
+             e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
+             e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
+             e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
+             e.submit(shutil.copy, 'src4.txt', 'dest4.txt')
 
-       .. versionchanged:: 3.9
-          Added *cancel_futures*.
+      .. versionchanged:: 3.9
+         Added *cancel_futures*.
 
 
 ThreadPoolExecutor
@@ -353,117 +353,117 @@ The :class:`Future` class encapsulates the asynchronous execution of a callable.
    instances are created by :meth:`Executor.submit` and should not be created
    directly except for testing.
 
-    .. method:: cancel()
+   .. method:: cancel()
 
-       Attempt to cancel the call.  If the call is currently being executed or
-       finished running and cannot be cancelled then the method will return
-       ``False``, otherwise the call will be cancelled and the method will
-       return ``True``.
+      Attempt to cancel the call.  If the call is currently being executed or
+      finished running and cannot be cancelled then the method will return
+      ``False``, otherwise the call will be cancelled and the method will
+      return ``True``.
 
-    .. method:: cancelled()
+   .. method:: cancelled()
 
-       Return ``True`` if the call was successfully cancelled.
+      Return ``True`` if the call was successfully cancelled.
 
-    .. method:: running()
+   .. method:: running()
 
-       Return ``True`` if the call is currently being executed and cannot be
-       cancelled.
+      Return ``True`` if the call is currently being executed and cannot be
+      cancelled.
 
-    .. method:: done()
+   .. method:: done()
 
-       Return ``True`` if the call was successfully cancelled or finished
-       running.
+      Return ``True`` if the call was successfully cancelled or finished
+      running.
 
-    .. method:: result(timeout=None)
+   .. method:: result(timeout=None)
 
-       Return the value returned by the call. If the call hasn't yet completed
-       then this method will wait up to *timeout* seconds.  If the call hasn't
-       completed in *timeout* seconds, then a
-       :exc:`TimeoutError` will be raised. *timeout* can be
-       an int or float.  If *timeout* is not specified or ``None``, there is no
-       limit to the wait time.
+      Return the value returned by the call. If the call hasn't yet completed
+      then this method will wait up to *timeout* seconds.  If the call hasn't
+      completed in *timeout* seconds, then a
+      :exc:`TimeoutError` will be raised. *timeout* can be
+      an int or float.  If *timeout* is not specified or ``None``, there is no
+      limit to the wait time.
 
-       If the future is cancelled before completing then :exc:`.CancelledError`
-       will be raised.
+      If the future is cancelled before completing then :exc:`.CancelledError`
+      will be raised.
 
-       If the call raised an exception, this method will raise the same exception.
+      If the call raised an exception, this method will raise the same exception.
 
-    .. method:: exception(timeout=None)
+   .. method:: exception(timeout=None)
 
-       Return the exception raised by the call.  If the call hasn't yet
-       completed then this method will wait up to *timeout* seconds.  If the
-       call hasn't completed in *timeout* seconds, then a
-       :exc:`TimeoutError` will be raised.  *timeout* can be
-       an int or float.  If *timeout* is not specified or ``None``, there is no
-       limit to the wait time.
+      Return the exception raised by the call.  If the call hasn't yet
+      completed then this method will wait up to *timeout* seconds.  If the
+      call hasn't completed in *timeout* seconds, then a
+      :exc:`TimeoutError` will be raised.  *timeout* can be
+      an int or float.  If *timeout* is not specified or ``None``, there is no
+      limit to the wait time.
 
-       If the future is cancelled before completing then :exc:`.CancelledError`
-       will be raised.
+      If the future is cancelled before completing then :exc:`.CancelledError`
+      will be raised.
 
-       If the call completed without raising, ``None`` is returned.
+      If the call completed without raising, ``None`` is returned.
 
-    .. method:: add_done_callback(fn)
+   .. method:: add_done_callback(fn)
 
-       Attaches the callable *fn* to the future.  *fn* will be called, with the
-       future as its only argument, when the future is cancelled or finishes
-       running.
+      Attaches the callable *fn* to the future.  *fn* will be called, with the
+      future as its only argument, when the future is cancelled or finishes
+      running.
 
-       Added callables are called in the order that they were added and are
-       always called in a thread belonging to the process that added them.  If
-       the callable raises an :exc:`Exception` subclass, it will be logged and
-       ignored.  If the callable raises a :exc:`BaseException` subclass, the
-       behavior is undefined.
+      Added callables are called in the order that they were added and are
+      always called in a thread belonging to the process that added them.  If
+      the callable raises an :exc:`Exception` subclass, it will be logged and
+      ignored.  If the callable raises a :exc:`BaseException` subclass, the
+      behavior is undefined.
 
-       If the future has already completed or been cancelled, *fn* will be
-       called immediately.
+      If the future has already completed or been cancelled, *fn* will be
+      called immediately.
 
    The following :class:`Future` methods are meant for use in unit tests and
    :class:`Executor` implementations.
 
-    .. method:: set_running_or_notify_cancel()
+   .. method:: set_running_or_notify_cancel()
 
-       This method should only be called by :class:`Executor` implementations
-       before executing the work associated with the :class:`Future` and by unit
-       tests.
+      This method should only be called by :class:`Executor` implementations
+      before executing the work associated with the :class:`Future` and by unit
+      tests.
 
-       If the method returns ``False`` then the :class:`Future` was cancelled,
-       i.e. :meth:`Future.cancel` was called and returned ``True``.  Any threads
-       waiting on the :class:`Future` completing (i.e. through
-       :func:`as_completed` or :func:`wait`) will be woken up.
+      If the method returns ``False`` then the :class:`Future` was cancelled,
+      i.e. :meth:`Future.cancel` was called and returned ``True``.  Any threads
+      waiting on the :class:`Future` completing (i.e. through
+      :func:`as_completed` or :func:`wait`) will be woken up.
 
-       If the method returns ``True`` then the :class:`Future` was not cancelled
-       and has been put in the running state, i.e. calls to
-       :meth:`Future.running` will return ``True``.
+      If the method returns ``True`` then the :class:`Future` was not cancelled
+      and has been put in the running state, i.e. calls to
+      :meth:`Future.running` will return ``True``.
 
-       This method can only be called once and cannot be called after
-       :meth:`Future.set_result` or :meth:`Future.set_exception` have been
-       called.
+      This method can only be called once and cannot be called after
+      :meth:`Future.set_result` or :meth:`Future.set_exception` have been
+      called.
 
-    .. method:: set_result(result)
+   .. method:: set_result(result)
 
-       Sets the result of the work associated with the :class:`Future` to
-       *result*.
+      Sets the result of the work associated with the :class:`Future` to
+      *result*.
 
-       This method should only be used by :class:`Executor` implementations and
-       unit tests.
+      This method should only be used by :class:`Executor` implementations and
+      unit tests.
 
-       .. versionchanged:: 3.8
-          This method raises
-          :exc:`concurrent.futures.InvalidStateError` if the :class:`Future` is
-          already done.
+      .. versionchanged:: 3.8
+         This method raises
+         :exc:`concurrent.futures.InvalidStateError` if the :class:`Future` is
+         already done.
 
-    .. method:: set_exception(exception)
+   .. method:: set_exception(exception)
 
-       Sets the result of the work associated with the :class:`Future` to the
-       :class:`Exception` *exception*.
+      Sets the result of the work associated with the :class:`Future` to the
+      :class:`Exception` *exception*.
 
-       This method should only be used by :class:`Executor` implementations and
-       unit tests.
+      This method should only be used by :class:`Executor` implementations and
+      unit tests.
 
-       .. versionchanged:: 3.8
-          This method raises
-          :exc:`concurrent.futures.InvalidStateError` if the :class:`Future` is
-          already done.
+      .. versionchanged:: 3.8
+         This method raises
+         :exc:`concurrent.futures.InvalidStateError` if the :class:`Future` is
+         already done.
 
 Module Functions
 ----------------
diff --git a/Doc/library/contextlib.rst b/Doc/library/contextlib.rst
index 7cd081d1f5..66b9c13710 100644
--- a/Doc/library/contextlib.rst
+++ b/Doc/library/contextlib.rst
@@ -45,7 +45,7 @@ Functions and classes provided:
 
    This function is a :term:`decorator` that can be used to define a factory
    function for :keyword:`with` statement context managers, without needing to
-   create a class or separate :meth:`__enter__` and :meth:`__exit__` methods.
+   create a class or separate :meth:`~object.__enter__` and :meth:`~object.__exit__` methods.
 
    While many objects natively support use in with statements, sometimes a
    resource needs to be managed that isn't a context manager in its own right,
@@ -515,7 +515,7 @@ Functions and classes provided:
           # the with statement, even if attempts to open files later
           # in the list raise an exception
 
-   The :meth:`__enter__` method returns the :class:`ExitStack` instance, and
+   The :meth:`~object.__enter__` method returns the :class:`ExitStack` instance, and
    performs no additional operations.
 
    Each instance maintains a stack of registered callbacks that are called in
@@ -543,9 +543,9 @@ Functions and classes provided:
 
    .. method:: enter_context(cm)
 
-      Enters a new context manager and adds its :meth:`__exit__` method to
+      Enters a new context manager and adds its :meth:`~object.__exit__` method to
       the callback stack. The return value is the result of the context
-      manager's own :meth:`__enter__` method.
+      manager's own :meth:`~object.__enter__` method.
 
       These context managers may suppress exceptions just as they normally
       would if used directly as part of a :keyword:`with` statement.
@@ -556,18 +556,18 @@ Functions and classes provided:
 
    .. method:: push(exit)
 
-      Adds a context manager's :meth:`__exit__` method to the callback stack.
+      Adds a context manager's :meth:`~object.__exit__` method to the callback stack.
 
       As ``__enter__`` is *not* invoked, this method can be used to cover
-      part of an :meth:`__enter__` implementation with a context manager's own
-      :meth:`__exit__` method.
+      part of an :meth:`~object.__enter__` implementation with a context manager's own
+      :meth:`~object.__exit__` method.
 
       If passed an object that is not a context manager, this method assumes
       it is a callback with the same signature as a context manager's
-      :meth:`__exit__` method and adds it directly to the callback stack.
+      :meth:`~object.__exit__` method and adds it directly to the callback stack.
 
       By returning true values, these callbacks can suppress exceptions the
-      same way context manager :meth:`__exit__` methods can.
+      same way context manager :meth:`~object.__exit__` methods can.
 
       The passed in object is returned from the function, allowing this
       method to be used as a function decorator.
@@ -714,7 +714,7 @@ Cleaning up in an ``__enter__`` implementation
 
 As noted in the documentation of :meth:`ExitStack.push`, this
 method can be useful in cleaning up an already allocated resource if later
-steps in the :meth:`__enter__` implementation fail.
+steps in the :meth:`~object.__enter__` implementation fail.
 
 Here's an example of doing this for a context manager that accepts resource
 acquisition and release functions, along with an optional validation function,
@@ -871,7 +871,7 @@ And also as a function decorator::
 
 Note that there is one additional limitation when using context managers
 as function decorators: there's no way to access the return value of
-:meth:`__enter__`. If that value is needed, then it is still necessary to use
+:meth:`~object.__enter__`. If that value is needed, then it is still necessary to use
 an explicit ``with`` statement.
 
 .. seealso::
diff --git a/Doc/library/csv.rst b/Doc/library/csv.rst
index 64baa69be4..aba398b8ee 100644
--- a/Doc/library/csv.rst
+++ b/Doc/library/csv.rst
@@ -288,9 +288,9 @@ The :mod:`csv` module defines the following classes:
       Inspecting each column, one of two key criteria will be considered to
       estimate if the sample contains a header:
 
-        - the second through n-th rows contain numeric values
-        - the second through n-th rows contain strings where at least one value's
-          length differs from that of the putative header of that column.
+      - the second through n-th rows contain numeric values
+      - the second through n-th rows contain strings where at least one value's
+        length differs from that of the putative header of that column.
 
       Twenty rows after the first row are sampled; if more than half of columns +
       rows meet the criteria, :const:`True` is returned.
diff --git a/Doc/library/ctypes.rst b/Doc/library/ctypes.rst
index 19cee10711..f8c0a53e3d 100644
--- a/Doc/library/ctypes.rst
+++ b/Doc/library/ctypes.rst
@@ -1403,7 +1403,8 @@ way is to instantiate one of the following classes:
    failure, an :class:`OSError` is automatically raised.
 
    .. versionchanged:: 3.3
-      :exc:`WindowsError` used to be raised.
+      :exc:`WindowsError` used to be raised,
+      which is now an alias of :exc:`OSError`.
 
    .. versionchanged:: 3.12
 
@@ -1737,70 +1738,70 @@ See :ref:`ctypes-callback-functions` for examples.
 Function prototypes created by these factory functions can be instantiated in
 different ways, depending on the type and number of the parameters in the call:
 
+.. function:: prototype(address)
+   :noindex:
+   :module:
 
-   .. function:: prototype(address)
-      :noindex:
-      :module:
+   Returns a foreign function at the specified address which must be an integer.
 
-      Returns a foreign function at the specified address which must be an integer.
 
+.. function:: prototype(callable)
+   :noindex:
+   :module:
 
-   .. function:: prototype(callable)
-      :noindex:
-      :module:
+   Create a C callable function (a callback function) from a Python *callable*.
 
-      Create a C callable function (a callback function) from a Python *callable*.
 
+.. function:: prototype(func_spec[, paramflags])
+   :noindex:
+   :module:
 
-   .. function:: prototype(func_spec[, paramflags])
-      :noindex:
-      :module:
+   Returns a foreign function exported by a shared library. *func_spec* must
+   be a 2-tuple ``(name_or_ordinal, library)``. The first item is the name of
+   the exported function as string, or the ordinal of the exported function
+   as small integer.  The second item is the shared library instance.
 
-      Returns a foreign function exported by a shared library. *func_spec* must
-      be a 2-tuple ``(name_or_ordinal, library)``. The first item is the name of
-      the exported function as string, or the ordinal of the exported function
-      as small integer.  The second item is the shared library instance.
 
+.. function:: prototype(vtbl_index, name[, paramflags[, iid]])
+   :noindex:
+   :module:
 
-   .. function:: prototype(vtbl_index, name[, paramflags[, iid]])
-      :noindex:
-      :module:
+   Returns a foreign function that will call a COM method. *vtbl_index* is
+   the index into the virtual function table, a small non-negative
+   integer. *name* is name of the COM method. *iid* is an optional pointer to
+   the interface identifier which is used in extended error reporting.
 
-      Returns a foreign function that will call a COM method. *vtbl_index* is
-      the index into the virtual function table, a small non-negative
-      integer. *name* is name of the COM method. *iid* is an optional pointer to
-      the interface identifier which is used in extended error reporting.
+   COM methods use a special calling convention: They require a pointer to
+   the COM interface as first argument, in addition to those parameters that
+   are specified in the :attr:`!argtypes` tuple.
 
-      COM methods use a special calling convention: They require a pointer to
-      the COM interface as first argument, in addition to those parameters that
-      are specified in the :attr:`!argtypes` tuple.
+The optional *paramflags* parameter creates foreign function wrappers with much
+more functionality than the features described above.
 
-   The optional *paramflags* parameter creates foreign function wrappers with much
-   more functionality than the features described above.
+*paramflags* must be a tuple of the same length as :attr:`~_FuncPtr.argtypes`.
 
-   *paramflags* must be a tuple of the same length as :attr:`~_FuncPtr.argtypes`.
+Each item in this tuple contains further information about a parameter, it must
+be a tuple containing one, two, or three items.
 
-   Each item in this tuple contains further information about a parameter, it must
-   be a tuple containing one, two, or three items.
+The first item is an integer containing a combination of direction
+flags for the parameter:
 
-   The first item is an integer containing a combination of direction
-   flags for the parameter:
+   1
+      Specifies an input parameter to the function.
 
-      1
-         Specifies an input parameter to the function.
+   2
+      Output parameter.  The foreign function fills in a value.
 
-      2
-         Output parameter.  The foreign function fills in a value.
+   4
+      Input parameter which defaults to the integer zero.
 
-      4
-         Input parameter which defaults to the integer zero.
+The optional second item is the parameter name as string.  If this is specified,
+the foreign function can be called with named parameters.
 
-   The optional second item is the parameter name as string.  If this is specified,
-   the foreign function can be called with named parameters.
+The optional third item is the default value for this parameter.
 
-   The optional third item is the default value for this parameter.
 
-This example demonstrates how to wrap the Windows ``MessageBoxW`` function so
+The following example demonstrates how to wrap the Windows ``MessageBoxW`` function so
 that it supports default parameters and named arguments. The C declaration from
 the windows header file is this::
 
@@ -2088,13 +2089,14 @@ Utility functions
 .. function:: WinError(code=None, descr=None)
 
    Windows only: this function is probably the worst-named thing in ctypes. It
-   creates an instance of OSError.  If *code* is not specified,
+   creates an instance of :exc:`OSError`.  If *code* is not specified,
    ``GetLastError`` is called to determine the error code. If *descr* is not
    specified, :func:`FormatError` is called to get a textual description of the
    error.
 
    .. versionchanged:: 3.3
-      An instance of :exc:`WindowsError` used to be created.
+      An instance of :exc:`WindowsError` used to be created, which is now an
+      alias of :exc:`OSError`.
 
 
 .. function:: wstring_at(address, size=-1)
diff --git a/Doc/library/curses.rst b/Doc/library/curses.rst
index 9ab67c2197..9b8a98f05f 100644
--- a/Doc/library/curses.rst
+++ b/Doc/library/curses.rst
@@ -1771,9 +1771,9 @@ The following table lists mouse button constants used by :meth:`getmouse`:
 | .. data:: BUTTON_ALT             | Control was down during button state change |
 +----------------------------------+---------------------------------------------+
 
-   .. versionchanged:: 3.10
-      The ``BUTTON5_*`` constants are now exposed if they are provided by the
-      underlying curses library.
+.. versionchanged:: 3.10
+   The ``BUTTON5_*`` constants are now exposed if they are provided by the
+   underlying curses library.
 
 The following table lists the predefined colors:
 
diff --git a/Doc/library/dataclasses.rst b/Doc/library/dataclasses.rst
index d68748767c..1b2f6d454d 100644
--- a/Doc/library/dataclasses.rst
+++ b/Doc/library/dataclasses.rst
@@ -319,13 +319,11 @@ Module contents
    module-level method (see below).  Users should never instantiate a
    :class:`Field` object directly.  Its documented attributes are:
 
-     - ``name``: The name of the field.
-
-     - ``type``: The type of the field.
-
-     - ``default``, ``default_factory``, ``init``, ``repr``, ``hash``,
-       ``compare``, ``metadata``, and ``kw_only`` have the identical
-       meaning and values as they do in the :func:`field` function.
+   - ``name``: The name of the field.
+   - ``type``: The type of the field.
+   - ``default``, ``default_factory``, ``init``, ``repr``, ``hash``,
+     ``compare``, ``metadata``, and ``kw_only`` have the identical
+     meaning and values as they do in the :func:`field` function.
 
    Other attributes may exist, but they are private and must not be
    inspected or relied on.
diff --git a/Doc/library/datetime.rst b/Doc/library/datetime.rst
index 04cc755629..649f1a3a5f 100644
--- a/Doc/library/datetime.rst
+++ b/Doc/library/datetime.rst
@@ -38,7 +38,8 @@ on efficient attribute extraction for output formatting and manipulation.
       Third-party library with expanded time zone and parsing support.
 
    Package `DateType <https://pypi.org/project/datetype/>`_
-      Third-party library that introduces distinct static types to e.g. allow static type checkers
+      Third-party library that introduces distinct static types to e.g. allow
+      :term:`static type checkers <static type checker>`
       to differentiate between naive and aware datetimes.
 
 .. _datetime-naive-aware:
diff --git a/Doc/library/decimal.rst b/Doc/library/decimal.rst
index 018ec1abf3..08bbb7ff58 100644
--- a/Doc/library/decimal.rst
+++ b/Doc/library/decimal.rst
@@ -1396,10 +1396,10 @@ In addition to the three supplied contexts, new contexts can be created with the
       With three arguments, compute ``(x**y) % modulo``.  For the three argument
       form, the following restrictions on the arguments hold:
 
-         - all three arguments must be integral
-         - ``y`` must be nonnegative
-         - at least one of ``x`` or ``y`` must be nonzero
-         - ``modulo`` must be nonzero and have at most 'precision' digits
+      - all three arguments must be integral
+      - ``y`` must be nonnegative
+      - at least one of ``x`` or ``y`` must be nonzero
+      - ``modulo`` must be nonzero and have at most 'precision' digits
 
       The value resulting from ``Context.power(x, y, modulo)`` is
       equal to the value that would be obtained by computing ``(x**y)
diff --git a/Doc/library/dialog.rst b/Doc/library/dialog.rst
index 53f98c1018..191e0da121 100644
--- a/Doc/library/dialog.rst
+++ b/Doc/library/dialog.rst
@@ -27,15 +27,15 @@ functions for creating simple modal dialogs to get a value from the user.
 
    The base class for custom dialogs.
 
-    .. method:: body(master)
+   .. method:: body(master)
 
-       Override to construct the dialog's interface and return the widget that
-       should have initial focus.
+      Override to construct the dialog's interface and return the widget that
+      should have initial focus.
 
-    .. method:: buttonbox()
+   .. method:: buttonbox()
 
-       Default behaviour adds OK and Cancel buttons. Override for custom button
-       layouts.
+      Default behaviour adds OK and Cancel buttons. Override for custom button
+      layouts.
 
 
 
diff --git a/Doc/library/difflib.rst b/Doc/library/difflib.rst
index c553611401..9abf19557f 100644
--- a/Doc/library/difflib.rst
+++ b/Doc/library/difflib.rst
@@ -171,9 +171,12 @@ diffs. For comparing directories and files, see also, the :mod:`filecmp` module.
    expressed in the ISO 8601 format. If not specified, the
    strings default to blanks.
 
+      >>> import sys
+      >>> from difflib import *
       >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
       >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
-      >>> sys.stdout.writelines(context_diff(s1, s2, fromfile='before.py', tofile='after.py'))
+      >>> sys.stdout.writelines(context_diff(s1, s2, fromfile='before.py',
+      ...                        tofile='after.py'))
       *** before.py
       --- after.py
       ***************
@@ -294,13 +297,12 @@ diffs. For comparing directories and files, see also, the :mod:`filecmp` module.
    For inputs that do not have trailing newlines, set the *lineterm* argument to
    ``""`` so that the output will be uniformly newline free.
 
-   The context diff format normally has a header for filenames and modification
+   The unified diff format normally has a header for filenames and modification
    times.  Any or all of these may be specified using strings for *fromfile*,
    *tofile*, *fromfiledate*, and *tofiledate*.  The modification times are normally
    expressed in the ISO 8601 format. If not specified, the
    strings default to blanks.
 
-
       >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
       >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
       >>> sys.stdout.writelines(unified_diff(s1, s2, fromfile='before.py', tofile='after.py'))
diff --git a/Doc/library/dis.rst b/Doc/library/dis.rst
index b559b085aa..3d0142e949 100644
--- a/Doc/library/dis.rst
+++ b/Doc/library/dis.rst
@@ -42,6 +42,14 @@ interpreter.
       bytecode to specialize it for different runtime conditions. The
       adaptive bytecode can be shown by passing ``adaptive=True``.
 
+   .. versionchanged:: 3.12
+      The argument of a jump is the offset of the target instruction relative
+      to the instruction that appears immediately after the jump instruction's
+      :opcode:`CACHE` entries.
+
+      As a consequence, the presence of the :opcode:`CACHE` instructions is
+      transparent for forward jumps but needs to be taken into account when
+      reasoning about backward jumps.
 
 Example: Given the function :func:`!myfunc`::
 
@@ -63,6 +71,28 @@ the following command can be used to display the disassembly of
 
 (The "2" is a line number).
 
+.. _dis-cli:
+
+Command-line interface
+----------------------
+
+The :mod:`dis` module can be invoked as a script from the command line:
+
+.. code-block:: sh
+
+   python -m dis [-h] [infile]
+
+The following options are accepted:
+
+.. program:: dis
+
+.. cmdoption:: -h, --help
+
+   Display usage and exit.
+
+If :file:`infile` is specified, its disassembled code will be written to stdout.
+Otherwise, disassembly is performed on compiled source code recieved from stdin.
+
 Bytecode analysis
 -----------------
 
@@ -428,6 +458,14 @@ operations on it as if it was a Python list. The top of the stack corresponds to
    .. versionadded:: 3.12
 
 
+.. opcode:: END_SEND
+
+   Implements ``del STACK[-2]``.
+   Used to clean up when a generator exits.
+
+   .. versionadded:: 3.12
+
+
 .. opcode:: COPY (i)
 
    Push the i-th item to the top of the stack without removing it from its original
@@ -1063,15 +1101,21 @@ iterations of the loop.
 
 .. opcode:: LOAD_SUPER_ATTR (namei)
 
-   This opcode implements :func:`super` (e.g. ``super().method()`` and
-   ``super().attr``). It works the same as :opcode:`LOAD_ATTR`, except that
-   ``namei`` is shifted left by 2 bits instead of 1, and instead of expecting a
-   single receiver on the stack, it expects three objects (from top of stack
-   down): ``self`` (the first argument to the current method), ``cls`` (the
-   class within which the current method was defined), and the global ``super``.
+   This opcode implements :func:`super`, both in its zero-argument and
+   two-argument forms (e.g. ``super().method()``, ``super().attr`` and
+   ``super(cls, self).method()``, ``super(cls, self).attr``).
+
+   It pops three values from the stack (from top of stack down):
+   - ``self``: the first argument to the current method
+   -  ``cls``: the class within which the current method was defined
+   -  the global ``super``
+
+   With respect to its argument, it works similarly to :opcode:`LOAD_ATTR`,
+   except that ``namei`` is shifted left by 2 bits instead of 1.
 
    The low bit of ``namei`` signals to attempt a method load, as with
-   :opcode:`LOAD_ATTR`.
+   :opcode:`LOAD_ATTR`, which results in pushing ``None`` and the loaded method.
+   When it is unset a single value is pushed to the stack.
 
    The second-low bit of ``namei``, if set, means that this was a two-argument
    call to :func:`super` (unset means zero-argument).
@@ -1498,9 +1542,9 @@ iterations of the loop.
    Equivalent to ``STACK[-1] = STACK[-2].send(STACK[-1])``. Used in ``yield from``
    and ``await`` statements.
 
-   If the call raises :exc:`StopIteration`, pop both items, push the
-   exception's ``value`` attribute, and increment the bytecode counter by
-   *delta*.
+   If the call raises :exc:`StopIteration`, pop the top value from the stack,
+   push the exception's ``value`` attribute, and increment the bytecode counter
+   by *delta*.
 
    .. versionadded:: 3.11
 
@@ -1528,7 +1572,7 @@ iterations of the loop.
 
    Calls an intrinsic function with one argument. Passes ``STACK[-1]`` as the
    argument and sets ``STACK[-1]`` to the result. Used to implement
-   functionality that is necessary but not performance critical.
+   functionality that is not performance critical.
 
    The operand determines which intrinsic function is called:
 
@@ -1576,9 +1620,13 @@ iterations of the loop.
 
 .. opcode:: CALL_INTRINSIC_2
 
-   Calls an intrinsic function with two arguments. Passes ``STACK[-2]``, ``STACK[-1]`` as the
-   arguments and sets ``STACK[-1]`` to the result. Used to implement functionality that is
-   necessary but not performance critical.
+   Calls an intrinsic function with two arguments. Used to implement functionality
+   that is not performance critical::
+
+      arg2 = STACK.pop()
+      arg1 = STACK.pop()
+      result = intrinsic2(arg1, arg2)
+      STACK.push(result)
 
    The operand determines which intrinsic function is called:
 
@@ -1663,8 +1711,9 @@ These collections are provided for automatic introspection of bytecode
 instructions:
 
 .. versionchanged:: 3.12
-   The collections now contain pseudo instructions as well. These are
-   opcodes with values ``>= MIN_PSEUDO_OPCODE``.
+   The collections now contain pseudo instructions and instrumented
+   instructions as well. These are opcodes with values ``>= MIN_PSEUDO_OPCODE``
+   and ``>= MIN_INSTRUMENTED_OPCODE``.
 
 .. data:: opname
 
diff --git a/Doc/library/doctest.rst b/Doc/library/doctest.rst
index d6e4dca086..b5583e46a6 100644
--- a/Doc/library/doctest.rst
+++ b/Doc/library/doctest.rst
@@ -277,13 +277,34 @@ Which Docstrings Are Examined?
 The module docstring, and all function, class and method docstrings are
 searched.  Objects imported into the module are not searched.
 
-In addition, if ``M.__test__`` exists and "is true", it must be a dict, and each
+In addition, there are cases when you want tests to be part of a module but not part
+of the help text, which requires that the tests not be included in the docstring.
+Doctest looks for a module-level variable called ``__test__`` and uses it to locate other
+tests. If ``M.__test__`` exists and is truthy, it must be a dict, and each
 entry maps a (string) name to a function object, class object, or string.
 Function and class object docstrings found from ``M.__test__`` are searched, and
 strings are treated as if they were docstrings.  In output, a key ``K`` in
-``M.__test__`` appears with name ::
+``M.__test__`` appears with name ``M.__test__.K``.
 
-   <name of M>.__test__.K
+For example, place this block of code at the top of :file:`example.py`:
+
+.. code-block:: python
+
+   __test__ = {
+       'numbers': """
+   >>> factorial(6)
+   720
+
+   >>> [factorial(n) for n in range(6)]
+   [1, 1, 2, 6, 24, 120]
+   """
+   }
+
+The value of ``example.__test__["numbers"]`` will be treated as a
+docstring and all the tests inside it will be run. It is
+important to note that the value can be mapped to a function,
+class object, or module; if so, :mod:`!doctest`
+searches them recursively for docstrings, which are then scanned for tests.
 
 Any classes found are recursively searched similarly, to test docstrings in
 their contained methods and nested classes.
diff --git a/Doc/library/email.compat32-message.rst b/Doc/library/email.compat32-message.rst
index 5bef155a4a..c4c322a82e 100644
--- a/Doc/library/email.compat32-message.rst
+++ b/Doc/library/email.compat32-message.rst
@@ -367,7 +367,7 @@ Here are the methods of the :class:`Message` class:
    .. method:: get(name, failobj=None)
 
       Return the value of the named header field.  This is identical to
-      :meth:`__getitem__` except that optional *failobj* is returned if the
+      :meth:`~object.__getitem__` except that optional *failobj* is returned if the
       named header is missing (defaults to ``None``).
 
    Here are some additional useful methods:
diff --git a/Doc/library/email.contentmanager.rst b/Doc/library/email.contentmanager.rst
index 918fc55677..5b49339650 100644
--- a/Doc/library/email.contentmanager.rst
+++ b/Doc/library/email.contentmanager.rst
@@ -32,9 +32,9 @@
       To find the handler, look for the following keys in the registry,
       stopping with the first one found:
 
-            * the string representing the full MIME type (``maintype/subtype``)
-            * the string representing the ``maintype``
-            * the empty string
+      * the string representing the full MIME type (``maintype/subtype``)
+      * the string representing the ``maintype``
+      * the empty string
 
       If none of these keys produce a handler, raise a :exc:`KeyError` for the
       full MIME type.
@@ -55,11 +55,11 @@
       look for the following keys in the registry, stopping with the first one
       found:
 
-           * the type itself (``typ``)
-           * the type's fully qualified name (``typ.__module__ + '.' +
-             typ.__qualname__``).
-           * the type's qualname (``typ.__qualname__``)
-           * the type's name (``typ.__name__``).
+      * the type itself (``typ``)
+      * the type's fully qualified name (``typ.__module__ + '.' +
+        typ.__qualname__``).
+      * the type's qualname (``typ.__qualname__``)
+      * the type's name (``typ.__name__``).
 
       If none of the above match, repeat all of the checks above for each of
       the types in the :term:`MRO` (``typ.__mro__``).  Finally, if no other key
@@ -132,15 +132,15 @@ Currently the email package provides only one concrete content manager,
        Add a :mailheader:`Content-Type` header with a ``maintype/subtype``
        value.
 
-           * For ``str``, set the MIME ``maintype`` to ``text``, and set the
-             subtype to *subtype* if it is specified, or ``plain`` if it is not.
-           * For ``bytes``, use the specified *maintype* and *subtype*, or
-             raise a :exc:`TypeError` if they are not specified.
-           * For :class:`~email.message.EmailMessage` objects, set the maintype
-             to ``message``, and set the subtype to *subtype* if it is
-             specified or ``rfc822`` if it is not.  If *subtype* is
-             ``partial``, raise an error (``bytes`` objects must be used to
-             construct ``message/partial`` parts).
+       * For ``str``, set the MIME ``maintype`` to ``text``, and set the
+         subtype to *subtype* if it is specified, or ``plain`` if it is not.
+       * For ``bytes``, use the specified *maintype* and *subtype*, or
+         raise a :exc:`TypeError` if they are not specified.
+       * For :class:`~email.message.EmailMessage` objects, set the maintype
+         to ``message``, and set the subtype to *subtype* if it is
+         specified or ``rfc822`` if it is not.  If *subtype* is
+         ``partial``, raise an error (``bytes`` objects must be used to
+         construct ``message/partial`` parts).
 
        If *charset* is provided (which is valid only for ``str``), encode the
        string to bytes using the specified character set.  The default is
@@ -155,14 +155,14 @@ Currently the email package provides only one concrete content manager,
        ``7bit`` for an input that contains non-ASCII values), raise a
        :exc:`ValueError`.
 
-            * For ``str`` objects, if *cte* is not set use heuristics to
-              determine the most compact encoding.
-            * For :class:`~email.message.EmailMessage`, per :rfc:`2046`, raise
-              an error if a *cte* of ``quoted-printable`` or ``base64`` is
-              requested for *subtype* ``rfc822``, and for any *cte* other than
-              ``7bit`` for *subtype* ``external-body``.  For
-              ``message/rfc822``, use ``8bit`` if *cte* is not specified.  For
-              all other values of *subtype*, use ``7bit``.
+       * For ``str`` objects, if *cte* is not set use heuristics to
+         determine the most compact encoding.
+       * For :class:`~email.message.EmailMessage`, per :rfc:`2046`, raise
+         an error if a *cte* of ``quoted-printable`` or ``base64`` is
+         requested for *subtype* ``rfc822``, and for any *cte* other than
+         ``7bit`` for *subtype* ``external-body``.  For
+         ``message/rfc822``, use ``8bit`` if *cte* is not specified.  For
+         all other values of *subtype*, use ``7bit``.
 
        .. note:: A *cte* of ``binary`` does not actually work correctly yet.
           The ``EmailMessage`` object as modified by ``set_content`` is
diff --git a/Doc/library/email.message.rst b/Doc/library/email.message.rst
index 225f498781..f58d93da6e 100644
--- a/Doc/library/email.message.rst
+++ b/Doc/library/email.message.rst
@@ -247,7 +247,7 @@ message objects.
    .. method:: get(name, failobj=None)
 
       Return the value of the named header field.  This is identical to
-      :meth:`__getitem__` except that optional *failobj* is returned if the
+      :meth:`~object.__getitem__` except that optional *failobj* is returned if the
       named header is missing (*failobj* defaults to ``None``).
 
 
diff --git a/Doc/library/email.policy.rst b/Doc/library/email.policy.rst
index 2439dee676..fd47dd0dc5 100644
--- a/Doc/library/email.policy.rst
+++ b/Doc/library/email.policy.rst
@@ -557,17 +557,17 @@ more closely to the RFCs relevant to their domains.
 With all of these :class:`EmailPolicies <.EmailPolicy>`, the effective API of
 the email package is changed from the Python 3.2 API in the following ways:
 
-   * Setting a header on a :class:`~email.message.Message` results in that
-     header being parsed and a header object created.
+* Setting a header on a :class:`~email.message.Message` results in that
+  header being parsed and a header object created.
 
-   * Fetching a header value from a :class:`~email.message.Message` results
-     in that header being parsed and a header object created and
-     returned.
+* Fetching a header value from a :class:`~email.message.Message` results
+  in that header being parsed and a header object created and
+  returned.
 
-   * Any header object, or any header that is refolded due to the
-     policy settings, is folded using an algorithm that fully implements the
-     RFC folding algorithms, including knowing where encoded words are required
-     and allowed.
+* Any header object, or any header that is refolded due to the
+  policy settings, is folded using an algorithm that fully implements the
+  RFC folding algorithms, including knowing where encoded words are required
+  and allowed.
 
 From the application view, this means that any header obtained through the
 :class:`~email.message.EmailMessage` is a header object with extra
diff --git a/Doc/library/enum.rst b/Doc/library/enum.rst
index 7653865f0b..57e1f581d4 100644
--- a/Doc/library/enum.rst
+++ b/Doc/library/enum.rst
@@ -198,11 +198,12 @@ Data Types
         >>> some_var = Color.RED
         >>> some_var in Color
         True
+        >>> Color.RED.value in Color
+        True
 
-      .. note::
+   .. versionchanged:: 3.12
 
-         In Python 3.12 it will be possible to check for member values and not
-         just members; until then, a ``TypeError`` will be raised if a
+         Before Python 3.12, a ``TypeError`` is raised if a
          non-Enum-member is used in a containment check.
 
    .. method:: EnumType.__dir__(cls)
@@ -597,8 +598,8 @@ Data Types
 
    If a *Flag* operation is performed with an *IntFlag* member and:
 
-      * the result is a valid *IntFlag*: an *IntFlag* is returned
-      * the result is not a valid *IntFlag*: the result depends on the *FlagBoundary* setting
+   * the result is a valid *IntFlag*: an *IntFlag* is returned
+   * the result is not a valid *IntFlag*: the result depends on the *FlagBoundary* setting
 
    The *repr()* of unnamed zero-valued flags has changed.  It is now:
 
@@ -625,8 +626,8 @@ Data Types
    :class:`!ReprEnum` uses the :meth:`repr() <Enum.__repr__>` of :class:`Enum`,
    but the :class:`str() <str>` of the mixed-in data type:
 
-      * :meth:`!int.__str__` for :class:`IntEnum` and :class:`IntFlag`
-      * :meth:`!str.__str__` for :class:`StrEnum`
+   * :meth:`!int.__str__` for :class:`IntEnum` and :class:`IntFlag`
+   * :meth:`!str.__str__` for :class:`StrEnum`
 
    Inherit from :class:`!ReprEnum` to keep the :class:`str() <str>` / :func:`format`
    of the mixed-in data type instead of using the
@@ -789,13 +790,13 @@ Supported ``_sunder_`` names
 - ``_generate_next_value_`` -- used to get an appropriate value for an enum
   member; may be overridden
 
-   .. note::
+  .. note::
 
-       For standard :class:`Enum` classes the next value chosen is the last value seen
-       incremented by one.
+     For standard :class:`Enum` classes the next value chosen is the last value seen
+     incremented by one.
 
-       For :class:`Flag` classes the next value chosen will be the next highest
-       power-of-two, regardless of the last value seen.
+     For :class:`Flag` classes the next value chosen will be the next highest
+     power-of-two, regardless of the last value seen.
 
 .. versionadded:: 3.6 ``_missing_``, ``_order_``, ``_generate_next_value_``
 .. versionadded:: 3.7 ``_ignore_``
@@ -817,11 +818,11 @@ Utilities and Decorators
 
    *auto* instances are only resolved when at the top level of an assignment:
 
-      * ``FIRST = auto()`` will work (auto() is replaced with ``1``);
-      * ``SECOND = auto(), -2`` will work (auto is replaced with ``2``, so ``2, -2`` is
-         used to create the ``SECOND`` enum member;
-      * ``THREE = [auto(), -3]`` will *not* work (``<auto instance>, -3`` is used to
-        create the ``THREE`` enum member)
+   * ``FIRST = auto()`` will work (auto() is replaced with ``1``);
+   * ``SECOND = auto(), -2`` will work (auto is replaced with ``2``, so ``2, -2`` is
+      used to create the ``SECOND`` enum member;
+   * ``THREE = [auto(), -3]`` will *not* work (``<auto instance>, -3`` is used to
+     create the ``THREE`` enum member)
 
    .. versionchanged:: 3.11.1
 
diff --git a/Doc/library/fcntl.rst b/Doc/library/fcntl.rst
index 969a79fa87..309ad652d4 100644
--- a/Doc/library/fcntl.rst
+++ b/Doc/library/fcntl.rst
@@ -18,7 +18,7 @@ interface to the :c:func:`fcntl` and :c:func:`ioctl` Unix routines.  For a
 complete description of these calls, see :manpage:`fcntl(2)` and
 :manpage:`ioctl(2)` Unix manual pages.
 
-.. include:: ../includes/wasm-notavail.rst
+.. availability:: Unix, not Emscripten, not WASI.
 
 All functions in this module take a file descriptor *fd* as their first
 argument.  This can be an integer file descriptor, such as returned by
diff --git a/Doc/library/functions.rst b/Doc/library/functions.rst
index 3cb70b7fda..954c7c0313 100644
--- a/Doc/library/functions.rst
+++ b/Doc/library/functions.rst
@@ -983,7 +983,7 @@ are always available.  They are listed here in alphabetical order.
    differently depending on the presence of the second argument. Without a
    second argument, *object* must be a collection object which supports the
    :term:`iterable` protocol (the :meth:`__iter__` method), or it must support
-   the sequence protocol (the :meth:`__getitem__` method with integer arguments
+   the sequence protocol (the :meth:`~object.__getitem__` method with integer arguments
    starting at ``0``).  If it does not support either of those protocols,
    :exc:`TypeError` is raised. If the second argument, *sentinel*, is given,
    then *object* must be a callable object.  The iterator created in this case
@@ -1158,8 +1158,8 @@ are always available.  They are listed here in alphabetical order.
 
   See also :func:`format` for more information.
 
-   .. index::
-      single: file object; open() built-in function
+.. index::
+   single: file object; open() built-in function
 
 .. function:: open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)
 
@@ -1360,28 +1360,28 @@ are always available.  They are listed here in alphabetical order.
 
    .. versionchanged:: 3.3
 
-         * The *opener* parameter was added.
-         * The ``'x'`` mode was added.
-         * :exc:`IOError` used to be raised, it is now an alias of :exc:`OSError`.
-         * :exc:`FileExistsError` is now raised if the file opened in exclusive
-           creation mode (``'x'``) already exists.
+      * The *opener* parameter was added.
+      * The ``'x'`` mode was added.
+      * :exc:`IOError` used to be raised, it is now an alias of :exc:`OSError`.
+      * :exc:`FileExistsError` is now raised if the file opened in exclusive
+        creation mode (``'x'``) already exists.
 
    .. versionchanged:: 3.4
 
-         * The file is now non-inheritable.
+      * The file is now non-inheritable.
 
    .. versionchanged:: 3.5
 
-         * If the system call is interrupted and the signal handler does not raise an
-           exception, the function now retries the system call instead of raising an
-           :exc:`InterruptedError` exception (see :pep:`475` for the rationale).
-         * The ``'namereplace'`` error handler was added.
+      * If the system call is interrupted and the signal handler does not raise an
+        exception, the function now retries the system call instead of raising an
+        :exc:`InterruptedError` exception (see :pep:`475` for the rationale).
+      * The ``'namereplace'`` error handler was added.
 
    .. versionchanged:: 3.6
 
-         * Support added to accept objects implementing :class:`os.PathLike`.
-         * On Windows, opening a console buffer may return a subclass of
-           :class:`io.RawIOBase` other than :class:`io.FileIO`.
+      * Support added to accept objects implementing :class:`os.PathLike`.
+      * On Windows, opening a console buffer may return a subclass of
+        :class:`io.RawIOBase` other than :class:`io.FileIO`.
 
    .. versionchanged:: 3.11
       The ``'U'`` mode has been removed.
@@ -1563,7 +1563,7 @@ are always available.  They are listed here in alphabetical order.
 
    Return a reverse :term:`iterator`.  *seq* must be an object which has
    a :meth:`__reversed__` method or supports the sequence protocol (the
-   :meth:`__len__` method and the :meth:`__getitem__` method with integer
+   :meth:`__len__` method and the :meth:`~object.__getitem__` method with integer
    arguments starting at ``0``).
 
 
diff --git a/Doc/library/getpass.rst b/Doc/library/getpass.rst
index d5bbe67fb3..5c79daf0f4 100644
--- a/Doc/library/getpass.rst
+++ b/Doc/library/getpass.rst
@@ -43,7 +43,7 @@ The :mod:`getpass` module provides two functions:
    Return the "login name" of the user.
 
    This function checks the environment variables :envvar:`LOGNAME`,
-   :envvar:`USER`, :envvar:`LNAME` and :envvar:`USERNAME`, in order, and
+   :envvar:`USER`, :envvar:`!LNAME` and :envvar:`USERNAME`, in order, and
    returns the value of the first one which is set to a non-empty string.  If
    none are set, the login name from the password database is returned on
    systems which support the :mod:`pwd` module, otherwise, an exception is
diff --git a/Doc/library/gettext.rst b/Doc/library/gettext.rst
index 7ebe91b372..dc6cf5533f 100644
--- a/Doc/library/gettext.rst
+++ b/Doc/library/gettext.rst
@@ -167,7 +167,7 @@ install themselves in the built-in namespace as the function :func:`!_`.
    :class:`NullTranslations` instance if *fallback* is true.
 
    .. versionchanged:: 3.3
-      :exc:`IOError` used to be raised instead of :exc:`OSError`.
+      :exc:`IOError` used to be raised, it is now an alias of :exc:`OSError`.
 
    .. versionchanged:: 3.11
       *codeset* parameter is removed.
diff --git a/Doc/library/graphlib.rst b/Doc/library/graphlib.rst
index fdd8f39ef4..5414d6370b 100644
--- a/Doc/library/graphlib.rst
+++ b/Doc/library/graphlib.rst
@@ -37,14 +37,14 @@
    In the general case, the steps required to perform the sorting of a given
    graph are as follows:
 
-         * Create an instance of the :class:`TopologicalSorter` with an optional
-           initial graph.
-         * Add additional nodes to the graph.
-         * Call :meth:`~TopologicalSorter.prepare` on the graph.
-         * While :meth:`~TopologicalSorter.is_active` is ``True``, iterate over
-           the nodes returned by :meth:`~TopologicalSorter.get_ready` and
-           process them. Call :meth:`~TopologicalSorter.done` on each node as it
-           finishes processing.
+   * Create an instance of the :class:`TopologicalSorter` with an optional
+     initial graph.
+   * Add additional nodes to the graph.
+   * Call :meth:`~TopologicalSorter.prepare` on the graph.
+   * While :meth:`~TopologicalSorter.is_active` is ``True``, iterate over
+     the nodes returned by :meth:`~TopologicalSorter.get_ready` and
+     process them. Call :meth:`~TopologicalSorter.done` on each node as it
+     finishes processing.
 
    In case just an immediate sorting of the nodes in the graph is required and
    no parallelism is involved, the convenience method
diff --git a/Doc/library/grp.rst b/Doc/library/grp.rst
index 14af744e3a..ee55b12ea8 100644
--- a/Doc/library/grp.rst
+++ b/Doc/library/grp.rst
@@ -10,7 +10,7 @@
 This module provides access to the Unix group database. It is available on all
 Unix versions.
 
-.. include:: ../includes/wasm-notavail.rst
+.. availability:: Unix, not Emscripten, not WASI.
 
 Group database entries are reported as a tuple-like object, whose attributes
 correspond to the members of the ``group`` structure (Attribute field below, see
diff --git a/Doc/library/gzip.rst b/Doc/library/gzip.rst
index 60236a1190..f931d0e399 100644
--- a/Doc/library/gzip.rst
+++ b/Doc/library/gzip.rst
@@ -250,6 +250,8 @@ Example of how to GZIP compress a binary string::
 
 .. program:: gzip
 
+.. _gzip-cli:
+
 Command Line Interface
 ----------------------
 
@@ -266,23 +268,23 @@ Once executed the :mod:`gzip` module keeps the input file(s).
 Command line options
 ^^^^^^^^^^^^^^^^^^^^
 
-.. cmdoption:: file
+.. option:: file
 
    If *file* is not specified, read from :data:`sys.stdin`.
 
-.. cmdoption:: --fast
+.. option:: --fast
 
    Indicates the fastest compression method (less compression).
 
-.. cmdoption:: --best
+.. option:: --best
 
    Indicates the slowest compression method (best compression).
 
-.. cmdoption:: -d, --decompress
+.. option:: -d, --decompress
 
    Decompress the given file.
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    Show the help message.
 
diff --git a/Doc/library/http.cookiejar.rst b/Doc/library/http.cookiejar.rst
index 87ef156a0b..12a6d76843 100644
--- a/Doc/library/http.cookiejar.rst
+++ b/Doc/library/http.cookiejar.rst
@@ -44,8 +44,8 @@ The module defines the following exception:
    cookies from a file.  :exc:`LoadError` is a subclass of :exc:`OSError`.
 
    .. versionchanged:: 3.3
-      LoadError was made a subclass of :exc:`OSError` instead of
-      :exc:`IOError`.
+      :exc:`LoadError` used to be a subtype of :exc:`IOError`, which is now an
+      alias of :exc:`OSError`.
 
 
 The following classes are provided:
diff --git a/Doc/library/idle.rst b/Doc/library/idle.rst
index 3211da50dc..e710d0bacf 100644
--- a/Doc/library/idle.rst
+++ b/Doc/library/idle.rst
@@ -439,24 +439,24 @@ the :kbd:`Command` key on macOS.
 
 * Some useful Emacs bindings are inherited from Tcl/Tk:
 
-   * :kbd:`C-a` beginning of line
+  * :kbd:`C-a` beginning of line
 
-   * :kbd:`C-e` end of line
+  * :kbd:`C-e` end of line
 
-   * :kbd:`C-k` kill line (but doesn't put it in clipboard)
+  * :kbd:`C-k` kill line (but doesn't put it in clipboard)
 
-   * :kbd:`C-l` center window around the insertion point
+  * :kbd:`C-l` center window around the insertion point
 
-   * :kbd:`C-b` go backward one character without deleting (usually you can
-     also use the cursor key for this)
+  * :kbd:`C-b` go backward one character without deleting (usually you can
+    also use the cursor key for this)
 
-   * :kbd:`C-f` go forward one character without deleting (usually you can
-     also use the cursor key for this)
+  * :kbd:`C-f` go forward one character without deleting (usually you can
+    also use the cursor key for this)
 
-   * :kbd:`C-p` go up one line (usually you can also use the cursor key for
-     this)
+  * :kbd:`C-p` go up one line (usually you can also use the cursor key for
+    this)
 
-   * :kbd:`C-d` delete next character
+  * :kbd:`C-d` delete next character
 
 Standard keybindings (like :kbd:`C-c` to copy and :kbd:`C-v` to paste)
 may work.  Keybindings are selected in the Configure IDLE dialog.
diff --git a/Doc/library/index.rst b/Doc/library/index.rst
index d064b680f9..0b348ae6f5 100644
--- a/Doc/library/index.rst
+++ b/Doc/library/index.rst
@@ -73,5 +73,6 @@ the `Python Package Index <https://pypi.org>`_.
    language.rst
    windows.rst
    unix.rst
+   cmdline.rst
    superseded.rst
    security_warnings.rst
diff --git a/Doc/library/inspect.rst b/Doc/library/inspect.rst
index 603ac3263b..9f0b965bb0 100644
--- a/Doc/library/inspect.rst
+++ b/Doc/library/inspect.rst
@@ -640,6 +640,9 @@ function.
    Accepts a wide range of Python callables, from plain functions and classes to
    :func:`functools.partial` objects.
 
+   If the passed object has a ``__signature__`` attribute, this function
+   returns it without further computations.
+
    For objects defined in modules using stringized annotations
    (``from __future__ import annotations``), :func:`signature` will
    attempt to automatically un-stringize the annotations using
@@ -760,6 +763,8 @@ function.
          sig = MySignature.from_callable(min)
          assert isinstance(sig, MySignature)
 
+       Its behavior is otherwise identical to that of :func:`signature`.
+
        .. versionadded:: 3.5
 
        .. versionadded:: 3.10
@@ -1458,10 +1463,11 @@ generator to be determined easily.
    Get current state of a generator-iterator.
 
    Possible states are:
-    * GEN_CREATED: Waiting to start execution.
-    * GEN_RUNNING: Currently being executed by the interpreter.
-    * GEN_SUSPENDED: Currently suspended at a yield expression.
-    * GEN_CLOSED: Execution has completed.
+
+   * GEN_CREATED: Waiting to start execution.
+   * GEN_RUNNING: Currently being executed by the interpreter.
+   * GEN_SUSPENDED: Currently suspended at a yield expression.
+   * GEN_CLOSED: Execution has completed.
 
    .. versionadded:: 3.2
 
@@ -1473,10 +1479,11 @@ generator to be determined easily.
    ``cr_frame`` attributes.
 
    Possible states are:
-    * CORO_CREATED: Waiting to start execution.
-    * CORO_RUNNING: Currently being executed by the interpreter.
-    * CORO_SUSPENDED: Currently suspended at an await expression.
-    * CORO_CLOSED: Execution has completed.
+
+   * CORO_CREATED: Waiting to start execution.
+   * CORO_RUNNING: Currently being executed by the interpreter.
+   * CORO_SUSPENDED: Currently suspended at an await expression.
+   * CORO_CLOSED: Execution has completed.
 
    .. versionadded:: 3.5
 
@@ -1489,10 +1496,11 @@ generator to be determined easily.
    ``ag_running`` and ``ag_frame`` attributes.
 
    Possible states are:
-    * AGEN_CREATED: Waiting to start execution.
-    * AGEN_RUNNING: Currently being executed by the interpreter.
-    * AGEN_SUSPENDED: Currently suspended at a yield expression.
-    * AGEN_CLOSED: Execution has completed.
+
+   * AGEN_CREATED: Waiting to start execution.
+   * AGEN_RUNNING: Currently being executed by the interpreter.
+   * AGEN_SUSPENDED: Currently suspended at a yield expression.
+   * AGEN_CLOSED: Execution has completed.
 
    .. versionadded:: 3.12
 
@@ -1650,6 +1658,6 @@ By default, accepts the name of a module and prints the source of that
 module. A class or function within the module can be printed instead by
 appended a colon and the qualified name of the target object.
 
-.. cmdoption:: --details
+.. option:: --details
 
    Print information about the specified object rather than the source code
diff --git a/Doc/library/io.rst b/Doc/library/io.rst
index 0108887921..6736aa9ee2 100644
--- a/Doc/library/io.rst
+++ b/Doc/library/io.rst
@@ -253,12 +253,12 @@ The implementation of I/O streams is organized as a hierarchy of classes.  First
 specify the various categories of streams, then concrete classes providing the
 standard stream implementations.
 
-   .. note::
+.. note::
 
-      The abstract base classes also provide default implementations of some
-      methods in order to help implementation of concrete stream classes.  For
-      example, :class:`BufferedIOBase` provides unoptimized implementations of
-      :meth:`!readinto` and :meth:`!readline`.
+   The abstract base classes also provide default implementations of some
+   methods in order to help implementation of concrete stream classes.  For
+   example, :class:`BufferedIOBase` provides unoptimized implementations of
+   :meth:`!readinto` and :meth:`!readline`.
 
 At the top of the I/O hierarchy is the abstract base class :class:`IOBase`.  It
 defines the basic interface to a stream.  Note, however, that there is no
diff --git a/Doc/library/itertools.rst b/Doc/library/itertools.rst
index 8a1c83aa3a..f97e7f720a 100644
--- a/Doc/library/itertools.rst
+++ b/Doc/library/itertools.rst
@@ -41,7 +41,7 @@ operator can be mapped across two vectors to form an efficient dot-product:
 ==================  =================       =================================================               =========================================
 Iterator            Arguments               Results                                                         Example
 ==================  =================       =================================================               =========================================
-:func:`count`       start, [step]           start, start+step, start+2*step, ...                            ``count(10) --> 10 11 12 13 14 ...``
+:func:`count`       [start[, step]]         start, start+step, start+2*step, ...                            ``count(10) --> 10 11 12 13 14 ...``
 :func:`cycle`       p                       p0, p1, ... plast, p0, p1, ...                                  ``cycle('ABCD') --> A B C D A B C D ...``
 :func:`repeat`      elem [,n]               elem, elem, elem, ... endlessly or up to n times                ``repeat(10, 3) --> 10 10 10``
 ==================  =================       =================================================               =========================================
@@ -1119,9 +1119,7 @@ The following recipes have a more mathematical flavor:
        # factor(1_000_000_000_000_007) --> 47 59 360620266859
        # factor(1_000_000_000_000_403) --> 1000000000000403
        for prime in sieve(math.isqrt(n) + 1):
-           while True:
-               if n % prime:
-                   break
+           while not n % prime:
                yield prime
                n //= prime
                if n == 1:
diff --git a/Doc/library/json.rst b/Doc/library/json.rst
index 6c30593817..e234fe92bc 100644
--- a/Doc/library/json.rst
+++ b/Doc/library/json.rst
@@ -703,7 +703,7 @@ specified, :data:`sys.stdin` and :data:`sys.stdout` will be used respectively:
 Command line options
 ^^^^^^^^^^^^^^^^^^^^
 
-.. cmdoption:: infile
+.. option:: infile
 
    The JSON file to be validated or pretty-printed:
 
@@ -723,36 +723,36 @@ Command line options
 
    If *infile* is not specified, read from :data:`sys.stdin`.
 
-.. cmdoption:: outfile
+.. option:: outfile
 
    Write the output of the *infile* to the given *outfile*. Otherwise, write it
    to :data:`sys.stdout`.
 
-.. cmdoption:: --sort-keys
+.. option:: --sort-keys
 
    Sort the output of dictionaries alphabetically by key.
 
    .. versionadded:: 3.5
 
-.. cmdoption:: --no-ensure-ascii
+.. option:: --no-ensure-ascii
 
    Disable escaping of non-ascii characters, see :func:`json.dumps` for more information.
 
    .. versionadded:: 3.9
 
-.. cmdoption:: --json-lines
+.. option:: --json-lines
 
    Parse every input line as separate JSON object.
 
    .. versionadded:: 3.8
 
-.. cmdoption:: --indent, --tab, --no-indent, --compact
+.. option:: --indent, --tab, --no-indent, --compact
 
    Mutually exclusive options for whitespace control.
 
    .. versionadded:: 3.9
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    Show the help message.
 
diff --git a/Doc/library/locale.rst b/Doc/library/locale.rst
index f2abb3638a..2a6d911d6b 100644
--- a/Doc/library/locale.rst
+++ b/Doc/library/locale.rst
@@ -303,7 +303,7 @@ The :mod:`locale` module defines the following exception and functions:
    *language code* and *encoding* may be ``None`` if their values cannot be
    determined.
 
-   .. deprecated-removed:: 3.11 3.13
+   .. deprecated-removed:: 3.11 3.15
 
 
 .. function:: getlocale(category=LC_CTYPE)
@@ -464,11 +464,16 @@ The :mod:`locale` module defines the following exception and functions:
 
 .. data:: LC_CTYPE
 
-   .. index:: pair: module; string
+   Locale category for the character type functions.  Most importantly, this
+   category defines the text encoding, i.e. how bytes are interpreted as
+   Unicode codepoints.  See :pep:`538` and :pep:`540` for how this variable
+   might be automatically coerced to ``C.UTF-8`` to avoid issues created by
+   invalid settings in containers or incompatible settings passed over remote
+   SSH connections.
 
-   Locale category for the character type functions.  Depending on the settings of
-   this category, the functions of module :mod:`string` dealing with case change
-   their behaviour.
+   Python doesn't internally use locale-dependent character transformation functions
+   from ``ctype.h``. Instead, an internal ``pyctype.h`` provides locale-independent
+   equivalents like :c:macro:`!Py_TOLOWER`.
 
 
 .. data:: LC_COLLATE
diff --git a/Doc/library/logging.config.rst b/Doc/library/logging.config.rst
index 448978f43b..1c0ea22dea 100644
--- a/Doc/library/logging.config.rst
+++ b/Doc/library/logging.config.rst
@@ -257,11 +257,11 @@ otherwise, the context is used to determine what to instantiate.
   which correspond to the arguments passed to create a
   :class:`~logging.Formatter` object:
 
-   * ``format``
-   * ``datefmt``
-   * ``style``
-   * ``validate`` (since version >=3.8)
-   * ``defaults`` (since version >=3.12)
+  * ``format``
+  * ``datefmt``
+  * ``style``
+  * ``validate`` (since version >=3.8)
+  * ``defaults`` (since version >=3.12)
 
   An optional ``class`` key indicates the name of the formatter's
   class (as a dotted module and class name).  The instantiation
@@ -544,9 +544,9 @@ valid keyword parameter name, and so will not clash with the names of
 the keyword arguments used in the call.  The ``'()'`` also serves as a
 mnemonic that the corresponding value is a callable.
 
-    .. versionchanged:: 3.11
-       The ``filters`` member of ``handlers`` and ``loggers`` can take
-       filter instances in addition to ids.
+.. versionchanged:: 3.11
+   The ``filters`` member of ``handlers`` and ``loggers`` can take
+   filter instances in addition to ids.
 
 You can also specify a special key ``'.'`` whose value is a dictionary is a
 mapping of attribute names to values. If found, the specified attributes will
diff --git a/Doc/library/logging.handlers.rst b/Doc/library/logging.handlers.rst
index 2a825db54a..2dd4bd081b 100644
--- a/Doc/library/logging.handlers.rst
+++ b/Doc/library/logging.handlers.rst
@@ -656,9 +656,7 @@ supports sending logging messages to a remote or local Unix syslog.
       to the other end. This method is called during handler initialization,
       but it's not regarded as an error if the other end isn't listening at
       this point - the method will be called again when emitting an event, if
-      but it's not regarded as an error if the other end isn't listening yet
-      --- the method will be called again when emitting an event,
-      if there is no socket at that point.
+      there is no socket at that point.
 
       .. versionadded:: 3.11
 
diff --git a/Doc/library/lzma.rst b/Doc/library/lzma.rst
index 434e7ac906..0d69c3bc01 100644
--- a/Doc/library/lzma.rst
+++ b/Doc/library/lzma.rst
@@ -333,19 +333,22 @@ the key ``"id"``, and may contain additional keys to specify filter-dependent
 options. Valid filter IDs are as follows:
 
 * Compression filters:
-   * :const:`FILTER_LZMA1` (for use with :const:`FORMAT_ALONE`)
-   * :const:`FILTER_LZMA2` (for use with :const:`FORMAT_XZ` and :const:`FORMAT_RAW`)
+
+  * :const:`FILTER_LZMA1` (for use with :const:`FORMAT_ALONE`)
+  * :const:`FILTER_LZMA2` (for use with :const:`FORMAT_XZ` and :const:`FORMAT_RAW`)
 
 * Delta filter:
-   * :const:`FILTER_DELTA`
+
+  * :const:`FILTER_DELTA`
 
 * Branch-Call-Jump (BCJ) filters:
-   * :const:`FILTER_X86`
-   * :const:`FILTER_IA64`
-   * :const:`FILTER_ARM`
-   * :const:`FILTER_ARMTHUMB`
-   * :const:`FILTER_POWERPC`
-   * :const:`FILTER_SPARC`
+
+  * :const:`FILTER_X86`
+  * :const:`FILTER_IA64`
+  * :const:`FILTER_ARM`
+  * :const:`FILTER_ARMTHUMB`
+  * :const:`FILTER_POWERPC`
+  * :const:`FILTER_SPARC`
 
 A filter chain can consist of up to 4 filters, and cannot be empty. The last
 filter in the chain must be a compression filter, and any other filters must be
@@ -354,21 +357,21 @@ delta or BCJ filters.
 Compression filters support the following options (specified as additional
 entries in the dictionary representing the filter):
 
-   * ``preset``: A compression preset to use as a source of default values for
-     options that are not specified explicitly.
-   * ``dict_size``: Dictionary size in bytes. This should be between 4 KiB and
-     1.5 GiB (inclusive).
-   * ``lc``: Number of literal context bits.
-   * ``lp``: Number of literal position bits. The sum ``lc + lp`` must be at
-     most 4.
-   * ``pb``: Number of position bits; must be at most 4.
-   * ``mode``: :const:`MODE_FAST` or :const:`MODE_NORMAL`.
-   * ``nice_len``: What should be considered a "nice length" for a match.
-     This should be 273 or less.
-   * ``mf``: What match finder to use -- :const:`MF_HC3`, :const:`MF_HC4`,
-     :const:`MF_BT2`, :const:`MF_BT3`, or :const:`MF_BT4`.
-   * ``depth``: Maximum search depth used by match finder. 0 (default) means to
-     select automatically based on other filter options.
+* ``preset``: A compression preset to use as a source of default values for
+  options that are not specified explicitly.
+* ``dict_size``: Dictionary size in bytes. This should be between 4 KiB and
+  1.5 GiB (inclusive).
+* ``lc``: Number of literal context bits.
+* ``lp``: Number of literal position bits. The sum ``lc + lp`` must be at
+  most 4.
+* ``pb``: Number of position bits; must be at most 4.
+* ``mode``: :const:`MODE_FAST` or :const:`MODE_NORMAL`.
+* ``nice_len``: What should be considered a "nice length" for a match.
+  This should be 273 or less.
+* ``mf``: What match finder to use -- :const:`MF_HC3`, :const:`MF_HC4`,
+  :const:`MF_BT2`, :const:`MF_BT3`, or :const:`MF_BT4`.
+* ``depth``: Maximum search depth used by match finder. 0 (default) means to
+  select automatically based on other filter options.
 
 The delta filter stores the differences between bytes, producing more repetitive
 input for the compressor in certain circumstances. It supports one option,
diff --git a/Doc/library/mailbox.rst b/Doc/library/mailbox.rst
index 91df07d914..b27deb20f1 100644
--- a/Doc/library/mailbox.rst
+++ b/Doc/library/mailbox.rst
@@ -167,7 +167,7 @@ Supported mailbox formats are Maildir, mbox, MH, Babyl, and MMDF.
       Return a representation of the message corresponding to *key*. If no such
       message exists, *default* is returned if the method was called as
       :meth:`get` and a :exc:`KeyError` exception is raised if the method was
-      called as :meth:`__getitem__`. The message is represented as an instance
+      called as :meth:`~object.__getitem__`. The message is represented as an instance
       of the appropriate format-specific :class:`Message` subclass unless a
       custom message factory was specified when the :class:`Mailbox` instance
       was initialized.
diff --git a/Doc/library/mmap.rst b/Doc/library/mmap.rst
index 69afadff1f..4ca7a64451 100644
--- a/Doc/library/mmap.rst
+++ b/Doc/library/mmap.rst
@@ -19,7 +19,7 @@ the current file position, and :meth:`seek` through the file to different positi
 A memory-mapped file is created by the :class:`~mmap.mmap` constructor, which is
 different on Unix and on Windows.  In either case you must provide a file
 descriptor for a file opened for update. If you wish to map an existing Python
-file object, use its :meth:`fileno` method to obtain the correct value for the
+file object, use its :meth:`~io.IOBase.fileno` method to obtain the correct value for the
 *fileno* parameter.  Otherwise, you can open the file using the
 :func:`os.open` function, which returns a file descriptor directly (the file
 still needs to be closed when done).
diff --git a/Doc/library/multiprocessing.rst b/Doc/library/multiprocessing.rst
index 2f0f1f800f..01a24172e5 100644
--- a/Doc/library/multiprocessing.rst
+++ b/Doc/library/multiprocessing.rst
@@ -2571,7 +2571,7 @@ multiple connections at the same time.
    **Windows**: An item in *object_list* must either be an integer
    handle which is waitable (according to the definition used by the
    documentation of the Win32 function ``WaitForMultipleObjects()``)
-   or it can be an object with a :meth:`fileno` method which returns a
+   or it can be an object with a :meth:`~io.IOBase.fileno` method which returns a
    socket handle or pipe handle.  (Note that pipe handles and socket
    handles are **not** waitable handles.)
 
@@ -2782,20 +2782,20 @@ worker threads rather than worker processes.
 
    Unlike :class:`Pool`, *maxtasksperchild* and *context* cannot be provided.
 
-    .. note::
+   .. note::
 
-        A :class:`ThreadPool` shares the same interface as :class:`Pool`, which
-        is designed around a pool of processes and predates the introduction of
-        the :class:`concurrent.futures` module.  As such, it inherits some
-        operations that don't make sense for a pool backed by threads, and it
-        has its own type for representing the status of asynchronous jobs,
-        :class:`AsyncResult`, that is not understood by any other libraries.
-
-        Users should generally prefer to use
-        :class:`concurrent.futures.ThreadPoolExecutor`, which has a simpler
-        interface that was designed around threads from the start, and which
-        returns :class:`concurrent.futures.Future` instances that are
-        compatible with many other libraries, including :mod:`asyncio`.
+      A :class:`ThreadPool` shares the same interface as :class:`Pool`, which
+      is designed around a pool of processes and predates the introduction of
+      the :class:`concurrent.futures` module.  As such, it inherits some
+      operations that don't make sense for a pool backed by threads, and it
+      has its own type for representing the status of asynchronous jobs,
+      :class:`AsyncResult`, that is not understood by any other libraries.
+
+      Users should generally prefer to use
+      :class:`concurrent.futures.ThreadPoolExecutor`, which has a simpler
+      interface that was designed around threads from the start, and which
+      returns :class:`concurrent.futures.Future` instances that are
+      compatible with many other libraries, including :mod:`asyncio`.
 
 
 .. _multiprocessing-programming:
diff --git a/Doc/library/numbers.rst b/Doc/library/numbers.rst
index b3dce151ae..2a05b56db0 100644
--- a/Doc/library/numbers.rst
+++ b/Doc/library/numbers.rst
@@ -160,23 +160,23 @@ refer to ``MyIntegral`` and ``OtherTypeIKnowAbout`` as
 of :class:`Complex` (``a : A <: Complex``), and ``b : B <:
 Complex``. I'll consider ``a + b``:
 
-    1. If ``A`` defines an :meth:`__add__` which accepts ``b``, all is
-       well.
-    2. If ``A`` falls back to the boilerplate code, and it were to
-       return a value from :meth:`__add__`, we'd miss the possibility
-       that ``B`` defines a more intelligent :meth:`__radd__`, so the
-       boilerplate should return :const:`NotImplemented` from
-       :meth:`__add__`. (Or ``A`` may not implement :meth:`__add__` at
-       all.)
-    3. Then ``B``'s :meth:`__radd__` gets a chance. If it accepts
-       ``a``, all is well.
-    4. If it falls back to the boilerplate, there are no more possible
-       methods to try, so this is where the default implementation
-       should live.
-    5. If ``B <: A``, Python tries ``B.__radd__`` before
-       ``A.__add__``. This is ok, because it was implemented with
-       knowledge of ``A``, so it can handle those instances before
-       delegating to :class:`Complex`.
+1. If ``A`` defines an :meth:`__add__` which accepts ``b``, all is
+   well.
+2. If ``A`` falls back to the boilerplate code, and it were to
+   return a value from :meth:`__add__`, we'd miss the possibility
+   that ``B`` defines a more intelligent :meth:`__radd__`, so the
+   boilerplate should return :const:`NotImplemented` from
+   :meth:`__add__`. (Or ``A`` may not implement :meth:`__add__` at
+   all.)
+3. Then ``B``'s :meth:`__radd__` gets a chance. If it accepts
+   ``a``, all is well.
+4. If it falls back to the boilerplate, there are no more possible
+   methods to try, so this is where the default implementation
+   should live.
+5. If ``B <: A``, Python tries ``B.__radd__`` before
+   ``A.__add__``. This is ok, because it was implemented with
+   knowledge of ``A``, so it can handle those instances before
+   delegating to :class:`Complex`.
 
 If ``A <: Complex`` and ``B <: Real`` without sharing any other knowledge,
 then the appropriate shared operation is the one involving the built
diff --git a/Doc/library/operator.rst b/Doc/library/operator.rst
index 57c67bcf3a..96f2c28787 100644
--- a/Doc/library/operator.rst
+++ b/Doc/library/operator.rst
@@ -306,7 +306,7 @@ expect a function argument.
               itemgetter(*items)
 
    Return a callable object that fetches *item* from its operand using the
-   operand's :meth:`__getitem__` method.  If multiple items are specified,
+   operand's :meth:`~object.__getitem__` method.  If multiple items are specified,
    returns a tuple of lookup values.  For example:
 
    * After ``f = itemgetter(2)``, the call ``f(r)`` returns ``r[2]``.
@@ -326,7 +326,7 @@ expect a function argument.
                   return tuple(obj[item] for item in items)
           return g
 
-   The items can be any type accepted by the operand's :meth:`__getitem__`
+   The items can be any type accepted by the operand's :meth:`~object.__getitem__`
    method.  Dictionaries accept any :term:`hashable` value.  Lists, tuples, and
    strings accept an index or a slice:
 
diff --git a/Doc/library/os.rst b/Doc/library/os.rst
index 4ffd520f9e..0c36c244ab 100644
--- a/Doc/library/os.rst
+++ b/Doc/library/os.rst
@@ -5141,8 +5141,10 @@ operating system.
 
 .. function:: sched_getaffinity(pid, /)
 
-   Return the set of CPUs the process with PID *pid* (or the current process
-   if zero) is restricted to.
+   Return the set of CPUs the process with PID *pid* is restricted to.
+
+   If *pid* is zero, return the set of CPUs the calling thread of the current
+   process is restricted to.
 
 
 .. _os-path:
@@ -5183,12 +5185,12 @@ Miscellaneous System Information
 
 .. function:: cpu_count()
 
-   Return the number of CPUs in the system. Returns ``None`` if undetermined.
-
-   This number is not equivalent to the number of CPUs the current process can
-   use.  The number of usable CPUs can be obtained with
-   ``len(os.sched_getaffinity(0))``
+   Return the number of logical CPUs in the system. Returns ``None`` if
+   undetermined.
 
+   This number is not equivalent to the number of logical CPUs the current
+   process can use. ``len(os.sched_getaffinity(0))`` gets the number of logical
+   CPUs the calling thread of the current process is restricted to
 
    .. versionadded:: 3.4
 
diff --git a/Doc/library/pickletools.rst b/Doc/library/pickletools.rst
index 480f4a6d32..41930f8cbe 100644
--- a/Doc/library/pickletools.rst
+++ b/Doc/library/pickletools.rst
@@ -17,6 +17,8 @@ are useful for Python core developers who are working on the :mod:`pickle`;
 ordinary users of the :mod:`pickle` module probably won't find the
 :mod:`pickletools` module relevant.
 
+.. _pickletools-cli:
+
 Command line usage
 ------------------
 
@@ -51,24 +53,24 @@ Command line options
 
 .. program:: pickletools
 
-.. cmdoption:: -a, --annotate
+.. option:: -a, --annotate
 
    Annotate each line with a short opcode description.
 
-.. cmdoption:: -o, --output=<file>
+.. option:: -o, --output=<file>
 
    Name of a file where the output should be written.
 
-.. cmdoption:: -l, --indentlevel=<num>
+.. option:: -l, --indentlevel=<num>
 
    The number of blanks by which to indent a new MARK level.
 
-.. cmdoption:: -m, --memo
+.. option:: -m, --memo
 
    When multiple objects are disassembled, preserve memo between
    disassemblies.
 
-.. cmdoption:: -p, --preamble=<preamble>
+.. option:: -p, --preamble=<preamble>
 
    When more than one pickle file are specified, print given preamble
    before each disassembly.
diff --git a/Doc/library/posix.rst b/Doc/library/posix.rst
index 0413f9d02a..5871574b44 100644
--- a/Doc/library/posix.rst
+++ b/Doc/library/posix.rst
@@ -11,6 +11,8 @@ This module provides access to operating system functionality that is
 standardized by the C Standard and the POSIX standard (a thinly disguised Unix
 interface).
 
+.. availability:: Unix.
+
 .. index:: pair: module; os
 
 **Do not import this module directly.**  Instead, import the module :mod:`os`,
diff --git a/Doc/library/profile.rst b/Doc/library/profile.rst
index 723f927135..4c60a1e0d7 100644
--- a/Doc/library/profile.rst
+++ b/Doc/library/profile.rst
@@ -121,6 +121,8 @@ results to a file by specifying a filename to the :func:`run` function::
 The :class:`pstats.Stats` class reads profile results from a file and formats
 them in various ways.
 
+.. _profile-cli:
+
 The files :mod:`cProfile` and :mod:`profile` can also be invoked as a script to
 profile another script.  For example::
 
@@ -133,11 +135,11 @@ the output by. This only applies when ``-o`` is not supplied.
 
 ``-m`` specifies that a module is being profiled instead of a script.
 
-   .. versionadded:: 3.7
-      Added the ``-m`` option to :mod:`cProfile`.
+.. versionadded:: 3.7
+   Added the ``-m`` option to :mod:`cProfile`.
 
-   .. versionadded:: 3.8
-      Added the ``-m`` option to :mod:`profile`.
+.. versionadded:: 3.8
+   Added the ``-m`` option to :mod:`profile`.
 
 The :mod:`pstats` module's :class:`~pstats.Stats` class has a variety of methods
 for manipulating and printing the data saved into a profile results file::
diff --git a/Doc/library/pty.rst b/Doc/library/pty.rst
index ad4981c971..af9378464e 100644
--- a/Doc/library/pty.rst
+++ b/Doc/library/pty.rst
@@ -16,6 +16,8 @@ The :mod:`pty` module defines operations for handling the pseudo-terminal
 concept: starting another process and being able to write to and read from its
 controlling terminal programmatically.
 
+.. availability:: Unix.
+
 Pseudo-terminal handling is highly platform dependent. This code is mainly
 tested on Linux, FreeBSD, and macOS (it is supposed to work on other POSIX
 platforms but it's not been thoroughly tested).
diff --git a/Doc/library/pwd.rst b/Doc/library/pwd.rst
index 7cafc66fd7..755f0d29ac 100644
--- a/Doc/library/pwd.rst
+++ b/Doc/library/pwd.rst
@@ -10,7 +10,7 @@
 This module provides access to the Unix user account and password database.  It
 is available on all Unix versions.
 
-.. include:: ../includes/wasm-notavail.rst
+.. availability:: Unix, not Emscripten, not WASI.
 
 Password database entries are reported as a tuple-like object, whose attributes
 correspond to the members of the ``passwd`` structure (Attribute field below,
diff --git a/Doc/library/py_compile.rst b/Doc/library/py_compile.rst
index 69b93a3bdf..38c416f9ad 100644
--- a/Doc/library/py_compile.rst
+++ b/Doc/library/py_compile.rst
@@ -125,6 +125,7 @@ byte-code cache files in the directory containing the source code.
       This option is useful when the ``.pycs`` are kept up to date by some
       system external to Python like a build system.
 
+.. _py_compile-cli:
 
 Command-Line Interface
 ----------------------
@@ -138,13 +139,13 @@ not be compiled.
 
 .. program:: python -m py_compile
 
-.. cmdoption:: <file> ... <fileN>
-               -
+.. option:: <file> ... <fileN>
+            -
 
    Positional arguments are files to compile.  If ``-`` is the only
    parameter, the list of files is taken from standard input.
 
-.. cmdoption:: -q, --quiet
+.. option:: -q, --quiet
 
    Suppress errors output.
 
diff --git a/Doc/library/re.rst b/Doc/library/re.rst
index 92aae10030..bb1c3132ba 100644
--- a/Doc/library/re.rst
+++ b/Doc/library/re.rst
@@ -176,7 +176,7 @@ The special characters are:
   ``x*+``, ``x++`` and ``x?+`` are equivalent to ``(?>x*)``, ``(?>x+)``
   and ``(?>x?)`` correspondingly.
 
-   .. versionadded:: 3.11
+  .. versionadded:: 3.11
 
 .. index::
    single: {} (curly brackets); in regular expressions
diff --git a/Doc/library/resource.rst b/Doc/library/resource.rst
index a5324c82c6..ef65674d1b 100644
--- a/Doc/library/resource.rst
+++ b/Doc/library/resource.rst
@@ -13,7 +13,7 @@
 This module provides basic mechanisms for measuring and controlling system
 resources utilized by a program.
 
-.. include:: ../includes/wasm-notavail.rst
+.. availability:: Unix, not Emscripten, not WASI.
 
 Symbolic constants are used to specify particular system resources and to
 request usage information about either the current process or its children.
diff --git a/Doc/library/selectors.rst b/Doc/library/selectors.rst
index dd50bac37e..76cbf91412 100644
--- a/Doc/library/selectors.rst
+++ b/Doc/library/selectors.rst
@@ -21,7 +21,7 @@ It defines a :class:`BaseSelector` abstract base class, along with several
 concrete implementations (:class:`KqueueSelector`, :class:`EpollSelector`...),
 that can be used to wait for I/O readiness notification on multiple file
 objects. In the following, "file object" refers to any object with a
-:meth:`fileno()` method, or a raw file descriptor. See :term:`file object`.
+:meth:`~io.IOBase.fileno` method, or a raw file descriptor. See :term:`file object`.
 
 :class:`DefaultSelector` is an alias to the most efficient implementation
 available on the current platform: this should be the default choice for most
diff --git a/Doc/library/shelve.rst b/Doc/library/shelve.rst
index 01314f491f..219219af6f 100644
--- a/Doc/library/shelve.rst
+++ b/Doc/library/shelve.rst
@@ -94,9 +94,9 @@ Two additional methods are supported:
 Restrictions
 ------------
 
-  .. index::
-     pair: module; dbm.ndbm
-     pair: module; dbm.gnu
+.. index::
+   pair: module; dbm.ndbm
+   pair: module; dbm.gnu
 
 * The choice of which database package will be used (such as :mod:`dbm.ndbm` or
   :mod:`dbm.gnu`) depends on which interface is available.  Therefore it is not
diff --git a/Doc/library/shutil.rst b/Doc/library/shutil.rst
index 4390a8e223..d1949d698f 100644
--- a/Doc/library/shutil.rst
+++ b/Doc/library/shutil.rst
@@ -476,6 +476,12 @@ Directory and files operations
       or ends with an extension that is in ``PATHEXT``; and filenames that
       have no extension can now be found.
 
+   .. versionchanged:: 3.12.1
+      On Windows, if *mode* includes ``os.X_OK``, executables with an
+      extension in ``PATHEXT`` will be preferred over executables without a
+      matching extension.
+      This brings behavior closer to that of Python 3.11.
+
 .. exception:: Error
 
    This exception collects exceptions that are raised during a multi-file
diff --git a/Doc/library/site.rst b/Doc/library/site.rst
index 02880c5641..2dc9fb09d7 100644
--- a/Doc/library/site.rst
+++ b/Doc/library/site.rst
@@ -266,11 +266,11 @@ If it is called without arguments, it will print the contents of
 :data:`USER_BASE` and whether the directory exists, then the same thing for
 :data:`USER_SITE`, and finally the value of :data:`ENABLE_USER_SITE`.
 
-.. cmdoption:: --user-base
+.. option:: --user-base
 
    Print the path to the user base directory.
 
-.. cmdoption:: --user-site
+.. option:: --user-site
 
    Print the path to the user site-packages directory.
 
diff --git a/Doc/library/socket.rst b/Doc/library/socket.rst
index 83957c8799..9ff1aa3984 100644
--- a/Doc/library/socket.rst
+++ b/Doc/library/socket.rst
@@ -207,14 +207,14 @@ created.  Socket addresses are represented as follows:
   - *addr* - Optional bytes-like object specifying the hardware physical
     address, whose interpretation depends on the device.
 
-   .. availability:: Linux >= 2.2.
+  .. availability:: Linux >= 2.2.
 
 - :const:`AF_QIPCRTR` is a Linux-only socket based interface for communicating
   with services running on co-processors in Qualcomm platforms. The address
   family is represented as a ``(node, port)`` tuple where the *node* and *port*
   are non-negative integers.
 
-   .. availability:: Linux >= 4.7.
+  .. availability:: Linux >= 4.7.
 
   .. versionadded:: 3.8
 
@@ -352,6 +352,11 @@ Constants
    defined then this protocol is unsupported.  More constants may be available
    depending on the system.
 
+.. data:: AF_UNSPEC
+
+   :const:`AF_UNSPEC` means that
+   :func:`getaddrinfo` should return socket addresses for any
+   address family (either IPv4, IPv6, or any other) that can be used.
 
 .. data:: SOCK_STREAM
           SOCK_DGRAM
@@ -380,6 +385,8 @@ Constants
 
    .. versionadded:: 3.2
 
+.. _socket-unix-constants:
+
 .. data:: SO_*
           SOMAXCONN
           MSG_*
@@ -858,7 +865,7 @@ The following functions all create :ref:`socket objects <socket-objects>`.
 .. function:: fromfd(fd, family, type, proto=0)
 
    Duplicate the file descriptor *fd* (an integer as returned by a file object's
-   :meth:`fileno` method) and build a socket object from the result.  Address
+   :meth:`~io.IOBase.fileno` method) and build a socket object from the result.  Address
    family, socket type and protocol number are as for the :func:`.socket` function
    above. The file descriptor should refer to a socket, but this is not checked ---
    subsequent operations on the object may fail if the file descriptor is invalid.
@@ -2100,7 +2107,7 @@ The next two examples are identical to the above two, but support both IPv4 and
 IPv6. The server side will listen to the first address family available (it
 should listen to both instead). On most of IPv6-ready systems, IPv6 will take
 precedence and the server may not accept IPv4 traffic. The client side will try
-to connect to the all addresses returned as a result of the name resolution, and
+to connect to all the addresses returned as a result of the name resolution, and
 sends traffic to the first one connected successfully. ::
 
    # Echo server program
diff --git a/Doc/library/socketserver.rst b/Doc/library/socketserver.rst
index d65e9fe81a..5fd213fa61 100644
--- a/Doc/library/socketserver.rst
+++ b/Doc/library/socketserver.rst
@@ -116,23 +116,28 @@ server is the address family.
    :class:`ForkingMixIn` and the Forking classes mentioned below are
    only available on POSIX platforms that support :func:`~os.fork`.
 
-   :meth:`socketserver.ForkingMixIn.server_close` waits until all child
-   processes complete, except if
-   :attr:`socketserver.ForkingMixIn.block_on_close` attribute is false.
+   .. attribute:: block_on_close
 
-   :meth:`socketserver.ThreadingMixIn.server_close` waits until all non-daemon
-   threads complete, except if
-   :attr:`socketserver.ThreadingMixIn.block_on_close` attribute is false. Use
-   daemonic threads by setting
-   :data:`ThreadingMixIn.daemon_threads` to ``True`` to not wait until threads
-   complete.
+      :meth:`ForkingMixIn.server_close <BaseServer.server_close>`
+      waits until all child processes complete, except if
+      :attr:`block_on_close` attribute is ``False``.
+
+      :meth:`ThreadingMixIn.server_close <BaseServer.server_close>`
+      waits until all non-daemon threads complete, except if
+      :attr:`block_on_close` attribute is ``False``.
+
+   .. attribute:: daemon_threads
+
+      For :class:`ThreadingMixIn` use daemonic threads by setting
+      :data:`ThreadingMixIn.daemon_threads <daemon_threads>`
+      to ``True`` to not wait until threads complete.
 
    .. versionchanged:: 3.7
 
-      :meth:`socketserver.ForkingMixIn.server_close` and
-      :meth:`socketserver.ThreadingMixIn.server_close` now waits until all
+      :meth:`ForkingMixIn.server_close <BaseServer.server_close>` and
+      :meth:`ThreadingMixIn.server_close <BaseServer.server_close>` now waits until all
       child processes and non-daemonic threads complete.
-      Add a new :attr:`socketserver.ForkingMixIn.block_on_close` class
+      Add a new :attr:`ForkingMixIn.block_on_close <block_on_close>` class
       attribute to opt-in for the pre-3.7 behaviour.
 
 
@@ -412,13 +417,13 @@ Request Handler Objects
 
       This function must do all the work required to service a request.  The
       default implementation does nothing.  Several instance attributes are
-      available to it; the request is available as :attr:`self.request`; the client
-      address as :attr:`self.client_address`; and the server instance as
-      :attr:`self.server`, in case it needs access to per-server information.
+      available to it; the request is available as :attr:`request`; the client
+      address as :attr:`client_address`; and the server instance as
+      :attr:`server`, in case it needs access to per-server information.
 
-      The type of :attr:`self.request` is different for datagram or stream
-      services.  For stream services, :attr:`self.request` is a socket object; for
-      datagram services, :attr:`self.request` is a pair of string and socket.
+      The type of :attr:`request` is different for datagram or stream
+      services.  For stream services, :attr:`request` is a socket object; for
+      datagram services, :attr:`request` is a pair of string and socket.
 
 
    .. method:: finish()
@@ -428,20 +433,42 @@ Request Handler Objects
       raises an exception, this function will not be called.
 
 
+   .. attribute:: request
+
+      The *new* :class:`socket.socket` object
+      to be used to communicate with the client.
+
+
+   .. attribute:: client_address
+
+      Client address returned by :meth:`BaseServer.get_request`.
+
+
+   .. attribute:: server
+
+      :class:`BaseServer` object used for handling the request.
+
+
 .. class:: StreamRequestHandler
            DatagramRequestHandler
 
    These :class:`BaseRequestHandler` subclasses override the
    :meth:`~BaseRequestHandler.setup` and :meth:`~BaseRequestHandler.finish`
-   methods, and provide :attr:`self.rfile` and :attr:`self.wfile` attributes.
-   The :attr:`self.rfile` and :attr:`self.wfile` attributes can be
-   read or written, respectively, to get the request data or return data
-   to the client.
-   The :attr:`!rfile` attributes support the :class:`io.BufferedIOBase` readable interface,
-   and :attr:`!wfile` attributes support the :class:`!io.BufferedIOBase` writable interface.
+   methods, and provide :attr:`rfile` and :attr:`wfile` attributes.
+
+   .. attribute:: rfile
+
+      A file object from which receives the request is read.
+      Support the :class:`io.BufferedIOBase` readable interface.
+
+   .. attribute:: wfile
+
+      A file object to which the reply is written.
+      Support the :class:`io.BufferedIOBase` writable interface
+
 
    .. versionchanged:: 3.6
-      :attr:`StreamRequestHandler.wfile` also supports the
+      :attr:`wfile` also supports the
       :class:`io.BufferedIOBase` writable interface.
 
 
diff --git a/Doc/library/sqlite3.rst b/Doc/library/sqlite3.rst
index d5afaa1c4c..3cb2f4548c 100644
--- a/Doc/library/sqlite3.rst
+++ b/Doc/library/sqlite3.rst
@@ -235,11 +235,11 @@ inserted data and retrieved values from it in multiple ways.
 
    * :ref:`sqlite3-howtos` for further reading:
 
-      * :ref:`sqlite3-placeholders`
-      * :ref:`sqlite3-adapters`
-      * :ref:`sqlite3-converters`
-      * :ref:`sqlite3-connection-context-manager`
-      * :ref:`sqlite3-howto-row-factory`
+     * :ref:`sqlite3-placeholders`
+     * :ref:`sqlite3-adapters`
+     * :ref:`sqlite3-converters`
+     * :ref:`sqlite3-connection-context-manager`
+     * :ref:`sqlite3-howto-row-factory`
 
    * :ref:`sqlite3-explanation` for in-depth background on transaction control.
 
@@ -523,13 +523,13 @@ Module constants
    the default `threading mode <https://sqlite.org/threadsafe.html>`_ the
    underlying SQLite library is compiled with. The SQLite threading modes are:
 
-     1. **Single-thread**: In this mode, all mutexes are disabled and SQLite is
-        unsafe to use in more than a single thread at once.
-     2. **Multi-thread**: In this mode, SQLite can be safely used by multiple
-        threads provided that no single database connection is used
-        simultaneously in two or more threads.
-     3. **Serialized**: In serialized mode, SQLite can be safely used by
-        multiple threads with no restriction.
+   1. **Single-thread**: In this mode, all mutexes are disabled and SQLite is
+      unsafe to use in more than a single thread at once.
+   2. **Multi-thread**: In this mode, SQLite can be safely used by multiple
+      threads provided that no single database connection is used
+      simultaneously in two or more threads.
+   3. **Serialized**: In serialized mode, SQLite can be safely used by
+      multiple threads with no restriction.
 
    The mappings from SQLite threading modes to DB-API 2.0 threadsafety levels
    are as follows:
@@ -1123,6 +1123,10 @@ Connection objects
                  f.write('%s\n' % line)
          con.close()
 
+      .. seealso::
+
+         :ref:`sqlite3-howto-encoding`
+
 
    .. method:: backup(target, *, pages=-1, progress=None, name="main", sleep=0.250)
 
@@ -1189,6 +1193,10 @@ Connection objects
 
       .. versionadded:: 3.7
 
+      .. seealso::
+
+         :ref:`sqlite3-howto-encoding`
+
    .. method:: getlimit(category, /)
 
       Get a connection runtime limit.
@@ -1410,39 +1418,8 @@ Connection objects
       and returns a text representation of it.
       The callable is invoked for SQLite values with the ``TEXT`` data type.
       By default, this attribute is set to :class:`str`.
-      If you want to return ``bytes`` instead, set *text_factory* to ``bytes``.
-
-      Example:
-
-      .. testcode::
-
-         con = sqlite3.connect(":memory:")
-         cur = con.cursor()
-
-         AUSTRIA = "Österreich"
-
-         # by default, rows are returned as str
-         cur.execute("SELECT ?", (AUSTRIA,))
-         row = cur.fetchone()
-         assert row[0] == AUSTRIA
-
-         # but we can make sqlite3 always return bytestrings ...
-         con.text_factory = bytes
-         cur.execute("SELECT ?", (AUSTRIA,))
-         row = cur.fetchone()
-         assert type(row[0]) is bytes
-         # the bytestrings will be encoded in UTF-8, unless you stored garbage in the
-         # database ...
-         assert row[0] == AUSTRIA.encode("utf-8")
-
-         # we can also implement a custom text_factory ...
-         # here we implement one that appends "foo" to all strings
-         con.text_factory = lambda x: x.decode("utf-8") + "foo"
-         cur.execute("SELECT ?", ("bar",))
-         row = cur.fetchone()
-         assert row[0] == "barfoo"
 
-         con.close()
+      See :ref:`sqlite3-howto-encoding` for more details.
 
    .. attribute:: total_changes
 
@@ -1601,7 +1578,6 @@ Cursor objects
              COMMIT;
          """)
 
-
    .. method:: fetchone()
 
       If :attr:`~Cursor.row_factory` is ``None``,
@@ -2406,9 +2382,9 @@ or if :attr:`~Connection.autocommit` is ``True``,
 the context manager does nothing.
 
 .. note::
-
    The context manager neither implicitly opens a new transaction
-   nor closes the connection.
+   nor closes the connection. If you need a closing context manager, consider
+   using :meth:`contextlib.closing`.
 
 .. testcode::
 
@@ -2580,6 +2556,47 @@ With some adjustments, the above recipe can be adapted to use a
 instead of a :class:`~collections.namedtuple`.
 
 
+.. _sqlite3-howto-encoding:
+
+How to handle non-UTF-8 text encodings
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+By default, :mod:`!sqlite3` uses :class:`str` to adapt SQLite values
+with the ``TEXT`` data type.
+This works well for UTF-8 encoded text, but it might fail for other encodings
+and invalid UTF-8.
+You can use a custom :attr:`~Connection.text_factory` to handle such cases.
+
+Because of SQLite's `flexible typing`_, it is not uncommon to encounter table
+columns with the ``TEXT`` data type containing non-UTF-8 encodings,
+or even arbitrary data.
+To demonstrate, let's assume we have a database with ISO-8859-2 (Latin-2)
+encoded text, for example a table of Czech-English dictionary entries.
+Assuming we now have a :class:`Connection` instance :py:data:`!con`
+connected to this database,
+we can decode the Latin-2 encoded text using this :attr:`~Connection.text_factory`:
+
+.. testcode::
+
+   con.text_factory = lambda data: str(data, encoding="latin2")
+
+For invalid UTF-8 or arbitrary data in stored in ``TEXT`` table columns,
+you can use the following technique, borrowed from the :ref:`unicode-howto`:
+
+.. testcode::
+
+   con.text_factory = lambda data: str(data, errors="surrogateescape")
+
+.. note::
+
+   The :mod:`!sqlite3` module API does not support strings
+   containing surrogates.
+
+.. seealso::
+
+   :ref:`unicode-howto`
+
+
 .. _sqlite3-explanation:
 
 Explanation
diff --git a/Doc/library/ssl.rst b/Doc/library/ssl.rst
index 5d6bc829d6..94d19507da 100644
--- a/Doc/library/ssl.rst
+++ b/Doc/library/ssl.rst
@@ -1380,18 +1380,18 @@ to speed up repeated connections from the same clients.
    Here's a table showing which versions in a client (down the side) can connect
    to which versions in a server (along the top):
 
-     .. table::
-
-       ========================  ============  ============  =============  =========  ===========  ===========
-        *client* / **server**    **SSLv2**     **SSLv3**     **TLS** [3]_   **TLSv1**  **TLSv1.1**  **TLSv1.2**
-       ------------------------  ------------  ------------  -------------  ---------  -----------  -----------
-        *SSLv2*                    yes           no            no [1]_        no         no         no
-        *SSLv3*                    no            yes           no [2]_        no         no         no
-        *TLS* (*SSLv23*) [3]_      no [1]_       no [2]_       yes            yes        yes        yes
-        *TLSv1*                    no            no            yes            yes        no         no
-        *TLSv1.1*                  no            no            yes            no         yes        no
-        *TLSv1.2*                  no            no            yes            no         no         yes
-       ========================  ============  ============  =============  =========  ===========  ===========
+   .. table::
+
+      ========================  ============  ============  =============  =========  ===========  ===========
+       *client* / **server**    **SSLv2**     **SSLv3**     **TLS** [3]_   **TLSv1**  **TLSv1.1**  **TLSv1.2**
+      ------------------------  ------------  ------------  -------------  ---------  -----------  -----------
+       *SSLv2*                    yes           no            no [1]_        no         no         no
+       *SSLv3*                    no            yes           no [2]_        no         no         no
+       *TLS* (*SSLv23*) [3]_      no [1]_       no [2]_       yes            yes        yes        yes
+       *TLSv1*                    no            no            yes            yes        no         no
+       *TLSv1.1*                  no            no            yes            no         yes        no
+       *TLSv1.2*                  no            no            yes            no         no         yes
+      ========================  ============  ============  =============  =========  ===========  ===========
 
    .. rubric:: Footnotes
    .. [1] :class:`SSLContext` disables SSLv2 with :data:`OP_NO_SSLv2` by default.
diff --git a/Doc/library/statistics.rst b/Doc/library/statistics.rst
index 6e6ca7cef3..318e5d7461 100644
--- a/Doc/library/statistics.rst
+++ b/Doc/library/statistics.rst
@@ -14,6 +14,7 @@
 .. testsetup:: *
 
    from statistics import *
+   import math
    __name__ = '<doctest>'
 
 --------------
@@ -741,6 +742,24 @@ However, for reading convenience, most of the examples show sorted sequences.
 
       *y = slope \* x + noise*
 
+   Continuing the example from :func:`correlation`, we look to see
+   how well a model based on major planets can predict the orbital
+   distances for dwarf planets:
+
+   .. doctest::
+
+      >>> model = linear_regression(period_squared, dist_cubed, proportional=True)
+      >>> slope = model.slope
+
+      >>> # Dwarf planets:   Pluto,  Eris,    Makemake, Haumea, Ceres
+      >>> orbital_periods = [90_560, 204_199, 111_845, 103_410, 1_680]  # days
+      >>> predicted_dist = [math.cbrt(slope * (p * p)) for p in orbital_periods]
+      >>> list(map(round, predicted_dist))
+      [5912, 10166, 6806, 6459, 414]
+
+      >>> [5_906, 10_152, 6_796, 6_450, 414]  # actual distance in million km
+      [5906, 10152, 6796, 6450, 414]
+
    .. versionadded:: 3.10
 
    .. versionchanged:: 3.11
diff --git a/Doc/library/stdtypes.rst b/Doc/library/stdtypes.rst
index 50f5660391..4d44ca2766 100644
--- a/Doc/library/stdtypes.rst
+++ b/Doc/library/stdtypes.rst
@@ -48,9 +48,9 @@ By default, an object is considered true unless its class defines either a
 returns zero, when called with the object. [1]_  Here are most of the built-in
 objects considered false:
 
-  .. index::
-     single: None (Built-in object)
-     single: False (Built-in object)
+.. index::
+   single: None (Built-in object)
+   single: False (Built-in object)
 
 * constants defined to be false: ``None`` and ``False``
 
@@ -804,6 +804,7 @@ number, :class:`float`, or :class:`complex`::
            hash_value = -2
        return hash_value
 
+.. _bltin-boolean-values:
 .. _typebool:
 
 Boolean Type - :class:`bool`
@@ -2263,7 +2264,7 @@ expression support in the :mod:`re` module).
 
    Return a copy of the string in which each character has been mapped through
    the given translation table.  The table must be an object that implements
-   indexing via :meth:`__getitem__`, typically a :term:`mapping` or
+   indexing via :meth:`~object.__getitem__`, typically a :term:`mapping` or
    :term:`sequence`.  When indexed by a Unicode ordinal (an integer), the
    table object can do any of the following: return a Unicode ordinal or a
    string, to map the character to one or more other characters; return
@@ -4853,7 +4854,7 @@ before the statement body is executed and exited when the statement ends:
    The exception passed in should never be reraised explicitly - instead, this
    method should return a false value to indicate that the method completed
    successfully and does not want to suppress the raised exception. This allows
-   context management code to easily detect whether or not an :meth:`__exit__`
+   context management code to easily detect whether or not an :meth:`~object.__exit__`
    method has actually failed.
 
 Python defines several context managers to support easy thread synchronisation,
diff --git a/Doc/library/string.rst b/Doc/library/string.rst
index 9b28f99536..262b785bbc 100644
--- a/Doc/library/string.rst
+++ b/Doc/library/string.rst
@@ -206,15 +206,15 @@ literal text, it can be escaped by doubling: ``{{`` and ``}}``.
 
 The grammar for a replacement field is as follows:
 
-   .. productionlist:: format-string
-      replacement_field: "{" [`field_name`] ["!" `conversion`] [":" `format_spec`] "}"
-      field_name: arg_name ("." `attribute_name` | "[" `element_index` "]")*
-      arg_name: [`identifier` | `digit`+]
-      attribute_name: `identifier`
-      element_index: `digit`+ | `index_string`
-      index_string: <any source character except "]"> +
-      conversion: "r" | "s" | "a"
-      format_spec: <described in the next section>
+.. productionlist:: format-string
+   replacement_field: "{" [`field_name`] ["!" `conversion`] [":" `format_spec`] "}"
+   field_name: arg_name ("." `attribute_name` | "[" `element_index` "]")*
+   arg_name: [`identifier` | `digit`+]
+   attribute_name: `identifier`
+   element_index: `digit`+ | `index_string`
+   index_string: <any source character except "]"> +
+   conversion: "r" | "s" | "a"
+   format_spec: <described in the next section>
 
 In less formal terms, the replacement field can start with a *field_name* that specifies
 the object whose value is to be formatted and inserted
@@ -332,30 +332,30 @@ affect the :func:`format` function.
 
 The meaning of the various alignment options is as follows:
 
-   .. index::
-      single: < (less); in string formatting
-      single: > (greater); in string formatting
-      single: = (equals); in string formatting
-      single: ^ (caret); in string formatting
-
-   +---------+----------------------------------------------------------+
-   | Option  | Meaning                                                  |
-   +=========+==========================================================+
-   | ``'<'`` | Forces the field to be left-aligned within the available |
-   |         | space (this is the default for most objects).            |
-   +---------+----------------------------------------------------------+
-   | ``'>'`` | Forces the field to be right-aligned within the          |
-   |         | available space (this is the default for numbers).       |
-   +---------+----------------------------------------------------------+
-   | ``'='`` | Forces the padding to be placed after the sign (if any)  |
-   |         | but before the digits.  This is used for printing fields |
-   |         | in the form '+000000120'. This alignment option is only  |
-   |         | valid for numeric types.  It becomes the default for     |
-   |         | numbers when '0' immediately precedes the field width.   |
-   +---------+----------------------------------------------------------+
-   | ``'^'`` | Forces the field to be centered within the available     |
-   |         | space.                                                   |
-   +---------+----------------------------------------------------------+
+.. index::
+   single: < (less); in string formatting
+   single: > (greater); in string formatting
+   single: = (equals); in string formatting
+   single: ^ (caret); in string formatting
+
++---------+----------------------------------------------------------+
+| Option  | Meaning                                                  |
++=========+==========================================================+
+| ``'<'`` | Forces the field to be left-aligned within the available |
+|         | space (this is the default for most objects).            |
++---------+----------------------------------------------------------+
+| ``'>'`` | Forces the field to be right-aligned within the          |
+|         | available space (this is the default for numbers).       |
++---------+----------------------------------------------------------+
+| ``'='`` | Forces the padding to be placed after the sign (if any)  |
+|         | but before the digits.  This is used for printing fields |
+|         | in the form '+000000120'. This alignment option is only  |
+|         | valid for numeric types.  It becomes the default for     |
+|         | numbers when '0' immediately precedes the field width.   |
++---------+----------------------------------------------------------+
+| ``'^'`` | Forces the field to be centered within the available     |
+|         | space.                                                   |
++---------+----------------------------------------------------------+
 
 Note that unless a minimum field width is defined, the field width will always
 be the same size as the data to fill it, so that the alignment option has no
@@ -364,23 +364,23 @@ meaning in this case.
 The *sign* option is only valid for number types, and can be one of the
 following:
 
-   .. index::
-      single: + (plus); in string formatting
-      single: - (minus); in string formatting
-      single: space; in string formatting
-
-   +---------+----------------------------------------------------------+
-   | Option  | Meaning                                                  |
-   +=========+==========================================================+
-   | ``'+'`` | indicates that a sign should be used for both            |
-   |         | positive as well as negative numbers.                    |
-   +---------+----------------------------------------------------------+
-   | ``'-'`` | indicates that a sign should be used only for negative   |
-   |         | numbers (this is the default behavior).                  |
-   +---------+----------------------------------------------------------+
-   | space   | indicates that a leading space should be used on         |
-   |         | positive numbers, and a minus sign on negative numbers.  |
-   +---------+----------------------------------------------------------+
+.. index::
+   single: + (plus); in string formatting
+   single: - (minus); in string formatting
+   single: space; in string formatting
+
++---------+----------------------------------------------------------+
+| Option  | Meaning                                                  |
++=========+==========================================================+
+| ``'+'`` | indicates that a sign should be used for both            |
+|         | positive as well as negative numbers.                    |
++---------+----------------------------------------------------------+
+| ``'-'`` | indicates that a sign should be used only for negative   |
+|         | numbers (this is the default behavior).                  |
++---------+----------------------------------------------------------+
+| space   | indicates that a leading space should be used on         |
+|         | positive numbers, and a minus sign on negative numbers.  |
++---------+----------------------------------------------------------+
 
 
 .. index:: single: z; in string formatting
diff --git a/Doc/library/subprocess.rst b/Doc/library/subprocess.rst
index 04340cca9e..7f22a5d185 100644
--- a/Doc/library/subprocess.rst
+++ b/Doc/library/subprocess.rst
@@ -666,18 +666,18 @@ functions.
    passed to the underlying ``CreateProcess`` function.
    *creationflags*, if given, can be one or more of the following flags:
 
-      * :data:`CREATE_NEW_CONSOLE`
-      * :data:`CREATE_NEW_PROCESS_GROUP`
-      * :data:`ABOVE_NORMAL_PRIORITY_CLASS`
-      * :data:`BELOW_NORMAL_PRIORITY_CLASS`
-      * :data:`HIGH_PRIORITY_CLASS`
-      * :data:`IDLE_PRIORITY_CLASS`
-      * :data:`NORMAL_PRIORITY_CLASS`
-      * :data:`REALTIME_PRIORITY_CLASS`
-      * :data:`CREATE_NO_WINDOW`
-      * :data:`DETACHED_PROCESS`
-      * :data:`CREATE_DEFAULT_ERROR_MODE`
-      * :data:`CREATE_BREAKAWAY_FROM_JOB`
+   * :data:`CREATE_NEW_CONSOLE`
+   * :data:`CREATE_NEW_PROCESS_GROUP`
+   * :data:`ABOVE_NORMAL_PRIORITY_CLASS`
+   * :data:`BELOW_NORMAL_PRIORITY_CLASS`
+   * :data:`HIGH_PRIORITY_CLASS`
+   * :data:`IDLE_PRIORITY_CLASS`
+   * :data:`NORMAL_PRIORITY_CLASS`
+   * :data:`REALTIME_PRIORITY_CLASS`
+   * :data:`CREATE_NO_WINDOW`
+   * :data:`DETACHED_PROCESS`
+   * :data:`CREATE_DEFAULT_ERROR_MODE`
+   * :data:`CREATE_BREAKAWAY_FROM_JOB`
 
    *pipesize* can be used to change the size of the pipe when
    :data:`PIPE` is used for *stdin*, *stdout* or *stderr*. The size of the pipe
@@ -742,8 +742,8 @@ the timeout expires before the process exits.
 
 Exceptions defined in this module all inherit from :exc:`SubprocessError`.
 
-   .. versionadded:: 3.3
-      The :exc:`SubprocessError` base class was added.
+.. versionadded:: 3.3
+   The :exc:`SubprocessError` base class was added.
 
 .. _subprocess-security:
 
diff --git a/Doc/library/sys.monitoring.rst b/Doc/library/sys.monitoring.rst
index 7b02b95fd7..f2fe3d7624 100644
--- a/Doc/library/sys.monitoring.rst
+++ b/Doc/library/sys.monitoring.rst
@@ -1,14 +1,16 @@
 :mod:`sys.monitoring` --- Execution event monitoring
 ====================================================
 
-..  module:: sys.monitoring
-    :synopsis: Access and control event monitoring
+.. module:: sys.monitoring
+   :synopsis: Access and control event monitoring
+
+.. versionadded:: 3.12
 
 -----------------
 
 .. note::
 
-    ``sys.monitoring`` is a namespace within the ``sys`` module,
+    :mod:`sys.monitoring` is a namespace within the :mod:`sys` module,
     not an independent module, so there is no need to
     ``import sys.monitoring``, simply ``import sys`` and then use
     ``sys.monitoring``.
@@ -18,45 +20,45 @@ This namespace provides access to the functions and constants necessary to
 activate and control event monitoring.
 
 As programs execute, events occur that might be of interest to tools that
-monitor execution. The :mod:`!sys.monitoring` namespace provides means to
+monitor execution. The :mod:`sys.monitoring` namespace provides means to
 receive callbacks when events of interest occur.
 
 The monitoring API consists of three components:
 
-* Tool identifiers
-* Events
-* Callbacks
+* `Tool identifiers`_
+* `Events`_
+* :ref:`Callbacks <callbacks>`
 
 Tool identifiers
 ----------------
 
-A tool identifier is an integer and associated name.
+A tool identifier is an integer and the associated name.
 Tool identifiers are used to discourage tools from interfering with each
 other and to allow multiple tools to operate at the same time.
 Currently tools are completely independent and cannot be used to
 monitor each other. This restriction may be lifted in the future.
 
 Before registering or activating events, a tool should choose an identifier.
-Identifiers are integers in the range 0 to 5.
+Identifiers are integers in the range 0 to 5 inclusive.
 
 Registering and using tools
 '''''''''''''''''''''''''''
 
-.. function:: use_tool_id(id: int, name: str) -> None
+.. function:: use_tool_id(tool_id: int, name: str, /) -> None
 
-   Must be called before ``id`` can be used.
-   ``id`` must be in the range 0 to 5 inclusive.
-   Raises a ``ValueError`` if ``id`` is in use.
+   Must be called before *tool_id* can be used.
+   *tool_id* must be in the range 0 to 5 inclusive.
+   Raises a :exc:`ValueError` if *tool_id* is in use.
 
-.. function:: free_tool_id(id: int) -> None
+.. function:: free_tool_id(tool_id: int, /) -> None
 
-   Should be called once a tool no longer requires ``id``.
+   Should be called once a tool no longer requires *tool_id*.
 
-.. function:: get_tool(id: int) -> str | None
+.. function:: get_tool(tool_id: int, /) -> str | None
 
-   Returns the name of the tool if ``id`` is in use,
+   Returns the name of the tool if *tool_id* is in use,
    otherwise it returns ``None``.
-   ``id`` must be in the range 0 to 5 inclusive.
+   *tool_id* must be in the range 0 to 5 inclusive.
 
 All IDs are treated the same by the VM with regard to events, but the
 following IDs are pre-defined to make co-operation of tools easier::
@@ -75,48 +77,89 @@ Events
 
 The following events are supported:
 
-BRANCH
-  A conditional branch is taken (or not).
-CALL
-  A call in Python code (event occurs before the call).
-C_RAISE
-  Exception raised from any callable, except Python functions (event occurs after the exit).
-C_RETURN
-  Return from any callable, except Python functions (event occurs after the return).
-EXCEPTION_HANDLED
-  An exception is handled.
-INSTRUCTION
-  A VM instruction is about to be executed.
-JUMP
-  An unconditional jump in the control flow graph is made.
-LINE
-  An instruction is about to be executed that has a different line number from the preceding instruction.
-PY_RESUME
-  Resumption of a Python function (for generator and coroutine functions), except for throw() calls.
-PY_RETURN
-  Return from a Python function (occurs immediately before the return, the callee's frame will be on the stack).
-PY_START
-  Start of a Python function (occurs immediately after the call, the callee's frame will be on the stack)
-PY_THROW
-  A Python function is resumed by a throw() call.
-PY_UNWIND
-  Exit from a Python function during exception unwinding.
-PY_YIELD
-  Yield from a Python function (occurs immediately before the yield, the callee's frame will be on the stack).
-RAISE
-  An exception is raised, except those that cause a ``STOP_ITERATION`` event.
-RERAISE
-  An exception is re-raised, for example at the end of a ``finally`` block.
-STOP_ITERATION
-  An artificial ``StopIteration`` is raised; see `the STOP_ITERATION event`_.
+.. monitoring-event:: BRANCH
+
+   A conditional branch is taken (or not).
+
+.. monitoring-event:: CALL
+
+   A call in Python code (event occurs before the call).
+
+.. monitoring-event:: C_RAISE
+
+   An exception raised from any callable, except for Python functions (event occurs after the exit).
+
+.. monitoring-event:: C_RETURN
+
+   Return from any callable, except for Python functions (event occurs after the return).
+
+.. monitoring-event:: EXCEPTION_HANDLED
+
+   An exception is handled.
+
+.. monitoring-event:: INSTRUCTION
+
+   A VM instruction is about to be executed.
+
+.. monitoring-event:: JUMP
+
+   An unconditional jump in the control flow graph is made.
+
+.. monitoring-event:: LINE
+
+   An instruction is about to be executed that has a different line number from the preceding instruction.
+
+.. monitoring-event:: PY_RESUME
+
+   Resumption of a Python function (for generator and coroutine functions), except for ``throw()`` calls.
+
+.. monitoring-event:: PY_RETURN
+
+   Return from a Python function (occurs immediately before the return, the callee's frame will be on the stack).
+
+.. monitoring-event:: PY_START
+
+   Start of a Python function (occurs immediately after the call, the callee's frame will be on the stack)
+
+.. monitoring-event:: PY_THROW
+
+   A Python function is resumed by a ``throw()`` call.
+
+.. monitoring-event:: PY_UNWIND
+
+   Exit from a Python function during exception unwinding.
+
+.. monitoring-event:: PY_YIELD
+
+   Yield from a Python function (occurs immediately before the yield, the callee's frame will be on the stack).
+
+.. monitoring-event:: RAISE
+
+   An exception is raised, except those that cause a :monitoring-event:`STOP_ITERATION` event.
+
+.. monitoring-event:: RERAISE
+
+   An exception is re-raised, for example at the end of a :keyword:`finally` block.
+
+.. monitoring-event:: STOP_ITERATION
+
+   An artificial :exc:`StopIteration` is raised; see `the STOP_ITERATION event`_.
+
 
 More events may be added in the future.
 
 These events are attributes of the :mod:`!sys.monitoring.events` namespace.
 Each event is represented as a power-of-2 integer constant.
 To define a set of events, simply bitwise or the individual events together.
-For example, to specify both ``PY_RETURN`` and ``PY_START`` events, use the
-expression ``PY_RETURN | PY_START``.
+For example, to specify both :monitoring-event:`PY_RETURN` and :monitoring-event:`PY_START`
+events, use the expression ``PY_RETURN | PY_START``.
+
+.. monitoring-event:: NO_EVENTS
+
+    An alias for ``0`` so users can do explict comparisions like::
+
+      if get_events(DEBUGGER_ID) == NO_EVENTS:
+          ...
 
 Events are divided into three groups:
 
@@ -127,16 +170,16 @@ Local events are associated with normal execution of the program and happen
 at clearly defined locations. All local events can be disabled.
 The local events are:
 
-* PY_START
-* PY_RESUME
-* PY_RETURN
-* PY_YIELD
-* CALL
-* LINE
-* INSTRUCTION
-* JUMP
-* BRANCH
-* STOP_ITERATION
+* :monitoring-event:`PY_START`
+* :monitoring-event:`PY_RESUME`
+* :monitoring-event:`PY_RETURN`
+* :monitoring-event:`PY_YIELD`
+* :monitoring-event:`CALL`
+* :monitoring-event:`LINE`
+* :monitoring-event:`INSTRUCTION`
+* :monitoring-event:`JUMP`
+* :monitoring-event:`BRANCH`
+* :monitoring-event:`STOP_ITERATION`
 
 Ancillary events
 ''''''''''''''''
@@ -144,12 +187,13 @@ Ancillary events
 Ancillary events can be monitored like other events, but are controlled
 by another event:
 
-* C_RAISE
-* C_RETURN
+* :monitoring-event:`C_RAISE`
+* :monitoring-event:`C_RETURN`
 
-The ``C_RETURN`` and ``C_RAISE`` events are are controlled by the ``CALL``
-event. ``C_RETURN`` and ``C_RAISE`` events will only be seen if the
-corresponding ``CALL`` event is being monitored.
+The :monitoring-event:`C_RETURN` and :monitoring-event:`C_RAISE` events
+are controlled by the :monitoring-event:`CALL` event.
+:monitoring-event:`C_RETURN` and :monitoring-event:`C_RAISE` events will only be seen if the
+corresponding :monitoring-event:`CALL` event is being monitored.
 
 Other events
 ''''''''''''
@@ -159,30 +203,31 @@ program and cannot be individually disabled.
 
 The other events that can be monitored are:
 
-* PY_THROW
-* PY_UNWIND
-* RAISE
-* EXCEPTION_HANDLED
+* :monitoring-event:`PY_THROW`
+* :monitoring-event:`PY_UNWIND`
+* :monitoring-event:`RAISE`
+* :monitoring-event:`EXCEPTION_HANDLED`
 
 
 The STOP_ITERATION event
 ''''''''''''''''''''''''
 
 :pep:`PEP 380 <380#use-of-stopiteration-to-return-values>`
-specifies that a ``StopIteration`` exception is raised when returning a value
+specifies that a :exc:`StopIteration` exception is raised when returning a value
 from a generator or coroutine. However, this is a very inefficient way to
 return a value, so some Python implementations, notably CPython 3.12+, do not
 raise an exception unless it would be visible to other code.
 
 To allow tools to monitor for real exceptions without slowing down generators
-and coroutines, the ``STOP_ITERATION`` event is provided.
-``STOP_ITERATION`` can be locally disabled, unlike ``RAISE``.
+and coroutines, the :monitoring-event:`STOP_ITERATION` event is provided.
+:monitoring-event:`STOP_ITERATION` can be locally disabled, unlike :monitoring-event:`RAISE`.
 
 
 Turning events on and off
 -------------------------
 
-In order to monitor an event, it must be turned on and a callback registered.
+In order to monitor an event, it must be turned on and a corresponding callback
+must be registered.
 Events can be turned on or off by setting the events either globally or
 for a particular code object.
 
@@ -192,14 +237,14 @@ Setting events globally
 
 Events can be controlled globally by modifying the set of events being monitored.
 
-.. function:: get_events(tool_id: int) -> int
+.. function:: get_events(tool_id: int, /) -> int
 
    Returns the ``int`` representing all the active events.
 
-.. function:: set_events(tool_id: int, event_set: int)
+.. function:: set_events(tool_id: int, event_set: int, /) -> None
 
-   Activates all events which are set in ``event_set``.
-   Raises a ``ValueError`` if ``tool_id`` is not in use.
+   Activates all events which are set in *event_set*.
+   Raises a :exc:`ValueError` if *tool_id* is not in use.
 
 No events are active by default.
 
@@ -208,14 +253,14 @@ Per code object events
 
 Events can also be controlled on a per code object basis.
 
-.. function:: get_local_events(tool_id: int, code: CodeType) -> int
+.. function:: get_local_events(tool_id: int, code: CodeType, /) -> int
 
-   Returns all the local events for ``code``
+   Returns all the local events for *code*
 
-.. function:: set_local_events(tool_id: int, code: CodeType, event_set: int)
+.. function:: set_local_events(tool_id: int, code: CodeType, event_set: int, /) -> None
 
-   Activates all the local events for ``code`` which are set in ``event_set``.
-   Raises a ``ValueError`` if ``tool_id`` is not in use.
+   Activates all the local events for *code* which are set in *event_set*.
+   Raises a :exc:`ValueError` if *tool_id* is not in use.
 
 Local events add to global events, but do not mask them.
 In other words, all global events will trigger for a code object,
@@ -225,8 +270,13 @@ regardless of the local events.
 Disabling events
 ''''''''''''''''
 
+.. data:: DISABLE
+
+   A special value that can be returned from a callback function to disable
+   events for the current code location.
+
 Local events can be disabled for a specific code location by returning
-``sys.monitoring.DISABLE`` from a callback function. This does not change
+:data:`sys.monitoring.DISABLE` from a callback function. This does not change
 which events are set, or any other code locations for the same event.
 
 Disabling events for specific locations is very important for high
@@ -234,19 +284,26 @@ performance monitoring. For example, a program can be run under a
 debugger with no overhead if the debugger disables all monitoring
 except for a few breakpoints.
 
+.. function:: restart_events() -> None
+
+   Enable all the events that were disabled by :data:`sys.monitoring.DISABLE`
+   for all tools.
+
+
+.. _callbacks:
 
 Registering callback functions
 ------------------------------
 
 To register a callable for events call
 
-.. function:: register_callback(tool_id: int, event: int, func: Callable | None) -> Callable | None
+.. function:: register_callback(tool_id: int, event: int, func: Callable | None, /) -> Callable | None
 
-   Registers the callable ``func`` for the ``event`` with the given ``tool_id``
+   Registers the callable *func* for the *event* with the given *tool_id*
 
-   If another callback was registered for the given ``tool_id`` and ``event``,
+   If another callback was registered for the given *tool_id* and *event*,
    it is unregistered and returned.
-   Otherwise ``register_callback`` returns ``None``.
+   Otherwise :func:`register_callback` returns ``None``.
 
 
 Functions can be unregistered by calling
@@ -254,47 +311,51 @@ Functions can be unregistered by calling
 
 Callback functions can be registered and unregistered at any time.
 
-Registering or unregistering a callback function will generate a ``sys.audit`` event.
+Registering or unregistering a callback function will generate a :func:`sys.audit` event.
 
 
 Callback function arguments
 '''''''''''''''''''''''''''
 
+.. data:: MISSING
+
+   A special value that is passed to a callback function to indicate
+   that there are no arguments to the call.
+
 When an active event occurs, the registered callback function is called.
 Different events will provide the callback function with different arguments, as follows:
 
-* ``PY_START`` and ``PY_RESUME``::
+* :monitoring-event:`PY_START` and :monitoring-event:`PY_RESUME`::
 
     func(code: CodeType, instruction_offset: int) -> DISABLE | Any
 
-* ``PY_RETURN`` and ``PY_YIELD``:
+* :monitoring-event:`PY_RETURN` and :monitoring-event:`PY_YIELD`::
 
-    ``func(code: CodeType, instruction_offset: int, retval: object) -> DISABLE | Any``
+    func(code: CodeType, instruction_offset: int, retval: object) -> DISABLE | Any
 
-* ``CALL``, ``C_RAISE`` and ``C_RETURN``:
+* :monitoring-event:`CALL`, :monitoring-event:`C_RAISE` and :monitoring-event:`C_RETURN`::
 
-    ``func(code: CodeType, instruction_offset: int, callable: object, arg0: object | MISSING) -> DISABLE | Any``
+    func(code: CodeType, instruction_offset: int, callable: object, arg0: object | MISSING) -> DISABLE | Any
 
-    If there are no arguments, ``arg0`` is set to ``MISSING``.
+  If there are no arguments, *arg0* is set to :data:`sys.monitoring.MISSING`.
 
-* ``RAISE``, ``RERAISE``, ``EXCEPTION_HANDLED``, ``PY_UNWIND``, ``PY_THROW`` and ``STOP_ITERATION``:
+* :monitoring-event:`RAISE`, :monitoring-event:`RERAISE`, :monitoring-event:`EXCEPTION_HANDLED`,
+  :monitoring-event:`PY_UNWIND`, :monitoring-event:`PY_THROW` and :monitoring-event:`STOP_ITERATION`::
 
-    ``func(code: CodeType, instruction_offset: int, exception: BaseException) -> DISABLE | Any``
+    func(code: CodeType, instruction_offset: int, exception: BaseException) -> DISABLE | Any
 
-* ``LINE``:
+* :monitoring-event:`LINE`::
 
-    ``func(code: CodeType, line_number: int) -> DISABLE | Any``
+    func(code: CodeType, line_number: int) -> DISABLE | Any
 
-* ``BRANCH`` and ``JUMP``:
+* :monitoring-event:`BRANCH` and :monitoring-event:`JUMP`::
 
-    ``func(code: CodeType, instruction_offset: int, destination_offset: int) -> DISABLE | Any``
+    func(code: CodeType, instruction_offset: int, destination_offset: int) -> DISABLE | Any
 
-  Note that the ``destination_offset`` is where the code will next execute.
+  Note that the *destination_offset* is where the code will next execute.
   For an untaken branch this will be the offset of the instruction following
   the branch.
 
-* ``INSTRUCTION``:
-
-    ``func(code: CodeType, instruction_offset: int) -> DISABLE | Any``
-
+* :monitoring-event:`INSTRUCTION`::
 
+    func(code: CodeType, instruction_offset: int) -> DISABLE | Any
diff --git a/Doc/library/sys.rst b/Doc/library/sys.rst
index 6fb4c0f1c5..b4666d99b8 100644
--- a/Doc/library/sys.rst
+++ b/Doc/library/sys.rst
@@ -173,7 +173,11 @@ always available.
 
    Call ``func(*args)``, while tracing is enabled.  The tracing state is saved,
    and restored afterwards.  This is intended to be called from a debugger from
-   a checkpoint, to recursively debug some other code.
+   a checkpoint, to recursively debug or profile some other code.
+
+   Tracing is suspended while calling a tracing function set by
+   :func:`settrace` or :func:`setprofile` to avoid infinite recursion.
+   :func:`!call_tracing` enables explicit recursion of the tracing function.
 
 
 .. data:: copyright
@@ -1471,13 +1475,16 @@ always available.
    its return value is not used, so it can simply return ``None``.  Error in the profile
    function will cause itself unset.
 
+   .. note::
+      The same tracing mechanism is used for :func:`!setprofile` as :func:`settrace`.
+      To trace calls with :func:`!setprofile` inside a tracing function
+      (e.g. in a debugger breakpoint), see :func:`call_tracing`.
+
    Profile functions should have three arguments: *frame*, *event*, and
    *arg*. *frame* is the current stack frame.  *event* is a string: ``'call'``,
    ``'return'``, ``'c_call'``, ``'c_return'``, or ``'c_exception'``. *arg* depends
    on the event type.
 
-   .. audit-event:: sys.setprofile "" sys.setprofile
-
    The events have the following meaning:
 
    ``'call'``
@@ -1499,6 +1506,9 @@ always available.
    ``'c_exception'``
       A C function has raised an exception.  *arg* is the C function object.
 
+   .. audit-event:: sys.setprofile "" sys.setprofile
+
+
 .. function:: setrecursionlimit(limit)
 
    Set the maximum depth of the Python interpreter stack to *limit*.  This limit
@@ -1552,13 +1562,16 @@ always available.
    function to be used for the new scope, or ``None`` if the scope shouldn't be
    traced.
 
-   The local trace function should return a reference to itself (or to another
-   function for further tracing in that scope), or ``None`` to turn off tracing
-   in that scope.
+   The local trace function should return a reference to itself, or to another
+   function which would then be used as the local trace function for the scope.
 
    If there is any error occurred in the trace function, it will be unset, just
    like ``settrace(None)`` is called.
 
+   .. note::
+      Tracing is disabled while calling the trace function (e.g. a function set by
+      :func:`!settrace`). For recursive tracing see :func:`call_tracing`.
+
    The events have the following meaning:
 
    ``'call'``
@@ -1779,7 +1792,7 @@ always available.
       However, if you are writing a library (and do not control in which
       context its code will be executed), be aware that the standard streams
       may be replaced with file-like objects like :class:`io.StringIO` which
-      do not support the :attr:!buffer` attribute.
+      do not support the :attr:`!buffer` attribute.
 
 
 .. data:: __stdin__
diff --git a/Doc/library/sysconfig.rst b/Doc/library/sysconfig.rst
index e5ed45b852..905abc3a7c 100644
--- a/Doc/library/sysconfig.rst
+++ b/Doc/library/sysconfig.rst
@@ -427,6 +427,7 @@ Other functions
 
    Return the path of :file:`Makefile`.
 
+.. _sysconfig-cli:
 
 Using :mod:`sysconfig` as a script
 ----------------------------------
diff --git a/Doc/library/syslog.rst b/Doc/library/syslog.rst
index f29ef03267..b5ab446e00 100644
--- a/Doc/library/syslog.rst
+++ b/Doc/library/syslog.rst
@@ -11,12 +11,12 @@ This module provides an interface to the Unix ``syslog`` library routines.
 Refer to the Unix manual pages for a detailed description of the ``syslog``
 facility.
 
+.. availability:: Unix, not Emscripten, not WASI.
+
 This module wraps the system ``syslog`` family of routines.  A pure Python
 library that can speak to a syslog server is available in the
 :mod:`logging.handlers` module as :class:`SysLogHandler`.
 
-.. include:: ../includes/wasm-notavail.rst
-
 The module defines the following functions:
 
 
diff --git a/Doc/library/tarfile.rst b/Doc/library/tarfile.rst
index 574ea337e7..68b2091aa2 100644
--- a/Doc/library/tarfile.rst
+++ b/Doc/library/tarfile.rst
@@ -1151,31 +1151,31 @@ For a list of the files in a tar archive, use the :option:`-l` option:
 Command-line options
 ~~~~~~~~~~~~~~~~~~~~
 
-.. cmdoption:: -l <tarfile>
-               --list <tarfile>
+.. option:: -l <tarfile>
+            --list <tarfile>
 
    List files in a tarfile.
 
-.. cmdoption:: -c <tarfile> <source1> ... <sourceN>
-               --create <tarfile> <source1> ... <sourceN>
+.. option:: -c <tarfile> <source1> ... <sourceN>
+            --create <tarfile> <source1> ... <sourceN>
 
    Create tarfile from source files.
 
-.. cmdoption:: -e <tarfile> [<output_dir>]
-               --extract <tarfile> [<output_dir>]
+.. option:: -e <tarfile> [<output_dir>]
+            --extract <tarfile> [<output_dir>]
 
    Extract tarfile into the current directory if *output_dir* is not specified.
 
-.. cmdoption:: -t <tarfile>
-               --test <tarfile>
+.. option:: -t <tarfile>
+            --test <tarfile>
 
    Test whether the tarfile is valid or not.
 
-.. cmdoption:: -v, --verbose
+.. option:: -v, --verbose
 
    Verbose output.
 
-.. cmdoption:: --filter <filtername>
+.. option:: --filter <filtername>
 
    Specifies the *filter* for ``--extract``.
    See :ref:`tarfile-extraction-filter` for details.
diff --git a/Doc/library/tempfile.rst b/Doc/library/tempfile.rst
index 097f7087ec..b68a78e826 100644
--- a/Doc/library/tempfile.rst
+++ b/Doc/library/tempfile.rst
@@ -115,14 +115,14 @@ The module defines the following user-callable items:
    * On Windows, make sure that at least one of the following conditions are
      fulfilled:
 
-         * *delete* is false
-         * additional open shares delete access (e.g. by calling :func:`os.open`
-           with the flag ``O_TEMPORARY``)
-         * *delete* is true but *delete_on_close* is false. Note, that in this
-           case the additional opens that do not share delete access (e.g.
-           created via builtin :func:`open`) must be closed before exiting the
-           context manager, else the :func:`os.unlink` call on context manager
-           exit will fail with a :exc:`PermissionError`.
+     * *delete* is false
+     * additional open shares delete access (e.g. by calling :func:`os.open`
+       with the flag ``O_TEMPORARY``)
+     * *delete* is true but *delete_on_close* is false. Note, that in this
+       case the additional opens that do not share delete access (e.g.
+       created via builtin :func:`open`) must be closed before exiting the
+       context manager, else the :func:`os.unlink` call on context manager
+       exit will fail with a :exc:`PermissionError`.
 
    On Windows, if *delete_on_close* is false, and the file is created in a
    directory for which the user lacks delete access, then the :func:`os.unlink`
@@ -147,7 +147,7 @@ The module defines the following user-callable items:
 
    This class operates exactly as :func:`TemporaryFile` does, except that
    data is spooled in memory until the file size exceeds *max_size*, or
-   until the file's :func:`fileno` method is called, at which point the
+   until the file's :func:`~io.IOBase.fileno` method is called, at which point the
    contents are written to disk and operation proceeds as with
    :func:`TemporaryFile`.
 
@@ -404,13 +404,13 @@ Here are some examples of typical usage of the :mod:`tempfile` module::
 
     # create a temporary file using a context manager
     # close the file, use the name to open the file again
-    >>> with tempfile.TemporaryFile(delete_on_close=False) as fp:
-    ...    fp.write(b'Hello world!')
-    ...    fp.close()
-    # the file is closed, but not removed
-    # open the file again by using its name
-    ...    with open(fp.name) as f
-    ...        f.read()
+    >>> with tempfile.NamedTemporaryFile(delete_on_close=False) as fp:
+    ...     fp.write(b'Hello world!')
+    ...     fp.close()
+    ... # the file is closed, but not removed
+    ... # open the file again by using its name
+    ...     with open(fp.name, mode='rb') as f:
+    ...         f.read()
     b'Hello world!'
     >>>
     # file is now removed
diff --git a/Doc/library/termios.rst b/Doc/library/termios.rst
index fb1ff567d4..57705ddc4e 100644
--- a/Doc/library/termios.rst
+++ b/Doc/library/termios.rst
@@ -16,6 +16,8 @@ complete description of these calls, see :manpage:`termios(3)` Unix manual
 page.  It is only available for those Unix versions that support POSIX
 *termios* style tty I/O control configured during installation.
 
+.. availability:: Unix.
+
 All functions in this module take a file descriptor *fd* as their first
 argument.  This can be an integer file descriptor, such as returned by
 ``sys.stdin.fileno()``, or a :term:`file object`, such as ``sys.stdin`` itself.
@@ -43,10 +45,20 @@ The module defines the following functions:
 
    Set the tty attributes for file descriptor *fd* from the *attributes*, which is
    a list like the one returned by :func:`tcgetattr`.  The *when* argument
-   determines when the attributes are changed: :const:`TCSANOW` to change
-   immediately, :const:`TCSADRAIN` to change after transmitting all queued output,
-   or :const:`TCSAFLUSH` to change after transmitting all queued output and
-   discarding all queued input.
+   determines when the attributes are changed:
+
+   .. data:: TCSANOW
+
+      Change attributes immediately.
+
+   .. data:: TCSADRAIN
+
+      Change attributes after transmitting all queued output.
+
+   .. data:: TCSAFLUSH
+
+      Change attributes after transmitting all queued output and
+      discarding all queued input.
 
 
 .. function:: tcsendbreak(fd, duration)
diff --git a/Doc/library/test.rst b/Doc/library/test.rst
index de60151bb3..7a8d38685b 100644
--- a/Doc/library/test.rst
+++ b/Doc/library/test.rst
@@ -498,44 +498,6 @@ The :mod:`test.support` module defines the following functions:
    rather than looking directly in the path directories.
 
 
-.. function:: match_test(test)
-
-   Determine whether *test* matches the patterns set in :func:`set_match_tests`.
-
-
-.. function:: set_match_tests(accept_patterns=None, ignore_patterns=None)
-
-   Define match patterns on test filenames and test method names for filtering tests.
-
-
-.. function:: run_unittest(*classes)
-
-   Execute :class:`unittest.TestCase` subclasses passed to the function. The
-   function scans the classes for methods starting with the prefix ``test_``
-   and executes the tests individually.
-
-   It is also legal to pass strings as parameters; these should be keys in
-   ``sys.modules``. Each associated module will be scanned by
-   ``unittest.TestLoader.loadTestsFromModule()``. This is usually seen in the
-   following :func:`test_main` function::
-
-      def test_main():
-          support.run_unittest(__name__)
-
-   This will run all tests defined in the named module.
-
-
-.. function:: run_doctest(module, verbosity=None, optionflags=0)
-
-   Run :func:`doctest.testmod` on the given *module*.  Return
-   ``(failure_count, test_count)``.
-
-   If *verbosity* is ``None``, :func:`doctest.testmod` is run with verbosity
-   set to :data:`verbose`.  Otherwise, it is run with verbosity set to
-   ``None``.  *optionflags* is passed as ``optionflags`` to
-   :func:`doctest.testmod`.
-
-
 .. function:: get_pagesize()
 
    Get size of a page in bytes.
@@ -1043,7 +1005,7 @@ The :mod:`test.support` module defines the following classes:
    :const:`resource.RLIMIT_CORE`'s soft limit to 0 to prevent coredump file
    creation.
 
-   On both platforms, the old value is restored by :meth:`__exit__`.
+   On both platforms, the old value is restored by :meth:`~object.__exit__`.
 
 
 .. class:: SaveSignals()
diff --git a/Doc/library/textwrap.rst b/Doc/library/textwrap.rst
index e2952ce3cc..7445410f91 100644
--- a/Doc/library/textwrap.rst
+++ b/Doc/library/textwrap.rst
@@ -238,7 +238,7 @@ hyphenated words; only then will long words be broken if necessary, unless
       However, the sentence detection algorithm is imperfect: it assumes that a
       sentence ending consists of a lowercase letter followed by one of ``'.'``,
       ``'!'``, or ``'?'``, possibly followed by one of ``'"'`` or ``"'"``,
-      followed by a space.  One problem with this is algorithm is that it is
+      followed by a space.  One problem with this algorithm is that it is
       unable to detect the difference between "Dr." in ::
 
          [...] Dr. Frankenstein's monster [...]
diff --git a/Doc/library/time.rst b/Doc/library/time.rst
index 9f23a6fc7d..93eceed29d 100644
--- a/Doc/library/time.rst
+++ b/Doc/library/time.rst
@@ -71,8 +71,8 @@ An explanation of some terminology and conventions is in order.
 * On the other hand, the precision of :func:`.time` and :func:`sleep` is better
   than their Unix equivalents: times are expressed as floating point numbers,
   :func:`.time` returns the most accurate time available (using Unix
-  :c:func:`gettimeofday` where available), and :func:`sleep` will accept a time
-  with a nonzero fraction (Unix :c:func:`select` is used to implement this, where
+  :c:func:`!gettimeofday` where available), and :func:`sleep` will accept a time
+  with a nonzero fraction (Unix :c:func:`!select` is used to implement this, where
   available).
 
 * The time value as returned by :func:`gmtime`, :func:`localtime`, and
@@ -84,12 +84,14 @@ An explanation of some terminology and conventions is in order.
   See :class:`struct_time` for a description of these objects.
 
   .. versionchanged:: 3.3
-     The :class:`struct_time` type was extended to provide the :attr:`tm_gmtoff`
-     and :attr:`tm_zone` attributes when platform supports corresponding
+     The :class:`struct_time` type was extended to provide
+     the :attr:`~struct_time.tm_gmtoff` and :attr:`~struct_time.tm_zone`
+     attributes when platform supports corresponding
      ``struct tm`` members.
 
   .. versionchanged:: 3.6
-     The :class:`struct_time` attributes :attr:`tm_gmtoff` and :attr:`tm_zone`
+     The :class:`struct_time` attributes
+     :attr:`~struct_time.tm_gmtoff` and :attr:`~struct_time.tm_zone`
      are now available on all platforms.
 
 * Use the following functions to convert between time representations:
@@ -496,6 +498,8 @@ Functions
       When used with the :func:`strptime` function, the ``%p`` directive only affects
       the output hour field if the ``%I`` directive is used to parse the hour.
 
+   .. _leap-second:
+
    (2)
       The range really is ``0`` to ``61``; value ``60`` is valid in
       timestamps representing `leap seconds`_ and value ``61`` is supported
@@ -566,32 +570,55 @@ Functions
    tuple` interface: values can be accessed by index and by attribute name.  The
    following values are present:
 
-   +-------+-------------------+---------------------------------+
-   | Index | Attribute         | Values                          |
-   +=======+===================+=================================+
-   | 0     | :attr:`tm_year`   | (for example, 1993)             |
-   +-------+-------------------+---------------------------------+
-   | 1     | :attr:`tm_mon`    | range [1, 12]                   |
-   +-------+-------------------+---------------------------------+
-   | 2     | :attr:`tm_mday`   | range [1, 31]                   |
-   +-------+-------------------+---------------------------------+
-   | 3     | :attr:`tm_hour`   | range [0, 23]                   |
-   +-------+-------------------+---------------------------------+
-   | 4     | :attr:`tm_min`    | range [0, 59]                   |
-   +-------+-------------------+---------------------------------+
-   | 5     | :attr:`tm_sec`    | range [0, 61]; see **(2)** in   |
-   |       |                   | :func:`strftime` description    |
-   +-------+-------------------+---------------------------------+
-   | 6     | :attr:`tm_wday`   | range [0, 6], Monday is 0       |
-   +-------+-------------------+---------------------------------+
-   | 7     | :attr:`tm_yday`   | range [1, 366]                  |
-   +-------+-------------------+---------------------------------+
-   | 8     | :attr:`tm_isdst`  | 0, 1 or -1; see below           |
-   +-------+-------------------+---------------------------------+
-   | N/A   | :attr:`tm_zone`   | abbreviation of timezone name   |
-   +-------+-------------------+---------------------------------+
-   | N/A   | :attr:`tm_gmtoff` | offset east of UTC in seconds   |
-   +-------+-------------------+---------------------------------+
+   .. list-table::
+
+      * - Index
+        - Attribute
+        - Values
+
+      * - 0
+        - .. attribute:: tm_year
+        - (for example, 1993)
+
+      * - 1
+        - .. attribute:: tm_mon
+        - range [1, 12]
+
+      * - 2
+        - .. attribute:: tm_day
+        - range [1, 31]
+
+      * - 3
+        - .. attribute:: tm_hour
+        - range [0, 23]
+
+      * - 4
+        - .. attribute:: tm_min
+        - range [0, 59]
+
+      * - 5
+        - .. attribute:: tm_sec
+        - range [0, 61]; see :ref:`Note (2) <leap-second>` in :func:`strftime`
+
+      * - 6
+        - .. attribute:: tm_wday
+        - range [0, 6]; Monday is 0
+
+      * - 7
+        - .. attribute:: tm_yday
+        - range [1, 366]
+
+      * - 8
+        - .. attribute:: tm_isdst
+        - 0, 1 or -1; see below
+
+      * - N/A
+        - .. attribute:: tm_zone
+        - abbreviation of timezone name
+
+      * - N/A
+        - .. attribute:: tm_gmtoff
+        - offset east of UTC in seconds
 
    Note that unlike the C structure, the month value is a range of [1, 12], not
    [0, 11].
@@ -912,8 +939,8 @@ Timezone Constants
    For the above Timezone constants (:data:`altzone`, :data:`daylight`, :data:`timezone`,
    and :data:`tzname`), the value is determined by the timezone rules in effect
    at module load time or the last time :func:`tzset` is called and may be incorrect
-   for times in the past.  It is recommended to use the :attr:`tm_gmtoff` and
-   :attr:`tm_zone` results from :func:`localtime` to obtain timezone information.
+   for times in the past.  It is recommended to use the :attr:`~struct_time.tm_gmtoff` and
+   :attr:`~struct_time.tm_zone` results from :func:`localtime` to obtain timezone information.
 
 
 .. seealso::
diff --git a/Doc/library/timeit.rst b/Doc/library/timeit.rst
index b3d2a1b9e0..616f8365b8 100644
--- a/Doc/library/timeit.rst
+++ b/Doc/library/timeit.rst
@@ -151,7 +151,7 @@ The module defines three convenience functions and a public class:
       so that the total time >= 0.2 second, returning the eventual
       (number of loops, time taken for that number of loops). It calls
       :meth:`.timeit` with increasing numbers from the sequence 1, 2, 5,
-      10, 20, 50, ... until the time taken is at least 0.2 second.
+      10, 20, 50, ... until the time taken is at least 0.2 seconds.
 
       If *callback* is given and is not ``None``, it will be called after
       each trial with two arguments: ``callback(number, time_taken)``.
@@ -214,36 +214,36 @@ Where the following options are understood:
 
 .. program:: timeit
 
-.. cmdoption:: -n N, --number=N
+.. option:: -n N, --number=N
 
    how many times to execute 'statement'
 
-.. cmdoption:: -r N, --repeat=N
+.. option:: -r N, --repeat=N
 
    how many times to repeat the timer (default 5)
 
-.. cmdoption:: -s S, --setup=S
+.. option:: -s S, --setup=S
 
    statement to be executed once initially (default ``pass``)
 
-.. cmdoption:: -p, --process
+.. option:: -p, --process
 
    measure process time, not wallclock time, using :func:`time.process_time`
    instead of :func:`time.perf_counter`, which is the default
 
    .. versionadded:: 3.3
 
-.. cmdoption:: -u, --unit=U
+.. option:: -u, --unit=U
 
    specify a time unit for timer output; can select ``nsec``, ``usec``, ``msec``, or ``sec``
 
    .. versionadded:: 3.5
 
-.. cmdoption:: -v, --verbose
+.. option:: -v, --verbose
 
    print raw timing results; repeat for more digits precision
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    print a short usage message and exit
 
diff --git a/Doc/library/tkinter.messagebox.rst b/Doc/library/tkinter.messagebox.rst
index 56c1d6c132..56090a0a0e 100644
--- a/Doc/library/tkinter.messagebox.rst
+++ b/Doc/library/tkinter.messagebox.rst
@@ -11,7 +11,8 @@
 
 The :mod:`tkinter.messagebox` module provides a template base class as well as
 a variety of convenience methods for commonly used configurations. The message
-boxes are modal and will return a subset of (True, False, OK, None, Yes, No) based on
+boxes are modal and will return a subset of (``True``, ``False``, ``None``,
+:data:`OK`, :data:`CANCEL`, :data:`YES`, :data:`NO`) based on
 the user's selection. Common message box styles and layouts include but are not
 limited to:
 
@@ -19,21 +20,175 @@ limited to:
 
 .. class:: Message(master=None, **options)
 
-   Create a default information message box.
+   Create a message window with an application-specified message, an icon
+   and a set of buttons.
+   Each of the buttons in the message window is identified by a unique symbolic name (see the *type* options).
+
+   The following options are supported:
+
+      *command*
+         Specifies the function to invoke when the user closes the dialog.
+         The name of the button clicked by the user to close the dialog is
+         passed as argument.
+         This is only available on macOS.
+
+      *default*
+         Gives the :ref:`symbolic name <messagebox-buttons>` of the default button
+         for this message window (:data:`OK`, :data:`CANCEL`, and so on).
+         If this option is not specified, the first button in the dialog will
+         be made the default.
+
+      *detail*
+         Specifies an auxiliary message to the main message given by the
+         *message* option.
+         The message detail will be presented beneath the main message and,
+         where supported by the OS, in a less emphasized font than the main
+         message.
+
+      *icon*
+         Specifies an :ref:`icon <messagebox-icons>` to display.
+         If this option is not specified, then the :data:`INFO` icon will be
+         displayed.
+
+      *message*
+         Specifies the message to display in this message box.
+         The default value is an empty string.
+
+      *parent*
+         Makes the specified window the logical parent of the message box.
+         The message box is displayed on top of its parent window.
+
+      *title*
+         Specifies a string to display as the title of the message box.
+         This option is ignored on macOS, where platform guidelines forbid
+         the use of a title on this kind of dialog.
+
+      *type*
+         Arranges for a :ref:`predefined set of buttons <messagebox-types>`
+         to be displayed.
+
+   .. method:: show(**options)
+
+      Display a message window and wait for the user to select one of the buttons. Then return the symbolic name of the selected button.
+      Keyword arguments can override options specified in the constructor.
+
 
 **Information message box**
 
-.. method:: showinfo(title=None, message=None, **options)
+.. function:: showinfo(title=None, message=None, **options)
+
+   Creates and displays an information message box with the specified title
+   and message.
 
 **Warning message boxes**
 
-.. method:: showwarning(title=None, message=None, **options)
-            showerror(title=None, message=None, **options)
+.. function:: showwarning(title=None, message=None, **options)
+
+   Creates and displays a warning message box with the specified title
+   and message.
+
+.. function:: showerror(title=None, message=None, **options)
+
+   Creates and displays an error message box with the specified title
+   and message.
 
 **Question message boxes**
 
-.. method:: askquestion(title=None, message=None, **options)
-            askokcancel(title=None, message=None, **options)
-            askretrycancel(title=None, message=None, **options)
-            askyesno(title=None, message=None, **options)
-            askyesnocancel(title=None, message=None, **options)
+.. function:: askquestion(title=None, message=None, *, type=YESNO, **options)
+
+   Ask a question. By default shows buttons :data:`YES` and :data:`NO`.
+   Returns the symbolic name of the selected button.
+
+.. function:: askokcancel(title=None, message=None, **options)
+
+   Ask if operation should proceed. Shows buttons :data:`OK` and :data:`CANCEL`.
+   Returns ``True`` if the answer is ok and ``False`` otherwise.
+
+.. function:: askretrycancel(title=None, message=None, **options)
+
+   Ask if operation should be retried. Shows buttons :data:`RETRY` and :data:`CANCEL`.
+   Return ``True`` if the answer is yes and ``False`` otherwise.
+
+.. function:: askyesno(title=None, message=None, **options)
+
+   Ask a question. Shows buttons :data:`YES` and :data:`NO`.
+   Returns ``True`` if the answer is yes and ``False`` otherwise.
+
+.. function:: askyesnocancel(title=None, message=None, **options)
+
+   Ask a question. Shows buttons :data:`YES`, :data:`NO` and :data:`CANCEL`.
+   Return ``True`` if the answer is yes, ``None`` if cancelled, and ``False``
+   otherwise.
+
+
+.. _messagebox-buttons:
+
+Symbolic names of buttons:
+
+.. data:: ABORT
+   :value: 'abort'
+.. data:: RETRY
+   :value: 'retry'
+.. data:: IGNORE
+   :value: 'ignore'
+.. data:: OK
+   :value: 'ok'
+.. data:: CANCEL
+   :value: 'cancel'
+.. data:: YES
+   :value: 'yes'
+.. data:: NO
+   :value: 'no'
+
+.. _messagebox-types:
+
+Predefined sets of buttons:
+
+.. data:: ABORTRETRYIGNORE
+   :value: 'abortretryignore'
+
+   Displays three buttons whose symbolic names are :data:`ABORT`,
+   :data:`RETRY` and :data:`IGNORE`.
+
+.. data:: OK
+   :value: 'ok'
+   :noindex:
+
+   Displays one button whose symbolic name is :data:`OK`.
+
+.. data:: OKCANCEL
+   :value: 'okcancel'
+
+   Displays two buttons whose symbolic names are :data:`OK` and
+   :data:`CANCEL`.
+
+.. data:: RETRYCANCEL
+   :value: 'retrycancel'
+
+   Displays two buttons whose symbolic names are :data:`RETRY` and
+   :data:`CANCEL`.
+
+.. data:: YESNO
+   :value: 'yesno'
+
+   Displays two buttons whose symbolic names are :data:`YES` and
+   :data:`NO`.
+
+.. data:: YESNOCANCEL
+   :value: 'yesnocancel'
+
+   Displays three buttons whose symbolic names are :data:`YES`,
+   :data:`NO` and :data:`CANCEL`.
+
+.. _messagebox-icons:
+
+Icon images:
+
+.. data:: ERROR
+   :value: 'error'
+.. data:: INFO
+   :value: 'info'
+.. data:: QUESTION
+   :value: 'question'
+.. data:: WARNING
+   :value: 'warning'
diff --git a/Doc/library/tkinter.rst b/Doc/library/tkinter.rst
index 246abf374b..ee34f2659c 100644
--- a/Doc/library/tkinter.rst
+++ b/Doc/library/tkinter.rst
@@ -533,24 +533,24 @@ interpreter will fail.
 
 A number of special cases exist:
 
-  * Tcl/Tk libraries can be built so they are not thread-aware. In this case,
-    :mod:`tkinter` calls the library from the originating Python thread, even
-    if this is different than the thread that created the Tcl interpreter. A global
-    lock ensures only one call occurs at a time.
-
-  * While :mod:`tkinter` allows you to create more than one instance of a :class:`Tk`
-    object (with its own interpreter), all interpreters that are part of the same
-    thread share a common event queue, which gets ugly fast. In practice, don't create
-    more than one instance of :class:`Tk` at a time. Otherwise, it's best to create
-    them in separate threads and ensure you're running a thread-aware Tcl/Tk build.
-
-  * Blocking event handlers are not the only way to prevent the Tcl interpreter from
-    reentering the event loop. It is even possible to run multiple nested event loops
-    or abandon the event loop entirely. If you're doing anything tricky when it comes
-    to events or threads, be aware of these possibilities.
-
-  * There are a few select :mod:`tkinter` functions that presently work only when
-    called from the thread that created the Tcl interpreter.
+* Tcl/Tk libraries can be built so they are not thread-aware. In this case,
+  :mod:`tkinter` calls the library from the originating Python thread, even
+  if this is different than the thread that created the Tcl interpreter. A global
+  lock ensures only one call occurs at a time.
+
+* While :mod:`tkinter` allows you to create more than one instance of a :class:`Tk`
+  object (with its own interpreter), all interpreters that are part of the same
+  thread share a common event queue, which gets ugly fast. In practice, don't create
+  more than one instance of :class:`Tk` at a time. Otherwise, it's best to create
+  them in separate threads and ensure you're running a thread-aware Tcl/Tk build.
+
+* Blocking event handlers are not the only way to prevent the Tcl interpreter from
+  reentering the event loop. It is even possible to run multiple nested event loops
+  or abandon the event loop entirely. If you're doing anything tricky when it comes
+  to events or threads, be aware of these possibilities.
+
+* There are a few select :mod:`tkinter` functions that presently work only when
+  called from the thread that created the Tcl interpreter.
 
 
 Handy Reference
diff --git a/Doc/library/tkinter.ttk.rst b/Doc/library/tkinter.ttk.rst
index 9f2f9eb858..dc31a1a4c1 100644
--- a/Doc/library/tkinter.ttk.rst
+++ b/Doc/library/tkinter.ttk.rst
@@ -104,33 +104,33 @@ Standard Options
 
 All the :mod:`ttk` Widgets accept the following options:
 
-   .. tabularcolumns:: |l|L|
-
-   +-----------+--------------------------------------------------------------+
-   | Option    | Description                                                  |
-   +===========+==============================================================+
-   | class     | Specifies the window class. The class is used when querying  |
-   |           | the option database for the window's other options, to       |
-   |           | determine the default bindtags for the window, and to select |
-   |           | the widget's default layout and style. This option is        |
-   |           | read-only, and may only be specified when the window is      |
-   |           | created.                                                     |
-   +-----------+--------------------------------------------------------------+
-   | cursor    | Specifies the mouse cursor to be used for the widget. If set |
-   |           | to the empty string (the default), the cursor is inherited   |
-   |           | for the parent widget.                                       |
-   +-----------+--------------------------------------------------------------+
-   | takefocus | Determines whether the window accepts the focus during       |
-   |           | keyboard traversal. 0, 1 or an empty string is returned.     |
-   |           | If 0 is returned, it means that the window should be skipped |
-   |           | entirely during keyboard traversal. If 1, it means that the  |
-   |           | window should receive the input focus as long as it is       |
-   |           | viewable. And an empty string means that the traversal       |
-   |           | scripts make the decision about whether or not to focus      |
-   |           | on the window.                                               |
-   +-----------+--------------------------------------------------------------+
-   | style     | May be used to specify a custom widget style.                |
-   +-----------+--------------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++-----------+--------------------------------------------------------------+
+| Option    | Description                                                  |
++===========+==============================================================+
+| class     | Specifies the window class. The class is used when querying  |
+|           | the option database for the window's other options, to       |
+|           | determine the default bindtags for the window, and to select |
+|           | the widget's default layout and style. This option is        |
+|           | read-only, and may only be specified when the window is      |
+|           | created.                                                     |
++-----------+--------------------------------------------------------------+
+| cursor    | Specifies the mouse cursor to be used for the widget. If set |
+|           | to the empty string (the default), the cursor is inherited   |
+|           | for the parent widget.                                       |
++-----------+--------------------------------------------------------------+
+| takefocus | Determines whether the window accepts the focus during       |
+|           | keyboard traversal. 0, 1 or an empty string is returned.     |
+|           | If 0 is returned, it means that the window should be skipped |
+|           | entirely during keyboard traversal. If 1, it means that the  |
+|           | window should receive the input focus as long as it is       |
+|           | viewable. And an empty string means that the traversal       |
+|           | scripts make the decision about whether or not to focus      |
+|           | on the window.                                               |
++-----------+--------------------------------------------------------------+
+| style     | May be used to specify a custom widget style.                |
++-----------+--------------------------------------------------------------+
 
 
 Scrollable Widget Options
@@ -139,24 +139,24 @@ Scrollable Widget Options
 The following options are supported by widgets that are controlled by a
 scrollbar.
 
-   .. tabularcolumns:: |l|L|
-
-   +----------------+---------------------------------------------------------+
-   | Option         | Description                                             |
-   +================+=========================================================+
-   | xscrollcommand | Used to communicate with horizontal scrollbars.         |
-   |                |                                                         |
-   |                | When the view in the widget's window change, the widget |
-   |                | will generate a Tcl command based on the scrollcommand. |
-   |                |                                                         |
-   |                | Usually this option consists of the method              |
-   |                | :meth:`Scrollbar.set` of some scrollbar. This will cause|
-   |                | the scrollbar to be updated whenever the view in the    |
-   |                | window changes.                                         |
-   +----------------+---------------------------------------------------------+
-   | yscrollcommand | Used to communicate with vertical scrollbars.           |
-   |                | For some more information, see above.                   |
-   +----------------+---------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++----------------+---------------------------------------------------------+
+| Option         | Description                                             |
++================+=========================================================+
+| xscrollcommand | Used to communicate with horizontal scrollbars.         |
+|                |                                                         |
+|                | When the view in the widget's window change, the widget |
+|                | will generate a Tcl command based on the scrollcommand. |
+|                |                                                         |
+|                | Usually this option consists of the method              |
+|                | :meth:`Scrollbar.set` of some scrollbar. This will cause|
+|                | the scrollbar to be updated whenever the view in the    |
+|                | window changes.                                         |
++----------------+---------------------------------------------------------+
+| yscrollcommand | Used to communicate with vertical scrollbars.           |
+|                | For some more information, see above.                   |
++----------------+---------------------------------------------------------+
 
 
 Label Options
@@ -165,93 +165,93 @@ Label Options
 The following options are supported by labels, buttons and other button-like
 widgets.
 
-   .. tabularcolumns:: |l|p{0.7\linewidth}|
-
-   +--------------+-----------------------------------------------------------+
-   | Option       | Description                                               |
-   +==============+===========================================================+
-   | text         | Specifies a text string to be displayed inside the widget.|
-   +--------------+-----------------------------------------------------------+
-   | textvariable | Specifies a name whose value will be used in place of the |
-   |              | text option resource.                                     |
-   +--------------+-----------------------------------------------------------+
-   | underline    | If set, specifies the index (0-based) of a character to   |
-   |              | underline in the text string. The underline character is  |
-   |              | used for mnemonic activation.                             |
-   +--------------+-----------------------------------------------------------+
-   | image        | Specifies an image to display. This is a list of 1 or more|
-   |              | elements. The first element is the default image name. The|
-   |              | rest of the list if a sequence of statespec/value pairs as|
-   |              | defined by :meth:`Style.map`, specifying different images |
-   |              | to use when the widget is in a particular state or a      |
-   |              | combination of states. All images in the list should have |
-   |              | the same size.                                            |
-   +--------------+-----------------------------------------------------------+
-   | compound     | Specifies how to display the image relative to the text,  |
-   |              | in the case both text and images options are present.     |
-   |              | Valid values are:                                         |
-   |              |                                                           |
-   |              | * text: display text only                                 |
-   |              | * image: display image only                               |
-   |              | * top, bottom, left, right: display image above, below,   |
-   |              |   left of, or right of the text, respectively.            |
-   |              | * none: the default. display the image if present,        |
-   |              |   otherwise the text.                                     |
-   +--------------+-----------------------------------------------------------+
-   | width        | If greater than zero, specifies how much space, in        |
-   |              | character widths, to allocate for the text label, if less |
-   |              | than zero, specifies a minimum width. If zero or          |
-   |              | unspecified, the natural width of the text label is used. |
-   +--------------+-----------------------------------------------------------+
+.. tabularcolumns:: |l|p{0.7\linewidth}|
+
++--------------+-----------------------------------------------------------+
+| Option       | Description                                               |
++==============+===========================================================+
+| text         | Specifies a text string to be displayed inside the widget.|
++--------------+-----------------------------------------------------------+
+| textvariable | Specifies a name whose value will be used in place of the |
+|              | text option resource.                                     |
++--------------+-----------------------------------------------------------+
+| underline    | If set, specifies the index (0-based) of a character to   |
+|              | underline in the text string. The underline character is  |
+|              | used for mnemonic activation.                             |
++--------------+-----------------------------------------------------------+
+| image        | Specifies an image to display. This is a list of 1 or more|
+|              | elements. The first element is the default image name. The|
+|              | rest of the list if a sequence of statespec/value pairs as|
+|              | defined by :meth:`Style.map`, specifying different images |
+|              | to use when the widget is in a particular state or a      |
+|              | combination of states. All images in the list should have |
+|              | the same size.                                            |
++--------------+-----------------------------------------------------------+
+| compound     | Specifies how to display the image relative to the text,  |
+|              | in the case both text and images options are present.     |
+|              | Valid values are:                                         |
+|              |                                                           |
+|              | * text: display text only                                 |
+|              | * image: display image only                               |
+|              | * top, bottom, left, right: display image above, below,   |
+|              |   left of, or right of the text, respectively.            |
+|              | * none: the default. display the image if present,        |
+|              |   otherwise the text.                                     |
++--------------+-----------------------------------------------------------+
+| width        | If greater than zero, specifies how much space, in        |
+|              | character widths, to allocate for the text label, if less |
+|              | than zero, specifies a minimum width. If zero or          |
+|              | unspecified, the natural width of the text label is used. |
++--------------+-----------------------------------------------------------+
 
 
 Compatibility Options
 ^^^^^^^^^^^^^^^^^^^^^
 
-   .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
-   +--------+----------------------------------------------------------------+
-   | Option | Description                                                    |
-   +========+================================================================+
-   | state  | May be set to "normal" or "disabled" to control the "disabled" |
-   |        | state bit. This is a write-only option: setting it changes the |
-   |        | widget state, but the :meth:`Widget.state` method does not     |
-   |        | affect this option.                                            |
-   +--------+----------------------------------------------------------------+
++--------+----------------------------------------------------------------+
+| Option | Description                                                    |
++========+================================================================+
+| state  | May be set to "normal" or "disabled" to control the "disabled" |
+|        | state bit. This is a write-only option: setting it changes the |
+|        | widget state, but the :meth:`Widget.state` method does not     |
+|        | affect this option.                                            |
++--------+----------------------------------------------------------------+
 
 Widget States
 ^^^^^^^^^^^^^
 
 The widget state is a bitmap of independent state flags.
 
-   .. tabularcolumns:: |l|L|
-
-   +------------+-------------------------------------------------------------+
-   | Flag       | Description                                                 |
-   +============+=============================================================+
-   | active     | The mouse cursor is over the widget and pressing a mouse    |
-   |            | button will cause some action to occur                      |
-   +------------+-------------------------------------------------------------+
-   | disabled   | Widget is disabled under program control                    |
-   +------------+-------------------------------------------------------------+
-   | focus      | Widget has keyboard focus                                   |
-   +------------+-------------------------------------------------------------+
-   | pressed    | Widget is being pressed                                     |
-   +------------+-------------------------------------------------------------+
-   | selected   | "On", "true", or "current" for things like Checkbuttons and |
-   |            | radiobuttons                                                |
-   +------------+-------------------------------------------------------------+
-   | background | Windows and Mac have a notion of an "active" or foreground  |
-   |            | window. The *background* state is set for widgets in a      |
-   |            | background window, and cleared for those in the foreground  |
-   |            | window                                                      |
-   +------------+-------------------------------------------------------------+
-   | readonly   | Widget should not allow user modification                   |
-   +------------+-------------------------------------------------------------+
-   | alternate  | A widget-specific alternate display format                  |
-   +------------+-------------------------------------------------------------+
-   | invalid    | The widget's value is invalid                               |
-   +------------+-------------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++------------+-------------------------------------------------------------+
+| Flag       | Description                                                 |
++============+=============================================================+
+| active     | The mouse cursor is over the widget and pressing a mouse    |
+|            | button will cause some action to occur                      |
++------------+-------------------------------------------------------------+
+| disabled   | Widget is disabled under program control                    |
++------------+-------------------------------------------------------------+
+| focus      | Widget has keyboard focus                                   |
++------------+-------------------------------------------------------------+
+| pressed    | Widget is being pressed                                     |
++------------+-------------------------------------------------------------+
+| selected   | "On", "true", or "current" for things like Checkbuttons and |
+|            | radiobuttons                                                |
++------------+-------------------------------------------------------------+
+| background | Windows and Mac have a notion of an "active" or foreground  |
+|            | window. The *background* state is set for widgets in a      |
+|            | background window, and cleared for those in the foreground  |
+|            | window                                                      |
++------------+-------------------------------------------------------------+
+| readonly   | Widget should not allow user modification                   |
++------------+-------------------------------------------------------------+
+| alternate  | A widget-specific alternate display format                  |
++------------+-------------------------------------------------------------+
+| invalid    | The widget's value is invalid                               |
++------------+-------------------------------------------------------------+
 
 A state specification is a sequence of state names, optionally prefixed with
 an exclamation point indicating that the bit is off.
@@ -311,43 +311,43 @@ Options
 
 This widget accepts the following specific options:
 
-   .. tabularcolumns:: |l|L|
-
-   +-----------------+--------------------------------------------------------+
-   | Option          | Description                                            |
-   +=================+========================================================+
-   | exportselection | Boolean value. If set, the widget selection is linked  |
-   |                 | to the Window Manager selection (which can be returned |
-   |                 | by invoking Misc.selection_get, for example).          |
-   +-----------------+--------------------------------------------------------+
-   | justify         | Specifies how the text is aligned within the widget.   |
-   |                 | One of "left", "center", or "right".                   |
-   +-----------------+--------------------------------------------------------+
-   | height          | Specifies the height of the pop-down listbox, in rows. |
-   +-----------------+--------------------------------------------------------+
-   | postcommand     | A script (possibly registered with Misc.register) that |
-   |                 | is called immediately before displaying the values. It |
-   |                 | may specify which values to display.                   |
-   +-----------------+--------------------------------------------------------+
-   | state           | One of "normal", "readonly", or "disabled". In the     |
-   |                 | "readonly" state, the value may not be edited directly,|
-   |                 | and the user can only selection of the values from the |
-   |                 | dropdown list. In the "normal" state, the text field is|
-   |                 | directly editable. In the "disabled" state, no         |
-   |                 | interaction is possible.                               |
-   +-----------------+--------------------------------------------------------+
-   | textvariable    | Specifies a name whose value is linked to the widget   |
-   |                 | value. Whenever the value associated with that name    |
-   |                 | changes, the widget value is updated, and vice versa.  |
-   |                 | See :class:`tkinter.StringVar`.                        |
-   +-----------------+--------------------------------------------------------+
-   | values          | Specifies the list of values to display in the         |
-   |                 | drop-down listbox.                                     |
-   +-----------------+--------------------------------------------------------+
-   | width           | Specifies an integer value indicating the desired width|
-   |                 | of the entry window, in average-size characters of the |
-   |                 | widget's font.                                         |
-   +-----------------+--------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++-----------------+--------------------------------------------------------+
+| Option          | Description                                            |
++=================+========================================================+
+| exportselection | Boolean value. If set, the widget selection is linked  |
+|                 | to the Window Manager selection (which can be returned |
+|                 | by invoking Misc.selection_get, for example).          |
++-----------------+--------------------------------------------------------+
+| justify         | Specifies how the text is aligned within the widget.   |
+|                 | One of "left", "center", or "right".                   |
++-----------------+--------------------------------------------------------+
+| height          | Specifies the height of the pop-down listbox, in rows. |
++-----------------+--------------------------------------------------------+
+| postcommand     | A script (possibly registered with Misc.register) that |
+|                 | is called immediately before displaying the values. It |
+|                 | may specify which values to display.                   |
++-----------------+--------------------------------------------------------+
+| state           | One of "normal", "readonly", or "disabled". In the     |
+|                 | "readonly" state, the value may not be edited directly,|
+|                 | and the user can only selection of the values from the |
+|                 | dropdown list. In the "normal" state, the text field is|
+|                 | directly editable. In the "disabled" state, no         |
+|                 | interaction is possible.                               |
++-----------------+--------------------------------------------------------+
+| textvariable    | Specifies a name whose value is linked to the widget   |
+|                 | value. Whenever the value associated with that name    |
+|                 | changes, the widget value is updated, and vice versa.  |
+|                 | See :class:`tkinter.StringVar`.                        |
++-----------------+--------------------------------------------------------+
+| values          | Specifies the list of values to display in the         |
+|                 | drop-down listbox.                                     |
++-----------------+--------------------------------------------------------+
+| width           | Specifies an integer value indicating the desired width|
+|                 | of the entry window, in average-size characters of the |
+|                 | widget's font.                                         |
++-----------------+--------------------------------------------------------+
 
 
 Virtual events
@@ -397,7 +397,7 @@ Options
 
 This widget accepts the following specific options:
 
-  .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
 +----------------------+------------------------------------------------------+
 | Option               | Description                                          |
@@ -473,25 +473,25 @@ Options
 
 This widget accepts the following specific options:
 
-   .. tabularcolumns:: |l|L|
-
-   +---------+----------------------------------------------------------------+
-   | Option  | Description                                                    |
-   +=========+================================================================+
-   | height  | If present and greater than zero, specifies the desired height |
-   |         | of the pane area (not including internal padding or tabs).     |
-   |         | Otherwise, the maximum height of all panes is used.            |
-   +---------+----------------------------------------------------------------+
-   | padding | Specifies the amount of extra space to add around the outside  |
-   |         | of the notebook. The padding is a list up to four length       |
-   |         | specifications left top right bottom. If fewer than four       |
-   |         | elements are specified, bottom defaults to top, right defaults |
-   |         | to left, and top defaults to left.                             |
-   +---------+----------------------------------------------------------------+
-   | width   | If present and greater than zero, specified the desired width  |
-   |         | of the pane area (not including internal padding). Otherwise,  |
-   |         | the maximum width of all panes is used.                        |
-   +---------+----------------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++---------+----------------------------------------------------------------+
+| Option  | Description                                                    |
++=========+================================================================+
+| height  | If present and greater than zero, specifies the desired height |
+|         | of the pane area (not including internal padding or tabs).     |
+|         | Otherwise, the maximum height of all panes is used.            |
++---------+----------------------------------------------------------------+
+| padding | Specifies the amount of extra space to add around the outside  |
+|         | of the notebook. The padding is a list up to four length       |
+|         | specifications left top right bottom. If fewer than four       |
+|         | elements are specified, bottom defaults to top, right defaults |
+|         | to left, and top defaults to left.                             |
++---------+----------------------------------------------------------------+
+| width   | If present and greater than zero, specified the desired width  |
+|         | of the pane area (not including internal padding). Otherwise,  |
+|         | the maximum width of all panes is used.                        |
++---------+----------------------------------------------------------------+
 
 
 Tab Options
@@ -499,39 +499,39 @@ Tab Options
 
 There are also specific options for tabs:
 
-   .. tabularcolumns:: |l|L|
-
-   +-----------+--------------------------------------------------------------+
-   | Option    | Description                                                  |
-   +===========+==============================================================+
-   | state     | Either "normal", "disabled" or "hidden". If "disabled", then |
-   |           | the tab is not selectable. If "hidden", then the tab is not  |
-   |           | shown.                                                       |
-   +-----------+--------------------------------------------------------------+
-   | sticky    | Specifies how the child window is positioned within the pane |
-   |           | area. Value is a string containing zero or more of the       |
-   |           | characters "n", "s", "e" or "w". Each letter refers to a     |
-   |           | side (north, south, east or west) that the child window will |
-   |           | stick to, as per the :meth:`grid` geometry manager.          |
-   +-----------+--------------------------------------------------------------+
-   | padding   | Specifies the amount of extra space to add between the       |
-   |           | notebook and this pane. Syntax is the same as for the option |
-   |           | padding used by this widget.                                 |
-   +-----------+--------------------------------------------------------------+
-   | text      | Specifies a text to be displayed in the tab.                 |
-   +-----------+--------------------------------------------------------------+
-   | image     | Specifies an image to display in the tab. See the option     |
-   |           | image described in :class:`Widget`.                          |
-   +-----------+--------------------------------------------------------------+
-   | compound  | Specifies how to display the image relative to the text, in  |
-   |           | the case both options text and image are present. See        |
-   |           | `Label Options`_ for legal values.                           |
-   +-----------+--------------------------------------------------------------+
-   | underline | Specifies the index (0-based) of a character to underline in |
-   |           | the text string. The underlined character is used for        |
-   |           | mnemonic activation if :meth:`Notebook.enable_traversal` is  |
-   |           | called.                                                      |
-   +-----------+--------------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++-----------+--------------------------------------------------------------+
+| Option    | Description                                                  |
++===========+==============================================================+
+| state     | Either "normal", "disabled" or "hidden". If "disabled", then |
+|           | the tab is not selectable. If "hidden", then the tab is not  |
+|           | shown.                                                       |
++-----------+--------------------------------------------------------------+
+| sticky    | Specifies how the child window is positioned within the pane |
+|           | area. Value is a string containing zero or more of the       |
+|           | characters "n", "s", "e" or "w". Each letter refers to a     |
+|           | side (north, south, east or west) that the child window will |
+|           | stick to, as per the :meth:`grid` geometry manager.          |
++-----------+--------------------------------------------------------------+
+| padding   | Specifies the amount of extra space to add between the       |
+|           | notebook and this pane. Syntax is the same as for the option |
+|           | padding used by this widget.                                 |
++-----------+--------------------------------------------------------------+
+| text      | Specifies a text to be displayed in the tab.                 |
++-----------+--------------------------------------------------------------+
+| image     | Specifies an image to display in the tab. See the option     |
+|           | image described in :class:`Widget`.                          |
++-----------+--------------------------------------------------------------+
+| compound  | Specifies how to display the image relative to the text, in  |
+|           | the case both options text and image are present. See        |
+|           | `Label Options`_ for legal values.                           |
++-----------+--------------------------------------------------------------+
+| underline | Specifies the index (0-based) of a character to underline in |
+|           | the text string. The underlined character is used for        |
+|           | mnemonic activation if :meth:`Notebook.enable_traversal` is  |
+|           | called.                                                      |
++-----------+--------------------------------------------------------------+
 
 
 Tab Identifiers
@@ -663,36 +663,36 @@ Options
 
 This widget accepts the following specific options:
 
-   .. tabularcolumns:: |l|L|
-
-   +----------+---------------------------------------------------------------+
-   | Option   | Description                                                   |
-   +==========+===============================================================+
-   | orient   | One of "horizontal" or "vertical". Specifies the orientation  |
-   |          | of the progress bar.                                          |
-   +----------+---------------------------------------------------------------+
-   | length   | Specifies the length of the long axis of the progress bar     |
-   |          | (width if horizontal, height if vertical).                    |
-   +----------+---------------------------------------------------------------+
-   | mode     | One of "determinate" or "indeterminate".                      |
-   +----------+---------------------------------------------------------------+
-   | maximum  | A number specifying the maximum value. Defaults to 100.       |
-   +----------+---------------------------------------------------------------+
-   | value    | The current value of the progress bar. In "determinate" mode, |
-   |          | this represents the amount of work completed. In              |
-   |          | "indeterminate" mode, it is interpreted as modulo *maximum*;  |
-   |          | that is, the progress bar completes one "cycle" when its value|
-   |          | increases by *maximum*.                                       |
-   +----------+---------------------------------------------------------------+
-   | variable | A name which is linked to the option value. If specified, the |
-   |          | value of the progress bar is automatically set to the value of|
-   |          | this name whenever the latter is modified.                    |
-   +----------+---------------------------------------------------------------+
-   | phase    | Read-only option. The widget periodically increments the value|
-   |          | of this option whenever its value is greater than 0 and, in   |
-   |          | determinate mode, less than maximum. This option may be used  |
-   |          | by the current theme to provide additional animation effects. |
-   +----------+---------------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++----------+---------------------------------------------------------------+
+| Option   | Description                                                   |
++==========+===============================================================+
+| orient   | One of "horizontal" or "vertical". Specifies the orientation  |
+|          | of the progress bar.                                          |
++----------+---------------------------------------------------------------+
+| length   | Specifies the length of the long axis of the progress bar     |
+|          | (width if horizontal, height if vertical).                    |
++----------+---------------------------------------------------------------+
+| mode     | One of "determinate" or "indeterminate".                      |
++----------+---------------------------------------------------------------+
+| maximum  | A number specifying the maximum value. Defaults to 100.       |
++----------+---------------------------------------------------------------+
+| value    | The current value of the progress bar. In "determinate" mode, |
+|          | this represents the amount of work completed. In              |
+|          | "indeterminate" mode, it is interpreted as modulo *maximum*;  |
+|          | that is, the progress bar completes one "cycle" when its value|
+|          | increases by *maximum*.                                       |
++----------+---------------------------------------------------------------+
+| variable | A name which is linked to the option value. If specified, the |
+|          | value of the progress bar is automatically set to the value of|
+|          | this name whenever the latter is modified.                    |
++----------+---------------------------------------------------------------+
+| phase    | Read-only option. The widget periodically increments the value|
+|          | of this option whenever its value is greater than 0 and, in   |
+|          | determinate mode, less than maximum. This option may be used  |
+|          | by the current theme to provide additional animation effects. |
++----------+---------------------------------------------------------------+
 
 
 ttk.Progressbar
@@ -734,14 +734,14 @@ Options
 
 This widget accepts the following specific option:
 
-   .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
-   +--------+----------------------------------------------------------------+
-   | Option | Description                                                    |
-   +========+================================================================+
-   | orient | One of "horizontal" or "vertical". Specifies the orientation of|
-   |        | the separator.                                                 |
-   +--------+----------------------------------------------------------------+
++--------+----------------------------------------------------------------+
+| Option | Description                                                    |
++========+================================================================+
+| orient | One of "horizontal" or "vertical". Specifies the orientation of|
+|        | the separator.                                                 |
++--------+----------------------------------------------------------------+
 
 
 Sizegrip
@@ -802,49 +802,49 @@ Options
 
 This widget accepts the following specific options:
 
-   .. tabularcolumns:: |l|p{0.7\linewidth}|
-
-   +----------------+--------------------------------------------------------+
-   | Option         | Description                                            |
-   +================+========================================================+
-   | columns        | A list of column identifiers, specifying the number of |
-   |                | columns and their names.                               |
-   +----------------+--------------------------------------------------------+
-   | displaycolumns | A list of column identifiers (either symbolic or       |
-   |                | integer indices) specifying which data columns are     |
-   |                | displayed and the order in which they appear, or the   |
-   |                | string "#all".                                         |
-   +----------------+--------------------------------------------------------+
-   | height         | Specifies the number of rows which should be visible.  |
-   |                | Note: the requested width is determined from the sum   |
-   |                | of the column widths.                                  |
-   +----------------+--------------------------------------------------------+
-   | padding        | Specifies the internal padding for the widget. The     |
-   |                | padding is a list of up to four length specifications. |
-   +----------------+--------------------------------------------------------+
-   | selectmode     | Controls how the built-in class bindings manage the    |
-   |                | selection. One of "extended", "browse" or "none".      |
-   |                | If set to "extended" (the default), multiple items may |
-   |                | be selected. If "browse", only a single item will be   |
-   |                | selected at a time. If "none", the selection will not  |
-   |                | be changed.                                            |
-   |                |                                                        |
-   |                | Note that the application code and tag bindings can set|
-   |                | the selection however they wish, regardless of the     |
-   |                | value  of this option.                                 |
-   +----------------+--------------------------------------------------------+
-   | show           | A list containing zero or more of the following values,|
-   |                | specifying which elements of the tree to display.      |
-   |                |                                                        |
-   |                | * tree: display tree labels in column #0.              |
-   |                | * headings: display the heading row.                   |
-   |                |                                                        |
-   |                | The default is "tree headings", i.e., show all         |
-   |                | elements.                                              |
-   |                |                                                        |
-   |                | **Note**: Column #0 always refers to the tree column,  |
-   |                | even if show="tree" is not specified.                  |
-   +----------------+--------------------------------------------------------+
+.. tabularcolumns:: |l|p{0.7\linewidth}|
+
++----------------+--------------------------------------------------------+
+| Option         | Description                                            |
++================+========================================================+
+| columns        | A list of column identifiers, specifying the number of |
+|                | columns and their names.                               |
++----------------+--------------------------------------------------------+
+| displaycolumns | A list of column identifiers (either symbolic or       |
+|                | integer indices) specifying which data columns are     |
+|                | displayed and the order in which they appear, or the   |
+|                | string "#all".                                         |
++----------------+--------------------------------------------------------+
+| height         | Specifies the number of rows which should be visible.  |
+|                | Note: the requested width is determined from the sum   |
+|                | of the column widths.                                  |
++----------------+--------------------------------------------------------+
+| padding        | Specifies the internal padding for the widget. The     |
+|                | padding is a list of up to four length specifications. |
++----------------+--------------------------------------------------------+
+| selectmode     | Controls how the built-in class bindings manage the    |
+|                | selection. One of "extended", "browse" or "none".      |
+|                | If set to "extended" (the default), multiple items may |
+|                | be selected. If "browse", only a single item will be   |
+|                | selected at a time. If "none", the selection will not  |
+|                | be changed.                                            |
+|                |                                                        |
+|                | Note that the application code and tag bindings can set|
+|                | the selection however they wish, regardless of the     |
+|                | value  of this option.                                 |
++----------------+--------------------------------------------------------+
+| show           | A list containing zero or more of the following values,|
+|                | specifying which elements of the tree to display.      |
+|                |                                                        |
+|                | * tree: display tree labels in column #0.              |
+|                | * headings: display the heading row.                   |
+|                |                                                        |
+|                | The default is "tree headings", i.e., show all         |
+|                | elements.                                              |
+|                |                                                        |
+|                | **Note**: Column #0 always refers to the tree column,  |
+|                | even if show="tree" is not specified.                  |
++----------------+--------------------------------------------------------+
 
 
 Item Options
@@ -853,27 +853,27 @@ Item Options
 The following item options may be specified for items in the insert and item
 widget commands.
 
-   .. tabularcolumns:: |l|L|
-
-   +--------+---------------------------------------------------------------+
-   | Option | Description                                                   |
-   +========+===============================================================+
-   | text   | The textual label to display for the item.                    |
-   +--------+---------------------------------------------------------------+
-   | image  | A Tk Image, displayed to the left of the label.               |
-   +--------+---------------------------------------------------------------+
-   | values | The list of values associated with the item.                  |
-   |        |                                                               |
-   |        | Each item should have the same number of values as the widget |
-   |        | option columns. If there are fewer values than columns, the   |
-   |        | remaining values are assumed empty. If there are more values  |
-   |        | than columns, the extra values are ignored.                   |
-   +--------+---------------------------------------------------------------+
-   | open   | ``True``/``False`` value indicating whether the item's        |
-   |        | children should be displayed or hidden.                       |
-   +--------+---------------------------------------------------------------+
-   | tags   | A list of tags associated with this item.                     |
-   +--------+---------------------------------------------------------------+
+.. tabularcolumns:: |l|L|
+
++--------+---------------------------------------------------------------+
+| Option | Description                                                   |
++========+===============================================================+
+| text   | The textual label to display for the item.                    |
++--------+---------------------------------------------------------------+
+| image  | A Tk Image, displayed to the left of the label.               |
++--------+---------------------------------------------------------------+
+| values | The list of values associated with the item.                  |
+|        |                                                               |
+|        | Each item should have the same number of values as the widget |
+|        | option columns. If there are fewer values than columns, the   |
+|        | remaining values are assumed empty. If there are more values  |
+|        | than columns, the extra values are ignored.                   |
++--------+---------------------------------------------------------------+
+| open   | ``True``/``False`` value indicating whether the item's        |
+|        | children should be displayed or hidden.                       |
++--------+---------------------------------------------------------------+
+| tags   | A list of tags associated with this item.                     |
++--------+---------------------------------------------------------------+
 
 
 Tag Options
@@ -881,20 +881,20 @@ Tag Options
 
 The following options may be specified on tags:
 
-   .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
-   +------------+-----------------------------------------------------------+
-   | Option     | Description                                               |
-   +============+===========================================================+
-   | foreground | Specifies the text foreground color.                      |
-   +------------+-----------------------------------------------------------+
-   | background | Specifies the cell or item background color.              |
-   +------------+-----------------------------------------------------------+
-   | font       | Specifies the font to use when drawing text.              |
-   +------------+-----------------------------------------------------------+
-   | image      | Specifies the item image, in case the item's image option |
-   |            | is empty.                                                 |
-   +------------+-----------------------------------------------------------+
++------------+-----------------------------------------------------------+
+| Option     | Description                                               |
++============+===========================================================+
+| foreground | Specifies the text foreground color.                      |
++------------+-----------------------------------------------------------+
+| background | Specifies the cell or item background color.              |
++------------+-----------------------------------------------------------+
+| font       | Specifies the font to use when drawing text.              |
++------------+-----------------------------------------------------------+
+| image      | Specifies the item image, in case the item's image option |
+|            | is empty.                                                 |
++------------+-----------------------------------------------------------+
 
 
 Column Identifiers
@@ -926,19 +926,19 @@ Virtual Events
 
 The Treeview widget generates the following virtual events.
 
-   .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
-   +--------------------+--------------------------------------------------+
-   | Event              | Description                                      |
-   +====================+==================================================+
-   | <<TreeviewSelect>> | Generated whenever the selection changes.        |
-   +--------------------+--------------------------------------------------+
-   | <<TreeviewOpen>>   | Generated just before settings the focus item to |
-   |                    | open=True.                                       |
-   +--------------------+--------------------------------------------------+
-   | <<TreeviewClose>>  | Generated just after setting the focus item to   |
-   |                    | open=False.                                      |
-   +--------------------+--------------------------------------------------+
++--------------------+--------------------------------------------------+
+| Event              | Description                                      |
++====================+==================================================+
+| <<TreeviewSelect>> | Generated whenever the selection changes.        |
++--------------------+--------------------------------------------------+
+| <<TreeviewOpen>>   | Generated just before settings the focus item to |
+|                    | open=True.                                       |
++--------------------+--------------------------------------------------+
+| <<TreeviewClose>>  | Generated just after setting the focus item to   |
+|                    | open=False.                                      |
++--------------------+--------------------------------------------------+
 
 The :meth:`Treeview.focus` and :meth:`Treeview.selection` methods can be used
 to determine the affected item or items.
@@ -986,19 +986,19 @@ ttk.Treeview
 
       The valid options/values are:
 
-      * id
+      id
          Returns the column name. This is a read-only option.
-      * anchor: One of the standard Tk anchor values.
+      anchor: One of the standard Tk anchor values.
          Specifies how the text in this column should be aligned with respect
          to the cell.
-      * minwidth: width
+      minwidth: width
          The minimum width of the column in pixels. The treeview widget will
          not make the column any smaller than specified by this option when
          the widget is resized or the user drags a column.
-      * stretch: ``True``/``False``
+      stretch: ``True``/``False``
          Specifies whether the column's width should be adjusted when
          the widget is resized.
-      * width: width
+      width: width
          The width of the column in pixels.
 
       To configure the tree column, call this with column = "#0"
@@ -1041,14 +1041,14 @@ ttk.Treeview
 
       The valid options/values are:
 
-      * text: text
+      text: text
          The text to display in the column heading.
-      * image: imageName
+      image: imageName
          Specifies an image to display to the right of the column heading.
-      * anchor: anchor
+      anchor: anchor
          Specifies how the heading text should be aligned. One of the standard
          Tk anchor values.
-      * command: callback
+      command: callback
          A callback to be invoked when the heading label is pressed.
 
       To configure the tree column heading, call this with column = "#0".
@@ -1398,25 +1398,25 @@ option. If you don't know the class name of a widget, use the method
       by statespec/value pairs (this is the imagespec), and *kw* may have the
       following options:
 
-       * border=padding
-          padding is a list of up to four integers, specifying the left, top,
-          right, and bottom borders, respectively.
+      border=padding
+         padding is a list of up to four integers, specifying the left, top,
+         right, and bottom borders, respectively.
 
-       * height=height
-          Specifies a minimum height for the element. If less than zero, the
-          base image's height is used as a default.
+      height=height
+         Specifies a minimum height for the element. If less than zero, the
+         base image's height is used as a default.
 
-       * padding=padding
-          Specifies the element's interior padding. Defaults to border's value
-          if not specified.
+      padding=padding
+         Specifies the element's interior padding. Defaults to border's value
+         if not specified.
 
-       * sticky=spec
-          Specifies how the image is placed within the final parcel. spec
-          contains zero or more characters "n", "s", "w", or "e".
+      sticky=spec
+         Specifies how the image is placed within the final parcel. spec
+         contains zero or more characters "n", "s", "w", or "e".
 
-       * width=width
-          Specifies a minimum width for the element. If less than zero, the
-          base image's width is used as a default.
+      width=width
+         Specifies a minimum width for the element. If less than zero, the
+         base image's width is used as a default.
 
       If "from" is used as the value of *etype*,
       :meth:`element_create` will clone an existing
@@ -1504,22 +1504,22 @@ uses a simplified version of the pack geometry manager: given an
 initial cavity, each element is allocated a parcel. Valid
 options/values are:
 
- * side: whichside
-    Specifies which side of the cavity to place the element; one of
-    top, right, bottom or left. If omitted, the element occupies the
-    entire cavity.
+side: whichside
+   Specifies which side of the cavity to place the element; one of
+   top, right, bottom or left. If omitted, the element occupies the
+   entire cavity.
 
- * sticky: nswe
-    Specifies where the element is placed inside its allocated parcel.
+sticky: nswe
+   Specifies where the element is placed inside its allocated parcel.
 
- * unit: 0 or 1
-    If set to 1, causes the element and all of its descendants to be treated as
-    a single element for the purposes of :meth:`Widget.identify` et al. It's
-    used for things like scrollbar thumbs with grips.
+unit: 0 or 1
+   If set to 1, causes the element and all of its descendants to be treated as
+   a single element for the purposes of :meth:`Widget.identify` et al. It's
+   used for things like scrollbar thumbs with grips.
 
- * children: [sublayout... ]
-    Specifies a list of elements to place inside the element. Each
-    element is a tuple (or other sequence type) where the first item is
-    the layout name, and the other is a `Layout`_.
+children: [sublayout... ]
+   Specifies a list of elements to place inside the element. Each
+   element is a tuple (or other sequence type) where the first item is
+   the layout name, and the other is a `Layout`_.
 
 .. _Layout: `Layouts`_
diff --git a/Doc/library/tokenize.rst b/Doc/library/tokenize.rst
index bffe93006e..92bdb05226 100644
--- a/Doc/library/tokenize.rst
+++ b/Doc/library/tokenize.rst
@@ -166,11 +166,11 @@ The following options are accepted:
 
 .. program:: tokenize
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    show this help message and exit
 
-.. cmdoption:: -e, --exact
+.. option:: -e, --exact
 
    display token names using the exact type
 
diff --git a/Doc/library/trace.rst b/Doc/library/trace.rst
index 40cf198f12..e9b59a6d18 100644
--- a/Doc/library/trace.rst
+++ b/Doc/library/trace.rst
@@ -34,11 +34,11 @@ all Python modules imported during the execution into the current directory.
 
 .. program:: trace
 
-.. cmdoption:: --help
+.. option:: --help
 
    Display usage and exit.
 
-.. cmdoption:: --version
+.. option:: --version
 
    Display the version of the module and exit.
 
@@ -56,28 +56,28 @@ the :option:`--trace <-t>` and :option:`--count <-c>` options. When
 
 .. program:: trace
 
-.. cmdoption:: -c, --count
+.. option:: -c, --count
 
    Produce a set of annotated listing files upon program completion that shows
    how many times each statement was executed.  See also
    :option:`--coverdir <-C>`, :option:`--file <-f>` and
    :option:`--no-report <-R>` below.
 
-.. cmdoption:: -t, --trace
+.. option:: -t, --trace
 
    Display lines as they are executed.
 
-.. cmdoption:: -l, --listfuncs
+.. option:: -l, --listfuncs
 
    Display the functions executed by running the program.
 
-.. cmdoption:: -r, --report
+.. option:: -r, --report
 
    Produce an annotated list from an earlier program run that used the
    :option:`--count <-c>` and :option:`--file <-f>` option.  This does not
    execute any code.
 
-.. cmdoption:: -T, --trackcalls
+.. option:: -T, --trackcalls
 
    Display the calling relationships exposed by running the program.
 
@@ -86,33 +86,33 @@ Modifiers
 
 .. program:: trace
 
-.. cmdoption:: -f, --file=<file>
+.. option:: -f, --file=<file>
 
    Name of a file to accumulate counts over several tracing runs.  Should be
    used with the :option:`--count <-c>` option.
 
-.. cmdoption:: -C, --coverdir=<dir>
+.. option:: -C, --coverdir=<dir>
 
    Directory where the report files go.  The coverage report for
    ``package.module`` is written to file :file:`{dir}/{package}/{module}.cover`.
 
-.. cmdoption:: -m, --missing
+.. option:: -m, --missing
 
    When generating annotated listings, mark lines which were not executed with
    ``>>>>>>``.
 
-.. cmdoption:: -s, --summary
+.. option:: -s, --summary
 
    When using :option:`--count <-c>` or :option:`--report <-r>`, write a brief
    summary to stdout for each file processed.
 
-.. cmdoption:: -R, --no-report
+.. option:: -R, --no-report
 
    Do not generate annotated listings.  This is useful if you intend to make
    several runs with :option:`--count <-c>`, and then produce a single set of
    annotated listings at the end.
 
-.. cmdoption:: -g, --timing
+.. option:: -g, --timing
 
    Prefix each line with the time since the program started.  Only used while
    tracing.
@@ -124,12 +124,12 @@ These options may be repeated multiple times.
 
 .. program:: trace
 
-.. cmdoption:: --ignore-module=<mod>
+.. option:: --ignore-module=<mod>
 
    Ignore each of the given module names and its submodules (if it is a
    package).  The argument can be a list of names separated by a comma.
 
-.. cmdoption:: --ignore-dir=<dir>
+.. option:: --ignore-dir=<dir>
 
    Ignore all modules and packages in the named directory and subdirectories.
    The argument can be a list of directories separated by :data:`os.pathsep`.
diff --git a/Doc/library/tty.rst b/Doc/library/tty.rst
index fc7f98c793..20ba7d7e0a 100644
--- a/Doc/library/tty.rst
+++ b/Doc/library/tty.rst
@@ -15,6 +15,8 @@
 The :mod:`tty` module defines functions for putting the tty into cbreak and raw
 modes.
 
+.. availability:: Unix.
+
 Because it requires the :mod:`termios` module, it will work only on Unix.
 
 The :mod:`tty` module defines the following functions:
@@ -43,6 +45,9 @@ The :mod:`tty` module defines the following functions:
    :func:`termios.tcsetattr`. The return value of :func:`termios.tcgetattr`
    is saved before setting *fd* to raw mode; this value is returned.
 
+   .. versionchanged:: 3.12
+      The return value is now the original tty attributes, instead of None.
+
 
 .. function:: setcbreak(fd, when=termios.TCSAFLUSH)
 
@@ -51,6 +56,9 @@ The :mod:`tty` module defines the following functions:
    :func:`termios.tcsetattr`. The return value of :func:`termios.tcgetattr`
    is saved before setting *fd* to cbreak mode; this value is returned.
 
+   .. versionchanged:: 3.12
+      The return value is now the original tty attributes, instead of None.
+
 
 .. seealso::
 
diff --git a/Doc/library/typing.rst b/Doc/library/typing.rst
index f36dc76c32..7b75094b9d 100644
--- a/Doc/library/typing.rst
+++ b/Doc/library/typing.rst
@@ -18,8 +18,8 @@
 .. note::
 
    The Python runtime does not enforce function and variable type annotations.
-   They can be used by third party tools such as type checkers, IDEs, linters,
-   etc.
+   They can be used by third party tools such as :term:`type checkers <static type checker>`,
+   IDEs, linters, etc.
 
 --------------
 
@@ -304,7 +304,7 @@ a callable with any arbitrary parameter list would be acceptable:
    x = concat  # Also OK
 
 ``Callable`` cannot express complex signatures such as functions that take a
-variadic number of arguments, :func:`overloaded functions <overload>`, or
+variadic number of arguments, :ref:`overloaded functions <overload>`, or
 functions that have keyword-only parameters. However, these signatures can be
 expressed by defining a :class:`Protocol` class with a
 :meth:`~object.__call__` method:
@@ -526,7 +526,7 @@ A user-defined class can be defined as a generic class.
            self.logger.info('%s: %s', self.name, message)
 
 This syntax indicates that the class ``LoggedVar`` is parameterised around a
-single :class:`type variable <TypeVar>` ``T`` . This also makes ``T`` valid as
+single :ref:`type variable <typevar>` ``T`` . This also makes ``T`` valid as
 a type within the class body.
 
 Generic classes implicitly inherit from :class:`Generic`. For compatibility
@@ -1135,16 +1135,13 @@ These can be used as types in annotations. They all support subscription using
 
       from collections.abc import Callable
       from threading import Lock
-      from typing import Concatenate, ParamSpec, TypeVar
-
-      P = ParamSpec('P')
-      R = TypeVar('R')
+      from typing import Concatenate
 
       # Use this lock to ensure that only one thread is executing a function
       # at any time.
       my_lock = Lock()
 
-      def with_lock(f: Callable[Concatenate[Lock, P], R]) -> Callable[P, R]:
+      def with_lock[**P, R](f: Callable[Concatenate[Lock, P], R]) -> Callable[P, R]:
           '''A type-safe decorator which provides a lock.'''
           def inner(*args: P.args, **kwargs: P.kwargs) -> R:
               # Provide the lock as the first argument.
@@ -1291,7 +1288,7 @@ These can be used as types in annotations. They all support subscription using
    completely disables typechecking for a function or class.
 
    The responsibility of how to interpret the metadata
-   lies with the the tool or library encountering an
+   lies with the tool or library encountering an
    ``Annotated`` annotation. A tool or library encountering an ``Annotated`` type
    can scan through the metadata elements to determine if they are of interest
    (e.g., using :func:`isinstance`).
@@ -1483,7 +1480,7 @@ These can be used as types in annotations. They all support subscription using
    Typing operator to conceptually mark an object as having been unpacked.
 
    For example, using the unpack operator ``*`` on a
-   :class:`type variable tuple <TypeVarTuple>` is equivalent to using ``Unpack``
+   :ref:`type variable tuple <typevartuple>` is equivalent to using ``Unpack``
    to mark the type variable tuple as having been unpacked::
 
       Ts = TypeVarTuple('Ts')
@@ -1574,6 +1571,8 @@ without the dedicated syntax, as documented below.
               ...
               # Etc.
 
+.. _typevar:
+
 .. class:: TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False, infer_variance=False)
 
    Type variable.
@@ -1718,9 +1717,11 @@ without the dedicated syntax, as documented below.
       :ref:`type parameter <type-params>` syntax introduced by :pep:`695`.
       The ``infer_variance`` parameter was added.
 
+.. _typevartuple:
+
 .. class:: TypeVarTuple(name)
 
-   Type variable tuple. A specialized form of :class:`type variable <TypeVar>`
+   Type variable tuple. A specialized form of :ref:`type variable <typevar>`
    that enables *variadic* generics.
 
    Type variable tuples can be declared in :ref:`type parameter lists <type-params>`
@@ -1838,7 +1839,7 @@ without the dedicated syntax, as documented below.
 .. class:: ParamSpec(name, *, bound=None, covariant=False, contravariant=False)
 
    Parameter specification variable.  A specialized version of
-   :class:`type variables <TypeVar>`.
+   :ref:`type variables <typevar>`.
 
    In :ref:`type parameter lists <type-params>`, parameter specifications
    can be declared with two asterisks (``**``)::
@@ -2392,6 +2393,13 @@ types.
          >>> Point3D.__total__
          True
 
+      This attribute reflects *only* the value of the ``total`` argument
+      to the current ``TypedDict`` class, not whether the class is semantically
+      total. For example, a ``TypedDict`` with ``__total__`` set to True may
+      have keys marked with :data:`NotRequired`, or it may inherit from another
+      ``TypedDict`` with ``total=False``. Therefore, it is generally better to use
+      :attr:`__required_keys__` and :attr:`__optional_keys__` for introspection.
+
    .. attribute:: __required_keys__
 
       .. versionadded:: 3.9
@@ -2427,6 +2435,14 @@ types.
 
       .. versionadded:: 3.9
 
+      .. note::
+
+         If ``from __future__ import annotations`` is used or if annotations
+         are given as strings, annotations are not evaluated when the
+         ``TypedDict`` is defined. Therefore, the runtime introspection that
+         ``__required_keys__`` and ``__optional_keys__`` rely on may not work
+         properly, and the values of the attributes may be incorrect.
+
    See :pep:`589` for more examples and detailed rules of using ``TypedDict``.
 
    .. versionadded:: 3.8
@@ -2734,6 +2750,8 @@ Functions and decorators
 
    .. versionadded:: 3.11
 
+.. _overload:
+
 .. decorator:: overload
 
    Decorator for creating overloaded functions and methods.
diff --git a/Doc/library/unittest.mock.rst b/Doc/library/unittest.mock.rst
index 13cd593f95..175ab0fb23 100644
--- a/Doc/library/unittest.mock.rst
+++ b/Doc/library/unittest.mock.rst
@@ -814,8 +814,8 @@ This applies to :meth:`~Mock.assert_called_with`,
 :meth:`~Mock.assert_any_call`.  When :ref:`auto-speccing`, it will also
 apply to method calls on the mock object.
 
-   .. versionchanged:: 3.4
-      Added signature introspection on specced and autospecced mock objects.
+.. versionchanged:: 3.4
+   Added signature introspection on specced and autospecced mock objects.
 
 
 .. class:: PropertyMock(*args, **kwargs)
@@ -1388,9 +1388,9 @@ patch
 
     .. note::
 
-        .. versionchanged:: 3.5
-           If you are patching builtins in a module then you don't
-           need to pass ``create=True``, it will be added by default.
+       .. versionchanged:: 3.5
+          If you are patching builtins in a module then you don't
+          need to pass ``create=True``, it will be added by default.
 
     Patch can be used as a :class:`TestCase` class decorator. It works by
     decorating each test method in the class. This reduces the boilerplate
@@ -1658,7 +1658,7 @@ Keywords can be used in the :func:`patch.dict` call to set values in the diction
 :func:`patch.dict` can be used with dictionary like objects that aren't actually
 dictionaries. At the very minimum they must support item getting, setting,
 deleting and either iteration or membership test. This corresponds to the
-magic methods :meth:`__getitem__`, :meth:`__setitem__`, :meth:`__delitem__` and either
+magic methods :meth:`~object.__getitem__`, :meth:`__setitem__`, :meth:`__delitem__` and either
 :meth:`__iter__` or :meth:`__contains__`.
 
     >>> class Container:
@@ -2482,8 +2482,8 @@ are closed properly and is becoming common::
         f.write('something')
 
 The issue is that even if you mock out the call to :func:`open` it is the
-*returned object* that is used as a context manager (and has :meth:`__enter__` and
-:meth:`__exit__` called).
+*returned object* that is used as a context manager (and has :meth:`~object.__enter__` and
+:meth:`~object.__exit__` called).
 
 Mocking context managers with a :class:`MagicMock` is common enough and fiddly
 enough that a helper function is useful. ::
diff --git a/Doc/library/unittest.rst b/Doc/library/unittest.rst
index 4c28e8fae8..21abc583f8 100644
--- a/Doc/library/unittest.rst
+++ b/Doc/library/unittest.rst
@@ -206,13 +206,13 @@ Command-line options
 
 .. program:: unittest
 
-.. cmdoption:: -b, --buffer
+.. option:: -b, --buffer
 
    The standard output and standard error streams are buffered during the test
    run. Output during a passing test is discarded. Output is echoed normally
    on test fail or error and is added to the failure messages.
 
-.. cmdoption:: -c, --catch
+.. option:: -c, --catch
 
    :kbd:`Control-C` during the test run waits for the current test to end and then
    reports all the results so far. A second :kbd:`Control-C` raises the normal
@@ -220,11 +220,11 @@ Command-line options
 
    See `Signal Handling`_ for the functions that provide this functionality.
 
-.. cmdoption:: -f, --failfast
+.. option:: -f, --failfast
 
    Stop the test run on the first error or failure.
 
-.. cmdoption:: -k
+.. option:: -k
 
    Only run test methods and classes that match the pattern or substring.
    This option may be used multiple times, in which case all test cases that
@@ -240,11 +240,11 @@ Command-line options
    For example, ``-k foo`` matches ``foo_tests.SomeTest.test_something``,
    ``bar_tests.SomeTest.test_foo``, but not ``bar_tests.FooTest.test_something``.
 
-.. cmdoption:: --locals
+.. option:: --locals
 
    Show local variables in tracebacks.
 
-.. cmdoption:: --durations N
+.. option:: --durations N
 
    Show the N slowest test cases (N=0 for all).
 
@@ -292,19 +292,19 @@ The ``discover`` sub-command has the following options:
 
 .. program:: unittest discover
 
-.. cmdoption:: -v, --verbose
+.. option:: -v, --verbose
 
    Verbose output
 
-.. cmdoption:: -s, --start-directory directory
+.. option:: -s, --start-directory directory
 
    Directory to start discovery (``.`` default)
 
-.. cmdoption:: -p, --pattern pattern
+.. option:: -p, --pattern pattern
 
    Pattern to match test files (``test*.py`` default)
 
-.. cmdoption:: -t, --top-level-directory directory
+.. option:: -t, --top-level-directory directory
 
    Top level directory of project (defaults to start directory)
 
diff --git a/Doc/library/urllib.error.rst b/Doc/library/urllib.error.rst
index a5bcb5b1e6..facb11f42a 100644
--- a/Doc/library/urllib.error.rst
+++ b/Doc/library/urllib.error.rst
@@ -27,8 +27,8 @@ The following exceptions are raised by :mod:`urllib.error` as appropriate:
       exception instance.
 
    .. versionchanged:: 3.3
-      :exc:`URLError` has been made a subclass of :exc:`OSError` instead
-      of :exc:`IOError`.
+      :exc:`URLError` used to be a subtype of :exc:`IOError`, which is now an
+      alias of :exc:`OSError`.
 
 
 .. exception:: HTTPError(url, code, msg, hdrs, fp)
diff --git a/Doc/library/urllib.request.rst b/Doc/library/urllib.request.rst
index 35b8f5b471..002dab8a65 100644
--- a/Doc/library/urllib.request.rst
+++ b/Doc/library/urllib.request.rst
@@ -315,10 +315,10 @@ The following classes are provided:
    list of hostname suffixes, optionally with ``:port`` appended, for example
    ``cern.ch,ncsa.uiuc.edu,some.host:8080``.
 
-    .. note::
+   .. note::
 
-       ``HTTP_PROXY`` will be ignored if a variable ``REQUEST_METHOD`` is set;
-       see the documentation on :func:`~urllib.request.getproxies`.
+      ``HTTP_PROXY`` will be ignored if a variable ``REQUEST_METHOD`` is set;
+      see the documentation on :func:`~urllib.request.getproxies`.
 
 
 .. class:: HTTPPasswordMgr()
@@ -1536,9 +1536,9 @@ some point in the future.
 :mod:`urllib.request` Restrictions
 ----------------------------------
 
-  .. index::
-     pair: HTTP; protocol
-     pair: FTP; protocol
+.. index::
+   pair: HTTP; protocol
+   pair: FTP; protocol
 
 * Currently, only the following protocols are supported: HTTP (versions 0.9 and
   1.0), FTP, local files, and data URLs.
diff --git a/Doc/library/uuid.rst b/Doc/library/uuid.rst
index adf0177065..e2d231da38 100644
--- a/Doc/library/uuid.rst
+++ b/Doc/library/uuid.rst
@@ -289,25 +289,25 @@ The following options are accepted:
 
 .. program:: uuid
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    Show the help message and exit.
 
-.. cmdoption:: -u <uuid>
-               --uuid <uuid>
+.. option:: -u <uuid>
+            --uuid <uuid>
 
    Specify the function name to use to generate the uuid. By default :func:`uuid4`
    is used.
 
-.. cmdoption:: -n <namespace>
-               --namespace <namespace>
+.. option:: -n <namespace>
+            --namespace <namespace>
 
    The namespace is a ``UUID``, or ``@ns`` where ``ns`` is a well-known predefined UUID
    addressed by namespace name. Such as ``@dns``, ``@url``, ``@oid``, and ``@x500``.
    Only required for :func:`uuid3` / :func:`uuid5` functions.
 
-.. cmdoption:: -N <name>
-               --name <name>
+.. option:: -N <name>
+            --name <name>
 
    The name used as part of generating the uuid. Only required for
    :func:`uuid3` / :func:`uuid5` functions.
diff --git a/Doc/library/wsgiref.rst b/Doc/library/wsgiref.rst
index 39a4c1ba14..be9e56b04c 100644
--- a/Doc/library/wsgiref.rst
+++ b/Doc/library/wsgiref.rst
@@ -180,7 +180,7 @@ also provides these miscellaneous utilities:
           print(chunk)
 
    .. versionchanged:: 3.11
-      Support for :meth:`__getitem__` method has been removed.
+      Support for :meth:`~object.__getitem__` method has been removed.
 
 
 :mod:`wsgiref.headers` -- WSGI response header tools
@@ -201,7 +201,7 @@ manipulation of WSGI response headers using a mapping-like interface.
    an empty list.
 
    :class:`Headers` objects support typical mapping operations including
-   :meth:`__getitem__`, :meth:`get`, :meth:`__setitem__`, :meth:`setdefault`,
+   :meth:`~object.__getitem__`, :meth:`get`, :meth:`__setitem__`, :meth:`setdefault`,
    :meth:`__delitem__` and :meth:`__contains__`.  For each of
    these methods, the key is the header name (treated case-insensitively), and the
    value is the first value associated with that header name.  Setting a header
diff --git a/Doc/library/xml.dom.pulldom.rst b/Doc/library/xml.dom.pulldom.rst
index d1df465a59..843c2fd7fd 100644
--- a/Doc/library/xml.dom.pulldom.rst
+++ b/Doc/library/xml.dom.pulldom.rst
@@ -115,7 +115,7 @@ DOMEventStream Objects
 .. class:: DOMEventStream(stream, parser, bufsize)
 
    .. versionchanged:: 3.11
-      Support for :meth:`__getitem__` method has been removed.
+      Support for :meth:`~object.__getitem__` method has been removed.
 
    .. method:: getEvent()
 
diff --git a/Doc/library/xml.etree.elementtree.rst b/Doc/library/xml.etree.elementtree.rst
index 54c9300850..57cfbb8d92 100644
--- a/Doc/library/xml.etree.elementtree.rst
+++ b/Doc/library/xml.etree.elementtree.rst
@@ -154,6 +154,7 @@ elements, call :meth:`XMLPullParser.read_events`.  Here is an example::
    ...     print(elem.tag, 'text=', elem.text)
    ...
    end
+   mytag text= sometext more text
 
 The obvious use case is applications that operate in a non-blocking fashion
 where the XML data is being received from a socket or read incrementally from
@@ -621,7 +622,9 @@ Functions
    *parser* is an optional parser instance.  If not given, the standard
    :class:`XMLParser` parser is used.  *parser* must be a subclass of
    :class:`XMLParser` and can only use the default :class:`TreeBuilder` as a
-   target.  Returns an :term:`iterator` providing ``(event, elem)`` pairs.
+   target. Returns an :term:`iterator` providing ``(event, elem)`` pairs;
+   it has a ``root`` attribute that references the root element of the
+   resulting XML tree once *source* is fully read.
 
    Note that while :func:`iterparse` builds the tree incrementally, it issues
    blocking reads on *source* (or the file it names).  As such, it's unsuitable
diff --git a/Doc/library/zipapp.rst b/Doc/library/zipapp.rst
index 7c01fc102f..104afca23a 100644
--- a/Doc/library/zipapp.rst
+++ b/Doc/library/zipapp.rst
@@ -54,7 +54,7 @@ The following options are understood:
 
 .. program:: zipapp
 
-.. cmdoption:: -o <output>, --output=<output>
+.. option:: -o <output>, --output=<output>
 
    Write the output to a file named *output*.  If this option is not specified,
    the output filename will be the same as the input *source*, with the
@@ -64,13 +64,13 @@ The following options are understood:
    An output filename must be specified if the *source* is an archive (and in
    that case, *output* must not be the same as *source*).
 
-.. cmdoption:: -p <interpreter>, --python=<interpreter>
+.. option:: -p <interpreter>, --python=<interpreter>
 
    Add a ``#!`` line to the archive specifying *interpreter* as the command
    to run.  Also, on POSIX, make the archive executable.  The default is to
    write no ``#!`` line, and not make the file executable.
 
-.. cmdoption:: -m <mainfn>, --main=<mainfn>
+.. option:: -m <mainfn>, --main=<mainfn>
 
    Write a ``__main__.py`` file to the archive that executes *mainfn*.  The
    *mainfn* argument should have the form "pkg.mod:fn", where "pkg.mod" is a
@@ -79,7 +79,7 @@ The following options are understood:
 
    :option:`--main` cannot be specified when copying an archive.
 
-.. cmdoption:: -c, --compress
+.. option:: -c, --compress
 
    Compress files with the deflate method, reducing the size of the output
    file. By default, files are stored uncompressed in the archive.
@@ -88,13 +88,13 @@ The following options are understood:
 
    .. versionadded:: 3.7
 
-.. cmdoption:: --info
+.. option:: --info
 
    Display the interpreter embedded in the archive, for diagnostic purposes.  In
    this case, any other options are ignored and SOURCE must be an archive, not a
    directory.
 
-.. cmdoption:: -h, --help
+.. option:: -h, --help
 
    Print a short usage message and exit.
 
diff --git a/Doc/library/zipfile.rst b/Doc/library/zipfile.rst
index 45f3d340bd..c011656d9e 100644
--- a/Doc/library/zipfile.rst
+++ b/Doc/library/zipfile.rst
@@ -905,27 +905,27 @@ For a list of the files in a ZIP archive, use the :option:`-l` option:
 Command-line options
 ~~~~~~~~~~~~~~~~~~~~
 
-.. cmdoption:: -l <zipfile>
-               --list <zipfile>
+.. option:: -l <zipfile>
+            --list <zipfile>
 
    List files in a zipfile.
 
-.. cmdoption:: -c <zipfile> <source1> ... <sourceN>
-               --create <zipfile> <source1> ... <sourceN>
+.. option:: -c <zipfile> <source1> ... <sourceN>
+            --create <zipfile> <source1> ... <sourceN>
 
    Create zipfile from source files.
 
-.. cmdoption:: -e <zipfile> <output_dir>
-               --extract <zipfile> <output_dir>
+.. option:: -e <zipfile> <output_dir>
+            --extract <zipfile> <output_dir>
 
    Extract zipfile into target directory.
 
-.. cmdoption:: -t <zipfile>
-               --test <zipfile>
+.. option:: -t <zipfile>
+            --test <zipfile>
 
    Test whether the zipfile is valid or not.
 
-.. cmdoption:: --metadata-encoding <encoding>
+.. option:: --metadata-encoding <encoding>
 
    Specify encoding of member names for :option:`-l`, :option:`-e` and
    :option:`-t`.
diff --git a/Doc/library/zipimport.rst b/Doc/library/zipimport.rst
index 11d19e8c86..47c81f0e63 100644
--- a/Doc/library/zipimport.rst
+++ b/Doc/library/zipimport.rst
@@ -113,7 +113,7 @@ zipimporter Objects
       file wasn't found.
 
       .. versionchanged:: 3.3
-         :exc:`IOError` used to be raised instead of :exc:`OSError`.
+         :exc:`IOError` used to be raised, it is now an alias of :exc:`OSError`.
 
 
    .. method:: get_filename(fullname)
diff --git a/Doc/reference/compound_stmts.rst b/Doc/reference/compound_stmts.rst
index 12ad18d411..8f64813398 100644
--- a/Doc/reference/compound_stmts.rst
+++ b/Doc/reference/compound_stmts.rst
@@ -489,37 +489,37 @@ The execution of the :keyword:`with` statement with one "item" proceeds as follo
 #. The context expression (the expression given in the
    :token:`~python-grammar:with_item`) is evaluated to obtain a context manager.
 
-#. The context manager's :meth:`__enter__` is loaded for later use.
+#. The context manager's :meth:`~object.__enter__` is loaded for later use.
 
-#. The context manager's :meth:`__exit__` is loaded for later use.
+#. The context manager's :meth:`~object.__exit__` is loaded for later use.
 
-#. The context manager's :meth:`__enter__` method is invoked.
+#. The context manager's :meth:`~object.__enter__` method is invoked.
 
 #. If a target was included in the :keyword:`with` statement, the return value
-   from :meth:`__enter__` is assigned to it.
+   from :meth:`~object.__enter__` is assigned to it.
 
    .. note::
 
-      The :keyword:`with` statement guarantees that if the :meth:`__enter__`
-      method returns without an error, then :meth:`__exit__` will always be
+      The :keyword:`with` statement guarantees that if the :meth:`~object.__enter__`
+      method returns without an error, then :meth:`~object.__exit__` will always be
       called. Thus, if an error occurs during the assignment to the target list,
       it will be treated the same as an error occurring within the suite would
       be. See step 7 below.
 
 #. The suite is executed.
 
-#. The context manager's :meth:`__exit__` method is invoked.  If an exception
+#. The context manager's :meth:`~object.__exit__` method is invoked.  If an exception
    caused the suite to be exited, its type, value, and traceback are passed as
-   arguments to :meth:`__exit__`. Otherwise, three :const:`None` arguments are
+   arguments to :meth:`~object.__exit__`. Otherwise, three :const:`None` arguments are
    supplied.
 
    If the suite was exited due to an exception, and the return value from the
-   :meth:`__exit__` method was false, the exception is reraised.  If the return
+   :meth:`~object.__exit__` method was false, the exception is reraised.  If the return
    value was true, the exception is suppressed, and execution continues with the
    statement following the :keyword:`with` statement.
 
    If the suite was exited for any reason other than an exception, the return
-   value from :meth:`__exit__` is ignored, and execution proceeds at the normal
+   value from :meth:`~object.__exit__` is ignored, and execution proceeds at the normal
    location for the kind of exit that was taken.
 
 The following code::
@@ -642,14 +642,14 @@ Here's an overview of the logical flow of a match statement:
    specified below.  **Name bindings made during a successful pattern match
    outlive the executed block and can be used after the match statement**.
 
-      .. note::
+   .. note::
 
-         During failed pattern matches, some subpatterns may succeed.  Do not
-         rely on bindings being made for a failed match.  Conversely, do not
-         rely on variables remaining unchanged after a failed match.  The exact
-         behavior is dependent on implementation and may vary.  This is an
-         intentional decision made to allow different implementations to add
-         optimizations.
+      During failed pattern matches, some subpatterns may succeed.  Do not
+      rely on bindings being made for a failed match.  Conversely, do not
+      rely on variables remaining unchanged after a failed match.  The exact
+      behavior is dependent on implementation and may vary.  This is an
+      intentional decision made to allow different implementations to add
+      optimizations.
 
 #. If the pattern succeeds, the corresponding guard (if present) is evaluated. In
    this case all name bindings are guaranteed to have happened.
@@ -1058,7 +1058,7 @@ subject value:
 .. note:: Key-value pairs are matched using the two-argument form of the mapping
    subject's ``get()`` method.  Matched key-value pairs must already be present
    in the mapping, and not created on-the-fly via :meth:`__missing__` or
-   :meth:`__getitem__`.
+   :meth:`~object.__getitem__`.
 
 In simple terms ``{KEY1: P1, KEY2: P2, ... }`` matches only if all the following
 happens:
@@ -1170,8 +1170,10 @@ In simple terms ``CLS(P1, attr=P2)`` matches only if the following happens:
 * ``isinstance(<subject>, CLS)``
 * convert ``P1`` to a keyword pattern using ``CLS.__match_args__``
 * For each keyword argument ``attr=P2``:
-   * ``hasattr(<subject>, "attr")``
-   * ``P2`` matches ``<subject>.attr``
+
+  * ``hasattr(<subject>, "attr")``
+  * ``P2`` matches ``<subject>.attr``
+
 * ... and so on for the corresponding keyword argument/pattern pair.
 
 .. seealso::
@@ -1838,29 +1840,29 @@ like ``TYPE_PARAMS_OF_ListOrSet`` are not actually bound at runtime.
 
 .. [#] In pattern matching, a sequence is defined as one of the following:
 
-      * a class that inherits from :class:`collections.abc.Sequence`
-      * a Python class that has been registered as :class:`collections.abc.Sequence`
-      * a builtin class that has its (CPython) :c:macro:`Py_TPFLAGS_SEQUENCE` bit set
-      * a class that inherits from any of the above
+   * a class that inherits from :class:`collections.abc.Sequence`
+   * a Python class that has been registered as :class:`collections.abc.Sequence`
+   * a builtin class that has its (CPython) :c:macro:`Py_TPFLAGS_SEQUENCE` bit set
+   * a class that inherits from any of the above
 
    The following standard library classes are sequences:
 
-      * :class:`array.array`
-      * :class:`collections.deque`
-      * :class:`list`
-      * :class:`memoryview`
-      * :class:`range`
-      * :class:`tuple`
+   * :class:`array.array`
+   * :class:`collections.deque`
+   * :class:`list`
+   * :class:`memoryview`
+   * :class:`range`
+   * :class:`tuple`
 
    .. note:: Subject values of type ``str``, ``bytes``, and ``bytearray``
       do not match sequence patterns.
 
 .. [#] In pattern matching, a mapping is defined as one of the following:
 
-      * a class that inherits from :class:`collections.abc.Mapping`
-      * a Python class that has been registered as :class:`collections.abc.Mapping`
-      * a builtin class that has its (CPython) :c:macro:`Py_TPFLAGS_MAPPING` bit set
-      * a class that inherits from any of the above
+   * a class that inherits from :class:`collections.abc.Mapping`
+   * a Python class that has been registered as :class:`collections.abc.Mapping`
+   * a builtin class that has its (CPython) :c:macro:`Py_TPFLAGS_MAPPING` bit set
+   * a class that inherits from any of the above
 
    The standard library classes :class:`dict` and :class:`types.MappingProxyType`
    are mappings.
diff --git a/Doc/reference/datamodel.rst b/Doc/reference/datamodel.rst
index 362ac75214..b8ad4c7b7a 100644
--- a/Doc/reference/datamodel.rst
+++ b/Doc/reference/datamodel.rst
@@ -2939,7 +2939,7 @@ For more information on context managers, see :ref:`typecontextmanager`.
    (i.e., prevent it from being propagated), it should return a true value.
    Otherwise, the exception will be processed normally upon exit from this method.
 
-   Note that :meth:`__exit__` methods should not reraise the passed-in exception;
+   Note that :meth:`~object.__exit__` methods should not reraise the passed-in exception;
    this is the caller's responsibility.
 
 
@@ -3257,12 +3257,12 @@ Asynchronous context managers can be used in an :keyword:`async with` statement.
 
 .. method:: object.__aenter__(self)
 
-   Semantically similar to :meth:`__enter__`, the only
+   Semantically similar to :meth:`~object.__enter__`, the only
    difference being that it must return an *awaitable*.
 
 .. method:: object.__aexit__(self, exc_type, exc_value, traceback)
 
-   Semantically similar to :meth:`__exit__`, the only
+   Semantically similar to :meth:`~object.__exit__`, the only
    difference being that it must return an *awaitable*.
 
 An example of an asynchronous context manager class::
diff --git a/Doc/reference/expressions.rst b/Doc/reference/expressions.rst
index 5d7a36aa8f..cac7ae7efa 100644
--- a/Doc/reference/expressions.rst
+++ b/Doc/reference/expressions.rst
@@ -499,8 +499,8 @@ the yield expression. It can be either set explicitly when raising
 :exc:`StopIteration`, or automatically when the subiterator is a generator
 (by returning a value from the subgenerator).
 
-   .. versionchanged:: 3.3
-      Added ``yield from <expr>`` to delegate control flow to a subiterator.
+.. versionchanged:: 3.3
+   Added ``yield from <expr>`` to delegate control flow to a subiterator.
 
 The parentheses may be omitted when the yield expression is the sole expression
 on the right hand side of an assignment statement.
@@ -882,7 +882,7 @@ to the index so that, for example, ``x[-1]`` selects the last item of ``x``. The
 resulting value must be a nonnegative integer less than the number of items in
 the sequence, and the subscription selects the item whose index is that value
 (counting from zero). Since the support for negative indices and slicing
-occurs in the object's :meth:`__getitem__` method, subclasses overriding
+occurs in the object's :meth:`~object.__getitem__` method, subclasses overriding
 this method will need to explicitly add that support.
 
 .. index::
@@ -937,7 +937,7 @@ slice list contains no proper slice).
    single: step (slice object attribute)
 
 The semantics for a slicing are as follows.  The primary is indexed (using the
-same :meth:`__getitem__` method as
+same :meth:`~object.__getitem__` method as
 normal subscription) with a key that is constructed from the slice list, as
 follows.  If the slice list contains at least one comma, the key is a tuple
 containing the conversion of the slice items; otherwise, the conversion of the
@@ -1663,7 +1663,7 @@ If an exception is raised during the iteration, it is as if :keyword:`in` raised
 that exception.
 
 Lastly, the old-style iteration protocol is tried: if a class defines
-:meth:`__getitem__`, ``x in y`` is ``True`` if and only if there is a non-negative
+:meth:`~object.__getitem__`, ``x in y`` is ``True`` if and only if there is a non-negative
 integer index *i* such that ``x is y[i] or x == y[i]``, and no lower integer index
 raises the :exc:`IndexError` exception.  (If any other exception is raised, it is as
 if :keyword:`in` raised that exception).
diff --git a/Doc/reference/import.rst b/Doc/reference/import.rst
index 0f416a5c58..a7beeea29b 100644
--- a/Doc/reference/import.rst
+++ b/Doc/reference/import.rst
@@ -375,32 +375,32 @@ of what happens during the loading portion of import::
 
 Note the following details:
 
- * If there is an existing module object with the given name in
-   :data:`sys.modules`, import will have already returned it.
+* If there is an existing module object with the given name in
+  :data:`sys.modules`, import will have already returned it.
 
- * The module will exist in :data:`sys.modules` before the loader
-   executes the module code.  This is crucial because the module code may
-   (directly or indirectly) import itself; adding it to :data:`sys.modules`
-   beforehand prevents unbounded recursion in the worst case and multiple
-   loading in the best.
+* The module will exist in :data:`sys.modules` before the loader
+  executes the module code.  This is crucial because the module code may
+  (directly or indirectly) import itself; adding it to :data:`sys.modules`
+  beforehand prevents unbounded recursion in the worst case and multiple
+  loading in the best.
 
- * If loading fails, the failing module -- and only the failing module --
-   gets removed from :data:`sys.modules`.  Any module already in the
-   :data:`sys.modules` cache, and any module that was successfully loaded
-   as a side-effect, must remain in the cache.  This contrasts with
-   reloading where even the failing module is left in :data:`sys.modules`.
+* If loading fails, the failing module -- and only the failing module --
+  gets removed from :data:`sys.modules`.  Any module already in the
+  :data:`sys.modules` cache, and any module that was successfully loaded
+  as a side-effect, must remain in the cache.  This contrasts with
+  reloading where even the failing module is left in :data:`sys.modules`.
 
- * After the module is created but before execution, the import machinery
-   sets the import-related module attributes ("_init_module_attrs" in
-   the pseudo-code example above), as summarized in a
-   :ref:`later section <import-mod-attrs>`.
+* After the module is created but before execution, the import machinery
+  sets the import-related module attributes ("_init_module_attrs" in
+  the pseudo-code example above), as summarized in a
+  :ref:`later section <import-mod-attrs>`.
 
- * Module execution is the key moment of loading in which the module's
-   namespace gets populated.  Execution is entirely delegated to the
-   loader, which gets to decide what gets populated and how.
+* Module execution is the key moment of loading in which the module's
+  namespace gets populated.  Execution is entirely delegated to the
+  loader, which gets to decide what gets populated and how.
 
- * The module created during loading and passed to exec_module() may
-   not be the one returned at the end of import [#fnlo]_.
+* The module created during loading and passed to exec_module() may
+  not be the one returned at the end of import [#fnlo]_.
 
 .. versionchanged:: 3.4
    The import system has taken over the boilerplate responsibilities of
@@ -417,13 +417,13 @@ returned from :meth:`~importlib.abc.Loader.exec_module` is ignored.
 
 Loaders must satisfy the following requirements:
 
- * If the module is a Python module (as opposed to a built-in module or a
-   dynamically loaded extension), the loader should execute the module's code
-   in the module's global name space (``module.__dict__``).
+* If the module is a Python module (as opposed to a built-in module or a
+  dynamically loaded extension), the loader should execute the module's code
+  in the module's global name space (``module.__dict__``).
 
- * If the loader cannot execute the module, it should raise an
-   :exc:`ImportError`, although any other exception raised during
-   :meth:`~importlib.abc.Loader.exec_module` will be propagated.
+* If the loader cannot execute the module, it should raise an
+  :exc:`ImportError`, although any other exception raised during
+  :meth:`~importlib.abc.Loader.exec_module` will be propagated.
 
 In many cases, the finder and loader can be the same object; in such cases the
 :meth:`~importlib.abc.MetaPathFinder.find_spec` method would just return a
@@ -453,20 +453,20 @@ import machinery will create the new module itself.
    functionality described above in addition to executing the module.  All
    the same constraints apply, with some additional clarification:
 
-    * If there is an existing module object with the given name in
-      :data:`sys.modules`, the loader must use that existing module.
-      (Otherwise, :func:`importlib.reload` will not work correctly.)  If the
-      named module does not exist in :data:`sys.modules`, the loader
-      must create a new module object and add it to :data:`sys.modules`.
+   * If there is an existing module object with the given name in
+     :data:`sys.modules`, the loader must use that existing module.
+     (Otherwise, :func:`importlib.reload` will not work correctly.)  If the
+     named module does not exist in :data:`sys.modules`, the loader
+     must create a new module object and add it to :data:`sys.modules`.
 
-    * The module *must* exist in :data:`sys.modules` before the loader
-      executes the module code, to prevent unbounded recursion or multiple
-      loading.
+   * The module *must* exist in :data:`sys.modules` before the loader
+     executes the module code, to prevent unbounded recursion or multiple
+     loading.
 
-    * If loading fails, the loader must remove any modules it has inserted
-      into :data:`sys.modules`, but it must remove **only** the failing
-      module(s), and only if the loader itself has loaded the module(s)
-      explicitly.
+   * If loading fails, the loader must remove any modules it has inserted
+     into :data:`sys.modules`, but it must remove **only** the failing
+     module(s), and only if the loader itself has loaded the module(s)
+     explicitly.
 
 .. versionchanged:: 3.5
    A :exc:`DeprecationWarning` is raised when ``exec_module()`` is defined but
@@ -559,7 +559,7 @@ listed below.
    functionality, for example getting data associated with a loader.
 
    It is **strongly** recommended that you rely on :attr:`__spec__`
-   instead instead of this attribute.
+   instead of this attribute.
 
    .. versionchanged:: 3.12
       The value of ``__loader__`` is expected to be the same as
@@ -580,7 +580,7 @@ listed below.
    relative imports for main modules, as defined in :pep:`366`.
 
    It is **strongly** recommended that you rely on :attr:`__spec__`
-   instead instead of this attribute.
+   instead of this attribute.
 
    .. versionchanged:: 3.6
       The value of ``__package__`` is expected to be the same as
@@ -650,7 +650,7 @@ listed below.
    from a file, that atypical scenario may be appropriate.
 
    It is **strongly** recommended that you rely on :attr:`__spec__`
-   instead instead of ``__cached__``.
+   instead of ``__cached__``.
 
 .. _package-path-rules:
 
@@ -693,17 +693,17 @@ with defaults for whatever information is missing.
 
 Here are the exact rules used:
 
- * If the module has a ``__spec__`` attribute, the information in the spec
-   is used to generate the repr.  The "name", "loader", "origin", and
-   "has_location" attributes are consulted.
+* If the module has a ``__spec__`` attribute, the information in the spec
+  is used to generate the repr.  The "name", "loader", "origin", and
+  "has_location" attributes are consulted.
 
- * If the module has a ``__file__`` attribute, this is used as part of the
-   module's repr.
+* If the module has a ``__file__`` attribute, this is used as part of the
+  module's repr.
 
- * If the module has no ``__file__`` but does have a ``__loader__`` that is not
-   ``None``, then the loader's repr is used as part of the module's repr.
+* If the module has no ``__file__`` but does have a ``__loader__`` that is not
+  ``None``, then the loader's repr is used as part of the module's repr.
 
- * Otherwise, just use the module's ``__name__`` in the repr.
+* Otherwise, just use the module's ``__name__`` in the repr.
 
 .. versionchanged:: 3.12
    Use of :meth:`!module_repr`, having been deprecated since Python 3.4, was
diff --git a/Doc/reference/introduction.rst b/Doc/reference/introduction.rst
index 81f0a5c5d4..cf186705e6 100644
--- a/Doc/reference/introduction.rst
+++ b/Doc/reference/introduction.rst
@@ -90,7 +90,8 @@ Notation
 
 .. index:: BNF, grammar, syntax, notation
 
-The descriptions of lexical analysis and syntax use a modified BNF grammar
+The descriptions of lexical analysis and syntax use a modified
+`Backus–Naur form (BNF) <https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form>`_ grammar
 notation.  This uses the following style of definition:
 
 .. productionlist:: notation
diff --git a/Doc/reference/lexical_analysis.rst b/Doc/reference/lexical_analysis.rst
index 816de9b575..55945e57be 100644
--- a/Doc/reference/lexical_analysis.rst
+++ b/Doc/reference/lexical_analysis.rst
@@ -657,12 +657,12 @@ is more easily recognized as broken.)  It is also important to note that the
 escape sequences only recognized in string literals fall into the category of
 unrecognized escapes for bytes literals.
 
-   .. versionchanged:: 3.6
-      Unrecognized escape sequences produce a :exc:`DeprecationWarning`.
+.. versionchanged:: 3.6
+   Unrecognized escape sequences produce a :exc:`DeprecationWarning`.
 
-   .. versionchanged:: 3.12
-      Unrecognized escape sequences produce a :exc:`SyntaxWarning`. In a future
-      Python version they will be eventually a :exc:`SyntaxError`.
+.. versionchanged:: 3.12
+   Unrecognized escape sequences produce a :exc:`SyntaxWarning`. In a future
+   Python version they will be eventually a :exc:`SyntaxError`.
 
 Even in a raw literal, quotes can be escaped with a backslash, but the
 backslash remains in the result; for example, ``r"\""`` is a valid string
diff --git a/Doc/requirements-oldest-sphinx.txt b/Doc/requirements-oldest-sphinx.txt
index d3ef5bc176..597341d99f 100644
--- a/Doc/requirements-oldest-sphinx.txt
+++ b/Doc/requirements-oldest-sphinx.txt
@@ -13,16 +13,15 @@ python-docs-theme>=2022.1
 # Sphinx 4.2 comes from ``needs_sphinx = '4.2'`` in ``Doc/conf.py``.
 
 alabaster==0.7.13
-Babel==2.12.1
+Babel==2.13.0
 certifi==2023.7.22
-charset-normalizer==3.2.0
-colorama==0.4.6
-docutils==0.16
+charset-normalizer==3.3.0
+docutils==0.17.1
 idna==3.4
 imagesize==1.4.1
-Jinja2==2.11.3
-MarkupSafe==1.1.1
-packaging==23.1
+Jinja2==3.1.2
+MarkupSafe==2.1.3
+packaging==23.2
 Pygments==2.16.1
 requests==2.31.0
 snowballstemmer==2.2.0
@@ -33,4 +32,4 @@ sphinxcontrib-htmlhelp==2.0.1
 sphinxcontrib-jsmath==1.0.1
 sphinxcontrib-qthelp==1.0.3
 sphinxcontrib-serializinghtml==1.1.5
-urllib3==2.0.4
+urllib3==2.0.7
diff --git a/Doc/tools/.nitignore b/Doc/tools/.nitignore
index 90a66ac8a2..c4c97a1cb7 100644
--- a/Doc/tools/.nitignore
+++ b/Doc/tools/.nitignore
@@ -34,8 +34,6 @@ Doc/library/__future__.rst
 Doc/library/abc.rst
 Doc/library/aifc.rst
 Doc/library/ast.rst
-Doc/library/asyncio-dev.rst
-Doc/library/asyncio-eventloop.rst
 Doc/library/asyncio-extending.rst
 Doc/library/asyncio-policy.rst
 Doc/library/asyncio-stream.rst
@@ -44,12 +42,10 @@ Doc/library/asyncio-task.rst
 Doc/library/audioop.rst
 Doc/library/bdb.rst
 Doc/library/bisect.rst
-Doc/library/bz2.rst
 Doc/library/calendar.rst
 Doc/library/cgi.rst
 Doc/library/chunk.rst
 Doc/library/cmd.rst
-Doc/library/codecs.rst
 Doc/library/collections.abc.rst
 Doc/library/collections.rst
 Doc/library/concurrent.futures.rst
@@ -76,7 +72,6 @@ Doc/library/ftplib.rst
 Doc/library/functions.rst
 Doc/library/functools.rst
 Doc/library/getopt.rst
-Doc/library/getpass.rst
 Doc/library/gettext.rst
 Doc/library/gzip.rst
 Doc/library/http.client.rst
@@ -115,12 +110,10 @@ Doc/library/reprlib.rst
 Doc/library/resource.rst
 Doc/library/rlcompleter.rst
 Doc/library/select.rst
-Doc/library/selectors.rst
 Doc/library/shelve.rst
 Doc/library/signal.rst
 Doc/library/smtplib.rst
 Doc/library/socket.rst
-Doc/library/socketserver.rst
 Doc/library/ssl.rst
 Doc/library/stdtypes.rst
 Doc/library/string.rst
@@ -132,13 +125,11 @@ Doc/library/telnetlib.rst
 Doc/library/tempfile.rst
 Doc/library/termios.rst
 Doc/library/test.rst
-Doc/library/time.rst
 Doc/library/tkinter.rst
 Doc/library/tkinter.scrolledtext.rst
 Doc/library/tkinter.tix.rst
 Doc/library/tkinter.ttk.rst
 Doc/library/traceback.rst
-Doc/library/tty.rst
 Doc/library/unittest.mock.rst
 Doc/library/unittest.rst
 Doc/library/urllib.parse.rst
@@ -162,8 +153,6 @@ Doc/reference/expressions.rst
 Doc/reference/import.rst
 Doc/reference/simple_stmts.rst
 Doc/tutorial/datastructures.rst
-Doc/tutorial/introduction.rst
-Doc/using/cmdline.rst
 Doc/using/windows.rst
 Doc/whatsnew/2.0.rst
 Doc/whatsnew/2.1.rst
diff --git a/Doc/tools/extensions/pyspecific.py b/Doc/tools/extensions/pyspecific.py
index c286bcf34f..cdb8cf85e2 100644
--- a/Doc/tools/extensions/pyspecific.py
+++ b/Doc/tools/extensions/pyspecific.py
@@ -607,6 +607,13 @@ def parse_pdb_command(env, sig, signode):
     return fullname
 
 
+def parse_monitoring_event(env, sig, signode):
+    """Transform a monitoring event signature into RST nodes."""
+    signode += addnodes.desc_addname('sys.monitoring.events.', 'sys.monitoring.events.')
+    signode += addnodes.desc_name(sig, sig)
+    return sig
+
+
 def process_audit_events(app, doctree, fromdocname):
     for node in doctree.traverse(audit_event_list):
         break
@@ -707,6 +714,7 @@ def setup(app):
     app.add_builder(PydocTopicsBuilder)
     app.add_object_type('opcode', 'opcode', '%s (opcode)', parse_opcode_signature)
     app.add_object_type('pdbcommand', 'pdbcmd', '%s (pdb command)', parse_pdb_command)
+    app.add_object_type('monitoring-event', 'monitoring-event', '%s (monitoring event)', parse_monitoring_event)
     app.add_object_type('2to3fixer', '2to3fixer', '%s (2to3 fixer)')
     app.add_directive_to_domain('py', 'decorator', PyDecoratorFunction)
     app.add_directive_to_domain('py', 'decoratormethod', PyDecoratorMethod)
diff --git a/Doc/tools/templates/download.html b/Doc/tools/templates/download.html
index 7920e0619f..b5353d6fb7 100644
--- a/Doc/tools/templates/download.html
+++ b/Doc/tools/templates/download.html
@@ -49,12 +49,12 @@ <h2>Unpacking</h2>
 
 <p>Unix users should download the .tar.bz2 archives; these are bzipped tar
 archives and can be handled in the usual way using tar and the bzip2
-program. The <a href="http://www.info-zip.org">InfoZIP</a> unzip program can be
+program. The <a href="https://infozip.sourceforge.net">Info-ZIP</a> unzip program can be
 used to handle the ZIP archives if desired. The .tar.bz2 archives provide the
 best compression and fastest download times.</p>
 
 <p>Windows users can use the ZIP archives since those are customary on that
-platform. These are created on Unix using the InfoZIP zip program.</p>
+platform. These are created on Unix using the Info-ZIP zip program.</p>
 
 
 <h2>Problems</h2>
diff --git a/Doc/tutorial/floatingpoint.rst b/Doc/tutorial/floatingpoint.rst
index b88055a41f..30f3dfb6b2 100644
--- a/Doc/tutorial/floatingpoint.rst
+++ b/Doc/tutorial/floatingpoint.rst
@@ -137,7 +137,7 @@ the :func:`math.isclose` function can be useful for comparing inexact values:
    True
 
 Alternatively, the :func:`round` function can be used to compare rough
-approximations::
+approximations:
 
 .. doctest::
 
diff --git a/Doc/tutorial/interactive.rst b/Doc/tutorial/interactive.rst
index 0d3896a483..4e054c4e6c 100644
--- a/Doc/tutorial/interactive.rst
+++ b/Doc/tutorial/interactive.rst
@@ -51,4 +51,4 @@ bpython_.
 
 .. _GNU Readline: https://tiswww.case.edu/php/chet/readline/rltop.html
 .. _IPython: https://ipython.org/
-.. _bpython: https://www.bpython-interpreter.org/
+.. _bpython: https://bpython-interpreter.org/
diff --git a/Doc/tutorial/introduction.rst b/Doc/tutorial/introduction.rst
index 0fc75c7d75..4536ab9486 100644
--- a/Doc/tutorial/introduction.rst
+++ b/Doc/tutorial/introduction.rst
@@ -428,7 +428,7 @@ type, i.e. it is possible to change their content::
     [1, 8, 27, 64, 125]
 
 You can also add new items at the end of the list, by using
-the :meth:`~list.append` *method* (we will see more about methods later)::
+the :meth:`!list.append` *method* (we will see more about methods later)::
 
    >>> cubes.append(216)  # add the cube of 6
    >>> cubes.append(7 ** 3)  # and the cube of 7
@@ -480,7 +480,7 @@ First Steps Towards Programming
 
 Of course, we can use Python for more complicated tasks than adding two and two
 together.  For instance, we can write an initial sub-sequence of the
-`Fibonacci series <https://en.wikipedia.org/wiki/Fibonacci_number>`_
+`Fibonacci series <https://en.wikipedia.org/wiki/Fibonacci_sequence>`_
 as follows::
 
    >>> # Fibonacci series:
diff --git a/Doc/using/cmdline.rst b/Doc/using/cmdline.rst
index bade3ca665..6b60b28606 100644
--- a/Doc/using/cmdline.rst
+++ b/Doc/using/cmdline.rst
@@ -59,7 +59,7 @@ all consecutive arguments will end up in :data:`sys.argv` -- note that the first
 element, subscript zero (``sys.argv[0]``), is a string reflecting the program's
 source.
 
-.. cmdoption:: -c <command>
+.. option:: -c <command>
 
    Execute the Python code in *command*.  *command* can be one or more
    statements separated by newlines, with significant leading whitespace as in
@@ -72,7 +72,7 @@ source.
 
    .. audit-event:: cpython.run_command command cmdoption-c
 
-.. cmdoption:: -m <module-name>
+.. option:: -m <module-name>
 
    Search :data:`sys.path` for the named module and execute its contents as
    the :mod:`__main__` module.
@@ -103,7 +103,7 @@ source.
 
    :option:`-I` option can  be used to run the script in isolated mode where
    :data:`sys.path` contains neither the current directory nor the user's
-   site-packages directory. All :envvar:`PYTHON*` environment variables are
+   site-packages directory. All ``PYTHON*`` environment variables are
    ignored, too.
 
    Many standard library modules contain code that is invoked on their execution
@@ -161,7 +161,7 @@ source.
 
    :option:`-I` option can  be used to run the script in isolated mode where
    :data:`sys.path` contains neither the script's directory nor the user's
-   site-packages directory. All :envvar:`PYTHON*` environment variables are
+   site-packages directory. All ``PYTHON*`` environment variables are
    ignored, too.
 
    .. audit-event:: cpython.run_file filename
@@ -188,35 +188,35 @@ automatically enabled, if available on your platform (see
 Generic options
 ~~~~~~~~~~~~~~~
 
-.. cmdoption:: -?
-               -h
-               --help
+.. option:: -?
+            -h
+            --help
 
    Print a short description of all command line options and corresponding
    environment variables and exit.
 
-.. cmdoption:: --help-env
+.. option:: --help-env
 
    Print a short description of Python-specific environment variables
    and exit.
 
    .. versionadded:: 3.11
 
-.. cmdoption:: --help-xoptions
+.. option:: --help-xoptions
 
    Print a description of implementation-specific :option:`-X` options
    and exit.
 
    .. versionadded:: 3.11
 
-.. cmdoption:: --help-all
+.. option:: --help-all
 
    Print complete usage information and exit.
 
    .. versionadded:: 3.11
 
-.. cmdoption:: -V
-               --version
+.. option:: -V
+            --version
 
    Print the Python version number and exit.  Example output could be:
 
@@ -240,7 +240,7 @@ Generic options
 Miscellaneous options
 ~~~~~~~~~~~~~~~~~~~~~
 
-.. cmdoption:: -b
+.. option:: -b
 
    Issue a warning when comparing :class:`bytes` or :class:`bytearray` with
    :class:`str` or :class:`bytes` with :class:`int`.  Issue an error when the
@@ -249,13 +249,13 @@ Miscellaneous options
    .. versionchanged:: 3.5
       Affects comparisons of :class:`bytes` with :class:`int`.
 
-.. cmdoption:: -B
+.. option:: -B
 
    If given, Python won't try to write ``.pyc`` files on the
    import of source modules.  See also :envvar:`PYTHONDONTWRITEBYTECODE`.
 
 
-.. cmdoption:: --check-hash-based-pycs default|always|never
+.. option:: --check-hash-based-pycs default|always|never
 
    Control the validation behavior of hash-based ``.pyc`` files. See
    :ref:`pyc-invalidation`. When set to ``default``, checked and unchecked
@@ -269,7 +269,7 @@ Miscellaneous options
    option.
 
 
-.. cmdoption:: -d
+.. option:: -d
 
    Turn on parser debugging output (for expert only).
    See also the :envvar:`PYTHONDEBUG` environment variable.
@@ -278,15 +278,15 @@ Miscellaneous options
    it's ignored.
 
 
-.. cmdoption:: -E
+.. option:: -E
 
-   Ignore all :envvar:`PYTHON*` environment variables, e.g.
+   Ignore all ``PYTHON*`` environment variables, e.g.
    :envvar:`PYTHONPATH` and :envvar:`PYTHONHOME`, that might be set.
 
    See also the :option:`-P` and :option:`-I` (isolated) options.
 
 
-.. cmdoption:: -i
+.. option:: -i
 
    When a script is passed as first argument or the :option:`-c` option is used,
    enter interactive mode after executing the script or the command, even when
@@ -297,20 +297,20 @@ Miscellaneous options
    raises an exception.  See also :envvar:`PYTHONINSPECT`.
 
 
-.. cmdoption:: -I
+.. option:: -I
 
    Run Python in isolated mode. This also implies :option:`-E`, :option:`-P`
    and :option:`-s` options.
 
    In isolated mode :data:`sys.path` contains neither the script's directory nor
-   the user's site-packages directory. All :envvar:`PYTHON*` environment
+   the user's site-packages directory. All ``PYTHON*`` environment
    variables are ignored, too. Further restrictions may be imposed to prevent
    the user from injecting malicious code.
 
    .. versionadded:: 3.4
 
 
-.. cmdoption:: -O
+.. option:: -O
 
    Remove assert statements and any code conditional on the value of
    :const:`__debug__`.  Augment the filename for compiled
@@ -321,7 +321,7 @@ Miscellaneous options
       Modify ``.pyc`` filenames according to :pep:`488`.
 
 
-.. cmdoption:: -OO
+.. option:: -OO
 
    Do :option:`-O` and also discard docstrings.  Augment the filename
    for compiled (:term:`bytecode`) files by adding ``.opt-2`` before the
@@ -331,7 +331,7 @@ Miscellaneous options
       Modify ``.pyc`` filenames according to :pep:`488`.
 
 
-.. cmdoption:: -P
+.. option:: -P
 
    Don't prepend a potentially unsafe path to :data:`sys.path`:
 
@@ -348,21 +348,21 @@ Miscellaneous options
    .. versionadded:: 3.11
 
 
-.. cmdoption:: -q
+.. option:: -q
 
    Don't display the copyright and version messages even in interactive mode.
 
    .. versionadded:: 3.2
 
 
-.. cmdoption:: -R
+.. option:: -R
 
    Turn on hash randomization. This option only has an effect if the
    :envvar:`PYTHONHASHSEED` environment variable is set to ``0``, since hash
    randomization is enabled by default.
 
    On previous versions of Python, this option turns on hash randomization,
-   so that the :meth:`__hash__` values of str and bytes objects
+   so that the :meth:`~object.__hash__` values of str and bytes objects
    are "salted" with an unpredictable random value.  Although they remain
    constant within an individual Python process, they are not predictable
    between repeated invocations of Python.
@@ -381,7 +381,7 @@ Miscellaneous options
    .. versionadded:: 3.2.3
 
 
-.. cmdoption:: -s
+.. option:: -s
 
    Don't add the :data:`user site-packages directory <site.USER_SITE>` to
    :data:`sys.path`.
@@ -391,7 +391,7 @@ Miscellaneous options
       :pep:`370` -- Per user site-packages directory
 
 
-.. cmdoption:: -S
+.. option:: -S
 
    Disable the import of the module :mod:`site` and the site-dependent
    manipulations of :data:`sys.path` that it entails.  Also disable these
@@ -399,7 +399,7 @@ Miscellaneous options
    :func:`site.main` if you want them to be triggered).
 
 
-.. cmdoption:: -u
+.. option:: -u
 
    Force the stdout and stderr streams to be unbuffered.  This option has no
    effect on the stdin stream.
@@ -410,7 +410,7 @@ Miscellaneous options
       The text layer of the stdout and stderr streams now is unbuffered.
 
 
-.. cmdoption:: -v
+.. option:: -v
 
    Print a message each time a module is initialized, showing the place
    (filename or built-in module) from which it is loaded.  When given twice
@@ -425,7 +425,7 @@ Miscellaneous options
 
 
 .. _using-on-warnings:
-.. cmdoption:: -W arg
+.. option:: -W arg
 
    Warning control. Python's warning machinery by default prints warning
    messages to :data:`sys.stderr`.
@@ -484,13 +484,13 @@ Miscellaneous options
    details.
 
 
-.. cmdoption:: -x
+.. option:: -x
 
    Skip the first line of the source, allowing use of non-Unix forms of
    ``#!cmd``.  This is intended for a DOS specific hack only.
 
 
-.. cmdoption:: -X
+.. option:: -X
 
    Reserved for various implementation-specific options.  CPython currently
    defines the following possible values:
@@ -597,7 +597,7 @@ Miscellaneous options
 Options you shouldn't use
 ~~~~~~~~~~~~~~~~~~~~~~~~~
 
-.. cmdoption:: -J
+.. option:: -J
 
    Reserved for use by Jython_.
 
@@ -851,9 +851,10 @@ conflict.
 
    If this environment variable is set to a non-empty string,
    :func:`faulthandler.enable` is called at startup: install a handler for
-   :const:`SIGSEGV`, :const:`SIGFPE`, :const:`SIGABRT`, :const:`SIGBUS` and
-   :const:`SIGILL` signals to dump the Python traceback.  This is equivalent to
-   :option:`-X` ``faulthandler`` option.
+   :const:`~signal.SIGSEGV`, :const:`~signal.SIGFPE`,
+   :const:`~signal.SIGABRT`, :const:`~signal.SIGBUS` and
+   :const:`~signal.SIGILL` signals to dump the Python traceback.
+   This is equivalent to :option:`-X` ``faulthandler`` option.
 
    .. versionadded:: 3.3
 
diff --git a/Doc/using/configure.rst b/Doc/using/configure.rst
index 3fe2a63587..11b6b53f8b 100644
--- a/Doc/using/configure.rst
+++ b/Doc/using/configure.rst
@@ -80,7 +80,7 @@ See also the :file:`Misc/SpecialBuilds.txt` in the Python source distribution.
 General Options
 ---------------
 
-.. cmdoption:: --enable-loadable-sqlite-extensions
+.. option:: --enable-loadable-sqlite-extensions
 
    Support loadable extensions in the :mod:`!_sqlite` extension module (default
    is no) of the :mod:`sqlite3` module.
@@ -90,12 +90,12 @@ General Options
 
    .. versionadded:: 3.6
 
-.. cmdoption:: --disable-ipv6
+.. option:: --disable-ipv6
 
    Disable IPv6 support (enabled by default if supported), see the
    :mod:`socket` module.
 
-.. cmdoption:: --enable-big-digits=[15|30]
+.. option:: --enable-big-digits=[15|30]
 
    Define the size in bits of Python :class:`int` digits: 15 or 30 bits.
 
@@ -105,7 +105,7 @@ General Options
 
    See :data:`sys.int_info.bits_per_digit <sys.int_info>`.
 
-.. cmdoption:: --with-suffix=SUFFIX
+.. option:: --with-suffix=SUFFIX
 
    Set the Python executable suffix to *SUFFIX*.
 
@@ -118,7 +118,7 @@ General Options
       The default suffix on WASM platform is one of ``.js``, ``.html``
       or ``.wasm``.
 
-.. cmdoption:: --with-tzpath=<list of absolute paths separated by pathsep>
+.. option:: --with-tzpath=<list of absolute paths separated by pathsep>
 
    Select the default time zone search path for :const:`zoneinfo.TZPATH`.
    See the :ref:`Compile-time configuration
@@ -130,7 +130,7 @@ General Options
 
    .. versionadded:: 3.9
 
-.. cmdoption:: --without-decimal-contextvar
+.. option:: --without-decimal-contextvar
 
    Build the ``_decimal`` extension module using a thread-local context rather
    than a coroutine-local context (default), see the :mod:`decimal` module.
@@ -139,7 +139,7 @@ General Options
 
    .. versionadded:: 3.9
 
-.. cmdoption:: --with-dbmliborder=<list of backend names>
+.. option:: --with-dbmliborder=<list of backend names>
 
    Override order to check db backends for the :mod:`dbm` module
 
@@ -149,7 +149,7 @@ General Options
    * ``gdbm``;
    * ``bdb``.
 
-.. cmdoption:: --without-c-locale-coercion
+.. option:: --without-c-locale-coercion
 
    Disable C locale coercion to a UTF-8 based locale (enabled by default).
 
@@ -157,13 +157,13 @@ General Options
 
    See :envvar:`PYTHONCOERCECLOCALE` and the :pep:`538`.
 
-.. cmdoption:: --without-freelists
+.. option:: --without-freelists
 
    Disable all freelists except the empty tuple singleton.
 
    .. versionadded:: 3.11
 
-.. cmdoption:: --with-platlibdir=DIRNAME
+.. option:: --with-platlibdir=DIRNAME
 
    Python library directory name (default is ``lib``).
 
@@ -173,7 +173,7 @@ General Options
 
    .. versionadded:: 3.9
 
-.. cmdoption:: --with-wheel-pkg-dir=PATH
+.. option:: --with-wheel-pkg-dir=PATH
 
    Directory of wheel packages used by the :mod:`ensurepip` module
    (none by default).
@@ -185,7 +185,7 @@ General Options
 
    .. versionadded:: 3.10
 
-.. cmdoption:: --with-pkg-config=[check|yes|no]
+.. option:: --with-pkg-config=[check|yes|no]
 
    Whether configure should use :program:`pkg-config` to detect build
    dependencies.
@@ -196,7 +196,7 @@ General Options
 
    .. versionadded:: 3.11
 
-.. cmdoption:: --enable-pystats
+.. option:: --enable-pystats
 
    Turn on internal statistics gathering.
 
@@ -211,7 +211,7 @@ General Options
 WebAssembly Options
 -------------------
 
-.. cmdoption:: --with-emscripten-target=[browser|node]
+.. option:: --with-emscripten-target=[browser|node]
 
    Set build flavor for ``wasm32-emscripten``.
 
@@ -220,7 +220,7 @@ WebAssembly Options
 
    .. versionadded:: 3.11
 
-.. cmdoption:: --enable-wasm-dynamic-linking
+.. option:: --enable-wasm-dynamic-linking
 
    Turn on dynamic linking support for WASM.
 
@@ -229,7 +229,7 @@ WebAssembly Options
 
    .. versionadded:: 3.11
 
-.. cmdoption:: --enable-wasm-pthreads
+.. option:: --enable-wasm-pthreads
 
    Turn on pthreads support for WASM.
 
@@ -239,7 +239,7 @@ WebAssembly Options
 Install Options
 ---------------
 
-.. cmdoption:: --prefix=PREFIX
+.. option:: --prefix=PREFIX
 
    Install architecture-independent files in PREFIX. On Unix, it
    defaults to :file:`/usr/local`.
@@ -249,20 +249,20 @@ Install Options
    As an example, one can use ``--prefix="$HOME/.local/"`` to install
    a Python in its home directory.
 
-.. cmdoption:: --exec-prefix=EPREFIX
+.. option:: --exec-prefix=EPREFIX
 
    Install architecture-dependent files in EPREFIX, defaults to :option:`--prefix`.
 
    This value can be retrieved at runtime using :data:`sys.exec_prefix`.
 
-.. cmdoption:: --disable-test-modules
+.. option:: --disable-test-modules
 
    Don't build nor install test modules, like the :mod:`test` package or the
    :mod:`!_testcapi` extension module (built and installed by default).
 
    .. versionadded:: 3.10
 
-.. cmdoption:: --with-ensurepip=[upgrade|install|no]
+.. option:: --with-ensurepip=[upgrade|install|no]
 
    Select the :mod:`ensurepip` command run on Python installation:
 
@@ -281,7 +281,7 @@ Configuring Python using ``--enable-optimizations --with-lto`` (PGO + LTO) is
 recommended for best performance. The experimental ``--enable-bolt`` flag can
 also be used to improve performance.
 
-.. cmdoption:: --enable-optimizations
+.. option:: --enable-optimizations
 
    Enable Profile Guided Optimization (PGO) using :envvar:`PROFILE_TASK`
    (disabled by default).
@@ -307,7 +307,7 @@ also be used to improve performance.
 
    .. versionadded:: 3.8
 
-.. cmdoption:: --with-lto=[full|thin|no|yes]
+.. option:: --with-lto=[full|thin|no|yes]
 
    Enable Link Time Optimization (LTO) in any build (disabled by default).
 
@@ -322,7 +322,7 @@ also be used to improve performance.
    .. versionchanged:: 3.12
       Use ThinLTO as the default optimization policy on Clang if the compiler accepts the flag.
 
-.. cmdoption:: --enable-bolt
+.. option:: --enable-bolt
 
    Enable usage of the `BOLT post-link binary optimizer
    <https://github.com/llvm/llvm-project/tree/main/bolt>`_ (disabled by
@@ -347,19 +347,19 @@ also be used to improve performance.
 
    .. versionadded:: 3.12
 
-.. cmdoption:: --with-computed-gotos
+.. option:: --with-computed-gotos
 
    Enable computed gotos in evaluation loop (enabled by default on supported
    compilers).
 
-.. cmdoption:: --without-pymalloc
+.. option:: --without-pymalloc
 
    Disable the specialized Python memory allocator :ref:`pymalloc <pymalloc>`
    (enabled by default).
 
    See also :envvar:`PYTHONMALLOC` environment variable.
 
-.. cmdoption:: --without-doc-strings
+.. option:: --without-doc-strings
 
    Disable static documentation strings to reduce the memory footprint (enabled
    by default). Documentation strings defined in Python are not affected.
@@ -368,11 +368,11 @@ also be used to improve performance.
 
    See the ``PyDoc_STRVAR()`` macro.
 
-.. cmdoption:: --enable-profiling
+.. option:: --enable-profiling
 
    Enable C-level code profiling with ``gprof`` (disabled by default).
 
-.. cmdoption:: --with-strict-overflow
+.. option:: --with-strict-overflow
 
    Add ``-fstrict-overflow`` to the C compiler flags (by default we add
    ``-fno-strict-overflow`` instead).
@@ -429,12 +429,12 @@ See also the :ref:`Python Development Mode <devmode>` and the
 Debug options
 -------------
 
-.. cmdoption:: --with-pydebug
+.. option:: --with-pydebug
 
    :ref:`Build Python in debug mode <debug-build>`: define the ``Py_DEBUG``
    macro (disabled by default).
 
-.. cmdoption:: --with-trace-refs
+.. option:: --with-trace-refs
 
    Enable tracing references for debugging purpose (disabled by default).
 
@@ -449,7 +449,7 @@ Debug options
 
    .. versionadded:: 3.8
 
-.. cmdoption:: --with-assertions
+.. option:: --with-assertions
 
    Build with C assertions enabled (default is no): ``assert(...);`` and
    ``_PyObject_ASSERT(...);``.
@@ -462,11 +462,11 @@ Debug options
 
    .. versionadded:: 3.6
 
-.. cmdoption:: --with-valgrind
+.. option:: --with-valgrind
 
    Enable Valgrind support (default is no).
 
-.. cmdoption:: --with-dtrace
+.. option:: --with-dtrace
 
    Enable DTrace support (default is no).
 
@@ -475,19 +475,19 @@ Debug options
 
    .. versionadded:: 3.6
 
-.. cmdoption:: --with-address-sanitizer
+.. option:: --with-address-sanitizer
 
    Enable AddressSanitizer memory error detector, ``asan`` (default is no).
 
    .. versionadded:: 3.6
 
-.. cmdoption:: --with-memory-sanitizer
+.. option:: --with-memory-sanitizer
 
    Enable MemorySanitizer allocation error detector, ``msan`` (default is no).
 
    .. versionadded:: 3.6
 
-.. cmdoption:: --with-undefined-behavior-sanitizer
+.. option:: --with-undefined-behavior-sanitizer
 
    Enable UndefinedBehaviorSanitizer undefined behaviour detector, ``ubsan``
    (default is no).
@@ -498,11 +498,11 @@ Debug options
 Linker options
 --------------
 
-.. cmdoption:: --enable-shared
+.. option:: --enable-shared
 
    Enable building a shared Python library: ``libpython`` (default is no).
 
-.. cmdoption:: --without-static-libpython
+.. option:: --without-static-libpython
 
    Do not build ``libpythonMAJOR.MINOR.a`` and do not install ``python.o``
    (built and enabled by default).
@@ -513,23 +513,23 @@ Linker options
 Libraries options
 -----------------
 
-.. cmdoption:: --with-libs='lib1 ...'
+.. option:: --with-libs='lib1 ...'
 
    Link against additional libraries (default is no).
 
-.. cmdoption:: --with-system-expat
+.. option:: --with-system-expat
 
    Build the :mod:`!pyexpat` module using an installed ``expat`` library
    (default is no).
 
-.. cmdoption:: --with-system-libmpdec
+.. option:: --with-system-libmpdec
 
    Build the ``_decimal`` extension module using an installed ``mpdec``
    library, see the :mod:`decimal` module (default is no).
 
    .. versionadded:: 3.3
 
-.. cmdoption:: --with-readline=editline
+.. option:: --with-readline=editline
 
    Use ``editline`` library for backend of the :mod:`readline` module.
 
@@ -537,7 +537,7 @@ Libraries options
 
    .. versionadded:: 3.10
 
-.. cmdoption:: --without-readline
+.. option:: --without-readline
 
    Don't build the :mod:`readline` module (built by default).
 
@@ -545,21 +545,21 @@ Libraries options
 
    .. versionadded:: 3.10
 
-.. cmdoption:: --with-libm=STRING
+.. option:: --with-libm=STRING
 
    Override ``libm`` math library to *STRING* (default is system-dependent).
 
-.. cmdoption:: --with-libc=STRING
+.. option:: --with-libc=STRING
 
    Override ``libc`` C library to *STRING* (default is system-dependent).
 
-.. cmdoption:: --with-openssl=DIR
+.. option:: --with-openssl=DIR
 
    Root of the OpenSSL directory.
 
    .. versionadded:: 3.7
 
-.. cmdoption:: --with-openssl-rpath=[no|auto|DIR]
+.. option:: --with-openssl-rpath=[no|auto|DIR]
 
    Set runtime library directory (rpath) for OpenSSL libraries:
 
@@ -574,7 +574,7 @@ Libraries options
 Security Options
 ----------------
 
-.. cmdoption:: --with-hash-algorithm=[fnv|siphash13|siphash24]
+.. option:: --with-hash-algorithm=[fnv|siphash13|siphash24]
 
    Select hash algorithm for use in ``Python/pyhash.c``:
 
@@ -587,7 +587,7 @@ Security Options
    .. versionadded:: 3.11
       ``siphash13`` is added and it is the new default.
 
-.. cmdoption:: --with-builtin-hashlib-hashes=md5,sha1,sha256,sha512,sha3,blake2
+.. option:: --with-builtin-hashlib-hashes=md5,sha1,sha256,sha512,sha3,blake2
 
    Built-in hash modules:
 
@@ -600,7 +600,7 @@ Security Options
 
    .. versionadded:: 3.9
 
-.. cmdoption:: --with-ssl-default-suites=[python|openssl|STRING]
+.. option:: --with-ssl-default-suites=[python|openssl|STRING]
 
    Override the OpenSSL default cipher suites string:
 
@@ -622,19 +622,19 @@ macOS Options
 
 See ``Mac/README.rst``.
 
-.. cmdoption:: --enable-universalsdk
-.. cmdoption:: --enable-universalsdk=SDKDIR
+.. option:: --enable-universalsdk
+.. option:: --enable-universalsdk=SDKDIR
 
    Create a universal binary build. *SDKDIR* specifies which macOS SDK should
    be used to perform the build (default is no).
 
-.. cmdoption:: --enable-framework
-.. cmdoption:: --enable-framework=INSTALLDIR
+.. option:: --enable-framework
+.. option:: --enable-framework=INSTALLDIR
 
    Create a Python.framework rather than a traditional Unix install. Optional
    *INSTALLDIR* specifies the installation path (default is no).
 
-.. cmdoption:: --with-universal-archs=ARCH
+.. option:: --with-universal-archs=ARCH
 
    Specify the kind of universal binary that should be created. This option is
    only valid when :option:`--enable-universalsdk` is set.
@@ -650,7 +650,7 @@ See ``Mac/README.rst``.
    * ``intel-64``;
    * ``all``.
 
-.. cmdoption:: --with-framework-name=FRAMEWORK
+.. option:: --with-framework-name=FRAMEWORK
 
    Specify the name for the python framework on macOS only valid when
    :option:`--enable-framework` is set (default: ``Python``).
@@ -664,21 +664,21 @@ for another CPU architecture or platform. Cross compiling requires a Python
 interpreter for the build platform. The version of the build Python must match
 the version of the cross compiled host Python.
 
-.. cmdoption:: --build=BUILD
+.. option:: --build=BUILD
 
    configure for building on BUILD, usually guessed by :program:`config.guess`.
 
-.. cmdoption:: --host=HOST
+.. option:: --host=HOST
 
    cross-compile to build programs to run on HOST (target platform)
 
-.. cmdoption:: --with-build-python=path/to/python
+.. option:: --with-build-python=path/to/python
 
    path to build ``python`` binary for cross compiling
 
    .. versionadded:: 3.11
 
-.. cmdoption:: CONFIG_SITE=file
+.. option:: CONFIG_SITE=file
 
    An environment variable that points to a file with configure overrides.
 
diff --git a/Doc/using/windows.rst b/Doc/using/windows.rst
index 919b76f281..e5843eeeb5 100644
--- a/Doc/using/windows.rst
+++ b/Doc/using/windows.rst
@@ -1187,21 +1187,22 @@ Otherwise, your users may experience problems using your application. Note that
 the first suggestion is the best, as the others may still be susceptible to
 non-standard paths in the registry and user site-packages.
 
-.. versionchanged::
-   3.6
+.. versionchanged:: 3.6
+
+   Add ``._pth`` file support and removes ``applocal`` option from
+   ``pyvenv.cfg``.
+
+.. versionchanged:: 3.6
 
-      * Adds ``._pth`` file support and removes ``applocal`` option from
-        ``pyvenv.cfg``.
-      * Adds :file:`python{XX}.zip` as a potential landmark when directly adjacent
-        to the executable.
+   Add :file:`python{XX}.zip` as a potential landmark when directly adjacent
+   to the executable.
 
-.. deprecated::
-   3.6
+.. deprecated:: 3.6
 
-      Modules specified in the registry under ``Modules`` (not ``PythonPath``)
-      may be imported by :class:`importlib.machinery.WindowsRegistryFinder`.
-      This finder is enabled on Windows in 3.6.0 and earlier, but may need to
-      be explicitly added to :data:`sys.meta_path` in the future.
+   Modules specified in the registry under ``Modules`` (not ``PythonPath``)
+   may be imported by :class:`importlib.machinery.WindowsRegistryFinder`.
+   This finder is enabled on Windows in 3.6.0 and earlier, but may need to
+   be explicitly added to :data:`sys.meta_path` in the future.
 
 Additional modules
 ==================
diff --git a/Doc/whatsnew/2.2.rst b/Doc/whatsnew/2.2.rst
index d9ead57413..6dfe79cef0 100644
--- a/Doc/whatsnew/2.2.rst
+++ b/Doc/whatsnew/2.2.rst
@@ -424,22 +424,22 @@ Another significant addition to 2.2 is an iteration interface at both the C and
 Python levels.  Objects can define how they can be looped over by callers.
 
 In Python versions up to 2.1, the usual way to make ``for item in obj`` work is
-to define a :meth:`__getitem__` method that looks something like this::
+to define a :meth:`~object.__getitem__` method that looks something like this::
 
    def __getitem__(self, index):
        return <next item>
 
-:meth:`__getitem__` is more properly used to define an indexing operation on an
+:meth:`~object.__getitem__` is more properly used to define an indexing operation on an
 object so that you can write ``obj[5]`` to retrieve the sixth element.  It's a
 bit misleading when you're using this only to support :keyword:`for` loops.
 Consider some file-like object that wants to be looped over; the *index*
 parameter is essentially meaningless, as the class probably assumes that a
-series of :meth:`__getitem__` calls will be made with *index* incrementing by
-one each time.  In other words, the presence of the :meth:`__getitem__` method
+series of :meth:`~object.__getitem__` calls will be made with *index* incrementing by
+one each time.  In other words, the presence of the :meth:`~object.__getitem__` method
 doesn't mean that using ``file[5]``  to randomly access the sixth element will
 work, though it really should.
 
-In Python 2.2, iteration can be implemented separately, and :meth:`__getitem__`
+In Python 2.2, iteration can be implemented separately, and :meth:`~object.__getitem__`
 methods can be limited to classes that really do support random access.  The
 basic idea of iterators is  simple.  A new built-in function, ``iter(obj)``
 or ``iter(C, sentinel)``, is used to get an iterator. ``iter(obj)`` returns
diff --git a/Doc/whatsnew/2.3.rst b/Doc/whatsnew/2.3.rst
index 0442c9fdd0..be5b3026d9 100644
--- a/Doc/whatsnew/2.3.rst
+++ b/Doc/whatsnew/2.3.rst
@@ -925,7 +925,7 @@ Deletion is more straightforward::
    >>> a
    [1, 3]
 
-One can also now pass slice objects to the :meth:`__getitem__` methods of the
+One can also now pass slice objects to the :meth:`~object.__getitem__` methods of the
 built-in sequences::
 
    >>> range(10).__getitem__(slice(0, 5, 2))
@@ -1596,7 +1596,7 @@ complete list of changes, or look through the CVS logs for all the details.
   module.
 
   Adding the mix-in as a superclass provides the full dictionary interface
-  whenever the class defines :meth:`__getitem__`, :meth:`__setitem__`,
+  whenever the class defines :meth:`~object.__getitem__`, :meth:`__setitem__`,
   :meth:`__delitem__`, and :meth:`keys`. For example::
 
      >>> import UserDict
diff --git a/Doc/whatsnew/2.5.rst b/Doc/whatsnew/2.5.rst
index f58b3ede27..3608153db0 100644
--- a/Doc/whatsnew/2.5.rst
+++ b/Doc/whatsnew/2.5.rst
@@ -575,15 +575,15 @@ structure is::
        with-block
 
 The expression is evaluated, and it should result in an object that supports the
-context management protocol (that is, has :meth:`__enter__` and :meth:`__exit__`
+context management protocol (that is, has :meth:`~object.__enter__` and :meth:`~object.__exit__`
 methods.
 
-The object's :meth:`__enter__` is called before *with-block* is executed and
+The object's :meth:`~object.__enter__` is called before *with-block* is executed and
 therefore can run set-up code. It also may return a value that is bound to the
 name *variable*, if given.  (Note carefully that *variable* is *not* assigned
 the result of *expression*.)
 
-After execution of the *with-block* is finished, the object's :meth:`__exit__`
+After execution of the *with-block* is finished, the object's :meth:`~object.__exit__`
 method is called, even if the block raised an exception, and can therefore run
 clean-up code.
 
@@ -609,7 +609,7 @@ part-way through the block.
 .. note::
 
    In this case, *f* is the same object created by :func:`open`, because
-   :meth:`file.__enter__` returns *self*.
+   :meth:`~object.__enter__` returns *self*.
 
 The :mod:`threading` module's locks and condition variables  also support the
 ':keyword:`with`' statement::
@@ -652,10 +652,10 @@ underlying implementation and should keep reading.
 A high-level explanation of the context management protocol is:
 
 * The expression is evaluated and should result in an object called a "context
-  manager".  The context manager must have :meth:`__enter__` and :meth:`__exit__`
+  manager".  The context manager must have :meth:`~object.__enter__` and :meth:`~object.__exit__`
   methods.
 
-* The context manager's :meth:`__enter__` method is called.  The value returned
+* The context manager's :meth:`~object.__enter__` method is called.  The value returned
   is assigned to *VAR*.  If no ``'as VAR'`` clause is present, the value is simply
   discarded.
 
@@ -669,7 +669,7 @@ A high-level explanation of the context management protocol is:
   if you do the author of the code containing the ':keyword:`with`' statement will
   never realize anything went wrong.
 
-* If *BLOCK* didn't raise an exception,  the :meth:`__exit__` method is still
+* If *BLOCK* didn't raise an exception,  the :meth:`~object.__exit__` method is still
   called, but *type*, *value*, and *traceback* are all ``None``.
 
 Let's think through an example.  I won't present detailed code but will only
@@ -703,7 +703,7 @@ rolled back if there's an exception. Here's the basic interface for
        def rollback (self):
            "Rolls back current transaction"
 
-The :meth:`__enter__` method is pretty easy, having only to start a new
+The :meth:`~object.__enter__` method is pretty easy, having only to start a new
 transaction.  For this application the resulting cursor object would be a useful
 result, so the method will return it.  The user can then add ``as cursor`` to
 their ':keyword:`with`' statement to bind the cursor to a variable name. ::
@@ -715,7 +715,7 @@ their ':keyword:`with`' statement to bind the cursor to a variable name. ::
            cursor = self.cursor()
            return cursor
 
-The :meth:`__exit__` method is the most complicated because it's where most of
+The :meth:`~object.__exit__` method is the most complicated because it's where most of
 the work has to be done.  The method has to check if an exception occurred.  If
 there was no exception, the transaction is committed.  The transaction is rolled
 back if there was an exception.
@@ -748,10 +748,10 @@ are useful for writing objects for use with the ':keyword:`with`' statement.
 The decorator is called :func:`contextmanager`, and lets you write a single
 generator function instead of defining a new class.  The generator should yield
 exactly one value.  The code up to the :keyword:`yield` will be executed as the
-:meth:`__enter__` method, and the value yielded will be the method's return
+:meth:`~object.__enter__` method, and the value yielded will be the method's return
 value that will get bound to the variable in the ':keyword:`with`' statement's
 :keyword:`!as` clause, if any.  The code after the :keyword:`yield` will be
-executed in the :meth:`__exit__` method.  Any exception raised in the block will
+executed in the :meth:`~object.__exit__` method.  Any exception raised in the block will
 be raised by the :keyword:`!yield` statement.
 
 Our database example from the previous section could be written  using this
@@ -1347,7 +1347,7 @@ complete list of changes, or look through the SVN logs for all the details.
   :func:`input` function to allow opening files in binary or :term:`universal
   newlines` mode.  Another new parameter, *openhook*, lets you use a function
   other than :func:`open`  to open the input files.  Once you're iterating over
-  the set of files, the :class:`FileInput` object's new :meth:`fileno` returns
+  the set of files, the :class:`FileInput` object's new :meth:`~fileinput.fileno` returns
   the file descriptor for the currently opened file. (Contributed by Georg
   Brandl.)
 
diff --git a/Doc/whatsnew/2.6.rst b/Doc/whatsnew/2.6.rst
index 96d9b792b3..2b7ef2cd4f 100644
--- a/Doc/whatsnew/2.6.rst
+++ b/Doc/whatsnew/2.6.rst
@@ -269,15 +269,15 @@ structure is::
        with-block
 
 The expression is evaluated, and it should result in an object that supports the
-context management protocol (that is, has :meth:`__enter__` and :meth:`__exit__`
+context management protocol (that is, has :meth:`~object.__enter__` and :meth:`~object.__exit__`
 methods).
 
-The object's :meth:`__enter__` is called before *with-block* is executed and
+The object's :meth:`~object.__enter__` is called before *with-block* is executed and
 therefore can run set-up code. It also may return a value that is bound to the
 name *variable*, if given.  (Note carefully that *variable* is *not* assigned
 the result of *expression*.)
 
-After execution of the *with-block* is finished, the object's :meth:`__exit__`
+After execution of the *with-block* is finished, the object's :meth:`~object.__exit__`
 method is called, even if the block raised an exception, and can therefore run
 clean-up code.
 
@@ -296,7 +296,7 @@ part-way through the block.
 .. note::
 
    In this case, *f* is the same object created by :func:`open`, because
-   :meth:`file.__enter__` returns *self*.
+   :meth:`~object.__enter__` returns *self*.
 
 The :mod:`threading` module's locks and condition variables  also support the
 ':keyword:`with`' statement::
@@ -339,16 +339,16 @@ underlying implementation and should keep reading.
 A high-level explanation of the context management protocol is:
 
 * The expression is evaluated and should result in an object called a "context
-  manager".  The context manager must have :meth:`__enter__` and :meth:`__exit__`
+  manager".  The context manager must have :meth:`~object.__enter__` and :meth:`~object.__exit__`
   methods.
 
-* The context manager's :meth:`__enter__` method is called.  The value returned
+* The context manager's :meth:`~object.__enter__` method is called.  The value returned
   is assigned to *VAR*.  If no ``as VAR`` clause is present, the value is simply
   discarded.
 
 * The code in *BLOCK* is executed.
 
-* If *BLOCK* raises an exception, the context manager's :meth:`__exit__` method
+* If *BLOCK* raises an exception, the context manager's :meth:`~object.__exit__` method
   is called with three arguments, the exception details (``type, value, traceback``,
   the same values returned by :func:`sys.exc_info`, which can also be ``None``
   if no exception occurred).  The method's return value controls whether an exception
@@ -357,7 +357,7 @@ A high-level explanation of the context management protocol is:
   if you do the author of the code containing the ':keyword:`with`' statement will
   never realize anything went wrong.
 
-* If *BLOCK* didn't raise an exception,  the :meth:`__exit__` method is still
+* If *BLOCK* didn't raise an exception,  the :meth:`~object.__exit__` method is still
   called, but *type*, *value*, and *traceback* are all ``None``.
 
 Let's think through an example.  I won't present detailed code but will only
@@ -391,7 +391,7 @@ rolled back if there's an exception. Here's the basic interface for
        def rollback(self):
            "Rolls back current transaction"
 
-The :meth:`__enter__` method is pretty easy, having only to start a new
+The :meth:`~object.__enter__` method is pretty easy, having only to start a new
 transaction.  For this application the resulting cursor object would be a useful
 result, so the method will return it.  The user can then add ``as cursor`` to
 their ':keyword:`with`' statement to bind the cursor to a variable name. ::
@@ -403,7 +403,7 @@ their ':keyword:`with`' statement to bind the cursor to a variable name. ::
            cursor = self.cursor()
            return cursor
 
-The :meth:`__exit__` method is the most complicated because it's where most of
+The :meth:`~object.__exit__` method is the most complicated because it's where most of
 the work has to be done.  The method has to check if an exception occurred.  If
 there was no exception, the transaction is committed.  The transaction is rolled
 back if there was an exception.
@@ -436,10 +436,10 @@ are useful when writing objects for use with the ':keyword:`with`' statement.
 The decorator is called :func:`contextmanager`, and lets you write a single
 generator function instead of defining a new class.  The generator should yield
 exactly one value.  The code up to the :keyword:`yield` will be executed as the
-:meth:`__enter__` method, and the value yielded will be the method's return
+:meth:`~object.__enter__` method, and the value yielded will be the method's return
 value that will get bound to the variable in the ':keyword:`with`' statement's
 :keyword:`!as` clause, if any.  The code after the :keyword:`!yield` will be
-executed in the :meth:`__exit__` method.  Any exception raised in the block will
+executed in the :meth:`~object.__exit__` method.  Any exception raised in the block will
 be raised by the :keyword:`!yield` statement.
 
 Using this decorator, our database example from the previous section
@@ -875,11 +875,11 @@ The signature of the new function is::
 
 The parameters are:
 
- * *args*: positional arguments whose values will be printed out.
- * *sep*: the separator, which will be printed between arguments.
- * *end*: the ending text, which will be printed after all of the
-   arguments have been output.
- * *file*: the file object to which the output will be sent.
+* *args*: positional arguments whose values will be printed out.
+* *sep*: the separator, which will be printed between arguments.
+* *end*: the ending text, which will be printed after all of the
+  arguments have been output.
+* *file*: the file object to which the output will be sent.
 
 .. seealso::
 
@@ -1138,13 +1138,13 @@ indicate that the external caller is done.
 The *flags* argument to :c:func:`PyObject_GetBuffer` specifies
 constraints upon the memory returned.  Some examples are:
 
- * :c:macro:`PyBUF_WRITABLE` indicates that the memory must be writable.
+* :c:macro:`PyBUF_WRITABLE` indicates that the memory must be writable.
 
- * :c:macro:`PyBUF_LOCK` requests a read-only or exclusive lock on the memory.
+* :c:macro:`PyBUF_LOCK` requests a read-only or exclusive lock on the memory.
 
- * :c:macro:`PyBUF_C_CONTIGUOUS` and :c:macro:`PyBUF_F_CONTIGUOUS`
-   requests a C-contiguous (last dimension varies the fastest) or
-   Fortran-contiguous (first dimension varies the fastest) array layout.
+* :c:macro:`PyBUF_C_CONTIGUOUS` and :c:macro:`PyBUF_F_CONTIGUOUS`
+  requests a C-contiguous (last dimension varies the fastest) or
+  Fortran-contiguous (first dimension varies the fastest) array layout.
 
 Two new argument codes for :c:func:`PyArg_ParseTuple`,
 ``s*`` and ``z*``, return locked buffer objects for a parameter.
@@ -1737,7 +1737,7 @@ Optimizations
   (Contributed by Antoine Pitrou.)  Memory usage is reduced
   by using pymalloc for the Unicode string's data.
 
-* The ``with`` statement now stores the :meth:`__exit__` method on the stack,
+* The ``with`` statement now stores the :meth:`~object.__exit__` method on the stack,
   producing a small speedup.  (Implemented by Jeffrey Yasskin.)
 
 * To reduce memory usage, the garbage collector will now clear internal
diff --git a/Doc/whatsnew/2.7.rst b/Doc/whatsnew/2.7.rst
index eda6c8be38..6413877db4 100644
--- a/Doc/whatsnew/2.7.rst
+++ b/Doc/whatsnew/2.7.rst
@@ -930,8 +930,8 @@ Optimizations
 Several performance enhancements have been added:
 
 * A new opcode was added to perform the initial setup for
-  :keyword:`with` statements, looking up the :meth:`__enter__` and
-  :meth:`__exit__` methods.  (Contributed by Benjamin Peterson.)
+  :keyword:`with` statements, looking up the :meth:`~object.__enter__` and
+  :meth:`~object.__exit__` methods.  (Contributed by Benjamin Peterson.)
 
 * The garbage collector now performs better for one common usage
   pattern: when many objects are being allocated without deallocating
@@ -2368,7 +2368,7 @@ Port-Specific Changes: Mac OS X
   installation and a user-installed copy of the same version.
   (Changed by Ronald Oussoren; :issue:`4865`.)
 
-   .. versionchanged:: 2.7.13
+  .. versionchanged:: 2.7.13
 
      As of 2.7.13, this change was removed.
      ``/Library/Python/2.7/site-packages``, the site-packages directory
@@ -2449,13 +2449,13 @@ that may require changes to your code:
   (Changed by Eric Smith; :issue:`5920`.)
 
 * Because of an optimization for the :keyword:`with` statement, the special
-  methods :meth:`__enter__` and :meth:`__exit__` must belong to the object's
+  methods :meth:`~object.__enter__` and :meth:`~object.__exit__` must belong to the object's
   type, and cannot be directly attached to the object's instance.  This
   affects new-style classes (derived from :class:`object`) and C extension
   types.  (:issue:`6101`.)
 
 * Due to a bug in Python 2.6, the *exc_value* parameter to
-  :meth:`__exit__` methods was often the string representation of the
+  :meth:`~object.__exit__` methods was often the string representation of the
   exception, not an instance.  This was fixed in 2.7, so *exc_value*
   will be an instance as expected.  (Fixed by Florent Xicluna;
   :issue:`7853`.)
diff --git a/Doc/whatsnew/3.10.rst b/Doc/whatsnew/3.10.rst
index 42e54fbad2..e233db7e63 100644
--- a/Doc/whatsnew/3.10.rst
+++ b/Doc/whatsnew/3.10.rst
@@ -221,116 +221,116 @@ have been incorporated. Some of the most notable ones are as follows:
 
 * Missing ``:`` before blocks:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> if rocket.position > event_horizon
-          File "<stdin>", line 1
-            if rocket.position > event_horizon
-                                              ^
-        SyntaxError: expected ':'
+      >>> if rocket.position > event_horizon
+        File "<stdin>", line 1
+          if rocket.position > event_horizon
+                                            ^
+      SyntaxError: expected ':'
 
-    (Contributed by Pablo Galindo in :issue:`42997`.)
+  (Contributed by Pablo Galindo in :issue:`42997`.)
 
 * Unparenthesised tuples in comprehensions targets:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> {x,y for x,y in zip('abcd', '1234')}
-          File "<stdin>", line 1
-            {x,y for x,y in zip('abcd', '1234')}
-             ^
-        SyntaxError: did you forget parentheses around the comprehension target?
+      >>> {x,y for x,y in zip('abcd', '1234')}
+        File "<stdin>", line 1
+          {x,y for x,y in zip('abcd', '1234')}
+           ^
+      SyntaxError: did you forget parentheses around the comprehension target?
 
-    (Contributed by Pablo Galindo in :issue:`43017`.)
+  (Contributed by Pablo Galindo in :issue:`43017`.)
 
 * Missing commas in collection literals and between expressions:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> items = {
-        ... x: 1,
-        ... y: 2
-        ... z: 3,
-          File "<stdin>", line 3
-            y: 2
-               ^
-        SyntaxError: invalid syntax. Perhaps you forgot a comma?
+      >>> items = {
+      ... x: 1,
+      ... y: 2
+      ... z: 3,
+        File "<stdin>", line 3
+          y: 2
+             ^
+      SyntaxError: invalid syntax. Perhaps you forgot a comma?
 
-    (Contributed by Pablo Galindo in :issue:`43822`.)
+  (Contributed by Pablo Galindo in :issue:`43822`.)
 
 * Multiple Exception types without parentheses:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> try:
-        ...     build_dyson_sphere()
-        ... except NotEnoughScienceError, NotEnoughResourcesError:
-          File "<stdin>", line 3
-            except NotEnoughScienceError, NotEnoughResourcesError:
-                   ^
-        SyntaxError: multiple exception types must be parenthesized
+      >>> try:
+      ...     build_dyson_sphere()
+      ... except NotEnoughScienceError, NotEnoughResourcesError:
+        File "<stdin>", line 3
+          except NotEnoughScienceError, NotEnoughResourcesError:
+                 ^
+      SyntaxError: multiple exception types must be parenthesized
 
-    (Contributed by Pablo Galindo in :issue:`43149`.)
+  (Contributed by Pablo Galindo in :issue:`43149`.)
 
 * Missing ``:`` and values in dictionary literals:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> values = {
-        ... x: 1,
-        ... y: 2,
-        ... z:
-        ... }
-          File "<stdin>", line 4
-            z:
-             ^
-        SyntaxError: expression expected after dictionary key and ':'
+      >>> values = {
+      ... x: 1,
+      ... y: 2,
+      ... z:
+      ... }
+        File "<stdin>", line 4
+          z:
+           ^
+      SyntaxError: expression expected after dictionary key and ':'
 
-        >>> values = {x:1, y:2, z w:3}
-          File "<stdin>", line 1
-            values = {x:1, y:2, z w:3}
-                                ^
-        SyntaxError: ':' expected after dictionary key
+      >>> values = {x:1, y:2, z w:3}
+        File "<stdin>", line 1
+          values = {x:1, y:2, z w:3}
+                              ^
+      SyntaxError: ':' expected after dictionary key
 
-    (Contributed by Pablo Galindo in :issue:`43823`.)
+  (Contributed by Pablo Galindo in :issue:`43823`.)
 
 * ``try`` blocks without ``except`` or ``finally`` blocks:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> try:
-        ...     x = 2
-        ... something = 3
-          File "<stdin>", line 3
-            something  = 3
-            ^^^^^^^^^
-        SyntaxError: expected 'except' or 'finally' block
+      >>> try:
+      ...     x = 2
+      ... something = 3
+        File "<stdin>", line 3
+          something  = 3
+          ^^^^^^^^^
+      SyntaxError: expected 'except' or 'finally' block
 
-    (Contributed by Pablo Galindo in :issue:`44305`.)
+  (Contributed by Pablo Galindo in :issue:`44305`.)
 
 * Usage of ``=`` instead of ``==`` in comparisons:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> if rocket.position = event_horizon:
-          File "<stdin>", line 1
-            if rocket.position = event_horizon:
-                               ^
-        SyntaxError: cannot assign to attribute here. Maybe you meant '==' instead of '='?
+      >>> if rocket.position = event_horizon:
+        File "<stdin>", line 1
+          if rocket.position = event_horizon:
+                             ^
+      SyntaxError: cannot assign to attribute here. Maybe you meant '==' instead of '='?
 
-    (Contributed by Pablo Galindo in :issue:`43797`.)
+  (Contributed by Pablo Galindo in :issue:`43797`.)
 
 * Usage of ``*`` in f-strings:
 
-    .. code-block:: python
+  .. code-block:: python
 
-        >>> f"Black holes {*all_black_holes} and revelations"
-          File "<stdin>", line 1
-            (*all_black_holes)
-             ^
-        SyntaxError: f-string: cannot use starred expression here
+      >>> f"Black holes {*all_black_holes} and revelations"
+        File "<stdin>", line 1
+          (*all_black_holes)
+           ^
+      SyntaxError: f-string: cannot use starred expression here
 
-    (Contributed by Pablo Galindo in :issue:`41064`.)
+  (Contributed by Pablo Galindo in :issue:`41064`.)
 
 IndentationErrors
 ~~~~~~~~~~~~~~~~~
@@ -365,10 +365,10 @@ raised from:
 
 (Contributed by Pablo Galindo in :issue:`38530`.)
 
-   .. warning::
-      Notice this won't work if :c:func:`PyErr_Display` is not called to display the error
-      which can happen if some other custom error display function is used. This is a common
-      scenario in some REPLs like IPython.
+.. warning::
+   Notice this won't work if :c:func:`PyErr_Display` is not called to display the error
+   which can happen if some other custom error display function is used. This is a common
+   scenario in some REPLs like IPython.
 
 NameErrors
 ~~~~~~~~~~
@@ -387,10 +387,10 @@ was raised from:
 
 (Contributed by Pablo Galindo in :issue:`38530`.)
 
-   .. warning::
-      Notice this won't work if :c:func:`PyErr_Display` is not called to display the error,
-      which can happen if some other custom error display function is used. This is a common
-      scenario in some REPLs like IPython.
+.. warning::
+   Notice this won't work if :c:func:`PyErr_Display` is not called to display the error,
+   which can happen if some other custom error display function is used. This is a common
+   scenario in some REPLs like IPython.
 
 
 PEP 626: Precise line numbers for debugging and other tools
@@ -433,16 +433,16 @@ A match statement takes an expression and compares its value to successive
 patterns given as one or more case blocks.  Specifically, pattern matching
 operates by:
 
-    1. using data with type and shape (the ``subject``)
-    2. evaluating the ``subject`` in the ``match`` statement
-    3. comparing the subject with each pattern in a ``case`` statement
-       from top to bottom until a match is confirmed.
-    4. executing the action associated with the pattern of the confirmed
-       match
-    5. If an exact match is not confirmed, the last case, a wildcard ``_``,
-       if provided, will be used as the matching case. If an exact match is
-       not confirmed and a wildcard case does not exist, the entire match
-       block is a no-op.
+1. using data with type and shape (the ``subject``)
+2. evaluating the ``subject`` in the ``match`` statement
+3. comparing the subject with each pattern in a ``case`` statement
+   from top to bottom until a match is confirmed.
+4. executing the action associated with the pattern of the confirmed
+   match
+5. If an exact match is not confirmed, the last case, a wildcard ``_``,
+   if provided, will be used as the matching case. If an exact match is
+   not confirmed and a wildcard case does not exist, the entire match
+   block is a no-op.
 
 Declarative approach
 ~~~~~~~~~~~~~~~~~~~~
@@ -2211,16 +2211,16 @@ Removed
 * Removed ``Py_UNICODE_str*`` functions manipulating ``Py_UNICODE*`` strings.
   (Contributed by Inada Naoki in :issue:`41123`.)
 
-   * ``Py_UNICODE_strlen``: use :c:func:`PyUnicode_GetLength` or
-     :c:macro:`PyUnicode_GET_LENGTH`
-   * ``Py_UNICODE_strcat``: use :c:func:`PyUnicode_CopyCharacters` or
-     :c:func:`PyUnicode_FromFormat`
-   * ``Py_UNICODE_strcpy``, ``Py_UNICODE_strncpy``: use
-     :c:func:`PyUnicode_CopyCharacters` or :c:func:`PyUnicode_Substring`
-   * ``Py_UNICODE_strcmp``: use :c:func:`PyUnicode_Compare`
-   * ``Py_UNICODE_strncmp``: use :c:func:`PyUnicode_Tailmatch`
-   * ``Py_UNICODE_strchr``, ``Py_UNICODE_strrchr``: use
-     :c:func:`PyUnicode_FindChar`
+  * ``Py_UNICODE_strlen``: use :c:func:`PyUnicode_GetLength` or
+    :c:macro:`PyUnicode_GET_LENGTH`
+  * ``Py_UNICODE_strcat``: use :c:func:`PyUnicode_CopyCharacters` or
+    :c:func:`PyUnicode_FromFormat`
+  * ``Py_UNICODE_strcpy``, ``Py_UNICODE_strncpy``: use
+    :c:func:`PyUnicode_CopyCharacters` or :c:func:`PyUnicode_Substring`
+  * ``Py_UNICODE_strcmp``: use :c:func:`PyUnicode_Compare`
+  * ``Py_UNICODE_strncmp``: use :c:func:`PyUnicode_Tailmatch`
+  * ``Py_UNICODE_strchr``, ``Py_UNICODE_strrchr``: use
+    :c:func:`PyUnicode_FindChar`
 
 * Removed ``PyUnicode_GetMax()``. Please migrate to new (:pep:`393`) APIs.
   (Contributed by Inada Naoki in :issue:`41103`.)
diff --git a/Doc/whatsnew/3.11.rst b/Doc/whatsnew/3.11.rst
index 88eaee9791..c28093ac19 100644
--- a/Doc/whatsnew/3.11.rst
+++ b/Doc/whatsnew/3.11.rst
@@ -1798,7 +1798,7 @@ Standard Library
   * :func:`importlib.resources.path`
 
 * The :func:`locale.getdefaultlocale` function is deprecated and will be
-  removed in Python 3.13. Use :func:`locale.setlocale`,
+  removed in Python 3.15. Use :func:`locale.setlocale`,
   :func:`locale.getpreferredencoding(False) <locale.getpreferredencoding>` and
   :func:`locale.getlocale` functions instead.
   (Contributed by Victor Stinner in :gh:`90817`.)
diff --git a/Doc/whatsnew/3.12.rst b/Doc/whatsnew/3.12.rst
index fad94d6d78..feed5238bf 100644
--- a/Doc/whatsnew/3.12.rst
+++ b/Doc/whatsnew/3.12.rst
@@ -121,7 +121,7 @@ Significant improvements in the standard library:
 * A :ref:`command-line interface <uuid-cli>` has been added to the
   :mod:`uuid` module
 * Due to the changes in :ref:`PEP 701 <whatsnew312-pep701>`,
-  producing tokens via the :mod:`tokenize` module is up to up to 64% faster.
+  producing tokens via the :mod:`tokenize` module is up to 64% faster.
 
 Security improvements:
 
@@ -303,7 +303,7 @@ Let's cover these in detail:
 See :pep:`701` for more details.
 
 As a positive side-effect of how this feature has been implemented (by parsing f-strings
-with :pep:`the PEG parser <617>`, now error messages for f-strings are more precise
+with :pep:`the PEG parser <617>`), now error messages for f-strings are more precise
 and include the exact location of the error. For example, in Python 3.11, the following
 f-string raises a :exc:`SyntaxError`:
 
@@ -354,7 +354,7 @@ create an interpreter with its own GIL::
    if (PyStatus_Exception(status)) {
        return -1;
    }
-   /* The new interpeter is now active in the current thread. */
+   /* The new interpreter is now active in the current thread. */
 
 For further examples how to use the C-API for sub-interpreters with a
 per-interpreter GIL, see :source:`Modules/_xxsubinterpretersmodule.c`.
@@ -716,6 +716,9 @@ importlib.resources
 * :func:`importlib.resources.as_file` now supports resource directories.
   (Contributed by Jason R. Coombs in :gh:`97930`.)
 
+* Rename first parameter of :func:`importlib.resources.files` to *anchor*.
+  (Contributed by Jason R. Coombs in :gh:`100598`.)
+
 inspect
 -------
 
@@ -1360,7 +1363,7 @@ Other modules:
 APIs:
 
 * :class:`!configparser.LegacyInterpolation` (:gh:`90765`)
-* :func:`locale.getdefaultlocale` (:gh:`90817`)
+* ``locale.resetlocale()`` (:gh:`90817`)
 * :meth:`!turtle.RawTurtle.settiltangle` (:gh:`50096`)
 * :func:`!unittest.findTestCases` (:gh:`50096`)
 * :func:`!unittest.getTestCaseNames` (:gh:`50096`)
@@ -1429,6 +1432,17 @@ and will be removed in Python 3.14.
 
 * The ``co_lnotab`` attribute of code objects.
 
+Pending Removal in Python 3.15
+------------------------------
+
+The following APIs have been deprecated
+and will be removed in Python 3.15.
+
+APIs:
+
+* :func:`locale.getdefaultlocale` (:gh:`90817`)
+
+
 Pending Removal in Future Versions
 ----------------------------------
 
@@ -2399,15 +2413,15 @@ Removed
 
 * Legacy Unicode APIs have been removed. See :pep:`623` for detail.
 
-   * :c:macro:`!PyUnicode_WCHAR_KIND`
-   * :c:func:`!PyUnicode_AS_UNICODE`
-   * :c:func:`!PyUnicode_AsUnicode`
-   * :c:func:`!PyUnicode_AsUnicodeAndSize`
-   * :c:func:`!PyUnicode_AS_DATA`
-   * :c:func:`!PyUnicode_FromUnicode`
-   * :c:func:`!PyUnicode_GET_SIZE`
-   * :c:func:`!PyUnicode_GetSize`
-   * :c:func:`!PyUnicode_GET_DATA_SIZE`
+  * :c:macro:`!PyUnicode_WCHAR_KIND`
+  * :c:func:`!PyUnicode_AS_UNICODE`
+  * :c:func:`!PyUnicode_AsUnicode`
+  * :c:func:`!PyUnicode_AsUnicodeAndSize`
+  * :c:func:`!PyUnicode_AS_DATA`
+  * :c:func:`!PyUnicode_FromUnicode`
+  * :c:func:`!PyUnicode_GET_SIZE`
+  * :c:func:`!PyUnicode_GetSize`
+  * :c:func:`!PyUnicode_GET_DATA_SIZE`
 
 * Remove the ``PyUnicode_InternImmortal()`` function macro.
   (Contributed by Victor Stinner in :gh:`85858`.)
diff --git a/Doc/whatsnew/3.3.rst b/Doc/whatsnew/3.3.rst
index 3361789ff6..ed267f5727 100644
--- a/Doc/whatsnew/3.3.rst
+++ b/Doc/whatsnew/3.3.rst
@@ -917,12 +917,12 @@ abstract methods. The recommended approach to declaring abstract descriptors is
 now to provide :attr:`__isabstractmethod__` as a dynamically updated
 property. The built-in descriptors have been updated accordingly.
 
-  * :class:`abc.abstractproperty` has been deprecated, use :class:`property`
-    with :func:`abc.abstractmethod` instead.
-  * :class:`abc.abstractclassmethod` has been deprecated, use
-    :class:`classmethod` with :func:`abc.abstractmethod` instead.
-  * :class:`abc.abstractstaticmethod` has been deprecated, use
-    :class:`staticmethod` with :func:`abc.abstractmethod` instead.
+* :class:`abc.abstractproperty` has been deprecated, use :class:`property`
+  with :func:`abc.abstractmethod` instead.
+* :class:`abc.abstractclassmethod` has been deprecated, use
+  :class:`classmethod` with :func:`abc.abstractmethod` instead.
+* :class:`abc.abstractstaticmethod` has been deprecated, use
+  :class:`staticmethod` with :func:`abc.abstractmethod` instead.
 
 (Contributed by Darren Dale in :issue:`11610`.)
 
@@ -1060,32 +1060,32 @@ function to the :mod:`crypt` module.
 curses
 ------
 
- * If the :mod:`curses` module is linked to the ncursesw library, use Unicode
-   functions when Unicode strings or characters are passed (e.g.
-   :c:func:`waddwstr`), and bytes functions otherwise (e.g. :c:func:`waddstr`).
- * Use the locale encoding instead of ``utf-8`` to encode Unicode strings.
- * :class:`curses.window` has a new :attr:`curses.window.encoding` attribute.
- * The :class:`curses.window` class has a new :meth:`~curses.window.get_wch`
-   method to get a wide character
- * The :mod:`curses` module has a new :meth:`~curses.unget_wch` function to
-   push a wide character so the next :meth:`~curses.window.get_wch` will return
-   it
+* If the :mod:`curses` module is linked to the ncursesw library, use Unicode
+  functions when Unicode strings or characters are passed (e.g.
+  :c:func:`waddwstr`), and bytes functions otherwise (e.g. :c:func:`waddstr`).
+* Use the locale encoding instead of ``utf-8`` to encode Unicode strings.
+* :class:`curses.window` has a new :attr:`curses.window.encoding` attribute.
+* The :class:`curses.window` class has a new :meth:`~curses.window.get_wch`
+  method to get a wide character
+* The :mod:`curses` module has a new :meth:`~curses.unget_wch` function to
+  push a wide character so the next :meth:`~curses.window.get_wch` will return
+  it
 
 (Contributed by Iñigo Serna in :issue:`6755`.)
 
 datetime
 --------
 
- * Equality comparisons between naive and aware :class:`~datetime.datetime`
-   instances now return :const:`False` instead of raising :exc:`TypeError`
-   (:issue:`15006`).
- * New :meth:`datetime.datetime.timestamp` method: Return POSIX timestamp
-   corresponding to the :class:`~datetime.datetime` instance.
- * The :meth:`datetime.datetime.strftime` method supports formatting years
-   older than 1000.
- * The :meth:`datetime.datetime.astimezone` method can now be
-   called without arguments to convert datetime instance to the system
-   timezone.
+* Equality comparisons between naive and aware :class:`~datetime.datetime`
+  instances now return :const:`False` instead of raising :exc:`TypeError`
+  (:issue:`15006`).
+* New :meth:`datetime.datetime.timestamp` method: Return POSIX timestamp
+  corresponding to the :class:`~datetime.datetime` instance.
+* The :meth:`datetime.datetime.strftime` method supports formatting years
+  older than 1000.
+* The :meth:`datetime.datetime.astimezone` method can now be
+  called without arguments to convert datetime instance to the system
+  timezone.
 
 
 .. _new-decimal:
@@ -1210,25 +1210,25 @@ the ``Message`` object it is serializing.  The default policy is
 
 The minimum set of controls implemented by all ``policy`` objects are:
 
-    .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
-    ===============     =======================================================
-    max_line_length     The maximum length, excluding the linesep character(s),
-                        individual lines may have when a ``Message`` is
-                        serialized.  Defaults to 78.
+===============     =======================================================
+max_line_length     The maximum length, excluding the linesep character(s),
+                    individual lines may have when a ``Message`` is
+                    serialized.  Defaults to 78.
 
-    linesep             The character used to separate individual lines when a
-                        ``Message`` is serialized.  Defaults to ``\n``.
+linesep             The character used to separate individual lines when a
+                    ``Message`` is serialized.  Defaults to ``\n``.
 
-    cte_type            ``7bit`` or ``8bit``.  ``8bit`` applies only to a
-                        ``Bytes`` ``generator``, and means that non-ASCII may
-                        be used where allowed by the protocol (or where it
-                        exists in the original input).
+cte_type            ``7bit`` or ``8bit``.  ``8bit`` applies only to a
+                    ``Bytes`` ``generator``, and means that non-ASCII may
+                    be used where allowed by the protocol (or where it
+                    exists in the original input).
 
-    raise_on_defect     Causes a ``parser`` to raise error when defects are
-                        encountered instead of adding them to the ``Message``
-                        object's ``defects`` list.
-    ===============     =======================================================
+raise_on_defect     Causes a ``parser`` to raise error when defects are
+                    encountered instead of adding them to the ``Message``
+                    object's ``defects`` list.
+===============     =======================================================
 
 A new policy instance, with new settings, is created using the
 :meth:`~email.policy.Policy.clone` method of policy objects.  ``clone`` takes
@@ -1263,21 +1263,21 @@ removal of the code) may occur if deemed necessary by the core developers.
 The new policies are instances of :class:`~email.policy.EmailPolicy`,
 and add the following additional controls:
 
-    .. tabularcolumns:: |l|L|
+.. tabularcolumns:: |l|L|
 
-    ===============     =======================================================
-    refold_source       Controls whether or not headers parsed by a
-                        :mod:`~email.parser` are refolded by the
-                        :mod:`~email.generator`.  It can be ``none``, ``long``,
-                        or ``all``.  The default is ``long``, which means that
-                        source headers with a line longer than
-                        ``max_line_length`` get refolded.  ``none`` means no
-                        line get refolded, and ``all`` means that all lines
-                        get refolded.
+===============     =======================================================
+refold_source       Controls whether or not headers parsed by a
+                    :mod:`~email.parser` are refolded by the
+                    :mod:`~email.generator`.  It can be ``none``, ``long``,
+                    or ``all``.  The default is ``long``, which means that
+                    source headers with a line longer than
+                    ``max_line_length`` get refolded.  ``none`` means no
+                    line get refolded, and ``all`` means that all lines
+                    get refolded.
 
-    header_factory      A callable that take a ``name`` and ``value`` and
-                        produces a custom header object.
-    ===============     =======================================================
+header_factory      A callable that take a ``name`` and ``value`` and
+                    produces a custom header object.
+===============     =======================================================
 
 The ``header_factory`` is the key to the new features provided by the new
 policies.  When one of the new policies is used, any header retrieved from
@@ -1352,18 +1352,18 @@ API.
 
 New utility functions:
 
-   * :func:`~email.utils.format_datetime`: given a :class:`~datetime.datetime`,
-     produce a string formatted for use in an email header.
+* :func:`~email.utils.format_datetime`: given a :class:`~datetime.datetime`,
+  produce a string formatted for use in an email header.
 
-   * :func:`~email.utils.parsedate_to_datetime`: given a date string from
-     an email header, convert it into an aware :class:`~datetime.datetime`,
-     or a naive :class:`~datetime.datetime` if the offset is ``-0000``.
+* :func:`~email.utils.parsedate_to_datetime`: given a date string from
+  an email header, convert it into an aware :class:`~datetime.datetime`,
+  or a naive :class:`~datetime.datetime` if the offset is ``-0000``.
 
-   * :func:`~email.utils.localtime`: With no argument, returns the
-     current local time as an aware :class:`~datetime.datetime` using the local
-     :class:`~datetime.timezone`.  Given an aware :class:`~datetime.datetime`,
-     converts it into an aware :class:`~datetime.datetime` using the
-     local :class:`~datetime.timezone`.
+* :func:`~email.utils.localtime`: With no argument, returns the
+  current local time as an aware :class:`~datetime.datetime` using the local
+  :class:`~datetime.timezone`.  Given an aware :class:`~datetime.datetime`,
+  converts it into an aware :class:`~datetime.datetime` using the
+  local :class:`~datetime.timezone`.
 
 
 ftplib
diff --git a/Doc/whatsnew/3.5.rst b/Doc/whatsnew/3.5.rst
index 3c0d8d665c..108e5293bc 100644
--- a/Doc/whatsnew/3.5.rst
+++ b/Doc/whatsnew/3.5.rst
@@ -921,7 +921,7 @@ and improves their substitutability for lists.
 Docstrings produced by :func:`~collections.namedtuple` can now be updated::
 
     Point = namedtuple('Point', ['x', 'y'])
-    Point.__doc__ += ': Cartesian coodinate'
+    Point.__doc__ += ': Cartesian coordinate'
     Point.x.__doc__ = 'abscissa'
     Point.y.__doc__ = 'ordinate'
 
diff --git a/Doc/whatsnew/3.7.rst b/Doc/whatsnew/3.7.rst
index e82bb756b8..4ed53d04e1 100644
--- a/Doc/whatsnew/3.7.rst
+++ b/Doc/whatsnew/3.7.rst
@@ -1580,13 +1580,13 @@ The initialization of the default warnings filters has changed as follows:
 * warnings filters enabled via the command line or the environment now have the
   following order of precedence:
 
-     * the ``BytesWarning`` filter for :option:`-b` (or ``-bb``)
-     * any filters specified with the :option:`-W` option
-     * any filters specified with the :envvar:`PYTHONWARNINGS` environment
-       variable
-     * any other CPython specific filters (e.g. the ``default`` filter added
-       for the new ``-X dev`` mode)
-     * any implicit filters defined directly by the warnings machinery
+  * the ``BytesWarning`` filter for :option:`-b` (or ``-bb``)
+  * any filters specified with the :option:`-W` option
+  * any filters specified with the :envvar:`PYTHONWARNINGS` environment
+    variable
+  * any other CPython specific filters (e.g. the ``default`` filter added
+    for the new ``-X dev`` mode)
+  * any implicit filters defined directly by the warnings machinery
 
 * in :ref:`CPython debug builds <debug-build>`, all warnings are now displayed
   by default (the implicit filter list is empty)
diff --git a/Doc/whatsnew/3.8.rst b/Doc/whatsnew/3.8.rst
index 68fd4d7759..e79b7cade7 100644
--- a/Doc/whatsnew/3.8.rst
+++ b/Doc/whatsnew/3.8.rst
@@ -123,7 +123,7 @@ There is a new function parameter syntax ``/`` to indicate that some
 function parameters must be specified positionally and cannot be used as
 keyword arguments.  This is the same notation shown by ``help()`` for C
 functions annotated with Larry Hastings'
-:ref:`Argument Clinic <howto-clinic>` tool.
+`Argument Clinic <devguide.python.org/development-tools/clinic/>`__ tool.
 
 In the following example, parameters *a* and *b* are positional-only,
 while *c* or *d* can be positional or keyword, and *e* or *f* are
@@ -1653,7 +1653,7 @@ Deprecated
   deprecated and will be prohibited in Python 3.9.
   (Contributed by Elvis Pranskevichus in :issue:`34075`.)
 
-* The :meth:`__getitem__` methods of :class:`xml.dom.pulldom.DOMEventStream`,
+* The :meth:`~object.__getitem__` methods of :class:`xml.dom.pulldom.DOMEventStream`,
   :class:`wsgiref.util.FileWrapper` and :class:`fileinput.FileInput` have been
   deprecated.
 
diff --git a/Grammar/python.gram b/Grammar/python.gram
index f88dc2bdd9..a4fd3f27db 100644
--- a/Grammar/python.gram
+++ b/Grammar/python.gram
@@ -19,8 +19,6 @@ _PyPegen_parse(Parser *p)
         result = eval_rule(p);
     } else if (p->start_rule == Py_func_type_input) {
         result = func_type_rule(p);
-    } else if (p->start_rule == Py_fstring_input) {
-        result = fstring_rule(p);
     }
 
     return result;
@@ -89,7 +87,6 @@ file[mod_ty]: a=[statements] ENDMARKER { _PyPegen_make_module(p, a) }
 interactive[mod_ty]: a=statement_newline { _PyAST_Interactive(a, p->arena) }
 eval[mod_ty]: a=expressions NEWLINE* ENDMARKER { _PyAST_Expression(a, p->arena) }
 func_type[mod_ty]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* ENDMARKER { _PyAST_FunctionType(a, b, p->arena) }
-fstring[expr_ty]: star_expressions
 
 # GENERAL STATEMENTS
 # ==================
@@ -647,20 +644,20 @@ type_param_seq[asdl_type_param_seq*]: a[asdl_type_param_seq*]=','.type_param+ ['
 
 type_param[type_param_ty] (memo):
     | a=NAME b=[type_param_bound] { _PyAST_TypeVar(a->v.Name.id, b, EXTRA) }
-    | '*' a=NAME colon=":" e=expression {
+    | '*' a=NAME colon=':' e=expression {
             RAISE_SYNTAX_ERROR_STARTING_FROM(colon, e->kind == Tuple_kind
                 ? "cannot use constraints with TypeVarTuple"
                 : "cannot use bound with TypeVarTuple")
         }
     | '*' a=NAME { _PyAST_TypeVarTuple(a->v.Name.id, EXTRA) }
-    | '**' a=NAME colon=":" e=expression {
+    | '**' a=NAME colon=':' e=expression {
             RAISE_SYNTAX_ERROR_STARTING_FROM(colon, e->kind == Tuple_kind
                 ? "cannot use constraints with ParamSpec"
                 : "cannot use bound with ParamSpec")
         }
     | '**' a=NAME { _PyAST_ParamSpec(a->v.Name.id, EXTRA) }
 
-type_param_bound[expr_ty]: ":" e=expression { e }
+type_param_bound[expr_ty]: ':' e=expression { e }
 
 # EXPRESSIONS
 # -----------
@@ -915,7 +912,7 @@ fstring_middle[expr_ty]:
     | fstring_replacement_field
     | t=FSTRING_MIDDLE { _PyPegen_constant_from_token(p, t) }
 fstring_replacement_field[expr_ty]:
-    | '{' a=(yield_expr | star_expressions) debug_expr="="? conversion=[fstring_conversion] format=[fstring_full_format_spec] rbrace='}' {
+    | '{' a=(yield_expr | star_expressions) debug_expr='='? conversion=[fstring_conversion] format=[fstring_full_format_spec] rbrace='}' {
         _PyPegen_formatted_value(p, a, debug_expr, conversion, format, rbrace, EXTRA) }
     | invalid_replacement_field
 fstring_conversion[ResultTokenWithMetadata*]:
@@ -1131,7 +1128,8 @@ func_type_comment[Token*]:
 
 # From here on, there are rules for invalid syntax with specialised error messages
 invalid_arguments:
-    | a=args ',' '*' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "iterable argument unpacking follows keyword argument unpacking") }
+    | ((','.(starred_expression | ( assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs) ',' b='*' {
+        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(b, "iterable argument unpacking follows keyword argument unpacking") }
     | a=expression b=for_if_clauses ',' [args | expression for_if_clauses] {
         RAISE_SYNTAX_ERROR_KNOWN_RANGE(a, _PyPegen_get_last_comprehension_item(PyPegen_last_item(b, comprehension_ty)), "Generator expression must be parenthesized") }
     | a=NAME b='=' expression for_if_clauses {
@@ -1371,11 +1369,11 @@ invalid_for_stmt:
     | [ASYNC] a='for' star_targets 'in' star_expressions ':' NEWLINE !INDENT {
         RAISE_INDENTATION_ERROR("expected an indented block after 'for' statement on line %d", a->lineno) }
 invalid_def_raw:
-    | [ASYNC] a='def' NAME '(' [params] ')' ['->' expression] ':' NEWLINE !INDENT {
+    | [ASYNC] a='def' NAME [type_params] '(' [params] ')' ['->' expression] ':' NEWLINE !INDENT {
         RAISE_INDENTATION_ERROR("expected an indented block after function definition on line %d", a->lineno) }
 invalid_class_def_raw:
-    | 'class' NAME ['(' [arguments] ')'] NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
-    | a='class' NAME ['(' [arguments] ')'] ':' NEWLINE !INDENT {
+    | 'class' NAME [type_params] ['(' [arguments] ')'] NEWLINE { RAISE_SYNTAX_ERROR("expected ':'") }
+    | a='class' NAME [type_params] ['(' [arguments] ')'] ':' NEWLINE !INDENT {
         RAISE_INDENTATION_ERROR("expected an indented block after class definition on line %d", a->lineno) }
 
 invalid_double_starred_kvpairs:
diff --git a/Include/compile.h b/Include/compile.h
index 3c5acd7209..52d0bc76c9 100644
--- a/Include/compile.h
+++ b/Include/compile.h
@@ -10,9 +10,6 @@ extern "C" {
 #define Py_eval_input 258
 #define Py_func_type_input 345
 
-/* This doesn't need to match anything */
-#define Py_fstring_input 800
-
 #ifndef Py_LIMITED_API
 #  define Py_CPYTHON_COMPILE_H
 #  include "cpython/compile.h"
diff --git a/Include/errcode.h b/Include/errcode.h
index 54ae929bf2..bd9066bb41 100644
--- a/Include/errcode.h
+++ b/Include/errcode.h
@@ -4,7 +4,6 @@
 extern "C" {
 #endif
 
-
 /* Error codes passed around between file input, tokenizer, parser and
    interpreter.  This is necessary so we can turn them into Python
    exceptions at a higher level.  Note that some errors have a
@@ -13,24 +12,25 @@ extern "C" {
    the parser only returns E_EOF when it hits EOF immediately, and it
    never returns E_OK. */
 
-#define E_OK            10      /* No error */
-#define E_EOF           11      /* End Of File */
-#define E_INTR          12      /* Interrupted */
-#define E_TOKEN         13      /* Bad token */
-#define E_SYNTAX        14      /* Syntax error */
-#define E_NOMEM         15      /* Ran out of memory */
-#define E_DONE          16      /* Parsing complete */
-#define E_ERROR         17      /* Execution error */
-#define E_TABSPACE      18      /* Inconsistent mixing of tabs and spaces */
-#define E_OVERFLOW      19      /* Node had too many children */
-#define E_TOODEEP       20      /* Too many indentation levels */
-#define E_DEDENT        21      /* No matching outer block for dedent */
-#define E_DECODE        22      /* Error in decoding into Unicode */
-#define E_EOFS          23      /* EOF in triple-quoted string */
-#define E_EOLS          24      /* EOL in single-quoted string */
-#define E_LINECONT      25      /* Unexpected characters after a line continuation */
-#define E_BADSINGLE     27      /* Ill-formed single statement input */
-#define E_INTERACT_STOP 28      /* Interactive mode stopped tokenization */
+#define E_OK             10      /* No error */
+#define E_EOF            11      /* End Of File */
+#define E_INTR           12      /* Interrupted */
+#define E_TOKEN          13      /* Bad token */
+#define E_SYNTAX         14      /* Syntax error */
+#define E_NOMEM          15      /* Ran out of memory */
+#define E_DONE           16      /* Parsing complete */
+#define E_ERROR          17      /* Execution error */
+#define E_TABSPACE       18      /* Inconsistent mixing of tabs and spaces */
+#define E_OVERFLOW       19      /* Node had too many children */
+#define E_TOODEEP        20      /* Too many indentation levels */
+#define E_DEDENT         21      /* No matching outer block for dedent */
+#define E_DECODE         22      /* Error in decoding into Unicode */
+#define E_EOFS           23      /* EOF in triple-quoted string */
+#define E_EOLS           24      /* EOL in single-quoted string */
+#define E_LINECONT       25      /* Unexpected characters after a line continuation */
+#define E_BADSINGLE      27      /* Ill-formed single statement input */
+#define E_INTERACT_STOP  28      /* Interactive mode stopped tokenization */
+#define E_COLUMNOVERFLOW 29      /* Column offset overflow */
 
 #ifdef __cplusplus
 }
diff --git a/Include/internal/pycore_pystate.h b/Include/internal/pycore_pystate.h
index ccfc2586f0..5be0ff6764 100644
--- a/Include/internal/pycore_pystate.h
+++ b/Include/internal/pycore_pystate.h
@@ -68,6 +68,12 @@ extern _Py_thread_local PyThreadState *_Py_tss_tstate;
 #endif
 PyAPI_DATA(PyThreadState *) _PyThreadState_GetCurrent(void);
 
+#ifndef NDEBUG
+extern int _PyThreadState_CheckConsistency(PyThreadState *tstate);
+#endif
+
+extern int _PyThreadState_MustExit(PyThreadState *tstate);
+
 /* Get the current Python thread state.
 
    This function is unsafe: it does not check for error and it can return NULL.
diff --git a/Include/moduleobject.h b/Include/moduleobject.h
index b8bdfe29d8..1717eb352d 100644
--- a/Include/moduleobject.h
+++ b/Include/moduleobject.h
@@ -84,13 +84,15 @@ struct PyModuleDef_Slot {
 #define _Py_mod_LAST_SLOT 3
 #endif
 
-/* for Py_mod_multiple_interpreters: */
-#define Py_MOD_MULTIPLE_INTERPRETERS_NOT_SUPPORTED ((void *)0)
-#define Py_MOD_MULTIPLE_INTERPRETERS_SUPPORTED ((void *)1)
-#define Py_MOD_PER_INTERPRETER_GIL_SUPPORTED ((void *)2)
-
 #endif /* New in 3.5 */
 
+/* for Py_mod_multiple_interpreters: */
+#if !defined(Py_LIMITED_API) || Py_LIMITED_API+0 >= 0x030c0000
+#  define Py_MOD_MULTIPLE_INTERPRETERS_NOT_SUPPORTED ((void *)0)
+#  define Py_MOD_MULTIPLE_INTERPRETERS_SUPPORTED ((void *)1)
+#  define Py_MOD_PER_INTERPRETER_GIL_SUPPORTED ((void *)2)
+#endif
+
 struct PyModuleDef {
   PyModuleDef_Base m_base;
   const char* m_name;
diff --git a/Include/patchlevel.h b/Include/patchlevel.h
index bb4598641c..c8440667d8 100644
--- a/Include/patchlevel.h
+++ b/Include/patchlevel.h
@@ -23,7 +23,7 @@
 #define PY_RELEASE_SERIAL       0
 
 /* Version as a string */
-#define PY_VERSION              "3.12.0"
+#define PY_VERSION              "3.12.0+"
 /*--end constants--*/
 
 /* Version as a single 4-byte hex number, e.g. 0x010502B2 == 1.5.2b2.
diff --git a/Lib/_pydatetime.py b/Lib/_pydatetime.py
index a6d43399f9..0e34d8aacf 100644
--- a/Lib/_pydatetime.py
+++ b/Lib/_pydatetime.py
@@ -1015,13 +1015,9 @@ def fromisocalendar(cls, year, week, day):
     def __repr__(self):
         """Convert to formal string, for repr().
 
-        >>> dt = datetime(2010, 1, 1)
-        >>> repr(dt)
-        'datetime.datetime(2010, 1, 1, 0, 0)'
-
-        >>> dt = datetime(2010, 1, 1, tzinfo=timezone.utc)
-        >>> repr(dt)
-        'datetime.datetime(2010, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)'
+        >>> d = date(2010, 1, 1)
+        >>> repr(d)
+        'datetime.date(2010, 1, 1)'
         """
         return "%s.%s(%d, %d, %d)" % (_get_class_module(self),
                                       self.__class__.__qualname__,
diff --git a/Lib/ast.py b/Lib/ast.py
index 07044706dc..de940d2e9c 100644
--- a/Lib/ast.py
+++ b/Lib/ast.py
@@ -1268,13 +1268,15 @@ def visit_JoinedStr(self, node):
         quote_type = quote_types[0]
         self.write(f"{quote_type}{value}{quote_type}")
 
-    def _write_fstring_inner(self, node):
+    def _write_fstring_inner(self, node, scape_newlines=False):
         if isinstance(node, JoinedStr):
             # for both the f-string itself, and format_spec
             for value in node.values:
-                self._write_fstring_inner(value)
+                self._write_fstring_inner(value, scape_newlines=scape_newlines)
         elif isinstance(node, Constant) and isinstance(node.value, str):
             value = node.value.replace("{", "{{").replace("}", "}}")
+            if scape_newlines:
+                value = value.replace("\n", "\\n")
             self.write(value)
         elif isinstance(node, FormattedValue):
             self.visit_FormattedValue(node)
@@ -1297,7 +1299,10 @@ def unparse_inner(inner):
                 self.write(f"!{chr(node.conversion)}")
             if node.format_spec:
                 self.write(":")
-                self._write_fstring_inner(node.format_spec)
+                self._write_fstring_inner(
+                    node.format_spec,
+                    scape_newlines=True
+                )
 
     def visit_Name(self, node):
         self.write(node.id)
diff --git a/Lib/asyncio/base_events.py b/Lib/asyncio/base_events.py
index 259004650d..5318a597e0 100644
--- a/Lib/asyncio/base_events.py
+++ b/Lib/asyncio/base_events.py
@@ -305,7 +305,7 @@ def _wakeup(self):
         self._waiters = None
         for waiter in waiters:
             if not waiter.done():
-                waiter.set_result(waiter)
+                waiter.set_result(None)
 
     def _start_serving(self):
         if self._serving:
@@ -377,7 +377,27 @@ async def serve_forever(self):
             self._serving_forever_fut = None
 
     async def wait_closed(self):
-        if self._waiters is None or self._active_count == 0:
+        """Wait until server is closed and all connections are dropped.
+
+        - If the server is not closed, wait.
+        - If it is closed, but there are still active connections, wait.
+
+        Anyone waiting here will be unblocked once both conditions
+        (server is closed and all connections have been dropped)
+        have become true, in either order.
+
+        Historical note: In 3.11 and before, this was broken, returning
+        immediately if the server was already closed, even if there
+        were still active connections. An attempted fix in 3.12.0 was
+        still broken, returning immediately if the server was still
+        open and there were no active connections. Hopefully in 3.12.1
+        we have it right.
+        """
+        # Waiters are unblocked by self._wakeup(), which is called
+        # from two places: self.close() and self._detach(), but only
+        # when both conditions have become true. To signal that this
+        # has happened, self._wakeup() sets self._waiters to None.
+        if self._waiters is None:
             return
         waiter = self._loop.create_future()
         self._waiters.append(waiter)
diff --git a/Lib/asyncio/streams.py b/Lib/asyncio/streams.py
index 14861dffce..f63eeca2a7 100644
--- a/Lib/asyncio/streams.py
+++ b/Lib/asyncio/streams.py
@@ -66,9 +66,8 @@ async def start_server(client_connected_cb, host=None, port=None, *,
     positional host and port, with various optional keyword arguments
     following.  The return value is the same as loop.create_server().
 
-    Additional optional keyword arguments are loop (to set the event loop
-    instance to use) and limit (to set the buffer limit passed to the
-    StreamReader).
+    Additional optional keyword argument is limit (to set the buffer
+    limit passed to the StreamReader).
 
     The return value is the same as loop.create_server(), i.e. a
     Server object which can be used to stop the service.
@@ -245,7 +244,19 @@ def connection_made(self, transport):
             res = self._client_connected_cb(reader,
                                             self._stream_writer)
             if coroutines.iscoroutine(res):
+                def callback(task):
+                    exc = task.exception()
+                    if exc is not None:
+                        self._loop.call_exception_handler({
+                            'message': 'Unhandled exception in client_connected_cb',
+                            'exception': exc,
+                            'transport': transport,
+                        })
+                        transport.close()
+
                 self._task = self._loop.create_task(res)
+                self._task.add_done_callback(callback)
+
             self._strong_reader = None
 
     def connection_lost(self, exc):
diff --git a/Lib/asyncio/subprocess.py b/Lib/asyncio/subprocess.py
index c4e5ba2061..043359bbd0 100644
--- a/Lib/asyncio/subprocess.py
+++ b/Lib/asyncio/subprocess.py
@@ -147,15 +147,17 @@ def kill(self):
 
     async def _feed_stdin(self, input):
         debug = self._loop.get_debug()
-        if input is not None:
-            self.stdin.write(input)
-            if debug:
-                logger.debug(
-                    '%r communicate: feed stdin (%s bytes)', self, len(input))
         try:
+            if input is not None:
+                self.stdin.write(input)
+                if debug:
+                    logger.debug(
+                        '%r communicate: feed stdin (%s bytes)', self, len(input))
+
             await self.stdin.drain()
         except (BrokenPipeError, ConnectionResetError) as exc:
-            # communicate() ignores BrokenPipeError and ConnectionResetError
+            # communicate() ignores BrokenPipeError and ConnectionResetError.
+            # write() and drain() can raise these exceptions.
             if debug:
                 logger.debug('%r communicate: stdin got %r', self, exc)
 
diff --git a/Lib/asyncio/taskgroups.py b/Lib/asyncio/taskgroups.py
index 930da53d90..d264e51f1f 100644
--- a/Lib/asyncio/taskgroups.py
+++ b/Lib/asyncio/taskgroups.py
@@ -54,16 +54,14 @@ def __repr__(self):
     async def __aenter__(self):
         if self._entered:
             raise RuntimeError(
-                f"TaskGroup {self!r} has been already entered")
-        self._entered = True
-
+                f"TaskGroup {self!r} has already been entered")
         if self._loop is None:
             self._loop = events.get_running_loop()
-
         self._parent_task = tasks.current_task(self._loop)
         if self._parent_task is None:
             raise RuntimeError(
                 f'TaskGroup {self!r} cannot determine the parent task')
+        self._entered = True
 
         return self
 
diff --git a/Lib/asyncio/tasks.py b/Lib/asyncio/tasks.py
index 152c9f8afc..65f2a6ef80 100644
--- a/Lib/asyncio/tasks.py
+++ b/Lib/asyncio/tasks.py
@@ -86,15 +86,25 @@ class Task(futures._PyFuture):  # Inherit Python Task implementation
     """A coroutine wrapped in a Future."""
 
     # An important invariant maintained while a Task not done:
+    # _fut_waiter is either None or a Future.  The Future
+    # can be either done() or not done().
+    # The task can be in any of 3 states:
     #
-    # - Either _fut_waiter is None, and _step() is scheduled;
-    # - or _fut_waiter is some Future, and _step() is *not* scheduled.
+    # - 1: _fut_waiter is not None and not _fut_waiter.done():
+    #      __step() is *not* scheduled and the Task is waiting for _fut_waiter.
+    # - 2: (_fut_waiter is None or _fut_waiter.done()) and __step() is scheduled:
+    #       the Task is waiting for __step() to be executed.
+    # - 3:  _fut_waiter is None and __step() is *not* scheduled:
+    #       the Task is currently executing (in __step()).
     #
-    # The only transition from the latter to the former is through
-    # _wakeup().  When _fut_waiter is not None, one of its callbacks
-    # must be _wakeup().
-
-    # If False, don't log a message if the task is destroyed whereas its
+    # * In state 1, one of the callbacks of __fut_waiter must be __wakeup().
+    # * The transition from 1 to 2 happens when _fut_waiter becomes done(),
+    #   as it schedules __wakeup() to be called (which calls __step() so
+    #   we way that __step() is scheduled).
+    # * It transitions from 2 to 3 when __step() is executed, and it clears
+    #   _fut_waiter to None.
+
+    # If False, don't log a message if the task is destroyed while its
     # status is still pending
     _log_destroy_pending = True
 
diff --git a/Lib/asyncio/timeouts.py b/Lib/asyncio/timeouts.py
index 029c468739..30042abb3a 100644
--- a/Lib/asyncio/timeouts.py
+++ b/Lib/asyncio/timeouts.py
@@ -49,8 +49,9 @@ def when(self) -> Optional[float]:
 
     def reschedule(self, when: Optional[float]) -> None:
         """Reschedule the timeout."""
-        assert self._state is not _State.CREATED
         if self._state is not _State.ENTERED:
+            if self._state is _State.CREATED:
+                raise RuntimeError("Timeout has not been entered")
             raise RuntimeError(
                 f"Cannot change state of {self._state.value} Timeout",
             )
@@ -82,11 +83,14 @@ def __repr__(self) -> str:
         return f"<Timeout [{self._state.value}]{info_str}>"
 
     async def __aenter__(self) -> "Timeout":
+        if self._state is not _State.CREATED:
+            raise RuntimeError("Timeout has already been entered")
+        task = tasks.current_task()
+        if task is None:
+            raise RuntimeError("Timeout should be used inside a task")
         self._state = _State.ENTERED
-        self._task = tasks.current_task()
+        self._task = task
         self._cancelling = self._task.cancelling()
-        if self._task is None:
-            raise RuntimeError("Timeout should be used inside a task")
         self.reschedule(self._when)
         return self
 
diff --git a/Lib/asyncio/unix_events.py b/Lib/asyncio/unix_events.py
index 17fb4d5f76..f2e920ada4 100644
--- a/Lib/asyncio/unix_events.py
+++ b/Lib/asyncio/unix_events.py
@@ -226,8 +226,7 @@ async def _make_subprocess_transport(self, protocol, args, shell,
         return transp
 
     def _child_watcher_callback(self, pid, returncode, transp):
-        # Skip one iteration for callbacks to be executed
-        self.call_soon_threadsafe(self.call_soon, transp._process_exited, returncode)
+        self.call_soon_threadsafe(transp._process_exited, returncode)
 
     async def create_unix_connection(
             self, protocol_factory, path=None, *,
@@ -1368,14 +1367,7 @@ def is_active(self):
         return True
 
     def close(self):
-        self._join_threads()
-
-    def _join_threads(self):
-        """Internal: Join all non-daemon threads"""
-        threads = [thread for thread in list(self._threads.values())
-                   if thread.is_alive() and not thread.daemon]
-        for thread in threads:
-            thread.join()
+        pass
 
     def __enter__(self):
         return self
@@ -1394,7 +1386,7 @@ def __del__(self, _warn=warnings.warn):
     def add_child_handler(self, pid, callback, *args):
         loop = events.get_running_loop()
         thread = threading.Thread(target=self._do_waitpid,
-                                  name=f"waitpid-{next(self._pid_counter)}",
+                                  name=f"asyncio-waitpid-{next(self._pid_counter)}",
                                   args=(loop, pid, callback, args),
                                   daemon=True)
         self._threads[pid] = thread
@@ -1462,8 +1454,6 @@ def _init_watcher(self):
                     self._watcher = PidfdChildWatcher()
                 else:
                     self._watcher = ThreadedChildWatcher()
-                if threading.current_thread() is threading.main_thread():
-                    self._watcher.attach_loop(self._local._loop)
 
     def set_event_loop(self, loop):
         """Set the event loop.
diff --git a/Lib/codecs.py b/Lib/codecs.py
index c1c55d8afe..82f23983e7 100644
--- a/Lib/codecs.py
+++ b/Lib/codecs.py
@@ -414,6 +414,9 @@ def __enter__(self):
     def __exit__(self, type, value, tb):
         self.stream.close()
 
+    def __reduce_ex__(self, proto):
+        raise TypeError("can't serialize %s" % self.__class__.__name__)
+
 ###
 
 class StreamReader(Codec):
@@ -663,6 +666,9 @@ def __enter__(self):
     def __exit__(self, type, value, tb):
         self.stream.close()
 
+    def __reduce_ex__(self, proto):
+        raise TypeError("can't serialize %s" % self.__class__.__name__)
+
 ###
 
 class StreamReaderWriter:
@@ -750,6 +756,9 @@ def __enter__(self):
     def __exit__(self, type, value, tb):
         self.stream.close()
 
+    def __reduce_ex__(self, proto):
+        raise TypeError("can't serialize %s" % self.__class__.__name__)
+
 ###
 
 class StreamRecoder:
@@ -866,6 +875,9 @@ def __enter__(self):
     def __exit__(self, type, value, tb):
         self.stream.close()
 
+    def __reduce_ex__(self, proto):
+        raise TypeError("can't serialize %s" % self.__class__.__name__)
+
 ### Shortcuts
 
 def open(filename, mode='r', encoding=None, errors='strict', buffering=-1):
diff --git a/Lib/codeop.py b/Lib/codeop.py
index 2213b69f23..4dd096574b 100644
--- a/Lib/codeop.py
+++ b/Lib/codeop.py
@@ -70,8 +70,7 @@ def _maybe_compile(compiler, source, filename, symbol):
                     return None
                 # fallthrough
 
-    return compiler(source, filename, symbol)
-
+    return compiler(source, filename, symbol, incomplete_input=False)
 
 def _is_syntax_error(err1, err2):
     rep1 = repr(err1)
@@ -82,8 +81,13 @@ def _is_syntax_error(err1, err2):
         return True
     return False
 
-def _compile(source, filename, symbol):
-    return compile(source, filename, symbol, PyCF_DONT_IMPLY_DEDENT | PyCF_ALLOW_INCOMPLETE_INPUT)
+def _compile(source, filename, symbol, incomplete_input=True):
+    flags = 0
+    if incomplete_input:
+        flags |= PyCF_ALLOW_INCOMPLETE_INPUT
+        flags |= PyCF_DONT_IMPLY_DEDENT
+    return compile(source, filename, symbol, flags)
+
 
 def compile_command(source, filename="<input>", symbol="single"):
     r"""Compile a command and determine whether it is incomplete.
@@ -114,8 +118,12 @@ class Compile:
     def __init__(self):
         self.flags = PyCF_DONT_IMPLY_DEDENT | PyCF_ALLOW_INCOMPLETE_INPUT
 
-    def __call__(self, source, filename, symbol):
-        codeob = compile(source, filename, symbol, self.flags, True)
+    def __call__(self, source, filename, symbol, **kwargs):
+        flags = self.flags
+        if kwargs.get('incomplete_input', True) is False:
+            flags &= ~PyCF_DONT_IMPLY_DEDENT
+            flags &= ~PyCF_ALLOW_INCOMPLETE_INPUT
+        codeob = compile(source, filename, symbol, flags, True)
         for feature in _features:
             if codeob.co_flags & feature.compiler_flag:
                 self.flags |= feature.compiler_flag
diff --git a/Lib/concurrent/futures/process.py b/Lib/concurrent/futures/process.py
index 301207f59d..8359a4fce6 100644
--- a/Lib/concurrent/futures/process.py
+++ b/Lib/concurrent/futures/process.py
@@ -71,6 +71,11 @@ def __init__(self):
         self._reader, self._writer = mp.Pipe(duplex=False)
 
     def close(self):
+        # Please note that we do not take the shutdown lock when
+        # calling clear() (to avoid deadlocking) so this method can
+        # only be called safely from the same thread as all calls to
+        # clear() even if you hold the shutdown lock. Otherwise we
+        # might try to read from the closed pipe.
         if not self._closed:
             self._closed = True
             self._writer.close()
@@ -336,7 +341,14 @@ def run(self):
         # Main loop for the executor manager thread.
 
         while True:
-            self.add_call_item_to_queue()
+            # gh-109047: During Python finalization, self.call_queue.put()
+            # creation of a thread can fail with RuntimeError.
+            try:
+                self.add_call_item_to_queue()
+            except BaseException as exc:
+                cause = format_exception(exc)
+                self.terminate_broken(cause)
+                return
 
             result_item, is_broken, cause = self.wait_result_broken_or_wakeup()
 
@@ -420,14 +432,18 @@ def wait_result_broken_or_wakeup(self):
             try:
                 result_item = result_reader.recv()
                 is_broken = False
-            except BaseException as e:
-                cause = format_exception(type(e), e, e.__traceback__)
+            except BaseException as exc:
+                cause = format_exception(exc)
 
         elif wakeup_reader in ready:
             is_broken = False
 
-        with self.shutdown_lock:
-            self.thread_wakeup.clear()
+        # No need to hold the _shutdown_lock here because:
+        # 1. we're the only thread to use the wakeup reader
+        # 2. we're also the only thread to call thread_wakeup.close()
+        # 3. we want to avoid a possible deadlock when both reader and writer
+        #    would block (gh-105829)
+        self.thread_wakeup.clear()
 
         return result_item, is_broken, cause
 
@@ -464,7 +480,7 @@ def is_shutting_down(self):
         return (_global_shutdown or executor is None
                 or executor._shutdown_thread)
 
-    def terminate_broken(self, cause):
+    def _terminate_broken(self, cause):
         # Terminate the executor because it is in a broken state. The cause
         # argument can be used to display more information on the error that
         # lead the executor into becoming broken.
@@ -489,7 +505,14 @@ def terminate_broken(self, cause):
 
         # Mark pending tasks as failed.
         for work_id, work_item in self.pending_work_items.items():
-            work_item.future.set_exception(bpe)
+            try:
+                work_item.future.set_exception(bpe)
+            except _base.InvalidStateError:
+                # set_exception() fails if the future is cancelled: ignore it.
+                # Trying to check if the future is cancelled before calling
+                # set_exception() would leave a race condition if the future is
+                # cancelled between the check and set_exception().
+                pass
             # Delete references to object. See issue16284
             del work_item
         self.pending_work_items.clear()
@@ -499,12 +522,18 @@ def terminate_broken(self, cause):
         for p in self.processes.values():
             p.terminate()
 
-        # Prevent queue writing to a pipe which is no longer read.
-        # https://github.com/python/cpython/issues/94777
-        self.call_queue._reader.close()
+        self.call_queue._terminate_broken()
+
+        # gh-107219: Close the connection writer which can unblock
+        # Queue._feed() if it was stuck in send_bytes().
+        self.call_queue._writer.close()
 
         # clean up resources
-        self.join_executor_internals()
+        self._join_executor_internals(broken=True)
+
+    def terminate_broken(self, cause):
+        with self.shutdown_lock:
+            self._terminate_broken(cause)
 
     def flag_executor_shutting_down(self):
         # Flag the executor as shutting down and cancel remaining tasks if
@@ -547,15 +576,24 @@ def shutdown_workers(self):
                     break
 
     def join_executor_internals(self):
-        self.shutdown_workers()
+        with self.shutdown_lock:
+            self._join_executor_internals()
+
+    def _join_executor_internals(self, broken=False):
+        # If broken, call_queue was closed and so can no longer be used.
+        if not broken:
+            self.shutdown_workers()
+
         # Release the queue's resources as soon as possible.
         self.call_queue.close()
         self.call_queue.join_thread()
-        with self.shutdown_lock:
-            self.thread_wakeup.close()
+        self.thread_wakeup.close()
+
         # If .join() is not called on the created processes then
         # some ctx.Queue methods may deadlock on Mac OS X.
         for p in self.processes.values():
+            if broken:
+                p.terminate()
             p.join()
 
     def get_n_children_alive(self):
@@ -706,7 +744,10 @@ def __init__(self, max_workers=None, mp_context=None,
         # as it could result in a deadlock if a worker process dies with the
         # _result_queue write lock still acquired.
         #
-        # _shutdown_lock must be locked to access _ThreadWakeup.
+        # _shutdown_lock must be locked to access _ThreadWakeup.close() and
+        # .wakeup(). Care must also be taken to not call clear or close from
+        # more than one thread since _ThreadWakeup.clear() is not protected by
+        # the _shutdown_lock
         self._executor_manager_thread_wakeup = _ThreadWakeup()
 
         # Create communication channels for the executor
diff --git a/Lib/contextlib.py b/Lib/contextlib.py
index b5acbcb9e6..2efed2d9ec 100644
--- a/Lib/contextlib.py
+++ b/Lib/contextlib.py
@@ -145,7 +145,10 @@ def __exit__(self, typ, value, traceback):
             except StopIteration:
                 return False
             else:
-                raise RuntimeError("generator didn't stop")
+                try:
+                    raise RuntimeError("generator didn't stop")
+                finally:
+                    self.gen.close()
         else:
             if value is None:
                 # Need to force instantiation so we can reliably
@@ -187,7 +190,10 @@ def __exit__(self, typ, value, traceback):
                     raise
                 exc.__traceback__ = traceback
                 return False
-            raise RuntimeError("generator didn't stop after throw()")
+            try:
+                raise RuntimeError("generator didn't stop after throw()")
+            finally:
+                self.gen.close()
 
 class _AsyncGeneratorContextManager(
     _GeneratorContextManagerBase,
@@ -212,7 +218,10 @@ async def __aexit__(self, typ, value, traceback):
             except StopAsyncIteration:
                 return False
             else:
-                raise RuntimeError("generator didn't stop")
+                try:
+                    raise RuntimeError("generator didn't stop")
+                finally:
+                    await self.gen.aclose()
         else:
             if value is None:
                 # Need to force instantiation so we can reliably
@@ -254,7 +263,10 @@ async def __aexit__(self, typ, value, traceback):
                     raise
                 exc.__traceback__ = traceback
                 return False
-            raise RuntimeError("generator didn't stop after athrow()")
+            try:
+                raise RuntimeError("generator didn't stop after athrow()")
+            finally:
+                await self.gen.aclose()
 
 
 def contextmanager(func):
diff --git a/Lib/dis.py b/Lib/dis.py
index 3a8e6ac3bf..320dec03d2 100644
--- a/Lib/dis.py
+++ b/Lib/dis.py
@@ -790,8 +790,7 @@ def dis(self):
             return output.getvalue()
 
 
-def _test():
-    """Simple test program to disassemble a file."""
+def main():
     import argparse
 
     parser = argparse.ArgumentParser()
@@ -803,4 +802,4 @@ def _test():
     dis(code)
 
 if __name__ == "__main__":
-    _test()
+    main()
diff --git a/Lib/doctest.py b/Lib/doctest.py
index a63df46a11..d7eaa8b131 100644
--- a/Lib/doctest.py
+++ b/Lib/doctest.py
@@ -1376,7 +1376,24 @@ def __run(self, test, compileflags, out):
 
             # The example raised an exception:  check if it was expected.
             else:
-                exc_msg = traceback.format_exception_only(*exception[:2])[-1]
+                formatted_ex = traceback.format_exception_only(*exception[:2])
+                if issubclass(exception[0], SyntaxError):
+                    # SyntaxError / IndentationError is special:
+                    # we don't care about the carets / suggestions / etc
+                    # We only care about the error message and notes.
+                    # They start with `SyntaxError:` (or any other class name)
+                    exception_line_prefixes = (
+                        f"{exception[0].__qualname__}:",
+                        f"{exception[0].__module__}.{exception[0].__qualname__}:",
+                    )
+                    exc_msg_index = next(
+                        index
+                        for index, line in enumerate(formatted_ex)
+                        if line.startswith(exception_line_prefixes)
+                    )
+                    formatted_ex = formatted_ex[exc_msg_index:]
+
+                exc_msg = "".join(formatted_ex)
                 if not quiet:
                     got += _exception_traceback(exception)
 
diff --git a/Lib/enum.py b/Lib/enum.py
index c207dc234c..4bd3756ec5 100644
--- a/Lib/enum.py
+++ b/Lib/enum.py
@@ -1217,14 +1217,13 @@ def __str__(self):
 
     def __dir__(self):
         """
-        Returns all members and all public methods
+        Returns public methods and other interesting attributes.
         """
-        if self.__class__._member_type_ is object:
-            interesting = set(['__class__', '__doc__', '__eq__', '__hash__', '__module__', 'name', 'value'])
-        else:
+        interesting = set()
+        if self.__class__._member_type_ is not object:
             interesting = set(object.__dir__(self))
         for name in getattr(self, '__dict__', []):
-            if name[0] != '_':
+            if name[0] != '_' and name not in self._member_map_:
                 interesting.add(name)
         for cls in self.__class__.mro():
             for name, obj in cls.__dict__.items():
@@ -1237,7 +1236,7 @@ def __dir__(self):
                     else:
                         # in case it was added by `dir(self)`
                         interesting.discard(name)
-                else:
+                elif name not in self._member_map_:
                     interesting.add(name)
         names = sorted(
                 set(['__class__', '__doc__', '__eq__', '__hash__', '__module__'])
diff --git a/Lib/gettext.py b/Lib/gettext.py
index b72b15f82d..e84765bfdf 100644
--- a/Lib/gettext.py
+++ b/Lib/gettext.py
@@ -46,6 +46,7 @@
 #   find this format documented anywhere.
 
 
+import operator
 import os
 import re
 import sys
@@ -166,14 +167,21 @@ def _parse(tokens, priority=-1):
 
 def _as_int(n):
     try:
-        i = round(n)
+        round(n)
     except TypeError:
         raise TypeError('Plural value must be an integer, got %s' %
                         (n.__class__.__name__,)) from None
+
     import warnings
+    frame = sys._getframe(1)
+    stacklevel = 2
+    while frame.f_back is not None and frame.f_globals.get('__name__') == __name__:
+        stacklevel += 1
+        frame = frame.f_back
     warnings.warn('Plural value must be an integer, got %s' %
                   (n.__class__.__name__,),
-                  DeprecationWarning, 4)
+                  DeprecationWarning,
+                  stacklevel)
     return n
 
 
@@ -200,7 +208,7 @@ def c2py(plural):
             elif c == ')':
                 depth -= 1
 
-        ns = {'_as_int': _as_int}
+        ns = {'_as_int': _as_int, '__name__': __name__}
         exec('''if True:
             def func(n):
                 if not isinstance(n, int):
diff --git a/Lib/idlelib/config.py b/Lib/idlelib/config.py
index 2b09d79470..898efeb4dd 100644
--- a/Lib/idlelib/config.py
+++ b/Lib/idlelib/config.py
@@ -597,7 +597,9 @@ def GetCoreKeys(self, keySetName=None):
         problem getting any core binding there will be an 'ultimate last
         resort fallback' to the CUA-ish bindings defined here.
         """
+        # TODO: = dict(sorted([(v-event, keys), ...]))?
         keyBindings={
+            # vitual-event: list of key events.
             '<<copy>>': ['<Control-c>', '<Control-C>'],
             '<<cut>>': ['<Control-x>', '<Control-X>'],
             '<<paste>>': ['<Control-v>', '<Control-V>'],
@@ -880,7 +882,7 @@ def _dump():  # htest # (not really, but ignore in coverage)
     line, crc = 0, 0
 
     def sprint(obj):
-        global line, crc
+        nonlocal line, crc
         txt = str(obj)
         line += 1
         crc = crc32(txt.encode(encoding='utf-8'), crc)
@@ -889,7 +891,7 @@ def sprint(obj):
 
     def dumpCfg(cfg):
         print('\n', cfg, '\n')  # Cfg has variable '0xnnnnnnnn' address.
-        for key in sorted(cfg.keys()):
+        for key in sorted(cfg):
             sections = cfg[key].sections()
             sprint(key)
             sprint(sections)
@@ -908,4 +910,6 @@ def dumpCfg(cfg):
     from unittest import main
     main('idlelib.idle_test.test_config', verbosity=2, exit=False)
 
-    # Run revised _dump() as htest?
+    _dump()
+    # Run revised _dump() (700+ lines) as htest?  More sorting.
+    # Perhaps as window with tabs for textviews, making it config viewer.
diff --git a/Lib/idlelib/configdialog.py b/Lib/idlelib/configdialog.py
index cda7966d55..eedf97bf74 100644
--- a/Lib/idlelib/configdialog.py
+++ b/Lib/idlelib/configdialog.py
@@ -211,14 +211,8 @@ def help(self):
                   contents=help_common+help_pages.get(page, ''))
 
     def deactivate_current_config(self):
-        """Remove current key bindings.
-        Iterate over window instances defined in parent and remove
-        the keybindings.
-        """
-        # Before a config is saved, some cleanup of current
-        # config must be done - remove the previous keybindings.
-        win_instances = self.parent.instance_dict.keys()
-        for instance in win_instances:
+        """Remove current key bindings in current windows."""
+        for instance in self.parent.instance_dict:
             instance.RemoveKeybindings()
 
     def activate_config_changes(self):
@@ -227,8 +221,7 @@ def activate_config_changes(self):
         Dynamically update the current parent window instances
         with some of the configuration changes.
         """
-        win_instances = self.parent.instance_dict.keys()
-        for instance in win_instances:
+        for instance in self.parent.instance_dict:
             instance.ResetColorizer()
             instance.ResetFont()
             instance.set_notabs_indentwidth()
@@ -583,22 +576,23 @@ def create_page_highlight(self):
                 (*)theme_message: Label
         """
         self.theme_elements = {
-            'Normal Code or Text': ('normal', '00'),
-            'Code Context': ('context', '01'),
-            'Python Keywords': ('keyword', '02'),
-            'Python Definitions': ('definition', '03'),
-            'Python Builtins': ('builtin', '04'),
-            'Python Comments': ('comment', '05'),
-            'Python Strings': ('string', '06'),
-            'Selected Text': ('hilite', '07'),
-            'Found Text': ('hit', '08'),
-            'Cursor': ('cursor', '09'),
-            'Editor Breakpoint': ('break', '10'),
-            'Shell Prompt': ('console', '11'),
-            'Error Text': ('error', '12'),
-            'Shell User Output': ('stdout', '13'),
-            'Shell User Exception': ('stderr', '14'),
-            'Line Number': ('linenumber', '16'),
+            # Display-name: internal-config-tag-name.
+            'Normal Code or Text': 'normal',
+            'Code Context': 'context',
+            'Python Keywords': 'keyword',
+            'Python Definitions': 'definition',
+            'Python Builtins': 'builtin',
+            'Python Comments': 'comment',
+            'Python Strings': 'string',
+            'Selected Text': 'hilite',
+            'Found Text': 'hit',
+            'Cursor': 'cursor',
+            'Editor Breakpoint': 'break',
+            'Shell Prompt': 'console',
+            'Error Text': 'error',
+            'Shell User Output': 'stdout',
+            'Shell User Exception': 'stderr',
+            'Line Number': 'linenumber',
             }
         self.builtin_name = tracers.add(
                 StringVar(self), self.var_changed_builtin_name)
@@ -658,7 +652,7 @@ def tem(event, elem=element):
                 # event.widget.winfo_top_level().highlight_target.set(elem)
                 self.highlight_target.set(elem)
             text.tag_bind(
-                    self.theme_elements[element][0], '<ButtonPress-1>', tem)
+                    self.theme_elements[element], '<ButtonPress-1>', tem)
         text['state'] = 'disabled'
         self.style.configure('frame_color_set.TFrame', borderwidth=1,
                              relief='solid')
@@ -765,8 +759,7 @@ def load_theme_cfg(self):
             self.builtinlist.SetMenu(item_list, item_list[0])
         self.set_theme_type()
         # Load theme element option menu.
-        theme_names = list(self.theme_elements.keys())
-        theme_names.sort(key=lambda x: self.theme_elements[x][1])
+        theme_names = list(self.theme_elements)
         self.targetlist.SetMenu(theme_names, theme_names[0])
         self.paint_theme_sample()
         self.set_highlight_target()
@@ -893,7 +886,7 @@ def on_new_color_set(self):
         new_color = self.color.get()
         self.style.configure('frame_color_set.TFrame', background=new_color)
         plane = 'foreground' if self.fg_bg_toggle.get() else 'background'
-        sample_element = self.theme_elements[self.highlight_target.get()][0]
+        sample_element = self.theme_elements[self.highlight_target.get()]
         self.highlight_sample.tag_config(sample_element, **{plane: new_color})
         theme = self.custom_name.get()
         theme_element = sample_element + '-' + plane
@@ -1007,7 +1000,7 @@ def set_color_sample(self):
             frame_color_set
         """
         # Set the color sample area.
-        tag = self.theme_elements[self.highlight_target.get()][0]
+        tag = self.theme_elements[self.highlight_target.get()]
         plane = 'foreground' if self.fg_bg_toggle.get() else 'background'
         color = self.highlight_sample.tag_cget(tag, plane)
         self.style.configure('frame_color_set.TFrame', background=color)
@@ -1037,7 +1030,7 @@ def paint_theme_sample(self):
         else:  # User theme
             theme = self.custom_name.get()
         for element_title in self.theme_elements:
-            element = self.theme_elements[element_title][0]
+            element = self.theme_elements[element_title]
             colors = idleConf.GetHighlight(theme, element)
             if element == 'cursor':  # Cursor sample needs special painting.
                 colors['background'] = idleConf.GetHighlight(
@@ -1477,12 +1470,13 @@ def load_keys_list(self, keyset_name):
             reselect = True
             list_index = self.bindingslist.index(ANCHOR)
         keyset = idleConf.GetKeySet(keyset_name)
-        bind_names = list(keyset.keys())
+        # 'set' is dict mapping virtual event to list of key events.
+        bind_names = list(keyset)
         bind_names.sort()
         self.bindingslist.delete(0, END)
         for bind_name in bind_names:
             key = ' '.join(keyset[bind_name])
-            bind_name = bind_name[2:-2]  # Trim off the angle brackets.
+            bind_name = bind_name[2:-2]  # Trim double angle brackets.
             if keyset_name in changes['keys']:
                 # Handle any unsaved changes to this key set.
                 if bind_name in changes['keys'][keyset_name]:
diff --git a/Lib/idlelib/debugger.py b/Lib/idlelib/debugger.py
index 452c62b426..a92bb98d90 100644
--- a/Lib/idlelib/debugger.py
+++ b/Lib/idlelib/debugger.py
@@ -509,7 +509,7 @@ def load_dict(self, dict, force=0, rpc_client=None):
             # There is also an obscure bug in sorted(dict) where the
             # interpreter gets into a loop requesting non-existing dict[0],
             # dict[1], dict[2], etc from the debugger_r.DictProxy.
-            ###
+            # TODO recheck above; see debugger_r 159ff, debugobj 60.
             keys_list = dict.keys()
             names = sorted(keys_list)
             ###
diff --git a/Lib/idlelib/debugobj.py b/Lib/idlelib/debugobj.py
index 71d01c7070..032b686f37 100644
--- a/Lib/idlelib/debugobj.py
+++ b/Lib/idlelib/debugobj.py
@@ -93,7 +93,8 @@ def setfunction(value, key=key, object=self.object):
 
 class DictTreeItem(SequenceTreeItem):
     def keys(self):
-        keys = list(self.object.keys())
+        # TODO return sorted(self.object)
+        keys = list(self.object)
         try:
             keys.sort()
         except:
diff --git a/Lib/idlelib/idle_test/test_config.py b/Lib/idlelib/idle_test/test_config.py
index 08ed76fe28..a746f1538a 100644
--- a/Lib/idlelib/idle_test/test_config.py
+++ b/Lib/idlelib/idle_test/test_config.py
@@ -274,8 +274,8 @@ def test_create_config_handlers(self):
                 conf.CreateConfigHandlers()
 
         # Check keys are equal
-        self.assertCountEqual(conf.defaultCfg.keys(), conf.config_types)
-        self.assertCountEqual(conf.userCfg.keys(), conf.config_types)
+        self.assertCountEqual(conf.defaultCfg, conf.config_types)
+        self.assertCountEqual(conf.userCfg, conf.config_types)
 
         # Check conf parser are correct type
         for default_parser in conf.defaultCfg.values():
diff --git a/Lib/idlelib/idle_test/test_configdialog.py b/Lib/idlelib/idle_test/test_configdialog.py
index e5d5b4013f..6f8518a9bb 100644
--- a/Lib/idlelib/idle_test/test_configdialog.py
+++ b/Lib/idlelib/idle_test/test_configdialog.py
@@ -430,7 +430,7 @@ def test_highlight_target_text_mouse(self):
 
         def tag_to_element(elem):
             for element, tag in d.theme_elements.items():
-                elem[tag[0]] = element
+                elem[tag] = element
 
         def click_it(start):
             x, y, dx, dy = hs.bbox(start)
diff --git a/Lib/idlelib/idle_test/test_debugobj.py b/Lib/idlelib/idle_test/test_debugobj.py
index 131ce22b8b..90ace4e1bc 100644
--- a/Lib/idlelib/idle_test/test_debugobj.py
+++ b/Lib/idlelib/idle_test/test_debugobj.py
@@ -37,7 +37,7 @@ def test_isexpandable(self):
 
     def test_keys(self):
         ti = debugobj.SequenceTreeItem('label', 'abc')
-        self.assertEqual(list(ti.keys()), [0, 1, 2])
+        self.assertEqual(list(ti.keys()), [0, 1, 2])  # keys() is a range.
 
 
 class DictTreeItemTest(unittest.TestCase):
@@ -50,7 +50,7 @@ def test_isexpandable(self):
 
     def test_keys(self):
         ti = debugobj.DictTreeItem('label', {1:1, 0:0, 2:2})
-        self.assertEqual(ti.keys(), [0, 1, 2])
+        self.assertEqual(ti.keys(), [0, 1, 2])  # keys() is a sorted list.
 
 
 if __name__ == '__main__':
diff --git a/Lib/idlelib/pyshell.py b/Lib/idlelib/pyshell.py
index 6028700356..7a2707935b 100755
--- a/Lib/idlelib/pyshell.py
+++ b/Lib/idlelib/pyshell.py
@@ -747,10 +747,11 @@ def showtraceback(self):
             self.tkconsole.open_stack_viewer()
 
     def checklinecache(self):
-        c = linecache.cache
-        for key in list(c.keys()):
+        "Remove keys other than '<pyshell#n>'."
+        cache = linecache.cache
+        for key in list(cache):  # Iterate list because mutate cache.
             if key[:1] + key[-1:] != "<>":
-                del c[key]
+                del cache[key]
 
     def runcommand(self, code):
         "Run the code without invoking the debugger"
diff --git a/Lib/idlelib/stackviewer.py b/Lib/idlelib/stackviewer.py
index 7b00c4cdb7..4858cc682a 100644
--- a/Lib/idlelib/stackviewer.py
+++ b/Lib/idlelib/stackviewer.py
@@ -99,7 +99,7 @@ def IsExpandable(self):
 
     def GetSubList(self):
         sublist = []
-        for key in self.object.keys():
+        for key in self.object.keys():  # self.object not necessarily dict.
             try:
                 value = self.object[key]
             except KeyError:
diff --git a/Lib/ipaddress.py b/Lib/ipaddress.py
index af1d5c4800..9ca90fd0f7 100644
--- a/Lib/ipaddress.py
+++ b/Lib/ipaddress.py
@@ -1938,6 +1938,9 @@ def __eq__(self, other):
             return False
         return self._scope_id == getattr(other, '_scope_id', None)
 
+    def __reduce__(self):
+        return (self.__class__, (str(self),))
+
     @property
     def scope_id(self):
         """Identifier of a particular zone of the address's scope.
diff --git a/Lib/locale.py b/Lib/locale.py
index e94f0d1acb..4965c97307 100644
--- a/Lib/locale.py
+++ b/Lib/locale.py
@@ -541,12 +541,14 @@ def getdefaultlocale(envvars=('LC_ALL', 'LC_CTYPE', 'LANG', 'LANGUAGE')):
     """
 
     import warnings
-    warnings.warn(
-        "Use setlocale(), getencoding() and getlocale() instead",
-        DeprecationWarning, stacklevel=2
-    )
+    warnings._deprecated(
+        "locale.getdefaultlocale",
+        "{name!r} is deprecated and slated for removal in Python {remove}. "
+        "Use setlocale(), getencoding() and getlocale() instead.",
+        remove=(3, 15))
     return _getdefaultlocale(envvars)
 
+
 def _getdefaultlocale(envvars=('LC_ALL', 'LC_CTYPE', 'LANG', 'LANGUAGE')):
     try:
         # check if it's supported by the _locale module
diff --git a/Lib/logging/handlers.py b/Lib/logging/handlers.py
index 671cc9596b..6e88184b51 100644
--- a/Lib/logging/handlers.py
+++ b/Lib/logging/handlers.py
@@ -833,10 +833,8 @@ class SysLogHandler(logging.Handler):
         "local7":       LOG_LOCAL7,
         }
 
-    #The map below appears to be trivially lowercasing the key. However,
-    #there's more to it than meets the eye - in some locales, lowercasing
-    #gives unexpected results. See SF #1524081: in the Turkish locale,
-    #"INFO".lower() != "info"
+    # Originally added to work around GH-43683. Unnecessary since GH-50043 but kept
+    # for backwards compatibility.
     priority_map = {
         "DEBUG" : "debug",
         "INFO" : "info",
diff --git a/Lib/multiprocessing/connection.py b/Lib/multiprocessing/connection.py
index 04eaea811c..7c425a2d8e 100644
--- a/Lib/multiprocessing/connection.py
+++ b/Lib/multiprocessing/connection.py
@@ -9,6 +9,7 @@
 
 __all__ = [ 'Client', 'Listener', 'Pipe', 'wait' ]
 
+import errno
 import io
 import os
 import sys
@@ -41,6 +42,7 @@
 BUFSIZE = 8192
 # A very generous timeout when it comes to local connections...
 CONNECTION_TIMEOUT = 20.
+WSA_OPERATION_ABORTED = 995
 
 _mmap_counter = itertools.count()
 
@@ -271,12 +273,22 @@ class PipeConnection(_ConnectionBase):
         with FILE_FLAG_OVERLAPPED.
         """
         _got_empty_message = False
+        _send_ov = None
 
         def _close(self, _CloseHandle=_winapi.CloseHandle):
+            ov = self._send_ov
+            if ov is not None:
+                # Interrupt WaitForMultipleObjects() in _send_bytes()
+                ov.cancel()
             _CloseHandle(self._handle)
 
         def _send_bytes(self, buf):
+            if self._send_ov is not None:
+                # A connection should only be used by a single thread
+                raise ValueError("concurrent send_bytes() calls "
+                                 "are not supported")
             ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)
+            self._send_ov = ov
             try:
                 if err == _winapi.ERROR_IO_PENDING:
                     waitres = _winapi.WaitForMultipleObjects(
@@ -286,7 +298,13 @@ def _send_bytes(self, buf):
                 ov.cancel()
                 raise
             finally:
+                self._send_ov = None
                 nwritten, err = ov.GetOverlappedResult(True)
+            if err == WSA_OPERATION_ABORTED:
+                # close() was called by another thread while
+                # WaitForMultipleObjects() was waiting for the overlapped
+                # operation.
+                raise OSError(errno.EPIPE, "handle is closed")
             assert err == 0
             assert nwritten == len(buf)
 
diff --git a/Lib/multiprocessing/popen_spawn_win32.py b/Lib/multiprocessing/popen_spawn_win32.py
index 4d60ffc030..af04430570 100644
--- a/Lib/multiprocessing/popen_spawn_win32.py
+++ b/Lib/multiprocessing/popen_spawn_win32.py
@@ -14,6 +14,7 @@
 #
 #
 
+# Exit code used by Popen.terminate()
 TERMINATE = 0x10000
 WINEXE = (sys.platform == 'win32' and getattr(sys, 'frozen', False))
 WINSERVICE = sys.executable.lower().endswith("pythonservice.exe")
@@ -122,9 +123,15 @@ def terminate(self):
         if self.returncode is None:
             try:
                 _winapi.TerminateProcess(int(self._handle), TERMINATE)
-            except OSError:
-                if self.wait(timeout=1.0) is None:
+            except PermissionError:
+                # ERROR_ACCESS_DENIED (winerror 5) is received when the
+                # process already died.
+                code = _winapi.GetExitCodeProcess(int(self._handle))
+                if code == _winapi.STILL_ACTIVE:
                     raise
+                self.returncode = code
+            else:
+                self.returncode = -signal.SIGTERM
 
     kill = terminate
 
diff --git a/Lib/multiprocessing/queues.py b/Lib/multiprocessing/queues.py
index daf9ee94a1..d36de75749 100644
--- a/Lib/multiprocessing/queues.py
+++ b/Lib/multiprocessing/queues.py
@@ -158,6 +158,15 @@ def cancel_join_thread(self):
         except AttributeError:
             pass
 
+    def _terminate_broken(self):
+        # Close a Queue on error.
+
+        # gh-94777: Prevent queue writing to a pipe which is no longer read.
+        self._reader.close()
+
+        self.close()
+        self.join_thread()
+
     def _start_thread(self):
         debug('Queue._start_thread()')
 
@@ -169,13 +178,19 @@ def _start_thread(self):
                   self._wlock, self._reader.close, self._writer.close,
                   self._ignore_epipe, self._on_queue_feeder_error,
                   self._sem),
-            name='QueueFeederThread'
+            name='QueueFeederThread',
+            daemon=True,
         )
-        self._thread.daemon = True
 
-        debug('doing self._thread.start()')
-        self._thread.start()
-        debug('... done self._thread.start()')
+        try:
+            debug('doing self._thread.start()')
+            self._thread.start()
+            debug('... done self._thread.start()')
+        except:
+            # gh-109047: During Python finalization, creating a thread
+            # can fail with RuntimeError.
+            self._thread = None
+            raise
 
         if not self._joincancelled:
             self._jointhread = Finalize(
diff --git a/Lib/multiprocessing/resource_tracker.py b/Lib/multiprocessing/resource_tracker.py
index ea36950729..79e96ecf32 100644
--- a/Lib/multiprocessing/resource_tracker.py
+++ b/Lib/multiprocessing/resource_tracker.py
@@ -51,15 +51,31 @@
     })
 
 
+class ReentrantCallError(RuntimeError):
+    pass
+
+
 class ResourceTracker(object):
 
     def __init__(self):
-        self._lock = threading.Lock()
+        self._lock = threading.RLock()
         self._fd = None
         self._pid = None
 
+    def _reentrant_call_error(self):
+        # gh-109629: this happens if an explicit call to the ResourceTracker
+        # gets interrupted by a garbage collection, invoking a finalizer (*)
+        # that itself calls back into ResourceTracker.
+        #   (*) for example the SemLock finalizer
+        raise ReentrantCallError(
+            "Reentrant call into the multiprocessing resource tracker")
+
     def _stop(self):
         with self._lock:
+            # This should not happen (_stop() isn't called by a finalizer)
+            # but we check for it anyway.
+            if self._lock._recursion_count() > 1:
+                return self._reentrant_call_error()
             if self._fd is None:
                 # not running
                 return
@@ -81,6 +97,9 @@ def ensure_running(self):
         This can be run from any process.  Usually a child process will use
         the resource created by its parent.'''
         with self._lock:
+            if self._lock._recursion_count() > 1:
+                # The code below is certainly not reentrant-safe, so bail out
+                return self._reentrant_call_error()
             if self._fd is not None:
                 # resource tracker was launched before, is it still running?
                 if self._check_alive():
@@ -159,7 +178,17 @@ def unregister(self, name, rtype):
         self._send('UNREGISTER', name, rtype)
 
     def _send(self, cmd, name, rtype):
-        self.ensure_running()
+        try:
+            self.ensure_running()
+        except ReentrantCallError:
+            # The code below might or might not work, depending on whether
+            # the resource tracker was already running and still alive.
+            # Better warn the user.
+            # (XXX is warnings.warn itself reentrant-safe? :-)
+            warnings.warn(
+                f"ResourceTracker called reentrantly for resource cleanup, "
+                f"which is unsupported. "
+                f"The {rtype} object {name!r} might leak.")
         msg = '{0}:{1}:{2}\n'.format(cmd, name, rtype).encode('ascii')
         if len(msg) > 512:
             # posix guarantees that writes to a pipe of less than PIPE_BUF
@@ -176,6 +205,7 @@ def _send(self, cmd, name, rtype):
 unregister = _resource_tracker.unregister
 getfd = _resource_tracker.getfd
 
+
 def main(fd):
     '''Run resource tracker.'''
     # protect the process from ^C and "killall python" etc
diff --git a/Lib/pathlib.py b/Lib/pathlib.py
index 65631b7039..bd5a096f9e 100644
--- a/Lib/pathlib.py
+++ b/Lib/pathlib.py
@@ -630,8 +630,7 @@ def with_name(self, name):
         if not self.name:
             raise ValueError("%r has an empty name" % (self,))
         f = self._flavour
-        drv, root, tail = f.splitroot(name)
-        if drv or root or not tail or f.sep in tail or (f.altsep and f.altsep in tail):
+        if not name or f.sep in name or (f.altsep and f.altsep in name) or name == '.':
             raise ValueError("Invalid name %r" % (name))
         return self._from_parsed_parts(self.drive, self.root,
                                        self._tail[:-1] + [name])
diff --git a/Lib/pdb.py b/Lib/pdb.py
index 6b6feac1dd..2e048ac5ba 100755
--- a/Lib/pdb.py
+++ b/Lib/pdb.py
@@ -136,6 +136,9 @@ def check(self):
         if not os.path.exists(self):
             print('Error:', self.orig, 'does not exist')
             sys.exit(1)
+        if os.path.isdir(self):
+            print('Error:', self.orig, 'is a directory')
+            sys.exit(1)
 
         # Replace pdb's dir with script's dir in front of module search path.
         sys.path[0] = os.path.dirname(self)
@@ -162,6 +165,9 @@ class _ModuleTarget(str):
     def check(self):
         try:
             self._details
+        except ImportError as e:
+            print(f"ImportError: {e}")
+            sys.exit(1)
         except Exception:
             traceback.print_exc()
             sys.exit(1)
@@ -410,8 +416,9 @@ def preloop(self):
                 # fields are changed to be displayed
                 if newvalue is not oldvalue and newvalue != oldvalue:
                     displaying[expr] = newvalue
-                    self.message('display %s: %r  [old: %r]' %
-                                 (expr, newvalue, oldvalue))
+                    self.message('display %s: %s  [old: %s]' %
+                                 (expr, self._safe_repr(newvalue, expr),
+                                  self._safe_repr(oldvalue, expr)))
 
     def interaction(self, frame, traceback):
         # Restore the previous signal handler at the Pdb prompt.
@@ -1264,7 +1271,7 @@ def do_args(self, arg):
         for i in range(n):
             name = co.co_varnames[i]
             if name in dict:
-                self.message('%s = %r' % (name, dict[name]))
+                self.message('%s = %s' % (name, self._safe_repr(dict[name], name)))
             else:
                 self.message('%s = *** undefined ***' % (name,))
     do_a = do_args
@@ -1275,7 +1282,7 @@ def do_retval(self, arg):
         Print the return value for the last return of a function.
         """
         if '__return__' in self.curframe_locals:
-            self.message(repr(self.curframe_locals['__return__']))
+            self.message(self._safe_repr(self.curframe_locals['__return__'], "retval"))
         else:
             self.error('Not yet returned!')
     do_rv = do_retval
@@ -1310,6 +1317,12 @@ def _msg_val_func(self, arg, func):
         except:
             self._error_exc()
 
+    def _safe_repr(self, obj, expr):
+        try:
+            return repr(obj)
+        except Exception as e:
+            return _rstr(f"*** repr({expr}) failed: {self._format_exc(e)} ***")
+
     def do_p(self, arg):
         """p expression
 
@@ -1486,8 +1499,8 @@ def do_display(self, arg):
         if not arg:
             if self.displaying:
                 self.message('Currently displaying:')
-                for item in self.displaying.get(self.curframe, {}).items():
-                    self.message('%s: %r' % item)
+                for key, val in self.displaying.get(self.curframe, {}).items():
+                    self.message('%s: %s' % (key, self._safe_repr(val, key)))
             else:
                 self.message('No expression is being displayed')
         else:
@@ -1496,7 +1509,7 @@ def do_display(self, arg):
             else:
                 val = self._getval_except(arg)
                 self.displaying.setdefault(self.curframe, {})[arg] = val
-                self.message('display %s: %r' % (arg, val))
+                self.message('display %s: %s' % (arg, self._safe_repr(val, arg)))
 
     complete_display = _complete_expression
 
@@ -1559,8 +1572,11 @@ def do_alias(self, arg):
             for alias in keys:
                 self.message("%s = %s" % (alias, self.aliases[alias]))
             return
-        if args[0] in self.aliases and len(args) == 1:
-            self.message("%s = %s" % (args[0], self.aliases[args[0]]))
+        if len(args) == 1:
+            if args[0] in self.aliases:
+                self.message("%s = %s" % (args[0], self.aliases[args[0]]))
+            else:
+                self.error(f"Unknown alias '{args[0]}'")
         else:
             self.aliases[args[0]] = ' '.join(args[1:])
 
diff --git a/Lib/random.py b/Lib/random.py
index 84bbfc5df1..1cfc2ba2f0 100644
--- a/Lib/random.py
+++ b/Lib/random.py
@@ -65,7 +65,7 @@
 
 try:
     # hashlib is pretty heavy to load, try lean internal module first
-    from _sha512 import sha512 as _sha512
+    from _sha2 import sha512 as _sha512
 except ImportError:
     # fallback to official implementation
     from hashlib import sha512 as _sha512
@@ -492,7 +492,14 @@ def choices(self, population, weights=None, *, cum_weights=None, k=1):
     ## -------------------- real-valued distributions  -------------------
 
     def uniform(self, a, b):
-        "Get a random number in the range [a, b) or [a, b] depending on rounding."
+        """Get a random number in the range [a, b) or [a, b] depending on rounding.
+
+        The mean (expected value) and variance of the random variable are:
+
+            E[X] = (a + b) / 2
+            Var[X] = (b - a) ** 2 / 12
+
+        """
         return a + (b - a) * self.random()
 
     def triangular(self, low=0.0, high=1.0, mode=None):
@@ -503,6 +510,11 @@ def triangular(self, low=0.0, high=1.0, mode=None):
 
         http://en.wikipedia.org/wiki/Triangular_distribution
 
+        The mean (expected value) and variance of the random variable are:
+
+            E[X] = (low + high + mode) / 3
+            Var[X] = (low**2 + high**2 + mode**2 - low*high - low*mode - high*mode) / 18
+
         """
         u = self.random()
         try:
@@ -593,12 +605,15 @@ def expovariate(self, lambd=1.0):
         positive infinity if lambd is positive, and from negative
         infinity to 0 if lambd is negative.
 
-        """
-        # lambd: rate lambd = 1/mean
-        # ('lambda' is a Python reserved word)
+        The mean (expected value) and variance of the random variable are:
+
+            E[X] = 1 / lambd
+            Var[X] = 1 / lambd ** 2
 
+        """
         # we use 1-random() instead of random() to preclude the
         # possibility of taking the log of zero.
+
         return -_log(1.0 - self.random()) / lambd
 
     def vonmisesvariate(self, mu, kappa):
@@ -654,8 +669,12 @@ def gammavariate(self, alpha, beta):
           pdf(x) =  --------------------------------------
                       math.gamma(alpha) * beta ** alpha
 
+        The mean (expected value) and variance of the random variable are:
+
+            E[X] = alpha * beta
+            Var[X] = alpha * beta ** 2
+
         """
-        # alpha > 0, beta > 0, mean is alpha*beta, variance is alpha*beta**2
 
         # Warning: a few older sources define the gamma distribution in terms
         # of alpha > -1.0
@@ -714,6 +733,11 @@ def betavariate(self, alpha, beta):
         Conditions on the parameters are alpha > 0 and beta > 0.
         Returned values range between 0 and 1.
 
+        The mean (expected value) and variance of the random variable are:
+
+            E[X] = alpha / (alpha + beta)
+            Var[X] = alpha * beta / ((alpha + beta)**2 * (alpha + beta + 1))
+
         """
         ## See
         ## http://mail.python.org/pipermail/python-bugs-list/2001-January/003752.html
@@ -766,6 +790,11 @@ def binomialvariate(self, n=1, p=0.5):
 
         Returns an integer in the range:   0 <= X <= n
 
+        The mean (expected value) and variance of the random variable are:
+
+            E[X] = n * p
+            Var[x] = n * p * (1 - p)
+
         """
         # Error check inputs and handle edge cases
         if n < 0:
diff --git a/Lib/re/_compiler.py b/Lib/re/_compiler.py
index d8e0d2fdef..285c21936f 100644
--- a/Lib/re/_compiler.py
+++ b/Lib/re/_compiler.py
@@ -149,6 +149,8 @@ def _compile(code, pattern, flags):
                 emit(0) # look ahead
             else:
                 lo, hi = av[1].getwidth()
+                if lo > MAXCODE:
+                    raise error("looks too much behind")
                 if lo != hi:
                     raise error("look-behind requires fixed-width pattern")
                 emit(lo) # look behind
@@ -549,7 +551,7 @@ def _compile_info(code, pattern, flags):
     else:
         emit(MAXCODE)
         prefix = prefix[:MAXCODE]
-    emit(min(hi, MAXCODE))
+    emit(hi)
     # add literal prefix
     if prefix:
         emit(len(prefix)) # length
diff --git a/Lib/re/_parser.py b/Lib/re/_parser.py
index 74bda2f103..4a492b79e8 100644
--- a/Lib/re/_parser.py
+++ b/Lib/re/_parser.py
@@ -68,6 +68,10 @@
 TYPE_FLAGS = SRE_FLAG_ASCII | SRE_FLAG_LOCALE | SRE_FLAG_UNICODE
 GLOBAL_FLAGS = SRE_FLAG_DEBUG | SRE_FLAG_TEMPLATE
 
+# Maximal value returned by SubPattern.getwidth().
+# Must be larger than MAXREPEAT, MAXCODE and sys.maxsize.
+MAXWIDTH = 1 << 64
+
 class State:
     # keeps track of state for parsing
     def __init__(self):
@@ -178,7 +182,7 @@ def getwidth(self):
         lo = hi = 0
         for op, av in self.data:
             if op is BRANCH:
-                i = MAXREPEAT - 1
+                i = MAXWIDTH
                 j = 0
                 for av in av[1]:
                     l, h = av.getwidth()
@@ -197,7 +201,10 @@ def getwidth(self):
             elif op in _REPEATCODES:
                 i, j = av[2].getwidth()
                 lo = lo + i * av[0]
-                hi = hi + j * av[1]
+                if av[1] == MAXREPEAT and j:
+                    hi = MAXWIDTH
+                else:
+                    hi = hi + j * av[1]
             elif op in _UNITCODES:
                 lo = lo + 1
                 hi = hi + 1
@@ -217,7 +224,7 @@ def getwidth(self):
                 hi = hi + j
             elif op is SUCCESS:
                 break
-        self.width = min(lo, MAXREPEAT - 1), min(hi, MAXREPEAT)
+        self.width = min(lo, MAXWIDTH), min(hi, MAXWIDTH)
         return self.width
 
 class Tokenizer:
diff --git a/Lib/reprlib.py b/Lib/reprlib.py
index a92b3e3dbb..a7b37630a4 100644
--- a/Lib/reprlib.py
+++ b/Lib/reprlib.py
@@ -29,6 +29,7 @@ def wrapper(self):
         wrapper.__name__ = getattr(user_function, '__name__')
         wrapper.__qualname__ = getattr(user_function, '__qualname__')
         wrapper.__annotations__ = getattr(user_function, '__annotations__', {})
+        wrapper.__type_params__ = getattr(user_function, '__type_params__', ())
         return wrapper
 
     return decorating_function
diff --git a/Lib/selectors.py b/Lib/selectors.py
index af6a4f94b5..c3b065b522 100644
--- a/Lib/selectors.py
+++ b/Lib/selectors.py
@@ -509,6 +509,7 @@ class KqueueSelector(_BaseSelectorImpl):
         def __init__(self):
             super().__init__()
             self._selector = select.kqueue()
+            self._max_events = 0
 
         def fileno(self):
             return self._selector.fileno()
@@ -520,10 +521,12 @@ def register(self, fileobj, events, data=None):
                     kev = select.kevent(key.fd, select.KQ_FILTER_READ,
                                         select.KQ_EV_ADD)
                     self._selector.control([kev], 0, 0)
+                    self._max_events += 1
                 if events & EVENT_WRITE:
                     kev = select.kevent(key.fd, select.KQ_FILTER_WRITE,
                                         select.KQ_EV_ADD)
                     self._selector.control([kev], 0, 0)
+                    self._max_events += 1
             except:
                 super().unregister(fileobj)
                 raise
@@ -534,6 +537,7 @@ def unregister(self, fileobj):
             if key.events & EVENT_READ:
                 kev = select.kevent(key.fd, select.KQ_FILTER_READ,
                                     select.KQ_EV_DELETE)
+                self._max_events -= 1
                 try:
                     self._selector.control([kev], 0, 0)
                 except OSError:
@@ -543,6 +547,7 @@ def unregister(self, fileobj):
             if key.events & EVENT_WRITE:
                 kev = select.kevent(key.fd, select.KQ_FILTER_WRITE,
                                     select.KQ_EV_DELETE)
+                self._max_events -= 1
                 try:
                     self._selector.control([kev], 0, 0)
                 except OSError:
@@ -555,7 +560,7 @@ def select(self, timeout=None):
             # If max_ev is 0, kqueue will ignore the timeout. For consistent
             # behavior with the other selector classes, we prevent that here
             # (using max). See https://bugs.python.org/issue29255
-            max_ev = max(len(self._fd_to_key), 1)
+            max_ev = self._max_events or 1
             ready = []
             try:
                 kev_list = self._selector.control(None, max_ev, timeout)
diff --git a/Lib/shutil.py b/Lib/shutil.py
index b37bd082ee..a278b74fab 100644
--- a/Lib/shutil.py
+++ b/Lib/shutil.py
@@ -481,7 +481,7 @@ def _copytree(entries, src, dst, symlinks, ignore, copy_function,
     if ignore is not None:
         ignored_names = ignore(os.fspath(src), [x.name for x in entries])
     else:
-        ignored_names = set()
+        ignored_names = ()
 
     os.makedirs(dst, exist_ok=dirs_exist_ok)
     errors = []
@@ -1554,8 +1554,16 @@ def which(cmd, mode=os.F_OK | os.X_OK, path=None):
         if use_bytes:
             pathext = [os.fsencode(ext) for ext in pathext]
 
-        # Always try checking the originally given cmd, if it doesn't match, try pathext
-        files = [cmd] + [cmd + ext for ext in pathext]
+        files = ([cmd] + [cmd + ext for ext in pathext])
+
+        # gh-109590. If we are looking for an executable, we need to look
+        # for a PATHEXT match. The first cmd is the direct match
+        # (e.g. python.exe instead of python)
+        # Check that direct match first if and only if the extension is in PATHEXT
+        # Otherwise check it last
+        suffix = os.path.splitext(files[0])[1].upper()
+        if mode & os.X_OK and not any(suffix == ext.upper() for ext in pathext):
+            files.append(files.pop(0))
     else:
         # On other platforms you don't have things like PATHEXT to tell you
         # what file suffixes are executable, so just pass on cmd as-is.
diff --git a/Lib/test/.ruff.toml b/Lib/test/.ruff.toml
index 3bdd472c0a..231b0e508f 100644
--- a/Lib/test/.ruff.toml
+++ b/Lib/test/.ruff.toml
@@ -3,14 +3,14 @@ select = [
     "F811",  # Redefinition of unused variable (useful for finding test methods with the same name)
 ]
 extend-exclude = [
+    # Excluded (run with the other AC files in its own separate ruff job in pre-commit)
+    "test_clinic.py",
     # Failed to lint
     "badsyntax_pep3120.py",
     "encoded_modules/module_iso_8859_1.py",
     "encoded_modules/module_koi8_r.py",
     # Failed to parse
     "badsyntax_3131.py",
-    "support/socket_helper.py",
-    "test_fstring.py",
     "test_lib2to3/data/bom.py",
     "test_lib2to3/data/crlf.py",
     "test_lib2to3/data/different_encoding.py",
@@ -20,23 +20,15 @@ extend-exclude = [
     "test_buffer.py",
     "test_capi/test_misc.py",
     "test_capi/test_unicode.py",
-    "test_ctypes/test_arrays.py",
-    "test_ctypes/test_functions.py",
-    "test_dataclasses.py",
+    "test_dataclasses/__init__.py",
     "test_descr.py",
     "test_enum.py",
     "test_functools.py",
-    "test_genericclass.py",
     "test_grammar.py",
     "test_import/__init__.py",
-    "test_keywordonlyarg.py",
     "test_lib2to3/data/py3_test_grammar.py",
     "test_pkg.py",
-    "test_subclassinit.py",
     "test_tokenize.py",
-    "test_typing.py",
     "test_yield_from.py",
     "time_hashlib.py",
-    # Pending https://github.com/python/cpython/pull/109139
-    "test_monitoring.py",
 ]
diff --git a/Lib/test/__main__.py b/Lib/test/__main__.py
index 19a6b2b890..82b50ad2c6 100644
--- a/Lib/test/__main__.py
+++ b/Lib/test/__main__.py
@@ -1,2 +1,2 @@
-from test.libregrtest import main
-main()
+from test.libregrtest.main import main
+main(_add_python_opts=True)
diff --git a/Lib/test/_test_eintr.py b/Lib/test/_test_eintr.py
index 006581f7cc..15586f15df 100644
--- a/Lib/test/_test_eintr.py
+++ b/Lib/test/_test_eintr.py
@@ -25,6 +25,12 @@
 from test.support import os_helper
 from test.support import socket_helper
 
+
+# gh-109592: Tolerate a difference of 20 ms when comparing timings
+# (clock resolution)
+CLOCK_RES = 0.020
+
+
 @contextlib.contextmanager
 def kill_on_error(proc):
     """Context manager killing the subprocess if a Python exception is raised."""
@@ -75,6 +81,9 @@ def subprocess(self, *args, **kw):
         cmd_args = (sys.executable, '-c') + args
         return subprocess.Popen(cmd_args, **kw)
 
+    def check_elapsed_time(self, elapsed):
+        self.assertGreaterEqual(elapsed, self.sleep_time - CLOCK_RES)
+
 
 @unittest.skipUnless(hasattr(signal, "setitimer"), "requires setitimer()")
 class OSEINTRTest(EINTRBaseTest):
@@ -373,7 +382,7 @@ def test_sleep(self):
         time.sleep(self.sleep_time)
         self.stop_alarm()
         dt = time.monotonic() - t0
-        self.assertGreaterEqual(dt, self.sleep_time)
+        self.check_elapsed_time(dt)
 
 
 @unittest.skipUnless(hasattr(signal, "setitimer"), "requires setitimer()")
@@ -435,7 +444,7 @@ def test_select(self):
         select.select([], [], [], self.sleep_time)
         dt = time.monotonic() - t0
         self.stop_alarm()
-        self.assertGreaterEqual(dt, self.sleep_time)
+        self.check_elapsed_time(dt)
 
     @unittest.skipIf(sys.platform == "darwin",
                      "poll may fail on macOS; see issue #28087")
@@ -447,7 +456,7 @@ def test_poll(self):
         poller.poll(self.sleep_time * 1e3)
         dt = time.monotonic() - t0
         self.stop_alarm()
-        self.assertGreaterEqual(dt, self.sleep_time)
+        self.check_elapsed_time(dt)
 
     @unittest.skipUnless(hasattr(select, 'epoll'), 'need select.epoll')
     def test_epoll(self):
@@ -458,7 +467,7 @@ def test_epoll(self):
         poller.poll(self.sleep_time)
         dt = time.monotonic() - t0
         self.stop_alarm()
-        self.assertGreaterEqual(dt, self.sleep_time)
+        self.check_elapsed_time(dt)
 
     @unittest.skipUnless(hasattr(select, 'kqueue'), 'need select.kqueue')
     def test_kqueue(self):
@@ -469,7 +478,7 @@ def test_kqueue(self):
         kqueue.control(None, 1, self.sleep_time)
         dt = time.monotonic() - t0
         self.stop_alarm()
-        self.assertGreaterEqual(dt, self.sleep_time)
+        self.check_elapsed_time(dt)
 
     @unittest.skipUnless(hasattr(select, 'devpoll'), 'need select.devpoll')
     def test_devpoll(self):
@@ -480,7 +489,7 @@ def test_devpoll(self):
         poller.poll(self.sleep_time * 1e3)
         dt = time.monotonic() - t0
         self.stop_alarm()
-        self.assertGreaterEqual(dt, self.sleep_time)
+        self.check_elapsed_time(dt)
 
 
 class FNTLEINTRTest(EINTRBaseTest):
@@ -512,8 +521,8 @@ def _lock(self, lock_func, lock_name):
                 # potential context switch delay
                 lock_func(f, fcntl.LOCK_EX)
                 dt = time.monotonic() - start_time
-                self.assertGreaterEqual(dt, self.sleep_time)
                 self.stop_alarm()
+                self.check_elapsed_time(dt)
             proc.wait()
 
     # Issue 35633: See https://bugs.python.org/issue35633#msg333662
diff --git a/Lib/test/_test_embed_set_config.py b/Lib/test/_test_embed_set_config.py
index 0c016b5d75..a2ddd133cf 100644
--- a/Lib/test/_test_embed_set_config.py
+++ b/Lib/test/_test_embed_set_config.py
@@ -9,9 +9,9 @@
 import os
 import sys
 import unittest
+from test.support import MS_WINDOWS
 
 
-MS_WINDOWS = (os.name == 'nt')
 MAX_HASH_SEED = 4294967295
 
 class SetConfigTests(unittest.TestCase):
diff --git a/Lib/test/_test_multiprocessing.py b/Lib/test/_test_multiprocessing.py
index 044bfc97b8..d52b10c2ec 100644
--- a/Lib/test/_test_multiprocessing.py
+++ b/Lib/test/_test_multiprocessing.py
@@ -78,10 +78,15 @@
     msvcrt = None
 
 
-if support.check_sanitizer(address=True):
-    # bpo-45200: Skip multiprocessing tests if Python is built with ASAN to
+if support.HAVE_ASAN_FORK_BUG:
+    # gh-89363: Skip multiprocessing tests if Python is built with ASAN to
     # work around a libasan race condition: dead lock in pthread_create().
-    raise unittest.SkipTest("libasan has a pthread_create() dead lock")
+    raise unittest.SkipTest("libasan has a pthread_create() dead lock related to thread+fork")
+
+
+# gh-110666: Tolerate a difference of 100 ms when comparing timings
+# (clock resolution)
+CLOCK_RES = 0.100
 
 
 def latin(s):
@@ -557,13 +562,14 @@ def handler(*args):
 
     def test_terminate(self):
         exitcode = self._kill_process(multiprocessing.Process.terminate)
-        if os.name != 'nt':
-            self.assertEqual(exitcode, -signal.SIGTERM)
+        self.assertEqual(exitcode, -signal.SIGTERM)
 
     def test_kill(self):
         exitcode = self._kill_process(multiprocessing.Process.kill)
         if os.name != 'nt':
             self.assertEqual(exitcode, -signal.SIGKILL)
+        else:
+            self.assertEqual(exitcode, -signal.SIGTERM)
 
     def test_cpu_count(self):
         try:
@@ -1650,12 +1656,11 @@ def test_waitfor(self):
     def _test_waitfor_timeout_f(cls, cond, state, success, sem):
         sem.release()
         with cond:
-            expected = 0.1
+            expected = 0.100
             dt = time.monotonic()
             result = cond.wait_for(lambda : state.value==4, timeout=expected)
             dt = time.monotonic() - dt
-            # borrow logic in assertTimeout() from test/lock_tests.py
-            if not result and expected * 0.6 < dt < expected * 10.0:
+            if not result and (expected - CLOCK_RES) <= dt:
                 success.value = True
 
     @unittest.skipUnless(HAS_SHAREDCTYPES, 'needs sharedctypes')
@@ -1674,7 +1679,7 @@ def test_waitfor_timeout(self):
 
         # Only increment 3 times, so state == 4 is never reached.
         for i in range(3):
-            time.sleep(0.01)
+            time.sleep(0.010)
             with cond:
                 state.value += 1
                 cond.notify()
@@ -2433,8 +2438,11 @@ def test_namespace(self):
 #
 #
 
-def sqr(x, wait=0.0):
-    time.sleep(wait)
+def sqr(x, wait=0.0, event=None):
+    if event is None:
+        time.sleep(wait)
+    else:
+        event.wait(wait)
     return x*x
 
 def mul(x, y):
@@ -2573,10 +2581,18 @@ def test_async(self):
         self.assertTimingAlmostEqual(get.elapsed, TIMEOUT1)
 
     def test_async_timeout(self):
-        res = self.pool.apply_async(sqr, (6, TIMEOUT2 + 1.0))
-        get = TimingWrapper(res.get)
-        self.assertRaises(multiprocessing.TimeoutError, get, timeout=TIMEOUT2)
-        self.assertTimingAlmostEqual(get.elapsed, TIMEOUT2)
+        p = self.Pool(3)
+        try:
+            event = threading.Event() if self.TYPE == 'threads' else None
+            res = p.apply_async(sqr, (6, TIMEOUT2 + support.SHORT_TIMEOUT, event))
+            get = TimingWrapper(res.get)
+            self.assertRaises(multiprocessing.TimeoutError, get, timeout=TIMEOUT2)
+            self.assertTimingAlmostEqual(get.elapsed, TIMEOUT2)
+        finally:
+            if event is not None:
+                event.set()
+            p.terminate()
+            p.join()
 
     def test_imap(self):
         it = self.pool.imap(sqr, list(range(10)))
@@ -2677,14 +2693,12 @@ def test_make_pool(self):
                 p.join()
 
     def test_terminate(self):
-        result = self.pool.map_async(
-            time.sleep, [0.1 for i in range(10000)], chunksize=1
-            )
-        self.pool.terminate()
-        join = TimingWrapper(self.pool.join)
-        join()
-        # Sanity check the pool didn't wait for all tasks to finish
-        self.assertLess(join.elapsed, 2.0)
+        # Simulate slow tasks which take "forever" to complete
+        p = self.Pool(3)
+        args = [support.LONG_TIMEOUT for i in range(10_000)]
+        result = p.map_async(time.sleep, args, chunksize=1)
+        p.terminate()
+        p.join()
 
     def test_empty_iterable(self):
         # See Issue 12157
@@ -4869,7 +4883,7 @@ class TestWait(unittest.TestCase):
     def _child_test_wait(cls, w, slow):
         for i in range(10):
             if slow:
-                time.sleep(random.random()*0.1)
+                time.sleep(random.random() * 0.100)
             w.send((i, os.getpid()))
         w.close()
 
@@ -4909,7 +4923,7 @@ def _child_test_wait_socket(cls, address, slow):
         s.connect(address)
         for i in range(10):
             if slow:
-                time.sleep(random.random()*0.1)
+                time.sleep(random.random() * 0.100)
             s.sendall(('%s\n' % i).encode('ascii'))
         s.close()
 
@@ -4958,25 +4972,19 @@ def test_wait_socket_slow(self):
     def test_wait_timeout(self):
         from multiprocessing.connection import wait
 
-        expected = 5
+        timeout = 5.0  # seconds
         a, b = multiprocessing.Pipe()
 
         start = time.monotonic()
-        res = wait([a, b], expected)
+        res = wait([a, b], timeout)
         delta = time.monotonic() - start
 
         self.assertEqual(res, [])
-        self.assertLess(delta, expected * 2)
-        self.assertGreater(delta, expected * 0.5)
+        self.assertGreater(delta, timeout - CLOCK_RES)
 
         b.send(None)
-
-        start = time.monotonic()
         res = wait([a, b], 20)
-        delta = time.monotonic() - start
-
         self.assertEqual(res, [a])
-        self.assertLess(delta, 0.4)
 
     @classmethod
     def signal_and_sleep(cls, sem, period):
@@ -5434,7 +5442,9 @@ def test_nested_startmethod(self):
         while not queue.empty():
             results.append(queue.get())
 
-        self.assertEqual(results, [2, 1])
+        # gh-109706: queue.put(1) can write into the queue before queue.put(2),
+        # there is no synchronization in the test.
+        self.assertSetEqual(set(results), set([2, 1]))
 
 
 @unittest.skipIf(sys.platform == "win32",
diff --git a/Lib/test/_typed_dict_helper.py b/Lib/test/_typed_dict_helper.py
deleted file mode 100644
index 9df0ede7d4..0000000000
--- a/Lib/test/_typed_dict_helper.py
+++ /dev/null
@@ -1,30 +0,0 @@
-"""Used to test `get_type_hints()` on a cross-module inherited `TypedDict` class
-
-This script uses future annotations to postpone a type that won't be available
-on the module inheriting from to `Foo`. The subclass in the other module should
-look something like this:
-
-    class Bar(_typed_dict_helper.Foo, total=False):
-        b: int
-
-In addition, it uses multiple levels of Annotated to test the interaction
-between the __future__ import, Annotated, and Required.
-"""
-
-from __future__ import annotations
-
-from typing import Annotated, Generic, Optional, Required, TypedDict, TypeVar
-
-
-OptionalIntType = Optional[int]
-
-class Foo(TypedDict):
-    a: OptionalIntType
-
-T = TypeVar("T")
-
-class FooGeneric(TypedDict, Generic[T]):
-    a: Optional[T]
-
-class VeryAnnotated(TypedDict, total=False):
-    a: Annotated[Annotated[Annotated[Required[int], "a"], "b"], "c"]
diff --git a/Lib/test/allsans.pem b/Lib/test/allsans.pem
deleted file mode 100644
index e400e178a1..0000000000
--- a/Lib/test/allsans.pem
+++ /dev/null
@@ -1,170 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/gIBADANBgkqhkiG9w0BAQEFAASCBugwggbkAgEAAoIBgQDBGvj+Uy/VUyTR
-mmIA1UEENThh0+pWODcvvUlkeIo+XTJ3FhF4/RVjImDHjozl28Xf2TzKnvQJa1KC
-pqa7fr8cL9QMwk4pH+S4ulxOu02Bl3Yafx2oJVUML37vciJg+zkzPx1k3tXFjXkr
-LGjZwOoufBC3AmPuq2xHFBzHrvp5/DIRH2slQFM9fpVZzN77gYyzxba0wCfCPpCf
-eJFRyYKW8c7MXrwnM82YtE7Rlnf227EkCdMNaSeZLUIxeVpcnScqZl0SIbR3YEiV
-0LPFkx0wJFm8qUEFU/h+0jamgy/ON+11nqmMlp3BjNi/JTVsa7N7A3dvdHC7VVlr
-WnUgU6MoSniyL6ijpucyHtZzK2mJy0sHR8PadHKow0O423/5N8GKTSOvaGMXTjAe
-OGs+9/P1ZYo3IjjQPz/NV3QlhK8zRqxF3cW0ekHHkT+/jZjCvSKm6mdbMQunKE1W
-+dokAc815pb48Mzf1eWKd/7UyUf7CXussyAaJ3clpaK1sbbn9m0CAwEAAQKCAYAe
-BaCCgdJk+xk1USg9cuo5ykBqzTSYlQLXdDlN2oO7sGehJhgvVEGX+QdM3ze+oM2B
-wNd3tQDB2iKo11oCunDh4/m2xhq6wA+iPK8POoWRSUf+VJb6xlsTmurENV1s8IHz
-GrPqM87OePFGqg/fEuQVuAotObzppVMfNdxHm0er4W6zRMw2rWqDnAOCQ5zDQ1/p
-ryp5rYpA49M+R9NoAMlByHRbR7s+6Qnk3NuIMDmUcpF2xeQ/KIMUiHnLEU/gKDpi
-bsk+VtyjlibR4zhh9/cJrLTApAIA+4eC176EJvKXCh5UIjd92JC7741HTNQXJpvG
-9PXbzhyUCmncr04U+46snGHdwD+lG4LS7oBGACTLMtpcMrlgAm6XCg4T8gRVE/9n
-FvCkqPHBR+vnhOxm+0x0yUY/DstJby6IPYPsfGK/s2n//j/vJrAZE1Pxlm9EPU13
-MRLcHstwjAc/NXRPnUN1DfcQvPLx6Tt6rqw3Wm1KO75kM+HZ56BX9/Bi1TgkiI0C
-gcEA5JTlXssJ3W8Cz6w1ZtGsThHQBDbvHF2D5AdqO7y6/eqzCQgBQl9BTfXOzsvP
-I1gf2CLEFBtGK09UjAuJQg90/NlKur7i7xt7HpAzEfGsDAL4P5BW5JnMNrzpJjjL
-0uUDsPJlA75Wi29N2SFiaIslY0sZ6nckInat5GRe4O1AMSHoJ5suY9yTZTU3XB4O
-A+XyddutI1GsFZgl8/8LyyNMcyNjxG3T5sr7IKf5/nIv6oMDjC2zLVZa8QS/MEnL
-Kaa7AoHBANhEsxfcjw2MaPkrsqAsOP0dDf7g2rdz6wKT5BzZu9e+/E76NmvVDpns
-e+kCjql9Os3/wonOMINvn1bTCQGTgk8+dw1fMyqg+zQCvH4ImcE6LSqhzblVHsIB
-zZ7rW86trri1U9+olNHG4nwkus0i4LV8eeORns+j8DgXr6/eOvjX3ZW5TyU7/Qgm
-SiSdBapzJbom3xJrbo9KQsrN5PVCOwuwrgY0o+2BeKyKhnt4uGv0bR+ii06EOJUA
-WvjD7gLI9wKBwGVRXk3jH29IOm3EvjLh80bzfEmx89CV3tUfOEZcRGIyOsNhCfXa
-dP7SWqWtDxZyhELwPgtPf43I7wfYQTHH2ioNQqN94ubrPmpwrkJg5cq5MkIyf2F6
-jlsg5xMrD6VeH4G6H25GWuQZJN9+fbkrHBpj+ovD3X9tLWzT1H5Miyx8BAQyM6DN
-74Nn0C8Dn2C49vyor5i9JdK4ivIY9ahH8CYE5L73k3p0NFXoPtY61ORUyCjFROtu
-oIa+fOQxgVzn6wKBwQC3DD7BnY7/Gq7m51ODOqrpoaPs7Qhyagyp298hhDD3hNEt
-T56sWmLHaV/fcqipUDNrlGRmGzz4ooutA2YGDYIn7Gj7ym4WULcN6Jr92e25nLIJ
-+XWUvjUQZFJThkXogxz1fZSGI7wCamHcTYJGipTDR54rPV+7w7hY4cN0CZbEdIE6
-buRMUZ/zO+VZZAYdpORz0N7SSlgDtAkgenCmHe64EEzbN8bgCcvHzl/RNfZyeSm7
-supSBJuXkfttvvg/JzUCgcEAlx0Pep9qCLvpk0WqzijBVHc3zK4wYxjhN2MBkF42
-SLWfogKpiPfIqxX6YF94roIA0VlW6Pj50v+sbPwq8nwsgFNhml80A4ODKr3O3Y3M
-fXDBJW5W5ZRb/vhIKRjXyCSckSRfj7N8HUYjCLkxQansNWimrldmSet0H2mYJN0Y
-JpBXdqpa76zoHzWpKFwD0fSVzvnMelPHSDCNOdIEHmR8e1x2F1/ufR/9/dBzPULY
-HMj0OhQHoi8kJyMIj3+bQkbC
------END PRIVATE KEY-----
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:5f
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=allsans
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                RSA Public-Key: (3072 bit)
-                Modulus:
-                    00:c1:1a:f8:fe:53:2f:d5:53:24:d1:9a:62:00:d5:
-                    41:04:35:38:61:d3:ea:56:38:37:2f:bd:49:64:78:
-                    8a:3e:5d:32:77:16:11:78:fd:15:63:22:60:c7:8e:
-                    8c:e5:db:c5:df:d9:3c:ca:9e:f4:09:6b:52:82:a6:
-                    a6:bb:7e:bf:1c:2f:d4:0c:c2:4e:29:1f:e4:b8:ba:
-                    5c:4e:bb:4d:81:97:76:1a:7f:1d:a8:25:55:0c:2f:
-                    7e:ef:72:22:60:fb:39:33:3f:1d:64:de:d5:c5:8d:
-                    79:2b:2c:68:d9:c0:ea:2e:7c:10:b7:02:63:ee:ab:
-                    6c:47:14:1c:c7:ae:fa:79:fc:32:11:1f:6b:25:40:
-                    53:3d:7e:95:59:cc:de:fb:81:8c:b3:c5:b6:b4:c0:
-                    27:c2:3e:90:9f:78:91:51:c9:82:96:f1:ce:cc:5e:
-                    bc:27:33:cd:98:b4:4e:d1:96:77:f6:db:b1:24:09:
-                    d3:0d:69:27:99:2d:42:31:79:5a:5c:9d:27:2a:66:
-                    5d:12:21:b4:77:60:48:95:d0:b3:c5:93:1d:30:24:
-                    59:bc:a9:41:05:53:f8:7e:d2:36:a6:83:2f:ce:37:
-                    ed:75:9e:a9:8c:96:9d:c1:8c:d8:bf:25:35:6c:6b:
-                    b3:7b:03:77:6f:74:70:bb:55:59:6b:5a:75:20:53:
-                    a3:28:4a:78:b2:2f:a8:a3:a6:e7:32:1e:d6:73:2b:
-                    69:89:cb:4b:07:47:c3:da:74:72:a8:c3:43:b8:db:
-                    7f:f9:37:c1:8a:4d:23:af:68:63:17:4e:30:1e:38:
-                    6b:3e:f7:f3:f5:65:8a:37:22:38:d0:3f:3f:cd:57:
-                    74:25:84:af:33:46:ac:45:dd:c5:b4:7a:41:c7:91:
-                    3f:bf:8d:98:c2:bd:22:a6:ea:67:5b:31:0b:a7:28:
-                    4d:56:f9:da:24:01:cf:35:e6:96:f8:f0:cc:df:d5:
-                    e5:8a:77:fe:d4:c9:47:fb:09:7b:ac:b3:20:1a:27:
-                    77:25:a5:a2:b5:b1:b6:e7:f6:6d
-                Exponent: 65537 (0x10001)
-        X509v3 extensions:
-            X509v3 Subject Alternative Name: 
-                DNS:allsans, othername:<unsupported>, othername:<unsupported>, email:user@example.org, DNS:www.example.org, DirName:/C=XY/L=Castle Anthrax/O=Python Software Foundation/CN=dirname example, URI:https://www.python.org/, IP Address:127.0.0.1, IP Address:0:0:0:0:0:0:0:1, Registered ID:1.2.3.4.5
-            X509v3 Key Usage: critical
-                Digital Signature, Key Encipherment
-            X509v3 Extended Key Usage: 
-                TLS Web Server Authentication, TLS Web Client Authentication
-            X509v3 Basic Constraints: critical
-                CA:FALSE
-            X509v3 Subject Key Identifier: 
-                D4:F1:D8:23:E0:A7:E9:CA:12:45:A0:0D:03:C2:25:A6:E8:65:BC:EE
-            X509v3 Authority Key Identifier: 
-                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
-                serial:CB:2D:80:99:5A:69:52:5B
-
-            Authority Information Access: 
-                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
-                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
-
-            X509v3 CRL Distribution Points: 
-
-                Full Name:
-                  URI:http://testca.pythontest.net/testca/revocation.crl
-
-    Signature Algorithm: sha256WithRSAEncryption
-         70:77:d8:82:b0:f4:ab:de:84:ce:88:32:63:5e:23:0f:b6:58:
-         a2:b1:65:ff:12:22:0b:88:a6:fa:06:40:9a:e7:63:a7:5d:ae:
-         94:c5:68:3c:4b:e9:95:34:01:75:24:df:9d:6e:9b:e4:ff:3f:
-         61:97:29:7b:ab:34:2c:14:d3:01:d2:eb:fb:84:40:db:12:54:
-         7e:7a:44:bc:08:eb:9f:e2:15:0b:11:4f:25:d2:56:51:95:ad:
-         6d:ad:07:aa:6a:61:f9:39:d5:82:8c:45:31:9f:2a:ff:18:98:
-         49:0c:bb:17:ad:d5:24:d3:d1:c7:c4:10:3e:c4:79:26:58:f4:
-         c5:de:82:16:c4:c3:c4:a7:a3:62:22:41:90:36:0f:bc:4c:fd:
-         6a:18:22:f2:87:e9:07:db:b4:3d:65:00:e4:70:f9:d6:e5:a8:
-         a1:b9:c9:9d:e7:5d:78:aa:98:d5:f8:f4:fd:5c:d9:4c:d0:6d:
-         bf:87:71:d3:5b:ec:f4:bf:46:f9:c8:f8:10:c5:72:af:c3:15:
-         b9:c4:06:67:0b:3f:f6:f4:64:c5:27:74:c1:6b:00:37:da:ea:
-         18:36:77:36:a7:3e:80:2e:5d:54:0f:01:df:ce:9e:97:dd:c9:
-         f2:8b:59:82:c5:65:31:c8:73:20:fd:24:23:25:d8:00:df:90:
-         93:26:76:08:0a:06:a9:0e:d3:d3:4c:6f:ef:a7:fb:de:eb:2a:
-         40:b9:e4:b1:44:0c:37:ca:c6:9e:44:4a:b4:7c:2c:40:52:35:
-         bb:b3:71:28:3d:35:fd:be:c9:4f:54:b3:99:c5:5f:84:38:fb:
-         2b:fb:ea:dd:88:e8:9d:c1:9b:67:87:3d:79:7b:3d:7e:61:1f:
-         70:3c:b7:c8:4c:17:a5:0c:a3:28:c7:ab:48:11:14:f7:98:7a:
-         da:4e:fb:91:76:89:0a:a6:c6:72:e0:96:d9:f1:80:ea:68:90:
-         37:5c:c6:69:c7:d7:bc:c7:d1:ae:5b:a9:12:59:c6:e4:6c:61:
-         a9:8b:ba:51:b3:13
------BEGIN CERTIFICATE-----
-MIIHDTCCBXWgAwIBAgIJAMstgJlaaVJfMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaMF0xCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
-MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xEDAOBgNVBAMMB2Fs
-bHNhbnMwggGiMA0GCSqGSIb3DQEBAQUAA4IBjwAwggGKAoIBgQDBGvj+Uy/VUyTR
-mmIA1UEENThh0+pWODcvvUlkeIo+XTJ3FhF4/RVjImDHjozl28Xf2TzKnvQJa1KC
-pqa7fr8cL9QMwk4pH+S4ulxOu02Bl3Yafx2oJVUML37vciJg+zkzPx1k3tXFjXkr
-LGjZwOoufBC3AmPuq2xHFBzHrvp5/DIRH2slQFM9fpVZzN77gYyzxba0wCfCPpCf
-eJFRyYKW8c7MXrwnM82YtE7Rlnf227EkCdMNaSeZLUIxeVpcnScqZl0SIbR3YEiV
-0LPFkx0wJFm8qUEFU/h+0jamgy/ON+11nqmMlp3BjNi/JTVsa7N7A3dvdHC7VVlr
-WnUgU6MoSniyL6ijpucyHtZzK2mJy0sHR8PadHKow0O423/5N8GKTSOvaGMXTjAe
-OGs+9/P1ZYo3IjjQPz/NV3QlhK8zRqxF3cW0ekHHkT+/jZjCvSKm6mdbMQunKE1W
-+dokAc815pb48Mzf1eWKd/7UyUf7CXussyAaJ3clpaK1sbbn9m0CAwEAAaOCAt4w
-ggLaMIIBMAYDVR0RBIIBJzCCASOCB2FsbHNhbnOgHgYDKgMEoBcMFXNvbWUgb3Ro
-ZXIgaWRlbnRpZmllcqA1BgYrBgEFAgKgKzApoBAbDktFUkJFUk9TLlJFQUxNoRUw
-E6ADAgEBoQwwChsIdXNlcm5hbWWBEHVzZXJAZXhhbXBsZS5vcmeCD3d3dy5leGFt
-cGxlLm9yZ6RnMGUxCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJh
-eDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xGDAWBgNVBAMM
-D2Rpcm5hbWUgZXhhbXBsZYYXaHR0cHM6Ly93d3cucHl0aG9uLm9yZy+HBH8AAAGH
-EAAAAAAAAAAAAAAAAAAAAAGIBCoDBAUwDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQW
-MBQGCCsGAQUFBwMBBggrBgEFBQcDAjAMBgNVHRMBAf8EAjAAMB0GA1UdDgQWBBTU
-8dgj4KfpyhJFoA0DwiWm6GW87jB9BgNVHSMEdjB0gBSziqCiunHxqCR51KRbJTYV
-HknIzaFRpE8wTTELMAkGA1UEBhMCWFkxJjAkBgNVBAoMHVB5dGhvbiBTb2Z0d2Fy
-ZSBGb3VuZGF0aW9uIENBMRYwFAYDVQQDDA1vdXItY2Etc2VydmVyggkAyy2AmVpp
-UlswgYMGCCsGAQUFBwEBBHcwdTA8BggrBgEFBQcwAoYwaHR0cDovL3Rlc3RjYS5w
-eXRob250ZXN0Lm5ldC90ZXN0Y2EvcHljYWNlcnQuY2VyMDUGCCsGAQUFBzABhilo
-dHRwOi8vdGVzdGNhLnB5dGhvbnRlc3QubmV0L3Rlc3RjYS9vY3NwLzBDBgNVHR8E
-PDA6MDigNqA0hjJodHRwOi8vdGVzdGNhLnB5dGhvbnRlc3QubmV0L3Rlc3RjYS9y
-ZXZvY2F0aW9uLmNybDANBgkqhkiG9w0BAQsFAAOCAYEAcHfYgrD0q96EzogyY14j
-D7ZYorFl/xIiC4im+gZAmudjp12ulMVoPEvplTQBdSTfnW6b5P8/YZcpe6s0LBTT
-AdLr+4RA2xJUfnpEvAjrn+IVCxFPJdJWUZWtba0Hqmph+TnVgoxFMZ8q/xiYSQy7
-F63VJNPRx8QQPsR5Jlj0xd6CFsTDxKejYiJBkDYPvEz9ahgi8ofpB9u0PWUA5HD5
-1uWoobnJneddeKqY1fj0/VzZTNBtv4dx01vs9L9G+cj4EMVyr8MVucQGZws/9vRk
-xSd0wWsAN9rqGDZ3Nqc+gC5dVA8B386el93J8otZgsVlMchzIP0kIyXYAN+QkyZ2
-CAoGqQ7T00xv76f73usqQLnksUQMN8rGnkRKtHwsQFI1u7NxKD01/b7JT1SzmcVf
-hDj7K/vq3YjoncGbZ4c9eXs9fmEfcDy3yEwXpQyjKMerSBEU95h62k77kXaJCqbG
-cuCW2fGA6miQN1zGacfXvMfRrlupElnG5GxhqYu6UbMT
------END CERTIFICATE-----
diff --git a/Lib/test/ann_module.py b/Lib/test/ann_module.py
deleted file mode 100644
index 5081e6b583..0000000000
--- a/Lib/test/ann_module.py
+++ /dev/null
@@ -1,62 +0,0 @@
-
-
-"""
-The module for testing variable annotations.
-Empty lines above are for good reason (testing for correct line numbers)
-"""
-
-from typing import Optional
-from functools import wraps
-
-__annotations__[1] = 2
-
-class C:
-
-    x = 5; y: Optional['C'] = None
-
-from typing import Tuple
-x: int = 5; y: str = x; f: Tuple[int, int]
-
-class M(type):
-
-    __annotations__['123'] = 123
-    o: type = object
-
-(pars): bool = True
-
-class D(C):
-    j: str = 'hi'; k: str= 'bye'
-
-from types import new_class
-h_class = new_class('H', (C,))
-j_class = new_class('J')
-
-class F():
-    z: int = 5
-    def __init__(self, x):
-        pass
-
-class Y(F):
-    def __init__(self):
-        super(F, self).__init__(123)
-
-class Meta(type):
-    def __new__(meta, name, bases, namespace):
-        return super().__new__(meta, name, bases, namespace)
-
-class S(metaclass = Meta):
-    x: str = 'something'
-    y: str = 'something else'
-
-def foo(x: int = 10):
-    def bar(y: List[str]):
-        x: str = 'yes'
-    bar()
-
-def dec(func):
-    @wraps(func)
-    def wrapper(*args, **kwargs):
-        return func(*args, **kwargs)
-    return wrapper
-
-u: int | float
diff --git a/Lib/test/ann_module2.py b/Lib/test/ann_module2.py
deleted file mode 100644
index 76cf5b3ad9..0000000000
--- a/Lib/test/ann_module2.py
+++ /dev/null
@@ -1,36 +0,0 @@
-"""
-Some correct syntax for variable annotation here.
-More examples are in test_grammar and test_parser.
-"""
-
-from typing import no_type_check, ClassVar
-
-i: int = 1
-j: int
-x: float = i/10
-
-def f():
-    class C: ...
-    return C()
-
-f().new_attr: object = object()
-
-class C:
-    def __init__(self, x: int) -> None:
-        self.x = x
-
-c = C(5)
-c.new_attr: int = 10
-
-__annotations__ = {}
-
-
-@no_type_check
-class NTC:
-    def meth(self, param: complex) -> None:
-        ...
-
-class CV:
-    var: ClassVar['CV']
-
-CV.var = CV()
diff --git a/Lib/test/ann_module3.py b/Lib/test/ann_module3.py
deleted file mode 100644
index eccd7be22d..0000000000
--- a/Lib/test/ann_module3.py
+++ /dev/null
@@ -1,18 +0,0 @@
-"""
-Correct syntax for variable annotation that should fail at runtime
-in a certain manner. More examples are in test_grammar and test_parser.
-"""
-
-def f_bad_ann():
-    __annotations__[1] = 2
-
-class C_OK:
-    def __init__(self, x: int) -> None:
-        self.x: no_such_name = x  # This one is OK as proposed by Guido
-
-class D_bad_ann:
-    def __init__(self, x: int) -> None:
-        sfel.y: int = 0
-
-def g_bad_ann():
-    no_such_name.attr: int = 0
diff --git a/Lib/test/ann_module4.py b/Lib/test/ann_module4.py
deleted file mode 100644
index 13e9aee54c..0000000000
--- a/Lib/test/ann_module4.py
+++ /dev/null
@@ -1,5 +0,0 @@
-# This ann_module isn't for test_typing,
-# it's for test_module
-
-a:int=3
-b:str=4
diff --git a/Lib/test/ann_module5.py b/Lib/test/ann_module5.py
deleted file mode 100644
index 837041e121..0000000000
--- a/Lib/test/ann_module5.py
+++ /dev/null
@@ -1,10 +0,0 @@
-# Used by test_typing to verify that Final wrapped in ForwardRef works.
-
-from __future__ import annotations
-
-from typing import Final
-
-name: Final[str] = "final"
-
-class MyClass:
-    value: Final = 3000
diff --git a/Lib/test/ann_module6.py b/Lib/test/ann_module6.py
deleted file mode 100644
index 679175669b..0000000000
--- a/Lib/test/ann_module6.py
+++ /dev/null
@@ -1,7 +0,0 @@
-# Tests that top-level ClassVar is not allowed
-
-from __future__ import annotations
-
-from typing import ClassVar
-
-wrong: ClassVar[int] = 1
diff --git a/Lib/test/ann_module7.py b/Lib/test/ann_module7.py
deleted file mode 100644
index 8f890cd280..0000000000
--- a/Lib/test/ann_module7.py
+++ /dev/null
@@ -1,11 +0,0 @@
-# Tests class have ``__text_signature__``
-
-from __future__ import annotations
-
-DEFAULT_BUFFER_SIZE = 8192
-
-class BufferedReader(object):
-    """BufferedReader(raw, buffer_size=DEFAULT_BUFFER_SIZE)\n--\n\n
-    Create a new buffered reader using the given readable raw IO object.
-    """
-    pass
diff --git a/Lib/test/ann_module8.py b/Lib/test/ann_module8.py
deleted file mode 100644
index bd03148137..0000000000
--- a/Lib/test/ann_module8.py
+++ /dev/null
@@ -1,10 +0,0 @@
-# Test `@no_type_check`,
-# see https://bugs.python.org/issue46571
-
-class NoTypeCheck_Outer:
-    class Inner:
-        x: int
-
-
-def NoTypeCheck_function(arg: int) -> int:
-    ...
diff --git a/Lib/test/autotest.py b/Lib/test/autotest.py
index fa85cc153a..b5a1fab404 100644
--- a/Lib/test/autotest.py
+++ b/Lib/test/autotest.py
@@ -1,5 +1,5 @@
 # This should be equivalent to running regrtest.py from the cmdline.
 # It can be especially handy if you're in an interactive shell, e.g.,
 # from test import autotest.
-from test.libregrtest import main
+from test.libregrtest.main import main
 main()
diff --git a/Lib/test/bad_coding.py b/Lib/test/bad_coding.py
deleted file mode 100644
index 971b0a8f3d..0000000000
--- a/Lib/test/bad_coding.py
+++ /dev/null
@@ -1 +0,0 @@
-# -*- coding: uft-8 -*-
diff --git a/Lib/test/bad_coding2.py b/Lib/test/bad_coding2.py
deleted file mode 100644
index bb2bb7e1e7..0000000000
--- a/Lib/test/bad_coding2.py
+++ /dev/null
@@ -1,2 +0,0 @@
-﻿#coding: utf8
-print('我')
diff --git a/Lib/test/badcert.pem b/Lib/test/badcert.pem
deleted file mode 100644
index c4191460f9..0000000000
--- a/Lib/test/badcert.pem
+++ /dev/null
@@ -1,36 +0,0 @@
------BEGIN RSA PRIVATE KEY-----
-MIICXwIBAAKBgQC8ddrhm+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9L
-opdJhTvbGfEj0DQs1IE8M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVH
-fhi/VwovESJlaBOp+WMnfhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQAB
-AoGBAK0FZpaKj6WnJZN0RqhhK+ggtBWwBnc0U/ozgKz2j1s3fsShYeiGtW6CK5nU
-D1dZ5wzhbGThI7LiOXDvRucc9n7vUgi0alqPQ/PFodPxAN/eEYkmXQ7W2k7zwsDA
-IUK0KUhktQbLu8qF/m8qM86ba9y9/9YkXuQbZ3COl5ahTZrhAkEA301P08RKv3KM
-oXnGU2UHTuJ1MAD2hOrPxjD4/wxA/39EWG9bZczbJyggB4RHu0I3NOSFjAm3HQm0
-ANOu5QK9owJBANgOeLfNNcF4pp+UikRFqxk5hULqRAWzVxVrWe85FlPm0VVmHbb/
-loif7mqjU8o1jTd/LM7RD9f2usZyE2psaw8CQQCNLhkpX3KO5kKJmS9N7JMZSc4j
-oog58yeYO8BBqKKzpug0LXuQultYv2K4veaIO04iL9VLe5z9S/Q1jaCHBBuXAkEA
-z8gjGoi1AOp6PBBLZNsncCvcV/0aC+1se4HxTNo2+duKSDnbq+ljqOM+E7odU+Nq
-ewvIWOG//e8fssd0mq3HywJBAJ8l/c8GVmrpFTx8r/nZ2Pyyjt3dH1widooDXYSV
-q6Gbf41Llo5sYAtmxdndTLASuHKecacTgZVhy0FryZpLKrU=
------END RSA PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-Just bad cert data
------END CERTIFICATE-----
------BEGIN RSA PRIVATE KEY-----
-MIICXwIBAAKBgQC8ddrhm+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9L
-opdJhTvbGfEj0DQs1IE8M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVH
-fhi/VwovESJlaBOp+WMnfhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQAB
-AoGBAK0FZpaKj6WnJZN0RqhhK+ggtBWwBnc0U/ozgKz2j1s3fsShYeiGtW6CK5nU
-D1dZ5wzhbGThI7LiOXDvRucc9n7vUgi0alqPQ/PFodPxAN/eEYkmXQ7W2k7zwsDA
-IUK0KUhktQbLu8qF/m8qM86ba9y9/9YkXuQbZ3COl5ahTZrhAkEA301P08RKv3KM
-oXnGU2UHTuJ1MAD2hOrPxjD4/wxA/39EWG9bZczbJyggB4RHu0I3NOSFjAm3HQm0
-ANOu5QK9owJBANgOeLfNNcF4pp+UikRFqxk5hULqRAWzVxVrWe85FlPm0VVmHbb/
-loif7mqjU8o1jTd/LM7RD9f2usZyE2psaw8CQQCNLhkpX3KO5kKJmS9N7JMZSc4j
-oog58yeYO8BBqKKzpug0LXuQultYv2K4veaIO04iL9VLe5z9S/Q1jaCHBBuXAkEA
-z8gjGoi1AOp6PBBLZNsncCvcV/0aC+1se4HxTNo2+duKSDnbq+ljqOM+E7odU+Nq
-ewvIWOG//e8fssd0mq3HywJBAJ8l/c8GVmrpFTx8r/nZ2Pyyjt3dH1widooDXYSV
-q6Gbf41Llo5sYAtmxdndTLASuHKecacTgZVhy0FryZpLKrU=
------END RSA PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-Just bad cert data
------END CERTIFICATE-----
diff --git a/Lib/test/badkey.pem b/Lib/test/badkey.pem
deleted file mode 100644
index 1c8a955719..0000000000
--- a/Lib/test/badkey.pem
+++ /dev/null
@@ -1,40 +0,0 @@
------BEGIN RSA PRIVATE KEY-----
-Bad Key, though the cert should be OK
------END RSA PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-MIICpzCCAhCgAwIBAgIJAP+qStv1cIGNMA0GCSqGSIb3DQEBBQUAMIGJMQswCQYD
-VQQGEwJVUzERMA8GA1UECBMIRGVsYXdhcmUxEzARBgNVBAcTCldpbG1pbmd0b24x
-IzAhBgNVBAoTGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMQwwCgYDVQQLEwNT
-U0wxHzAdBgNVBAMTFnNvbWVtYWNoaW5lLnB5dGhvbi5vcmcwHhcNMDcwODI3MTY1
-NDUwWhcNMTMwMjE2MTY1NDUwWjCBiTELMAkGA1UEBhMCVVMxETAPBgNVBAgTCERl
-bGF3YXJlMRMwEQYDVQQHEwpXaWxtaW5ndG9uMSMwIQYDVQQKExpQeXRob24gU29m
-dHdhcmUgRm91bmRhdGlvbjEMMAoGA1UECxMDU1NMMR8wHQYDVQQDExZzb21lbWFj
-aGluZS5weXRob24ub3JnMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC8ddrh
-m+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9LopdJhTvbGfEj0DQs1IE8
-M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVHfhi/VwovESJlaBOp+WMn
-fhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQABoxUwEzARBglghkgBhvhC
-AQEEBAMCBkAwDQYJKoZIhvcNAQEFBQADgYEAF4Q5BVqmCOLv1n8je/Jw9K669VXb
-08hyGzQhkemEBYQd6fzQ9A/1ZzHkJKb1P6yreOLSEh4KcxYPyrLRC1ll8nr5OlCx
-CMhKkTnR6qBsdNV0XtdU2+N25hqW+Ma4ZeqsN/iiJVCGNOZGnvQuvCAGWF8+J/f/
-iHkC6gGdBJhogs4=
------END CERTIFICATE-----
------BEGIN RSA PRIVATE KEY-----
-Bad Key, though the cert should be OK
------END RSA PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-MIICpzCCAhCgAwIBAgIJAP+qStv1cIGNMA0GCSqGSIb3DQEBBQUAMIGJMQswCQYD
-VQQGEwJVUzERMA8GA1UECBMIRGVsYXdhcmUxEzARBgNVBAcTCldpbG1pbmd0b24x
-IzAhBgNVBAoTGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMQwwCgYDVQQLEwNT
-U0wxHzAdBgNVBAMTFnNvbWVtYWNoaW5lLnB5dGhvbi5vcmcwHhcNMDcwODI3MTY1
-NDUwWhcNMTMwMjE2MTY1NDUwWjCBiTELMAkGA1UEBhMCVVMxETAPBgNVBAgTCERl
-bGF3YXJlMRMwEQYDVQQHEwpXaWxtaW5ndG9uMSMwIQYDVQQKExpQeXRob24gU29m
-dHdhcmUgRm91bmRhdGlvbjEMMAoGA1UECxMDU1NMMR8wHQYDVQQDExZzb21lbWFj
-aGluZS5weXRob24ub3JnMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC8ddrh
-m+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9LopdJhTvbGfEj0DQs1IE8
-M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVHfhi/VwovESJlaBOp+WMn
-fhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQABoxUwEzARBglghkgBhvhC
-AQEEBAMCBkAwDQYJKoZIhvcNAQEFBQADgYEAF4Q5BVqmCOLv1n8je/Jw9K669VXb
-08hyGzQhkemEBYQd6fzQ9A/1ZzHkJKb1P6yreOLSEh4KcxYPyrLRC1ll8nr5OlCx
-CMhKkTnR6qBsdNV0XtdU2+N25hqW+Ma4ZeqsN/iiJVCGNOZGnvQuvCAGWF8+J/f/
-iHkC6gGdBJhogs4=
------END CERTIFICATE-----
diff --git a/Lib/test/badsyntax_3131.py b/Lib/test/badsyntax_3131.py
deleted file mode 100644
index 901d3744ca..0000000000
--- a/Lib/test/badsyntax_3131.py
+++ /dev/null
@@ -1,2 +0,0 @@
-# -*- coding: utf-8 -*-
-€ = 2
diff --git a/Lib/test/badsyntax_future10.py b/Lib/test/badsyntax_future10.py
deleted file mode 100644
index fa5ab67a98..0000000000
--- a/Lib/test/badsyntax_future10.py
+++ /dev/null
@@ -1,3 +0,0 @@
-from __future__ import absolute_import
-"spam, bar, blah"
-from __future__ import print_function
diff --git a/Lib/test/badsyntax_future3.py b/Lib/test/badsyntax_future3.py
deleted file mode 100644
index f1c8417eda..0000000000
--- a/Lib/test/badsyntax_future3.py
+++ /dev/null
@@ -1,10 +0,0 @@
-"""This is a test"""
-from __future__ import nested_scopes
-from __future__ import rested_snopes
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/badsyntax_future4.py b/Lib/test/badsyntax_future4.py
deleted file mode 100644
index b5f4c98e92..0000000000
--- a/Lib/test/badsyntax_future4.py
+++ /dev/null
@@ -1,10 +0,0 @@
-"""This is a test"""
-import __future__
-from __future__ import nested_scopes
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/badsyntax_future5.py b/Lib/test/badsyntax_future5.py
deleted file mode 100644
index 8a7e5fcb70..0000000000
--- a/Lib/test/badsyntax_future5.py
+++ /dev/null
@@ -1,12 +0,0 @@
-"""This is a test"""
-from __future__ import nested_scopes
-import foo
-from __future__ import nested_scopes
-
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/badsyntax_future6.py b/Lib/test/badsyntax_future6.py
deleted file mode 100644
index 5a8b55a02c..0000000000
--- a/Lib/test/badsyntax_future6.py
+++ /dev/null
@@ -1,10 +0,0 @@
-"""This is a test"""
-"this isn't a doc string"
-from __future__ import nested_scopes
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/badsyntax_future7.py b/Lib/test/badsyntax_future7.py
deleted file mode 100644
index 131db2c216..0000000000
--- a/Lib/test/badsyntax_future7.py
+++ /dev/null
@@ -1,11 +0,0 @@
-"""This is a test"""
-
-from __future__ import nested_scopes; import string; from __future__ import \
-     nested_scopes
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/badsyntax_future8.py b/Lib/test/badsyntax_future8.py
deleted file mode 100644
index ca45289e2e..0000000000
--- a/Lib/test/badsyntax_future8.py
+++ /dev/null
@@ -1,10 +0,0 @@
-"""This is a test"""
-
-from __future__ import *
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-print(f(2)(4))
diff --git a/Lib/test/badsyntax_future9.py b/Lib/test/badsyntax_future9.py
deleted file mode 100644
index 916de06ab7..0000000000
--- a/Lib/test/badsyntax_future9.py
+++ /dev/null
@@ -1,10 +0,0 @@
-"""This is a test"""
-
-from __future__ import nested_scopes, braces
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-print(f(2)(4))
diff --git a/Lib/test/capath/4e1295a3.0 b/Lib/test/capath/4e1295a3.0
deleted file mode 100644
index 9d7ac238d8..0000000000
--- a/Lib/test/capath/4e1295a3.0
+++ /dev/null
@@ -1,14 +0,0 @@
------BEGIN CERTIFICATE-----
-MIICLDCCAdYCAQAwDQYJKoZIhvcNAQEEBQAwgaAxCzAJBgNVBAYTAlBUMRMwEQYD
-VQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5ldXJv
-bmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMTEmJy
-dXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZpMB4X
-DTk2MDkwNTAzNDI0M1oXDTk2MTAwNTAzNDI0M1owgaAxCzAJBgNVBAYTAlBUMRMw
-EQYDVQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5l
-dXJvbmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMT
-EmJydXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZp
-MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAL7+aty3S1iBA/+yxjxv4q1MUTd1kjNw
-L4lYKbpzzlmC5beaQXeQ2RmGMTXU+mDvuqItjVHOK3DvPK7lTcSGftUCAwEAATAN
-BgkqhkiG9w0BAQQFAANBAFqPEKFjk6T6CKTHvaQeEAsX0/8YHPHqH/9AnhSjrwuX
-9EBc0n6bVGhN7XaXd6sJ7dym9sbsWxb+pJdurnkxjx4=
------END CERTIFICATE-----
diff --git a/Lib/test/capath/5ed36f99.0 b/Lib/test/capath/5ed36f99.0
deleted file mode 100644
index e7dfc82947..0000000000
--- a/Lib/test/capath/5ed36f99.0
+++ /dev/null
@@ -1,41 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIHPTCCBSWgAwIBAgIBADANBgkqhkiG9w0BAQQFADB5MRAwDgYDVQQKEwdSb290
-IENBMR4wHAYDVQQLExVodHRwOi8vd3d3LmNhY2VydC5vcmcxIjAgBgNVBAMTGUNB
-IENlcnQgU2lnbmluZyBBdXRob3JpdHkxITAfBgkqhkiG9w0BCQEWEnN1cHBvcnRA
-Y2FjZXJ0Lm9yZzAeFw0wMzAzMzAxMjI5NDlaFw0zMzAzMjkxMjI5NDlaMHkxEDAO
-BgNVBAoTB1Jvb3QgQ0ExHjAcBgNVBAsTFWh0dHA6Ly93d3cuY2FjZXJ0Lm9yZzEi
-MCAGA1UEAxMZQ0EgQ2VydCBTaWduaW5nIEF1dGhvcml0eTEhMB8GCSqGSIb3DQEJ
-ARYSc3VwcG9ydEBjYWNlcnQub3JnMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIIC
-CgKCAgEAziLA4kZ97DYoB1CW8qAzQIxL8TtmPzHlawI229Z89vGIj053NgVBlfkJ
-8BLPRoZzYLdufujAWGSuzbCtRRcMY/pnCujW0r8+55jE8Ez64AO7NV1sId6eINm6
-zWYyN3L69wj1x81YyY7nDl7qPv4coRQKFWyGhFtkZip6qUtTefWIonvuLwphK42y
-fk1WpRPs6tqSnqxEQR5YYGUFZvjARL3LlPdCfgv3ZWiYUQXw8wWRBB0bF4LsyFe7
-w2t6iPGwcswlWyCR7BYCEo8y6RcYSNDHBS4CMEK4JZwFaz+qOqfrU0j36NK2B5jc
-G8Y0f3/JHIJ6BVgrCFvzOKKrF11myZjXnhCLotLddJr3cQxyYN/Nb5gznZY0dj4k
-epKwDpUeb+agRThHqtdB7Uq3EvbXG4OKDy7YCbZZ16oE/9KTfWgu3YtLq1i6L43q
-laegw1SJpfvbi1EinbLDvhG+LJGGi5Z4rSDTii8aP8bQUWWHIbEZAWV/RRyH9XzQ
-QUxPKZgh/TMfdQwEUfoZd9vUFBzugcMd9Zi3aQaRIt0AUMyBMawSB3s42mhb5ivU
-fslfrejrckzzAeVLIL+aplfKkQABi6F1ITe1Yw1nPkZPcCBnzsXWWdsC4PDSy826
-YreQQejdIOQpvGQpQsgi3Hia/0PsmBsJUUtaWsJx8cTLc6nloQsCAwEAAaOCAc4w
-ggHKMB0GA1UdDgQWBBQWtTIb1Mfz4OaO873SsDrusjkY0TCBowYDVR0jBIGbMIGY
-gBQWtTIb1Mfz4OaO873SsDrusjkY0aF9pHsweTEQMA4GA1UEChMHUm9vdCBDQTEe
-MBwGA1UECxMVaHR0cDovL3d3dy5jYWNlcnQub3JnMSIwIAYDVQQDExlDQSBDZXJ0
-IFNpZ25pbmcgQXV0aG9yaXR5MSEwHwYJKoZIhvcNAQkBFhJzdXBwb3J0QGNhY2Vy
-dC5vcmeCAQAwDwYDVR0TAQH/BAUwAwEB/zAyBgNVHR8EKzApMCegJaAjhiFodHRw
-czovL3d3dy5jYWNlcnQub3JnL3Jldm9rZS5jcmwwMAYJYIZIAYb4QgEEBCMWIWh0
-dHBzOi8vd3d3LmNhY2VydC5vcmcvcmV2b2tlLmNybDA0BglghkgBhvhCAQgEJxYl
-aHR0cDovL3d3dy5jYWNlcnQub3JnL2luZGV4LnBocD9pZD0xMDBWBglghkgBhvhC
-AQ0ESRZHVG8gZ2V0IHlvdXIgb3duIGNlcnRpZmljYXRlIGZvciBGUkVFIGhlYWQg
-b3ZlciB0byBodHRwOi8vd3d3LmNhY2VydC5vcmcwDQYJKoZIhvcNAQEEBQADggIB
-ACjH7pyCArpcgBLKNQodgW+JapnM8mgPf6fhjViVPr3yBsOQWqy1YPaZQwGjiHCc
-nWKdpIevZ1gNMDY75q1I08t0AoZxPuIrA2jxNGJARjtT6ij0rPtmlVOKTV39O9lg
-18p5aTuxZZKmxoGCXJzN600BiqXfEVWqFcofN8CCmHBh22p8lqOOLlQ+TyGpkO/c
-gr/c6EWtTZBzCDyUZbAEmXZ/4rzCahWqlwQ3JNgelE5tDlG+1sSPypZt90Pf6DBl
-Jzt7u0NDY8RD97LsaMzhGY4i+5jhe1o+ATc7iwiwovOVThrLm82asduycPAtStvY
-sONvRUgzEv/+PDIqVPfE94rwiCPCR/5kenHA0R6mY7AHfqQv0wGP3J8rtsYIqQ+T
-SCX8Ev2fQtzzxD72V7DX3WnRBnc0CkvSyqD/HMaMyRa+xMwyN2hzXwj7UfdJUzYF
-CpUCTPJ5GhD22Dp1nPMd8aINcGeGG7MW9S/lpOt5hvk9C8JzC6WZrG/8Z7jlLwum
-GCSNe9FINSkYQKyTYOGWhlC0elnYjyELn8+CkcY7v2vcB5G5l1YjqrZslMZIBjzk
-zk6q5PYvCdxTby78dOs6Y5nCpqyJvKeyRKANihDjbPIky/qbn3BHLt4Ui9SyIAmW
-omTxJBzcoTWcFbLUvFUufQb1nA5V9FrWk9p2rSVzTMVD
------END CERTIFICATE-----
diff --git a/Lib/test/capath/6e88d7b8.0 b/Lib/test/capath/6e88d7b8.0
deleted file mode 100644
index 9d7ac238d8..0000000000
--- a/Lib/test/capath/6e88d7b8.0
+++ /dev/null
@@ -1,14 +0,0 @@
------BEGIN CERTIFICATE-----
-MIICLDCCAdYCAQAwDQYJKoZIhvcNAQEEBQAwgaAxCzAJBgNVBAYTAlBUMRMwEQYD
-VQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5ldXJv
-bmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMTEmJy
-dXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZpMB4X
-DTk2MDkwNTAzNDI0M1oXDTk2MTAwNTAzNDI0M1owgaAxCzAJBgNVBAYTAlBUMRMw
-EQYDVQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5l
-dXJvbmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMT
-EmJydXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZp
-MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAL7+aty3S1iBA/+yxjxv4q1MUTd1kjNw
-L4lYKbpzzlmC5beaQXeQ2RmGMTXU+mDvuqItjVHOK3DvPK7lTcSGftUCAwEAATAN
-BgkqhkiG9w0BAQQFAANBAFqPEKFjk6T6CKTHvaQeEAsX0/8YHPHqH/9AnhSjrwuX
-9EBc0n6bVGhN7XaXd6sJ7dym9sbsWxb+pJdurnkxjx4=
------END CERTIFICATE-----
diff --git a/Lib/test/capath/99d0fa06.0 b/Lib/test/capath/99d0fa06.0
deleted file mode 100644
index e7dfc82947..0000000000
--- a/Lib/test/capath/99d0fa06.0
+++ /dev/null
@@ -1,41 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIHPTCCBSWgAwIBAgIBADANBgkqhkiG9w0BAQQFADB5MRAwDgYDVQQKEwdSb290
-IENBMR4wHAYDVQQLExVodHRwOi8vd3d3LmNhY2VydC5vcmcxIjAgBgNVBAMTGUNB
-IENlcnQgU2lnbmluZyBBdXRob3JpdHkxITAfBgkqhkiG9w0BCQEWEnN1cHBvcnRA
-Y2FjZXJ0Lm9yZzAeFw0wMzAzMzAxMjI5NDlaFw0zMzAzMjkxMjI5NDlaMHkxEDAO
-BgNVBAoTB1Jvb3QgQ0ExHjAcBgNVBAsTFWh0dHA6Ly93d3cuY2FjZXJ0Lm9yZzEi
-MCAGA1UEAxMZQ0EgQ2VydCBTaWduaW5nIEF1dGhvcml0eTEhMB8GCSqGSIb3DQEJ
-ARYSc3VwcG9ydEBjYWNlcnQub3JnMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIIC
-CgKCAgEAziLA4kZ97DYoB1CW8qAzQIxL8TtmPzHlawI229Z89vGIj053NgVBlfkJ
-8BLPRoZzYLdufujAWGSuzbCtRRcMY/pnCujW0r8+55jE8Ez64AO7NV1sId6eINm6
-zWYyN3L69wj1x81YyY7nDl7qPv4coRQKFWyGhFtkZip6qUtTefWIonvuLwphK42y
-fk1WpRPs6tqSnqxEQR5YYGUFZvjARL3LlPdCfgv3ZWiYUQXw8wWRBB0bF4LsyFe7
-w2t6iPGwcswlWyCR7BYCEo8y6RcYSNDHBS4CMEK4JZwFaz+qOqfrU0j36NK2B5jc
-G8Y0f3/JHIJ6BVgrCFvzOKKrF11myZjXnhCLotLddJr3cQxyYN/Nb5gznZY0dj4k
-epKwDpUeb+agRThHqtdB7Uq3EvbXG4OKDy7YCbZZ16oE/9KTfWgu3YtLq1i6L43q
-laegw1SJpfvbi1EinbLDvhG+LJGGi5Z4rSDTii8aP8bQUWWHIbEZAWV/RRyH9XzQ
-QUxPKZgh/TMfdQwEUfoZd9vUFBzugcMd9Zi3aQaRIt0AUMyBMawSB3s42mhb5ivU
-fslfrejrckzzAeVLIL+aplfKkQABi6F1ITe1Yw1nPkZPcCBnzsXWWdsC4PDSy826
-YreQQejdIOQpvGQpQsgi3Hia/0PsmBsJUUtaWsJx8cTLc6nloQsCAwEAAaOCAc4w
-ggHKMB0GA1UdDgQWBBQWtTIb1Mfz4OaO873SsDrusjkY0TCBowYDVR0jBIGbMIGY
-gBQWtTIb1Mfz4OaO873SsDrusjkY0aF9pHsweTEQMA4GA1UEChMHUm9vdCBDQTEe
-MBwGA1UECxMVaHR0cDovL3d3dy5jYWNlcnQub3JnMSIwIAYDVQQDExlDQSBDZXJ0
-IFNpZ25pbmcgQXV0aG9yaXR5MSEwHwYJKoZIhvcNAQkBFhJzdXBwb3J0QGNhY2Vy
-dC5vcmeCAQAwDwYDVR0TAQH/BAUwAwEB/zAyBgNVHR8EKzApMCegJaAjhiFodHRw
-czovL3d3dy5jYWNlcnQub3JnL3Jldm9rZS5jcmwwMAYJYIZIAYb4QgEEBCMWIWh0
-dHBzOi8vd3d3LmNhY2VydC5vcmcvcmV2b2tlLmNybDA0BglghkgBhvhCAQgEJxYl
-aHR0cDovL3d3dy5jYWNlcnQub3JnL2luZGV4LnBocD9pZD0xMDBWBglghkgBhvhC
-AQ0ESRZHVG8gZ2V0IHlvdXIgb3duIGNlcnRpZmljYXRlIGZvciBGUkVFIGhlYWQg
-b3ZlciB0byBodHRwOi8vd3d3LmNhY2VydC5vcmcwDQYJKoZIhvcNAQEEBQADggIB
-ACjH7pyCArpcgBLKNQodgW+JapnM8mgPf6fhjViVPr3yBsOQWqy1YPaZQwGjiHCc
-nWKdpIevZ1gNMDY75q1I08t0AoZxPuIrA2jxNGJARjtT6ij0rPtmlVOKTV39O9lg
-18p5aTuxZZKmxoGCXJzN600BiqXfEVWqFcofN8CCmHBh22p8lqOOLlQ+TyGpkO/c
-gr/c6EWtTZBzCDyUZbAEmXZ/4rzCahWqlwQ3JNgelE5tDlG+1sSPypZt90Pf6DBl
-Jzt7u0NDY8RD97LsaMzhGY4i+5jhe1o+ATc7iwiwovOVThrLm82asduycPAtStvY
-sONvRUgzEv/+PDIqVPfE94rwiCPCR/5kenHA0R6mY7AHfqQv0wGP3J8rtsYIqQ+T
-SCX8Ev2fQtzzxD72V7DX3WnRBnc0CkvSyqD/HMaMyRa+xMwyN2hzXwj7UfdJUzYF
-CpUCTPJ5GhD22Dp1nPMd8aINcGeGG7MW9S/lpOt5hvk9C8JzC6WZrG/8Z7jlLwum
-GCSNe9FINSkYQKyTYOGWhlC0elnYjyELn8+CkcY7v2vcB5G5l1YjqrZslMZIBjzk
-zk6q5PYvCdxTby78dOs6Y5nCpqyJvKeyRKANihDjbPIky/qbn3BHLt4Ui9SyIAmW
-omTxJBzcoTWcFbLUvFUufQb1nA5V9FrWk9p2rSVzTMVD
------END CERTIFICATE-----
diff --git a/Lib/test/capath/b1930218.0 b/Lib/test/capath/b1930218.0
deleted file mode 100644
index 941d7919f8..0000000000
--- a/Lib/test/capath/b1930218.0
+++ /dev/null
@@ -1,26 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIEbTCCAtWgAwIBAgIJAMstgJlaaVJbMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
-Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcjCCAaIwDQYJKoZI
-hvcNAQEBBQADggGPADCCAYoCggGBALGE009cBICRT4JJujAL9+jL+RTvPZ8LPwpi
-/BsgpSDRYF+HWh8W0e2XcKbaGwMsfqBbPE4vFn4OiSmJ4RANONpqd183E7Moj3tc
-dq2e6NP1nvWDqhAHjeZRmPB8DVLyDCEe2LmZJqklAye7XKsuMyei1iOog4dEKZ+X
-tSRv17kK/Sjuu/tBWOodmd1EhquYvhzcy6mJHTZcqehHtfRSSKq1pGfvPtfi0zPe
-mCnYerBZXOexDsz9n+v21ToOC8/+Cz2iv0UYzpTnqVVgiNTYhFB5BS5BA3SuZyb2
-WxIImM4Kl+0BD4lPF1z6Ph01JEeSMr/3pBgrPNBImeGizaPMUFMgtcbjZoV7VxDs
-M0/Bd+cbfoHGxPNFIMCR3RN2ewOv9naOooNjV91jvLtaHBdSitYGSMwPx9NP6Noi
-bIb5TlymKQc72FZMWbMgSQd7lITPK8McGk6HZJK6QuHmrX0d9lSQbyvps8xLKzMm
-I/1lwDzwea3JwYHvNwTgJz6w7hW+UQIDAQABo1AwTjAdBgNVHQ4EFgQUs4qgorpx
-8agkedSkWyU2FR5JyM0wHwYDVR0jBBgwFoAUs4qgorpx8agkedSkWyU2FR5JyM0w
-DAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAYEAazIv5wUY6lzJlfTgwgxB
-XxoKlcnHfQXuilYpNVBAt/6fe1scw2kvoMvSuJEvUBli9ycYbZV7UxYVolrcFOP7
-sTKpadumM0c8ux/S3HD5ai4M2Ixt5V0dQzxOkd6gyNqgSw6dXrYPSknwe7ZTnv01
-FFvjTbQYpjZh6I8zm9QF+VRm3+DLGKNO3BeooLPBqPTWncp/aFMa15Xa6NOeSABx
-lZkRB8+WwH3OfTDoT+GDFjOh/1mbPkznOjgBnw9nTP0ti0rUAUY3M+gTaxWpHWh2
-RaKCM2kmMGAFyI+9tHWrvnqLSGhwQLQbUcXmeq1rT9sXwGBnLmNhmyxImbh2RaCe
-zO8zHlBOq3LDZciyebM1gyF404tsOhjoZTI5uMCdcS81NorAF2LYiz7hIhgrTGOm
-Dp0K+qtbNfuIkXdMjYydqc/8q8LmWgV7fgRuOc+Tzmc7esuvtjbh+3FkRdSm8M7v
-dQSZaZrliAoQAnSJ7HWERIBI38H36TfOzpKSXIkiCHMf
------END CERTIFICATE-----
diff --git a/Lib/test/capath/ceff1710.0 b/Lib/test/capath/ceff1710.0
deleted file mode 100644
index 941d7919f8..0000000000
--- a/Lib/test/capath/ceff1710.0
+++ /dev/null
@@ -1,26 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIEbTCCAtWgAwIBAgIJAMstgJlaaVJbMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
-Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcjCCAaIwDQYJKoZI
-hvcNAQEBBQADggGPADCCAYoCggGBALGE009cBICRT4JJujAL9+jL+RTvPZ8LPwpi
-/BsgpSDRYF+HWh8W0e2XcKbaGwMsfqBbPE4vFn4OiSmJ4RANONpqd183E7Moj3tc
-dq2e6NP1nvWDqhAHjeZRmPB8DVLyDCEe2LmZJqklAye7XKsuMyei1iOog4dEKZ+X
-tSRv17kK/Sjuu/tBWOodmd1EhquYvhzcy6mJHTZcqehHtfRSSKq1pGfvPtfi0zPe
-mCnYerBZXOexDsz9n+v21ToOC8/+Cz2iv0UYzpTnqVVgiNTYhFB5BS5BA3SuZyb2
-WxIImM4Kl+0BD4lPF1z6Ph01JEeSMr/3pBgrPNBImeGizaPMUFMgtcbjZoV7VxDs
-M0/Bd+cbfoHGxPNFIMCR3RN2ewOv9naOooNjV91jvLtaHBdSitYGSMwPx9NP6Noi
-bIb5TlymKQc72FZMWbMgSQd7lITPK8McGk6HZJK6QuHmrX0d9lSQbyvps8xLKzMm
-I/1lwDzwea3JwYHvNwTgJz6w7hW+UQIDAQABo1AwTjAdBgNVHQ4EFgQUs4qgorpx
-8agkedSkWyU2FR5JyM0wHwYDVR0jBBgwFoAUs4qgorpx8agkedSkWyU2FR5JyM0w
-DAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAYEAazIv5wUY6lzJlfTgwgxB
-XxoKlcnHfQXuilYpNVBAt/6fe1scw2kvoMvSuJEvUBli9ycYbZV7UxYVolrcFOP7
-sTKpadumM0c8ux/S3HD5ai4M2Ixt5V0dQzxOkd6gyNqgSw6dXrYPSknwe7ZTnv01
-FFvjTbQYpjZh6I8zm9QF+VRm3+DLGKNO3BeooLPBqPTWncp/aFMa15Xa6NOeSABx
-lZkRB8+WwH3OfTDoT+GDFjOh/1mbPkznOjgBnw9nTP0ti0rUAUY3M+gTaxWpHWh2
-RaKCM2kmMGAFyI+9tHWrvnqLSGhwQLQbUcXmeq1rT9sXwGBnLmNhmyxImbh2RaCe
-zO8zHlBOq3LDZciyebM1gyF404tsOhjoZTI5uMCdcS81NorAF2LYiz7hIhgrTGOm
-Dp0K+qtbNfuIkXdMjYydqc/8q8LmWgV7fgRuOc+Tzmc7esuvtjbh+3FkRdSm8M7v
-dQSZaZrliAoQAnSJ7HWERIBI38H36TfOzpKSXIkiCHMf
------END CERTIFICATE-----
diff --git a/Lib/test/certdata/allsans.pem b/Lib/test/certdata/allsans.pem
new file mode 100644
index 0000000000..e400e178a1
--- /dev/null
+++ b/Lib/test/certdata/allsans.pem
@@ -0,0 +1,170 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:5f
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=allsans
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                RSA Public-Key: (3072 bit)
+                Modulus:
+                    00:c1:1a:f8:fe:53:2f:d5:53:24:d1:9a:62:00:d5:
+                    41:04:35:38:61:d3:ea:56:38:37:2f:bd:49:64:78:
+                    8a:3e:5d:32:77:16:11:78:fd:15:63:22:60:c7:8e:
+                    8c:e5:db:c5:df:d9:3c:ca:9e:f4:09:6b:52:82:a6:
+                    a6:bb:7e:bf:1c:2f:d4:0c:c2:4e:29:1f:e4:b8:ba:
+                    5c:4e:bb:4d:81:97:76:1a:7f:1d:a8:25:55:0c:2f:
+                    7e:ef:72:22:60:fb:39:33:3f:1d:64:de:d5:c5:8d:
+                    79:2b:2c:68:d9:c0:ea:2e:7c:10:b7:02:63:ee:ab:
+                    6c:47:14:1c:c7:ae:fa:79:fc:32:11:1f:6b:25:40:
+                    53:3d:7e:95:59:cc:de:fb:81:8c:b3:c5:b6:b4:c0:
+                    27:c2:3e:90:9f:78:91:51:c9:82:96:f1:ce:cc:5e:
+                    bc:27:33:cd:98:b4:4e:d1:96:77:f6:db:b1:24:09:
+                    d3:0d:69:27:99:2d:42:31:79:5a:5c:9d:27:2a:66:
+                    5d:12:21:b4:77:60:48:95:d0:b3:c5:93:1d:30:24:
+                    59:bc:a9:41:05:53:f8:7e:d2:36:a6:83:2f:ce:37:
+                    ed:75:9e:a9:8c:96:9d:c1:8c:d8:bf:25:35:6c:6b:
+                    b3:7b:03:77:6f:74:70:bb:55:59:6b:5a:75:20:53:
+                    a3:28:4a:78:b2:2f:a8:a3:a6:e7:32:1e:d6:73:2b:
+                    69:89:cb:4b:07:47:c3:da:74:72:a8:c3:43:b8:db:
+                    7f:f9:37:c1:8a:4d:23:af:68:63:17:4e:30:1e:38:
+                    6b:3e:f7:f3:f5:65:8a:37:22:38:d0:3f:3f:cd:57:
+                    74:25:84:af:33:46:ac:45:dd:c5:b4:7a:41:c7:91:
+                    3f:bf:8d:98:c2:bd:22:a6:ea:67:5b:31:0b:a7:28:
+                    4d:56:f9:da:24:01:cf:35:e6:96:f8:f0:cc:df:d5:
+                    e5:8a:77:fe:d4:c9:47:fb:09:7b:ac:b3:20:1a:27:
+                    77:25:a5:a2:b5:b1:b6:e7:f6:6d
+                Exponent: 65537 (0x10001)
+        X509v3 extensions:
+            X509v3 Subject Alternative Name: 
+                DNS:allsans, othername:<unsupported>, othername:<unsupported>, email:user@example.org, DNS:www.example.org, DirName:/C=XY/L=Castle Anthrax/O=Python Software Foundation/CN=dirname example, URI:https://www.python.org/, IP Address:127.0.0.1, IP Address:0:0:0:0:0:0:0:1, Registered ID:1.2.3.4.5
+            X509v3 Key Usage: critical
+                Digital Signature, Key Encipherment
+            X509v3 Extended Key Usage: 
+                TLS Web Server Authentication, TLS Web Client Authentication
+            X509v3 Basic Constraints: critical
+                CA:FALSE
+            X509v3 Subject Key Identifier: 
+                D4:F1:D8:23:E0:A7:E9:CA:12:45:A0:0D:03:C2:25:A6:E8:65:BC:EE
+            X509v3 Authority Key Identifier: 
+                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
+                serial:CB:2D:80:99:5A:69:52:5B
+
+            Authority Information Access: 
+                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
+                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
+
+            X509v3 CRL Distribution Points: 
+
+                Full Name:
+                  URI:http://testca.pythontest.net/testca/revocation.crl
+
+    Signature Algorithm: sha256WithRSAEncryption
+         70:77:d8:82:b0:f4:ab:de:84:ce:88:32:63:5e:23:0f:b6:58:
+         a2:b1:65:ff:12:22:0b:88:a6:fa:06:40:9a:e7:63:a7:5d:ae:
+         94:c5:68:3c:4b:e9:95:34:01:75:24:df:9d:6e:9b:e4:ff:3f:
+         61:97:29:7b:ab:34:2c:14:d3:01:d2:eb:fb:84:40:db:12:54:
+         7e:7a:44:bc:08:eb:9f:e2:15:0b:11:4f:25:d2:56:51:95:ad:
+         6d:ad:07:aa:6a:61:f9:39:d5:82:8c:45:31:9f:2a:ff:18:98:
+         49:0c:bb:17:ad:d5:24:d3:d1:c7:c4:10:3e:c4:79:26:58:f4:
+         c5:de:82:16:c4:c3:c4:a7:a3:62:22:41:90:36:0f:bc:4c:fd:
+         6a:18:22:f2:87:e9:07:db:b4:3d:65:00:e4:70:f9:d6:e5:a8:
+         a1:b9:c9:9d:e7:5d:78:aa:98:d5:f8:f4:fd:5c:d9:4c:d0:6d:
+         bf:87:71:d3:5b:ec:f4:bf:46:f9:c8:f8:10:c5:72:af:c3:15:
+         b9:c4:06:67:0b:3f:f6:f4:64:c5:27:74:c1:6b:00:37:da:ea:
+         18:36:77:36:a7:3e:80:2e:5d:54:0f:01:df:ce:9e:97:dd:c9:
+         f2:8b:59:82:c5:65:31:c8:73:20:fd:24:23:25:d8:00:df:90:
+         93:26:76:08:0a:06:a9:0e:d3:d3:4c:6f:ef:a7:fb:de:eb:2a:
+         40:b9:e4:b1:44:0c:37:ca:c6:9e:44:4a:b4:7c:2c:40:52:35:
+         bb:b3:71:28:3d:35:fd:be:c9:4f:54:b3:99:c5:5f:84:38:fb:
+         2b:fb:ea:dd:88:e8:9d:c1:9b:67:87:3d:79:7b:3d:7e:61:1f:
+         70:3c:b7:c8:4c:17:a5:0c:a3:28:c7:ab:48:11:14:f7:98:7a:
+         da:4e:fb:91:76:89:0a:a6:c6:72:e0:96:d9:f1:80:ea:68:90:
+         37:5c:c6:69:c7:d7:bc:c7:d1:ae:5b:a9:12:59:c6:e4:6c:61:
+         a9:8b:ba:51:b3:13
+-----BEGIN CERTIFICATE-----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+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/badcert.pem b/Lib/test/certdata/badcert.pem
new file mode 100644
index 0000000000..c4191460f9
--- /dev/null
+++ b/Lib/test/certdata/badcert.pem
@@ -0,0 +1,36 @@
+-----BEGIN RSA PRIVATE KEY-----
+MIICXwIBAAKBgQC8ddrhm+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9L
+opdJhTvbGfEj0DQs1IE8M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVH
+fhi/VwovESJlaBOp+WMnfhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQAB
+AoGBAK0FZpaKj6WnJZN0RqhhK+ggtBWwBnc0U/ozgKz2j1s3fsShYeiGtW6CK5nU
+D1dZ5wzhbGThI7LiOXDvRucc9n7vUgi0alqPQ/PFodPxAN/eEYkmXQ7W2k7zwsDA
+IUK0KUhktQbLu8qF/m8qM86ba9y9/9YkXuQbZ3COl5ahTZrhAkEA301P08RKv3KM
+oXnGU2UHTuJ1MAD2hOrPxjD4/wxA/39EWG9bZczbJyggB4RHu0I3NOSFjAm3HQm0
+ANOu5QK9owJBANgOeLfNNcF4pp+UikRFqxk5hULqRAWzVxVrWe85FlPm0VVmHbb/
+loif7mqjU8o1jTd/LM7RD9f2usZyE2psaw8CQQCNLhkpX3KO5kKJmS9N7JMZSc4j
+oog58yeYO8BBqKKzpug0LXuQultYv2K4veaIO04iL9VLe5z9S/Q1jaCHBBuXAkEA
+z8gjGoi1AOp6PBBLZNsncCvcV/0aC+1se4HxTNo2+duKSDnbq+ljqOM+E7odU+Nq
+ewvIWOG//e8fssd0mq3HywJBAJ8l/c8GVmrpFTx8r/nZ2Pyyjt3dH1widooDXYSV
+q6Gbf41Llo5sYAtmxdndTLASuHKecacTgZVhy0FryZpLKrU=
+-----END RSA PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+Just bad cert data
+-----END CERTIFICATE-----
+-----BEGIN RSA PRIVATE KEY-----
+MIICXwIBAAKBgQC8ddrhm+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9L
+opdJhTvbGfEj0DQs1IE8M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVH
+fhi/VwovESJlaBOp+WMnfhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQAB
+AoGBAK0FZpaKj6WnJZN0RqhhK+ggtBWwBnc0U/ozgKz2j1s3fsShYeiGtW6CK5nU
+D1dZ5wzhbGThI7LiOXDvRucc9n7vUgi0alqPQ/PFodPxAN/eEYkmXQ7W2k7zwsDA
+IUK0KUhktQbLu8qF/m8qM86ba9y9/9YkXuQbZ3COl5ahTZrhAkEA301P08RKv3KM
+oXnGU2UHTuJ1MAD2hOrPxjD4/wxA/39EWG9bZczbJyggB4RHu0I3NOSFjAm3HQm0
+ANOu5QK9owJBANgOeLfNNcF4pp+UikRFqxk5hULqRAWzVxVrWe85FlPm0VVmHbb/
+loif7mqjU8o1jTd/LM7RD9f2usZyE2psaw8CQQCNLhkpX3KO5kKJmS9N7JMZSc4j
+oog58yeYO8BBqKKzpug0LXuQultYv2K4veaIO04iL9VLe5z9S/Q1jaCHBBuXAkEA
+z8gjGoi1AOp6PBBLZNsncCvcV/0aC+1se4HxTNo2+duKSDnbq+ljqOM+E7odU+Nq
+ewvIWOG//e8fssd0mq3HywJBAJ8l/c8GVmrpFTx8r/nZ2Pyyjt3dH1widooDXYSV
+q6Gbf41Llo5sYAtmxdndTLASuHKecacTgZVhy0FryZpLKrU=
+-----END RSA PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+Just bad cert data
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/badkey.pem b/Lib/test/certdata/badkey.pem
new file mode 100644
index 0000000000..1c8a955719
--- /dev/null
+++ b/Lib/test/certdata/badkey.pem
@@ -0,0 +1,40 @@
+-----BEGIN RSA PRIVATE KEY-----
+Bad Key, though the cert should be OK
+-----END RSA PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+MIICpzCCAhCgAwIBAgIJAP+qStv1cIGNMA0GCSqGSIb3DQEBBQUAMIGJMQswCQYD
+VQQGEwJVUzERMA8GA1UECBMIRGVsYXdhcmUxEzARBgNVBAcTCldpbG1pbmd0b24x
+IzAhBgNVBAoTGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMQwwCgYDVQQLEwNT
+U0wxHzAdBgNVBAMTFnNvbWVtYWNoaW5lLnB5dGhvbi5vcmcwHhcNMDcwODI3MTY1
+NDUwWhcNMTMwMjE2MTY1NDUwWjCBiTELMAkGA1UEBhMCVVMxETAPBgNVBAgTCERl
+bGF3YXJlMRMwEQYDVQQHEwpXaWxtaW5ndG9uMSMwIQYDVQQKExpQeXRob24gU29m
+dHdhcmUgRm91bmRhdGlvbjEMMAoGA1UECxMDU1NMMR8wHQYDVQQDExZzb21lbWFj
+aGluZS5weXRob24ub3JnMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC8ddrh
+m+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9LopdJhTvbGfEj0DQs1IE8
+M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVHfhi/VwovESJlaBOp+WMn
+fhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQABoxUwEzARBglghkgBhvhC
+AQEEBAMCBkAwDQYJKoZIhvcNAQEFBQADgYEAF4Q5BVqmCOLv1n8je/Jw9K669VXb
+08hyGzQhkemEBYQd6fzQ9A/1ZzHkJKb1P6yreOLSEh4KcxYPyrLRC1ll8nr5OlCx
+CMhKkTnR6qBsdNV0XtdU2+N25hqW+Ma4ZeqsN/iiJVCGNOZGnvQuvCAGWF8+J/f/
+iHkC6gGdBJhogs4=
+-----END CERTIFICATE-----
+-----BEGIN RSA PRIVATE KEY-----
+Bad Key, though the cert should be OK
+-----END RSA PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+MIICpzCCAhCgAwIBAgIJAP+qStv1cIGNMA0GCSqGSIb3DQEBBQUAMIGJMQswCQYD
+VQQGEwJVUzERMA8GA1UECBMIRGVsYXdhcmUxEzARBgNVBAcTCldpbG1pbmd0b24x
+IzAhBgNVBAoTGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMQwwCgYDVQQLEwNT
+U0wxHzAdBgNVBAMTFnNvbWVtYWNoaW5lLnB5dGhvbi5vcmcwHhcNMDcwODI3MTY1
+NDUwWhcNMTMwMjE2MTY1NDUwWjCBiTELMAkGA1UEBhMCVVMxETAPBgNVBAgTCERl
+bGF3YXJlMRMwEQYDVQQHEwpXaWxtaW5ndG9uMSMwIQYDVQQKExpQeXRob24gU29m
+dHdhcmUgRm91bmRhdGlvbjEMMAoGA1UECxMDU1NMMR8wHQYDVQQDExZzb21lbWFj
+aGluZS5weXRob24ub3JnMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC8ddrh
+m+LutBvjYcQlnH21PPIseJ1JVG2HMmN2CmZk2YukO+9LopdJhTvbGfEj0DQs1IE8
+M+kTUyOmuKfVrFMKwtVeCJphrAnhoz7TYOuLBSqt7lVHfhi/VwovESJlaBOp+WMn
+fhcduPEYHYx/6cnVapIkZnLt30zu2um+DzA9jQIDAQABoxUwEzARBglghkgBhvhC
+AQEEBAMCBkAwDQYJKoZIhvcNAQEFBQADgYEAF4Q5BVqmCOLv1n8je/Jw9K669VXb
+08hyGzQhkemEBYQd6fzQ9A/1ZzHkJKb1P6yreOLSEh4KcxYPyrLRC1ll8nr5OlCx
+CMhKkTnR6qBsdNV0XtdU2+N25hqW+Ma4ZeqsN/iiJVCGNOZGnvQuvCAGWF8+J/f/
+iHkC6gGdBJhogs4=
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/capath/4e1295a3.0 b/Lib/test/certdata/capath/4e1295a3.0
new file mode 100644
index 0000000000..9d7ac238d8
--- /dev/null
+++ b/Lib/test/certdata/capath/4e1295a3.0
@@ -0,0 +1,14 @@
+-----BEGIN CERTIFICATE-----
+MIICLDCCAdYCAQAwDQYJKoZIhvcNAQEEBQAwgaAxCzAJBgNVBAYTAlBUMRMwEQYD
+VQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5ldXJv
+bmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMTEmJy
+dXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZpMB4X
+DTk2MDkwNTAzNDI0M1oXDTk2MTAwNTAzNDI0M1owgaAxCzAJBgNVBAYTAlBUMRMw
+EQYDVQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5l
+dXJvbmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMT
+EmJydXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZp
+MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAL7+aty3S1iBA/+yxjxv4q1MUTd1kjNw
+L4lYKbpzzlmC5beaQXeQ2RmGMTXU+mDvuqItjVHOK3DvPK7lTcSGftUCAwEAATAN
+BgkqhkiG9w0BAQQFAANBAFqPEKFjk6T6CKTHvaQeEAsX0/8YHPHqH/9AnhSjrwuX
+9EBc0n6bVGhN7XaXd6sJ7dym9sbsWxb+pJdurnkxjx4=
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/capath/5ed36f99.0 b/Lib/test/certdata/capath/5ed36f99.0
new file mode 100644
index 0000000000..e7dfc82947
--- /dev/null
+++ b/Lib/test/certdata/capath/5ed36f99.0
@@ -0,0 +1,41 @@
+-----BEGIN CERTIFICATE-----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+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/capath/6e88d7b8.0 b/Lib/test/certdata/capath/6e88d7b8.0
new file mode 100644
index 0000000000..9d7ac238d8
--- /dev/null
+++ b/Lib/test/certdata/capath/6e88d7b8.0
@@ -0,0 +1,14 @@
+-----BEGIN CERTIFICATE-----
+MIICLDCCAdYCAQAwDQYJKoZIhvcNAQEEBQAwgaAxCzAJBgNVBAYTAlBUMRMwEQYD
+VQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5ldXJv
+bmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMTEmJy
+dXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZpMB4X
+DTk2MDkwNTAzNDI0M1oXDTk2MTAwNTAzNDI0M1owgaAxCzAJBgNVBAYTAlBUMRMw
+EQYDVQQIEwpRdWVlbnNsYW5kMQ8wDQYDVQQHEwZMaXNib2ExFzAVBgNVBAoTDk5l
+dXJvbmlvLCBMZGEuMRgwFgYDVQQLEw9EZXNlbnZvbHZpbWVudG8xGzAZBgNVBAMT
+EmJydXR1cy5uZXVyb25pby5wdDEbMBkGCSqGSIb3DQEJARYMc2FtcG9AaWtpLmZp
+MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAL7+aty3S1iBA/+yxjxv4q1MUTd1kjNw
+L4lYKbpzzlmC5beaQXeQ2RmGMTXU+mDvuqItjVHOK3DvPK7lTcSGftUCAwEAATAN
+BgkqhkiG9w0BAQQFAANBAFqPEKFjk6T6CKTHvaQeEAsX0/8YHPHqH/9AnhSjrwuX
+9EBc0n6bVGhN7XaXd6sJ7dym9sbsWxb+pJdurnkxjx4=
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/capath/99d0fa06.0 b/Lib/test/certdata/capath/99d0fa06.0
new file mode 100644
index 0000000000..e7dfc82947
--- /dev/null
+++ b/Lib/test/certdata/capath/99d0fa06.0
@@ -0,0 +1,41 @@
+-----BEGIN CERTIFICATE-----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+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/capath/b1930218.0 b/Lib/test/certdata/capath/b1930218.0
new file mode 100644
index 0000000000..941d7919f8
--- /dev/null
+++ b/Lib/test/certdata/capath/b1930218.0
@@ -0,0 +1,26 @@
+-----BEGIN CERTIFICATE-----
+MIIEbTCCAtWgAwIBAgIJAMstgJlaaVJbMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
+BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
+MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
+NDIzMTZaME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
+Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcjCCAaIwDQYJKoZI
+hvcNAQEBBQADggGPADCCAYoCggGBALGE009cBICRT4JJujAL9+jL+RTvPZ8LPwpi
+/BsgpSDRYF+HWh8W0e2XcKbaGwMsfqBbPE4vFn4OiSmJ4RANONpqd183E7Moj3tc
+dq2e6NP1nvWDqhAHjeZRmPB8DVLyDCEe2LmZJqklAye7XKsuMyei1iOog4dEKZ+X
+tSRv17kK/Sjuu/tBWOodmd1EhquYvhzcy6mJHTZcqehHtfRSSKq1pGfvPtfi0zPe
+mCnYerBZXOexDsz9n+v21ToOC8/+Cz2iv0UYzpTnqVVgiNTYhFB5BS5BA3SuZyb2
+WxIImM4Kl+0BD4lPF1z6Ph01JEeSMr/3pBgrPNBImeGizaPMUFMgtcbjZoV7VxDs
+M0/Bd+cbfoHGxPNFIMCR3RN2ewOv9naOooNjV91jvLtaHBdSitYGSMwPx9NP6Noi
+bIb5TlymKQc72FZMWbMgSQd7lITPK8McGk6HZJK6QuHmrX0d9lSQbyvps8xLKzMm
+I/1lwDzwea3JwYHvNwTgJz6w7hW+UQIDAQABo1AwTjAdBgNVHQ4EFgQUs4qgorpx
+8agkedSkWyU2FR5JyM0wHwYDVR0jBBgwFoAUs4qgorpx8agkedSkWyU2FR5JyM0w
+DAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAYEAazIv5wUY6lzJlfTgwgxB
+XxoKlcnHfQXuilYpNVBAt/6fe1scw2kvoMvSuJEvUBli9ycYbZV7UxYVolrcFOP7
+sTKpadumM0c8ux/S3HD5ai4M2Ixt5V0dQzxOkd6gyNqgSw6dXrYPSknwe7ZTnv01
+FFvjTbQYpjZh6I8zm9QF+VRm3+DLGKNO3BeooLPBqPTWncp/aFMa15Xa6NOeSABx
+lZkRB8+WwH3OfTDoT+GDFjOh/1mbPkznOjgBnw9nTP0ti0rUAUY3M+gTaxWpHWh2
+RaKCM2kmMGAFyI+9tHWrvnqLSGhwQLQbUcXmeq1rT9sXwGBnLmNhmyxImbh2RaCe
+zO8zHlBOq3LDZciyebM1gyF404tsOhjoZTI5uMCdcS81NorAF2LYiz7hIhgrTGOm
+Dp0K+qtbNfuIkXdMjYydqc/8q8LmWgV7fgRuOc+Tzmc7esuvtjbh+3FkRdSm8M7v
+dQSZaZrliAoQAnSJ7HWERIBI38H36TfOzpKSXIkiCHMf
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/capath/ceff1710.0 b/Lib/test/certdata/capath/ceff1710.0
new file mode 100644
index 0000000000..941d7919f8
--- /dev/null
+++ b/Lib/test/certdata/capath/ceff1710.0
@@ -0,0 +1,26 @@
+-----BEGIN CERTIFICATE-----
+MIIEbTCCAtWgAwIBAgIJAMstgJlaaVJbMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
+BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
+MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
+NDIzMTZaME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
+Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcjCCAaIwDQYJKoZI
+hvcNAQEBBQADggGPADCCAYoCggGBALGE009cBICRT4JJujAL9+jL+RTvPZ8LPwpi
+/BsgpSDRYF+HWh8W0e2XcKbaGwMsfqBbPE4vFn4OiSmJ4RANONpqd183E7Moj3tc
+dq2e6NP1nvWDqhAHjeZRmPB8DVLyDCEe2LmZJqklAye7XKsuMyei1iOog4dEKZ+X
+tSRv17kK/Sjuu/tBWOodmd1EhquYvhzcy6mJHTZcqehHtfRSSKq1pGfvPtfi0zPe
+mCnYerBZXOexDsz9n+v21ToOC8/+Cz2iv0UYzpTnqVVgiNTYhFB5BS5BA3SuZyb2
+WxIImM4Kl+0BD4lPF1z6Ph01JEeSMr/3pBgrPNBImeGizaPMUFMgtcbjZoV7VxDs
+M0/Bd+cbfoHGxPNFIMCR3RN2ewOv9naOooNjV91jvLtaHBdSitYGSMwPx9NP6Noi
+bIb5TlymKQc72FZMWbMgSQd7lITPK8McGk6HZJK6QuHmrX0d9lSQbyvps8xLKzMm
+I/1lwDzwea3JwYHvNwTgJz6w7hW+UQIDAQABo1AwTjAdBgNVHQ4EFgQUs4qgorpx
+8agkedSkWyU2FR5JyM0wHwYDVR0jBBgwFoAUs4qgorpx8agkedSkWyU2FR5JyM0w
+DAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAYEAazIv5wUY6lzJlfTgwgxB
+XxoKlcnHfQXuilYpNVBAt/6fe1scw2kvoMvSuJEvUBli9ycYbZV7UxYVolrcFOP7
+sTKpadumM0c8ux/S3HD5ai4M2Ixt5V0dQzxOkd6gyNqgSw6dXrYPSknwe7ZTnv01
+FFvjTbQYpjZh6I8zm9QF+VRm3+DLGKNO3BeooLPBqPTWncp/aFMa15Xa6NOeSABx
+lZkRB8+WwH3OfTDoT+GDFjOh/1mbPkznOjgBnw9nTP0ti0rUAUY3M+gTaxWpHWh2
+RaKCM2kmMGAFyI+9tHWrvnqLSGhwQLQbUcXmeq1rT9sXwGBnLmNhmyxImbh2RaCe
+zO8zHlBOq3LDZciyebM1gyF404tsOhjoZTI5uMCdcS81NorAF2LYiz7hIhgrTGOm
+Dp0K+qtbNfuIkXdMjYydqc/8q8LmWgV7fgRuOc+Tzmc7esuvtjbh+3FkRdSm8M7v
+dQSZaZrliAoQAnSJ7HWERIBI38H36TfOzpKSXIkiCHMf
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/ffdh3072.pem b/Lib/test/certdata/ffdh3072.pem
new file mode 100644
index 0000000000..ad69bac8d0
--- /dev/null
+++ b/Lib/test/certdata/ffdh3072.pem
@@ -0,0 +1,41 @@
+    DH Parameters: (3072 bit)
+        prime:
+            00:ff:ff:ff:ff:ff:ff:ff:ff:ad:f8:54:58:a2:bb:
+            4a:9a:af:dc:56:20:27:3d:3c:f1:d8:b9:c5:83:ce:
+            2d:36:95:a9:e1:36:41:14:64:33:fb:cc:93:9d:ce:
+            24:9b:3e:f9:7d:2f:e3:63:63:0c:75:d8:f6:81:b2:
+            02:ae:c4:61:7a:d3:df:1e:d5:d5:fd:65:61:24:33:
+            f5:1f:5f:06:6e:d0:85:63:65:55:3d:ed:1a:f3:b5:
+            57:13:5e:7f:57:c9:35:98:4f:0c:70:e0:e6:8b:77:
+            e2:a6:89:da:f3:ef:e8:72:1d:f1:58:a1:36:ad:e7:
+            35:30:ac:ca:4f:48:3a:79:7a:bc:0a:b1:82:b3:24:
+            fb:61:d1:08:a9:4b:b2:c8:e3:fb:b9:6a:da:b7:60:
+            d7:f4:68:1d:4f:42:a3:de:39:4d:f4:ae:56:ed:e7:
+            63:72:bb:19:0b:07:a7:c8:ee:0a:6d:70:9e:02:fc:
+            e1:cd:f7:e2:ec:c0:34:04:cd:28:34:2f:61:91:72:
+            fe:9c:e9:85:83:ff:8e:4f:12:32:ee:f2:81:83:c3:
+            fe:3b:1b:4c:6f:ad:73:3b:b5:fc:bc:2e:c2:20:05:
+            c5:8e:f1:83:7d:16:83:b2:c6:f3:4a:26:c1:b2:ef:
+            fa:88:6b:42:38:61:1f:cf:dc:de:35:5b:3b:65:19:
+            03:5b:bc:34:f4:de:f9:9c:02:38:61:b4:6f:c9:d6:
+            e6:c9:07:7a:d9:1d:26:91:f7:f7:ee:59:8c:b0:fa:
+            c1:86:d9:1c:ae:fe:13:09:85:13:92:70:b4:13:0c:
+            93:bc:43:79:44:f4:fd:44:52:e2:d7:4d:d3:64:f2:
+            e2:1e:71:f5:4b:ff:5c:ae:82:ab:9c:9d:f6:9e:e8:
+            6d:2b:c5:22:36:3a:0d:ab:c5:21:97:9b:0d:ea:da:
+            1d:bf:9a:42:d5:c4:48:4e:0a:bc:d0:6b:fa:53:dd:
+            ef:3c:1b:20:ee:3f:d5:9d:7c:25:e4:1d:2b:66:c6:
+            2e:37:ff:ff:ff:ff:ff:ff:ff:ff
+        generator: 2 (0x2)
+        recommended-private-length: 276 bits
+-----BEGIN DH PARAMETERS-----
+MIIBjAKCAYEA//////////+t+FRYortKmq/cViAnPTzx2LnFg84tNpWp4TZBFGQz
++8yTnc4kmz75fS/jY2MMddj2gbICrsRhetPfHtXV/WVhJDP1H18GbtCFY2VVPe0a
+87VXE15/V8k1mE8McODmi3fipona8+/och3xWKE2rec1MKzKT0g6eXq8CrGCsyT7
+YdEIqUuyyOP7uWrat2DX9GgdT0Kj3jlN9K5W7edjcrsZCwenyO4KbXCeAvzhzffi
+7MA0BM0oNC9hkXL+nOmFg/+OTxIy7vKBg8P+OxtMb61zO7X8vC7CIAXFjvGDfRaD
+ssbzSibBsu/6iGtCOGEfz9zeNVs7ZRkDW7w09N75nAI4YbRvydbmyQd62R0mkff3
+7lmMsPrBhtkcrv4TCYUTknC0EwyTvEN5RPT9RFLi103TZPLiHnH1S/9croKrnJ32
+nuhtK8UiNjoNq8Uhl5sN6todv5pC1cRITgq80Gv6U93vPBsg7j/VnXwl5B0rZsYu
+N///////////AgECAgIBFA==
+-----END DH PARAMETERS-----
diff --git a/Lib/test/certdata/idnsans.pem b/Lib/test/certdata/idnsans.pem
new file mode 100644
index 0000000000..cbcac7818d
--- /dev/null
+++ b/Lib/test/certdata/idnsans.pem
@@ -0,0 +1,169 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:60
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=idnsans
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                RSA Public-Key: (3072 bit)
+                Modulus:
+                    00:bc:b2:aa:65:4e:e1:ee:2e:36:d6:4c:be:52:2f:
+                    60:f5:7f:0f:54:e9:64:33:2d:50:05:e6:0b:32:85:
+                    de:65:af:61:69:7d:8c:23:ae:86:f9:31:ab:fd:d5:
+                    a3:8b:6c:94:53:be:83:72:5e:c2:76:e8:53:d2:d1:
+                    1c:9c:44:65:db:a2:67:08:10:9c:57:1b:2f:5a:23:
+                    ed:0c:2d:80:6d:d4:6e:66:82:a0:87:f8:77:15:0b:
+                    03:f3:08:d9:61:56:74:f0:be:98:00:ef:2f:33:b3:
+                    7f:ba:7b:36:40:3d:69:05:d3:25:8e:31:82:ed:4d:
+                    ca:bd:03:91:96:79:ab:ed:e5:53:20:9b:52:99:17:
+                    78:0e:e2:4e:7c:a0:fc:a4:dc:07:bd:0f:42:c0:69:
+                    8b:17:e8:31:62:05:8c:78:d5:e5:11:e5:46:d2:6f:
+                    92:18:5d:a0:dd:f1:de:a3:a9:6f:e3:9d:88:60:73:
+                    a0:b1:92:fd:60:4c:91:67:f3:b5:79:96:b1:b4:bd:
+                    83:12:45:4b:56:0d:0f:58:26:1f:c4:28:0c:63:1b:
+                    0e:c0:79:8e:36:f6:9e:93:13:85:28:26:10:e6:a0:
+                    56:11:d8:d2:ef:6b:08:4d:22:99:71:a2:5f:ef:d1:
+                    fb:34:bd:e1:50:8c:8f:d4:b1:30:fc:da:d4:5f:9d:
+                    82:f8:21:7f:2c:ce:12:ec:13:9f:f9:22:af:1a:88:
+                    b1:e3:55:b2:0c:c2:60:d8:01:ad:0f:eb:70:29:da:
+                    47:f5:6e:24:a7:f6:6a:43:2f:c9:50:6b:34:a8:ca:
+                    bf:31:cc:8a:b6:41:2e:47:32:f1:9b:78:c0:26:4b:
+                    48:a1:d7:46:71:f3:8b:95:9a:45:a5:6a:f8:2f:b5:
+                    27:e5:c3:c2:bf:65:74:fd:73:bd:2b:66:9f:d3:74:
+                    11:98:f7:97:0e:16:c6:e0:e5:4f:f6:d0:cf:cb:96:
+                    98:ac:f6:d7:01:09:aa:15:69:84:85:ba:96:ad:ac:
+                    ff:a9:f3:2d:7d:a8:fd:a7:79:bb
+                Exponent: 65537 (0x10001)
+        X509v3 extensions:
+            X509v3 Subject Alternative Name: 
+                DNS:idnsans, DNS:xn--knig-5qa.idn.pythontest.net, DNS:xn--knigsgsschen-lcb0w.idna2003.pythontest.net, DNS:xn--knigsgchen-b4a3dun.idna2008.pythontest.net, DNS:xn--nxasmq6b.idna2003.pythontest.net, DNS:xn--nxasmm1c.idna2008.pythontest.net
+            X509v3 Key Usage: critical
+                Digital Signature, Key Encipherment
+            X509v3 Extended Key Usage: 
+                TLS Web Server Authentication, TLS Web Client Authentication
+            X509v3 Basic Constraints: critical
+                CA:FALSE
+            X509v3 Subject Key Identifier: 
+                5C:BE:18:7F:7B:3F:CE:99:66:80:79:53:4B:DD:33:1B:42:A5:7E:00
+            X509v3 Authority Key Identifier: 
+                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
+                serial:CB:2D:80:99:5A:69:52:5B
+
+            Authority Information Access: 
+                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
+                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
+
+            X509v3 CRL Distribution Points: 
+
+                Full Name:
+                  URI:http://testca.pythontest.net/testca/revocation.crl
+
+    Signature Algorithm: sha256WithRSAEncryption
+         5d:7a:f8:81:e0:a7:c1:3f:39:eb:d3:52:2c:e1:cb:4d:29:b3:
+         77:18:17:18:9e:12:fc:11:cc:3c:49:cb:6b:f4:4d:6c:b8:d2:
+         f4:e9:37:f8:6b:ed:f5:d7:f1:eb:5a:41:04:c7:f3:8c:da:e1:
+         05:8e:ae:58:71:d9:01:8a:32:46:b2:dd:95:46:e1:ce:82:04:
+         fa:0b:1c:29:75:07:85:ce:cd:59:d4:cc:f3:56:b3:72:4d:cb:
+         90:0f:ce:02:21:ce:5d:17:84:96:7f:6a:00:57:42:b7:24:5b:
+         07:25:1e:77:a8:9d:da:41:09:8e:29:79:b4:b0:a1:45:c8:70:
+         ae:2c:86:24:ae:3d:9a:74:a7:04:78:d6:1f:1b:17:c5:c1:6d:
+         b1:1a:fd:f4:50:2e:61:16:84:89:d0:42:3f:b6:bf:bd:52:bd:
+         c8:3e:8e:87:b4:f0:bd:ad:c7:51:65:2f:77:e8:69:79:0e:03:
+         63:89:e7:70:ad:c8:d1:2f:1a:a5:06:d2:90:db:7c:07:35:9a:
+         0b:0e:85:87:d1:70:17:a7:88:0f:c6:b5:9c:88:00:fa:f9:b2:
+         0a:19:5a:4b:8d:91:12:51:5e:0e:c1:d8:9e:02:78:d0:2d:24:
+         09:fe:d4:97:3c:cb:a0:1f:9a:ab:f7:0f:e2:fa:64:23:4e:53:
+         0a:15:3e:f5:04:01:86:29:8b:8e:24:40:2f:b1:90:87:5c:3b:
+         7b:a7:4c:06:af:c3:90:7f:e9:c6:56:42:61:15:2c:83:f1:7c:
+         4f:89:17:f3:a0:11:34:3f:8d:af:75:34:60:1e:e0:f2:f3:02:
+         e7:aa:b3:f7:9f:1c:f8:69:f4:fe:da:57:6e:1b:95:53:70:cd:
+         ed:b6:bb:2a:84:eb:ab:c3:a9:b4:d5:15:a0:b2:cc:81:2d:f1:
+         56:c1:54:9b:5f:14:4c:5f:ad:5f:f5:06:ee:22:60:45:e4:50:
+         35:64:ac:ac:ca:4a:bf:86:78:f8:53:2d:17:d8:e8:84:c8:07:
+         a4:c2:29:76:c7:1f
+-----BEGIN CERTIFICATE-----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+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/keycert.passwd.pem b/Lib/test/certdata/keycert.passwd.pem
new file mode 100644
index 0000000000..c330c36d8f
--- /dev/null
+++ b/Lib/test/certdata/keycert.passwd.pem
@@ -0,0 +1,69 @@
+-----BEGIN ENCRYPTED PRIVATE KEY-----
+MIIHbTBXBgkqhkiG9w0BBQ0wSjApBgkqhkiG9w0BBQwwHAQIhD+rJdxqb6ECAggA
+MAwGCCqGSIb3DQIJBQAwHQYJYIZIAWUDBAEqBBDTdyjCP3riOSUfxix4aXEvBIIH
+ECGkbsFabrcFMZcplw5jHMaOlG7rYjUzwDJ80JM8uzbv2Jb8SvNlns2+xmnEvH/M
+mNvRmnXmplbVjH3XBMK8o2Psnr2V/a0j7/pgqpRxHykG+koOY4gzdt3MAg8JPbS2
+hymSl+Y5EpciO3xLfz4aFL1ZNqspQbO/TD13Ij7DUIy7xIRBMp4taoZCrP0cEBAZ
++wgu9m23I4dh3E8RUBzWyFFNic2MVVHrui6JbHc4dIHfyKLtXJDhUcS0vIC9PvcV
+jhorh3UZC4lM+/jjXV5AhzQ0VrJ2tXAUX2dA144XHzkSH2QmwfnajPsci7BL2CGC
+rjyTy4NfB/lDwU+55dqJZQSKXMxAapJMrtgw7LD5CKQcN6zmfhXGssJ7HQUXKkaX
+I1YOFzuUD7oo56BVCnVswv0jX9RxrE5QYNreMlOP9cS+kIYH65N+PAhlURuQC14K
+PgDkHn5knSa2UQA5tc5f7zdHOZhGRUfcjLP+KAWA3nh+/2OKw/X3zuPx75YT/FKe
+tACPw5hjEpl62m9Xa0eWepZXwqkIOkzHMmCyNCsbC0mmRoEjmvfnslfsmnh4Dg/c
+4YsTYMOLLIeCa+WIc38aA5W2lNO9lW0LwLhX1rP+GRVPv+TVHXlfoyaI+jp0iXrJ
+t3xxT0gaiIR/VznyS7Py68QV/zB7VdqbsNzS7LdquHK1k8+7OYiWjY3gqyU40Iu2
+d1eSnIoDvQJwyYp7XYXbOlXNLY+s1Qb7yxcW3vXm0Bg3gKT8r1XHWJ9rj+CxAn5r
+ysfkPs1JsesxzzQjwTiDNvHnBnZnwxuxfBr26ektEHmuAXSl8V6dzLN/aaPjpTj4
+CkE7KyqX3U9bLkp+ztl4xWKEmW44nskzm0+iqrtrxMyTfvvID4QrABjZL4zmWIqc
+e3ZfA3AYk9VDIegk/YKGC5VZ8YS7ZXQ0ASK652XqJ7QlMKTxxV7zda6Fp4uW6/qN
+ezt5wgbGGhZQXj2wDQmWNQYyG/juIgYTpCUA54U5XBIjuR6pg+Ytm0UrvNjsUoAC
+wGelyqaLDq8U8jdIFYVTJy9aJjQOYXjsUJ0dZN2aGHSlju0ZGIZc49cTIVQ9BTC5
+Yc0Vlwzpl+LuA25DzKZNSb/ci0lO/cQGJ2uXQQgaNgdsHlu8nukENGJhnIzx4fzK
+wEh3yHxhTRCzPPwDfXmx0IHXrPqJhSpAgaXBVIm8OjvmMxO+W75W4uLfNY/B7e2H
+3cjklGuvkofOf7sEOrGUYf4cb6Obg8FpvHgpKo5Twwmoh/qvEKckBFqNhZXDDl88
+GbGlSEgyaAV1Ig8s1NJKBolWFa0juyPAwJ8vT1T4iwW7kQ7KXKt2UNn96K/HxkLu
+pikvukz8oRHMlfVHa0R48UB1fFHwZLzPmwkpu6ancIxk3uO3yfhf6iDk3bmnyMlz
+g3k/b6MrLYaOVByRxay85jH3Vvgqfgn6wa6BJ7xQ81eZ8B45gFuTH0J5JtLL7SH8
+darRPLCYfA+Ums9/H6pU5EXfd3yfjMIbvhCXHkJrrljkZ+th3p8dyto6wmYqIY6I
+qR9sU+o6DhRaiP8tCICuhHxQpXylUM6WeJkJwduTJ8KWIvzsj4mReIKOl/oC2jSd
+gIdKhb9Q3zj9ce4N5m6v66tyvjxGZ+xf3BvUPDD+LwZeXgf7OBsNVbXzQbzto594
+nbCzPocFi3gERE50ru4K70eQCy08TPG5NpOz+DDdO5vpAuMLYEuI7O3L+3GjW40Q
+G5bu7H5/i7o/RWR67qhG/7p9kPw3nkUtYgnvnWaPMIuTfb4c2d069kjlfgWjIbbI
+tpSKmm5DHlqTE4/ECAbIEDtSaw9dXHCdL3nh5+n428xDdGbjN4lT86tfu17EYKzl
+ydH1RJ1LX3o3TEj9UkmDPt7LnftvwybMFEcP7hM2xD4lC++wKQs7Alg6dTkBnJV4
+5xU78WRntJkJTU7kFkpPKA0QfyCuSF1fAMoukDBkqUdOj6jE0BlJQlHk5iwgnJlt
+uEdkTjHZEjIUxWC6llPcAzaPNlmnD45AgfEW+Jn21IvutmJiQAz5lm9Z9PXaR0C8
+hXB6owRY67C0YKQwXhoNf6xQun2xGBGYy5rPEEezX1S1tUH5GR/KW1Lh+FzFqHXI
+ZEb5avfDqHKehGAjPON+Br7akuQ125M9LLjKuSyPaQzeeCAy356Xd7XzVwbPddbm
+9S9WSPqzaPgh10chIHoNoC8HMd33dB5j9/Q6jrbU/oPlptu/GlorWblvJdcTuBGI
+IVn45RFnkG8hCz0GJSNzW7+70YdESQbfJW79vssWMaiSjFE0pMyFXrFR5lBywBTx
+PiGEUWtvrKG94X1TMlGUzDzDJOQNZ9dT94bonNe9pVmP5BP4/DzwwiWh6qrzWk6p
+j8OE4cfCSh2WvHnhJbH7/N0v+JKjtxeIeJ16jx/K2oK5
+-----END ENCRYPTED PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+MIIEWTCCAsGgAwIBAgIJAJinz4jHSjLtMA0GCSqGSIb3DQEBCwUAMF8xCzAJBgNV
+BAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9u
+IFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODA4
+MjkxNDIzMTVaFw0yODA4MjYxNDIzMTVaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQH
+DA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5k
+YXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGP
+ADCCAYoCggGBALKUqUtopT6E68kN+uJNEt34i2EbmG/bwjcD8IaMsgJPSsMO2Bpd
+3S6qWgkCeOyCfmAwBxK2kNbxGb63ouysEv7l8GCTJTWv3hG/HQcejJpnAEGi6K1U
+fDbyE/db6yZ12SoHVTGkadN4vYGCPd1Wj9ZO1F877SHQ8rDWX3xgTWkxN2ojBw44
+T8RHSDiG8D/CvG4uEy+VUszL+Uvny5y2poNSqvI3J56sptWSrh8nIIbkPZPBdUne
+LYMOHTFK3ZjXSmhlXgziTxK71nnzM3Y9K9gxPnRqoXbvu/wFo55hQCkETiRkYgmm
+jXcBMZ0TClQVnQWuLjMthRnWFZs4Lfmwqjs7FZD/61581R2BYehvpWbLvvuOJhwv
+DFzexL2sXcAl7SsxbzeQKRHqGbIDfbnQTXfs3/VC6Ye5P82P2ucj+XC32N9piRmO
+gCBP8L3ub+YzzdxikZN2gZXXE2jsb3QyE/R2LkWdWyshpKe+RsZP1SBRbHShUyOh
+yJ90baoiEwj2mwIDAQABoxgwFjAUBgNVHREEDTALgglsb2NhbGhvc3QwDQYJKoZI
+hvcNAQELBQADggGBAHRUO/UIHl3jXQENewYayHxkIx8t7nu40iO2DXbicSijz5bo
+5//xAB6RxhBAlsDBehgQP1uoZg+WJW+nHu3CIVOU3qZNZRaozxiCl2UFKcNqLOmx
+R3NKpo1jYf4REQIeG8Yw9+hSWLRbshNteP6bKUUf+vanhg9+axyOEOH/iOQvgk/m
+b8wA8wNa4ujWljPbTQnj7ry8RqhTM0GcAN5LSdSvcKcpzLcs3aYwh+Z8e30sQWna
+F40sa5u7izgBTOrwpcDm/w5kC46vpRQ5fnbshVw6pne2by0mdMECASid/p25N103
+jMqTFlmO7kpf/jpCSmamp3/JSEE1BJKHwQ6Ql4nzRA2N1mnvWH7Zxcv043gkHeAu
+0x8evpvwuhdIyproejNFlBpKmW8OX7yKTCPPMC/VkX8Q1rVkxU0DQ6hmvwZlhoKa
+9Wc2uXpw9xF8itV4Uvcdr3dwqByvIqn7iI/gB+4l41e0u8OmH2MKOx4Nxlly5TNW
+HcVKQHyOeyvnINuBAQ==
+-----END CERTIFICATE-----
+
diff --git a/Lib/test/certdata/keycert.pem b/Lib/test/certdata/keycert.pem
new file mode 100644
index 0000000000..0d39863373
--- /dev/null
+++ b/Lib/test/certdata/keycert.pem
@@ -0,0 +1,66 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+MIIEWTCCAsGgAwIBAgIJAJinz4jHSjLtMA0GCSqGSIb3DQEBCwUAMF8xCzAJBgNV
+BAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9u
+IFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODA4
+MjkxNDIzMTVaFw0yODA4MjYxNDIzMTVaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQH
+DA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5k
+YXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGP
+ADCCAYoCggGBALKUqUtopT6E68kN+uJNEt34i2EbmG/bwjcD8IaMsgJPSsMO2Bpd
+3S6qWgkCeOyCfmAwBxK2kNbxGb63ouysEv7l8GCTJTWv3hG/HQcejJpnAEGi6K1U
+fDbyE/db6yZ12SoHVTGkadN4vYGCPd1Wj9ZO1F877SHQ8rDWX3xgTWkxN2ojBw44
+T8RHSDiG8D/CvG4uEy+VUszL+Uvny5y2poNSqvI3J56sptWSrh8nIIbkPZPBdUne
+LYMOHTFK3ZjXSmhlXgziTxK71nnzM3Y9K9gxPnRqoXbvu/wFo55hQCkETiRkYgmm
+jXcBMZ0TClQVnQWuLjMthRnWFZs4Lfmwqjs7FZD/61581R2BYehvpWbLvvuOJhwv
+DFzexL2sXcAl7SsxbzeQKRHqGbIDfbnQTXfs3/VC6Ye5P82P2ucj+XC32N9piRmO
+gCBP8L3ub+YzzdxikZN2gZXXE2jsb3QyE/R2LkWdWyshpKe+RsZP1SBRbHShUyOh
+yJ90baoiEwj2mwIDAQABoxgwFjAUBgNVHREEDTALgglsb2NhbGhvc3QwDQYJKoZI
+hvcNAQELBQADggGBAHRUO/UIHl3jXQENewYayHxkIx8t7nu40iO2DXbicSijz5bo
+5//xAB6RxhBAlsDBehgQP1uoZg+WJW+nHu3CIVOU3qZNZRaozxiCl2UFKcNqLOmx
+R3NKpo1jYf4REQIeG8Yw9+hSWLRbshNteP6bKUUf+vanhg9+axyOEOH/iOQvgk/m
+b8wA8wNa4ujWljPbTQnj7ry8RqhTM0GcAN5LSdSvcKcpzLcs3aYwh+Z8e30sQWna
+F40sa5u7izgBTOrwpcDm/w5kC46vpRQ5fnbshVw6pne2by0mdMECASid/p25N103
+jMqTFlmO7kpf/jpCSmamp3/JSEE1BJKHwQ6Ql4nzRA2N1mnvWH7Zxcv043gkHeAu
+0x8evpvwuhdIyproejNFlBpKmW8OX7yKTCPPMC/VkX8Q1rVkxU0DQ6hmvwZlhoKa
+9Wc2uXpw9xF8itV4Uvcdr3dwqByvIqn7iI/gB+4l41e0u8OmH2MKOx4Nxlly5TNW
+HcVKQHyOeyvnINuBAQ==
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/keycert2.pem b/Lib/test/certdata/keycert2.pem
new file mode 100644
index 0000000000..e59d45439d
--- /dev/null
+++ b/Lib/test/certdata/keycert2.pem
@@ -0,0 +1,66 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+-----BEGIN CERTIFICATE-----
+MIIEbTCCAtWgAwIBAgIUF15VKdwjiTzzKgs6PnNpEekV9QQwDQYJKoZIhvcNAQEL
+BQAwYjELMAkGA1UEBhMCWFkxFzAVBgNVBAcMDkNhc3RsZSBBbnRocmF4MSMwIQYD
+VQQKDBpQeXRob24gU29mdHdhcmUgRm91bmRhdGlvbjEVMBMGA1UEAwwMZmFrZWhv
+c3RuYW1lMB4XDTIxMDMxNzA4NDgyMFoXDTQwMDUxNjA4NDgyMFowYjELMAkGA1UE
+BhMCWFkxFzAVBgNVBAcMDkNhc3RsZSBBbnRocmF4MSMwIQYDVQQKDBpQeXRob24g
+U29mdHdhcmUgRm91bmRhdGlvbjEVMBMGA1UEAwwMZmFrZWhvc3RuYW1lMIIBojAN
+BgkqhkiG9w0BAQEFAAOCAY8AMIIBigKCAYEAn/BVsYuKFZQ1cXvDQxYG/iGABq/4
+WVrmNWau3e4Oe8j6MSa4LfmzfPflO6k3bqsgdh8vBtE6ngAjqyHaT2fD+1eROWIg
+EsHye9p21aO6kfQwCgORRPD1NGyRZhS4ww4oXPe9M3OIpUQ30VspVKY+vJ3nzmOA
+sxc3oqlTi19sHs7O2dIX5ZElxgZgtI9RW0FNiN2CYNwigmm4U7VOjsiiLc4ydr1W
+jqEPgdCr/JXmkUOgDWQQBUBdi3qUsuRdvqEg/kB4z6/tNdleQ5q7HSHPVnvGMqJ0
+tbv9xyO5S6IX91vqha6EFo59AySOeknFdbhK/wdPoZ9owUUzOXdRfQXlVptbvATi
+budArznrsYlS7MSaWuE+NQyc5yZOVfoROISrwyppa8LpbEafKI1BMlIvHc1jgUXw
+IoyFr96gD4xgPyd95+vj5ZQnMwtgbFWYVZi6kjAsKdYNiUwjPygu0+LzpfxBpJu+
+n3Ji3gNRH/KFHUYPt0++1T/h6mdiT9OifDvDAgMBAAGjGzAZMBcGA1UdEQQQMA6C
+DGZha2Vob3N0bmFtZTANBgkqhkiG9w0BAQsFAAOCAYEARzdkuqa0Hexi/saMkdi3
+bubpQkc7X0RYKWnjy/PgcmbvQXLiWRMZOH9rMWvd5v+ZfkgAtsbOQuP8ycioNIFY
+Il5SEmxHEN81z5UNSPLOib6ky13gzrnXRAxnnO7cICG7AaMu1dHv57fqjevcx/n/
+nxPNKwKL+TDpMw7ATVZw7Py7JciKyFAfwtkvt17j/ldvaQvuwmWHzyFVrQniQcQq
+QEa4jy/Y/pXHAgCKq1qbe0ush17j1ChyH7l4SkF2xJKcYYQF5ipw8zg6WeOL2NFE
+G1KDJN0SsMmM3PMN1e0lLQP3G+UaatervrKXu51QleKL32Xlby+pp1w9KKs39/Tb
+RT8EMe9A6cecod6TL0ZUQHow6ykNYBkfSKDLTKWnL9ifZ0C/DvgmS7DpJg3oAa1e
+GhIglMrgqJflTHAI/PvEsCKM1O0Un2dVGWsUCzPfhj1cKmagyb0Zd+2Tk9xGSRs9
+2ceXMxRCjOJwEHUCFuTYeqowabdlpi0nyPbSn7JIwCpT
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/keycert3.pem b/Lib/test/certdata/keycert3.pem
new file mode 100644
index 0000000000..f6887ba7a8
--- /dev/null
+++ b/Lib/test/certdata/keycert3.pem
@@ -0,0 +1,164 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:5c
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=localhost
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                RSA Public-Key: (3072 bit)
+                Modulus:
+                    00:c5:b4:b3:ad:79:09:50:a2:33:7b:ce:d9:2e:c7:
+                    b9:b4:86:61:8a:90:fd:61:87:48:5b:2a:a4:dc:0f:
+                    ce:e3:90:b0:2a:03:06:56:7a:78:d9:32:30:9b:6d:
+                    9d:ef:3f:e0:0e:6c:22:24:60:82:b3:3d:76:3b:62:
+                    2f:87:e4:cd:ce:da:65:c8:0f:1a:07:1a:32:ff:19:
+                    6b:68:13:20:cd:5e:f9:bd:50:2f:8c:46:e4:8e:ab:
+                    63:1a:2c:71:d0:1b:44:71:d9:3c:5c:62:b3:15:50:
+                    ce:db:f7:7a:e9:37:52:c6:46:b0:af:d6:02:12:5c:
+                    ce:04:bc:42:68:a0:04:7b:01:a7:63:d2:91:bf:a3:
+                    47:ea:0c:07:45:8c:7e:90:65:b8:67:d6:26:65:7b:
+                    e7:86:6e:37:1f:76:01:ff:1f:41:7c:76:7d:4f:3c:
+                    6a:15:88:75:e2:71:bb:10:e2:40:7a:d3:4d:8f:7f:
+                    e6:97:3f:86:f6:40:a0:1b:7e:5c:8d:1c:42:87:3c:
+                    71:0e:39:35:eb:16:33:1d:73:e6:ea:29:6d:b8:7a:
+                    91:2c:31:92:39:f6:ac:7d:85:4f:f8:46:fa:77:fe:
+                    ff:af:13:04:cb:ec:d9:bb:8a:5a:6d:cd:99:f6:72:
+                    f1:82:5b:7f:4b:0b:49:cd:60:b3:b3:90:ed:c7:f3:
+                    1c:00:ef:98:7a:bb:29:1d:07:e5:8e:fe:fd:82:28:
+                    82:bd:33:f6:4e:fb:d4:0d:ae:66:a8:91:f2:83:6a:
+                    60:a4:df:d6:fc:86:50:b0:34:be:8b:b1:5a:6f:77:
+                    75:d3:4b:95:a7:e1:85:a7:f7:61:2a:8a:5b:54:24:
+                    9a:0f:a3:ba:5c:ed:54:dd:58:28:38:cd:51:67:e1:
+                    0f:19:87:83:45:36:7f:ea:4c:1f:25:10:c8:2b:b0:
+                    d4:d5:e5:cc:99:ef:38:68:06:25:0c:48:ee:39:6e:
+                    6a:36:36:c9:c4:ed:c7:bf:25:48:65:a9:ee:6e:87:
+                    43:d3:d4:c2:01:81:35:7e:a0:33
+                Exponent: 65537 (0x10001)
+        X509v3 extensions:
+            X509v3 Subject Alternative Name: 
+                DNS:localhost
+            X509v3 Key Usage: critical
+                Digital Signature, Key Encipherment
+            X509v3 Extended Key Usage: 
+                TLS Web Server Authentication, TLS Web Client Authentication
+            X509v3 Basic Constraints: critical
+                CA:FALSE
+            X509v3 Subject Key Identifier: 
+                85:75:10:25:D0:2C:80:50:24:1A:5B:57:70:DE:B5:CB:71:A9:3B:7B
+            X509v3 Authority Key Identifier: 
+                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
+                serial:CB:2D:80:99:5A:69:52:5B
+
+            Authority Information Access: 
+                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
+                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
+
+            X509v3 CRL Distribution Points: 
+
+                Full Name:
+                  URI:http://testca.pythontest.net/testca/revocation.crl
+
+    Signature Algorithm: sha256WithRSAEncryption
+         95:f3:56:bb:d5:8c:70:bd:d1:de:da:63:b0:29:d7:db:60:27:
+         d6:59:fd:61:1b:30:c6:d0:5d:73:7d:34:e1:68:e3:28:a6:89:
+         e6:60:bd:89:d3:0e:f4:72:ad:72:76:f8:86:21:fd:75:3c:f8:
+         6d:be:9c:04:e1:82:03:69:6c:ae:d0:55:ba:5e:f2:ca:f5:0f:
+         8e:d6:d9:8d:c8:56:46:f4:f8:ac:74:2a:19:7b:8e:47:70:1f:
+         fb:fb:bd:69:02:a1:a5:4a:6e:21:1c:04:14:15:55:bf:bf:24:
+         43:c8:17:03:be:3e:2c:ea:db:c8:af:1d:fd:52:df:d6:15:49:
+         9e:c2:44:69:ef:f1:45:43:83:b2:1e:cf:14:1c:13:3f:fe:9c:
+         71:cb:e7:1b:18:56:36:a7:af:44:f1:0b:a1:79:44:46:f9:43:
+         46:29:d8:b0:ca:49:4d:65:60:d3:f6:8e:74:bc:62:9e:1e:8d:
+         4b:29:9a:b4:0d:f0:a2:77:5b:34:e4:11:2f:a7:25:c5:e5:07:
+         76:12:ae:be:75:73:15:e4:0a:7d:53:38:56:3f:79:6d:6e:ca:
+         ed:80:ab:56:ed:7e:8b:1c:e7:e3:d4:62:30:22:70:e7:29:b2:
+         03:3c:fe:fa:3d:f0:36:c0:4d:11:a2:99:d3:29:31:27:b8:c5:
+         b8:15:a3:3c:4f:9b:73:5e:2b:b2:fb:cb:fd:75:47:b8:17:bd:
+         21:d8:e6:c1:b9:ff:73:81:d8:25:08:6d:08:5e:1c:a5:83:50:
+         de:67:e6:da:d0:8e:5a:d3:f2:2a:b1:3f:b8:80:21:07:6a:71:
+         15:6d:05:eb:51:b3:59:8d:d4:15:46:7e:02:a8:13:01:16:99:
+         bd:03:cc:70:71:2a:23:16:78:af:d1:d5:01:9d:04:b4:63:93:
+         9a:04:3a:92:2e:e6:7e:73:93:a5:fe:50:9b:bd:0e:ea:54:86:
+         6f:7c:e5:14:77:fe:c2:28:5a:4a:0e:d7:2d:8c:e9:ed:61:29:
+         b2:53:ff:6c:04:bc
+-----BEGIN CERTIFICATE-----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+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/keycert4.pem b/Lib/test/certdata/keycert4.pem
new file mode 100644
index 0000000000..1003d67fd0
--- /dev/null
+++ b/Lib/test/certdata/keycert4.pem
@@ -0,0 +1,164 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:5d
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=fakehostname
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                RSA Public-Key: (3072 bit)
+                Modulus:
+                    00:b7:e3:2d:d2:ea:25:dd:99:db:dd:33:fd:9a:14:
+                    17:ba:0a:f4:6f:67:08:61:d6:1b:86:97:b2:10:46:
+                    d7:68:6a:43:ea:30:b9:44:74:d1:c9:b4:d7:85:e4:
+                    cd:bb:c4:b7:a2:fa:9e:30:b7:b3:75:27:28:b4:da:
+                    47:87:41:bd:66:f5:3a:87:e4:0a:ee:3a:41:36:b6:
+                    2f:b5:e7:31:28:2a:85:3d:69:6c:9d:4e:21:fe:7a:
+                    92:93:4f:4c:a3:83:63:5c:29:08:d1:51:a5:9c:6e:
+                    1c:c1:1f:81:0c:2a:e0:88:97:32:08:cf:cf:c4:20:
+                    a9:0e:aa:10:83:c2:ae:be:16:fd:c0:ca:cf:b3:ec:
+                    1c:fe:c9:1f:34:8b:18:af:2a:ef:e5:ed:28:f1:43:
+                    bc:fb:47:f9:02:23:b3:95:89:17:08:3b:94:01:40:
+                    f8:fb:54:bb:c2:4f:3e:15:03:ab:bf:2d:d5:e7:80:
+                    ad:87:36:e6:ae:e9:65:e6:e7:23:4d:41:ba:ab:07:
+                    5d:40:10:97:18:65:ff:dc:56:b9:de:57:81:7e:66:
+                    32:e5:a0:02:a0:4a:7f:46:07:c7:96:3b:28:a5:4d:
+                    0d:7c:4d:c2:9d:f8:7d:a2:72:2a:51:68:ff:fe:41:
+                    1f:ca:3f:1e:46:2b:f4:97:53:79:b2:aa:6e:b6:40:
+                    e1:88:ee:df:f9:92:d5:5d:8c:68:6c:ea:d1:d9:c7:
+                    0d:52:46:28:a9:88:b6:16:6e:d5:51:ad:2c:5a:e3:
+                    06:25:82:98:28:53:0b:eb:be:fb:42:e6:40:0d:9d:
+                    3c:35:54:65:ac:c5:cb:3e:e9:ae:fe:3e:87:18:9c:
+                    98:aa:ee:4e:1b:e4:e0:14:6f:74:72:be:5f:43:2c:
+                    03:32:f0:da:a9:45:6a:38:70:70:ff:5d:0d:c5:09:
+                    8c:05:1e:53:92:83:1f:dd:2f:94:9e:d2:2d:dd:5b:
+                    52:b3:6c:fe:8e:bd:a3:60:ea:79:7f:d4:45:cf:52:
+                    c2:75:01:34:bc:9f:3b:f3:85:c7
+                Exponent: 65537 (0x10001)
+        X509v3 extensions:
+            X509v3 Subject Alternative Name: 
+                DNS:fakehostname
+            X509v3 Key Usage: critical
+                Digital Signature, Key Encipherment
+            X509v3 Extended Key Usage: 
+                TLS Web Server Authentication, TLS Web Client Authentication
+            X509v3 Basic Constraints: critical
+                CA:FALSE
+            X509v3 Subject Key Identifier: 
+                C8:BD:A8:B4:C0:F2:32:10:73:47:9C:48:81:32:F8:BA:BB:26:84:97
+            X509v3 Authority Key Identifier: 
+                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
+                serial:CB:2D:80:99:5A:69:52:5B
+
+            Authority Information Access: 
+                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
+                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
+
+            X509v3 CRL Distribution Points: 
+
+                Full Name:
+                  URI:http://testca.pythontest.net/testca/revocation.crl
+
+    Signature Algorithm: sha256WithRSAEncryption
+         76:87:76:4d:e4:0f:88:bf:2c:f3:58:67:c0:97:6c:cd:59:18:
+         82:83:4c:04:19:a5:6d:aa:fa:64:3d:49:32:3e:e1:56:95:b2:
+         13:f7:cf:d3:11:b0:72:b7:5b:e7:d7:85:69:51:3c:b6:54:80:
+         45:2f:28:10:21:20:b9:ba:e9:27:5a:b7:3f:82:b7:69:f5:46:
+         f5:bf:a2:8b:17:7f:f2:14:d1:46:97:b5:8b:47:fb:9f:e8:5c:
+         05:0e:9d:11:bd:7c:9a:03:84:0b:ca:29:66:4a:ca:0d:6f:09:
+         1e:7a:27:c1:7f:03:96:70:8d:18:a5:2f:a4:98:a5:19:aa:8c:
+         5d:1e:8c:3e:bb:6d:3b:c0:33:c0:15:e1:bd:09:3d:9f:e8:dc:
+         12:d4:cb:44:1d:06:f5:e8:d6:4e:a1:2d:5c:9f:5d:1f:5b:2a:
+         c3:4d:40:8d:da:d1:78:80:d0:c6:31:72:10:48:8a:e9:10:7a:
+         13:30:11:b2:9e:67:0e:ed:a1:aa:ec:73:2d:f0:b8:8a:22:75:
+         0f:30:69:5c:50:7e:91:ce:da:91:c7:70:8c:65:ff:f6:58:fb:
+         00:bd:45:cc:e2:e4:e3:e5:16:36:7d:f3:a2:4a:9c:45:ff:d9:
+         a5:16:e0:2f:b5:5b:6c:e6:8a:13:15:48:73:bd:7c:80:33:c3:
+         d4:3b:3a:1d:85:0e:a4:f7:f7:fb:48:0c:e9:a0:4b:5e:8a:5c:
+         67:f8:25:02:6f:cd:72:c1:aa:5a:93:64:7c:14:20:43:e0:13:
+         7f:0d:e1:0d:61:5e:2e:2c:cd:7a:2e:2a:ae:b6:75:6a:5f:a0:
+         1a:9b:b6:67:2d:b0:a5:1c:54:bc:8c:70:7e:15:2b:c0:50:e3:
+         03:bb:a4:a5:fc:45:01:c9:3f:a7:b8:18:dc:3e:08:07:a1:9b:
+         f5:bd:95:bd:49:e8:10:7c:91:7d:2d:c4:c2:98:b6:b7:51:69:
+         d7:0a:68:40:b5:0f:85:a0:a9:67:77:c6:68:cb:0e:58:34:b3:
+         58:e7:c8:7c:09:67
+-----BEGIN CERTIFICATE-----
+MIIF9zCCBF+gAwIBAgIJAMstgJlaaVJdMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
+BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
+MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
+NDIzMTZaMGIxCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
+MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xFTATBgNVBAMMDGZh
+a2Vob3N0bmFtZTCCAaIwDQYJKoZIhvcNAQEBBQADggGPADCCAYoCggGBALfjLdLq
+Jd2Z290z/ZoUF7oK9G9nCGHWG4aXshBG12hqQ+owuUR00cm014XkzbvEt6L6njC3
+s3UnKLTaR4dBvWb1OofkCu46QTa2L7XnMSgqhT1pbJ1OIf56kpNPTKODY1wpCNFR
+pZxuHMEfgQwq4IiXMgjPz8QgqQ6qEIPCrr4W/cDKz7PsHP7JHzSLGK8q7+XtKPFD
+vPtH+QIjs5WJFwg7lAFA+PtUu8JPPhUDq78t1eeArYc25q7pZebnI01BuqsHXUAQ
+lxhl/9xWud5XgX5mMuWgAqBKf0YHx5Y7KKVNDXxNwp34faJyKlFo//5BH8o/HkYr
+9JdTebKqbrZA4Yju3/mS1V2MaGzq0dnHDVJGKKmIthZu1VGtLFrjBiWCmChTC+u+
++0LmQA2dPDVUZazFyz7prv4+hxicmKruThvk4BRvdHK+X0MsAzLw2qlFajhwcP9d
+DcUJjAUeU5KDH90vlJ7SLd1bUrNs/o69o2DqeX/URc9SwnUBNLyfO/OFxwIDAQAB
+o4IBwzCCAb8wFwYDVR0RBBAwDoIMZmFrZWhvc3RuYW1lMA4GA1UdDwEB/wQEAwIF
+oDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/BAIwADAd
+BgNVHQ4EFgQUyL2otMDyMhBzR5xIgTL4ursmhJcwfQYDVR0jBHYwdIAUs4qgorpx
+8agkedSkWyU2FR5JyM2hUaRPME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRo
+b24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZl
+coIJAMstgJlaaVJbMIGDBggrBgEFBQcBAQR3MHUwPAYIKwYBBQUHMAKGMGh0dHA6
+Ly90ZXN0Y2EucHl0aG9udGVzdC5uZXQvdGVzdGNhL3B5Y2FjZXJ0LmNlcjA1Bggr
+BgEFBQcwAYYpaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2Evb2Nz
+cC8wQwYDVR0fBDwwOjA4oDagNIYyaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5l
+dC90ZXN0Y2EvcmV2b2NhdGlvbi5jcmwwDQYJKoZIhvcNAQELBQADggGBAHaHdk3k
+D4i/LPNYZ8CXbM1ZGIKDTAQZpW2q+mQ9STI+4VaVshP3z9MRsHK3W+fXhWlRPLZU
+gEUvKBAhILm66Sdatz+Ct2n1RvW/oosXf/IU0UaXtYtH+5/oXAUOnRG9fJoDhAvK
+KWZKyg1vCR56J8F/A5ZwjRilL6SYpRmqjF0ejD67bTvAM8AV4b0JPZ/o3BLUy0Qd
+BvXo1k6hLVyfXR9bKsNNQI3a0XiA0MYxchBIiukQehMwEbKeZw7toarscy3wuIoi
+dQ8waVxQfpHO2pHHcIxl//ZY+wC9Rczi5OPlFjZ986JKnEX/2aUW4C+1W2zmihMV
+SHO9fIAzw9Q7Oh2FDqT39/tIDOmgS16KXGf4JQJvzXLBqlqTZHwUIEPgE38N4Q1h
+Xi4szXouKq62dWpfoBqbtmctsKUcVLyMcH4VK8BQ4wO7pKX8RQHJP6e4GNw+CAeh
+m/W9lb1J6BB8kX0txMKYtrdRadcKaEC1D4WgqWd3xmjLDlg0s1jnyHwJZw==
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/keycertecc.pem b/Lib/test/certdata/keycertecc.pem
new file mode 100644
index 0000000000..81daa4ccb9
--- /dev/null
+++ b/Lib/test/certdata/keycertecc.pem
@@ -0,0 +1,106 @@
+-----BEGIN PRIVATE KEY-----
+MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDBcNwE+cm17mmr7Yg6d
+0DNCnheGFOjkYH4tYzTyCkcZGShkmF/tKhIqb3imKz0Kx9+hZANiAATyp8ws6CuN
+OI2/3MC4jZVSkmoDzm/X/ZrkEm4TVHKPSZ6kzZRpmmUlLS9l7SQZSLYyDAFBFzoG
+JJYHhZNQXEO7HFszn6KnvLjhwS6ddzlaHPziEknrSr0OKhJmdJHrQAQ=
+-----END PRIVATE KEY-----
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:5e
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=localhost-ecc
+        Subject Public Key Info:
+            Public Key Algorithm: id-ecPublicKey
+                Public-Key: (384 bit)
+                pub:
+                    04:f2:a7:cc:2c:e8:2b:8d:38:8d:bf:dc:c0:b8:8d:
+                    95:52:92:6a:03:ce:6f:d7:fd:9a:e4:12:6e:13:54:
+                    72:8f:49:9e:a4:cd:94:69:9a:65:25:2d:2f:65:ed:
+                    24:19:48:b6:32:0c:01:41:17:3a:06:24:96:07:85:
+                    93:50:5c:43:bb:1c:5b:33:9f:a2:a7:bc:b8:e1:c1:
+                    2e:9d:77:39:5a:1c:fc:e2:12:49:eb:4a:bd:0e:2a:
+                    12:66:74:91:eb:40:04
+                ASN1 OID: secp384r1
+                NIST CURVE: P-384
+        X509v3 extensions:
+            X509v3 Subject Alternative Name: 
+                DNS:localhost-ecc
+            X509v3 Key Usage: critical
+                Digital Signature, Key Encipherment
+            X509v3 Extended Key Usage: 
+                TLS Web Server Authentication, TLS Web Client Authentication
+            X509v3 Basic Constraints: critical
+                CA:FALSE
+            X509v3 Subject Key Identifier: 
+                79:11:98:86:15:4F:48:F4:31:0B:D2:CC:C8:26:3A:09:07:5D:96:40
+            X509v3 Authority Key Identifier: 
+                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
+                serial:CB:2D:80:99:5A:69:52:5B
+
+            Authority Information Access: 
+                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
+                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
+
+            X509v3 CRL Distribution Points: 
+
+                Full Name:
+                  URI:http://testca.pythontest.net/testca/revocation.crl
+
+    Signature Algorithm: sha256WithRSAEncryption
+         6e:42:e8:a2:2d:28:14:e3:25:5c:c1:7e:54:e9:3a:ff:30:db:
+         94:ba:b2:f6:5f:ae:9a:c1:90:b3:4f:ce:65:1d:84:64:c0:71:
+         2c:44:8e:7e:00:79:f5:8c:4a:1d:34:13:44:de:99:2e:db:53:
+         ee:ec:74:97:4d:59:1a:09:82:4f:98:75:91:a7:a0:b9:da:5e:
+         68:f5:32:85:be:36:3d:83:d4:ee:f9:87:67:31:85:41:53:9a:
+         e7:05:96:13:1c:88:2e:7f:33:b1:ee:bd:f9:50:52:24:ed:3d:
+         92:95:6e:30:c3:af:74:a9:ee:15:bb:da:7c:14:50:8e:e3:99:
+         ea:ba:b4:37:8a:50:61:26:de:01:93:b8:a2:6b:d9:c7:38:5e:
+         b2:f8:96:3d:a8:9f:7d:0c:71:d4:7e:cc:a0:57:af:7e:ce:3f:
+         a7:a7:27:68:c1:28:d7:4f:44:c1:b4:93:c3:c7:35:2b:50:c3:
+         8e:2c:d0:46:c1:3f:e1:67:d3:f0:81:ae:f3:5c:3e:4f:d5:a8:
+         07:8f:e0:eb:ef:d8:dc:47:e0:3d:58:eb:de:0e:7f:b2:58:cb:
+         5c:f1:2f:65:7e:0f:0d:cc:ca:ba:83:53:63:bc:dd:18:0c:ee:
+         ed:ec:96:88:d0:38:c5:d7:ab:e7:55:79:7b:6d:ba:c0:a0:e9:
+         5c:ca:7c:fb:f8:70:c7:fb:f5:b2:b5:74:cb:f7:c0:0d:20:9f:
+         1d:b7:4c:bf:8a:8d:cd:e3:bc:4e:30:78:02:12:a0:9b:d5:8f:
+         49:3c:95:91:76:6e:7c:54:dc:61:7a:2e:20:ed:35:25:e0:c5:
+         17:50:02:83:00:74:8f:f0:1c:97:96:08:fc:2e:63:a4:f7:97:
+         87:43:2a:32:04:2d:4c:f9:1a:07:bf:68:91:fc:50:21:a1:3c:
+         8d:8f:fb:83:57:83:1f:b6:55:5c:55:2f:58:64:ad:f3:27:ba:
+         d0:e3:cd:58:01:a3:c9:ba:1d:95:dc:30:d5:af:b9:20:ad:d9:
+         48:ba:8d:9a:66:ee
+-----BEGIN CERTIFICATE-----
+MIIEyzCCAzOgAwIBAgIJAMstgJlaaVJeMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
+BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
+MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
+NDIzMTZaMGMxCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
+MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xFjAUBgNVBAMMDWxv
+Y2FsaG9zdC1lY2MwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAATyp8ws6CuNOI2/3MC4
+jZVSkmoDzm/X/ZrkEm4TVHKPSZ6kzZRpmmUlLS9l7SQZSLYyDAFBFzoGJJYHhZNQ
+XEO7HFszn6KnvLjhwS6ddzlaHPziEknrSr0OKhJmdJHrQASjggHEMIIBwDAYBgNV
+HREEETAPgg1sb2NhbGhvc3QtZWNjMA4GA1UdDwEB/wQEAwIFoDAdBgNVHSUEFjAU
+BggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUeRGY
+hhVPSPQxC9LMyCY6CQddlkAwfQYDVR0jBHYwdIAUs4qgorpx8agkedSkWyU2FR5J
+yM2hUaRPME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
+Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcoIJAMstgJlaaVJb
+MIGDBggrBgEFBQcBAQR3MHUwPAYIKwYBBQUHMAKGMGh0dHA6Ly90ZXN0Y2EucHl0
+aG9udGVzdC5uZXQvdGVzdGNhL3B5Y2FjZXJ0LmNlcjA1BggrBgEFBQcwAYYpaHR0
+cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2Evb2NzcC8wQwYDVR0fBDww
+OjA4oDagNIYyaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2EvcmV2
+b2NhdGlvbi5jcmwwDQYJKoZIhvcNAQELBQADggGBAG5C6KItKBTjJVzBflTpOv8w
+25S6svZfrprBkLNPzmUdhGTAcSxEjn4AefWMSh00E0TemS7bU+7sdJdNWRoJgk+Y
+dZGnoLnaXmj1MoW+Nj2D1O75h2cxhUFTmucFlhMciC5/M7HuvflQUiTtPZKVbjDD
+r3Sp7hW72nwUUI7jmeq6tDeKUGEm3gGTuKJr2cc4XrL4lj2on30McdR+zKBXr37O
+P6enJ2jBKNdPRMG0k8PHNStQw44s0EbBP+Fn0/CBrvNcPk/VqAeP4Ovv2NxH4D1Y
+694Of7JYy1zxL2V+Dw3MyrqDU2O83RgM7u3slojQOMXXq+dVeXttusCg6VzKfPv4
+cMf79bK1dMv3wA0gnx23TL+Kjc3jvE4weAISoJvVj0k8lZF2bnxU3GF6LiDtNSXg
+xRdQAoMAdI/wHJeWCPwuY6T3l4dDKjIELUz5Gge/aJH8UCGhPI2P+4NXgx+2VVxV
+L1hkrfMnutDjzVgBo8m6HZXcMNWvuSCt2Ui6jZpm7g==
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/make_ssl_certs.py b/Lib/test/certdata/make_ssl_certs.py
new file mode 100644
index 0000000000..94a35a64ab
--- /dev/null
+++ b/Lib/test/certdata/make_ssl_certs.py
@@ -0,0 +1,312 @@
+"""Make the custom certificate and private key files used by test_ssl
+and friends."""
+
+import os
+import pprint
+import shutil
+import tempfile
+from subprocess import *
+
+startdate = "20180829142316Z"
+enddate = "20371028142316Z"
+
+req_template = """
+    [ default ]
+    base_url               = http://testca.pythontest.net/testca
+
+    [req]
+    distinguished_name     = req_distinguished_name
+    prompt                 = no
+
+    [req_distinguished_name]
+    C                      = XY
+    L                      = Castle Anthrax
+    O                      = Python Software Foundation
+    CN                     = {hostname}
+
+    [req_x509_extensions_nosan]
+
+    [req_x509_extensions_simple]
+    subjectAltName         = @san
+
+    [req_x509_extensions_full]
+    subjectAltName         = @san
+    keyUsage               = critical,keyEncipherment,digitalSignature
+    extendedKeyUsage       = serverAuth,clientAuth
+    basicConstraints       = critical,CA:false
+    subjectKeyIdentifier   = hash
+    authorityKeyIdentifier = keyid:always,issuer:always
+    authorityInfoAccess    = @issuer_ocsp_info
+    crlDistributionPoints  = @crl_info
+
+    [ issuer_ocsp_info ]
+    caIssuers;URI.0        = $base_url/pycacert.cer
+    OCSP;URI.0             = $base_url/ocsp/
+
+    [ crl_info ]
+    URI.0                  = $base_url/revocation.crl
+
+    [san]
+    DNS.1 = {hostname}
+    {extra_san}
+
+    [dir_sect]
+    C                      = XY
+    L                      = Castle Anthrax
+    O                      = Python Software Foundation
+    CN                     = dirname example
+
+    [princ_name]
+    realm = EXP:0, GeneralString:KERBEROS.REALM
+    principal_name = EXP:1, SEQUENCE:principal_seq
+
+    [principal_seq]
+    name_type = EXP:0, INTEGER:1
+    name_string = EXP:1, SEQUENCE:principals
+
+    [principals]
+    princ1 = GeneralString:username
+
+    [ ca ]
+    default_ca      = CA_default
+
+    [ CA_default ]
+    dir = cadir
+    database  = $dir/index.txt
+    crlnumber = $dir/crl.txt
+    default_md = sha256
+    startdate = {startdate}
+    default_startdate = {startdate}
+    enddate = {enddate}
+    default_enddate = {enddate}
+    default_days = 7000
+    default_crl_days = 7000
+    certificate = pycacert.pem
+    private_key = pycakey.pem
+    serial    = $dir/serial
+    RANDFILE  = $dir/.rand
+    policy          = policy_match
+
+    [ policy_match ]
+    countryName             = match
+    stateOrProvinceName     = optional
+    organizationName        = match
+    organizationalUnitName  = optional
+    commonName              = supplied
+    emailAddress            = optional
+
+    [ policy_anything ]
+    countryName   = optional
+    stateOrProvinceName = optional
+    localityName    = optional
+    organizationName  = optional
+    organizationalUnitName  = optional
+    commonName    = supplied
+    emailAddress    = optional
+
+
+    [ v3_ca ]
+
+    subjectKeyIdentifier=hash
+    authorityKeyIdentifier=keyid:always,issuer
+    basicConstraints = CA:true
+
+    """
+
+here = os.path.abspath(os.path.dirname(__file__))
+
+
+def make_cert_key(hostname, sign=False, extra_san='',
+                  ext='req_x509_extensions_full', key='rsa:3072'):
+    print("creating cert for " + hostname)
+    tempnames = []
+    for i in range(3):
+        with tempfile.NamedTemporaryFile(delete=False) as f:
+            tempnames.append(f.name)
+    req_file, cert_file, key_file = tempnames
+    try:
+        req = req_template.format(
+            hostname=hostname,
+            extra_san=extra_san,
+            startdate=startdate,
+            enddate=enddate
+        )
+        with open(req_file, 'w') as f:
+            f.write(req)
+        args = ['req', '-new', '-nodes', '-days', '7000',
+                '-newkey', key, '-keyout', key_file,
+                '-extensions', ext,
+                '-config', req_file]
+        if sign:
+            with tempfile.NamedTemporaryFile(delete=False) as f:
+                tempnames.append(f.name)
+                reqfile = f.name
+            args += ['-out', reqfile ]
+
+        else:
+            args += ['-x509', '-out', cert_file ]
+        check_call(['openssl'] + args)
+
+        if sign:
+            args = [
+                'ca',
+                '-config', req_file,
+                '-extensions', ext,
+                '-out', cert_file,
+                '-outdir', 'cadir',
+                '-policy', 'policy_anything',
+                '-batch', '-infiles', reqfile
+            ]
+            check_call(['openssl'] + args)
+
+
+        with open(cert_file, 'r') as f:
+            cert = f.read()
+        with open(key_file, 'r') as f:
+            key = f.read()
+        return cert, key
+    finally:
+        for name in tempnames:
+            os.remove(name)
+
+TMP_CADIR = 'cadir'
+
+def unmake_ca():
+    shutil.rmtree(TMP_CADIR)
+
+def make_ca():
+    os.mkdir(TMP_CADIR)
+    with open(os.path.join('cadir','index.txt'),'a+') as f:
+        pass # empty file
+    with open(os.path.join('cadir','crl.txt'),'a+') as f:
+        f.write("00")
+    with open(os.path.join('cadir','index.txt.attr'),'w+') as f:
+        f.write('unique_subject = no')
+    # random start value for serial numbers
+    with open(os.path.join('cadir','serial'), 'w') as f:
+        f.write('CB2D80995A69525B\n')
+
+    with tempfile.NamedTemporaryFile("w") as t:
+        req = req_template.format(
+            hostname='our-ca-server',
+            extra_san='',
+            startdate=startdate,
+            enddate=enddate
+        )
+        t.write(req)
+        t.flush()
+        with tempfile.NamedTemporaryFile() as f:
+            args = ['req', '-config', t.name, '-new',
+                    '-nodes',
+                    '-newkey', 'rsa:3072',
+                    '-keyout', 'pycakey.pem',
+                    '-out', f.name,
+                    '-subj', '/C=XY/L=Castle Anthrax/O=Python Software Foundation CA/CN=our-ca-server']
+            check_call(['openssl'] + args)
+            args = ['ca', '-config', t.name,
+                    '-out', 'pycacert.pem', '-batch', '-outdir', TMP_CADIR,
+                    '-keyfile', 'pycakey.pem',
+                    '-selfsign', '-extensions', 'v3_ca', '-infiles', f.name ]
+            check_call(['openssl'] + args)
+            args = ['ca', '-config', t.name, '-gencrl', '-out', 'revocation.crl']
+            check_call(['openssl'] + args)
+
+    # capath hashes depend on subject!
+    check_call([
+        'openssl', 'x509', '-in', 'pycacert.pem', '-out', 'capath/ceff1710.0'
+    ])
+    shutil.copy('capath/ceff1710.0', 'capath/b1930218.0')
+
+
+def print_cert(path):
+    import _ssl
+    pprint.pprint(_ssl._test_decode_cert(path))
+
+
+if __name__ == '__main__':
+    os.chdir(here)
+    cert, key = make_cert_key('localhost', ext='req_x509_extensions_simple')
+    with open('ssl_cert.pem', 'w') as f:
+        f.write(cert)
+    with open('ssl_key.pem', 'w') as f:
+        f.write(key)
+    print("password protecting ssl_key.pem in ssl_key.passwd.pem")
+    check_call(['openssl','pkey','-in','ssl_key.pem','-out','ssl_key.passwd.pem','-aes256','-passout','pass:somepass'])
+    check_call(['openssl','pkey','-in','ssl_key.pem','-out','keycert.passwd.pem','-aes256','-passout','pass:somepass'])
+
+    with open('keycert.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    with open('keycert.passwd.pem', 'a+') as f:
+        f.write(cert)
+
+    # For certificate matching tests
+    make_ca()
+    cert, key = make_cert_key('fakehostname', ext='req_x509_extensions_simple')
+    with open('keycert2.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    cert, key = make_cert_key('localhost', sign=True)
+    with open('keycert3.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    cert, key = make_cert_key('fakehostname', sign=True)
+    with open('keycert4.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    cert, key = make_cert_key(
+        'localhost-ecc', sign=True, key='param:secp384r1.pem'
+    )
+    with open('keycertecc.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    extra_san = [
+        'otherName.1 = 1.2.3.4;UTF8:some other identifier',
+        'otherName.2 = 1.3.6.1.5.2.2;SEQUENCE:princ_name',
+        'email.1 = user@example.org',
+        'DNS.2 = www.example.org',
+        # GEN_X400
+        'dirName.1 = dir_sect',
+        # GEN_EDIPARTY
+        'URI.1 = https://www.python.org/',
+        'IP.1 = 127.0.0.1',
+        'IP.2 = ::1',
+        'RID.1 = 1.2.3.4.5',
+    ]
+
+    cert, key = make_cert_key('allsans', sign=True, extra_san='\n'.join(extra_san))
+    with open('allsans.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    extra_san = [
+        # könig (king)
+        'DNS.2 = xn--knig-5qa.idn.pythontest.net',
+        # königsgäßchen (king's alleyway)
+        'DNS.3 = xn--knigsgsschen-lcb0w.idna2003.pythontest.net',
+        'DNS.4 = xn--knigsgchen-b4a3dun.idna2008.pythontest.net',
+        # βόλοσ (marble)
+        'DNS.5 = xn--nxasmq6b.idna2003.pythontest.net',
+        'DNS.6 = xn--nxasmm1c.idna2008.pythontest.net',
+    ]
+
+    # IDN SANS, signed
+    cert, key = make_cert_key('idnsans', sign=True, extra_san='\n'.join(extra_san))
+    with open('idnsans.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    cert, key = make_cert_key('nosan', sign=True, ext='req_x509_extensions_nosan')
+    with open('nosan.pem', 'w') as f:
+        f.write(key)
+        f.write(cert)
+
+    unmake_ca()
+    print("update Lib/test/test_ssl.py and Lib/test/test_asyncio/utils.py")
+    print_cert('keycert.pem')
+    print_cert('keycert3.pem')
diff --git a/Lib/test/certdata/nokia.pem b/Lib/test/certdata/nokia.pem
new file mode 100644
index 0000000000..0d044df436
--- /dev/null
+++ b/Lib/test/certdata/nokia.pem
@@ -0,0 +1,31 @@
+# Certificate for projects.developer.nokia.com:443 (see issue 13034)
+-----BEGIN CERTIFICATE-----
+MIIFLDCCBBSgAwIBAgIQLubqdkCgdc7lAF9NfHlUmjANBgkqhkiG9w0BAQUFADCB
+vDELMAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQL
+ExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTswOQYDVQQLEzJUZXJtcyBvZiB1c2Ug
+YXQgaHR0cHM6Ly93d3cudmVyaXNpZ24uY29tL3JwYSAoYykxMDE2MDQGA1UEAxMt
+VmVyaVNpZ24gQ2xhc3MgMyBJbnRlcm5hdGlvbmFsIFNlcnZlciBDQSAtIEczMB4X
+DTExMDkyMTAwMDAwMFoXDTEyMDkyMDIzNTk1OVowcTELMAkGA1UEBhMCRkkxDjAM
+BgNVBAgTBUVzcG9vMQ4wDAYDVQQHFAVFc3BvbzEOMAwGA1UEChQFTm9raWExCzAJ
+BgNVBAsUAkJJMSUwIwYDVQQDFBxwcm9qZWN0cy5kZXZlbG9wZXIubm9raWEuY29t
+MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCr92w1bpHYSYxUEx8N/8Iddda2
+lYi+aXNtQfV/l2Fw9Ykv3Ipw4nLeGTj18FFlAZgMdPRlgrzF/NNXGw/9l3/qKdow
+CypkQf8lLaxb9Ze1E/KKmkRJa48QTOqvo6GqKuTI6HCeGlG1RxDb8YSKcQWLiytn
+yj3Wp4MgRQO266xmMQIDAQABo4IB9jCCAfIwQQYDVR0RBDowOIIccHJvamVjdHMu
+ZGV2ZWxvcGVyLm5va2lhLmNvbYIYcHJvamVjdHMuZm9ydW0ubm9raWEuY29tMAkG
+A1UdEwQCMAAwCwYDVR0PBAQDAgWgMEEGA1UdHwQ6MDgwNqA0oDKGMGh0dHA6Ly9T
+VlJJbnRsLUczLWNybC52ZXJpc2lnbi5jb20vU1ZSSW50bEczLmNybDBEBgNVHSAE
+PTA7MDkGC2CGSAGG+EUBBxcDMCowKAYIKwYBBQUHAgEWHGh0dHBzOi8vd3d3LnZl
+cmlzaWduLmNvbS9ycGEwKAYDVR0lBCEwHwYJYIZIAYb4QgQBBggrBgEFBQcDAQYI
+KwYBBQUHAwIwcgYIKwYBBQUHAQEEZjBkMCQGCCsGAQUFBzABhhhodHRwOi8vb2Nz
+cC52ZXJpc2lnbi5jb20wPAYIKwYBBQUHMAKGMGh0dHA6Ly9TVlJJbnRsLUczLWFp
+YS52ZXJpc2lnbi5jb20vU1ZSSW50bEczLmNlcjBuBggrBgEFBQcBDARiMGChXqBc
+MFowWDBWFglpbWFnZS9naWYwITAfMAcGBSsOAwIaBBRLa7kolgYMu9BSOJsprEsH
+iyEFGDAmFiRodHRwOi8vbG9nby52ZXJpc2lnbi5jb20vdnNsb2dvMS5naWYwDQYJ
+KoZIhvcNAQEFBQADggEBACQuPyIJqXwUyFRWw9x5yDXgMW4zYFopQYOw/ItRY522
+O5BsySTh56BWS6mQB07XVfxmYUGAvRQDA5QHpmY8jIlNwSmN3s8RKo+fAtiNRlcL
+x/mWSfuMs3D/S6ev3D6+dpEMZtjrhOdctsarMKp8n/hPbwhAbg5hVjpkW5n8vz2y
+0KxvvkA1AxpLwpVv7OlK17ttzIHw8bp9HTlHBU5s8bKz4a565V/a5HI0CSEv/+0y
+ko4/ghTnZc1CkmUngKKeFMSah/mT/xAh8XnE2l1AazFa8UKuYki1e+ArHaGZc4ix
+UYOtiRphwfuYQhRZ7qX9q2MMkCMI65XNK/SaFrAbbG0=
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/nosan.pem b/Lib/test/certdata/nosan.pem
new file mode 100644
index 0000000000..ec10cdcabb
--- /dev/null
+++ b/Lib/test/certdata/nosan.pem
@@ -0,0 +1,130 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
+Certificate:
+    Data:
+        Version: 1 (0x0)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:61
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=nosan
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                RSA Public-Key: (3072 bit)
+                Modulus:
+                    00:af:de:c5:28:38:4e:05:ec:fc:9e:01:3d:90:e9:
+                    7a:57:ac:65:0e:bb:57:d8:81:d9:c8:b4:b2:cb:86:
+                    f9:fb:00:2b:87:32:3e:d3:03:95:0a:5f:1b:1e:a4:
+                    99:f9:9b:62:62:f4:bb:c0:6e:4b:2b:d4:85:9d:2d:
+                    90:2f:36:08:f0:b1:44:7e:13:81:db:63:5d:3c:06:
+                    15:6d:f6:c9:37:1c:59:2f:13:43:8e:15:b0:1a:d7:
+                    82:02:b5:83:de:d7:c3:ff:e0:7b:fa:65:fb:bf:18:
+                    90:d4:af:05:c7:34:25:2e:d2:9e:a2:fe:6a:2c:a5:
+                    9e:4e:de:cc:79:32:05:5a:4a:19:27:18:01:02:dc:
+                    aa:7b:cc:e8:2e:b0:c9:84:f1:74:9b:90:d4:1a:dc:
+                    04:4c:91:6e:28:91:3a:96:28:07:80:1c:38:d5:15:
+                    5c:b2:87:36:50:9a:8f:a0:68:bc:e1:59:f2:55:49:
+                    98:65:26:cb:a2:2e:86:46:1a:b5:53:ab:ce:44:89:
+                    7b:04:e2:5f:2b:3d:a2:3e:98:a9:15:cd:63:f5:dc:
+                    86:56:f8:5c:75:b6:22:24:b6:e9:9d:1d:66:f5:39:
+                    05:ab:be:6f:00:89:3f:5b:f0:f7:05:09:45:2b:be:
+                    14:05:70:b0:d2:09:98:ca:95:0d:2d:45:6a:d2:48:
+                    aa:eb:56:c4:a5:74:ea:de:a9:12:ed:a6:31:b3:14:
+                    9a:46:9d:37:2f:b2:52:fb:ac:fe:69:83:90:e3:06:
+                    c6:26:55:c0:e3:ae:64:6e:26:e8:46:ab:9d:97:ff:
+                    a1:c4:0b:de:c6:a2:e5:4a:f2:d4:f5:2d:53:2f:d7:
+                    0b:9f:54:f9:fe:8b:d4:f3:c3:13:ae:45:67:94:bd:
+                    5a:8b:00:98:16:43:d3:77:c8:a7:72:98:7f:95:ae:
+                    96:64:fe:80:7d:49:cc:83:6a:41:9e:cd:90:56:e4:
+                    27:8e:41:b3:49:f1:6a:17:e7:c8:cd:c5:e7:c6:8e:
+                    da:8a:c6:6c:b3:b6:ee:37:af:71
+                Exponent: 65537 (0x10001)
+    Signature Algorithm: sha256WithRSAEncryption
+         91:42:c2:15:57:42:47:77:e7:0f:c5:55:26:b1:5b:c3:5e:ba:
+         81:db:e1:a4:9f:b8:42:5a:21:c9:8c:18:ae:0f:90:ab:9a:24:
+         e7:d2:78:fc:bd:97:29:b1:5c:46:1f:5b:b8:d2:a7:87:f1:50:
+         53:5b:d3:be:57:74:bd:e5:75:db:50:81:f7:37:95:0b:69:ef:
+         39:8c:5c:82:d5:64:62:d5:8b:e9:e0:31:e1:73:d2:5a:2c:de:
+         43:5a:06:e5:d3:4d:d0:35:e0:9f:c2:73:31:bc:35:69:d4:fb:
+         7d:f0:1a:33:f7:f6:25:72:9c:a6:84:05:08:f6:b5:e8:04:10:
+         f1:1f:f2:95:ad:a1:f8:d8:80:a5:eb:75:43:99:33:90:0c:79:
+         fc:c0:87:08:95:20:aa:c2:81:0b:22:6f:56:f4:8f:2a:23:f8:
+         40:47:1c:03:a5:b1:04:0a:04:4a:df:d0:88:a8:bc:31:f2:42:
+         9b:d8:11:14:9e:e3:68:ea:07:2c:15:de:d2:36:5a:15:38:ed:
+         d2:af:0e:b4:b6:1d:a0:57:94:ea:c3:c7:4c:14:57:81:00:57:
+         94:d3:b0:27:69:d7:48:02:6c:e5:97:f7:be:22:7c:38:24:af:
+         b2:b0:7b:08:75:1e:ca:2e:c7:41:ef:8b:74:cf:c9:c3:6f:39:
+         b9:52:41:18:c6:70:24:54:51:04:fe:5f:88:70:35:e5:1c:8e:
+         d6:67:69:44:44:33:9b:8c:fe:a5:b9:95:48:66:84:f3:1a:04:
+         ab:a3:57:c1:b6:b4:2f:28:12:45:2b:cb:42:d3:f4:a5:ce:7b:
+         6c:1f:e4:c8:a9:e7:d4:6d:c8:27:2d:69:26:c5:e8:73:10:54:
+         1f:c3:bf:fd:aa:f5:95:6f:f6:ca:d5:06:8f:1b:79:93:e3:86:
+         ba:8d:fe:a8:10:8f:95:3e:14:09:bf:ca:88:59:e2:93:b6:ec:
+         03:a9:7e:dd:1f:5f:13:d3:29:b3:a6:f3:6a:df:30:53:44:c8:
+         cd:e5:82:57:bc:9c
+-----BEGIN CERTIFICATE-----
+MIIEJDCCAowCCQDLLYCZWmlSYTANBgkqhkiG9w0BAQsFADBNMQswCQYDVQQGEwJY
+WTEmMCQGA1UECgwdUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24gQ0ExFjAUBgNV
+BAMMDW91ci1jYS1zZXJ2ZXIwHhcNMTgwODI5MTQyMzE2WhcNMzcxMDI4MTQyMzE2
+WjBbMQswCQYDVQQGEwJYWTEXMBUGA1UEBwwOQ2FzdGxlIEFudGhyYXgxIzAhBgNV
+BAoMGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMQ4wDAYDVQQDDAVub3NhbjCC
+AaIwDQYJKoZIhvcNAQEBBQADggGPADCCAYoCggGBAK/exSg4TgXs/J4BPZDpeles
+ZQ67V9iB2ci0ssuG+fsAK4cyPtMDlQpfGx6kmfmbYmL0u8BuSyvUhZ0tkC82CPCx
+RH4TgdtjXTwGFW32yTccWS8TQ44VsBrXggK1g97Xw//ge/pl+78YkNSvBcc0JS7S
+nqL+aiylnk7ezHkyBVpKGScYAQLcqnvM6C6wyYTxdJuQ1BrcBEyRbiiROpYoB4Ac
+ONUVXLKHNlCaj6BovOFZ8lVJmGUmy6IuhkYatVOrzkSJewTiXys9oj6YqRXNY/Xc
+hlb4XHW2IiS26Z0dZvU5Bau+bwCJP1vw9wUJRSu+FAVwsNIJmMqVDS1FatJIqutW
+xKV06t6pEu2mMbMUmkadNy+yUvus/mmDkOMGxiZVwOOuZG4m6EarnZf/ocQL3sai
+5Ury1PUtUy/XC59U+f6L1PPDE65FZ5S9WosAmBZD03fIp3KYf5WulmT+gH1JzINq
+QZ7NkFbkJ45Bs0nxahfnyM3F58aO2orGbLO27jevcQIDAQABMA0GCSqGSIb3DQEB
+CwUAA4IBgQCRQsIVV0JHd+cPxVUmsVvDXrqB2+Gkn7hCWiHJjBiuD5CrmiTn0nj8
+vZcpsVxGH1u40qeH8VBTW9O+V3S95XXbUIH3N5ULae85jFyC1WRi1Yvp4DHhc9Ja
+LN5DWgbl003QNeCfwnMxvDVp1Pt98Boz9/YlcpymhAUI9rXoBBDxH/KVraH42ICl
+63VDmTOQDHn8wIcIlSCqwoELIm9W9I8qI/hARxwDpbEECgRK39CIqLwx8kKb2BEU
+nuNo6gcsFd7SNloVOO3Srw60th2gV5Tqw8dMFFeBAFeU07AnaddIAmzll/e+Inw4
+JK+ysHsIdR7KLsdB74t0z8nDbzm5UkEYxnAkVFEE/l+IcDXlHI7WZ2lERDObjP6l
+uZVIZoTzGgSro1fBtrQvKBJFK8tC0/SlzntsH+TIqefUbcgnLWkmxehzEFQfw7/9
+qvWVb/bK1QaPG3mT44a6jf6oEI+VPhQJv8qIWeKTtuwDqX7dH18T0ymzpvNq3zBT
+RMjN5YJXvJw=
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/nullbytecert.pem b/Lib/test/certdata/nullbytecert.pem
new file mode 100644
index 0000000000..447186c950
--- /dev/null
+++ b/Lib/test/certdata/nullbytecert.pem
@@ -0,0 +1,90 @@
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number: 0 (0x0)
+    Signature Algorithm: sha1WithRSAEncryption
+        Issuer: C=US, ST=Oregon, L=Beaverton, O=Python Software Foundation, OU=Python Core Development, CN=null.python.org\x00example.org/emailAddress=python-dev@python.org
+        Validity
+            Not Before: Aug  7 13:11:52 2013 GMT
+            Not After : Aug  7 13:12:52 2013 GMT
+        Subject: C=US, ST=Oregon, L=Beaverton, O=Python Software Foundation, OU=Python Core Development, CN=null.python.org\x00example.org/emailAddress=python-dev@python.org
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                Public-Key: (2048 bit)
+                Modulus:
+                    00:b5:ea:ed:c9:fb:46:7d:6f:3b:76:80:dd:3a:f3:
+                    03:94:0b:a7:a6:db:ec:1d:df:ff:23:74:08:9d:97:
+                    16:3f:a3:a4:7b:3e:1b:0e:96:59:25:03:a7:26:e2:
+                    88:a9:cf:79:cd:f7:04:56:b0:ab:79:32:6e:59:c1:
+                    32:30:54:eb:58:a8:cb:91:f0:42:a5:64:27:cb:d4:
+                    56:31:88:52:ad:cf:bd:7f:f0:06:64:1f:cc:27:b8:
+                    a3:8b:8c:f3:d8:29:1f:25:0b:f5:46:06:1b:ca:02:
+                    45:ad:7b:76:0a:9c:bf:bb:b9:ae:0d:16:ab:60:75:
+                    ae:06:3e:9c:7c:31:dc:92:2f:29:1a:e0:4b:0c:91:
+                    90:6c:e9:37:c5:90:d7:2a:d7:97:15:a3:80:8f:5d:
+                    7b:49:8f:54:30:d4:97:2c:1c:5b:37:b5:ab:69:30:
+                    68:43:d3:33:78:4b:02:60:f5:3c:44:80:a1:8f:e7:
+                    f0:0f:d1:5e:87:9e:46:cf:62:fc:f9:bf:0c:65:12:
+                    f1:93:c8:35:79:3f:c8:ec:ec:47:f5:ef:be:44:d5:
+                    ae:82:1e:2d:9a:9f:98:5a:67:65:e1:74:70:7c:cb:
+                    d3:c2:ce:0e:45:49:27:dc:e3:2d:d4:fb:48:0e:2f:
+                    9e:77:b8:14:46:c0:c4:36:ca:02:ae:6a:91:8c:da:
+                    2f:85
+                Exponent: 65537 (0x10001)
+        X509v3 extensions:
+            X509v3 Basic Constraints: critical
+                CA:FALSE
+            X509v3 Subject Key Identifier:
+                88:5A:55:C0:52:FF:61:CD:52:A3:35:0F:EA:5A:9C:24:38:22:F7:5C
+            X509v3 Key Usage:
+                Digital Signature, Non Repudiation, Key Encipherment
+            X509v3 Subject Alternative Name:
+                *************************************************************
+                WARNING: The values for DNS, email and URI are WRONG. OpenSSL
+                         doesn't print the text after a NULL byte.
+                *************************************************************
+                DNS:altnull.python.org, email:null@python.org, URI:http://null.python.org, IP Address:192.0.2.1, IP Address:2001:DB8:0:0:0:0:0:1
+    Signature Algorithm: sha1WithRSAEncryption
+         ac:4f:45:ef:7d:49:a8:21:70:8e:88:59:3e:d4:36:42:70:f5:
+         a3:bd:8b:d7:a8:d0:58:f6:31:4a:b1:a4:a6:dd:6f:d9:e8:44:
+         3c:b6:0a:71:d6:7f:b1:08:61:9d:60:ce:75:cf:77:0c:d2:37:
+         86:02:8d:5e:5d:f9:0f:71:b4:16:a8:c1:3d:23:1c:f1:11:b3:
+         56:6e:ca:d0:8d:34:94:e6:87:2a:99:f2:ae:ae:cc:c2:e8:86:
+         de:08:a8:7f:c5:05:fa:6f:81:a7:82:e6:d0:53:9d:34:f4:ac:
+         3e:40:fe:89:57:7a:29:a4:91:7e:0b:c6:51:31:e5:10:2f:a4:
+         60:76:cd:95:51:1a:be:8b:a1:b0:fd:ad:52:bd:d7:1b:87:60:
+         d2:31:c7:17:c4:18:4f:2d:08:25:a3:a7:4f:b7:92:ca:e2:f5:
+         25:f1:54:75:81:9d:b3:3d:61:a2:f7:da:ed:e1:c6:6f:2c:60:
+         1f:d8:6f:c5:92:05:ab:c9:09:62:49:a9:14:ad:55:11:cc:d6:
+         4a:19:94:99:97:37:1d:81:5f:8b:cf:a3:a8:96:44:51:08:3d:
+         0b:05:65:12:eb:b6:70:80:88:48:72:4f:c6:c2:da:cf:cd:8e:
+         5b:ba:97:2f:60:b4:96:56:49:5e:3a:43:76:63:04:be:2a:f6:
+         c1:ca:a9:94
+-----BEGIN CERTIFICATE-----
+MIIE2DCCA8CgAwIBAgIBADANBgkqhkiG9w0BAQUFADCBxTELMAkGA1UEBhMCVVMx
+DzANBgNVBAgMBk9yZWdvbjESMBAGA1UEBwwJQmVhdmVydG9uMSMwIQYDVQQKDBpQ
+eXRob24gU29mdHdhcmUgRm91bmRhdGlvbjEgMB4GA1UECwwXUHl0aG9uIENvcmUg
+RGV2ZWxvcG1lbnQxJDAiBgNVBAMMG251bGwucHl0aG9uLm9yZwBleGFtcGxlLm9y
+ZzEkMCIGCSqGSIb3DQEJARYVcHl0aG9uLWRldkBweXRob24ub3JnMB4XDTEzMDgw
+NzEzMTE1MloXDTEzMDgwNzEzMTI1MlowgcUxCzAJBgNVBAYTAlVTMQ8wDQYDVQQI
+DAZPcmVnb24xEjAQBgNVBAcMCUJlYXZlcnRvbjEjMCEGA1UECgwaUHl0aG9uIFNv
+ZnR3YXJlIEZvdW5kYXRpb24xIDAeBgNVBAsMF1B5dGhvbiBDb3JlIERldmVsb3Bt
+ZW50MSQwIgYDVQQDDBtudWxsLnB5dGhvbi5vcmcAZXhhbXBsZS5vcmcxJDAiBgkq
+hkiG9w0BCQEWFXB5dGhvbi1kZXZAcHl0aG9uLm9yZzCCASIwDQYJKoZIhvcNAQEB
+BQADggEPADCCAQoCggEBALXq7cn7Rn1vO3aA3TrzA5QLp6bb7B3f/yN0CJ2XFj+j
+pHs+Gw6WWSUDpybiiKnPec33BFawq3kyblnBMjBU61ioy5HwQqVkJ8vUVjGIUq3P
+vX/wBmQfzCe4o4uM89gpHyUL9UYGG8oCRa17dgqcv7u5rg0Wq2B1rgY+nHwx3JIv
+KRrgSwyRkGzpN8WQ1yrXlxWjgI9de0mPVDDUlywcWze1q2kwaEPTM3hLAmD1PESA
+oY/n8A/RXoeeRs9i/Pm/DGUS8ZPINXk/yOzsR/XvvkTVroIeLZqfmFpnZeF0cHzL
+08LODkVJJ9zjLdT7SA4vnne4FEbAxDbKAq5qkYzaL4UCAwEAAaOB0DCBzTAMBgNV
+HRMBAf8EAjAAMB0GA1UdDgQWBBSIWlXAUv9hzVKjNQ/qWpwkOCL3XDALBgNVHQ8E
+BAMCBeAwgZAGA1UdEQSBiDCBhYIeYWx0bnVsbC5weXRob24ub3JnAGV4YW1wbGUu
+Y29tgSBudWxsQHB5dGhvbi5vcmcAdXNlckBleGFtcGxlLm9yZ4YpaHR0cDovL251
+bGwucHl0aG9uLm9yZwBodHRwOi8vZXhhbXBsZS5vcmeHBMAAAgGHECABDbgAAAAA
+AAAAAAAAAAEwDQYJKoZIhvcNAQEFBQADggEBAKxPRe99SaghcI6IWT7UNkJw9aO9
+i9eo0Fj2MUqxpKbdb9noRDy2CnHWf7EIYZ1gznXPdwzSN4YCjV5d+Q9xtBaowT0j
+HPERs1ZuytCNNJTmhyqZ8q6uzMLoht4IqH/FBfpvgaeC5tBTnTT0rD5A/olXeimk
+kX4LxlEx5RAvpGB2zZVRGr6LobD9rVK91xuHYNIxxxfEGE8tCCWjp0+3ksri9SXx
+VHWBnbM9YaL32u3hxm8sYB/Yb8WSBavJCWJJqRStVRHM1koZlJmXNx2BX4vPo6iW
+RFEIPQsFZRLrtnCAiEhyT8bC2s/Njlu6ly9gtJZWSV46Q3ZjBL4q9sHKqZQ=
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/nullcert.pem b/Lib/test/certdata/nullcert.pem
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/Lib/test/certdata/pycacert.pem b/Lib/test/certdata/pycacert.pem
new file mode 100644
index 0000000000..360cd57426
--- /dev/null
+++ b/Lib/test/certdata/pycacert.pem
@@ -0,0 +1,99 @@
+Certificate:
+    Data:
+        Version: 3 (0x2)
+        Serial Number:
+            cb:2d:80:99:5a:69:52:5b
+        Signature Algorithm: sha256WithRSAEncryption
+        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Validity
+            Not Before: Aug 29 14:23:16 2018 GMT
+            Not After : Oct 28 14:23:16 2037 GMT
+        Subject: C=XY, O=Python Software Foundation CA, CN=our-ca-server
+        Subject Public Key Info:
+            Public Key Algorithm: rsaEncryption
+                RSA Public-Key: (3072 bit)
+                Modulus:
+                    00:b1:84:d3:4f:5c:04:80:91:4f:82:49:ba:30:0b:
+                    f7:e8:cb:f9:14:ef:3d:9f:0b:3f:0a:62:fc:1b:20:
+                    a5:20:d1:60:5f:87:5a:1f:16:d1:ed:97:70:a6:da:
+                    1b:03:2c:7e:a0:5b:3c:4e:2f:16:7e:0e:89:29:89:
+                    e1:10:0d:38:da:6a:77:5f:37:13:b3:28:8f:7b:5c:
+                    76:ad:9e:e8:d3:f5:9e:f5:83:aa:10:07:8d:e6:51:
+                    98:f0:7c:0d:52:f2:0c:21:1e:d8:b9:99:26:a9:25:
+                    03:27:bb:5c:ab:2e:33:27:a2:d6:23:a8:83:87:44:
+                    29:9f:97:b5:24:6f:d7:b9:0a:fd:28:ee:bb:fb:41:
+                    58:ea:1d:99:dd:44:86:ab:98:be:1c:dc:cb:a9:89:
+                    1d:36:5c:a9:e8:47:b5:f4:52:48:aa:b5:a4:67:ef:
+                    3e:d7:e2:d3:33:de:98:29:d8:7a:b0:59:5c:e7:b1:
+                    0e:cc:fd:9f:eb:f6:d5:3a:0e:0b:cf:fe:0b:3d:a2:
+                    bf:45:18:ce:94:e7:a9:55:60:88:d4:d8:84:50:79:
+                    05:2e:41:03:74:ae:67:26:f6:5b:12:08:98:ce:0a:
+                    97:ed:01:0f:89:4f:17:5c:fa:3e:1d:35:24:47:92:
+                    32:bf:f7:a4:18:2b:3c:d0:48:99:e1:a2:cd:a3:cc:
+                    50:53:20:b5:c6:e3:66:85:7b:57:10:ec:33:4f:c1:
+                    77:e7:1b:7e:81:c6:c4:f3:45:20:c0:91:dd:13:76:
+                    7b:03:af:f6:76:8e:a2:83:63:57:dd:63:bc:bb:5a:
+                    1c:17:52:8a:d6:06:48:cc:0f:c7:d3:4f:e8:da:22:
+                    6c:86:f9:4e:5c:a6:29:07:3b:d8:56:4c:59:b3:20:
+                    49:07:7b:94:84:cf:2b:c3:1c:1a:4e:87:64:92:ba:
+                    42:e1:e6:ad:7d:1d:f6:54:90:6f:2b:e9:b3:cc:4b:
+                    2b:33:26:23:fd:65:c0:3c:f0:79:ad:c9:c1:81:ef:
+                    37:04:e0:27:3e:b0:ee:15:be:51
+                Exponent: 65537 (0x10001)
+        X509v3 extensions:
+            X509v3 Subject Key Identifier: 
+                B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+            X509v3 Authority Key Identifier: 
+                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
+
+            X509v3 Basic Constraints: 
+                CA:TRUE
+    Signature Algorithm: sha256WithRSAEncryption
+         6b:32:2f:e7:05:18:ea:5c:c9:95:f4:e0:c2:0c:41:5f:1a:0a:
+         95:c9:c7:7d:05:ee:8a:56:29:35:50:40:b7:fe:9f:7b:5b:1c:
+         c3:69:2f:a0:cb:d2:b8:91:2f:50:19:62:f7:27:18:6d:95:7b:
+         53:16:15:a2:5a:dc:14:e3:fb:b1:32:a9:69:db:a6:33:47:3c:
+         bb:1f:d2:dc:70:f9:6a:2e:0c:d8:8c:6d:e5:5d:1d:43:3c:4e:
+         91:de:a0:c8:da:a0:4b:0e:9d:5e:b6:0f:4a:49:f0:7b:b6:53:
+         9e:fd:35:14:5b:e3:4d:b4:18:a6:36:61:e8:8f:33:9b:d4:05:
+         f9:54:66:df:e0:cb:18:a3:4e:dc:17:a8:a0:b3:c1:a8:f4:d6:
+         9d:ca:7f:68:53:1a:d7:95:da:e8:d3:9e:48:00:71:95:99:11:
+         07:cf:96:c0:7d:ce:7d:30:e8:4f:e1:83:16:33:a1:ff:59:9b:
+         3e:4c:e7:3a:38:01:9f:0f:67:4c:fd:2d:8b:4a:d4:01:46:37:
+         33:e8:13:6b:15:a9:1d:68:76:45:a2:82:33:69:26:30:60:05:
+         c8:8f:bd:b4:75:ab:be:7a:8b:48:68:70:40:b4:1b:51:c5:e6:
+         7a:ad:6b:4f:db:17:c0:60:67:2e:63:61:9b:2c:48:99:b8:76:
+         45:a0:9e:cc:ef:33:1e:50:4e:ab:72:c3:65:c8:b2:79:b3:35:
+         83:21:78:d3:8b:6c:3a:18:e8:65:32:39:b8:c0:9d:71:2f:35:
+         36:8a:c0:17:62:d8:8b:3e:e1:22:18:2b:4c:63:a6:0e:9d:0a:
+         fa:ab:5b:35:fb:88:91:77:4c:8d:8c:9d:a9:cf:fc:ab:c2:e6:
+         5a:05:7b:7e:04:6e:39:cf:93:ce:67:3b:7a:cb:af:b6:36:e1:
+         fb:71:64:45:d4:a6:f0:ce:ef:75:04:99:69:9a:e5:88:0a:10:
+         02:74:89:ec:75:84:44:80:48:df:c1:f7:e9:37:ce:ce:92:92:
+         5c:89:22:08:73:1f
+-----BEGIN CERTIFICATE-----
+MIIEbTCCAtWgAwIBAgIJAMstgJlaaVJbMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
+BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
+MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
+NDIzMTZaME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
+Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcjCCAaIwDQYJKoZI
+hvcNAQEBBQADggGPADCCAYoCggGBALGE009cBICRT4JJujAL9+jL+RTvPZ8LPwpi
+/BsgpSDRYF+HWh8W0e2XcKbaGwMsfqBbPE4vFn4OiSmJ4RANONpqd183E7Moj3tc
+dq2e6NP1nvWDqhAHjeZRmPB8DVLyDCEe2LmZJqklAye7XKsuMyei1iOog4dEKZ+X
+tSRv17kK/Sjuu/tBWOodmd1EhquYvhzcy6mJHTZcqehHtfRSSKq1pGfvPtfi0zPe
+mCnYerBZXOexDsz9n+v21ToOC8/+Cz2iv0UYzpTnqVVgiNTYhFB5BS5BA3SuZyb2
+WxIImM4Kl+0BD4lPF1z6Ph01JEeSMr/3pBgrPNBImeGizaPMUFMgtcbjZoV7VxDs
+M0/Bd+cbfoHGxPNFIMCR3RN2ewOv9naOooNjV91jvLtaHBdSitYGSMwPx9NP6Noi
+bIb5TlymKQc72FZMWbMgSQd7lITPK8McGk6HZJK6QuHmrX0d9lSQbyvps8xLKzMm
+I/1lwDzwea3JwYHvNwTgJz6w7hW+UQIDAQABo1AwTjAdBgNVHQ4EFgQUs4qgorpx
+8agkedSkWyU2FR5JyM0wHwYDVR0jBBgwFoAUs4qgorpx8agkedSkWyU2FR5JyM0w
+DAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAYEAazIv5wUY6lzJlfTgwgxB
+XxoKlcnHfQXuilYpNVBAt/6fe1scw2kvoMvSuJEvUBli9ycYbZV7UxYVolrcFOP7
+sTKpadumM0c8ux/S3HD5ai4M2Ixt5V0dQzxOkd6gyNqgSw6dXrYPSknwe7ZTnv01
+FFvjTbQYpjZh6I8zm9QF+VRm3+DLGKNO3BeooLPBqPTWncp/aFMa15Xa6NOeSABx
+lZkRB8+WwH3OfTDoT+GDFjOh/1mbPkznOjgBnw9nTP0ti0rUAUY3M+gTaxWpHWh2
+RaKCM2kmMGAFyI+9tHWrvnqLSGhwQLQbUcXmeq1rT9sXwGBnLmNhmyxImbh2RaCe
+zO8zHlBOq3LDZciyebM1gyF404tsOhjoZTI5uMCdcS81NorAF2LYiz7hIhgrTGOm
+Dp0K+qtbNfuIkXdMjYydqc/8q8LmWgV7fgRuOc+Tzmc7esuvtjbh+3FkRdSm8M7v
+dQSZaZrliAoQAnSJ7HWERIBI38H36TfOzpKSXIkiCHMf
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/pycakey.pem b/Lib/test/certdata/pycakey.pem
new file mode 100644
index 0000000000..819bdef1ff
--- /dev/null
+++ b/Lib/test/certdata/pycakey.pem
@@ -0,0 +1,40 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
diff --git a/Lib/test/certdata/revocation.crl b/Lib/test/certdata/revocation.crl
new file mode 100644
index 0000000000..621675eb5c
--- /dev/null
+++ b/Lib/test/certdata/revocation.crl
@@ -0,0 +1,14 @@
+-----BEGIN X509 CRL-----
+MIICJjCBjwIBATANBgkqhkiG9w0BAQsFADBNMQswCQYDVQQGEwJYWTEmMCQGA1UE
+CgwdUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24gQ0ExFjAUBgNVBAMMDW91ci1j
+YS1zZXJ2ZXIXDTIxMDMxNzA4NDgyMFoXDTQwMDUxNjA4NDgyMFqgDjAMMAoGA1Ud
+FAQDAgEAMA0GCSqGSIb3DQEBCwUAA4IBgQCd2GrHb4zr2R8eK7YMHwlkgICxbWP1
+4nuEi55yzUcmMcCZJ6ZQV3yYqTlAULGQ9qWAUdhsyH+yu3hRKFKHQv0DAdKKxgow
+66YasAQQ99DskXOPxmRoIA7qtIWZbLtBwHQJWh+uUFlTdUXitGIX5Xie74xu5YIr
+moa3QeuZyG5+gigSTUyst5T/J/cHfBzlAJLc2k3Ty4EPYXKHCVnrZWJbRmxq199l
+A7S+eBb9qWXSYXCn6v+EZ76pUS3u/66kZ86PO3h9294BzdhxbCJ27dQXNHw6owe2
+Iyiv0aWx+TNSGSf4yCqaYTH6RtEoviI3h/inVFHNGgjlMzdaGw/0I3bkB0rt2WSR
+Vck37HnXvQvVEkgO/39C0WKZus6m4gmOgZcbJbXaR8uIR5Hmw3SEyGEPEIBu6tXV
+BLJOSOSu2vVUH5GUIrpvK9FTySKYa+MGryoPasuqZNfwpaXK+ON2G6QsmcXPWZY0
+Dry6t0w2geW6UYVGmb831i8ZP3JVVVwcwi0=
+-----END X509 CRL-----
diff --git a/Lib/test/certdata/secp384r1.pem b/Lib/test/certdata/secp384r1.pem
new file mode 100644
index 0000000000..eef7117af7
--- /dev/null
+++ b/Lib/test/certdata/secp384r1.pem
@@ -0,0 +1,7 @@
+$ openssl genpkey -genparam -algorithm EC -pkeyopt ec_paramgen_curve:secp384r1 -pkeyopt ec_param_enc:named_curve -text
+-----BEGIN EC PARAMETERS-----
+BgUrgQQAIg==
+-----END EC PARAMETERS-----
+ECDSA-Parameters: (384 bit)
+ASN1 OID: secp384r1
+NIST CURVE: P-384
diff --git a/Lib/test/certdata/selfsigned_pythontestdotnet.pem b/Lib/test/certdata/selfsigned_pythontestdotnet.pem
new file mode 100644
index 0000000000..2b1760747b
--- /dev/null
+++ b/Lib/test/certdata/selfsigned_pythontestdotnet.pem
@@ -0,0 +1,34 @@
+-----BEGIN CERTIFICATE-----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+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/ssl_cert.pem b/Lib/test/certdata/ssl_cert.pem
new file mode 100644
index 0000000000..de596717bd
--- /dev/null
+++ b/Lib/test/certdata/ssl_cert.pem
@@ -0,0 +1,26 @@
+-----BEGIN CERTIFICATE-----
+MIIEWTCCAsGgAwIBAgIJAJinz4jHSjLtMA0GCSqGSIb3DQEBCwUAMF8xCzAJBgNV
+BAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9u
+IFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODA4
+MjkxNDIzMTVaFw0yODA4MjYxNDIzMTVaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQH
+DA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5k
+YXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGP
+ADCCAYoCggGBALKUqUtopT6E68kN+uJNEt34i2EbmG/bwjcD8IaMsgJPSsMO2Bpd
+3S6qWgkCeOyCfmAwBxK2kNbxGb63ouysEv7l8GCTJTWv3hG/HQcejJpnAEGi6K1U
+fDbyE/db6yZ12SoHVTGkadN4vYGCPd1Wj9ZO1F877SHQ8rDWX3xgTWkxN2ojBw44
+T8RHSDiG8D/CvG4uEy+VUszL+Uvny5y2poNSqvI3J56sptWSrh8nIIbkPZPBdUne
+LYMOHTFK3ZjXSmhlXgziTxK71nnzM3Y9K9gxPnRqoXbvu/wFo55hQCkETiRkYgmm
+jXcBMZ0TClQVnQWuLjMthRnWFZs4Lfmwqjs7FZD/61581R2BYehvpWbLvvuOJhwv
+DFzexL2sXcAl7SsxbzeQKRHqGbIDfbnQTXfs3/VC6Ye5P82P2ucj+XC32N9piRmO
+gCBP8L3ub+YzzdxikZN2gZXXE2jsb3QyE/R2LkWdWyshpKe+RsZP1SBRbHShUyOh
+yJ90baoiEwj2mwIDAQABoxgwFjAUBgNVHREEDTALgglsb2NhbGhvc3QwDQYJKoZI
+hvcNAQELBQADggGBAHRUO/UIHl3jXQENewYayHxkIx8t7nu40iO2DXbicSijz5bo
+5//xAB6RxhBAlsDBehgQP1uoZg+WJW+nHu3CIVOU3qZNZRaozxiCl2UFKcNqLOmx
+R3NKpo1jYf4REQIeG8Yw9+hSWLRbshNteP6bKUUf+vanhg9+axyOEOH/iOQvgk/m
+b8wA8wNa4ujWljPbTQnj7ry8RqhTM0GcAN5LSdSvcKcpzLcs3aYwh+Z8e30sQWna
+F40sa5u7izgBTOrwpcDm/w5kC46vpRQ5fnbshVw6pne2by0mdMECASid/p25N103
+jMqTFlmO7kpf/jpCSmamp3/JSEE1BJKHwQ6Ql4nzRA2N1mnvWH7Zxcv043gkHeAu
+0x8evpvwuhdIyproejNFlBpKmW8OX7yKTCPPMC/VkX8Q1rVkxU0DQ6hmvwZlhoKa
+9Wc2uXpw9xF8itV4Uvcdr3dwqByvIqn7iI/gB+4l41e0u8OmH2MKOx4Nxlly5TNW
+HcVKQHyOeyvnINuBAQ==
+-----END CERTIFICATE-----
diff --git a/Lib/test/certdata/ssl_key.passwd.pem b/Lib/test/certdata/ssl_key.passwd.pem
new file mode 100644
index 0000000000..46de61ab85
--- /dev/null
+++ b/Lib/test/certdata/ssl_key.passwd.pem
@@ -0,0 +1,42 @@
+-----BEGIN ENCRYPTED PRIVATE KEY-----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+-----END ENCRYPTED PRIVATE KEY-----
diff --git a/Lib/test/certdata/ssl_key.pem b/Lib/test/certdata/ssl_key.pem
new file mode 100644
index 0000000000..1ea4578d81
--- /dev/null
+++ b/Lib/test/certdata/ssl_key.pem
@@ -0,0 +1,40 @@
+-----BEGIN PRIVATE KEY-----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+-----END PRIVATE KEY-----
diff --git a/Lib/test/certdata/talos-2019-0758.pem b/Lib/test/certdata/talos-2019-0758.pem
new file mode 100644
index 0000000000..13b95a77fd
--- /dev/null
+++ b/Lib/test/certdata/talos-2019-0758.pem
@@ -0,0 +1,22 @@
+-----BEGIN CERTIFICATE-----
+MIIDqDCCApKgAwIBAgIBAjALBgkqhkiG9w0BAQswHzELMAkGA1UEBhMCVUsxEDAO
+BgNVBAMTB2NvZHktY2EwHhcNMTgwNjE4MTgwMDU4WhcNMjgwNjE0MTgwMDU4WjA7
+MQswCQYDVQQGEwJVSzEsMCoGA1UEAxMjY29kZW5vbWljb24tdm0tMi50ZXN0Lmxh
+bC5jaXNjby5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC63fGB
+J80A9Av1GB0bptslKRIUtJm8EeEu34HkDWbL6AJY0P8WfDtlXjlPaLqFa6sqH6ES
+V48prSm1ZUbDSVL8R6BYVYpOlK8/48xk4pGTgRzv69gf5SGtQLwHy8UPBKgjSZoD
+5a5k5wJXGswhKFFNqyyxqCvWmMnJWxXTt2XDCiWc4g4YAWi4O4+6SeeHVAV9rV7C
+1wxqjzKovVe2uZOHjKEzJbbIU6JBPb6TRfMdRdYOw98n1VXDcKVgdX2DuuqjCzHP
+WhU4Tw050M9NaK3eXp4Mh69VuiKoBGOLSOcS8reqHIU46Reg0hqeL8LIL6OhFHIF
+j7HR6V1X6F+BfRS/AgMBAAGjgdYwgdMwCQYDVR0TBAIwADAdBgNVHQ4EFgQUOktp
+HQjxDXXUg8prleY9jeLKeQ4wTwYDVR0jBEgwRoAUx6zgPygZ0ZErF9sPC4+5e2Io
+UU+hI6QhMB8xCzAJBgNVBAYTAlVLMRAwDgYDVQQDEwdjb2R5LWNhggkA1QEAuwb7
+2s0wCQYDVR0SBAIwADAuBgNVHREEJzAlgiNjb2Rlbm9taWNvbi12bS0yLnRlc3Qu
+bGFsLmNpc2NvLmNvbTAOBgNVHQ8BAf8EBAMCBaAwCwYDVR0fBAQwAjAAMAsGCSqG
+SIb3DQEBCwOCAQEAvqantx2yBlM11RoFiCfi+AfSblXPdrIrHvccepV4pYc/yO6p
+t1f2dxHQb8rWH3i6cWag/EgIZx+HJQvo0rgPY1BFJsX1WnYf1/znZpkUBGbVmlJr
+t/dW1gSkNS6sPsM0Q+7HPgEv8CPDNK5eo7vU2seE0iWOkxSyVUuiCEY9ZVGaLVit
+p0C78nZ35Pdv4I+1cosmHl28+es1WI22rrnmdBpH8J1eY6WvUw2xuZHLeNVN0TzV
+Q3qq53AaCWuLOD1AjESWuUCxMZTK9DPS4JKXTK8RLyDeqOvJGjsSWp3kL0y3GaQ+
+10T1rfkKJub2+m9A9duin1fn6tHc2wSvB7m3DA==
+-----END CERTIFICATE-----
diff --git a/Lib/test/coding20731.py b/Lib/test/coding20731.py
deleted file mode 100644
index b0e227ad11..0000000000
--- a/Lib/test/coding20731.py
+++ /dev/null
@@ -1,4 +0,0 @@
-#coding:latin1
-
-
-
diff --git a/Lib/test/dataclass_module_1.py b/Lib/test/dataclass_module_1.py
deleted file mode 100644
index 87a33f8191..0000000000
--- a/Lib/test/dataclass_module_1.py
+++ /dev/null
@@ -1,32 +0,0 @@
-#from __future__ import annotations
-USING_STRINGS = False
-
-# dataclass_module_1.py and dataclass_module_1_str.py are identical
-# except only the latter uses string annotations.
-
-import dataclasses
-import typing
-
-T_CV2 = typing.ClassVar[int]
-T_CV3 = typing.ClassVar
-
-T_IV2 = dataclasses.InitVar[int]
-T_IV3 = dataclasses.InitVar
-
-@dataclasses.dataclass
-class CV:
-    T_CV4 = typing.ClassVar
-    cv0: typing.ClassVar[int] = 20
-    cv1: typing.ClassVar = 30
-    cv2: T_CV2
-    cv3: T_CV3
-    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
-
-@dataclasses.dataclass
-class IV:
-    T_IV4 = dataclasses.InitVar
-    iv0: dataclasses.InitVar[int]
-    iv1: dataclasses.InitVar
-    iv2: T_IV2
-    iv3: T_IV3
-    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/dataclass_module_1_str.py b/Lib/test/dataclass_module_1_str.py
deleted file mode 100644
index 6de490b7ad..0000000000
--- a/Lib/test/dataclass_module_1_str.py
+++ /dev/null
@@ -1,32 +0,0 @@
-from __future__ import annotations
-USING_STRINGS = True
-
-# dataclass_module_1.py and dataclass_module_1_str.py are identical
-# except only the latter uses string annotations.
-
-import dataclasses
-import typing
-
-T_CV2 = typing.ClassVar[int]
-T_CV3 = typing.ClassVar
-
-T_IV2 = dataclasses.InitVar[int]
-T_IV3 = dataclasses.InitVar
-
-@dataclasses.dataclass
-class CV:
-    T_CV4 = typing.ClassVar
-    cv0: typing.ClassVar[int] = 20
-    cv1: typing.ClassVar = 30
-    cv2: T_CV2
-    cv3: T_CV3
-    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
-
-@dataclasses.dataclass
-class IV:
-    T_IV4 = dataclasses.InitVar
-    iv0: dataclasses.InitVar[int]
-    iv1: dataclasses.InitVar
-    iv2: T_IV2
-    iv3: T_IV3
-    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/dataclass_module_2.py b/Lib/test/dataclass_module_2.py
deleted file mode 100644
index 68fb733e29..0000000000
--- a/Lib/test/dataclass_module_2.py
+++ /dev/null
@@ -1,32 +0,0 @@
-#from __future__ import annotations
-USING_STRINGS = False
-
-# dataclass_module_2.py and dataclass_module_2_str.py are identical
-# except only the latter uses string annotations.
-
-from dataclasses import dataclass, InitVar
-from typing import ClassVar
-
-T_CV2 = ClassVar[int]
-T_CV3 = ClassVar
-
-T_IV2 = InitVar[int]
-T_IV3 = InitVar
-
-@dataclass
-class CV:
-    T_CV4 = ClassVar
-    cv0: ClassVar[int] = 20
-    cv1: ClassVar = 30
-    cv2: T_CV2
-    cv3: T_CV3
-    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
-
-@dataclass
-class IV:
-    T_IV4 = InitVar
-    iv0: InitVar[int]
-    iv1: InitVar
-    iv2: T_IV2
-    iv3: T_IV3
-    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/dataclass_module_2_str.py b/Lib/test/dataclass_module_2_str.py
deleted file mode 100644
index b363d17c17..0000000000
--- a/Lib/test/dataclass_module_2_str.py
+++ /dev/null
@@ -1,32 +0,0 @@
-from __future__ import annotations
-USING_STRINGS = True
-
-# dataclass_module_2.py and dataclass_module_2_str.py are identical
-# except only the latter uses string annotations.
-
-from dataclasses import dataclass, InitVar
-from typing import ClassVar
-
-T_CV2 = ClassVar[int]
-T_CV3 = ClassVar
-
-T_IV2 = InitVar[int]
-T_IV3 = InitVar
-
-@dataclass
-class CV:
-    T_CV4 = ClassVar
-    cv0: ClassVar[int] = 20
-    cv1: ClassVar = 30
-    cv2: T_CV2
-    cv3: T_CV3
-    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
-
-@dataclass
-class IV:
-    T_IV4 = InitVar
-    iv0: InitVar[int]
-    iv1: InitVar
-    iv2: T_IV2
-    iv3: T_IV3
-    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/dataclass_textanno.py b/Lib/test/dataclass_textanno.py
deleted file mode 100644
index 3eb6c943d4..0000000000
--- a/Lib/test/dataclass_textanno.py
+++ /dev/null
@@ -1,12 +0,0 @@
-from __future__ import annotations
-
-import dataclasses
-
-
-class Foo:
-    pass
-
-
-@dataclasses.dataclass
-class Bar:
-    foo: Foo
diff --git a/Lib/test/ffdh3072.pem b/Lib/test/ffdh3072.pem
deleted file mode 100644
index ad69bac8d0..0000000000
--- a/Lib/test/ffdh3072.pem
+++ /dev/null
@@ -1,41 +0,0 @@
-    DH Parameters: (3072 bit)
-        prime:
-            00:ff:ff:ff:ff:ff:ff:ff:ff:ad:f8:54:58:a2:bb:
-            4a:9a:af:dc:56:20:27:3d:3c:f1:d8:b9:c5:83:ce:
-            2d:36:95:a9:e1:36:41:14:64:33:fb:cc:93:9d:ce:
-            24:9b:3e:f9:7d:2f:e3:63:63:0c:75:d8:f6:81:b2:
-            02:ae:c4:61:7a:d3:df:1e:d5:d5:fd:65:61:24:33:
-            f5:1f:5f:06:6e:d0:85:63:65:55:3d:ed:1a:f3:b5:
-            57:13:5e:7f:57:c9:35:98:4f:0c:70:e0:e6:8b:77:
-            e2:a6:89:da:f3:ef:e8:72:1d:f1:58:a1:36:ad:e7:
-            35:30:ac:ca:4f:48:3a:79:7a:bc:0a:b1:82:b3:24:
-            fb:61:d1:08:a9:4b:b2:c8:e3:fb:b9:6a:da:b7:60:
-            d7:f4:68:1d:4f:42:a3:de:39:4d:f4:ae:56:ed:e7:
-            63:72:bb:19:0b:07:a7:c8:ee:0a:6d:70:9e:02:fc:
-            e1:cd:f7:e2:ec:c0:34:04:cd:28:34:2f:61:91:72:
-            fe:9c:e9:85:83:ff:8e:4f:12:32:ee:f2:81:83:c3:
-            fe:3b:1b:4c:6f:ad:73:3b:b5:fc:bc:2e:c2:20:05:
-            c5:8e:f1:83:7d:16:83:b2:c6:f3:4a:26:c1:b2:ef:
-            fa:88:6b:42:38:61:1f:cf:dc:de:35:5b:3b:65:19:
-            03:5b:bc:34:f4:de:f9:9c:02:38:61:b4:6f:c9:d6:
-            e6:c9:07:7a:d9:1d:26:91:f7:f7:ee:59:8c:b0:fa:
-            c1:86:d9:1c:ae:fe:13:09:85:13:92:70:b4:13:0c:
-            93:bc:43:79:44:f4:fd:44:52:e2:d7:4d:d3:64:f2:
-            e2:1e:71:f5:4b:ff:5c:ae:82:ab:9c:9d:f6:9e:e8:
-            6d:2b:c5:22:36:3a:0d:ab:c5:21:97:9b:0d:ea:da:
-            1d:bf:9a:42:d5:c4:48:4e:0a:bc:d0:6b:fa:53:dd:
-            ef:3c:1b:20:ee:3f:d5:9d:7c:25:e4:1d:2b:66:c6:
-            2e:37:ff:ff:ff:ff:ff:ff:ff:ff
-        generator: 2 (0x2)
-        recommended-private-length: 276 bits
------BEGIN DH PARAMETERS-----
-MIIBjAKCAYEA//////////+t+FRYortKmq/cViAnPTzx2LnFg84tNpWp4TZBFGQz
-+8yTnc4kmz75fS/jY2MMddj2gbICrsRhetPfHtXV/WVhJDP1H18GbtCFY2VVPe0a
-87VXE15/V8k1mE8McODmi3fipona8+/och3xWKE2rec1MKzKT0g6eXq8CrGCsyT7
-YdEIqUuyyOP7uWrat2DX9GgdT0Kj3jlN9K5W7edjcrsZCwenyO4KbXCeAvzhzffi
-7MA0BM0oNC9hkXL+nOmFg/+OTxIy7vKBg8P+OxtMb61zO7X8vC7CIAXFjvGDfRaD
-ssbzSibBsu/6iGtCOGEfz9zeNVs7ZRkDW7w09N75nAI4YbRvydbmyQd62R0mkff3
-7lmMsPrBhtkcrv4TCYUTknC0EwyTvEN5RPT9RFLi103TZPLiHnH1S/9croKrnJ32
-nuhtK8UiNjoNq8Uhl5sN6todv5pC1cRITgq80Gv6U93vPBsg7j/VnXwl5B0rZsYu
-N///////////AgECAgIBFA==
------END DH PARAMETERS-----
diff --git a/Lib/test/future_test1.py b/Lib/test/future_test1.py
deleted file mode 100644
index 297c2e087c..0000000000
--- a/Lib/test/future_test1.py
+++ /dev/null
@@ -1,11 +0,0 @@
-"""This is a test"""
-
-# Import the name nested_scopes twice to trigger SF bug #407394 (regression).
-from __future__ import nested_scopes, nested_scopes
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/future_test2.py b/Lib/test/future_test2.py
deleted file mode 100644
index 3d7fc860a3..0000000000
--- a/Lib/test/future_test2.py
+++ /dev/null
@@ -1,10 +0,0 @@
-"""This is a test"""
-
-from __future__ import nested_scopes; import site
-
-def f(x):
-    def g(y):
-        return x + y
-    return g
-
-result = f(2)(4)
diff --git a/Lib/test/gdb_sample.py b/Lib/test/gdb_sample.py
deleted file mode 100644
index 4188f50136..0000000000
--- a/Lib/test/gdb_sample.py
+++ /dev/null
@@ -1,12 +0,0 @@
-# Sample script for use by test_gdb.py
-
-def foo(a, b, c):
-    bar(a=a, b=b, c=c)
-
-def bar(a, b, c):
-    baz(a, b, c)
-
-def baz(*args):
-    id(42)
-
-foo(1, 2, 3)
diff --git a/Lib/test/idnsans.pem b/Lib/test/idnsans.pem
deleted file mode 100644
index cbcac7818d..0000000000
--- a/Lib/test/idnsans.pem
+++ /dev/null
@@ -1,169 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/QIBADANBgkqhkiG9w0BAQEFAASCBucwggbjAgEAAoIBgQC8sqplTuHuLjbW
-TL5SL2D1fw9U6WQzLVAF5gsyhd5lr2FpfYwjrob5Mav91aOLbJRTvoNyXsJ26FPS
-0RycRGXbomcIEJxXGy9aI+0MLYBt1G5mgqCH+HcVCwPzCNlhVnTwvpgA7y8zs3+6
-ezZAPWkF0yWOMYLtTcq9A5GWeavt5VMgm1KZF3gO4k58oPyk3Ae9D0LAaYsX6DFi
-BYx41eUR5UbSb5IYXaDd8d6jqW/jnYhgc6Cxkv1gTJFn87V5lrG0vYMSRUtWDQ9Y
-Jh/EKAxjGw7AeY429p6TE4UoJhDmoFYR2NLvawhNIplxol/v0fs0veFQjI/UsTD8
-2tRfnYL4IX8szhLsE5/5Iq8aiLHjVbIMwmDYAa0P63Ap2kf1biSn9mpDL8lQazSo
-yr8xzIq2QS5HMvGbeMAmS0ih10Zx84uVmkWlavgvtSflw8K/ZXT9c70rZp/TdBGY
-95cOFsbg5U/20M/Llpis9tcBCaoVaYSFupatrP+p8y19qP2nebsCAwEAAQKCAYEA
-uaYWWwHW6pzxOrnabcVLYX0WunW9LVShbIw97AElI2n/LuhkXh6xkK48BsqP0vaK
-oDHJ5VYxgQdmoP03Zs8sX4BSWe7twg1u8wJxkA+cUXI1BAn0opHjpwJlalEEfe2v
-s8PwjMrF59nsCq56W42PrDlms5UmuQ5WLsw6Co++hZmfxW7LPu+GIS6qBZfluNT5
-kBpZlDDCtkyteUD4SVI3wvmOSi+Wzv4e7P2wC9kByjENIcfhC5QQURRD4sA1hWCp
-2SThYWqJOCEc2SvGgoqgTRaJuQ2aVG9qrntXt0N4V+WdJWXBK0jedkB2flLve1fR
-KmDYuc9k/c1svmS3Y+iZohBha9H8jpuJmXYBxxg1iNg9m7qkfg8F8wxCYLQKB+U6
-tjRS7by+jSE08On7mpDDhJORnlh+rfEuWPPwAKQpLpdp76KDTvR++GvfOMUiOrFM
-e9s5aXp+vcgkSSqYvigE+sFpCjQWwkGBkMdT16Pf9CzhQaM08YuLnzfLEYgLFw6R
-AoHBAN5NQINBmlq/cptGSru66kfecqHfI7xHnnGWKAkto/B1x7Crrgs4Tk5b4vaA
-JmAqatt5P1e7zco7uAXXebY5VURuH/30TlkuaB+oGFp0OMw6165n8RVPT2ZaDViK
-ssJ9LT8fJ+23TWCCT2Z1zUlM/NnHAMjKOVsJK3/KEkVvlc7ROC7uVooc78AsQehg
-zpL3GBYEeBukT8aNUMqUlesCsIs/dQHW7DzQL2xGkQagm5/PDsxaCsT7ynA8eL3X
-TW+IXwKBwQDZTV3TaG6wqtL8y2DR0lN5jY/eYayX4e18iZ+XEZVTntPdVVyJIE4d
-0A5ZfcILb9WE8R21iptROYSjcH/05j+3fQMJ1WAK0sNfGTUNNT3jYU8YzLvos+wW
-G8E+mNMpFPWNvLV5Qrl4VvoifGh8AMvplUEz8uAzGJbXbRxUPcmjth2ph8zULEDn
-/+o4OcT3gh1bp+HCqch0OuiJRn9qNUpsJG5GMm5FtjBjZM97ucZ1/0DaWl3JUxUN
-/pueo3J9vCUCgcBg2Fjdlcvv8u2z1aijJmgATVm1SWfhE3ZkV50zem2sSTNotTJK
-cwoyOveimeueA3ywBp9g0lFx5Bhkex3sFAggmrVXRoKHeZ8lA28woOdJmezybxfp
-R7b4iQy9YRdFgZEfqawUdMHB5KNAqNt5LpANNBQUZX0dOt53eooBM/6Yri8CyxRq
-cPbFysIfwWTdQ8Z7eRD2Qdv7TP9AcgDp9C8DSu7nkUEzsSKn0gpGT9vcgDEbN7Lv
-ZB4qTT3wvoZeq5MCgcBIG18eDtJkN1sp3Yb0OTnP5QSvg3PVNngq0jQt2fzWMacW
-FARP0HN7exW35n4kc2jD44q7OhJOAqsb3PHo3xqXlZkTg0WKceO4w9GR32/46spn
-bVCRaFrX/z/BuM6hHD5bWRpS8aw/3YTFOsklFNKVYRyw01BIREmRlLhIz/QAKidv
-oQt8AG9NTON44tqUUw3Q40WL5fEJeJ6/JrCTGrnmZrRdANEMuucVpFchNEVB1IC9
-tCzY6IPdD/atzojoZi0CgcB2x9oWLjJ0XJIp2pMAb8nCMVjkKrznKFjZbDm8EQBs
-ou7pM2zkO3VRcWT1BXQocinJsjQqjQiTawP6IN2FQgT0d89V+pwd+jdvpdildQhP
-1/6SErVRZV//oopKTsC6TIBL/EmW1TkP3ulQIZs8YklFgybeHdDyNFi+VgPXkVGe
-IHp0nEzrui9q0YJsjHfFHBeGyzDSfbiBYiF7Auk66gYZbXufebP/LZNG/FIamPP3
-rwYIeeV1IVwk9tPBw6fGwrs=
------END PRIVATE KEY-----
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:60
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=idnsans
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                RSA Public-Key: (3072 bit)
-                Modulus:
-                    00:bc:b2:aa:65:4e:e1:ee:2e:36:d6:4c:be:52:2f:
-                    60:f5:7f:0f:54:e9:64:33:2d:50:05:e6:0b:32:85:
-                    de:65:af:61:69:7d:8c:23:ae:86:f9:31:ab:fd:d5:
-                    a3:8b:6c:94:53:be:83:72:5e:c2:76:e8:53:d2:d1:
-                    1c:9c:44:65:db:a2:67:08:10:9c:57:1b:2f:5a:23:
-                    ed:0c:2d:80:6d:d4:6e:66:82:a0:87:f8:77:15:0b:
-                    03:f3:08:d9:61:56:74:f0:be:98:00:ef:2f:33:b3:
-                    7f:ba:7b:36:40:3d:69:05:d3:25:8e:31:82:ed:4d:
-                    ca:bd:03:91:96:79:ab:ed:e5:53:20:9b:52:99:17:
-                    78:0e:e2:4e:7c:a0:fc:a4:dc:07:bd:0f:42:c0:69:
-                    8b:17:e8:31:62:05:8c:78:d5:e5:11:e5:46:d2:6f:
-                    92:18:5d:a0:dd:f1:de:a3:a9:6f:e3:9d:88:60:73:
-                    a0:b1:92:fd:60:4c:91:67:f3:b5:79:96:b1:b4:bd:
-                    83:12:45:4b:56:0d:0f:58:26:1f:c4:28:0c:63:1b:
-                    0e:c0:79:8e:36:f6:9e:93:13:85:28:26:10:e6:a0:
-                    56:11:d8:d2:ef:6b:08:4d:22:99:71:a2:5f:ef:d1:
-                    fb:34:bd:e1:50:8c:8f:d4:b1:30:fc:da:d4:5f:9d:
-                    82:f8:21:7f:2c:ce:12:ec:13:9f:f9:22:af:1a:88:
-                    b1:e3:55:b2:0c:c2:60:d8:01:ad:0f:eb:70:29:da:
-                    47:f5:6e:24:a7:f6:6a:43:2f:c9:50:6b:34:a8:ca:
-                    bf:31:cc:8a:b6:41:2e:47:32:f1:9b:78:c0:26:4b:
-                    48:a1:d7:46:71:f3:8b:95:9a:45:a5:6a:f8:2f:b5:
-                    27:e5:c3:c2:bf:65:74:fd:73:bd:2b:66:9f:d3:74:
-                    11:98:f7:97:0e:16:c6:e0:e5:4f:f6:d0:cf:cb:96:
-                    98:ac:f6:d7:01:09:aa:15:69:84:85:ba:96:ad:ac:
-                    ff:a9:f3:2d:7d:a8:fd:a7:79:bb
-                Exponent: 65537 (0x10001)
-        X509v3 extensions:
-            X509v3 Subject Alternative Name: 
-                DNS:idnsans, DNS:xn--knig-5qa.idn.pythontest.net, DNS:xn--knigsgsschen-lcb0w.idna2003.pythontest.net, DNS:xn--knigsgchen-b4a3dun.idna2008.pythontest.net, DNS:xn--nxasmq6b.idna2003.pythontest.net, DNS:xn--nxasmm1c.idna2008.pythontest.net
-            X509v3 Key Usage: critical
-                Digital Signature, Key Encipherment
-            X509v3 Extended Key Usage: 
-                TLS Web Server Authentication, TLS Web Client Authentication
-            X509v3 Basic Constraints: critical
-                CA:FALSE
-            X509v3 Subject Key Identifier: 
-                5C:BE:18:7F:7B:3F:CE:99:66:80:79:53:4B:DD:33:1B:42:A5:7E:00
-            X509v3 Authority Key Identifier: 
-                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
-                serial:CB:2D:80:99:5A:69:52:5B
-
-            Authority Information Access: 
-                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
-                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
-
-            X509v3 CRL Distribution Points: 
-
-                Full Name:
-                  URI:http://testca.pythontest.net/testca/revocation.crl
-
-    Signature Algorithm: sha256WithRSAEncryption
-         5d:7a:f8:81:e0:a7:c1:3f:39:eb:d3:52:2c:e1:cb:4d:29:b3:
-         77:18:17:18:9e:12:fc:11:cc:3c:49:cb:6b:f4:4d:6c:b8:d2:
-         f4:e9:37:f8:6b:ed:f5:d7:f1:eb:5a:41:04:c7:f3:8c:da:e1:
-         05:8e:ae:58:71:d9:01:8a:32:46:b2:dd:95:46:e1:ce:82:04:
-         fa:0b:1c:29:75:07:85:ce:cd:59:d4:cc:f3:56:b3:72:4d:cb:
-         90:0f:ce:02:21:ce:5d:17:84:96:7f:6a:00:57:42:b7:24:5b:
-         07:25:1e:77:a8:9d:da:41:09:8e:29:79:b4:b0:a1:45:c8:70:
-         ae:2c:86:24:ae:3d:9a:74:a7:04:78:d6:1f:1b:17:c5:c1:6d:
-         b1:1a:fd:f4:50:2e:61:16:84:89:d0:42:3f:b6:bf:bd:52:bd:
-         c8:3e:8e:87:b4:f0:bd:ad:c7:51:65:2f:77:e8:69:79:0e:03:
-         63:89:e7:70:ad:c8:d1:2f:1a:a5:06:d2:90:db:7c:07:35:9a:
-         0b:0e:85:87:d1:70:17:a7:88:0f:c6:b5:9c:88:00:fa:f9:b2:
-         0a:19:5a:4b:8d:91:12:51:5e:0e:c1:d8:9e:02:78:d0:2d:24:
-         09:fe:d4:97:3c:cb:a0:1f:9a:ab:f7:0f:e2:fa:64:23:4e:53:
-         0a:15:3e:f5:04:01:86:29:8b:8e:24:40:2f:b1:90:87:5c:3b:
-         7b:a7:4c:06:af:c3:90:7f:e9:c6:56:42:61:15:2c:83:f1:7c:
-         4f:89:17:f3:a0:11:34:3f:8d:af:75:34:60:1e:e0:f2:f3:02:
-         e7:aa:b3:f7:9f:1c:f8:69:f4:fe:da:57:6e:1b:95:53:70:cd:
-         ed:b6:bb:2a:84:eb:ab:c3:a9:b4:d5:15:a0:b2:cc:81:2d:f1:
-         56:c1:54:9b:5f:14:4c:5f:ad:5f:f5:06:ee:22:60:45:e4:50:
-         35:64:ac:ac:ca:4a:bf:86:78:f8:53:2d:17:d8:e8:84:c8:07:
-         a4:c2:29:76:c7:1f
------BEGIN CERTIFICATE-----
-MIIGvTCCBSWgAwIBAgIJAMstgJlaaVJgMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaMF0xCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
-MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xEDAOBgNVBAMMB2lk
-bnNhbnMwggGiMA0GCSqGSIb3DQEBAQUAA4IBjwAwggGKAoIBgQC8sqplTuHuLjbW
-TL5SL2D1fw9U6WQzLVAF5gsyhd5lr2FpfYwjrob5Mav91aOLbJRTvoNyXsJ26FPS
-0RycRGXbomcIEJxXGy9aI+0MLYBt1G5mgqCH+HcVCwPzCNlhVnTwvpgA7y8zs3+6
-ezZAPWkF0yWOMYLtTcq9A5GWeavt5VMgm1KZF3gO4k58oPyk3Ae9D0LAaYsX6DFi
-BYx41eUR5UbSb5IYXaDd8d6jqW/jnYhgc6Cxkv1gTJFn87V5lrG0vYMSRUtWDQ9Y
-Jh/EKAxjGw7AeY429p6TE4UoJhDmoFYR2NLvawhNIplxol/v0fs0veFQjI/UsTD8
-2tRfnYL4IX8szhLsE5/5Iq8aiLHjVbIMwmDYAa0P63Ap2kf1biSn9mpDL8lQazSo
-yr8xzIq2QS5HMvGbeMAmS0ih10Zx84uVmkWlavgvtSflw8K/ZXT9c70rZp/TdBGY
-95cOFsbg5U/20M/Llpis9tcBCaoVaYSFupatrP+p8y19qP2nebsCAwEAAaOCAo4w
-ggKKMIHhBgNVHREEgdkwgdaCB2lkbnNhbnOCH3huLS1rbmlnLTVxYS5pZG4ucHl0
-aG9udGVzdC5uZXSCLnhuLS1rbmlnc2dzc2NoZW4tbGNiMHcuaWRuYTIwMDMucHl0
-aG9udGVzdC5uZXSCLnhuLS1rbmlnc2djaGVuLWI0YTNkdW4uaWRuYTIwMDgucHl0
-aG9udGVzdC5uZXSCJHhuLS1ueGFzbXE2Yi5pZG5hMjAwMy5weXRob250ZXN0Lm5l
-dIIkeG4tLW54YXNtbTFjLmlkbmEyMDA4LnB5dGhvbnRlc3QubmV0MA4GA1UdDwEB
-/wQEAwIFoDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/
-BAIwADAdBgNVHQ4EFgQUXL4Yf3s/zplmgHlTS90zG0KlfgAwfQYDVR0jBHYwdIAU
-s4qgorpx8agkedSkWyU2FR5JyM2hUaRPME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQK
-DB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNh
-LXNlcnZlcoIJAMstgJlaaVJbMIGDBggrBgEFBQcBAQR3MHUwPAYIKwYBBQUHMAKG
-MGh0dHA6Ly90ZXN0Y2EucHl0aG9udGVzdC5uZXQvdGVzdGNhL3B5Y2FjZXJ0LmNl
-cjA1BggrBgEFBQcwAYYpaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0
-Y2Evb2NzcC8wQwYDVR0fBDwwOjA4oDagNIYyaHR0cDovL3Rlc3RjYS5weXRob250
-ZXN0Lm5ldC90ZXN0Y2EvcmV2b2NhdGlvbi5jcmwwDQYJKoZIhvcNAQELBQADggGB
-AF16+IHgp8E/OevTUizhy00ps3cYFxieEvwRzDxJy2v0TWy40vTpN/hr7fXX8eta
-QQTH84za4QWOrlhx2QGKMkay3ZVG4c6CBPoLHCl1B4XOzVnUzPNWs3JNy5APzgIh
-zl0XhJZ/agBXQrckWwclHneondpBCY4pebSwoUXIcK4shiSuPZp0pwR41h8bF8XB
-bbEa/fRQLmEWhInQQj+2v71Svcg+joe08L2tx1FlL3foaXkOA2OJ53CtyNEvGqUG
-0pDbfAc1mgsOhYfRcBeniA/GtZyIAPr5sgoZWkuNkRJRXg7B2J4CeNAtJAn+1Jc8
-y6Afmqv3D+L6ZCNOUwoVPvUEAYYpi44kQC+xkIdcO3unTAavw5B/6cZWQmEVLIPx
-fE+JF/OgETQ/ja91NGAe4PLzAueqs/efHPhp9P7aV24blVNwze22uyqE66vDqbTV
-FaCyzIEt8VbBVJtfFExfrV/1Bu4iYEXkUDVkrKzKSr+GePhTLRfY6ITIB6TCKXbH
-Hw==
------END CERTIFICATE-----
diff --git a/Lib/test/inspect_fodder.py b/Lib/test/inspect_fodder.py
deleted file mode 100644
index 60ba7aa783..0000000000
--- a/Lib/test/inspect_fodder.py
+++ /dev/null
@@ -1,120 +0,0 @@
-# line 1
-'A module docstring.'
-
-import inspect
-# line 5
-
-# line 7
-def spam(a, /, b, c, d=3, e=4, f=5, *g, **h):
-    eggs(b + d, c + f)
-
-# line 11
-def eggs(x, y):
-    "A docstring."
-    global fr, st
-    fr = inspect.currentframe()
-    st = inspect.stack()
-    p = x
-    q = y / 0
-
-# line 20
-class StupidGit:
-    """A longer,
-
-    indented
-
-    docstring."""
-# line 27
-
-    def abuse(self, a, b, c):
-        """Another
-
-\tdocstring
-
-        containing
-
-\ttabs
-\t
-        """
-        self.argue(a, b, c)
-# line 40
-    def argue(self, a, b, c):
-        try:
-            spam(a, b, c)
-        except BaseException as e:
-            self.ex = e
-            self.tr = inspect.trace()
-
-    @property
-    def contradiction(self):
-        'The automatic gainsaying.'
-        pass
-
-# line 53
-class MalodorousPervert(StupidGit):
-    def abuse(self, a, b, c):
-        pass
-
-    @property
-    def contradiction(self):
-        pass
-
-Tit = MalodorousPervert
-
-class ParrotDroppings:
-    pass
-
-class FesteringGob(MalodorousPervert, ParrotDroppings):
-    def abuse(self, a, b, c):
-        pass
-
-    @property
-    def contradiction(self):
-        pass
-
-async def lobbest(grenade):
-    pass
-
-currentframe = inspect.currentframe()
-try:
-    raise Exception()
-except BaseException as e:
-    tb = e.__traceback__
-
-class Callable:
-    def __call__(self, *args):
-        return args
-
-    def as_method_of(self, obj):
-        from types import MethodType
-        return MethodType(self, obj)
-
-custom_method = Callable().as_method_of(42)
-del Callable
-
-# line 95
-class WhichComments:
-  # line 97
-    # before f
-    def f(self):
-      # line 100
-        # start f
-        return 1
-        # line 103
-        # end f
-       # line 105
-    # after f
-
-    # before asyncf - line 108
-    async def asyncf(self):
-        # start asyncf
-        return 2
-        # end asyncf
-       # after asyncf - line 113
-    # end of WhichComments - line 114
-  # after WhichComments - line 115
-
-# Test that getsource works on a line that includes
-# a closing parenthesis with the opening paren being in another line
-(
-); after_closing = lambda: 1
diff --git a/Lib/test/inspect_fodder2.py b/Lib/test/inspect_fodder2.py
deleted file mode 100644
index 0346461369..0000000000
--- a/Lib/test/inspect_fodder2.py
+++ /dev/null
@@ -1,292 +0,0 @@
-# line 1
-def wrap(foo=None):
-    def wrapper(func):
-        return func
-    return wrapper
-
-# line 7
-def replace(func):
-    def insteadfunc():
-        print('hello')
-    return insteadfunc
-
-# line 13
-@wrap()
-@wrap(wrap)
-def wrapped():
-    pass
-
-# line 19
-@replace
-def gone():
-    pass
-
-# line 24
-oll = lambda m: m
-
-# line 27
-tll = lambda g: g and \
-g and \
-g
-
-# line 32
-tlli = lambda d: d and \
-    d
-
-# line 36
-def onelinefunc(): pass
-
-# line 39
-def manyargs(arg1, arg2,
-arg3, arg4): pass
-
-# line 43
-def twolinefunc(m): return m and \
-m
-
-# line 47
-a = [None,
-     lambda x: x,
-     None]
-
-# line 52
-def setfunc(func):
-    globals()["anonymous"] = func
-setfunc(lambda x, y: x*y)
-
-# line 57
-def with_comment():  # hello
-    world
-
-# line 61
-multiline_sig = [
-    lambda x, \
-            y: x+y,
-    None,
-    ]
-
-# line 68
-def func69():
-    class cls70:
-        def func71():
-            pass
-    return cls70
-extra74 = 74
-
-# line 76
-def func77(): pass
-(extra78, stuff78) = 'xy'
-extra79 = 'stop'
-
-# line 81
-class cls82:
-    def func83(): pass
-(extra84, stuff84) = 'xy'
-extra85 = 'stop'
-
-# line 87
-def func88():
-    # comment
-    return 90
-
-# line 92
-def f():
-    class X:
-        def g():
-            "doc"
-            return 42
-    return X
-method_in_dynamic_class = f().g
-
-#line 101
-def keyworded(*arg1, arg2=1):
-    pass
-
-#line 105
-def annotated(arg1: list):
-    pass
-
-#line 109
-def keyword_only_arg(*, arg):
-    pass
-
-@wrap(lambda: None)
-def func114():
-    return 115
-
-class ClassWithMethod:
-    def method(self):
-        pass
-
-from functools import wraps
-
-def decorator(func):
-    @wraps(func)
-    def fake():
-        return 42
-    return fake
-
-#line 129
-@decorator
-def real():
-    return 20
-
-#line 134
-class cls135:
-    def func136():
-        def func137():
-            never_reached1
-            never_reached2
-
-# line 141
-class cls142:
-    a = """
-class cls149:
-    ...
-"""
-
-# line 148
-class cls149:
-
-    def func151(self):
-        pass
-
-'''
-class cls160:
-    pass
-'''
-
-# line 159
-class cls160:
-
-    def func162(self):
-        pass
-
-# line 165
-class cls166:
-    a = '''
-    class cls175:
-        ...
-    '''
-
-# line 172
-class cls173:
-
-    class cls175:
-        pass
-
-# line 178
-class cls179:
-    pass
-
-# line 182
-class cls183:
-
-    class cls185:
-
-        def func186(self):
-            pass
-
-def class_decorator(cls):
-    return cls
-
-# line 193
-@class_decorator
-@class_decorator
-class cls196:
-
-    @class_decorator
-    @class_decorator
-    class cls200:
-        pass
-
-class cls203:
-    class cls204:
-        class cls205:
-            pass
-    class cls207:
-        class cls205:
-            pass
-
-# line 211
-def func212():
-    class cls213:
-        pass
-    return cls213
-
-# line 217
-class cls213:
-    def func219(self):
-        class cls220:
-            pass
-        return cls220
-
-# line 224
-async def func225():
-    class cls226:
-        pass
-    return cls226
-
-# line 230
-class cls226:
-    async def func232(self):
-        class cls233:
-            pass
-        return cls233
-
-if True:
-    class cls238:
-        class cls239:
-            '''if clause cls239'''
-else:
-    class cls238:
-        class cls239:
-            '''else clause 239'''
-            pass
-
-#line 247
-def positional_only_arg(a, /):
-    pass
-
-#line 251
-def all_markers(a, b, /, c, d, *, e, f):
-    pass
-
-# line 255
-def all_markers_with_args_and_kwargs(a, b, /, c, d, *args, e, f, **kwargs):
-    pass
-
-#line 259
-def all_markers_with_defaults(a, b=1, /, c=2, d=3, *, e=4, f=5):
-    pass
-
-# line 263
-def deco_factory(**kwargs):
-    def deco(f):
-        @wraps(f)
-        def wrapper(*a, **kwd):
-            kwd.update(kwargs)
-            return f(*a, **kwd)
-        return wrapper
-    return deco
-
-@deco_factory(foo=(1 + 2), bar=lambda: 1)
-def complex_decorated(foo=0, bar=lambda: 0):
-    return foo + bar()
-
-# line 276
-parenthesized_lambda = (
-    lambda: ())
-parenthesized_lambda2 = [
-    lambda: ()][0]
-parenthesized_lambda3 = {0:
-    lambda: ()}[0]
-
-# line 285
-post_line_parenthesized_lambda1 = (lambda: ()
-)
-
-# line 289
-nested_lambda = (
-    lambda right: [].map(
-        lambda length: ()))
diff --git a/Lib/test/inspect_stock_annotations.py b/Lib/test/inspect_stock_annotations.py
deleted file mode 100644
index d115a25b65..0000000000
--- a/Lib/test/inspect_stock_annotations.py
+++ /dev/null
@@ -1,28 +0,0 @@
-a:int=3
-b:str="foo"
-
-class MyClass:
-    a:int=4
-    b:str="bar"
-    def __init__(self, a, b):
-        self.a = a
-        self.b = b
-    def __eq__(self, other):
-        return isinstance(other, MyClass) and self.a == other.a and self.b == other.b
-
-def function(a:int, b:str) -> MyClass:
-    return MyClass(a, b)
-
-
-def function2(a:int, b:"str", c:MyClass) -> MyClass:
-    pass
-
-
-def function3(a:"int", b:"str", c:"MyClass"):
-    pass
-
-
-class UnannotatedClass:
-    pass
-
-def unannotated_function(a, b, c): pass
diff --git a/Lib/test/inspect_stringized_annotations.py b/Lib/test/inspect_stringized_annotations.py
deleted file mode 100644
index a56fb050ea..0000000000
--- a/Lib/test/inspect_stringized_annotations.py
+++ /dev/null
@@ -1,34 +0,0 @@
-from __future__ import annotations
-
-a:int=3
-b:str="foo"
-
-class MyClass:
-    a:int=4
-    b:str="bar"
-    def __init__(self, a, b):
-        self.a = a
-        self.b = b
-    def __eq__(self, other):
-        return isinstance(other, MyClass) and self.a == other.a and self.b == other.b
-
-def function(a:int, b:str) -> MyClass:
-    return MyClass(a, b)
-
-
-def function2(a:int, b:"str", c:MyClass) -> MyClass:
-    pass
-
-
-def function3(a:"int", b:"str", c:"MyClass"):
-    pass
-
-
-class UnannotatedClass:
-    pass
-
-def unannotated_function(a, b, c): pass
-
-class MyClassWithLocalAnnotations:
-    mytype = int
-    x: mytype
diff --git a/Lib/test/inspect_stringized_annotations_2.py b/Lib/test/inspect_stringized_annotations_2.py
deleted file mode 100644
index 87206d5a64..0000000000
--- a/Lib/test/inspect_stringized_annotations_2.py
+++ /dev/null
@@ -1,3 +0,0 @@
-from __future__ import annotations
-
-def foo(a, b, c):  pass
diff --git a/Lib/test/keycert.passwd.pem b/Lib/test/keycert.passwd.pem
deleted file mode 100644
index c330c36d8f..0000000000
--- a/Lib/test/keycert.passwd.pem
+++ /dev/null
@@ -1,69 +0,0 @@
------BEGIN ENCRYPTED PRIVATE KEY-----
-MIIHbTBXBgkqhkiG9w0BBQ0wSjApBgkqhkiG9w0BBQwwHAQIhD+rJdxqb6ECAggA
-MAwGCCqGSIb3DQIJBQAwHQYJYIZIAWUDBAEqBBDTdyjCP3riOSUfxix4aXEvBIIH
-ECGkbsFabrcFMZcplw5jHMaOlG7rYjUzwDJ80JM8uzbv2Jb8SvNlns2+xmnEvH/M
-mNvRmnXmplbVjH3XBMK8o2Psnr2V/a0j7/pgqpRxHykG+koOY4gzdt3MAg8JPbS2
-hymSl+Y5EpciO3xLfz4aFL1ZNqspQbO/TD13Ij7DUIy7xIRBMp4taoZCrP0cEBAZ
-+wgu9m23I4dh3E8RUBzWyFFNic2MVVHrui6JbHc4dIHfyKLtXJDhUcS0vIC9PvcV
-jhorh3UZC4lM+/jjXV5AhzQ0VrJ2tXAUX2dA144XHzkSH2QmwfnajPsci7BL2CGC
-rjyTy4NfB/lDwU+55dqJZQSKXMxAapJMrtgw7LD5CKQcN6zmfhXGssJ7HQUXKkaX
-I1YOFzuUD7oo56BVCnVswv0jX9RxrE5QYNreMlOP9cS+kIYH65N+PAhlURuQC14K
-PgDkHn5knSa2UQA5tc5f7zdHOZhGRUfcjLP+KAWA3nh+/2OKw/X3zuPx75YT/FKe
-tACPw5hjEpl62m9Xa0eWepZXwqkIOkzHMmCyNCsbC0mmRoEjmvfnslfsmnh4Dg/c
-4YsTYMOLLIeCa+WIc38aA5W2lNO9lW0LwLhX1rP+GRVPv+TVHXlfoyaI+jp0iXrJ
-t3xxT0gaiIR/VznyS7Py68QV/zB7VdqbsNzS7LdquHK1k8+7OYiWjY3gqyU40Iu2
-d1eSnIoDvQJwyYp7XYXbOlXNLY+s1Qb7yxcW3vXm0Bg3gKT8r1XHWJ9rj+CxAn5r
-ysfkPs1JsesxzzQjwTiDNvHnBnZnwxuxfBr26ektEHmuAXSl8V6dzLN/aaPjpTj4
-CkE7KyqX3U9bLkp+ztl4xWKEmW44nskzm0+iqrtrxMyTfvvID4QrABjZL4zmWIqc
-e3ZfA3AYk9VDIegk/YKGC5VZ8YS7ZXQ0ASK652XqJ7QlMKTxxV7zda6Fp4uW6/qN
-ezt5wgbGGhZQXj2wDQmWNQYyG/juIgYTpCUA54U5XBIjuR6pg+Ytm0UrvNjsUoAC
-wGelyqaLDq8U8jdIFYVTJy9aJjQOYXjsUJ0dZN2aGHSlju0ZGIZc49cTIVQ9BTC5
-Yc0Vlwzpl+LuA25DzKZNSb/ci0lO/cQGJ2uXQQgaNgdsHlu8nukENGJhnIzx4fzK
-wEh3yHxhTRCzPPwDfXmx0IHXrPqJhSpAgaXBVIm8OjvmMxO+W75W4uLfNY/B7e2H
-3cjklGuvkofOf7sEOrGUYf4cb6Obg8FpvHgpKo5Twwmoh/qvEKckBFqNhZXDDl88
-GbGlSEgyaAV1Ig8s1NJKBolWFa0juyPAwJ8vT1T4iwW7kQ7KXKt2UNn96K/HxkLu
-pikvukz8oRHMlfVHa0R48UB1fFHwZLzPmwkpu6ancIxk3uO3yfhf6iDk3bmnyMlz
-g3k/b6MrLYaOVByRxay85jH3Vvgqfgn6wa6BJ7xQ81eZ8B45gFuTH0J5JtLL7SH8
-darRPLCYfA+Ums9/H6pU5EXfd3yfjMIbvhCXHkJrrljkZ+th3p8dyto6wmYqIY6I
-qR9sU+o6DhRaiP8tCICuhHxQpXylUM6WeJkJwduTJ8KWIvzsj4mReIKOl/oC2jSd
-gIdKhb9Q3zj9ce4N5m6v66tyvjxGZ+xf3BvUPDD+LwZeXgf7OBsNVbXzQbzto594
-nbCzPocFi3gERE50ru4K70eQCy08TPG5NpOz+DDdO5vpAuMLYEuI7O3L+3GjW40Q
-G5bu7H5/i7o/RWR67qhG/7p9kPw3nkUtYgnvnWaPMIuTfb4c2d069kjlfgWjIbbI
-tpSKmm5DHlqTE4/ECAbIEDtSaw9dXHCdL3nh5+n428xDdGbjN4lT86tfu17EYKzl
-ydH1RJ1LX3o3TEj9UkmDPt7LnftvwybMFEcP7hM2xD4lC++wKQs7Alg6dTkBnJV4
-5xU78WRntJkJTU7kFkpPKA0QfyCuSF1fAMoukDBkqUdOj6jE0BlJQlHk5iwgnJlt
-uEdkTjHZEjIUxWC6llPcAzaPNlmnD45AgfEW+Jn21IvutmJiQAz5lm9Z9PXaR0C8
-hXB6owRY67C0YKQwXhoNf6xQun2xGBGYy5rPEEezX1S1tUH5GR/KW1Lh+FzFqHXI
-ZEb5avfDqHKehGAjPON+Br7akuQ125M9LLjKuSyPaQzeeCAy356Xd7XzVwbPddbm
-9S9WSPqzaPgh10chIHoNoC8HMd33dB5j9/Q6jrbU/oPlptu/GlorWblvJdcTuBGI
-IVn45RFnkG8hCz0GJSNzW7+70YdESQbfJW79vssWMaiSjFE0pMyFXrFR5lBywBTx
-PiGEUWtvrKG94X1TMlGUzDzDJOQNZ9dT94bonNe9pVmP5BP4/DzwwiWh6qrzWk6p
-j8OE4cfCSh2WvHnhJbH7/N0v+JKjtxeIeJ16jx/K2oK5
------END ENCRYPTED PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-MIIEWTCCAsGgAwIBAgIJAJinz4jHSjLtMA0GCSqGSIb3DQEBCwUAMF8xCzAJBgNV
-BAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9u
-IFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODA4
-MjkxNDIzMTVaFw0yODA4MjYxNDIzMTVaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQH
-DA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5k
-YXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGP
-ADCCAYoCggGBALKUqUtopT6E68kN+uJNEt34i2EbmG/bwjcD8IaMsgJPSsMO2Bpd
-3S6qWgkCeOyCfmAwBxK2kNbxGb63ouysEv7l8GCTJTWv3hG/HQcejJpnAEGi6K1U
-fDbyE/db6yZ12SoHVTGkadN4vYGCPd1Wj9ZO1F877SHQ8rDWX3xgTWkxN2ojBw44
-T8RHSDiG8D/CvG4uEy+VUszL+Uvny5y2poNSqvI3J56sptWSrh8nIIbkPZPBdUne
-LYMOHTFK3ZjXSmhlXgziTxK71nnzM3Y9K9gxPnRqoXbvu/wFo55hQCkETiRkYgmm
-jXcBMZ0TClQVnQWuLjMthRnWFZs4Lfmwqjs7FZD/61581R2BYehvpWbLvvuOJhwv
-DFzexL2sXcAl7SsxbzeQKRHqGbIDfbnQTXfs3/VC6Ye5P82P2ucj+XC32N9piRmO
-gCBP8L3ub+YzzdxikZN2gZXXE2jsb3QyE/R2LkWdWyshpKe+RsZP1SBRbHShUyOh
-yJ90baoiEwj2mwIDAQABoxgwFjAUBgNVHREEDTALgglsb2NhbGhvc3QwDQYJKoZI
-hvcNAQELBQADggGBAHRUO/UIHl3jXQENewYayHxkIx8t7nu40iO2DXbicSijz5bo
-5//xAB6RxhBAlsDBehgQP1uoZg+WJW+nHu3CIVOU3qZNZRaozxiCl2UFKcNqLOmx
-R3NKpo1jYf4REQIeG8Yw9+hSWLRbshNteP6bKUUf+vanhg9+axyOEOH/iOQvgk/m
-b8wA8wNa4ujWljPbTQnj7ry8RqhTM0GcAN5LSdSvcKcpzLcs3aYwh+Z8e30sQWna
-F40sa5u7izgBTOrwpcDm/w5kC46vpRQ5fnbshVw6pne2by0mdMECASid/p25N103
-jMqTFlmO7kpf/jpCSmamp3/JSEE1BJKHwQ6Ql4nzRA2N1mnvWH7Zxcv043gkHeAu
-0x8evpvwuhdIyproejNFlBpKmW8OX7yKTCPPMC/VkX8Q1rVkxU0DQ6hmvwZlhoKa
-9Wc2uXpw9xF8itV4Uvcdr3dwqByvIqn7iI/gB+4l41e0u8OmH2MKOx4Nxlly5TNW
-HcVKQHyOeyvnINuBAQ==
------END CERTIFICATE-----
-
diff --git a/Lib/test/keycert.pem b/Lib/test/keycert.pem
deleted file mode 100644
index 0d39863373..0000000000
--- a/Lib/test/keycert.pem
+++ /dev/null
@@ -1,66 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/wIBADANBgkqhkiG9w0BAQEFAASCBukwggblAgEAAoIBgQCylKlLaKU+hOvJ
-DfriTRLd+IthG5hv28I3A/CGjLICT0rDDtgaXd0uqloJAnjsgn5gMAcStpDW8Rm+
-t6LsrBL+5fBgkyU1r94Rvx0HHoyaZwBBouitVHw28hP3W+smddkqB1UxpGnTeL2B
-gj3dVo/WTtRfO+0h0PKw1l98YE1pMTdqIwcOOE/ER0g4hvA/wrxuLhMvlVLMy/lL
-58uctqaDUqryNyeerKbVkq4fJyCG5D2TwXVJ3i2DDh0xSt2Y10poZV4M4k8Su9Z5
-8zN2PSvYMT50aqF277v8BaOeYUApBE4kZGIJpo13ATGdEwpUFZ0Fri4zLYUZ1hWb
-OC35sKo7OxWQ/+tefNUdgWHob6Vmy777jiYcLwxc3sS9rF3AJe0rMW83kCkR6hmy
-A3250E137N/1QumHuT/Nj9rnI/lwt9jfaYkZjoAgT/C97m/mM83cYpGTdoGV1xNo
-7G90MhP0di5FnVsrIaSnvkbGT9UgUWx0oVMjocifdG2qIhMI9psCAwEAAQKCAYBT
-sHmaPmNaZj59jZCqp0YVQlpHWwBYQ5vD3pPE6oCttm0p9nXt/VkfenQRTthOtmT1
-POzDp00/feP7zeGLmqSYUjgRekPw4gdnN7Ip2PY5kdW77NWwDSzdLxuOS8Rq1MW9
-/Yu+ZPe3RBlDbT8C0IM+Atlh/BqIQ3zIxN4g0pzUlF0M33d6AYfYSzOcUhibOO7H
-j84r+YXBNkIRgYKZYbutRXuZYaGuqejRpBj3voVu0d3Ntdb6lCWuClpB9HzfGN0c
-RTv8g6UYO4sK3qyFn90ibIR/1GB9watvtoWVZqggiWeBzSWVWRsGEf9O+Cx4oJw1
-IphglhmhbgNksbj7bD24on/icldSOiVkoUemUOFmHWhCm4PnB1GmbD8YMfEdSbks
-qDr1Ps1zg4mGOinVD/4cY7vuPFO/HCH07wfeaUGzRt4g0/yLr+XjVofOA3oowyxv
-JAzr+niHA3lg5ecj4r7M68efwzN1OCyjMrVJw2RAzwvGxE+rm5NiT08SWlKQZnkC
-gcEA4wvyLpIur/UB84nV3XVJ89UMNBLm++aTFzld047BLJtMaOhvNqx6Cl5c8VuW
-l261KHjiVzpfNM3/A2LBQJcYkhX7avkqEXlj57cl+dCWAVwUzKmLJTPjfaTTZnYJ
-xeN3dMYjJz2z2WtgvfvDoJLukVwIMmhTY8wtqqYyQBJ/l06pBsfw5TNvmVIOQHds
-8ASOiFt+WRLk2bl9xrGGayqt3VV93KVRzF27cpjOgEcG74F3c0ZW9snERN7vIYwB
-JfrlAoHBAMlahPwMP2TYylG8OzHe7EiehTekSO26LGh0Cq3wTGXYsK/q8hQCzL14
-kWW638vpwXL6L9ntvrd7hjzWRO3vX/VxnYEA6f0bpqHq1tZi6lzix5CTUN5McpDg
-QnjenSJNrNjS1zEF8WeY9iLEuDI/M/iUW4y9R6s3WpgQhPDXpSvd2g3gMGRUYhxQ
-Xna8auiJeYFq0oNaOxvJj+VeOfJ3ZMJttd+Y7gTOYZcbg3SdRb/kdxYki0RMD2hF
-4ZvjJ6CTfwKBwQDiMqiZFTJGQwYqp4vWEmAW+I4r4xkUpWatoI2Fk5eI5T9+1PLX
-uYXsho56NxEU1UrOg4Cb/p+TcBc8PErkGqR0BkpxDMOInTOXSrQe6lxIBoECVXc3
-HTbrmiay0a5y5GfCgxPKqIJhfcToAceoVjovv0y7S4yoxGZKuUEe7E8JY2iqRNAO
-yOvKCCICv/hcN235E44RF+2/rDlOltagNej5tY6rIFkaDdgOF4bD7f9O5eEni1Bg
-litfoesDtQP/3rECgcEAkQfvQ7D6tIPmbqsbJBfCr6fmoqZllT4FIJN84b50+OL0
-mTGsfjdqC4tdhx3sdu7/VPbaIqm5NmX10bowWgWSY7MbVME4yQPyqSwC5NbIonEC
-d6N0mzoLR0kQ+Ai4u+2g82gicgAq2oj1uSNi3WZi48jQjHYFulCbo246o1NgeFFK
-77WshYe2R1ioQfQDOU1URKCR0uTaMHClgfu112yiGd12JAD+aF3TM0kxDXz+sXI5
-SKy311DFxECZeXRLpcC3AoHBAJkNMJWTyPYbeVu+CTQkec8Uun233EkXa2kUNZc/
-5DuXDaK+A3DMgYRufTKSPpDHGaCZ1SYPInX1Uoe2dgVjWssRL2uitR4ENabDoAOA
-ICVYXYYNagqQu5wwirF0QeaMXo1fjhuuHQh8GsMdXZvYEaAITZ9/NG5x/oY08+8H
-kr78SMBOPy3XQn964uKG+e3JwpOG14GKABdAlrHKFXNWchu/6dgcYXB87mrC/GhO
-zNwzC+QhFTZoOomFoqMgFWujng==
------END PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-MIIEWTCCAsGgAwIBAgIJAJinz4jHSjLtMA0GCSqGSIb3DQEBCwUAMF8xCzAJBgNV
-BAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9u
-IFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODA4
-MjkxNDIzMTVaFw0yODA4MjYxNDIzMTVaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQH
-DA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5k
-YXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGP
-ADCCAYoCggGBALKUqUtopT6E68kN+uJNEt34i2EbmG/bwjcD8IaMsgJPSsMO2Bpd
-3S6qWgkCeOyCfmAwBxK2kNbxGb63ouysEv7l8GCTJTWv3hG/HQcejJpnAEGi6K1U
-fDbyE/db6yZ12SoHVTGkadN4vYGCPd1Wj9ZO1F877SHQ8rDWX3xgTWkxN2ojBw44
-T8RHSDiG8D/CvG4uEy+VUszL+Uvny5y2poNSqvI3J56sptWSrh8nIIbkPZPBdUne
-LYMOHTFK3ZjXSmhlXgziTxK71nnzM3Y9K9gxPnRqoXbvu/wFo55hQCkETiRkYgmm
-jXcBMZ0TClQVnQWuLjMthRnWFZs4Lfmwqjs7FZD/61581R2BYehvpWbLvvuOJhwv
-DFzexL2sXcAl7SsxbzeQKRHqGbIDfbnQTXfs3/VC6Ye5P82P2ucj+XC32N9piRmO
-gCBP8L3ub+YzzdxikZN2gZXXE2jsb3QyE/R2LkWdWyshpKe+RsZP1SBRbHShUyOh
-yJ90baoiEwj2mwIDAQABoxgwFjAUBgNVHREEDTALgglsb2NhbGhvc3QwDQYJKoZI
-hvcNAQELBQADggGBAHRUO/UIHl3jXQENewYayHxkIx8t7nu40iO2DXbicSijz5bo
-5//xAB6RxhBAlsDBehgQP1uoZg+WJW+nHu3CIVOU3qZNZRaozxiCl2UFKcNqLOmx
-R3NKpo1jYf4REQIeG8Yw9+hSWLRbshNteP6bKUUf+vanhg9+axyOEOH/iOQvgk/m
-b8wA8wNa4ujWljPbTQnj7ry8RqhTM0GcAN5LSdSvcKcpzLcs3aYwh+Z8e30sQWna
-F40sa5u7izgBTOrwpcDm/w5kC46vpRQ5fnbshVw6pne2by0mdMECASid/p25N103
-jMqTFlmO7kpf/jpCSmamp3/JSEE1BJKHwQ6Ql4nzRA2N1mnvWH7Zxcv043gkHeAu
-0x8evpvwuhdIyproejNFlBpKmW8OX7yKTCPPMC/VkX8Q1rVkxU0DQ6hmvwZlhoKa
-9Wc2uXpw9xF8itV4Uvcdr3dwqByvIqn7iI/gB+4l41e0u8OmH2MKOx4Nxlly5TNW
-HcVKQHyOeyvnINuBAQ==
------END CERTIFICATE-----
diff --git a/Lib/test/keycert2.pem b/Lib/test/keycert2.pem
deleted file mode 100644
index e59d45439d..0000000000
--- a/Lib/test/keycert2.pem
+++ /dev/null
@@ -1,66 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/QIBADANBgkqhkiG9w0BAQEFAASCBucwggbjAgEAAoIBgQCf8FWxi4oVlDVx
-e8NDFgb+IYAGr/hZWuY1Zq7d7g57yPoxJrgt+bN89+U7qTduqyB2Hy8G0TqeACOr
-IdpPZ8P7V5E5YiASwfJ72nbVo7qR9DAKA5FE8PU0bJFmFLjDDihc970zc4ilRDfR
-WylUpj68nefOY4CzFzeiqVOLX2wezs7Z0hflkSXGBmC0j1FbQU2I3YJg3CKCabhT
-tU6OyKItzjJ2vVaOoQ+B0Kv8leaRQ6ANZBAFQF2LepSy5F2+oSD+QHjPr+012V5D
-mrsdIc9We8YyonS1u/3HI7lLohf3W+qFroQWjn0DJI56ScV1uEr/B0+hn2jBRTM5
-d1F9BeVWm1u8BOJu50CvOeuxiVLsxJpa4T41DJznJk5V+hE4hKvDKmlrwulsRp8o
-jUEyUi8dzWOBRfAijIWv3qAPjGA/J33n6+PllCczC2BsVZhVmLqSMCwp1g2JTCM/
-KC7T4vOl/EGkm76fcmLeA1Ef8oUdRg+3T77VP+HqZ2JP06J8O8MCAwEAAQKCAYAw
-YvJZ82BEJQGCIrIxMpHNAm+MFmKpDdIFp9oRdDrXgjcG9bLU3e1KSmkEgq4tggIh
-GlAM3PHB6ULhPC2ixj7JZHWgCaqwYhKtG6vF+HGyRFDgRrIFTGyyfoICgxReloLp
-lV2dGj/l19yXLuAzJtRmFdOSYhIGnGiNgnKvAKBiNajoxyHJpv7piPZqyc0QMZJ2
-bKVMDm02TSuhz4FDuzktaGtl9uQf5GQfnvTZRrRpkC70vigGnrFuSBiCgopF6NLq
-6AXl8YS3Jcu2oGWrZDfS/GlG1QmvGGsmr9wndJSGG43jcpcRZt0g1nJNu4Fioq3e
-7y6Gap9TEsciuQOv/6RD457XkNARmTQxFpEwmSgOPQn2pFcDspo71Ej7azzL/Z+3
-jvnVo3wxgxBcrpyh+vhBtJARp4pT4anW4PcD6IcPSOWbnI8Ldoj1XN5QkJcBcykK
-6LmsAUqsmEQDNsmnGZWyYSCns4P2vUJi0hwQz8UiQwgAta3xnq4v5On7l3cq35kC
-gcEA0+joOFbZBeGlCb27tDW4VCW0cQuczzuNEoBUKnsNSqy0nx1O7hgHm/f/NQDD
-cpxiD15bRQ0KM9QbQC4dGaVoLsM07hUGk97dCxQPs2zot4CodCKGohs7E154tEDP
-zVg3YS5mubUmqdqtn8ZCKeeZye/Tv2ageyF300sEgj2Cd7EZ8S4sB0PxZ2tqT3jy
-cBL5cDruLEWuHIQjN7WwSjxnXocpb1OU7dJ+v4zFPCkSCOoa0DTTw4jFhPEOBdqV
-T619AoHBAME3QyW4QVtU2Ct9u0B1XThhqSEyOpUrcH9nOoefggwP4WF3phVx16BG
-aDKUIGQ62klRa5fi2eooxcjQRLv1sWO0UzssnO6ABMnGkUiRdrowo6xukNak0RTp
-0gvNoJ0SZxGF0yWSCw1Rq3qP2Koj7XDumFChAzLMyUsnoOl29SA7GfXcZp1pZTiq
-kOfFMWt0CIHu/EK03YWcd4vfQEq6lus39RCSXuL++Jva3yiEl5s069RFZvP1bNrD
-emkfetDSPwKBwQClk+8fVnzs44sZOW9ZOEB3P57mVbSJGHb6Zdtd9hhEqP3Y9gWe
-dJg9fmGjAJ23CAp3B7s5ER9PsAQ6+c0zJNNq9ox9G2CwWgtNhLdf81FDUPxPAktA
-jxZx4/dcoOe+A5gCD0elA67aOUxA86DvLVA1QXeqrn3muBfwuUUknvs6mt8yXGl6
-o9QUgxHmVxLYD3tn/iPr4+ZP0c/Sz9yXpOsAKYxuuFg+G6N9+HiEsXKuFH4vAZgV
-yODNJ61VVZ4lS+ECgcAqFqOl39E81+qO7sCPdgFsermg5ZQlUmUbG52AVZq6jesG
-lE21disGWs/v1JyJuNg8CGRrnZriiycqa1PNreOKWImY5kr5GSHx4jNbn3RBcr70
-nNEoMJbq+1QqBgzqqkuRYZlxIbMOn6++7v6/cTwT0aWUSr6rnjhrCqLeuG8FKlqp
-V+1ydLb79QvDsQzm30vLIggJb+ShakgQS/1xSdv+OR5FEd1hjTESokbiSJ/Ny2Vj
-xAp9MgUYUmSj6ZuTSXkCgcAggshdRQLom/EK2pYwffIpKfBiyLbi+KIjKxkiPEsb
-jrrQbvh9ZN6iAG3StVAYB5c6vewfeIlcDT0YJDyy1hGRLRG7vf9ubPf+n7Xp1y0W
-oo9L9qfCHu0jmWwtinkFYjpTDkXlxXCG2v3TllNsNX/5afYo8sb9oxXHLTpBlwZB
-fw6IgNZblWQevdgmUMTP9W2W7AZUxEz4gOM6lQkOwC3U59Dx2yO6rD3An6G1tlZF
-2MClyf8o5d5ePObH8rkxrpY=
------END PRIVATE KEY-----
------BEGIN CERTIFICATE-----
-MIIEbTCCAtWgAwIBAgIUF15VKdwjiTzzKgs6PnNpEekV9QQwDQYJKoZIhvcNAQEL
-BQAwYjELMAkGA1UEBhMCWFkxFzAVBgNVBAcMDkNhc3RsZSBBbnRocmF4MSMwIQYD
-VQQKDBpQeXRob24gU29mdHdhcmUgRm91bmRhdGlvbjEVMBMGA1UEAwwMZmFrZWhv
-c3RuYW1lMB4XDTIxMDMxNzA4NDgyMFoXDTQwMDUxNjA4NDgyMFowYjELMAkGA1UE
-BhMCWFkxFzAVBgNVBAcMDkNhc3RsZSBBbnRocmF4MSMwIQYDVQQKDBpQeXRob24g
-U29mdHdhcmUgRm91bmRhdGlvbjEVMBMGA1UEAwwMZmFrZWhvc3RuYW1lMIIBojAN
-BgkqhkiG9w0BAQEFAAOCAY8AMIIBigKCAYEAn/BVsYuKFZQ1cXvDQxYG/iGABq/4
-WVrmNWau3e4Oe8j6MSa4LfmzfPflO6k3bqsgdh8vBtE6ngAjqyHaT2fD+1eROWIg
-EsHye9p21aO6kfQwCgORRPD1NGyRZhS4ww4oXPe9M3OIpUQ30VspVKY+vJ3nzmOA
-sxc3oqlTi19sHs7O2dIX5ZElxgZgtI9RW0FNiN2CYNwigmm4U7VOjsiiLc4ydr1W
-jqEPgdCr/JXmkUOgDWQQBUBdi3qUsuRdvqEg/kB4z6/tNdleQ5q7HSHPVnvGMqJ0
-tbv9xyO5S6IX91vqha6EFo59AySOeknFdbhK/wdPoZ9owUUzOXdRfQXlVptbvATi
-budArznrsYlS7MSaWuE+NQyc5yZOVfoROISrwyppa8LpbEafKI1BMlIvHc1jgUXw
-IoyFr96gD4xgPyd95+vj5ZQnMwtgbFWYVZi6kjAsKdYNiUwjPygu0+LzpfxBpJu+
-n3Ji3gNRH/KFHUYPt0++1T/h6mdiT9OifDvDAgMBAAGjGzAZMBcGA1UdEQQQMA6C
-DGZha2Vob3N0bmFtZTANBgkqhkiG9w0BAQsFAAOCAYEARzdkuqa0Hexi/saMkdi3
-bubpQkc7X0RYKWnjy/PgcmbvQXLiWRMZOH9rMWvd5v+ZfkgAtsbOQuP8ycioNIFY
-Il5SEmxHEN81z5UNSPLOib6ky13gzrnXRAxnnO7cICG7AaMu1dHv57fqjevcx/n/
-nxPNKwKL+TDpMw7ATVZw7Py7JciKyFAfwtkvt17j/ldvaQvuwmWHzyFVrQniQcQq
-QEa4jy/Y/pXHAgCKq1qbe0ush17j1ChyH7l4SkF2xJKcYYQF5ipw8zg6WeOL2NFE
-G1KDJN0SsMmM3PMN1e0lLQP3G+UaatervrKXu51QleKL32Xlby+pp1w9KKs39/Tb
-RT8EMe9A6cecod6TL0ZUQHow6ykNYBkfSKDLTKWnL9ifZ0C/DvgmS7DpJg3oAa1e
-GhIglMrgqJflTHAI/PvEsCKM1O0Un2dVGWsUCzPfhj1cKmagyb0Zd+2Tk9xGSRs9
-2ceXMxRCjOJwEHUCFuTYeqowabdlpi0nyPbSn7JIwCpT
------END CERTIFICATE-----
diff --git a/Lib/test/keycert3.pem b/Lib/test/keycert3.pem
deleted file mode 100644
index f6887ba7a8..0000000000
--- a/Lib/test/keycert3.pem
+++ /dev/null
@@ -1,164 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/gIBADANBgkqhkiG9w0BAQEFAASCBugwggbkAgEAAoIBgQDFtLOteQlQojN7
-ztkux7m0hmGKkP1hh0hbKqTcD87jkLAqAwZWenjZMjCbbZ3vP+AObCIkYIKzPXY7
-Yi+H5M3O2mXIDxoHGjL/GWtoEyDNXvm9UC+MRuSOq2MaLHHQG0Rx2TxcYrMVUM7b
-93rpN1LGRrCv1gISXM4EvEJooAR7Aadj0pG/o0fqDAdFjH6QZbhn1iZle+eGbjcf
-dgH/H0F8dn1PPGoViHXicbsQ4kB6002Pf+aXP4b2QKAbflyNHEKHPHEOOTXrFjMd
-c+bqKW24epEsMZI59qx9hU/4Rvp3/v+vEwTL7Nm7ilptzZn2cvGCW39LC0nNYLOz
-kO3H8xwA75h6uykdB+WO/v2CKIK9M/ZO+9QNrmaokfKDamCk39b8hlCwNL6LsVpv
-d3XTS5Wn4YWn92EqiltUJJoPo7pc7VTdWCg4zVFn4Q8Zh4NFNn/qTB8lEMgrsNTV
-5cyZ7zhoBiUMSO45bmo2NsnE7ce/JUhlqe5uh0PT1MIBgTV+oDMCAwEAAQKCAYEA
-udsy4gwblqK0tVnxz0lQqYV+os3EdO/BNHr1Oi7eNg2pngTz603812mYSjUVOHma
-vtQmkH3twGQyBoc52Y1dcGzdK+IOfMjDUg7qao840ffL3I1J9ZwbdodlhZBsec94
-W3J1jP/4DDzICf8vm5g3h0+i/9m2Xt7BibAU2dg7/grC+lNUUoxDqaEfIOF/hW0q
-muq1c8e0EisAROIh5FzUqhWVnWxU6eM7tuFlkuyu4whLLHB3LI466Lo+CTqT9M+v
-jJYlvS5+AZW3qMBp6WOI8C+VIiBL178mo+Igkyyy5AYXcWeNkjp6ygRWvtWXIhCv
-CI29mf+BP/54jAY0rQRXJ2UcSHXmM6PTDkE/L2OKeiY1Ou8gLOwun3yBVdbkXJMb
-PWmUW4N8qSIJQ+vE2TDqmkqAT6m+ilzOXl1O+LLTvGyMnOiiSLXK9mC4ND3tqaQu
-hvKivnI1doErcWUaIf1DHiJmLrGxrTCUKjCEoefqVq2/dDdtCfx7CqUvjl3DYKMB
-AoHBAP+Vdi6D07gZFepEGCaJ+YH6cxEyO73CNnea/F1whVAzOv91kHS32jC9PAI3
-/wYlX+DLcN9mVF/q62V4SLZYfOxTPW4vWO0A45URe9s9Z795fdAcQ5jt3QFOVSnk
-3XSaCkIOwckuwabGJi4+foiUEOnLLzQi1/g7x12dwejxVNhqhz5KFkOQPv8fQRed
-sb5LVLYDeprsB2Vsx0fHwg4z9FvTIxLBeI7+sJD30lNpYZrCl/T9x4e1SV2Rwn2W
-bghxgQKBwQDGBx07biZK9RB5g4qPl+G6vz0M+/KBfpwQbMYxSyct7u6gfGD9mWBO
-qocIIr39Unac3kUL237Cn3HbgiGCRe7Mwd7XqnSSGWM5oWSlVQxEKTXYUlTbd9O9
-DKuyQGOl/AMEwD4ZbEOfQNmnd1U4nh1AV052FQY8Ry/atGFT9fApA/5X/bbenOwQ
-YGDsokLzPf2BIDncpE+VNevUMoMI7EnySgjjfpL+cRld0qpLqBMo2h5VddeJ/5YM
-1YcNfMQiw7MCgcEAwXqXuKa7A8aZvHpH/gS9CRRbP01TxFbdfLWrDeE8SnY9111c
-Ob9kQTk/0D4rpK9uYXIgxD1m6iWghXQFN2TNTOnGuz7EhsYBgrt1k4Zsn5qND5oV
-4hNPFsoB1nEW5EooMdGSCYaHuoSOKrvMdgAAvbu+xC0MaTJ3vfrK7Fik7h/WueTD
-7emohuFWGVabU38bZZ5EljrPboxmX4Rs9uuFtG2lQ3GKnlVXvKaeZd6EsO9WsXPc
-NHOcUmUhYokaSvIBAoHAGCxGJTsM8Zl4qVylTWH87A7sJOmccLJD2r1sdBf4cGL6
-PhzwugQ+/VtToGqdRo8Ka5u2Ufw5PQi5nVIFRSHERLpluW3VTQBMXHyXDJeVJ7zg
-Fcf3E9NMxYcGbnvtrhVVSP8ulWvh1U7VQtwOSxsB9xixOzjVygXmkYvzVYxwBJG4
-OoV+DS6aomUhb8Fe6tJmX5zPc1+bV1t9ril8VVqCrFDdROfuiaDEt+8/Wnzp2dLG
-YShBZ1cLugVWtw7D4nqBAoHAF29k64iAxY5Y4OOibVkqjUCPyqG2oxiXqgO7CxZp
-FGUat5UtV2mIBlSENs1o5AZ1nPlgWtPtg0xVCaG2t/Rq7ugvUfAnAhUK6zX8FS+T
-gCXE+7iKuuIJiCo13/iAwF/CLfuXvj4CZ71ta0wX9w99f1FcPEk0x+ytiyuWJK8K
-tyubL34JwNrnkh/8e3LcV3L88Sk9ZmxeTz31f3cA3Fy2ZJOAUMD9dKXeKtY7azzt
-MkhXedRsdLSKqMh0VGeGHoLS
------END PRIVATE KEY-----
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:5c
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=localhost
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                RSA Public-Key: (3072 bit)
-                Modulus:
-                    00:c5:b4:b3:ad:79:09:50:a2:33:7b:ce:d9:2e:c7:
-                    b9:b4:86:61:8a:90:fd:61:87:48:5b:2a:a4:dc:0f:
-                    ce:e3:90:b0:2a:03:06:56:7a:78:d9:32:30:9b:6d:
-                    9d:ef:3f:e0:0e:6c:22:24:60:82:b3:3d:76:3b:62:
-                    2f:87:e4:cd:ce:da:65:c8:0f:1a:07:1a:32:ff:19:
-                    6b:68:13:20:cd:5e:f9:bd:50:2f:8c:46:e4:8e:ab:
-                    63:1a:2c:71:d0:1b:44:71:d9:3c:5c:62:b3:15:50:
-                    ce:db:f7:7a:e9:37:52:c6:46:b0:af:d6:02:12:5c:
-                    ce:04:bc:42:68:a0:04:7b:01:a7:63:d2:91:bf:a3:
-                    47:ea:0c:07:45:8c:7e:90:65:b8:67:d6:26:65:7b:
-                    e7:86:6e:37:1f:76:01:ff:1f:41:7c:76:7d:4f:3c:
-                    6a:15:88:75:e2:71:bb:10:e2:40:7a:d3:4d:8f:7f:
-                    e6:97:3f:86:f6:40:a0:1b:7e:5c:8d:1c:42:87:3c:
-                    71:0e:39:35:eb:16:33:1d:73:e6:ea:29:6d:b8:7a:
-                    91:2c:31:92:39:f6:ac:7d:85:4f:f8:46:fa:77:fe:
-                    ff:af:13:04:cb:ec:d9:bb:8a:5a:6d:cd:99:f6:72:
-                    f1:82:5b:7f:4b:0b:49:cd:60:b3:b3:90:ed:c7:f3:
-                    1c:00:ef:98:7a:bb:29:1d:07:e5:8e:fe:fd:82:28:
-                    82:bd:33:f6:4e:fb:d4:0d:ae:66:a8:91:f2:83:6a:
-                    60:a4:df:d6:fc:86:50:b0:34:be:8b:b1:5a:6f:77:
-                    75:d3:4b:95:a7:e1:85:a7:f7:61:2a:8a:5b:54:24:
-                    9a:0f:a3:ba:5c:ed:54:dd:58:28:38:cd:51:67:e1:
-                    0f:19:87:83:45:36:7f:ea:4c:1f:25:10:c8:2b:b0:
-                    d4:d5:e5:cc:99:ef:38:68:06:25:0c:48:ee:39:6e:
-                    6a:36:36:c9:c4:ed:c7:bf:25:48:65:a9:ee:6e:87:
-                    43:d3:d4:c2:01:81:35:7e:a0:33
-                Exponent: 65537 (0x10001)
-        X509v3 extensions:
-            X509v3 Subject Alternative Name: 
-                DNS:localhost
-            X509v3 Key Usage: critical
-                Digital Signature, Key Encipherment
-            X509v3 Extended Key Usage: 
-                TLS Web Server Authentication, TLS Web Client Authentication
-            X509v3 Basic Constraints: critical
-                CA:FALSE
-            X509v3 Subject Key Identifier: 
-                85:75:10:25:D0:2C:80:50:24:1A:5B:57:70:DE:B5:CB:71:A9:3B:7B
-            X509v3 Authority Key Identifier: 
-                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
-                serial:CB:2D:80:99:5A:69:52:5B
-
-            Authority Information Access: 
-                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
-                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
-
-            X509v3 CRL Distribution Points: 
-
-                Full Name:
-                  URI:http://testca.pythontest.net/testca/revocation.crl
-
-    Signature Algorithm: sha256WithRSAEncryption
-         95:f3:56:bb:d5:8c:70:bd:d1:de:da:63:b0:29:d7:db:60:27:
-         d6:59:fd:61:1b:30:c6:d0:5d:73:7d:34:e1:68:e3:28:a6:89:
-         e6:60:bd:89:d3:0e:f4:72:ad:72:76:f8:86:21:fd:75:3c:f8:
-         6d:be:9c:04:e1:82:03:69:6c:ae:d0:55:ba:5e:f2:ca:f5:0f:
-         8e:d6:d9:8d:c8:56:46:f4:f8:ac:74:2a:19:7b:8e:47:70:1f:
-         fb:fb:bd:69:02:a1:a5:4a:6e:21:1c:04:14:15:55:bf:bf:24:
-         43:c8:17:03:be:3e:2c:ea:db:c8:af:1d:fd:52:df:d6:15:49:
-         9e:c2:44:69:ef:f1:45:43:83:b2:1e:cf:14:1c:13:3f:fe:9c:
-         71:cb:e7:1b:18:56:36:a7:af:44:f1:0b:a1:79:44:46:f9:43:
-         46:29:d8:b0:ca:49:4d:65:60:d3:f6:8e:74:bc:62:9e:1e:8d:
-         4b:29:9a:b4:0d:f0:a2:77:5b:34:e4:11:2f:a7:25:c5:e5:07:
-         76:12:ae:be:75:73:15:e4:0a:7d:53:38:56:3f:79:6d:6e:ca:
-         ed:80:ab:56:ed:7e:8b:1c:e7:e3:d4:62:30:22:70:e7:29:b2:
-         03:3c:fe:fa:3d:f0:36:c0:4d:11:a2:99:d3:29:31:27:b8:c5:
-         b8:15:a3:3c:4f:9b:73:5e:2b:b2:fb:cb:fd:75:47:b8:17:bd:
-         21:d8:e6:c1:b9:ff:73:81:d8:25:08:6d:08:5e:1c:a5:83:50:
-         de:67:e6:da:d0:8e:5a:d3:f2:2a:b1:3f:b8:80:21:07:6a:71:
-         15:6d:05:eb:51:b3:59:8d:d4:15:46:7e:02:a8:13:01:16:99:
-         bd:03:cc:70:71:2a:23:16:78:af:d1:d5:01:9d:04:b4:63:93:
-         9a:04:3a:92:2e:e6:7e:73:93:a5:fe:50:9b:bd:0e:ea:54:86:
-         6f:7c:e5:14:77:fe:c2:28:5a:4a:0e:d7:2d:8c:e9:ed:61:29:
-         b2:53:ff:6c:04:bc
------BEGIN CERTIFICATE-----
-MIIF8TCCBFmgAwIBAgIJAMstgJlaaVJcMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
-MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxv
-Y2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGPADCCAYoCggGBAMW0s615CVCi
-M3vO2S7HubSGYYqQ/WGHSFsqpNwPzuOQsCoDBlZ6eNkyMJttne8/4A5sIiRggrM9
-djtiL4fkzc7aZcgPGgcaMv8Za2gTIM1e+b1QL4xG5I6rYxoscdAbRHHZPFxisxVQ
-ztv3euk3UsZGsK/WAhJczgS8QmigBHsBp2PSkb+jR+oMB0WMfpBluGfWJmV754Zu
-Nx92Af8fQXx2fU88ahWIdeJxuxDiQHrTTY9/5pc/hvZAoBt+XI0cQoc8cQ45NesW
-Mx1z5uopbbh6kSwxkjn2rH2FT/hG+nf+/68TBMvs2buKWm3NmfZy8YJbf0sLSc1g
-s7OQ7cfzHADvmHq7KR0H5Y7+/YIogr0z9k771A2uZqiR8oNqYKTf1vyGULA0voux
-Wm93ddNLlafhhaf3YSqKW1Qkmg+julztVN1YKDjNUWfhDxmHg0U2f+pMHyUQyCuw
-1NXlzJnvOGgGJQxI7jluajY2ycTtx78lSGWp7m6HQ9PUwgGBNX6gMwIDAQABo4IB
-wDCCAbwwFAYDVR0RBA0wC4IJbG9jYWxob3N0MA4GA1UdDwEB/wQEAwIFoDAdBgNV
-HSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/BAIwADAdBgNVHQ4E
-FgQUhXUQJdAsgFAkGltXcN61y3GpO3swfQYDVR0jBHYwdIAUs4qgorpx8agkedSk
-WyU2FR5JyM2hUaRPME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29m
-dHdhcmUgRm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcoIJAMst
-gJlaaVJbMIGDBggrBgEFBQcBAQR3MHUwPAYIKwYBBQUHMAKGMGh0dHA6Ly90ZXN0
-Y2EucHl0aG9udGVzdC5uZXQvdGVzdGNhL3B5Y2FjZXJ0LmNlcjA1BggrBgEFBQcw
-AYYpaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2Evb2NzcC8wQwYD
-VR0fBDwwOjA4oDagNIYyaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0
-Y2EvcmV2b2NhdGlvbi5jcmwwDQYJKoZIhvcNAQELBQADggGBAJXzVrvVjHC90d7a
-Y7Ap19tgJ9ZZ/WEbMMbQXXN9NOFo4yimieZgvYnTDvRyrXJ2+IYh/XU8+G2+nATh
-ggNpbK7QVbpe8sr1D47W2Y3IVkb0+Kx0Khl7jkdwH/v7vWkCoaVKbiEcBBQVVb+/
-JEPIFwO+Pizq28ivHf1S39YVSZ7CRGnv8UVDg7IezxQcEz/+nHHL5xsYVjanr0Tx
-C6F5REb5Q0Yp2LDKSU1lYNP2jnS8Yp4ejUspmrQN8KJ3WzTkES+nJcXlB3YSrr51
-cxXkCn1TOFY/eW1uyu2Aq1btfosc5+PUYjAicOcpsgM8/vo98DbATRGimdMpMSe4
-xbgVozxPm3NeK7L7y/11R7gXvSHY5sG5/3OB2CUIbQheHKWDUN5n5trQjlrT8iqx
-P7iAIQdqcRVtBetRs1mN1BVGfgKoEwEWmb0DzHBxKiMWeK/R1QGdBLRjk5oEOpIu
-5n5zk6X+UJu9DupUhm985RR3/sIoWkoO1y2M6e1hKbJT/2wEvA==
------END CERTIFICATE-----
diff --git a/Lib/test/keycert4.pem b/Lib/test/keycert4.pem
deleted file mode 100644
index 1003d67fd0..0000000000
--- a/Lib/test/keycert4.pem
+++ /dev/null
@@ -1,164 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/gIBADANBgkqhkiG9w0BAQEFAASCBugwggbkAgEAAoIBgQC34y3S6iXdmdvd
-M/2aFBe6CvRvZwhh1huGl7IQRtdoakPqMLlEdNHJtNeF5M27xLei+p4wt7N1Jyi0
-2keHQb1m9TqH5AruOkE2ti+15zEoKoU9aWydTiH+epKTT0yjg2NcKQjRUaWcbhzB
-H4EMKuCIlzIIz8/EIKkOqhCDwq6+Fv3Ays+z7Bz+yR80ixivKu/l7SjxQ7z7R/kC
-I7OViRcIO5QBQPj7VLvCTz4VA6u/LdXngK2HNuau6WXm5yNNQbqrB11AEJcYZf/c
-VrneV4F+ZjLloAKgSn9GB8eWOyilTQ18TcKd+H2icipRaP/+QR/KPx5GK/SXU3my
-qm62QOGI7t/5ktVdjGhs6tHZxw1SRiipiLYWbtVRrSxa4wYlgpgoUwvrvvtC5kAN
-nTw1VGWsxcs+6a7+PocYnJiq7k4b5OAUb3Ryvl9DLAMy8NqpRWo4cHD/XQ3FCYwF
-HlOSgx/dL5Se0i3dW1KzbP6OvaNg6nl/1EXPUsJ1ATS8nzvzhccCAwEAAQKCAYEA
-nD3GvaJ9MeB802JNZBEWZ9jO/6jHknldQeq6POI0PF+t/NoRUH0BkyS4yucxdw0a
-CrxulG5BaJUxHRkqFV5iE4zhgnzcXLXamyYJO8GIHtyiASAGTVIJyDNVPxztvTDx
-x2iGOXPqBxP4Eo82EqSLywLMXHhVzAsEGZWeGpXb61+Vk62+9Nz1dfZlMTvOaWdO
-Fkp/sx8e/1KT3KGBANlOXIxioP4Xj1Tbg6nY0fogf3vud5j52B1pu8xL7PkPIaFq
-DEGz3XvWhBF/+Cs5iDeYz8eQpfQig7HdHVn2D8dZmzQgpLw1yGbPAnqrgopWfm7R
-MqiyFe82p2t+vfSoG5jz28XxPtzBJV3ljxKxlbnclqu/CAYSjzaYohDzyhjdZOZI
-r9DOfWOqu01Ha3EEsApn95fusHHGTH2FOy0u61FSTrfLfqsLw9WRJPWleirKikhf
-SZzi223QrmzZMtuCF7VgTx3ghDhBmFD8uzVVQ1SwPZ8CgftRkFcn1llXIAfJ3iHB
-AoHBAOg3DOIdtUVgpjMKhpAyuH54fYvGl7afIMNbKRle0kCiP45wtGJ43RPMqiR8
-1rxZB3+iapICI/lnhk3O7vVRkR64yiqQBcl/hXZ1BhyD6iDXWYmm5mcnymcoqfwc
-p9TfzEPyGPb3SM2YlI0cSPRqM/jDvGvnDeKIpzEKvUlwJ59WoN2HOHTIXf+XbN5n
-unpuTt6YKJvc48DrXsPnUzkCmUfbOmgHfeb9/qBs/8kY4YJMsZEjqf88o7mCJCIy
-BtDxTwKBwQDKuOwE8e0GIA01ZHd6RfR+ZCvmp2oauxal4EJsBx+ZZnhEWGaSm1fE
-Bf/ih074ghcSKoSrdYpD1xGZ6fGVWMx3jcL11yLDOUiiPDJsm8hUBZ0IW1qXyfCP
-l7xy1bUkWwPXdmFuGp1exrcjooKrFNuTdYiK4nQZSKuCfXQRADrmEJmM+gYwhqI7
-4XsYo848B9A4hbY6RLEox4uvo/RmafY0iR0PMhVEc+ydNLKB/4LpahZqBQ4kTpMv
-o4+rEvYt1gkCgcB08gx177ozx1nMCLf99N0/LBUmCIytNvR8DfPjyAIg9NUHOjFO
-CkpkR0VEfO50Cm4hVD1RbOyLFRzpIJbtSvfHvg5qYv/XG3auUn8Sa0jE408/aKNO
-PhbL3wnEYvYO2ep4KXtzHNQ4XmgprJ39IWMtG/5PZRx0ApgYtazgSDBcKXd4OTow
-bhwQtUTpuNmMAPONXJnO7O5yYNbn2B7sbiedrYV7kJJSe4X5awtiTjp7sX4XdxuM
-5BAcQ7NI2WLfZTcCgcBp/X9hIoATmMRvKwUQx+yJ/KO7Z8KhETpJJdR0mNDbqmit
-Cy8t7cxYb+6WqLoQUivv0o0k/EJ7L8JDH76woAnfZB4P3RiOy69/K0wN3vFBhOHS
-kbju7aU53lKoE7YuuOtsRrewEng/KlRsbDY3bqNTGLt4KegbpBQQGLmLffxNd1Zh
-EAQWcP33ou9yNYrJdihWtQpOssWRlash/O32ceZJF3s7C6t068tFclz2fPocQdxQ
-OC5pqy9nU/P0tOhDlMkCgcEAosaBJLIeAYlOU0+2uSx5g5mIqOOTyrDEmqqad6T/
-wkB7vW2QaoDvLL22Yrzdn9vQ0V0rqzhVtan7sq5pn/BQJAueZYN8rFxS3uuW+UQk
-Nsc4GLJzU8Az/2DvqEIrnE7zRc5E1FOI9gKLrBlpJB2o0hVcBznDe05Gax6Kjqbm
-jHqzyU73SpxpEy3OesClCeCQIMr47HaL9aSqaEX4U9bMpgHi0HgTTHqvJ5pch0hY
-dYl+WAE9LAyF1DF29BirEXVw
------END PRIVATE KEY-----
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:5d
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=fakehostname
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                RSA Public-Key: (3072 bit)
-                Modulus:
-                    00:b7:e3:2d:d2:ea:25:dd:99:db:dd:33:fd:9a:14:
-                    17:ba:0a:f4:6f:67:08:61:d6:1b:86:97:b2:10:46:
-                    d7:68:6a:43:ea:30:b9:44:74:d1:c9:b4:d7:85:e4:
-                    cd:bb:c4:b7:a2:fa:9e:30:b7:b3:75:27:28:b4:da:
-                    47:87:41:bd:66:f5:3a:87:e4:0a:ee:3a:41:36:b6:
-                    2f:b5:e7:31:28:2a:85:3d:69:6c:9d:4e:21:fe:7a:
-                    92:93:4f:4c:a3:83:63:5c:29:08:d1:51:a5:9c:6e:
-                    1c:c1:1f:81:0c:2a:e0:88:97:32:08:cf:cf:c4:20:
-                    a9:0e:aa:10:83:c2:ae:be:16:fd:c0:ca:cf:b3:ec:
-                    1c:fe:c9:1f:34:8b:18:af:2a:ef:e5:ed:28:f1:43:
-                    bc:fb:47:f9:02:23:b3:95:89:17:08:3b:94:01:40:
-                    f8:fb:54:bb:c2:4f:3e:15:03:ab:bf:2d:d5:e7:80:
-                    ad:87:36:e6:ae:e9:65:e6:e7:23:4d:41:ba:ab:07:
-                    5d:40:10:97:18:65:ff:dc:56:b9:de:57:81:7e:66:
-                    32:e5:a0:02:a0:4a:7f:46:07:c7:96:3b:28:a5:4d:
-                    0d:7c:4d:c2:9d:f8:7d:a2:72:2a:51:68:ff:fe:41:
-                    1f:ca:3f:1e:46:2b:f4:97:53:79:b2:aa:6e:b6:40:
-                    e1:88:ee:df:f9:92:d5:5d:8c:68:6c:ea:d1:d9:c7:
-                    0d:52:46:28:a9:88:b6:16:6e:d5:51:ad:2c:5a:e3:
-                    06:25:82:98:28:53:0b:eb:be:fb:42:e6:40:0d:9d:
-                    3c:35:54:65:ac:c5:cb:3e:e9:ae:fe:3e:87:18:9c:
-                    98:aa:ee:4e:1b:e4:e0:14:6f:74:72:be:5f:43:2c:
-                    03:32:f0:da:a9:45:6a:38:70:70:ff:5d:0d:c5:09:
-                    8c:05:1e:53:92:83:1f:dd:2f:94:9e:d2:2d:dd:5b:
-                    52:b3:6c:fe:8e:bd:a3:60:ea:79:7f:d4:45:cf:52:
-                    c2:75:01:34:bc:9f:3b:f3:85:c7
-                Exponent: 65537 (0x10001)
-        X509v3 extensions:
-            X509v3 Subject Alternative Name: 
-                DNS:fakehostname
-            X509v3 Key Usage: critical
-                Digital Signature, Key Encipherment
-            X509v3 Extended Key Usage: 
-                TLS Web Server Authentication, TLS Web Client Authentication
-            X509v3 Basic Constraints: critical
-                CA:FALSE
-            X509v3 Subject Key Identifier: 
-                C8:BD:A8:B4:C0:F2:32:10:73:47:9C:48:81:32:F8:BA:BB:26:84:97
-            X509v3 Authority Key Identifier: 
-                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
-                serial:CB:2D:80:99:5A:69:52:5B
-
-            Authority Information Access: 
-                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
-                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
-
-            X509v3 CRL Distribution Points: 
-
-                Full Name:
-                  URI:http://testca.pythontest.net/testca/revocation.crl
-
-    Signature Algorithm: sha256WithRSAEncryption
-         76:87:76:4d:e4:0f:88:bf:2c:f3:58:67:c0:97:6c:cd:59:18:
-         82:83:4c:04:19:a5:6d:aa:fa:64:3d:49:32:3e:e1:56:95:b2:
-         13:f7:cf:d3:11:b0:72:b7:5b:e7:d7:85:69:51:3c:b6:54:80:
-         45:2f:28:10:21:20:b9:ba:e9:27:5a:b7:3f:82:b7:69:f5:46:
-         f5:bf:a2:8b:17:7f:f2:14:d1:46:97:b5:8b:47:fb:9f:e8:5c:
-         05:0e:9d:11:bd:7c:9a:03:84:0b:ca:29:66:4a:ca:0d:6f:09:
-         1e:7a:27:c1:7f:03:96:70:8d:18:a5:2f:a4:98:a5:19:aa:8c:
-         5d:1e:8c:3e:bb:6d:3b:c0:33:c0:15:e1:bd:09:3d:9f:e8:dc:
-         12:d4:cb:44:1d:06:f5:e8:d6:4e:a1:2d:5c:9f:5d:1f:5b:2a:
-         c3:4d:40:8d:da:d1:78:80:d0:c6:31:72:10:48:8a:e9:10:7a:
-         13:30:11:b2:9e:67:0e:ed:a1:aa:ec:73:2d:f0:b8:8a:22:75:
-         0f:30:69:5c:50:7e:91:ce:da:91:c7:70:8c:65:ff:f6:58:fb:
-         00:bd:45:cc:e2:e4:e3:e5:16:36:7d:f3:a2:4a:9c:45:ff:d9:
-         a5:16:e0:2f:b5:5b:6c:e6:8a:13:15:48:73:bd:7c:80:33:c3:
-         d4:3b:3a:1d:85:0e:a4:f7:f7:fb:48:0c:e9:a0:4b:5e:8a:5c:
-         67:f8:25:02:6f:cd:72:c1:aa:5a:93:64:7c:14:20:43:e0:13:
-         7f:0d:e1:0d:61:5e:2e:2c:cd:7a:2e:2a:ae:b6:75:6a:5f:a0:
-         1a:9b:b6:67:2d:b0:a5:1c:54:bc:8c:70:7e:15:2b:c0:50:e3:
-         03:bb:a4:a5:fc:45:01:c9:3f:a7:b8:18:dc:3e:08:07:a1:9b:
-         f5:bd:95:bd:49:e8:10:7c:91:7d:2d:c4:c2:98:b6:b7:51:69:
-         d7:0a:68:40:b5:0f:85:a0:a9:67:77:c6:68:cb:0e:58:34:b3:
-         58:e7:c8:7c:09:67
------BEGIN CERTIFICATE-----
-MIIF9zCCBF+gAwIBAgIJAMstgJlaaVJdMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaMGIxCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
-MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xFTATBgNVBAMMDGZh
-a2Vob3N0bmFtZTCCAaIwDQYJKoZIhvcNAQEBBQADggGPADCCAYoCggGBALfjLdLq
-Jd2Z290z/ZoUF7oK9G9nCGHWG4aXshBG12hqQ+owuUR00cm014XkzbvEt6L6njC3
-s3UnKLTaR4dBvWb1OofkCu46QTa2L7XnMSgqhT1pbJ1OIf56kpNPTKODY1wpCNFR
-pZxuHMEfgQwq4IiXMgjPz8QgqQ6qEIPCrr4W/cDKz7PsHP7JHzSLGK8q7+XtKPFD
-vPtH+QIjs5WJFwg7lAFA+PtUu8JPPhUDq78t1eeArYc25q7pZebnI01BuqsHXUAQ
-lxhl/9xWud5XgX5mMuWgAqBKf0YHx5Y7KKVNDXxNwp34faJyKlFo//5BH8o/HkYr
-9JdTebKqbrZA4Yju3/mS1V2MaGzq0dnHDVJGKKmIthZu1VGtLFrjBiWCmChTC+u+
-+0LmQA2dPDVUZazFyz7prv4+hxicmKruThvk4BRvdHK+X0MsAzLw2qlFajhwcP9d
-DcUJjAUeU5KDH90vlJ7SLd1bUrNs/o69o2DqeX/URc9SwnUBNLyfO/OFxwIDAQAB
-o4IBwzCCAb8wFwYDVR0RBBAwDoIMZmFrZWhvc3RuYW1lMA4GA1UdDwEB/wQEAwIF
-oDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/BAIwADAd
-BgNVHQ4EFgQUyL2otMDyMhBzR5xIgTL4ursmhJcwfQYDVR0jBHYwdIAUs4qgorpx
-8agkedSkWyU2FR5JyM2hUaRPME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRo
-b24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZl
-coIJAMstgJlaaVJbMIGDBggrBgEFBQcBAQR3MHUwPAYIKwYBBQUHMAKGMGh0dHA6
-Ly90ZXN0Y2EucHl0aG9udGVzdC5uZXQvdGVzdGNhL3B5Y2FjZXJ0LmNlcjA1Bggr
-BgEFBQcwAYYpaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2Evb2Nz
-cC8wQwYDVR0fBDwwOjA4oDagNIYyaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5l
-dC90ZXN0Y2EvcmV2b2NhdGlvbi5jcmwwDQYJKoZIhvcNAQELBQADggGBAHaHdk3k
-D4i/LPNYZ8CXbM1ZGIKDTAQZpW2q+mQ9STI+4VaVshP3z9MRsHK3W+fXhWlRPLZU
-gEUvKBAhILm66Sdatz+Ct2n1RvW/oosXf/IU0UaXtYtH+5/oXAUOnRG9fJoDhAvK
-KWZKyg1vCR56J8F/A5ZwjRilL6SYpRmqjF0ejD67bTvAM8AV4b0JPZ/o3BLUy0Qd
-BvXo1k6hLVyfXR9bKsNNQI3a0XiA0MYxchBIiukQehMwEbKeZw7toarscy3wuIoi
-dQ8waVxQfpHO2pHHcIxl//ZY+wC9Rczi5OPlFjZ986JKnEX/2aUW4C+1W2zmihMV
-SHO9fIAzw9Q7Oh2FDqT39/tIDOmgS16KXGf4JQJvzXLBqlqTZHwUIEPgE38N4Q1h
-Xi4szXouKq62dWpfoBqbtmctsKUcVLyMcH4VK8BQ4wO7pKX8RQHJP6e4GNw+CAeh
-m/W9lb1J6BB8kX0txMKYtrdRadcKaEC1D4WgqWd3xmjLDlg0s1jnyHwJZw==
------END CERTIFICATE-----
diff --git a/Lib/test/keycertecc.pem b/Lib/test/keycertecc.pem
deleted file mode 100644
index 81daa4ccb9..0000000000
--- a/Lib/test/keycertecc.pem
+++ /dev/null
@@ -1,106 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIG2AgEAMBAGByqGSM49AgEGBSuBBAAiBIGeMIGbAgEBBDBcNwE+cm17mmr7Yg6d
-0DNCnheGFOjkYH4tYzTyCkcZGShkmF/tKhIqb3imKz0Kx9+hZANiAATyp8ws6CuN
-OI2/3MC4jZVSkmoDzm/X/ZrkEm4TVHKPSZ6kzZRpmmUlLS9l7SQZSLYyDAFBFzoG
-JJYHhZNQXEO7HFszn6KnvLjhwS6ddzlaHPziEknrSr0OKhJmdJHrQAQ=
------END PRIVATE KEY-----
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:5e
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=localhost-ecc
-        Subject Public Key Info:
-            Public Key Algorithm: id-ecPublicKey
-                Public-Key: (384 bit)
-                pub:
-                    04:f2:a7:cc:2c:e8:2b:8d:38:8d:bf:dc:c0:b8:8d:
-                    95:52:92:6a:03:ce:6f:d7:fd:9a:e4:12:6e:13:54:
-                    72:8f:49:9e:a4:cd:94:69:9a:65:25:2d:2f:65:ed:
-                    24:19:48:b6:32:0c:01:41:17:3a:06:24:96:07:85:
-                    93:50:5c:43:bb:1c:5b:33:9f:a2:a7:bc:b8:e1:c1:
-                    2e:9d:77:39:5a:1c:fc:e2:12:49:eb:4a:bd:0e:2a:
-                    12:66:74:91:eb:40:04
-                ASN1 OID: secp384r1
-                NIST CURVE: P-384
-        X509v3 extensions:
-            X509v3 Subject Alternative Name: 
-                DNS:localhost-ecc
-            X509v3 Key Usage: critical
-                Digital Signature, Key Encipherment
-            X509v3 Extended Key Usage: 
-                TLS Web Server Authentication, TLS Web Client Authentication
-            X509v3 Basic Constraints: critical
-                CA:FALSE
-            X509v3 Subject Key Identifier: 
-                79:11:98:86:15:4F:48:F4:31:0B:D2:CC:C8:26:3A:09:07:5D:96:40
-            X509v3 Authority Key Identifier: 
-                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-                DirName:/C=XY/O=Python Software Foundation CA/CN=our-ca-server
-                serial:CB:2D:80:99:5A:69:52:5B
-
-            Authority Information Access: 
-                CA Issuers - URI:http://testca.pythontest.net/testca/pycacert.cer
-                OCSP - URI:http://testca.pythontest.net/testca/ocsp/
-
-            X509v3 CRL Distribution Points: 
-
-                Full Name:
-                  URI:http://testca.pythontest.net/testca/revocation.crl
-
-    Signature Algorithm: sha256WithRSAEncryption
-         6e:42:e8:a2:2d:28:14:e3:25:5c:c1:7e:54:e9:3a:ff:30:db:
-         94:ba:b2:f6:5f:ae:9a:c1:90:b3:4f:ce:65:1d:84:64:c0:71:
-         2c:44:8e:7e:00:79:f5:8c:4a:1d:34:13:44:de:99:2e:db:53:
-         ee:ec:74:97:4d:59:1a:09:82:4f:98:75:91:a7:a0:b9:da:5e:
-         68:f5:32:85:be:36:3d:83:d4:ee:f9:87:67:31:85:41:53:9a:
-         e7:05:96:13:1c:88:2e:7f:33:b1:ee:bd:f9:50:52:24:ed:3d:
-         92:95:6e:30:c3:af:74:a9:ee:15:bb:da:7c:14:50:8e:e3:99:
-         ea:ba:b4:37:8a:50:61:26:de:01:93:b8:a2:6b:d9:c7:38:5e:
-         b2:f8:96:3d:a8:9f:7d:0c:71:d4:7e:cc:a0:57:af:7e:ce:3f:
-         a7:a7:27:68:c1:28:d7:4f:44:c1:b4:93:c3:c7:35:2b:50:c3:
-         8e:2c:d0:46:c1:3f:e1:67:d3:f0:81:ae:f3:5c:3e:4f:d5:a8:
-         07:8f:e0:eb:ef:d8:dc:47:e0:3d:58:eb:de:0e:7f:b2:58:cb:
-         5c:f1:2f:65:7e:0f:0d:cc:ca:ba:83:53:63:bc:dd:18:0c:ee:
-         ed:ec:96:88:d0:38:c5:d7:ab:e7:55:79:7b:6d:ba:c0:a0:e9:
-         5c:ca:7c:fb:f8:70:c7:fb:f5:b2:b5:74:cb:f7:c0:0d:20:9f:
-         1d:b7:4c:bf:8a:8d:cd:e3:bc:4e:30:78:02:12:a0:9b:d5:8f:
-         49:3c:95:91:76:6e:7c:54:dc:61:7a:2e:20:ed:35:25:e0:c5:
-         17:50:02:83:00:74:8f:f0:1c:97:96:08:fc:2e:63:a4:f7:97:
-         87:43:2a:32:04:2d:4c:f9:1a:07:bf:68:91:fc:50:21:a1:3c:
-         8d:8f:fb:83:57:83:1f:b6:55:5c:55:2f:58:64:ad:f3:27:ba:
-         d0:e3:cd:58:01:a3:c9:ba:1d:95:dc:30:d5:af:b9:20:ad:d9:
-         48:ba:8d:9a:66:ee
------BEGIN CERTIFICATE-----
-MIIEyzCCAzOgAwIBAgIJAMstgJlaaVJeMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaMGMxCzAJBgNVBAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEj
-MCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24xFjAUBgNVBAMMDWxv
-Y2FsaG9zdC1lY2MwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAATyp8ws6CuNOI2/3MC4
-jZVSkmoDzm/X/ZrkEm4TVHKPSZ6kzZRpmmUlLS9l7SQZSLYyDAFBFzoGJJYHhZNQ
-XEO7HFszn6KnvLjhwS6ddzlaHPziEknrSr0OKhJmdJHrQASjggHEMIIBwDAYBgNV
-HREEETAPgg1sb2NhbGhvc3QtZWNjMA4GA1UdDwEB/wQEAwIFoDAdBgNVHSUEFjAU
-BggrBgEFBQcDAQYIKwYBBQUHAwIwDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUeRGY
-hhVPSPQxC9LMyCY6CQddlkAwfQYDVR0jBHYwdIAUs4qgorpx8agkedSkWyU2FR5J
-yM2hUaRPME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
-Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcoIJAMstgJlaaVJb
-MIGDBggrBgEFBQcBAQR3MHUwPAYIKwYBBQUHMAKGMGh0dHA6Ly90ZXN0Y2EucHl0
-aG9udGVzdC5uZXQvdGVzdGNhL3B5Y2FjZXJ0LmNlcjA1BggrBgEFBQcwAYYpaHR0
-cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2Evb2NzcC8wQwYDVR0fBDww
-OjA4oDagNIYyaHR0cDovL3Rlc3RjYS5weXRob250ZXN0Lm5ldC90ZXN0Y2EvcmV2
-b2NhdGlvbi5jcmwwDQYJKoZIhvcNAQELBQADggGBAG5C6KItKBTjJVzBflTpOv8w
-25S6svZfrprBkLNPzmUdhGTAcSxEjn4AefWMSh00E0TemS7bU+7sdJdNWRoJgk+Y
-dZGnoLnaXmj1MoW+Nj2D1O75h2cxhUFTmucFlhMciC5/M7HuvflQUiTtPZKVbjDD
-r3Sp7hW72nwUUI7jmeq6tDeKUGEm3gGTuKJr2cc4XrL4lj2on30McdR+zKBXr37O
-P6enJ2jBKNdPRMG0k8PHNStQw44s0EbBP+Fn0/CBrvNcPk/VqAeP4Ovv2NxH4D1Y
-694Of7JYy1zxL2V+Dw3MyrqDU2O83RgM7u3slojQOMXXq+dVeXttusCg6VzKfPv4
-cMf79bK1dMv3wA0gnx23TL+Kjc3jvE4weAISoJvVj0k8lZF2bnxU3GF6LiDtNSXg
-xRdQAoMAdI/wHJeWCPwuY6T3l4dDKjIELUz5Gge/aJH8UCGhPI2P+4NXgx+2VVxV
-L1hkrfMnutDjzVgBo8m6HZXcMNWvuSCt2Ui6jZpm7g==
------END CERTIFICATE-----
diff --git a/Lib/test/libregrtest/__init__.py b/Lib/test/libregrtest/__init__.py
index 5e8dba5dbd..e69de29bb2 100644
--- a/Lib/test/libregrtest/__init__.py
+++ b/Lib/test/libregrtest/__init__.py
@@ -1,2 +0,0 @@
-from test.libregrtest.cmdline import _parse_args, RESOURCE_NAMES, ALL_RESOURCES
-from test.libregrtest.main import main
diff --git a/Lib/test/libregrtest/cmdline.py b/Lib/test/libregrtest/cmdline.py
index d1a590d8c1..9ba6ec63ca 100644
--- a/Lib/test/libregrtest/cmdline.py
+++ b/Lib/test/libregrtest/cmdline.py
@@ -1,8 +1,9 @@
 import argparse
-import os
+import os.path
 import shlex
 import sys
 from test.support import os_helper
+from .utils import ALL_RESOURCES, RESOURCE_NAMES
 
 
 USAGE = """\
@@ -27,8 +28,10 @@
 Additional option details:
 
 -r randomizes test execution order. You can use --randseed=int to provide an
-int seed value for the randomizer; this is useful for reproducing troublesome
-test orders.
+int seed value for the randomizer. The randseed value will be used
+to set seeds for all random usages in tests
+(including randomizing the tests order if -r is set).
+By default we always set random seed, but do not randomize test order.
 
 -s On the first invocation of regrtest using -s, the first test file found
 or the first test file given on the command line is run, and the name of
@@ -130,25 +133,17 @@
 """
 
 
-ALL_RESOURCES = ('audio', 'curses', 'largefile', 'network',
-                 'decimal', 'cpu', 'subprocess', 'urlfetch', 'gui', 'walltime')
-
-# Other resources excluded from --use=all:
-#
-# - extralagefile (ex: test_zipfile64): really too slow to be enabled
-#   "by default"
-# - tzdata: while needed to validate fully test_datetime, it makes
-#   test_datetime too slow (15-20 min on some buildbots) and so is disabled by
-#   default (see bpo-30822).
-RESOURCE_NAMES = ALL_RESOURCES + ('extralargefile', 'tzdata')
-
-
 class Namespace(argparse.Namespace):
     def __init__(self, **kwargs) -> None:
+        self.ci = False
         self.testdir = None
         self.verbose = 0
         self.quiet = False
         self.exclude = False
+        self.cleanup = False
+        self.wait = False
+        self.list_cases = False
+        self.list_tests = False
         self.single = False
         self.randomize = False
         self.fromfile = None
@@ -157,7 +152,7 @@ def __init__(self, **kwargs) -> None:
         self.trace = False
         self.coverdir = 'coverage'
         self.runleaks = False
-        self.huntrleaks = False
+        self.huntrleaks: tuple[int, int, str] | None = None
         self.rerun = False
         self.verbose3 = False
         self.print_slow = False
@@ -166,10 +161,17 @@ def __init__(self, **kwargs) -> None:
         self.forever = False
         self.header = False
         self.failfast = False
-        self.match_tests = None
-        self.ignore_tests = None
+        self.match_tests = []
         self.pgo = False
         self.pgo_extended = False
+        self.worker_json = None
+        self.start = None
+        self.timeout = None
+        self.memlimit = None
+        self.threshold = None
+        self.fail_rerun = False
+        self.tempdir = None
+        self._add_python_opts = True
 
         super().__init__(**kwargs)
 
@@ -180,6 +182,20 @@ def error(self, message):
         super().error(message + "\nPass -h or --help for complete help.")
 
 
+class FilterAction(argparse.Action):
+    def __call__(self, parser, namespace, value, option_string=None):
+        items = getattr(namespace, self.dest)
+        items.append((value, self.const))
+
+
+class FromFileFilterAction(argparse.Action):
+    def __call__(self, parser, namespace, value, option_string=None):
+        items = getattr(namespace, self.dest)
+        with open(value, encoding='utf-8') as fp:
+            for line in fp:
+                items.append((line.strip(), self.const))
+
+
 def _create_parser():
     # Set prog to prevent the uninformative "__main__.py" from displaying in
     # error messages when using "python -m test ...".
@@ -189,6 +205,7 @@ def _create_parser():
                         epilog=EPILOG,
                         add_help=False,
                         formatter_class=argparse.RawDescriptionHelpFormatter)
+    parser.set_defaults(match_tests=[])
 
     # Arguments with this clause added to its help are described further in
     # the epilog's "Additional option details" section.
@@ -198,19 +215,27 @@ def _create_parser():
     # We add help explicitly to control what argument group it renders under.
     group.add_argument('-h', '--help', action='help',
                        help='show this help message and exit')
-    group.add_argument('--timeout', metavar='TIMEOUT', type=float,
+    group.add_argument('--fast-ci', action='store_true',
+                       help='Fast Continuous Integration (CI) mode used by '
+                            'GitHub Actions')
+    group.add_argument('--slow-ci', action='store_true',
+                       help='Slow Continuous Integration (CI) mode used by '
+                            'buildbot workers')
+    group.add_argument('--timeout', metavar='TIMEOUT',
                         help='dump the traceback and exit if a test takes '
                              'more than TIMEOUT seconds; disabled if TIMEOUT '
                              'is negative or equals to zero')
     group.add_argument('--wait', action='store_true',
                        help='wait for user input, e.g., allow a debugger '
                             'to be attached')
-    group.add_argument('--worker-args', metavar='ARGS')
     group.add_argument('-S', '--start', metavar='START',
                        help='the name of the test at which to start.' +
                             more_details)
     group.add_argument('-p', '--python', metavar='PYTHON',
                        help='Command to run Python test subprocesses with.')
+    group.add_argument('--randseed', metavar='SEED',
+                       dest='random_seed', type=int,
+                       help='pass a global random seed')
 
     group = parser.add_argument_group('Verbosity')
     group.add_argument('-v', '--verbose', action='count',
@@ -231,10 +256,6 @@ def _create_parser():
     group = parser.add_argument_group('Selecting tests')
     group.add_argument('-r', '--randomize', action='store_true',
                        help='randomize test execution order.' + more_details)
-    group.add_argument('--randseed', metavar='SEED',
-                       dest='random_seed', type=int,
-                       help='pass a random seed to reproduce a previous '
-                            'random run')
     group.add_argument('-f', '--fromfile', metavar='FILE',
                        help='read names of tests to run from a file.' +
                             more_details)
@@ -244,17 +265,19 @@ def _create_parser():
                        help='single step through a set of tests.' +
                             more_details)
     group.add_argument('-m', '--match', metavar='PAT',
-                       dest='match_tests', action='append',
+                       dest='match_tests', action=FilterAction, const=True,
                        help='match test cases and methods with glob pattern PAT')
     group.add_argument('-i', '--ignore', metavar='PAT',
-                       dest='ignore_tests', action='append',
+                       dest='match_tests', action=FilterAction, const=False,
                        help='ignore test cases and methods with glob pattern PAT')
     group.add_argument('--matchfile', metavar='FILENAME',
-                       dest='match_filename',
+                       dest='match_tests',
+                       action=FromFileFilterAction, const=True,
                        help='similar to --match but get patterns from a '
                             'text file, one pattern per line')
     group.add_argument('--ignorefile', metavar='FILENAME',
-                       dest='ignore_filename',
+                       dest='match_tests',
+                       action=FromFileFilterAction, const=False,
                        help='similar to --matchfile but it receives patterns '
                             'from text file to ignore')
     group.add_argument('-G', '--failfast', action='store_true',
@@ -324,6 +347,9 @@ def _create_parser():
                        help='override the working directory for the test run')
     group.add_argument('--cleanup', action='store_true',
                        help='remove old test_python_* directories')
+    group.add_argument('--dont-add-python-opts', dest='_add_python_opts',
+                       action='store_false',
+                       help="internal option, don't use it")
     return parser
 
 
@@ -374,7 +400,52 @@ def _parse_args(args, **kwargs):
     for arg in ns.args:
         if arg.startswith('-'):
             parser.error("unrecognized arguments: %s" % arg)
-            sys.exit(1)
+
+    if ns.timeout is not None:
+        # Support "--timeout=" (no value) so Makefile.pre.pre TESTTIMEOUT
+        # can be used by "make buildbottest" and "make test".
+        if ns.timeout != "":
+            try:
+                ns.timeout = float(ns.timeout)
+            except ValueError:
+                parser.error(f"invalid timeout value: {ns.timeout!r}")
+        else:
+            ns.timeout = None
+
+    # Continuous Integration (CI): common options for fast/slow CI modes
+    if ns.slow_ci or ns.fast_ci:
+        # Similar to options:
+        #
+        #     -j0 --randomize --fail-env-changed --fail-rerun --rerun
+        #     --slowest --verbose3
+        if ns.use_mp is None:
+            ns.use_mp = 0
+        ns.randomize = True
+        ns.fail_env_changed = True
+        ns.fail_rerun = True
+        if ns.python is None:
+            ns.rerun = True
+        ns.print_slow = True
+        ns.verbose3 = True
+    else:
+        ns._add_python_opts = False
+
+    # When both --slow-ci and --fast-ci options are present,
+    # --slow-ci has the priority
+    if ns.slow_ci:
+        # Similar to: -u "all" --timeout=1200
+        if ns.use is None:
+            ns.use = []
+        ns.use.insert(0, ['all'])
+        if ns.timeout is None:
+            ns.timeout = 1200  # 20 minutes
+    elif ns.fast_ci:
+        # Similar to: -u "all,-cpu" --timeout=600
+        if ns.use is None:
+            ns.use = []
+        ns.use.insert(0, ['all', '-cpu'])
+        if ns.timeout is None:
+            ns.timeout = 600  # 10 minutes
 
     if ns.single and ns.fromfile:
         parser.error("-s and -f don't go together!")
@@ -401,10 +472,6 @@ def _parse_args(args, **kwargs):
     if ns.timeout is not None:
         if ns.timeout <= 0:
             ns.timeout = None
-    if ns.use_mp is not None:
-        if ns.use_mp <= 0:
-            # Use all cores + extras for tests that like to sleep
-            ns.use_mp = 2 + (os.cpu_count() or 1)
     if ns.use:
         for a in ns.use:
             for r in a:
@@ -427,25 +494,28 @@ def _parse_args(args, **kwargs):
         ns.randomize = True
     if ns.verbose:
         ns.header = True
-    if ns.huntrleaks and ns.verbose3:
+    # When -jN option is used, a worker process does not use --verbose3
+    # and so -R 3:3 -jN --verbose3 just works as expected: there is no false
+    # alarm about memory leak.
+    if ns.huntrleaks and ns.verbose3 and ns.use_mp is None:
         ns.verbose3 = False
+        # run_single_test() replaces sys.stdout with io.StringIO if verbose3
+        # is true. In this case, huntrleaks sees an write into StringIO as
+        # a memory leak, whereas it is not (gh-71290).
         print("WARNING: Disable --verbose3 because it's incompatible with "
-              "--huntrleaks: see http://bugs.python.org/issue27103",
+              "--huntrleaks without -jN option",
               file=sys.stderr)
-    if ns.match_filename:
-        if ns.match_tests is None:
-            ns.match_tests = []
-        with open(ns.match_filename) as fp:
-            for line in fp:
-                ns.match_tests.append(line.strip())
-    if ns.ignore_filename:
-        if ns.ignore_tests is None:
-            ns.ignore_tests = []
-        with open(ns.ignore_filename) as fp:
-            for line in fp:
-                ns.ignore_tests.append(line.strip())
     if ns.forever:
         # --forever implies --failfast
         ns.failfast = True
 
+    if ns.huntrleaks:
+        warmup, repetitions, _ = ns.huntrleaks
+        if warmup < 1 or repetitions < 1:
+            msg = ("Invalid values for the --huntrleaks/-R parameters. The "
+                   "number of warmups and repetitions must be at least 1 "
+                   "each (1:1).")
+            print(msg, file=sys.stderr, flush=True)
+            sys.exit(2)
+
     return ns
diff --git a/Lib/test/libregrtest/filter.py b/Lib/test/libregrtest/filter.py
new file mode 100644
index 0000000000..817624d79e
--- /dev/null
+++ b/Lib/test/libregrtest/filter.py
@@ -0,0 +1,72 @@
+import itertools
+import operator
+import re
+
+
+# By default, don't filter tests
+_test_matchers = ()
+_test_patterns = ()
+
+
+def match_test(test):
+    # Function used by support.run_unittest() and regrtest --list-cases
+    result = False
+    for matcher, result in reversed(_test_matchers):
+        if matcher(test.id()):
+            return result
+    return not result
+
+
+def _is_full_match_test(pattern):
+    # If a pattern contains at least one dot, it's considered
+    # as a full test identifier.
+    # Example: 'test.test_os.FileTests.test_access'.
+    #
+    # ignore patterns which contain fnmatch patterns: '*', '?', '[...]'
+    # or '[!...]'. For example, ignore 'test_access*'.
+    return ('.' in pattern) and (not re.search(r'[?*\[\]]', pattern))
+
+
+def set_match_tests(patterns):
+    global _test_matchers, _test_patterns
+
+    if not patterns:
+        _test_matchers = ()
+        _test_patterns = ()
+    else:
+        itemgetter = operator.itemgetter
+        patterns = tuple(patterns)
+        if patterns != _test_patterns:
+            _test_matchers = [
+                (_compile_match_function(map(itemgetter(0), it)), result)
+                for result, it in itertools.groupby(patterns, itemgetter(1))
+            ]
+            _test_patterns = patterns
+
+
+def _compile_match_function(patterns):
+    patterns = list(patterns)
+
+    if all(map(_is_full_match_test, patterns)):
+        # Simple case: all patterns are full test identifier.
+        # The test.bisect_cmd utility only uses such full test identifiers.
+        return set(patterns).__contains__
+    else:
+        import fnmatch
+        regex = '|'.join(map(fnmatch.translate, patterns))
+        # The search *is* case sensitive on purpose:
+        # don't use flags=re.IGNORECASE
+        regex_match = re.compile(regex).match
+
+        def match_test_regex(test_id, regex_match=regex_match):
+            if regex_match(test_id):
+                # The regex matches the whole identifier, for example
+                # 'test.test_os.FileTests.test_access'.
+                return True
+            else:
+                # Try to match parts of the test identifier.
+                # For example, split 'test.test_os.FileTests.test_access'
+                # into: 'test', 'test_os', 'FileTests' and 'test_access'.
+                return any(map(regex_match, test_id.split(".")))
+
+        return match_test_regex
diff --git a/Lib/test/libregrtest/findtests.py b/Lib/test/libregrtest/findtests.py
new file mode 100644
index 0000000000..78343775bc
--- /dev/null
+++ b/Lib/test/libregrtest/findtests.py
@@ -0,0 +1,106 @@
+import os
+import sys
+import unittest
+
+from test import support
+
+from .filter import match_test, set_match_tests
+from .utils import (
+    StrPath, TestName, TestTuple, TestList, TestFilter,
+    abs_module_name, count, printlist)
+
+
+# If these test directories are encountered recurse into them and treat each
+# "test_*.py" file or each sub-directory as a separate test module. This can
+# increase parallelism.
+#
+# Beware this can't generally be done for any directory with sub-tests as the
+# __init__.py may do things which alter what tests are to be run.
+SPLITTESTDIRS: set[TestName] = {
+    "test_asyncio",
+    "test_concurrent_futures",
+    "test_future_stmt",
+    "test_gdb",
+    "test_inspect",
+    "test_multiprocessing_fork",
+    "test_multiprocessing_forkserver",
+    "test_multiprocessing_spawn",
+}
+
+
+def findtestdir(path: StrPath | None = None) -> StrPath:
+    return path or os.path.dirname(os.path.dirname(__file__)) or os.curdir
+
+
+def findtests(*, testdir: StrPath | None = None, exclude=(),
+              split_test_dirs: set[TestName] = SPLITTESTDIRS,
+              base_mod: str = "") -> TestList:
+    """Return a list of all applicable test modules."""
+    testdir = findtestdir(testdir)
+    tests = []
+    for name in os.listdir(testdir):
+        mod, ext = os.path.splitext(name)
+        if (not mod.startswith("test_")) or (mod in exclude):
+            continue
+        if base_mod:
+            fullname = f"{base_mod}.{mod}"
+        else:
+            fullname = mod
+        if fullname in split_test_dirs:
+            subdir = os.path.join(testdir, mod)
+            if not base_mod:
+                fullname = f"test.{mod}"
+            tests.extend(findtests(testdir=subdir, exclude=exclude,
+                                   split_test_dirs=split_test_dirs,
+                                   base_mod=fullname))
+        elif ext in (".py", ""):
+            tests.append(fullname)
+    return sorted(tests)
+
+
+def split_test_packages(tests, *, testdir: StrPath | None = None, exclude=(),
+                        split_test_dirs=SPLITTESTDIRS):
+    testdir = findtestdir(testdir)
+    splitted = []
+    for name in tests:
+        if name in split_test_dirs:
+            subdir = os.path.join(testdir, name)
+            splitted.extend(findtests(testdir=subdir, exclude=exclude,
+                                      split_test_dirs=split_test_dirs,
+                                      base_mod=name))
+        else:
+            splitted.append(name)
+    return splitted
+
+
+def _list_cases(suite):
+    for test in suite:
+        if isinstance(test, unittest.loader._FailedTest):
+            continue
+        if isinstance(test, unittest.TestSuite):
+            _list_cases(test)
+        elif isinstance(test, unittest.TestCase):
+            if match_test(test):
+                print(test.id())
+
+def list_cases(tests: TestTuple, *,
+               match_tests: TestFilter | None = None,
+               test_dir: StrPath | None = None):
+    support.verbose = False
+    set_match_tests(match_tests)
+
+    skipped = []
+    for test_name in tests:
+        module_name = abs_module_name(test_name, test_dir)
+        try:
+            suite = unittest.defaultTestLoader.loadTestsFromName(module_name)
+            _list_cases(suite)
+        except unittest.SkipTest:
+            skipped.append(test_name)
+
+    if skipped:
+        sys.stdout.flush()
+        stderr = sys.stderr
+        print(file=stderr)
+        print(count(len(skipped), "test"), "skipped:", file=stderr)
+        printlist(skipped, file=stderr)
diff --git a/Lib/test/libregrtest/logger.py b/Lib/test/libregrtest/logger.py
new file mode 100644
index 0000000000..a125706927
--- /dev/null
+++ b/Lib/test/libregrtest/logger.py
@@ -0,0 +1,86 @@
+import os
+import time
+
+from test.support import MS_WINDOWS
+from .results import TestResults
+from .runtests import RunTests
+from .utils import print_warning
+
+if MS_WINDOWS:
+    from .win_utils import WindowsLoadTracker
+
+
+class Logger:
+    def __init__(self, results: TestResults, quiet: bool, pgo: bool):
+        self.start_time = time.perf_counter()
+        self.test_count_text = ''
+        self.test_count_width = 3
+        self.win_load_tracker: WindowsLoadTracker | None = None
+        self._results: TestResults = results
+        self._quiet: bool = quiet
+        self._pgo: bool = pgo
+
+    def log(self, line: str = '') -> None:
+        empty = not line
+
+        # add the system load prefix: "load avg: 1.80 "
+        load_avg = self.get_load_avg()
+        if load_avg is not None:
+            line = f"load avg: {load_avg:.2f} {line}"
+
+        # add the timestamp prefix:  "0:01:05 "
+        log_time = time.perf_counter() - self.start_time
+
+        mins, secs = divmod(int(log_time), 60)
+        hours, mins = divmod(mins, 60)
+        formatted_log_time = "%d:%02d:%02d" % (hours, mins, secs)
+
+        line = f"{formatted_log_time} {line}"
+        if empty:
+            line = line[:-1]
+
+        print(line, flush=True)
+
+    def get_load_avg(self) -> float | None:
+        if hasattr(os, 'getloadavg'):
+            return os.getloadavg()[0]
+        if self.win_load_tracker is not None:
+            return self.win_load_tracker.getloadavg()
+        return None
+
+    def display_progress(self, test_index: int, text: str) -> None:
+        if self._quiet:
+            return
+        results = self._results
+
+        # "[ 51/405/1] test_tcl passed"
+        line = f"{test_index:{self.test_count_width}}{self.test_count_text}"
+        fails = len(results.bad) + len(results.env_changed)
+        if fails and not self._pgo:
+            line = f"{line}/{fails}"
+        self.log(f"[{line}] {text}")
+
+    def set_tests(self, runtests: RunTests) -> None:
+        if runtests.forever:
+            self.test_count_text = ''
+            self.test_count_width = 3
+        else:
+            self.test_count_text = '/{}'.format(len(runtests.tests))
+            self.test_count_width = len(self.test_count_text) - 1
+
+    def start_load_tracker(self) -> None:
+        if not MS_WINDOWS:
+            return
+
+        try:
+            self.win_load_tracker = WindowsLoadTracker()
+        except PermissionError as error:
+            # Standard accounts may not have access to the performance
+            # counters.
+            print_warning(f'Failed to create WindowsLoadTracker: {error}')
+
+    def stop_load_tracker(self) -> None:
+        if self.win_load_tracker is None:
+            return
+        self.win_load_tracker.close()
+        self.win_load_tracker = None
diff --git a/Lib/test/libregrtest/main.py b/Lib/test/libregrtest/main.py
index ab03647ca5..8544bb484c 100644
--- a/Lib/test/libregrtest/main.py
+++ b/Lib/test/libregrtest/main.py
@@ -1,38 +1,30 @@
-import faulthandler
-import locale
 import os
-import platform
 import random
 import re
+import shlex
 import sys
 import sysconfig
-import tempfile
 import time
-import unittest
-from test.libregrtest.cmdline import _parse_args
-from test.libregrtest.runtest import (
-    findtests, split_test_packages, runtest, abs_module_name,
-    PROGRESS_MIN_TIME, State, MatchTestsDict, RunTests)
-from test.libregrtest.setup import setup_tests
-from test.libregrtest.pgo import setup_pgo_tests
-from test.libregrtest.utils import (strip_py_suffix, count, format_duration,
-                                    printlist, get_build_info)
-from test import support
-from test.support import TestStats
-from test.support import os_helper
-from test.support import threading_helper
-
-
-# bpo-38203: Maximum delay in seconds to exit Python (call Py_Finalize()).
-# Used to protect against threading._shutdown() hang.
-# Must be smaller than buildbot "1200 seconds without output" limit.
-EXIT_TIMEOUT = 120.0
 
-EXITCODE_BAD_TEST = 2
-EXITCODE_ENV_CHANGED = 3
-EXITCODE_NO_TESTS_RAN = 4
-EXITCODE_RERUN_FAIL = 5
-EXITCODE_INTERRUPTED = 130
+from test import support
+from test.support import os_helper, MS_WINDOWS
+
+from .cmdline import _parse_args, Namespace
+from .findtests import findtests, split_test_packages, list_cases
+from .logger import Logger
+from .pgo import setup_pgo_tests
+from .result import State
+from .results import TestResults, EXITCODE_INTERRUPTED
+from .runtests import RunTests, HuntRefleak
+from .setup import setup_process, setup_test_dir
+from .single import run_single_test, PROGRESS_MIN_TIME
+from .utils import (
+    StrPath, StrJSON, TestName, TestList, TestTuple, TestFilter,
+    strip_py_suffix, count, format_duration,
+    printlist, get_temp_dir, get_work_dir, exit_timeout,
+    display_header, cleanup_temp_dir, print_warning,
+    is_cross_compiled, get_host_runner, process_cpu_count,
+    EXIT_TIMEOUT)
 
 
 class Regrtest:
@@ -58,306 +50,210 @@ class Regrtest:
     directly to set the values that would normally be set by flags
     on the command line.
     """
-    def __init__(self):
-        # Namespace of command line options
-        self.ns = None
-
-        # tests
-        self.tests = []
-        self.selected = []
-        self.all_runtests: list[RunTests] = []
-
-        # test results
-        self.good: list[str] = []
-        self.bad: list[str] = []
-        self.rerun_bad: list[str] = []
-        self.skipped: list[str] = []
-        self.resource_denied: list[str] = []
-        self.environment_changed: list[str] = []
-        self.run_no_tests: list[str] = []
-        self.rerun: list[str] = []
-
-        self.need_rerun: list[TestResult] = []
+    def __init__(self, ns: Namespace, _add_python_opts: bool = False):
+        # Log verbosity
+        self.verbose: int = int(ns.verbose)
+        self.quiet: bool = ns.quiet
+        self.pgo: bool = ns.pgo
+        self.pgo_extended: bool = ns.pgo_extended
+
+        # Test results
+        self.results: TestResults = TestResults()
         self.first_state: str | None = None
-        self.interrupted = False
-        self.total_stats = TestStats()
 
-        # used by --slow
-        self.test_times = []
+        # Logger
+        self.logger = Logger(self.results, self.quiet, self.pgo)
+
+        # Actions
+        self.want_header: bool = ns.header
+        self.want_list_tests: bool = ns.list_tests
+        self.want_list_cases: bool = ns.list_cases
+        self.want_wait: bool = ns.wait
+        self.want_cleanup: bool = ns.cleanup
+        self.want_rerun: bool = ns.rerun
+        self.want_run_leaks: bool = ns.runleaks
+
+        self.ci_mode: bool = (ns.fast_ci or ns.slow_ci)
+        self.want_add_python_opts: bool = (_add_python_opts
+                                           and ns._add_python_opts)
+
+        # Select tests
+        self.match_tests: TestFilter = ns.match_tests
+        self.exclude: bool = ns.exclude
+        self.fromfile: StrPath | None = ns.fromfile
+        self.starting_test: TestName | None = ns.start
+        self.cmdline_args: TestList = ns.args
+
+        # Workers
+        if ns.use_mp is None:
+            num_workers = 0  # run sequentially
+        elif ns.use_mp <= 0:
+            num_workers = -1  # use the number of CPUs
+        else:
+            num_workers = ns.use_mp
+        self.num_workers: int = num_workers
+        self.worker_json: StrJSON | None = ns.worker_json
+
+        # Options to run tests
+        self.fail_fast: bool = ns.failfast
+        self.fail_env_changed: bool = ns.fail_env_changed
+        self.fail_rerun: bool = ns.fail_rerun
+        self.forever: bool = ns.forever
+        self.output_on_failure: bool = ns.verbose3
+        self.timeout: float | None = ns.timeout
+        if ns.huntrleaks:
+            warmups, runs, filename = ns.huntrleaks
+            filename = os.path.abspath(filename)
+            self.hunt_refleak: HuntRefleak | None = HuntRefleak(warmups, runs, filename)
+        else:
+            self.hunt_refleak = None
+        self.test_dir: StrPath | None = ns.testdir
+        self.junit_filename: StrPath | None = ns.xmlpath
+        self.memory_limit: str | None = ns.memlimit
+        self.gc_threshold: int | None = ns.threshold
+        self.use_resources: tuple[str, ...] = tuple(ns.use_resources)
+        if ns.python:
+            self.python_cmd: tuple[str, ...] | None = tuple(ns.python)
+        else:
+            self.python_cmd = None
+        self.coverage: bool = ns.trace
+        self.coverage_dir: StrPath | None = ns.coverdir
+        self.tmp_dir: StrPath | None = ns.tempdir
+
+        # Randomize
+        self.randomize: bool = ns.randomize
+        if ('SOURCE_DATE_EPOCH' in os.environ
+            # don't use the variable if empty
+            and os.environ['SOURCE_DATE_EPOCH']
+        ):
+            self.randomize = False
+            # SOURCE_DATE_EPOCH should be an integer, but use a string to not
+            # fail if it's not integer. random.seed() accepts a string.
+            # https://reproducible-builds.org/docs/source-date-epoch/
+            self.random_seed: int | str = os.environ['SOURCE_DATE_EPOCH']
+        elif ns.random_seed is None:
+            self.random_seed = random.getrandbits(32)
+        else:
+            self.random_seed = ns.random_seed
 
-        # used by --coverage, trace.Trace instance
-        self.tracer = None
+        # tests
+        self.first_runtests: RunTests | None = None
+
+        # used by --slowest
+        self.print_slowest: bool = ns.print_slow
 
         # used to display the progress bar "[ 3/100]"
         self.start_time = time.perf_counter()
-        self.test_count_text = ''
-        self.test_count_width = 1
 
         # used by --single
-        self.next_single_test = None
-        self.next_single_filename = None
-
-        # used by --junit-xml
-        self.testsuite_xml = None
-
-        # misc
-        self.win_load_tracker = None
-        self.tmp_dir = None
-
-    def get_executed(self):
-        return (set(self.good) | set(self.bad) | set(self.skipped)
-                | set(self.resource_denied) | set(self.environment_changed)
-                | set(self.run_no_tests))
-
-    def accumulate_result(self, result, rerun=False):
-        fail_env_changed = self.ns.fail_env_changed
-        test_name = result.test_name
-
-        match result.state:
-            case State.PASSED:
-                self.good.append(test_name)
-            case State.ENV_CHANGED:
-                self.environment_changed.append(test_name)
-            case State.SKIPPED:
-                self.skipped.append(test_name)
-            case State.RESOURCE_DENIED:
-                self.resource_denied.append(test_name)
-            case State.INTERRUPTED:
-                self.interrupted = True
-            case State.DID_NOT_RUN:
-                self.run_no_tests.append(test_name)
-            case _:
-                if result.is_failed(fail_env_changed):
-                    self.bad.append(test_name)
-                    self.need_rerun.append(result)
-                else:
-                    raise ValueError(f"invalid test state: {result.state!r}")
-
-        if result.has_meaningful_duration() and not rerun:
-            self.test_times.append((result.duration, test_name))
-        if result.stats is not None:
-            self.total_stats.accumulate(result.stats)
-        if rerun:
-            self.rerun.append(test_name)
-
-        xml_data = result.xml_data
-        if xml_data:
-            import xml.etree.ElementTree as ET
-            for e in xml_data:
-                try:
-                    self.testsuite_xml.append(ET.fromstring(e))
-                except ET.ParseError:
-                    print(xml_data, file=sys.__stderr__)
-                    raise
+        self.single_test_run: bool = ns.single
+        self.next_single_test: TestName | None = None
+        self.next_single_filename: StrPath | None = None
 
     def log(self, line=''):
-        empty = not line
-
-        # add the system load prefix: "load avg: 1.80 "
-        load_avg = self.getloadavg()
-        if load_avg is not None:
-            line = f"load avg: {load_avg:.2f} {line}"
+        self.logger.log(line)
 
-        # add the timestamp prefix:  "0:01:05 "
-        test_time = time.perf_counter() - self.start_time
-
-        mins, secs = divmod(int(test_time), 60)
-        hours, mins = divmod(mins, 60)
-        test_time = "%d:%02d:%02d" % (hours, mins, secs)
-
-        line = f"{test_time} {line}"
-        if empty:
-            line = line[:-1]
-
-        print(line, flush=True)
-
-    def display_progress(self, test_index, text):
-        quiet = self.ns.quiet
-        pgo = self.ns.pgo
-        if quiet:
-            return
-
-        # "[ 51/405/1] test_tcl passed"
-        line = f"{test_index:{self.test_count_width}}{self.test_count_text}"
-        fails = len(self.bad) + len(self.environment_changed)
-        if fails and not pgo:
-            line = f"{line}/{fails}"
-        self.log(f"[{line}] {text}")
-
-    def parse_args(self, kwargs):
-        ns = _parse_args(sys.argv[1:], **kwargs)
-
-        if ns.xmlpath:
-            support.junit_xml_list = self.testsuite_xml = []
-
-        strip_py_suffix(ns.args)
-
-        if ns.huntrleaks:
-            warmup, repetitions, _ = ns.huntrleaks
-            if warmup < 1 or repetitions < 1:
-                msg = ("Invalid values for the --huntrleaks/-R parameters. The "
-                       "number of warmups and repetitions must be at least 1 "
-                       "each (1:1).")
-                print(msg, file=sys.stderr, flush=True)
-                sys.exit(2)
-
-        if ns.tempdir:
-            ns.tempdir = os.path.expanduser(ns.tempdir)
-
-        self.ns = ns
-
-    def find_tests(self, tests):
-        ns = self.ns
-        single = ns.single
-        fromfile = ns.fromfile
-        pgo = ns.pgo
-        exclude = ns.exclude
-        test_dir = ns.testdir
-        starting_test = ns.start
-        randomize = ns.randomize
-
-        self.tests = tests
-
-        if single:
+    def find_tests(self, tests: TestList | None = None) -> tuple[TestTuple, TestList | None]:
+        if self.single_test_run:
             self.next_single_filename = os.path.join(self.tmp_dir, 'pynexttest')
             try:
                 with open(self.next_single_filename, 'r') as fp:
                     next_test = fp.read().strip()
-                    self.tests = [next_test]
+                    tests = [next_test]
             except OSError:
                 pass
 
-        if fromfile:
-            self.tests = []
+        if self.fromfile:
+            tests = []
             # regex to match 'test_builtin' in line:
             # '0:00:00 [  4/400] test_builtin -- test_dict took 1 sec'
             regex = re.compile(r'\btest_[a-zA-Z0-9_]+\b')
-            with open(os.path.join(os_helper.SAVEDCWD, fromfile)) as fp:
+            with open(os.path.join(os_helper.SAVEDCWD, self.fromfile)) as fp:
                 for line in fp:
                     line = line.split('#', 1)[0]
                     line = line.strip()
                     match = regex.search(line)
                     if match is not None:
-                        self.tests.append(match.group())
+                        tests.append(match.group())
 
-        strip_py_suffix(self.tests)
+        strip_py_suffix(tests)
 
-        if pgo:
+        if self.pgo:
             # add default PGO tests if no tests are specified
-            setup_pgo_tests(ns)
+            setup_pgo_tests(self.cmdline_args, self.pgo_extended)
 
         exclude_tests = set()
-        if exclude:
-            for arg in ns.args:
+        if self.exclude:
+            for arg in self.cmdline_args:
                 exclude_tests.add(arg)
-            ns.args = []
+            self.cmdline_args = []
 
-        alltests = findtests(testdir=test_dir, exclude=exclude_tests)
+        alltests = findtests(testdir=self.test_dir,
+                             exclude=exclude_tests)
 
-        if not fromfile:
-            self.selected = self.tests or ns.args
-            if self.selected:
-                self.selected = split_test_packages(self.selected)
+        if not self.fromfile:
+            selected = tests or self.cmdline_args
+            if selected:
+                selected = split_test_packages(selected)
             else:
-                self.selected = alltests
+                selected = alltests
         else:
-            self.selected = self.tests
+            selected = tests
 
-        if single:
-            self.selected = self.selected[:1]
+        if self.single_test_run:
+            selected = selected[:1]
             try:
-                pos = alltests.index(self.selected[0])
+                pos = alltests.index(selected[0])
                 self.next_single_test = alltests[pos + 1]
             except IndexError:
                 pass
 
         # Remove all the selected tests that precede start if it's set.
-        if starting_test:
+        if self.starting_test:
             try:
-                del self.selected[:self.selected.index(starting_test)]
+                del selected[:selected.index(self.starting_test)]
             except ValueError:
-                print(f"Cannot find starting test: {starting_test}")
+                print(f"Cannot find starting test: {self.starting_test}")
                 sys.exit(1)
 
-        if randomize:
-            if ns.random_seed is None:
-                ns.random_seed = random.randrange(10000000)
-            random.seed(ns.random_seed)
-            random.shuffle(self.selected)
+        random.seed(self.random_seed)
+        if self.randomize:
+            random.shuffle(selected)
+
+        return (tuple(selected), tests)
 
-    def list_tests(self):
-        for name in self.selected:
+    @staticmethod
+    def list_tests(tests: TestTuple):
+        for name in tests:
             print(name)
 
-    def _list_cases(self, suite):
-        for test in suite:
-            if isinstance(test, unittest.loader._FailedTest):
-                continue
-            if isinstance(test, unittest.TestSuite):
-                self._list_cases(test)
-            elif isinstance(test, unittest.TestCase):
-                if support.match_test(test):
-                    print(test.id())
-
-    def list_cases(self):
-        ns = self.ns
-        test_dir = ns.testdir
-        support.verbose = False
-        support.set_match_tests(ns.match_tests, ns.ignore_tests)
-
-        skipped = []
-        for test_name in self.selected:
-            module_name = abs_module_name(test_name, test_dir)
-            try:
-                suite = unittest.defaultTestLoader.loadTestsFromName(module_name)
-                self._list_cases(suite)
-            except unittest.SkipTest:
-                skipped.append(test_name)
-
-        if skipped:
-            sys.stdout.flush()
-            stderr = sys.stderr
-            print(file=stderr)
-            print(count(len(skipped), "test"), "skipped:", file=stderr)
-            printlist(skipped, file=stderr)
-
-    def get_rerun_match(self, rerun_list) -> MatchTestsDict:
-        rerun_match_tests = {}
-        for result in rerun_list:
-            match_tests = result.get_rerun_match_tests()
-            # ignore empty match list
-            if match_tests:
-                rerun_match_tests[result.test_name] = match_tests
-        return rerun_match_tests
-
-    def _rerun_failed_tests(self, need_rerun):
+    def _rerun_failed_tests(self, runtests: RunTests):
         # Configure the runner to re-run tests
-        ns = self.ns
-        ns.verbose = True
-        ns.failfast = False
-        ns.verbose3 = False
-        ns.forever = False
-        if ns.use_mp is None:
-            ns.use_mp = 1
-
-        # Get tests to re-run
-        tests = [result.test_name for result in need_rerun]
-        match_tests = self.get_rerun_match(need_rerun)
-        self.set_tests(tests)
+        if self.num_workers == 0:
+            # Always run tests in fresh processes to have more deterministic
+            # initial state. Don't re-run tests in parallel but limit to a
+            # single worker process to have side effects (on the system load
+            # and timings) between tests.
+            self.num_workers = 1
 
-        # Clear previously failed tests
-        self.rerun_bad.extend(self.bad)
-        self.bad.clear()
-        self.need_rerun.clear()
+        tests, match_tests_dict = self.results.prepare_rerun()
 
         # Re-run failed tests
         self.log(f"Re-running {len(tests)} failed tests in verbose mode in subprocesses")
-        runtests = RunTests(tests, match_tests=match_tests, rerun=True)
-        self.all_runtests.append(runtests)
-        self._run_tests_mp(runtests)
-
-    def rerun_failed_tests(self, need_rerun):
-        if self.ns.python:
+        runtests = runtests.copy(
+            tests=tests,
+            rerun=True,
+            verbose=True,
+            forever=False,
+            fail_fast=False,
+            match_tests_dict=match_tests_dict,
+            output_on_failure=False)
+        self.logger.set_tests(runtests)
+        self._run_tests_mp(runtests, self.num_workers)
+        return runtests
+
+    def rerun_failed_tests(self, runtests: RunTests):
+        if self.python_cmd:
             # Temp patch for https://github.com/python/cpython/issues/94052
             self.log(
                 "Re-running failed tests is not supported with --python "
@@ -365,126 +261,61 @@ def rerun_failed_tests(self, need_rerun):
             )
             return
 
-        self.first_state = self.get_tests_state()
+        self.first_state = self.get_state()
 
         print()
-        self._rerun_failed_tests(need_rerun)
-
-        if self.bad:
-            print(count(len(self.bad), 'test'), "failed again:")
-            printlist(self.bad)
+        rerun_runtests = self._rerun_failed_tests(runtests)
 
-        self.display_result()
+        if self.results.bad:
+            print(count(len(self.results.bad), 'test'), "failed again:")
+            printlist(self.results.bad)
 
-    def display_result(self):
-        pgo = self.ns.pgo
-        quiet = self.ns.quiet
-        print_slow = self.ns.print_slow
+        self.display_result(rerun_runtests)
 
+    def display_result(self, runtests):
         # If running the test suite for PGO then no one cares about results.
-        if pgo:
+        if runtests.pgo:
             return
 
+        state = self.get_state()
         print()
-        print("== Tests result: %s ==" % self.get_tests_state())
-
-        if self.interrupted:
-            print("Test suite interrupted by signal SIGINT.")
-
-        omitted = set(self.selected) - self.get_executed()
-        if omitted:
-            print()
-            print(count(len(omitted), "test"), "omitted:")
-            printlist(omitted)
-
-        if self.good and not quiet:
-            print()
-            if (not self.bad
-                and not self.skipped
-                and not self.interrupted
-                and len(self.good) > 1):
-                print("All", end=' ')
-            print(count(len(self.good), "test"), "OK.")
-
-        if print_slow:
-            self.test_times.sort(reverse=True)
-            print()
-            print("10 slowest tests:")
-            for test_time, test in self.test_times[:10]:
-                print("- %s: %s" % (test, format_duration(test_time)))
-
-        if self.bad:
-            print()
-            print(count(len(self.bad), "test"), "failed:")
-            printlist(self.bad)
-
-        if self.environment_changed:
-            print()
-            print("{} altered the execution environment:".format(
-                     count(len(self.environment_changed), "test")))
-            printlist(self.environment_changed)
-
-        if self.skipped and not quiet:
-            print()
-            print(count(len(self.skipped), "test"), "skipped:")
-            printlist(self.skipped)
-
-        if self.resource_denied and not quiet:
-            print()
-            print(count(len(self.resource_denied), "test"), "skipped (resource denied):")
-            printlist(self.resource_denied)
-
-        if self.rerun:
-            print()
-            print("%s:" % count(len(self.rerun), "re-run test"))
-            printlist(self.rerun)
-
-        if self.run_no_tests:
-            print()
-            print(count(len(self.run_no_tests), "test"), "run no tests:")
-            printlist(self.run_no_tests)
-
-    def run_test(self, test_index, test_name, previous_test, save_modules):
-        text = test_name
-        if previous_test:
-            text = '%s -- %s' % (text, previous_test)
-        self.display_progress(test_index, text)
+        print(f"== Tests result: {state} ==")
 
-        if self.tracer:
+        self.results.display_result(runtests.tests,
+                                    self.quiet, self.print_slowest)
+
+    def run_test(self, test_name: TestName, runtests: RunTests, tracer):
+        if tracer is not None:
             # If we're tracing code coverage, then we don't exit with status
             # if on a false return value from main.
-            cmd = ('result = runtest(self.ns, test_name); '
-                   'self.accumulate_result(result)')
-            ns = dict(locals())
-            self.tracer.runctx(cmd, globals=globals(), locals=ns)
-            result = ns['result']
+            cmd = ('result = run_single_test(test_name, runtests)')
+            namespace = dict(locals())
+            tracer.runctx(cmd, globals=globals(), locals=namespace)
+            result = namespace['result']
         else:
-            result = runtest(self.ns, test_name)
-            self.accumulate_result(result)
+            result = run_single_test(test_name, runtests)
 
-        # Unload the newly imported modules (best effort finalization)
-        for module in sys.modules.keys():
-            if module not in save_modules and module.startswith("test."):
-                support.unload(module)
+        self.results.accumulate_result(result, runtests)
 
         return result
 
     def run_tests_sequentially(self, runtests):
-        ns = self.ns
-        coverage = ns.trace
-        fail_fast = ns.failfast
-        fail_env_changed = ns.fail_env_changed
-        timeout = ns.timeout
-
-        if coverage:
+        if self.coverage:
             import trace
-            self.tracer = trace.Trace(trace=False, count=True)
+            tracer = trace.Trace(trace=False, count=True)
+        else:
+            tracer = None
 
         save_modules = sys.modules.keys()
 
-        msg = "Run tests sequentially"
-        if timeout:
-            msg += " (timeout: %s)" % format_duration(timeout)
+        jobs = runtests.get_jobs()
+        if jobs is not None:
+            tests = count(jobs, 'test')
+        else:
+            tests = 'tests'
+        msg = f"Run {tests} sequentially"
+        if runtests.timeout:
+            msg += " (timeout: %s)" % format_duration(runtests.timeout)
         self.log(msg)
 
         previous_test = None
@@ -492,10 +323,19 @@ def run_tests_sequentially(self, runtests):
         for test_index, test_name in enumerate(tests_iter, 1):
             start_time = time.perf_counter()
 
-            result = self.run_test(test_index, test_name,
-                                   previous_test, save_modules)
+            text = test_name
+            if previous_test:
+                text = '%s -- %s' % (text, previous_test)
+            self.logger.display_progress(test_index, text)
+
+            result = self.run_test(test_name, runtests, tracer)
 
-            if result.must_stop(fail_fast, fail_env_changed):
+            # Unload the newly imported modules (best effort finalization)
+            for module in sys.modules.keys():
+                if module not in save_modules and module.startswith("test."):
+                    support.unload(module)
+
+            if result.must_stop(self.fail_fast, self.fail_env_changed):
                 break
 
             previous_test = str(result)
@@ -509,129 +349,19 @@ def run_tests_sequentially(self, runtests):
         if previous_test:
             print(previous_test)
 
-    def display_header(self):
-        # Print basic platform information
-        print("==", platform.python_implementation(), *sys.version.split())
-        print("==", platform.platform(aliased=True),
-                      "%s-endian" % sys.byteorder)
-        print("== Python build:", ' '.join(get_build_info()))
-        print("== cwd:", os.getcwd())
-        cpu_count = os.cpu_count()
-        if cpu_count:
-            print("== CPU count:", cpu_count)
-        print("== encodings: locale=%s, FS=%s"
-              % (locale.getencoding(), sys.getfilesystemencoding()))
-        self.display_sanitizers()
-
-    def display_sanitizers(self):
-        # This makes it easier to remember what to set in your local
-        # environment when trying to reproduce a sanitizer failure.
-        asan = support.check_sanitizer(address=True)
-        msan = support.check_sanitizer(memory=True)
-        ubsan = support.check_sanitizer(ub=True)
-        sanitizers = []
-        if asan:
-            sanitizers.append("address")
-        if msan:
-            sanitizers.append("memory")
-        if ubsan:
-            sanitizers.append("undefined behavior")
-        if not sanitizers:
-            return
+        return tracer
 
-        print(f"== sanitizers: {', '.join(sanitizers)}")
-        for sanitizer, env_var in (
-            (asan, "ASAN_OPTIONS"),
-            (msan, "MSAN_OPTIONS"),
-            (ubsan, "UBSAN_OPTIONS"),
-        ):
-            options= os.environ.get(env_var)
-            if sanitizer and options is not None:
-                print(f"== {env_var}={options!r}")
-
-    def no_tests_run(self):
-        return not any((self.good, self.bad, self.skipped, self.interrupted,
-                        self.environment_changed))
-
-    def get_tests_state(self):
-        fail_env_changed = self.ns.fail_env_changed
-
-        result = []
-        if self.bad:
-            result.append("FAILURE")
-        elif fail_env_changed and self.environment_changed:
-            result.append("ENV CHANGED")
-        elif self.no_tests_run():
-            result.append("NO TESTS RAN")
-
-        if self.interrupted:
-            result.append("INTERRUPTED")
-
-        if not result:
-            result.append("SUCCESS")
-
-        result = ', '.join(result)
+    def get_state(self):
+        state = self.results.get_state(self.fail_env_changed)
         if self.first_state:
-            result = '%s then %s' % (self.first_state, result)
-        return result
-
-    def _run_tests_mp(self, runtests: RunTests) -> None:
-        from test.libregrtest.runtest_mp import run_tests_multiprocess
-        # If we're on windows and this is the parent runner (not a worker),
-        # track the load average.
-        if sys.platform == 'win32':
-            from test.libregrtest.win_utils import WindowsLoadTracker
-
-            try:
-                self.win_load_tracker = WindowsLoadTracker()
-            except PermissionError as error:
-                # Standard accounts may not have access to the performance
-                # counters.
-                print(f'Failed to create WindowsLoadTracker: {error}')
-
-        try:
-            run_tests_multiprocess(self, runtests)
-        finally:
-            if self.win_load_tracker is not None:
-                self.win_load_tracker.close()
-                self.win_load_tracker = None
-
-    def set_tests(self, tests):
-        self.tests = tests
-        if self.ns.forever:
-            self.test_count_text = ''
-            self.test_count_width = 3
-        else:
-            self.test_count_text = '/{}'.format(len(self.tests))
-            self.test_count_width = len(self.test_count_text) - 1
+            state = f'{self.first_state} then {state}'
+        return state
 
-    def run_tests(self):
-        # For a partial run, we do not need to clutter the output.
-        if (self.ns.header
-            or not(self.ns.pgo or self.ns.quiet or self.ns.single
-                   or self.tests or self.ns.args)):
-            self.display_header()
-
-        if self.ns.huntrleaks:
-            warmup, repetitions, _ = self.ns.huntrleaks
-            if warmup < 3:
-                msg = ("WARNING: Running tests with --huntrleaks/-R and less than "
-                        "3 warmup repetitions can give false positives!")
-                print(msg, file=sys.stdout, flush=True)
-
-        if self.ns.randomize:
-            print("Using random seed", self.ns.random_seed)
-
-        tests = self.selected
-        self.set_tests(tests)
-        runtests = RunTests(tests, forever=self.ns.forever)
-        self.all_runtests.append(runtests)
-        if self.ns.use_mp:
-            self._run_tests_mp(runtests)
-        else:
-            self.run_tests_sequentially(runtests)
+    def _run_tests_mp(self, runtests: RunTests, num_workers: int) -> None:
+        from .run_workers import RunWorkers
+        RunWorkers(num_workers, runtests, self.logger, self.results).run()
 
-    def finalize(self):
+    def finalize_tests(self, tracer):
         if self.next_single_filename:
             if self.next_single_test:
                 with open(self.next_single_filename, 'w') as fp:
@@ -639,253 +369,297 @@ def finalize(self):
             else:
                 os.unlink(self.next_single_filename)
 
-        if self.tracer:
-            r = self.tracer.results()
-            r.write_results(show_missing=True, summary=True,
-                            coverdir=self.ns.coverdir)
+        if tracer is not None:
+            results = tracer.results()
+            results.write_results(show_missing=True, summary=True,
+                                  coverdir=self.coverage_dir)
 
-        if self.ns.runleaks:
+        if self.want_run_leaks:
             os.system("leaks %d" % os.getpid())
 
-        self.save_xml_result()
+        if self.junit_filename:
+            self.results.write_junit(self.junit_filename)
 
     def display_summary(self):
-        duration = time.perf_counter() - self.start_time
-        first_runtests = self.all_runtests[0]
-        # the second runtests (re-run failed tests) disables forever,
-        # use the first runtests
-        forever = first_runtests.forever
-        filtered = bool(self.ns.match_tests) or bool(self.ns.ignore_tests)
+        duration = time.perf_counter() - self.logger.start_time
+        filtered = bool(self.match_tests)
 
         # Total duration
         print()
         print("Total duration: %s" % format_duration(duration))
 
-        # Total tests
-        total = self.total_stats
-        text = f'run={total.tests_run:,}'
-        if filtered:
-            text = f"{text} (filtered)"
-        stats = [text]
-        if total.failures:
-            stats.append(f'failures={total.failures:,}')
-        if total.skipped:
-            stats.append(f'skipped={total.skipped:,}')
-        print(f"Total tests: {' '.join(stats)}")
-
-        # Total test files
-        all_tests = [self.good, self.bad, self.rerun,
-                     self.skipped,
-                     self.environment_changed, self.run_no_tests]
-        run = sum(map(len, all_tests))
-        text = f'run={run}'
-        if not forever:
-            ntest = len(first_runtests.tests)
-            text = f"{text}/{ntest}"
-        if filtered:
-            text = f"{text} (filtered)"
-        report = [text]
-        for name, tests in (
-            ('failed', self.bad),
-            ('env_changed', self.environment_changed),
-            ('skipped', self.skipped),
-            ('resource_denied', self.resource_denied),
-            ('rerun', self.rerun),
-            ('run_no_tests', self.run_no_tests),
-        ):
-            if tests:
-                report.append(f'{name}={len(tests)}')
-        print(f"Total test files: {' '.join(report)}")
+        self.results.display_summary(self.first_runtests, filtered)
 
         # Result
-        result = self.get_tests_state()
-        print(f"Result: {result}")
-
-    def save_xml_result(self):
-        if not self.ns.xmlpath and not self.testsuite_xml:
-            return
+        state = self.get_state()
+        print(f"Result: {state}")
+
+    def create_run_tests(self, tests: TestTuple):
+        return RunTests(
+            tests,
+            fail_fast=self.fail_fast,
+            fail_env_changed=self.fail_env_changed,
+            match_tests=self.match_tests,
+            match_tests_dict=None,
+            rerun=False,
+            forever=self.forever,
+            pgo=self.pgo,
+            pgo_extended=self.pgo_extended,
+            output_on_failure=self.output_on_failure,
+            timeout=self.timeout,
+            verbose=self.verbose,
+            quiet=self.quiet,
+            hunt_refleak=self.hunt_refleak,
+            test_dir=self.test_dir,
+            use_junit=(self.junit_filename is not None),
+            memory_limit=self.memory_limit,
+            gc_threshold=self.gc_threshold,
+            use_resources=self.use_resources,
+            python_cmd=self.python_cmd,
+            randomize=self.randomize,
+            random_seed=self.random_seed,
+            json_file=None,
+        )
+
+    def _run_tests(self, selected: TestTuple, tests: TestList | None) -> int:
+        if self.hunt_refleak and self.hunt_refleak.warmups < 3:
+            msg = ("WARNING: Running tests with --huntrleaks/-R and "
+                   "less than 3 warmup repetitions can give false positives!")
+            print(msg, file=sys.stdout, flush=True)
+
+        if self.num_workers < 0:
+            # Use all CPUs + 2 extra worker processes for tests
+            # that like to sleep
+            self.num_workers = (process_cpu_count() or 1) + 2
 
-        import xml.etree.ElementTree as ET
-        root = ET.Element("testsuites")
-
-        # Manually count the totals for the overall summary
-        totals = {'tests': 0, 'errors': 0, 'failures': 0}
-        for suite in self.testsuite_xml:
-            root.append(suite)
-            for k in totals:
-                try:
-                    totals[k] += int(suite.get(k, 0))
-                except ValueError:
-                    pass
-
-        for k, v in totals.items():
-            root.set(k, str(v))
-
-        xmlpath = os.path.join(os_helper.SAVEDCWD, self.ns.xmlpath)
-        with open(xmlpath, 'wb') as f:
-            for s in ET.tostringlist(root):
-                f.write(s)
-
-    def fix_umask(self):
-        if support.is_emscripten:
-            # Emscripten has default umask 0o777, which breaks some tests.
-            # see https://github.com/emscripten-core/emscripten/issues/17269
-            old_mask = os.umask(0)
-            if old_mask == 0o777:
-                os.umask(0o027)
-            else:
-                os.umask(old_mask)
-
-    def set_temp_dir(self):
-        if self.ns.tempdir:
-            self.tmp_dir = self.ns.tempdir
-
-        if not self.tmp_dir:
-            # When tests are run from the Python build directory, it is best practice
-            # to keep the test files in a subfolder.  This eases the cleanup of leftover
-            # files using the "make distclean" command.
-            if sysconfig.is_python_build():
-                self.tmp_dir = sysconfig.get_config_var('abs_builddir')
-                if self.tmp_dir is None:
-                    # bpo-30284: On Windows, only srcdir is available. Using
-                    # abs_builddir mostly matters on UNIX when building Python
-                    # out of the source tree, especially when the source tree
-                    # is read only.
-                    self.tmp_dir = sysconfig.get_config_var('srcdir')
-                self.tmp_dir = os.path.join(self.tmp_dir, 'build')
-            else:
-                self.tmp_dir = tempfile.gettempdir()
+        # For a partial run, we do not need to clutter the output.
+        if (self.want_header
+            or not(self.pgo or self.quiet or self.single_test_run
+                   or tests or self.cmdline_args)):
+            display_header(self.use_resources, self.python_cmd)
 
-        self.tmp_dir = os.path.abspath(self.tmp_dir)
+        print("Using random seed:", self.random_seed)
 
-    def is_worker(self):
-        return (self.ns.worker_args is not None)
+        runtests = self.create_run_tests(selected)
+        self.first_runtests = runtests
+        self.logger.set_tests(runtests)
 
-    def create_temp_dir(self):
-        os.makedirs(self.tmp_dir, exist_ok=True)
+        setup_process()
 
-        # Define a writable temp dir that will be used as cwd while running
-        # the tests. The name of the dir includes the pid to allow parallel
-        # testing (see the -j option).
-        # Emscripten and WASI have stubbed getpid(), Emscripten has only
-        # milisecond clock resolution. Use randint() instead.
-        if sys.platform in {"emscripten", "wasi"}:
-            nounce = random.randint(0, 1_000_000)
+        if self.hunt_refleak and not self.num_workers:
+            # gh-109739: WindowsLoadTracker thread interfers with refleak check
+            use_load_tracker = False
         else:
-            nounce = os.getpid()
+            # WindowsLoadTracker is only needed on Windows
+            use_load_tracker = MS_WINDOWS
 
-        if self.is_worker():
-            test_cwd = 'test_python_worker_{}'.format(nounce)
-        else:
-            test_cwd = 'test_python_{}'.format(nounce)
-        test_cwd += os_helper.FS_NONASCII
-        test_cwd = os.path.join(self.tmp_dir, test_cwd)
-        return test_cwd
-
-    def cleanup(self):
-        import glob
-
-        path = os.path.join(glob.escape(self.tmp_dir), 'test_python_*')
-        print("Cleanup %s directory" % self.tmp_dir)
-        for name in glob.glob(path):
-            if os.path.isdir(name):
-                print("Remove directory: %s" % name)
-                os_helper.rmtree(name)
+        if use_load_tracker:
+            self.logger.start_load_tracker()
+        try:
+            if self.num_workers:
+                self._run_tests_mp(runtests, self.num_workers)
+                tracer = None
             else:
-                print("Remove file: %s" % name)
-                os_helper.unlink(name)
+                tracer = self.run_tests_sequentially(runtests)
 
-    def main(self, tests=None, **kwargs):
-        self.parse_args(kwargs)
+            self.display_result(runtests)
 
-        self.set_temp_dir()
+            if self.want_rerun and self.results.need_rerun():
+                self.rerun_failed_tests(runtests)
+        finally:
+            if use_load_tracker:
+                self.logger.stop_load_tracker()
 
-        self.fix_umask()
+        self.display_summary()
+        self.finalize_tests(tracer)
 
-        if self.ns.cleanup:
-            self.cleanup()
-            sys.exit(0)
+        return self.results.get_exitcode(self.fail_env_changed,
+                                         self.fail_rerun)
 
-        test_cwd = self.create_temp_dir()
+    def run_tests(self, selected: TestTuple, tests: TestList | None) -> int:
+        os.makedirs(self.tmp_dir, exist_ok=True)
+        work_dir = get_work_dir(self.tmp_dir)
 
-        try:
-            # Run the tests in a context manager that temporarily changes the CWD
-            # to a temporary and writable directory. If it's not possible to
-            # create or change the CWD, the original CWD will be used.
+        # Put a timeout on Python exit
+        with exit_timeout():
+            # Run the tests in a context manager that temporarily changes the
+            # CWD to a temporary and writable directory. If it's not possible
+            # to create or change the CWD, the original CWD will be used.
             # The original CWD is available from os_helper.SAVEDCWD.
-            with os_helper.temp_cwd(test_cwd, quiet=True):
-                # When using multiprocessing, worker processes will use test_cwd
-                # as their parent temporary directory. So when the main process
-                # exit, it removes also subdirectories of worker processes.
-                self.ns.tempdir = test_cwd
+            with os_helper.temp_cwd(work_dir, quiet=True):
+                # When using multiprocessing, worker processes will use
+                # work_dir as their parent temporary directory. So when the
+                # main process exit, it removes also subdirectories of worker
+                # processes.
+                return self._run_tests(selected, tests)
+
+    def _add_cross_compile_opts(self, regrtest_opts):
+        # WASM/WASI buildbot builders pass multiple PYTHON environment
+        # variables such as PYTHONPATH and _PYTHON_HOSTRUNNER.
+        keep_environ = bool(self.python_cmd)
+        environ = None
+
+        # Are we using cross-compilation?
+        cross_compile = is_cross_compiled()
+
+        # Get HOSTRUNNER
+        hostrunner = get_host_runner()
+
+        if cross_compile:
+            # emulate -E, but keep PYTHONPATH + cross compile env vars,
+            # so test executable can load correct sysconfigdata file.
+            keep = {
+                '_PYTHON_PROJECT_BASE',
+                '_PYTHON_HOST_PLATFORM',
+                '_PYTHON_SYSCONFIGDATA_NAME',
+                'PYTHONPATH'
+            }
+            old_environ = os.environ
+            new_environ = {
+                name: value for name, value in os.environ.items()
+                if not name.startswith(('PYTHON', '_PYTHON')) or name in keep
+            }
+            # Only set environ if at least one variable was removed
+            if new_environ != old_environ:
+                environ = new_environ
+            keep_environ = True
+
+        if cross_compile and hostrunner:
+            if self.num_workers == 0:
+                # For now use only two cores for cross-compiled builds;
+                # hostrunner can be expensive.
+                regrtest_opts.extend(['-j', '2'])
+
+            # If HOSTRUNNER is set and -p/--python option is not given, then
+            # use hostrunner to execute python binary for tests.
+            if not self.python_cmd:
+                buildpython = sysconfig.get_config_var("BUILDPYTHON")
+                python_cmd = f"{hostrunner} {buildpython}"
+                regrtest_opts.extend(["--python", python_cmd])
+                keep_environ = True
+
+        return (environ, keep_environ)
+
+    def _add_ci_python_opts(self, python_opts, keep_environ):
+        # --fast-ci and --slow-ci add options to Python:
+        # "-u -W default -bb -E"
+
+        # Unbuffered stdout and stderr
+        if not sys.stdout.write_through:
+            python_opts.append('-u')
+
+        # Add warnings filter 'default'
+        if 'default' not in sys.warnoptions:
+            python_opts.extend(('-W', 'default'))
+
+        # Error on bytes/str comparison
+        if sys.flags.bytes_warning < 2:
+            python_opts.append('-bb')
+
+        if not keep_environ:
+            # Ignore PYTHON* environment variables
+            if not sys.flags.ignore_environment:
+                python_opts.append('-E')
+
+    def _execute_python(self, cmd, environ):
+        # Make sure that messages before execv() are logged
+        sys.stdout.flush()
+        sys.stderr.flush()
+
+        cmd_text = shlex.join(cmd)
+        try:
+            print(f"+ {cmd_text}", flush=True)
 
-                self._main(tests, kwargs)
-        except SystemExit as exc:
-            # bpo-38203: Python can hang at exit in Py_Finalize(), especially
-            # on threading._shutdown() call: put a timeout
-            if threading_helper.can_start_thread:
-                faulthandler.dump_traceback_later(EXIT_TIMEOUT, exit=True)
+            if hasattr(os, 'execv') and not MS_WINDOWS:
+                os.execv(cmd[0], cmd)
+                # On success, execv() do no return.
+                # On error, it raises an OSError.
+            else:
+                import subprocess
+                with subprocess.Popen(cmd, env=environ) as proc:
+                    try:
+                        proc.wait()
+                    except KeyboardInterrupt:
+                        # There is no need to call proc.terminate(): on CTRL+C,
+                        # SIGTERM is also sent to the child process.
+                        try:
+                            proc.wait(timeout=EXIT_TIMEOUT)
+                        except subprocess.TimeoutExpired:
+                            proc.kill()
+                            proc.wait()
+                            sys.exit(EXITCODE_INTERRUPTED)
+
+                sys.exit(proc.returncode)
+        except Exception as exc:
+            print_warning(f"Failed to change Python options: {exc!r}\n"
+                          f"Command: {cmd_text}")
+            # continue executing main()
+
+    def _add_python_opts(self):
+        python_opts = []
+        regrtest_opts = []
+
+        environ, keep_environ = self._add_cross_compile_opts(regrtest_opts)
+        if self.ci_mode:
+            self._add_ci_python_opts(python_opts, keep_environ)
+
+        if (not python_opts) and (not regrtest_opts) and (environ is None):
+            # Nothing changed: nothing to do
+            return
 
-            sys.exit(exc.code)
+        # Create new command line
+        cmd = list(sys.orig_argv)
+        if python_opts:
+            cmd[1:1] = python_opts
+        if regrtest_opts:
+            cmd.extend(regrtest_opts)
+        cmd.append("--dont-add-python-opts")
 
-    def getloadavg(self):
-        if self.win_load_tracker is not None:
-            return self.win_load_tracker.getloadavg()
+        self._execute_python(cmd, environ)
 
-        if hasattr(os, 'getloadavg'):
-            return os.getloadavg()[0]
+    def _init(self):
+        # Set sys.stdout encoder error handler to backslashreplace,
+        # similar to sys.stderr error handler, to avoid UnicodeEncodeError
+        # when printing a traceback or any other non-encodable character.
+        sys.stdout.reconfigure(errors="backslashreplace")
 
-        return None
+        if self.junit_filename and not os.path.isabs(self.junit_filename):
+            self.junit_filename = os.path.abspath(self.junit_filename)
 
-    def get_exitcode(self):
-        exitcode = 0
-        if self.bad:
-            exitcode = EXITCODE_BAD_TEST
-        elif self.interrupted:
-            exitcode = EXITCODE_INTERRUPTED
-        elif self.ns.fail_env_changed and self.environment_changed:
-            exitcode = EXITCODE_ENV_CHANGED
-        elif self.no_tests_run():
-            exitcode = EXITCODE_NO_TESTS_RAN
-        elif self.rerun and self.ns.fail_rerun:
-            exitcode = EXITCODE_RERUN_FAIL
-        return exitcode
-
-    def action_run_tests(self):
-        self.run_tests()
-        self.display_result()
-
-        need_rerun = self.need_rerun
-        if self.ns.rerun and need_rerun:
-            self.rerun_failed_tests(need_rerun)
+        strip_py_suffix(self.cmdline_args)
 
-        self.display_summary()
-        self.finalize()
+        self.tmp_dir = get_temp_dir(self.tmp_dir)
 
-    def _main(self, tests, kwargs):
-        if self.is_worker():
-            from test.libregrtest.runtest_mp import run_tests_worker
-            run_tests_worker(self.ns.worker_args)
-            return
+    def main(self, tests: TestList | None = None):
+        if self.want_add_python_opts:
+            self._add_python_opts()
+
+        self._init()
+
+        if self.want_cleanup:
+            cleanup_temp_dir(self.tmp_dir)
+            sys.exit(0)
 
-        if self.ns.wait:
+        if self.want_wait:
             input("Press any key to continue...")
 
-        setup_tests(self.ns)
-        self.find_tests(tests)
+        setup_test_dir(self.test_dir)
+        selected, tests = self.find_tests(tests)
 
         exitcode = 0
-        if self.ns.list_tests:
-            self.list_tests()
-        elif self.ns.list_cases:
-            self.list_cases()
+        if self.want_list_tests:
+            self.list_tests(selected)
+        elif self.want_list_cases:
+            list_cases(selected,
+                       match_tests=self.match_tests,
+                       test_dir=self.test_dir)
         else:
-            self.action_run_tests()
-            exitcode = self.get_exitcode()
+            exitcode = self.run_tests(selected, tests)
 
         sys.exit(exitcode)
 
 
-def main(tests=None, **kwargs):
+def main(tests=None, _add_python_opts=False, **kwargs):
     """Run the Python suite."""
-    Regrtest().main(tests=tests, **kwargs)
+    ns = _parse_args(sys.argv[1:], **kwargs)
+    Regrtest(ns, _add_python_opts=_add_python_opts).main(tests=tests)
diff --git a/Lib/test/libregrtest/pgo.py b/Lib/test/libregrtest/pgo.py
index 42ce5fba7a..e3a6927be5 100644
--- a/Lib/test/libregrtest/pgo.py
+++ b/Lib/test/libregrtest/pgo.py
@@ -42,15 +42,15 @@
     'test_set',
     'test_sqlite3',
     'test_statistics',
+    'test_str',
     'test_struct',
     'test_tabnanny',
     'test_time',
-    'test_unicode',
     'test_xml_etree',
     'test_xml_etree_c',
 ]
 
-def setup_pgo_tests(ns):
-    if not ns.args and not ns.pgo_extended:
+def setup_pgo_tests(cmdline_args, pgo_extended: bool):
+    if not cmdline_args and not pgo_extended:
         # run default set of tests for PGO training
-        ns.args = PGO_TESTS[:]
+        cmdline_args[:] = PGO_TESTS[:]
diff --git a/Lib/test/libregrtest/refleak.py b/Lib/test/libregrtest/refleak.py
index 206802b60d..ada1a65b86 100644
--- a/Lib/test/libregrtest/refleak.py
+++ b/Lib/test/libregrtest/refleak.py
@@ -1,10 +1,13 @@
-import os
 import sys
 import warnings
 from inspect import isabstract
+from typing import Any
+
 from test import support
 from test.support import os_helper
-from test.libregrtest.utils import clear_caches
+
+from .runtests import HuntRefleak
+from .utils import clear_caches
 
 try:
     from _abc import _get_dump
@@ -19,7 +22,9 @@ def _get_dump(cls):
                 cls._abc_negative_cache, cls._abc_negative_cache_version)
 
 
-def dash_R(ns, test_name, test_func):
+def runtest_refleak(test_name, test_func,
+                    hunt_refleak: HuntRefleak,
+                    quiet: bool):
     """Run a test multiple times, looking for reference leaks.
 
     Returns:
@@ -41,6 +46,7 @@ def dash_R(ns, test_name, test_func):
     fs = warnings.filters[:]
     ps = copyreg.dispatch_table.copy()
     pic = sys.path_importer_cache.copy()
+    zdc: dict[str, Any] | None
     try:
         import zipimport
     except ImportError:
@@ -62,9 +68,10 @@ def dash_R(ns, test_name, test_func):
     def get_pooled_int(value):
         return int_pool.setdefault(value, value)
 
-    nwarmup, ntracked, fname = ns.huntrleaks
-    fname = os.path.join(os_helper.SAVEDCWD, fname)
-    repcount = nwarmup + ntracked
+    warmups = hunt_refleak.warmups
+    runs = hunt_refleak.runs
+    filename = hunt_refleak.filename
+    repcount = warmups + runs
 
     # Pre-allocate to ensure that the loop doesn't allocate anything new
     rep_range = list(range(repcount))
@@ -78,7 +85,7 @@ def get_pooled_int(value):
     # initialize variables to make pyflakes quiet
     rc_before = alloc_before = fd_before = interned_before = 0
 
-    if not ns.quiet:
+    if not quiet:
         print("beginning", repcount, "repetitions", file=sys.stderr)
         print(("1234567890"*(repcount//10 + 1))[:repcount], file=sys.stderr,
               flush=True)
@@ -102,7 +109,7 @@ def get_pooled_int(value):
         rc_after = gettotalrefcount() - interned_after * 2
         fd_after = fd_count()
 
-        if not ns.quiet:
+        if not quiet:
             print('.', end='', file=sys.stderr, flush=True)
 
         rc_deltas[i] = get_pooled_int(rc_after - rc_before)
@@ -114,7 +121,7 @@ def get_pooled_int(value):
         fd_before = fd_after
         interned_before = interned_after
 
-    if not ns.quiet:
+    if not quiet:
         print(file=sys.stderr)
 
     # These checkers return False on success, True on failure
@@ -143,12 +150,12 @@ def check_fd_deltas(deltas):
         (fd_deltas, 'file descriptors', check_fd_deltas)
     ]:
         # ignore warmup runs
-        deltas = deltas[nwarmup:]
+        deltas = deltas[warmups:]
         if checker(deltas):
             msg = '%s leaked %s %s, sum=%s' % (
                 test_name, deltas, item_name, sum(deltas))
             print(msg, file=sys.stderr, flush=True)
-            with open(fname, "a", encoding="utf-8") as refrep:
+            with open(filename, "a", encoding="utf-8") as refrep:
                 print(msg, file=refrep)
                 refrep.flush()
             failed = True
diff --git a/Lib/test/libregrtest/result.py b/Lib/test/libregrtest/result.py
new file mode 100644
index 0000000000..8bfd3665ac
--- /dev/null
+++ b/Lib/test/libregrtest/result.py
@@ -0,0 +1,212 @@
+import dataclasses
+import json
+from typing import Any
+
+from .utils import (
+    StrJSON, TestName, FilterTuple,
+    format_duration, normalize_test_name, print_warning)
+
+
+@dataclasses.dataclass(slots=True)
+class TestStats:
+    tests_run: int = 0
+    failures: int = 0
+    skipped: int = 0
+
+    @staticmethod
+    def from_unittest(result):
+        return TestStats(result.testsRun,
+                         len(result.failures),
+                         len(result.skipped))
+
+    @staticmethod
+    def from_doctest(results):
+        return TestStats(results.attempted,
+                         results.failed,
+                         results.skipped)
+
+    def accumulate(self, stats):
+        self.tests_run += stats.tests_run
+        self.failures += stats.failures
+        self.skipped += stats.skipped
+
+
+# Avoid enum.Enum to reduce the number of imports when tests are run
+class State:
+    PASSED = "PASSED"
+    FAILED = "FAILED"
+    SKIPPED = "SKIPPED"
+    UNCAUGHT_EXC = "UNCAUGHT_EXC"
+    REFLEAK = "REFLEAK"
+    ENV_CHANGED = "ENV_CHANGED"
+    RESOURCE_DENIED = "RESOURCE_DENIED"
+    INTERRUPTED = "INTERRUPTED"
+    WORKER_FAILED = "WORKER_FAILED"   # non-zero worker process exit code
+    WORKER_BUG = "WORKER_BUG"         # exception when running a worker
+    DID_NOT_RUN = "DID_NOT_RUN"
+    TIMEOUT = "TIMEOUT"
+
+    @staticmethod
+    def is_failed(state):
+        return state in {
+            State.FAILED,
+            State.UNCAUGHT_EXC,
+            State.REFLEAK,
+            State.WORKER_FAILED,
+            State.WORKER_BUG,
+            State.TIMEOUT}
+
+    @staticmethod
+    def has_meaningful_duration(state):
+        # Consider that the duration is meaningless for these cases.
+        # For example, if a whole test file is skipped, its duration
+        # is unlikely to be the duration of executing its tests,
+        # but just the duration to execute code which skips the test.
+        return state not in {
+            State.SKIPPED,
+            State.RESOURCE_DENIED,
+            State.INTERRUPTED,
+            State.WORKER_FAILED,
+            State.WORKER_BUG,
+            State.DID_NOT_RUN}
+
+    @staticmethod
+    def must_stop(state):
+        return state in {
+            State.INTERRUPTED,
+            State.WORKER_BUG,
+        }
+
+
+@dataclasses.dataclass(slots=True)
+class TestResult:
+    test_name: TestName
+    state: str | None = None
+    # Test duration in seconds
+    duration: float | None = None
+    xml_data: list[str] | None = None
+    stats: TestStats | None = None
+
+    # errors and failures copied from support.TestFailedWithDetails
+    errors: list[tuple[str, str]] | None = None
+    failures: list[tuple[str, str]] | None = None
+
+    def is_failed(self, fail_env_changed: bool) -> bool:
+        if self.state == State.ENV_CHANGED:
+            return fail_env_changed
+        return State.is_failed(self.state)
+
+    def _format_failed(self):
+        if self.errors and self.failures:
+            le = len(self.errors)
+            lf = len(self.failures)
+            error_s = "error" + ("s" if le > 1 else "")
+            failure_s = "failure" + ("s" if lf > 1 else "")
+            return f"{self.test_name} failed ({le} {error_s}, {lf} {failure_s})"
+
+        if self.errors:
+            le = len(self.errors)
+            error_s = "error" + ("s" if le > 1 else "")
+            return f"{self.test_name} failed ({le} {error_s})"
+
+        if self.failures:
+            lf = len(self.failures)
+            failure_s = "failure" + ("s" if lf > 1 else "")
+            return f"{self.test_name} failed ({lf} {failure_s})"
+
+        return f"{self.test_name} failed"
+
+    def __str__(self) -> str:
+        match self.state:
+            case State.PASSED:
+                return f"{self.test_name} passed"
+            case State.FAILED:
+                return self._format_failed()
+            case State.SKIPPED:
+                return f"{self.test_name} skipped"
+            case State.UNCAUGHT_EXC:
+                return f"{self.test_name} failed (uncaught exception)"
+            case State.REFLEAK:
+                return f"{self.test_name} failed (reference leak)"
+            case State.ENV_CHANGED:
+                return f"{self.test_name} failed (env changed)"
+            case State.RESOURCE_DENIED:
+                return f"{self.test_name} skipped (resource denied)"
+            case State.INTERRUPTED:
+                return f"{self.test_name} interrupted"
+            case State.WORKER_FAILED:
+                return f"{self.test_name} worker non-zero exit code"
+            case State.WORKER_BUG:
+                return f"{self.test_name} worker bug"
+            case State.DID_NOT_RUN:
+                return f"{self.test_name} ran no tests"
+            case State.TIMEOUT:
+                return f"{self.test_name} timed out ({format_duration(self.duration)})"
+            case _:
+                raise ValueError("unknown result state: {state!r}")
+
+    def has_meaningful_duration(self):
+        return State.has_meaningful_duration(self.state)
+
+    def set_env_changed(self):
+        if self.state is None or self.state == State.PASSED:
+            self.state = State.ENV_CHANGED
+
+    def must_stop(self, fail_fast: bool, fail_env_changed: bool) -> bool:
+        if State.must_stop(self.state):
+            return True
+        if fail_fast and self.is_failed(fail_env_changed):
+            return True
+        return False
+
+    def get_rerun_match_tests(self) -> FilterTuple | None:
+        match_tests = []
+
+        errors = self.errors or []
+        failures = self.failures or []
+        for error_list, is_error in (
+            (errors, True),
+            (failures, False),
+        ):
+            for full_name, *_ in error_list:
+                match_name = normalize_test_name(full_name, is_error=is_error)
+                if match_name is None:
+                    # 'setUpModule (test.test_sys)': don't filter tests
+                    return None
+                if not match_name:
+                    error_type = "ERROR" if is_error else "FAIL"
+                    print_warning(f"rerun failed to parse {error_type} test name: "
+                                  f"{full_name!r}: don't filter tests")
+                    return None
+                match_tests.append(match_name)
+
+        if not match_tests:
+            return None
+        return tuple(match_tests)
+
+    def write_json_into(self, file) -> None:
+        json.dump(self, file, cls=_EncodeTestResult)
+
+    @staticmethod
+    def from_json(worker_json: StrJSON) -> 'TestResult':
+        return json.loads(worker_json, object_hook=_decode_test_result)
+
+
+class _EncodeTestResult(json.JSONEncoder):
+    def default(self, o: Any) -> dict[str, Any]:
+        if isinstance(o, TestResult):
+            result = dataclasses.asdict(o)
+            result["__test_result__"] = o.__class__.__name__
+            return result
+        else:
+            return super().default(o)
+
+
+def _decode_test_result(data: dict[str, Any]) -> TestResult | dict[str, Any]:
+    if "__test_result__" in data:
+        data.pop('__test_result__')
+        if data['stats'] is not None:
+            data['stats'] = TestStats(**data['stats'])
+        return TestResult(**data)
+    else:
+        return data
diff --git a/Lib/test/libregrtest/results.py b/Lib/test/libregrtest/results.py
new file mode 100644
index 0000000000..1feb43f8c0
--- /dev/null
+++ b/Lib/test/libregrtest/results.py
@@ -0,0 +1,260 @@
+import sys
+
+from .runtests import RunTests
+from .result import State, TestResult, TestStats
+from .utils import (
+    StrPath, TestName, TestTuple, TestList, FilterDict,
+    printlist, count, format_duration)
+
+
+# Python uses exit code 1 when an exception is not catched
+# argparse.ArgumentParser.error() uses exit code 2
+EXITCODE_BAD_TEST = 2
+EXITCODE_ENV_CHANGED = 3
+EXITCODE_NO_TESTS_RAN = 4
+EXITCODE_RERUN_FAIL = 5
+EXITCODE_INTERRUPTED = 130   # 128 + signal.SIGINT=2
+
+
+class TestResults:
+    def __init__(self):
+        self.bad: TestList = []
+        self.good: TestList = []
+        self.rerun_bad: TestList = []
+        self.skipped: TestList = []
+        self.resource_denied: TestList = []
+        self.env_changed: TestList = []
+        self.run_no_tests: TestList = []
+        self.rerun: TestList = []
+        self.rerun_results: list[TestResult] = []
+
+        self.interrupted: bool = False
+        self.worker_bug: bool = False
+        self.test_times: list[tuple[float, TestName]] = []
+        self.stats = TestStats()
+        # used by --junit-xml
+        self.testsuite_xml: list[str] = []
+
+    def is_all_good(self):
+        return (not self.bad
+                and not self.skipped
+                and not self.interrupted
+                and not self.worker_bug)
+
+    def get_executed(self):
+        return (set(self.good) | set(self.bad) | set(self.skipped)
+                | set(self.resource_denied) | set(self.env_changed)
+                | set(self.run_no_tests))
+
+    def no_tests_run(self):
+        return not any((self.good, self.bad, self.skipped, self.interrupted,
+                        self.env_changed))
+
+    def get_state(self, fail_env_changed):
+        state = []
+        if self.bad:
+            state.append("FAILURE")
+        elif fail_env_changed and self.env_changed:
+            state.append("ENV CHANGED")
+        elif self.no_tests_run():
+            state.append("NO TESTS RAN")
+
+        if self.interrupted:
+            state.append("INTERRUPTED")
+        if self.worker_bug:
+            state.append("WORKER BUG")
+        if not state:
+            state.append("SUCCESS")
+
+        return ', '.join(state)
+
+    def get_exitcode(self, fail_env_changed, fail_rerun):
+        exitcode = 0
+        if self.bad:
+            exitcode = EXITCODE_BAD_TEST
+        elif self.interrupted:
+            exitcode = EXITCODE_INTERRUPTED
+        elif fail_env_changed and self.env_changed:
+            exitcode = EXITCODE_ENV_CHANGED
+        elif self.no_tests_run():
+            exitcode = EXITCODE_NO_TESTS_RAN
+        elif fail_rerun and self.rerun:
+            exitcode = EXITCODE_RERUN_FAIL
+        elif self.worker_bug:
+            exitcode = EXITCODE_BAD_TEST
+        return exitcode
+
+    def accumulate_result(self, result: TestResult, runtests: RunTests):
+        test_name = result.test_name
+        rerun = runtests.rerun
+        fail_env_changed = runtests.fail_env_changed
+
+        match result.state:
+            case State.PASSED:
+                self.good.append(test_name)
+            case State.ENV_CHANGED:
+                self.env_changed.append(test_name)
+                self.rerun_results.append(result)
+            case State.SKIPPED:
+                self.skipped.append(test_name)
+            case State.RESOURCE_DENIED:
+                self.resource_denied.append(test_name)
+            case State.INTERRUPTED:
+                self.interrupted = True
+            case State.DID_NOT_RUN:
+                self.run_no_tests.append(test_name)
+            case _:
+                if result.is_failed(fail_env_changed):
+                    self.bad.append(test_name)
+                    self.rerun_results.append(result)
+                else:
+                    raise ValueError(f"invalid test state: {result.state!r}")
+
+        if result.state == State.WORKER_BUG:
+            self.worker_bug = True
+
+        if result.has_meaningful_duration() and not rerun:
+            self.test_times.append((result.duration, test_name))
+        if result.stats is not None:
+            self.stats.accumulate(result.stats)
+        if rerun:
+            self.rerun.append(test_name)
+
+        xml_data = result.xml_data
+        if xml_data:
+            self.add_junit(xml_data)
+
+    def need_rerun(self):
+        return bool(self.rerun_results)
+
+    def prepare_rerun(self) -> tuple[TestTuple, FilterDict]:
+        tests: TestList = []
+        match_tests_dict = {}
+        for result in self.rerun_results:
+            tests.append(result.test_name)
+
+            match_tests = result.get_rerun_match_tests()
+            # ignore empty match list
+            if match_tests:
+                match_tests_dict[result.test_name] = match_tests
+
+        # Clear previously failed tests
+        self.rerun_bad.extend(self.bad)
+        self.bad.clear()
+        self.env_changed.clear()
+        self.rerun_results.clear()
+
+        return (tuple(tests), match_tests_dict)
+
+    def add_junit(self, xml_data: list[str]):
+        import xml.etree.ElementTree as ET
+        for e in xml_data:
+            try:
+                self.testsuite_xml.append(ET.fromstring(e))
+            except ET.ParseError:
+                print(xml_data, file=sys.__stderr__)
+                raise
+
+    def write_junit(self, filename: StrPath):
+        if not self.testsuite_xml:
+            # Don't create empty XML file
+            return
+
+        import xml.etree.ElementTree as ET
+        root = ET.Element("testsuites")
+
+        # Manually count the totals for the overall summary
+        totals = {'tests': 0, 'errors': 0, 'failures': 0}
+        for suite in self.testsuite_xml:
+            root.append(suite)
+            for k in totals:
+                try:
+                    totals[k] += int(suite.get(k, 0))
+                except ValueError:
+                    pass
+
+        for k, v in totals.items():
+            root.set(k, str(v))
+
+        with open(filename, 'wb') as f:
+            for s in ET.tostringlist(root):
+                f.write(s)
+
+    def display_result(self, tests: TestTuple, quiet: bool, print_slowest: bool):
+        if print_slowest:
+            self.test_times.sort(reverse=True)
+            print()
+            print("10 slowest tests:")
+            for test_time, test in self.test_times[:10]:
+                print("- %s: %s" % (test, format_duration(test_time)))
+
+        all_tests = []
+        omitted = set(tests) - self.get_executed()
+
+        # less important
+        all_tests.append((omitted, "test", "{} omitted:"))
+        if not quiet:
+            all_tests.append((self.skipped, "test", "{} skipped:"))
+            all_tests.append((self.resource_denied, "test", "{} skipped (resource denied):"))
+        all_tests.append((self.run_no_tests, "test", "{} run no tests:"))
+
+        # more important
+        all_tests.append((self.env_changed, "test", "{} altered the execution environment (env changed):"))
+        all_tests.append((self.rerun, "re-run test", "{}:"))
+        all_tests.append((self.bad, "test", "{} failed:"))
+
+        for tests_list, count_text, title_format in all_tests:
+            if tests_list:
+                print()
+                count_text = count(len(tests_list), count_text)
+                print(title_format.format(count_text))
+                printlist(tests_list)
+
+        if self.good and not quiet:
+            print()
+            text = count(len(self.good), "test")
+            text = f"{text} OK."
+            if (self.is_all_good() and len(self.good) > 1):
+                text = f"All {text}"
+            print(text)
+
+        if self.interrupted:
+            print()
+            print("Test suite interrupted by signal SIGINT.")
+
+    def display_summary(self, first_runtests: RunTests, filtered: bool):
+        # Total tests
+        stats = self.stats
+        text = f'run={stats.tests_run:,}'
+        if filtered:
+            text = f"{text} (filtered)"
+        report = [text]
+        if stats.failures:
+            report.append(f'failures={stats.failures:,}')
+        if stats.skipped:
+            report.append(f'skipped={stats.skipped:,}')
+        print(f"Total tests: {' '.join(report)}")
+
+        # Total test files
+        all_tests = [self.good, self.bad, self.rerun,
+                     self.skipped,
+                     self.env_changed, self.run_no_tests]
+        run = sum(map(len, all_tests))
+        text = f'run={run}'
+        if not first_runtests.forever:
+            ntest = len(first_runtests.tests)
+            text = f"{text}/{ntest}"
+        if filtered:
+            text = f"{text} (filtered)"
+        report = [text]
+        for name, tests in (
+            ('failed', self.bad),
+            ('env_changed', self.env_changed),
+            ('skipped', self.skipped),
+            ('resource_denied', self.resource_denied),
+            ('rerun', self.rerun),
+            ('run_no_tests', self.run_no_tests),
+        ):
+            if tests:
+                report.append(f'{name}={len(tests)}')
+        print(f"Total test files: {' '.join(report)}")
diff --git a/Lib/test/libregrtest/run_workers.py b/Lib/test/libregrtest/run_workers.py
new file mode 100644
index 0000000000..ab03cb54d6
--- /dev/null
+++ b/Lib/test/libregrtest/run_workers.py
@@ -0,0 +1,607 @@
+import contextlib
+import dataclasses
+import faulthandler
+import os.path
+import queue
+import signal
+import subprocess
+import sys
+import tempfile
+import threading
+import time
+import traceback
+from typing import Literal, TextIO
+
+from test import support
+from test.support import os_helper, MS_WINDOWS
+
+from .logger import Logger
+from .result import TestResult, State
+from .results import TestResults
+from .runtests import RunTests, JsonFile, JsonFileType
+from .single import PROGRESS_MIN_TIME
+from .utils import (
+    StrPath, TestName,
+    format_duration, print_warning, count, plural, get_signal_name)
+from .worker import create_worker_process, USE_PROCESS_GROUP
+
+if MS_WINDOWS:
+    import locale
+    import msvcrt
+
+
+
+# Display the running tests if nothing happened last N seconds
+PROGRESS_UPDATE = 30.0   # seconds
+assert PROGRESS_UPDATE >= PROGRESS_MIN_TIME
+
+# Kill the main process after 5 minutes. It is supposed to write an update
+# every PROGRESS_UPDATE seconds. Tolerate 5 minutes for Python slowest
+# buildbot workers.
+MAIN_PROCESS_TIMEOUT = 5 * 60.0
+assert MAIN_PROCESS_TIMEOUT >= PROGRESS_UPDATE
+
+# Time to wait until a worker completes: should be immediate
+WAIT_COMPLETED_TIMEOUT = 30.0   # seconds
+
+# Time to wait a killed process (in seconds)
+WAIT_KILLED_TIMEOUT = 60.0
+
+
+# We do not use a generator so multiple threads can call next().
+class MultiprocessIterator:
+
+    """A thread-safe iterator over tests for multiprocess mode."""
+
+    def __init__(self, tests_iter):
+        self.lock = threading.Lock()
+        self.tests_iter = tests_iter
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        with self.lock:
+            if self.tests_iter is None:
+                raise StopIteration
+            return next(self.tests_iter)
+
+    def stop(self):
+        with self.lock:
+            self.tests_iter = None
+
+
+@dataclasses.dataclass(slots=True, frozen=True)
+class MultiprocessResult:
+    result: TestResult
+    # bpo-45410: stderr is written into stdout to keep messages order
+    worker_stdout: str | None = None
+    err_msg: str | None = None
+
+
+ExcStr = str
+QueueOutput = tuple[Literal[False], MultiprocessResult] | tuple[Literal[True], ExcStr]
+
+
+class ExitThread(Exception):
+    pass
+
+
+class WorkerError(Exception):
+    def __init__(self,
+                 test_name: TestName,
+                 err_msg: str | None,
+                 stdout: str | None,
+                 state: str):
+        result = TestResult(test_name, state=state)
+        self.mp_result = MultiprocessResult(result, stdout, err_msg)
+        super().__init__()
+
+
+class WorkerThread(threading.Thread):
+    def __init__(self, worker_id: int, runner: "RunWorkers") -> None:
+        super().__init__()
+        self.worker_id = worker_id
+        self.runtests = runner.runtests
+        self.pending = runner.pending
+        self.output = runner.output
+        self.timeout = runner.worker_timeout
+        self.log = runner.log
+        self.test_name: TestName | None = None
+        self.start_time: float | None = None
+        self._popen: subprocess.Popen[str] | None = None
+        self._killed = False
+        self._stopped = False
+
+    def __repr__(self) -> str:
+        info = [f'WorkerThread #{self.worker_id}']
+        if self.is_alive():
+            info.append("running")
+        else:
+            info.append('stopped')
+        test = self.test_name
+        if test:
+            info.append(f'test={test}')
+        popen = self._popen
+        if popen is not None:
+            dt = time.monotonic() - self.start_time
+            info.extend((f'pid={self._popen.pid}',
+                         f'time={format_duration(dt)}'))
+        return '<%s>' % ' '.join(info)
+
+    def _kill(self) -> None:
+        popen = self._popen
+        if popen is None:
+            return
+
+        if self._killed:
+            return
+        self._killed = True
+
+        if USE_PROCESS_GROUP:
+            what = f"{self} process group"
+        else:
+            what = f"{self} process"
+
+        print(f"Kill {what}", file=sys.stderr, flush=True)
+        try:
+            if USE_PROCESS_GROUP:
+                os.killpg(popen.pid, signal.SIGKILL)
+            else:
+                popen.kill()
+        except ProcessLookupError:
+            # popen.kill(): the process completed, the WorkerThread thread
+            # read its exit status, but Popen.send_signal() read the returncode
+            # just before Popen.wait() set returncode.
+            pass
+        except OSError as exc:
+            print_warning(f"Failed to kill {what}: {exc!r}")
+
+    def stop(self) -> None:
+        # Method called from a different thread to stop this thread
+        self._stopped = True
+        self._kill()
+
+    def _run_process(self, runtests: RunTests, output_fd: int,
+                     tmp_dir: StrPath | None = None) -> int | None:
+        popen = create_worker_process(runtests, output_fd, tmp_dir)
+        self._popen = popen
+        self._killed = False
+
+        try:
+            if self._stopped:
+                # If kill() has been called before self._popen is set,
+                # self._popen is still running. Call again kill()
+                # to ensure that the process is killed.
+                self._kill()
+                raise ExitThread
+
+            try:
+                # gh-94026: stdout+stderr are written to tempfile
+                retcode = popen.wait(timeout=self.timeout)
+                assert retcode is not None
+                return retcode
+            except subprocess.TimeoutExpired:
+                if self._stopped:
+                    # kill() has been called: communicate() fails on reading
+                    # closed stdout
+                    raise ExitThread
+
+                # On timeout, kill the process
+                self._kill()
+
+                # None means TIMEOUT for the caller
+                retcode = None
+                # bpo-38207: Don't attempt to call communicate() again: on it
+                # can hang until all child processes using stdout
+                # pipes completes.
+            except OSError:
+                if self._stopped:
+                    # kill() has been called: communicate() fails
+                    # on reading closed stdout
+                    raise ExitThread
+                raise
+        except:
+            self._kill()
+            raise
+        finally:
+            self._wait_completed()
+            self._popen = None
+
+    def create_stdout(self, stack: contextlib.ExitStack) -> TextIO:
+        """Create stdout temporay file (file descriptor)."""
+
+        if MS_WINDOWS:
+            # gh-95027: When stdout is not a TTY, Python uses the ANSI code
+            # page for the sys.stdout encoding. If the main process runs in a
+            # terminal, sys.stdout uses WindowsConsoleIO with UTF-8 encoding.
+            encoding = locale.getencoding()
+        else:
+            encoding = sys.stdout.encoding
+
+        # gh-94026: Write stdout+stderr to a tempfile as workaround for
+        # non-blocking pipes on Emscripten with NodeJS.
+        # gh-109425: Use "backslashreplace" error handler: log corrupted
+        # stdout+stderr, instead of failing with a UnicodeDecodeError and not
+        # logging stdout+stderr at all.
+        stdout_file = tempfile.TemporaryFile('w+',
+                                             encoding=encoding,
+                                             errors='backslashreplace')
+        stack.enter_context(stdout_file)
+        return stdout_file
+
+    def create_json_file(self, stack: contextlib.ExitStack) -> tuple[JsonFile, TextIO | None]:
+        """Create JSON file."""
+
+        json_file_use_stdout = self.runtests.json_file_use_stdout()
+        if json_file_use_stdout:
+            json_file = JsonFile(None, JsonFileType.STDOUT)
+            json_tmpfile = None
+        else:
+            json_tmpfile = tempfile.TemporaryFile('w+', encoding='utf8')
+            stack.enter_context(json_tmpfile)
+
+            json_fd = json_tmpfile.fileno()
+            if MS_WINDOWS:
+                json_handle = msvcrt.get_osfhandle(json_fd)
+                json_file = JsonFile(json_handle,
+                                     JsonFileType.WINDOWS_HANDLE)
+            else:
+                json_file = JsonFile(json_fd, JsonFileType.UNIX_FD)
+        return (json_file, json_tmpfile)
+
+    def create_worker_runtests(self, test_name: TestName, json_file: JsonFile) -> RunTests:
+        """Create the worker RunTests."""
+
+        tests = (test_name,)
+        if self.runtests.rerun:
+            match_tests = self.runtests.get_match_tests(test_name)
+        else:
+            match_tests = None
+
+        kwargs = {}
+        if match_tests:
+            kwargs['match_tests'] = [(test, True) for test in match_tests]
+        if self.runtests.output_on_failure:
+            kwargs['verbose'] = True
+            kwargs['output_on_failure'] = False
+        return self.runtests.copy(
+            tests=tests,
+            json_file=json_file,
+            **kwargs)
+
+    def run_tmp_files(self, worker_runtests: RunTests,
+                      stdout_fd: int) -> tuple[int | None, list[StrPath]]:
+        # gh-93353: Check for leaked temporary files in the parent process,
+        # since the deletion of temporary files can happen late during
+        # Python finalization: too late for libregrtest.
+        if not support.is_wasi:
+            # Don't check for leaked temporary files and directories if Python is
+            # run on WASI. WASI don't pass environment variables like TMPDIR to
+            # worker processes.
+            tmp_dir = tempfile.mkdtemp(prefix="test_python_")
+            tmp_dir = os.path.abspath(tmp_dir)
+            try:
+                retcode = self._run_process(worker_runtests,
+                                            stdout_fd, tmp_dir)
+            finally:
+                tmp_files = os.listdir(tmp_dir)
+                os_helper.rmtree(tmp_dir)
+        else:
+            retcode = self._run_process(worker_runtests, stdout_fd)
+            tmp_files = []
+
+        return (retcode, tmp_files)
+
+    def read_stdout(self, stdout_file: TextIO) -> str:
+        stdout_file.seek(0)
+        try:
+            return stdout_file.read().strip()
+        except Exception as exc:
+            # gh-101634: Catch UnicodeDecodeError if stdout cannot be
+            # decoded from encoding
+            raise WorkerError(self.test_name,
+                              f"Cannot read process stdout: {exc}",
+                              stdout=None,
+                              state=State.WORKER_BUG)
+
+    def read_json(self, json_file: JsonFile, json_tmpfile: TextIO | None,
+                  stdout: str) -> tuple[TestResult, str]:
+        try:
+            if json_tmpfile is not None:
+                json_tmpfile.seek(0)
+                worker_json = json_tmpfile.read()
+            elif json_file.file_type == JsonFileType.STDOUT:
+                stdout, _, worker_json = stdout.rpartition("\n")
+                stdout = stdout.rstrip()
+            else:
+                with json_file.open(encoding='utf8') as json_fp:
+                    worker_json = json_fp.read()
+        except Exception as exc:
+            # gh-101634: Catch UnicodeDecodeError if stdout cannot be
+            # decoded from encoding
+            err_msg = f"Failed to read worker process JSON: {exc}"
+            raise WorkerError(self.test_name, err_msg, stdout,
+                              state=State.WORKER_BUG)
+
+        if not worker_json:
+            raise WorkerError(self.test_name, "empty JSON", stdout,
+                              state=State.WORKER_BUG)
+
+        try:
+            result = TestResult.from_json(worker_json)
+        except Exception as exc:
+            # gh-101634: Catch UnicodeDecodeError if stdout cannot be
+            # decoded from encoding
+            err_msg = f"Failed to parse worker process JSON: {exc}"
+            raise WorkerError(self.test_name, err_msg, stdout,
+                              state=State.WORKER_BUG)
+
+        return (result, stdout)
+
+    def _runtest(self, test_name: TestName) -> MultiprocessResult:
+        with contextlib.ExitStack() as stack:
+            stdout_file = self.create_stdout(stack)
+            json_file, json_tmpfile = self.create_json_file(stack)
+            worker_runtests = self.create_worker_runtests(test_name, json_file)
+
+            retcode, tmp_files = self.run_tmp_files(worker_runtests,
+                                                    stdout_file.fileno())
+
+            stdout = self.read_stdout(stdout_file)
+
+            if retcode is None:
+                raise WorkerError(self.test_name, stdout=stdout,
+                                  err_msg=None,
+                                  state=State.TIMEOUT)
+            if retcode != 0:
+                name = get_signal_name(retcode)
+                if name:
+                    retcode = f"{retcode} ({name})"
+                raise WorkerError(self.test_name, f"Exit code {retcode}", stdout,
+                                  state=State.WORKER_FAILED)
+
+            result, stdout = self.read_json(json_file, json_tmpfile, stdout)
+
+        if tmp_files:
+            msg = (f'\n\n'
+                   f'Warning -- {test_name} leaked temporary files '
+                   f'({len(tmp_files)}): {", ".join(sorted(tmp_files))}')
+            stdout += msg
+            result.set_env_changed()
+
+        return MultiprocessResult(result, stdout)
+
+    def run(self) -> None:
+        fail_fast = self.runtests.fail_fast
+        fail_env_changed = self.runtests.fail_env_changed
+        while not self._stopped:
+            try:
+                try:
+                    test_name = next(self.pending)
+                except StopIteration:
+                    break
+
+                self.start_time = time.monotonic()
+                self.test_name = test_name
+                try:
+                    mp_result = self._runtest(test_name)
+                except WorkerError as exc:
+                    mp_result = exc.mp_result
+                finally:
+                    self.test_name = None
+                mp_result.result.duration = time.monotonic() - self.start_time
+                self.output.put((False, mp_result))
+
+                if mp_result.result.must_stop(fail_fast, fail_env_changed):
+                    break
+            except ExitThread:
+                break
+            except BaseException:
+                self.output.put((True, traceback.format_exc()))
+                break
+
+    def _wait_completed(self) -> None:
+        popen = self._popen
+
+        try:
+            popen.wait(WAIT_COMPLETED_TIMEOUT)
+        except (subprocess.TimeoutExpired, OSError) as exc:
+            print_warning(f"Failed to wait for {self} completion "
+                          f"(timeout={format_duration(WAIT_COMPLETED_TIMEOUT)}): "
+                          f"{exc!r}")
+
+    def wait_stopped(self, start_time: float) -> None:
+        # bpo-38207: RunWorkers.stop_workers() called self.stop()
+        # which killed the process. Sometimes, killing the process from the
+        # main thread does not interrupt popen.communicate() in
+        # WorkerThread thread. This loop with a timeout is a workaround
+        # for that.
+        #
+        # Moreover, if this method fails to join the thread, it is likely
+        # that Python will hang at exit while calling threading._shutdown()
+        # which tries again to join the blocked thread. Regrtest.main()
+        # uses EXIT_TIMEOUT to workaround this second bug.
+        while True:
+            # Write a message every second
+            self.join(1.0)
+            if not self.is_alive():
+                break
+            dt = time.monotonic() - start_time
+            self.log(f"Waiting for {self} thread for {format_duration(dt)}")
+            if dt > WAIT_KILLED_TIMEOUT:
+                print_warning(f"Failed to join {self} in {format_duration(dt)}")
+                break
+
+
+def get_running(workers: list[WorkerThread]) -> str | None:
+    running: list[str] = []
+    for worker in workers:
+        test_name = worker.test_name
+        if not test_name:
+            continue
+        dt = time.monotonic() - worker.start_time
+        if dt >= PROGRESS_MIN_TIME:
+            text = f'{test_name} ({format_duration(dt)})'
+            running.append(text)
+    if not running:
+        return None
+    return f"running ({len(running)}): {', '.join(running)}"
+
+
+class RunWorkers:
+    def __init__(self, num_workers: int, runtests: RunTests,
+                 logger: Logger, results: TestResults) -> None:
+        self.num_workers = num_workers
+        self.runtests = runtests
+        self.log = logger.log
+        self.display_progress = logger.display_progress
+        self.results: TestResults = results
+
+        self.output: queue.Queue[QueueOutput] = queue.Queue()
+        tests_iter = runtests.iter_tests()
+        self.pending = MultiprocessIterator(tests_iter)
+        self.timeout = runtests.timeout
+        if self.timeout is not None:
+            # Rely on faulthandler to kill a worker process. This timouet is
+            # when faulthandler fails to kill a worker process. Give a maximum
+            # of 5 minutes to faulthandler to kill the worker.
+            self.worker_timeout: float | None = min(self.timeout * 1.5, self.timeout + 5 * 60)
+        else:
+            self.worker_timeout = None
+        self.workers: list[WorkerThread] | None = None
+
+        jobs = self.runtests.get_jobs()
+        if jobs is not None:
+            # Don't spawn more threads than the number of jobs:
+            # these worker threads would never get anything to do.
+            self.num_workers = min(self.num_workers, jobs)
+
+    def start_workers(self) -> None:
+        self.workers = [WorkerThread(index, self)
+                        for index in range(1, self.num_workers + 1)]
+        jobs = self.runtests.get_jobs()
+        if jobs is not None:
+            tests = count(jobs, 'test')
+        else:
+            tests = 'tests'
+        nworkers = len(self.workers)
+        processes = plural(nworkers, "process", "processes")
+        msg = (f"Run {tests} in parallel using "
+               f"{nworkers} worker {processes}")
+        if self.timeout:
+            msg += (" (timeout: %s, worker timeout: %s)"
+                    % (format_duration(self.timeout),
+                       format_duration(self.worker_timeout)))
+        self.log(msg)
+        for worker in self.workers:
+            worker.start()
+
+    def stop_workers(self) -> None:
+        start_time = time.monotonic()
+        for worker in self.workers:
+            worker.stop()
+        for worker in self.workers:
+            worker.wait_stopped(start_time)
+
+    def _get_result(self) -> QueueOutput | None:
+        pgo = self.runtests.pgo
+        use_faulthandler = (self.timeout is not None)
+
+        # bpo-46205: check the status of workers every iteration to avoid
+        # waiting forever on an empty queue.
+        while any(worker.is_alive() for worker in self.workers):
+            if use_faulthandler:
+                faulthandler.dump_traceback_later(MAIN_PROCESS_TIMEOUT,
+                                                  exit=True)
+
+            # wait for a thread
+            try:
+                return self.output.get(timeout=PROGRESS_UPDATE)
+            except queue.Empty:
+                pass
+
+            if not pgo:
+                # display progress
+                running = get_running(self.workers)
+                if running:
+                    self.log(running)
+
+        # all worker threads are done: consume pending results
+        try:
+            return self.output.get(timeout=0)
+        except queue.Empty:
+            return None
+
+    def display_result(self, mp_result: MultiprocessResult) -> None:
+        result = mp_result.result
+        pgo = self.runtests.pgo
+
+        text = str(result)
+        if mp_result.err_msg:
+            # WORKER_BUG
+            text += ' (%s)' % mp_result.err_msg
+        elif (result.duration >= PROGRESS_MIN_TIME and not pgo):
+            text += ' (%s)' % format_duration(result.duration)
+        if not pgo:
+            running = get_running(self.workers)
+            if running:
+                text += f' -- {running}'
+        self.display_progress(self.test_index, text)
+
+    def _process_result(self, item: QueueOutput) -> TestResult:
+        """Returns True if test runner must stop."""
+        if item[0]:
+            # Thread got an exception
+            format_exc = item[1]
+            print_warning(f"regrtest worker thread failed: {format_exc}")
+            result = TestResult("<regrtest worker>", state=State.WORKER_BUG)
+            self.results.accumulate_result(result, self.runtests)
+            return result
+
+        self.test_index += 1
+        mp_result = item[1]
+        result = mp_result.result
+        self.results.accumulate_result(result, self.runtests)
+        self.display_result(mp_result)
+
+        # Display worker stdout
+        if not self.runtests.output_on_failure:
+            show_stdout = True
+        else:
+            # --verbose3 ignores stdout on success
+            show_stdout = (result.state != State.PASSED)
+        if show_stdout:
+            stdout = mp_result.worker_stdout
+            if stdout:
+                print(stdout, flush=True)
+
+        return result
+
+    def run(self) -> None:
+        fail_fast = self.runtests.fail_fast
+        fail_env_changed = self.runtests.fail_env_changed
+
+        self.start_workers()
+
+        self.test_index = 0
+        try:
+            while True:
+                item = self._get_result()
+                if item is None:
+                    break
+
+                result = self._process_result(item)
+                if result.must_stop(fail_fast, fail_env_changed):
+                    break
+        except KeyboardInterrupt:
+            print()
+            self.results.interrupted = True
+        finally:
+            if self.timeout is not None:
+                faulthandler.cancel_dump_traceback_later()
+
+            # Always ensure that all worker processes are no longer
+            # worker when we exit this function
+            self.pending.stop()
+            self.stop_workers()
diff --git a/Lib/test/libregrtest/runtest.py b/Lib/test/libregrtest/runtest.py
deleted file mode 100644
index 16ae04191d..0000000000
--- a/Lib/test/libregrtest/runtest.py
+++ /dev/null
@@ -1,575 +0,0 @@
-import dataclasses
-import doctest
-import faulthandler
-import gc
-import importlib
-import io
-import os
-import sys
-import time
-import traceback
-import unittest
-
-from test import support
-from test.support import TestStats
-from test.support import os_helper
-from test.support import threading_helper
-from test.libregrtest.cmdline import Namespace
-from test.libregrtest.save_env import saved_test_environment
-from test.libregrtest.utils import clear_caches, format_duration, print_warning
-
-
-MatchTests = list[str]
-MatchTestsDict = dict[str, MatchTests]
-
-
-# Avoid enum.Enum to reduce the number of imports when tests are run
-class State:
-    PASSED = "PASSED"
-    FAILED = "FAILED"
-    SKIPPED = "SKIPPED"
-    UNCAUGHT_EXC = "UNCAUGHT_EXC"
-    REFLEAK = "REFLEAK"
-    ENV_CHANGED = "ENV_CHANGED"
-    RESOURCE_DENIED = "RESOURCE_DENIED"
-    INTERRUPTED = "INTERRUPTED"
-    MULTIPROCESSING_ERROR = "MULTIPROCESSING_ERROR"
-    DID_NOT_RUN = "DID_NOT_RUN"
-    TIMEOUT = "TIMEOUT"
-
-    @staticmethod
-    def is_failed(state):
-        return state in {
-            State.FAILED,
-            State.UNCAUGHT_EXC,
-            State.REFLEAK,
-            State.MULTIPROCESSING_ERROR,
-            State.TIMEOUT}
-
-    @staticmethod
-    def has_meaningful_duration(state):
-        # Consider that the duration is meaningless for these cases.
-        # For example, if a whole test file is skipped, its duration
-        # is unlikely to be the duration of executing its tests,
-        # but just the duration to execute code which skips the test.
-        return state not in {
-            State.SKIPPED,
-            State.RESOURCE_DENIED,
-            State.INTERRUPTED,
-            State.MULTIPROCESSING_ERROR,
-            State.DID_NOT_RUN}
-
-    @staticmethod
-    def must_stop(state):
-        return state in {
-            State.INTERRUPTED,
-            State.MULTIPROCESSING_ERROR}
-
-
-# gh-90681: When rerunning tests, we might need to rerun the whole
-# class or module suite if some its life-cycle hooks fail.
-# Test level hooks are not affected.
-_TEST_LIFECYCLE_HOOKS = frozenset((
-    'setUpClass', 'tearDownClass',
-    'setUpModule', 'tearDownModule',
-))
-
-def normalize_test_name(test_full_name, *, is_error=False):
-    short_name = test_full_name.split(" ")[0]
-    if is_error and short_name in _TEST_LIFECYCLE_HOOKS:
-        if test_full_name.startswith(('setUpModule (', 'tearDownModule (')):
-            # if setUpModule() or tearDownModule() failed, don't filter
-            # tests with the test file name, don't use use filters.
-            return None
-
-        # This means that we have a failure in a life-cycle hook,
-        # we need to rerun the whole module or class suite.
-        # Basically the error looks like this:
-        #    ERROR: setUpClass (test.test_reg_ex.RegTest)
-        # or
-        #    ERROR: setUpModule (test.test_reg_ex)
-        # So, we need to parse the class / module name.
-        lpar = test_full_name.index('(')
-        rpar = test_full_name.index(')')
-        return test_full_name[lpar + 1: rpar].split('.')[-1]
-    return short_name
-
-
-@dataclasses.dataclass(slots=True)
-class TestResult:
-    test_name: str
-    state: str | None = None
-    # Test duration in seconds
-    duration: float | None = None
-    xml_data: list[str] | None = None
-    stats: TestStats | None = None
-
-    # errors and failures copied from support.TestFailedWithDetails
-    errors: list[tuple[str, str]] | None = None
-    failures: list[tuple[str, str]] | None = None
-
-    def is_failed(self, fail_env_changed: bool) -> bool:
-        if self.state == State.ENV_CHANGED:
-            return fail_env_changed
-        return State.is_failed(self.state)
-
-    def _format_failed(self):
-        if self.errors and self.failures:
-            le = len(self.errors)
-            lf = len(self.failures)
-            error_s = "error" + ("s" if le > 1 else "")
-            failure_s = "failure" + ("s" if lf > 1 else "")
-            return f"{self.test_name} failed ({le} {error_s}, {lf} {failure_s})"
-
-        if self.errors:
-            le = len(self.errors)
-            error_s = "error" + ("s" if le > 1 else "")
-            return f"{self.test_name} failed ({le} {error_s})"
-
-        if self.failures:
-            lf = len(self.failures)
-            failure_s = "failure" + ("s" if lf > 1 else "")
-            return f"{self.test_name} failed ({lf} {failure_s})"
-
-        return f"{self.test_name} failed"
-
-    def __str__(self) -> str:
-        match self.state:
-            case State.PASSED:
-                return f"{self.test_name} passed"
-            case State.FAILED:
-                return self._format_failed()
-            case State.SKIPPED:
-                return f"{self.test_name} skipped"
-            case State.UNCAUGHT_EXC:
-                return f"{self.test_name} failed (uncaught exception)"
-            case State.REFLEAK:
-                return f"{self.test_name} failed (reference leak)"
-            case State.ENV_CHANGED:
-                return f"{self.test_name} failed (env changed)"
-            case State.RESOURCE_DENIED:
-                return f"{self.test_name} skipped (resource denied)"
-            case State.INTERRUPTED:
-                return f"{self.test_name} interrupted"
-            case State.MULTIPROCESSING_ERROR:
-                return f"{self.test_name} process crashed"
-            case State.DID_NOT_RUN:
-                return f"{self.test_name} ran no tests"
-            case State.TIMEOUT:
-                return f"{self.test_name} timed out ({format_duration(self.duration)})"
-            case _:
-                raise ValueError("unknown result state: {state!r}")
-
-    def has_meaningful_duration(self):
-        return State.has_meaningful_duration(self.state)
-
-    def set_env_changed(self):
-        if self.state is None or self.state == State.PASSED:
-            self.state = State.ENV_CHANGED
-
-    def must_stop(self, fail_fast: bool, fail_env_changed: bool) -> bool:
-        if State.must_stop(self.state):
-            return True
-        if fail_fast and self.is_failed(fail_env_changed):
-            return True
-        return False
-
-    def get_rerun_match_tests(self):
-        match_tests = []
-
-        errors = self.errors or []
-        failures = self.failures or []
-        for error_list, is_error in (
-            (errors, True),
-            (failures, False),
-        ):
-            for full_name, *_ in error_list:
-                match_name = normalize_test_name(full_name, is_error=is_error)
-                if match_name is None:
-                    # 'setUpModule (test.test_sys)': don't filter tests
-                    return None
-                if not match_name:
-                    error_type = "ERROR" if is_error else "FAIL"
-                    print_warning(f"rerun failed to parse {error_type} test name: "
-                                  f"{full_name!r}: don't filter tests")
-                    return None
-                match_tests.append(match_name)
-
-        return match_tests
-
-
-@dataclasses.dataclass(slots=True, frozen=True)
-class RunTests:
-    tests: list[str]
-    match_tests: MatchTestsDict | None = None
-    rerun: bool = False
-    forever: bool = False
-
-    def get_match_tests(self, test_name) -> MatchTests | None:
-        if self.match_tests is not None:
-            return self.match_tests.get(test_name, None)
-        else:
-            return None
-
-    def iter_tests(self):
-        tests = tuple(self.tests)
-        if self.forever:
-            while True:
-                yield from tests
-        else:
-            yield from tests
-
-
-# Minimum duration of a test to display its duration or to mention that
-# the test is running in background
-PROGRESS_MIN_TIME = 30.0   # seconds
-
-#If these test directories are encountered recurse into them and treat each
-# test_ .py or dir as a separate test module. This can increase parallelism.
-# Beware this can't generally be done for any directory with sub-tests as the
-# __init__.py may do things which alter what tests are to be run.
-
-SPLITTESTDIRS = {
-    "test_asyncio",
-    "test_concurrent_futures",
-    "test_multiprocessing_fork",
-    "test_multiprocessing_forkserver",
-    "test_multiprocessing_spawn",
-}
-
-
-def findtestdir(path=None):
-    return path or os.path.dirname(os.path.dirname(__file__)) or os.curdir
-
-
-def findtests(*, testdir=None, exclude=(),
-              split_test_dirs=SPLITTESTDIRS, base_mod=""):
-    """Return a list of all applicable test modules."""
-    testdir = findtestdir(testdir)
-    tests = []
-    for name in os.listdir(testdir):
-        mod, ext = os.path.splitext(name)
-        if (not mod.startswith("test_")) or (mod in exclude):
-            continue
-        if mod in split_test_dirs:
-            subdir = os.path.join(testdir, mod)
-            mod = f"{base_mod or 'test'}.{mod}"
-            tests.extend(findtests(testdir=subdir, exclude=exclude,
-                                   split_test_dirs=split_test_dirs, base_mod=mod))
-        elif ext in (".py", ""):
-            tests.append(f"{base_mod}.{mod}" if base_mod else mod)
-    return sorted(tests)
-
-
-def split_test_packages(tests, *, testdir=None, exclude=(),
-                        split_test_dirs=SPLITTESTDIRS):
-    testdir = findtestdir(testdir)
-    splitted = []
-    for name in tests:
-        if name in split_test_dirs:
-            subdir = os.path.join(testdir, name)
-            splitted.extend(findtests(testdir=subdir, exclude=exclude,
-                                      split_test_dirs=split_test_dirs,
-                                      base_mod=name))
-        else:
-            splitted.append(name)
-    return splitted
-
-
-def abs_module_name(test_name: str, test_dir: str | None) -> str:
-    if test_name.startswith('test.') or test_dir:
-        return test_name
-    else:
-        # Import it from the test package
-        return 'test.' + test_name
-
-
-def setup_support(ns: Namespace):
-    support.PGO = ns.pgo
-    support.PGO_EXTENDED = ns.pgo_extended
-    support.set_match_tests(ns.match_tests, ns.ignore_tests)
-    support.failfast = ns.failfast
-    support.verbose = ns.verbose
-    if ns.xmlpath:
-        support.junit_xml_list = []
-    else:
-        support.junit_xml_list = None
-
-
-def _runtest(result: TestResult, ns: Namespace) -> None:
-    # Capture stdout and stderr, set faulthandler timeout,
-    # and create JUnit XML report.
-    verbose = ns.verbose
-    output_on_failure = ns.verbose3
-    timeout = ns.timeout
-
-    use_timeout = (
-        timeout is not None and threading_helper.can_start_thread
-    )
-    if use_timeout:
-        faulthandler.dump_traceback_later(timeout, exit=True)
-
-    try:
-        setup_support(ns)
-
-        if output_on_failure:
-            support.verbose = True
-
-            stream = io.StringIO()
-            orig_stdout = sys.stdout
-            orig_stderr = sys.stderr
-            print_warning = support.print_warning
-            orig_print_warnings_stderr = print_warning.orig_stderr
-
-            output = None
-            try:
-                sys.stdout = stream
-                sys.stderr = stream
-                # print_warning() writes into the temporary stream to preserve
-                # messages order. If support.environment_altered becomes true,
-                # warnings will be written to sys.stderr below.
-                print_warning.orig_stderr = stream
-
-                _runtest_env_changed_exc(result, ns, display_failure=False)
-                # Ignore output if the test passed successfully
-                if result.state != State.PASSED:
-                    output = stream.getvalue()
-            finally:
-                sys.stdout = orig_stdout
-                sys.stderr = orig_stderr
-                print_warning.orig_stderr = orig_print_warnings_stderr
-
-            if output is not None:
-                sys.stderr.write(output)
-                sys.stderr.flush()
-        else:
-            # Tell tests to be moderately quiet
-            support.verbose = verbose
-            _runtest_env_changed_exc(result, ns, display_failure=not verbose)
-
-        xml_list = support.junit_xml_list
-        if xml_list:
-            import xml.etree.ElementTree as ET
-            result.xml_data = [ET.tostring(x).decode('us-ascii')
-                               for x in xml_list]
-    finally:
-        if use_timeout:
-            faulthandler.cancel_dump_traceback_later()
-        support.junit_xml_list = None
-
-
-def runtest(ns: Namespace, test_name: str) -> TestResult:
-    """Run a single test.
-
-    ns -- regrtest namespace of options
-    test_name -- the name of the test
-
-    Returns a TestResult.
-
-    If ns.xmlpath is not None, xml_data is a list containing each
-    generated testsuite element.
-    """
-    start_time = time.perf_counter()
-    result = TestResult(test_name)
-    try:
-        _runtest(result, ns)
-    except:
-        if not ns.pgo:
-            msg = traceback.format_exc()
-            print(f"test {test_name} crashed -- {msg}",
-                  file=sys.stderr, flush=True)
-        result.state = State.UNCAUGHT_EXC
-    result.duration = time.perf_counter() - start_time
-    return result
-
-
-def run_unittest(test_mod):
-    loader = unittest.TestLoader()
-    tests = loader.loadTestsFromModule(test_mod)
-    for error in loader.errors:
-        print(error, file=sys.stderr)
-    if loader.errors:
-        raise Exception("errors while loading tests")
-    return support.run_unittest(tests)
-
-
-def save_env(ns: Namespace, test_name: str):
-    return saved_test_environment(test_name, ns.verbose, ns.quiet, pgo=ns.pgo)
-
-
-def regrtest_runner(result, test_func, ns) -> None:
-    # Run test_func(), collect statistics, and detect reference and memory
-    # leaks.
-    if ns.huntrleaks:
-        from test.libregrtest.refleak import dash_R
-        refleak, test_result = dash_R(ns, result.test_name, test_func)
-    else:
-        test_result = test_func()
-        refleak = False
-
-    if refleak:
-        result.state = State.REFLEAK
-
-    match test_result:
-        case TestStats():
-            stats = test_result
-        case unittest.TestResult():
-            stats = TestStats.from_unittest(test_result)
-        case doctest.TestResults():
-            stats = TestStats.from_doctest(test_result)
-        case None:
-            print_warning(f"{result.test_name} test runner returned None: {test_func}")
-            stats = None
-        case _:
-            print_warning(f"Unknown test result type: {type(test_result)}")
-            stats = None
-
-    result.stats = stats
-
-
-# Storage of uncollectable objects
-FOUND_GARBAGE = []
-
-
-def _load_run_test(result: TestResult, ns: Namespace) -> None:
-    # Load the test function, run the test function.
-    module_name = abs_module_name(result.test_name, ns.testdir)
-
-    # Remove the module from sys.module to reload it if it was already imported
-    sys.modules.pop(module_name, None)
-
-    test_mod = importlib.import_module(module_name)
-
-    if hasattr(test_mod, "test_main"):
-        # https://github.com/python/cpython/issues/89392
-        raise Exception(f"Module {result.test_name} defines test_main() which is no longer supported by regrtest")
-    def test_func():
-        return run_unittest(test_mod)
-
-    try:
-        with save_env(ns, result.test_name):
-            regrtest_runner(result, test_func, ns)
-    finally:
-        # First kill any dangling references to open files etc.
-        # This can also issue some ResourceWarnings which would otherwise get
-        # triggered during the following test run, and possibly produce
-        # failures.
-        support.gc_collect()
-
-        remove_testfn(result.test_name, ns.verbose)
-
-    if gc.garbage:
-        support.environment_altered = True
-        print_warning(f"{result.test_name} created {len(gc.garbage)} "
-                      f"uncollectable object(s)")
-
-        # move the uncollectable objects somewhere,
-        # so we don't see them again
-        FOUND_GARBAGE.extend(gc.garbage)
-        gc.garbage.clear()
-
-    support.reap_children()
-
-
-def _runtest_env_changed_exc(result: TestResult, ns: Namespace,
-                             display_failure: bool = True) -> None:
-    # Detect environment changes, handle exceptions.
-
-    # Reset the environment_altered flag to detect if a test altered
-    # the environment
-    support.environment_altered = False
-
-    if ns.pgo:
-        display_failure = False
-
-    test_name = result.test_name
-    try:
-        clear_caches()
-        support.gc_collect()
-
-        with save_env(ns, test_name):
-            _load_run_test(result, ns)
-    except support.ResourceDenied as msg:
-        if not ns.quiet and not ns.pgo:
-            print(f"{test_name} skipped -- {msg}", flush=True)
-        result.state = State.RESOURCE_DENIED
-        return
-    except unittest.SkipTest as msg:
-        if not ns.quiet and not ns.pgo:
-            print(f"{test_name} skipped -- {msg}", flush=True)
-        result.state = State.SKIPPED
-        return
-    except support.TestFailedWithDetails as exc:
-        msg = f"test {test_name} failed"
-        if display_failure:
-            msg = f"{msg} -- {exc}"
-        print(msg, file=sys.stderr, flush=True)
-        result.state = State.FAILED
-        result.errors = exc.errors
-        result.failures = exc.failures
-        result.stats = exc.stats
-        return
-    except support.TestFailed as exc:
-        msg = f"test {test_name} failed"
-        if display_failure:
-            msg = f"{msg} -- {exc}"
-        print(msg, file=sys.stderr, flush=True)
-        result.state = State.FAILED
-        result.stats = exc.stats
-        return
-    except support.TestDidNotRun:
-        result.state = State.DID_NOT_RUN
-        return
-    except KeyboardInterrupt:
-        print()
-        result.state = State.INTERRUPTED
-        return
-    except:
-        if not ns.pgo:
-            msg = traceback.format_exc()
-            print(f"test {test_name} crashed -- {msg}",
-                  file=sys.stderr, flush=True)
-        result.state = State.UNCAUGHT_EXC
-        return
-
-    if support.environment_altered:
-        result.set_env_changed()
-    # Don't override the state if it was already set (REFLEAK or ENV_CHANGED)
-    if result.state is None:
-        result.state = State.PASSED
-
-
-def remove_testfn(test_name: str, verbose: int) -> None:
-    # Try to clean up os_helper.TESTFN if left behind.
-    #
-    # While tests shouldn't leave any files or directories behind, when a test
-    # fails that can be tedious for it to arrange.  The consequences can be
-    # especially nasty on Windows, since if a test leaves a file open, it
-    # cannot be deleted by name (while there's nothing we can do about that
-    # here either, we can display the name of the offending test, which is a
-    # real help).
-    name = os_helper.TESTFN
-    if not os.path.exists(name):
-        return
-
-    if os.path.isdir(name):
-        import shutil
-        kind, nuker = "directory", shutil.rmtree
-    elif os.path.isfile(name):
-        kind, nuker = "file", os.unlink
-    else:
-        raise RuntimeError(f"os.path says {name!r} exists but is neither "
-                           f"directory nor file")
-
-    if verbose:
-        print_warning(f"{test_name} left behind {kind} {name!r}")
-        support.environment_altered = True
-
-    try:
-        import stat
-        # fix possible permissions problems that might prevent cleanup
-        os.chmod(name, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)
-        nuker(name)
-    except Exception as exc:
-        print_warning(f"{test_name} left behind {kind} {name!r} "
-                      f"and it couldn't be removed: {exc}")
diff --git a/Lib/test/libregrtest/runtest_mp.py b/Lib/test/libregrtest/runtest_mp.py
deleted file mode 100644
index 60089554ca..0000000000
--- a/Lib/test/libregrtest/runtest_mp.py
+++ /dev/null
@@ -1,631 +0,0 @@
-import dataclasses
-import faulthandler
-import json
-import os.path
-import queue
-import signal
-import subprocess
-import sys
-import tempfile
-import threading
-import time
-import traceback
-from typing import NamedTuple, NoReturn, Literal, Any, TextIO
-
-from test import support
-from test.support import os_helper
-from test.support import TestStats
-
-from test.libregrtest.cmdline import Namespace
-from test.libregrtest.main import Regrtest
-from test.libregrtest.runtest import (
-    runtest, TestResult, State, PROGRESS_MIN_TIME,
-    MatchTests, RunTests)
-from test.libregrtest.setup import setup_tests
-from test.libregrtest.utils import format_duration, print_warning
-
-if sys.platform == 'win32':
-    import locale
-
-
-# Display the running tests if nothing happened last N seconds
-PROGRESS_UPDATE = 30.0   # seconds
-assert PROGRESS_UPDATE >= PROGRESS_MIN_TIME
-
-# Kill the main process after 5 minutes. It is supposed to write an update
-# every PROGRESS_UPDATE seconds. Tolerate 5 minutes for Python slowest
-# buildbot workers.
-MAIN_PROCESS_TIMEOUT = 5 * 60.0
-assert MAIN_PROCESS_TIMEOUT >= PROGRESS_UPDATE
-
-# Time to wait until a worker completes: should be immediate
-JOIN_TIMEOUT = 30.0   # seconds
-
-USE_PROCESS_GROUP = (hasattr(os, "setsid") and hasattr(os, "killpg"))
-
-
-@dataclasses.dataclass(slots=True)
-class WorkerJob:
-    test_name: str
-    namespace: Namespace
-    rerun: bool = False
-    match_tests: MatchTests | None = None
-
-
-class _EncodeWorkerJob(json.JSONEncoder):
-    def default(self, o: Any) -> dict[str, Any]:
-        match o:
-            case WorkerJob():
-                result = dataclasses.asdict(o)
-                result["__worker_job__"] = True
-                return result
-            case Namespace():
-                result = vars(o)
-                result["__namespace__"] = True
-                return result
-            case _:
-                return super().default(o)
-
-
-def _decode_worker_job(d: dict[str, Any]) -> WorkerJob | dict[str, Any]:
-    if "__worker_job__" in d:
-        d.pop('__worker_job__')
-        return WorkerJob(**d)
-    if "__namespace__" in d:
-        d.pop('__namespace__')
-        return Namespace(**d)
-    else:
-        return d
-
-
-def _parse_worker_args(worker_json: str) -> tuple[Namespace, str]:
-    return json.loads(worker_json,
-                      object_hook=_decode_worker_job)
-
-
-def run_test_in_subprocess(worker_job: WorkerJob,
-                           output_file: TextIO,
-                           tmp_dir: str | None = None) -> subprocess.Popen:
-    ns = worker_job.namespace
-    python = ns.python
-    worker_args = json.dumps(worker_job, cls=_EncodeWorkerJob)
-
-    if python is not None:
-        executable = python
-    else:
-        executable = [sys.executable]
-    cmd = [*executable, *support.args_from_interpreter_flags(),
-           '-u',    # Unbuffered stdout and stderr
-           '-m', 'test.regrtest',
-           '--worker-args', worker_args]
-
-    env = dict(os.environ)
-    if tmp_dir is not None:
-        env['TMPDIR'] = tmp_dir
-        env['TEMP'] = tmp_dir
-        env['TMP'] = tmp_dir
-
-    # Running the child from the same working directory as regrtest's original
-    # invocation ensures that TEMPDIR for the child is the same when
-    # sysconfig.is_python_build() is true. See issue 15300.
-    kw = dict(
-        env=env,
-        stdout=output_file,
-        # bpo-45410: Write stderr into stdout to keep messages order
-        stderr=output_file,
-        text=True,
-        close_fds=(os.name != 'nt'),
-        cwd=os_helper.SAVEDCWD,
-    )
-    if USE_PROCESS_GROUP:
-        kw['start_new_session'] = True
-    return subprocess.Popen(cmd, **kw)
-
-
-def run_tests_worker(worker_json: str) -> NoReturn:
-    worker_job = _parse_worker_args(worker_json)
-    ns = worker_job.namespace
-    test_name = worker_job.test_name
-    rerun = worker_job.rerun
-    match_tests = worker_job.match_tests
-
-    setup_tests(ns)
-
-    if rerun:
-        if match_tests:
-            matching = "matching: " + ", ".join(match_tests)
-            print(f"Re-running {test_name} in verbose mode ({matching})", flush=True)
-        else:
-            print(f"Re-running {test_name} in verbose mode", flush=True)
-        ns.verbose = True
-
-    if match_tests is not None:
-        ns.match_tests = match_tests
-
-    result = runtest(ns, test_name)
-    print()   # Force a newline (just in case)
-
-    # Serialize TestResult as dict in JSON
-    print(json.dumps(result, cls=EncodeTestResult), flush=True)
-    sys.exit(0)
-
-
-# We do not use a generator so multiple threads can call next().
-class MultiprocessIterator:
-
-    """A thread-safe iterator over tests for multiprocess mode."""
-
-    def __init__(self, tests_iter):
-        self.lock = threading.Lock()
-        self.tests_iter = tests_iter
-
-    def __iter__(self):
-        return self
-
-    def __next__(self):
-        with self.lock:
-            if self.tests_iter is None:
-                raise StopIteration
-            return next(self.tests_iter)
-
-    def stop(self):
-        with self.lock:
-            self.tests_iter = None
-
-
-class MultiprocessResult(NamedTuple):
-    result: TestResult
-    # bpo-45410: stderr is written into stdout to keep messages order
-    worker_stdout: str | None = None
-    err_msg: str | None = None
-
-
-ExcStr = str
-QueueOutput = tuple[Literal[False], MultiprocessResult] | tuple[Literal[True], ExcStr]
-
-
-class ExitThread(Exception):
-    pass
-
-
-class TestWorkerProcess(threading.Thread):
-    def __init__(self, worker_id: int, runner: "MultiprocessTestRunner") -> None:
-        super().__init__()
-        self.worker_id = worker_id
-        self.runtests = runner.runtests
-        self.pending = runner.pending
-        self.output = runner.output
-        self.ns = runner.ns
-        self.timeout = runner.worker_timeout
-        self.regrtest = runner.regrtest
-        self.rerun = runner.rerun
-        self.current_test_name = None
-        self.start_time = None
-        self._popen = None
-        self._killed = False
-        self._stopped = False
-
-    def __repr__(self) -> str:
-        info = [f'TestWorkerProcess #{self.worker_id}']
-        if self.is_alive():
-            info.append("running")
-        else:
-            info.append('stopped')
-        test = self.current_test_name
-        if test:
-            info.append(f'test={test}')
-        popen = self._popen
-        if popen is not None:
-            dt = time.monotonic() - self.start_time
-            info.extend((f'pid={self._popen.pid}',
-                         f'time={format_duration(dt)}'))
-        return '<%s>' % ' '.join(info)
-
-    def _kill(self) -> None:
-        popen = self._popen
-        if popen is None:
-            return
-
-        if self._killed:
-            return
-        self._killed = True
-
-        if USE_PROCESS_GROUP:
-            what = f"{self} process group"
-        else:
-            what = f"{self}"
-
-        print(f"Kill {what}", file=sys.stderr, flush=True)
-        try:
-            if USE_PROCESS_GROUP:
-                os.killpg(popen.pid, signal.SIGKILL)
-            else:
-                popen.kill()
-        except ProcessLookupError:
-            # popen.kill(): the process completed, the TestWorkerProcess thread
-            # read its exit status, but Popen.send_signal() read the returncode
-            # just before Popen.wait() set returncode.
-            pass
-        except OSError as exc:
-            print_warning(f"Failed to kill {what}: {exc!r}")
-
-    def stop(self) -> None:
-        # Method called from a different thread to stop this thread
-        self._stopped = True
-        self._kill()
-
-    def mp_result_error(
-        self,
-        test_result: TestResult,
-        stdout: str | None = None,
-        err_msg=None
-    ) -> MultiprocessResult:
-        return MultiprocessResult(test_result, stdout, err_msg)
-
-    def _run_process(self, worker_job, output_file: TextIO,
-                     tmp_dir: str | None = None) -> int:
-        self.current_test_name = worker_job.test_name
-        try:
-            popen = run_test_in_subprocess(worker_job, output_file, tmp_dir)
-
-            self._killed = False
-            self._popen = popen
-        except:
-            self.current_test_name = None
-            raise
-
-        try:
-            if self._stopped:
-                # If kill() has been called before self._popen is set,
-                # self._popen is still running. Call again kill()
-                # to ensure that the process is killed.
-                self._kill()
-                raise ExitThread
-
-            try:
-                # gh-94026: stdout+stderr are written to tempfile
-                retcode = popen.wait(timeout=self.timeout)
-                assert retcode is not None
-                return retcode
-            except subprocess.TimeoutExpired:
-                if self._stopped:
-                    # kill() has been called: communicate() fails on reading
-                    # closed stdout
-                    raise ExitThread
-
-                # On timeout, kill the process
-                self._kill()
-
-                # None means TIMEOUT for the caller
-                retcode = None
-                # bpo-38207: Don't attempt to call communicate() again: on it
-                # can hang until all child processes using stdout
-                # pipes completes.
-            except OSError:
-                if self._stopped:
-                    # kill() has been called: communicate() fails
-                    # on reading closed stdout
-                    raise ExitThread
-                raise
-        except:
-            self._kill()
-            raise
-        finally:
-            self._wait_completed()
-            self._popen = None
-            self.current_test_name = None
-
-    def _runtest(self, test_name: str) -> MultiprocessResult:
-        if sys.platform == 'win32':
-            # gh-95027: When stdout is not a TTY, Python uses the ANSI code
-            # page for the sys.stdout encoding. If the main process runs in a
-            # terminal, sys.stdout uses WindowsConsoleIO with UTF-8 encoding.
-            encoding = locale.getencoding()
-        else:
-            encoding = sys.stdout.encoding
-
-        match_tests = self.runtests.get_match_tests(test_name)
-
-        # gh-94026: Write stdout+stderr to a tempfile as workaround for
-        # non-blocking pipes on Emscripten with NodeJS.
-        with tempfile.TemporaryFile('w+', encoding=encoding) as stdout_file:
-            worker_job = WorkerJob(test_name,
-                                   namespace=self.ns,
-                                   rerun=self.rerun,
-                                   match_tests=match_tests)
-            # gh-93353: Check for leaked temporary files in the parent process,
-            # since the deletion of temporary files can happen late during
-            # Python finalization: too late for libregrtest.
-            if not support.is_wasi:
-                # Don't check for leaked temporary files and directories if Python is
-                # run on WASI. WASI don't pass environment variables like TMPDIR to
-                # worker processes.
-                tmp_dir = tempfile.mkdtemp(prefix="test_python_")
-                tmp_dir = os.path.abspath(tmp_dir)
-                try:
-                    retcode = self._run_process(worker_job, stdout_file, tmp_dir)
-                finally:
-                    tmp_files = os.listdir(tmp_dir)
-                    os_helper.rmtree(tmp_dir)
-            else:
-                retcode = self._run_process(worker_job, stdout_file)
-                tmp_files = ()
-            stdout_file.seek(0)
-
-            try:
-                stdout = stdout_file.read().strip()
-            except Exception as exc:
-                # gh-101634: Catch UnicodeDecodeError if stdout cannot be
-                # decoded from encoding
-                err_msg = f"Cannot read process stdout: {exc}"
-                result = TestResult(test_name, state=State.MULTIPROCESSING_ERROR)
-                return self.mp_result_error(result, err_msg=err_msg)
-
-        if retcode is None:
-            result = TestResult(test_name, state=State.TIMEOUT)
-            return self.mp_result_error(result, stdout)
-
-        err_msg = None
-        if retcode != 0:
-            err_msg = "Exit code %s" % retcode
-        else:
-            stdout, _, worker_json = stdout.rpartition("\n")
-            stdout = stdout.rstrip()
-            if not worker_json:
-                err_msg = "Failed to parse worker stdout"
-            else:
-                try:
-                    # deserialize run_tests_worker() output
-                    result = json.loads(worker_json,
-                                        object_hook=decode_test_result)
-                except Exception as exc:
-                    err_msg = "Failed to parse worker JSON: %s" % exc
-
-        if err_msg:
-            result = TestResult(test_name, state=State.MULTIPROCESSING_ERROR)
-            return self.mp_result_error(result, stdout, err_msg)
-
-        if tmp_files:
-            msg = (f'\n\n'
-                   f'Warning -- {test_name} leaked temporary files '
-                   f'({len(tmp_files)}): {", ".join(sorted(tmp_files))}')
-            stdout += msg
-            result.set_env_changed()
-
-        return MultiprocessResult(result, stdout)
-
-    def run(self) -> None:
-        fail_fast = self.ns.failfast
-        fail_env_changed = self.ns.fail_env_changed
-        while not self._stopped:
-            try:
-                try:
-                    test_name = next(self.pending)
-                except StopIteration:
-                    break
-
-                self.start_time = time.monotonic()
-                mp_result = self._runtest(test_name)
-                mp_result.result.duration = time.monotonic() - self.start_time
-                self.output.put((False, mp_result))
-
-                if mp_result.result.must_stop(fail_fast, fail_env_changed):
-                    break
-            except ExitThread:
-                break
-            except BaseException:
-                self.output.put((True, traceback.format_exc()))
-                break
-
-    def _wait_completed(self) -> None:
-        popen = self._popen
-
-        try:
-            popen.wait(JOIN_TIMEOUT)
-        except (subprocess.TimeoutExpired, OSError) as exc:
-            print_warning(f"Failed to wait for {self} completion "
-                          f"(timeout={format_duration(JOIN_TIMEOUT)}): "
-                          f"{exc!r}")
-
-    def wait_stopped(self, start_time: float) -> None:
-        # bpo-38207: MultiprocessTestRunner.stop_workers() called self.stop()
-        # which killed the process. Sometimes, killing the process from the
-        # main thread does not interrupt popen.communicate() in
-        # TestWorkerProcess thread. This loop with a timeout is a workaround
-        # for that.
-        #
-        # Moreover, if this method fails to join the thread, it is likely
-        # that Python will hang at exit while calling threading._shutdown()
-        # which tries again to join the blocked thread. Regrtest.main()
-        # uses EXIT_TIMEOUT to workaround this second bug.
-        while True:
-            # Write a message every second
-            self.join(1.0)
-            if not self.is_alive():
-                break
-            dt = time.monotonic() - start_time
-            self.regrtest.log(f"Waiting for {self} thread "
-                              f"for {format_duration(dt)}")
-            if dt > JOIN_TIMEOUT:
-                print_warning(f"Failed to join {self} in {format_duration(dt)}")
-                break
-
-
-def get_running(workers: list[TestWorkerProcess]) -> list[TestWorkerProcess]:
-    running = []
-    for worker in workers:
-        current_test_name = worker.current_test_name
-        if not current_test_name:
-            continue
-        dt = time.monotonic() - worker.start_time
-        if dt >= PROGRESS_MIN_TIME:
-            text = '%s (%s)' % (current_test_name, format_duration(dt))
-            running.append(text)
-    return running
-
-
-class MultiprocessTestRunner:
-    def __init__(self, regrtest: Regrtest, runtests: RunTests) -> None:
-        ns = regrtest.ns
-        timeout = ns.timeout
-
-        self.regrtest = regrtest
-        self.runtests = runtests
-        self.rerun = runtests.rerun
-        self.log = self.regrtest.log
-        self.ns = ns
-        self.output: queue.Queue[QueueOutput] = queue.Queue()
-        tests_iter = runtests.iter_tests()
-        self.pending = MultiprocessIterator(tests_iter)
-        if timeout is not None:
-            # Rely on faulthandler to kill a worker process. This timouet is
-            # when faulthandler fails to kill a worker process. Give a maximum
-            # of 5 minutes to faulthandler to kill the worker.
-            self.worker_timeout = min(timeout * 1.5, timeout + 5 * 60)
-        else:
-            self.worker_timeout = None
-        self.workers = None
-
-    def start_workers(self) -> None:
-        use_mp = self.ns.use_mp
-        timeout = self.ns.timeout
-        self.workers = [TestWorkerProcess(index, self)
-                        for index in range(1, use_mp + 1)]
-        msg = f"Run tests in parallel using {len(self.workers)} child processes"
-        if timeout:
-            msg += (" (timeout: %s, worker timeout: %s)"
-                    % (format_duration(timeout),
-                       format_duration(self.worker_timeout)))
-        self.log(msg)
-        for worker in self.workers:
-            worker.start()
-
-    def stop_workers(self) -> None:
-        start_time = time.monotonic()
-        for worker in self.workers:
-            worker.stop()
-        for worker in self.workers:
-            worker.wait_stopped(start_time)
-
-    def _get_result(self) -> QueueOutput | None:
-        pgo = self.ns.pgo
-        use_faulthandler = (self.ns.timeout is not None)
-        timeout = PROGRESS_UPDATE
-
-        # bpo-46205: check the status of workers every iteration to avoid
-        # waiting forever on an empty queue.
-        while any(worker.is_alive() for worker in self.workers):
-            if use_faulthandler:
-                faulthandler.dump_traceback_later(MAIN_PROCESS_TIMEOUT,
-                                                  exit=True)
-
-            # wait for a thread
-            try:
-                return self.output.get(timeout=timeout)
-            except queue.Empty:
-                pass
-
-            # display progress
-            running = get_running(self.workers)
-            if running and not pgo:
-                self.log('running: %s' % ', '.join(running))
-
-        # all worker threads are done: consume pending results
-        try:
-            return self.output.get(timeout=0)
-        except queue.Empty:
-            return None
-
-    def display_result(self, mp_result: MultiprocessResult) -> None:
-        result = mp_result.result
-        pgo = self.ns.pgo
-
-        text = str(result)
-        if mp_result.err_msg:
-            # MULTIPROCESSING_ERROR
-            text += ' (%s)' % mp_result.err_msg
-        elif (result.duration >= PROGRESS_MIN_TIME and not pgo):
-            text += ' (%s)' % format_duration(result.duration)
-        running = get_running(self.workers)
-        if running and not pgo:
-            text += ' -- running: %s' % ', '.join(running)
-        self.regrtest.display_progress(self.test_index, text)
-
-    def _process_result(self, item: QueueOutput) -> bool:
-        """Returns True if test runner must stop."""
-        rerun = self.runtests.rerun
-        if item[0]:
-            # Thread got an exception
-            format_exc = item[1]
-            print_warning(f"regrtest worker thread failed: {format_exc}")
-            result = TestResult("<regrtest worker>", state=State.MULTIPROCESSING_ERROR)
-            self.regrtest.accumulate_result(result, rerun=rerun)
-            return result
-
-        self.test_index += 1
-        mp_result = item[1]
-        result = mp_result.result
-        self.regrtest.accumulate_result(result, rerun=rerun)
-        self.display_result(mp_result)
-
-        if mp_result.worker_stdout:
-            print(mp_result.worker_stdout, flush=True)
-
-        return result
-
-    def run_tests(self) -> None:
-        fail_fast = self.ns.failfast
-        fail_env_changed = self.ns.fail_env_changed
-        timeout = self.ns.timeout
-
-        self.start_workers()
-
-        self.test_index = 0
-        try:
-            while True:
-                item = self._get_result()
-                if item is None:
-                    break
-
-                result = self._process_result(item)
-                if result.must_stop(fail_fast, fail_env_changed):
-                    break
-        except KeyboardInterrupt:
-            print()
-            self.regrtest.interrupted = True
-        finally:
-            if timeout is not None:
-                faulthandler.cancel_dump_traceback_later()
-
-            # Always ensure that all worker processes are no longer
-            # worker when we exit this function
-            self.pending.stop()
-            self.stop_workers()
-
-
-def run_tests_multiprocess(regrtest: Regrtest, runtests: RunTests) -> None:
-    MultiprocessTestRunner(regrtest, runtests).run_tests()
-
-
-class EncodeTestResult(json.JSONEncoder):
-    """Encode a TestResult (sub)class object into a JSON dict."""
-
-    def default(self, o: Any) -> dict[str, Any]:
-        if isinstance(o, TestResult):
-            result = dataclasses.asdict(o)
-            result["__test_result__"] = o.__class__.__name__
-            return result
-
-        return super().default(o)
-
-
-def decode_test_result(d: dict[str, Any]) -> TestResult | dict[str, Any]:
-    """Decode a TestResult (sub)class object from a JSON dict."""
-
-    if "__test_result__" not in d:
-        return d
-
-    d.pop('__test_result__')
-    if d['stats'] is not None:
-        d['stats'] = TestStats(**d['stats'])
-    return TestResult(**d)
diff --git a/Lib/test/libregrtest/runtests.py b/Lib/test/libregrtest/runtests.py
new file mode 100644
index 0000000000..bfed1b4a2a
--- /dev/null
+++ b/Lib/test/libregrtest/runtests.py
@@ -0,0 +1,161 @@
+import contextlib
+import dataclasses
+import json
+import os
+import subprocess
+from typing import Any
+
+from test import support
+
+from .utils import (
+    StrPath, StrJSON, TestTuple, TestFilter, FilterTuple, FilterDict)
+
+
+class JsonFileType:
+    UNIX_FD = "UNIX_FD"
+    WINDOWS_HANDLE = "WINDOWS_HANDLE"
+    STDOUT = "STDOUT"
+
+
+@dataclasses.dataclass(slots=True, frozen=True)
+class JsonFile:
+    # file type depends on file_type:
+    # - UNIX_FD: file descriptor (int)
+    # - WINDOWS_HANDLE: handle (int)
+    # - STDOUT: use process stdout (None)
+    file: int | None
+    file_type: str
+
+    def configure_subprocess(self, popen_kwargs: dict) -> None:
+        match self.file_type:
+            case JsonFileType.UNIX_FD:
+                # Unix file descriptor
+                popen_kwargs['pass_fds'] = [self.file]
+            case JsonFileType.WINDOWS_HANDLE:
+                # Windows handle
+                startupinfo = subprocess.STARTUPINFO()
+                startupinfo.lpAttributeList = {"handle_list": [self.file]}
+                popen_kwargs['startupinfo'] = startupinfo
+
+    @contextlib.contextmanager
+    def inherit_subprocess(self):
+        if self.file_type == JsonFileType.WINDOWS_HANDLE:
+            os.set_handle_inheritable(self.file, True)
+            try:
+                yield
+            finally:
+                os.set_handle_inheritable(self.file, False)
+        else:
+            yield
+
+    def open(self, mode='r', *, encoding):
+        if self.file_type == JsonFileType.STDOUT:
+            raise ValueError("for STDOUT file type, just use sys.stdout")
+
+        file = self.file
+        if self.file_type == JsonFileType.WINDOWS_HANDLE:
+            import msvcrt
+            # Create a file descriptor from the handle
+            file = msvcrt.open_osfhandle(file, os.O_WRONLY)
+        return open(file, mode, encoding=encoding)
+
+
+@dataclasses.dataclass(slots=True, frozen=True)
+class HuntRefleak:
+    warmups: int
+    runs: int
+    filename: StrPath
+
+
+@dataclasses.dataclass(slots=True, frozen=True)
+class RunTests:
+    tests: TestTuple
+    fail_fast: bool
+    fail_env_changed: bool
+    match_tests: TestFilter
+    match_tests_dict: FilterDict | None
+    rerun: bool
+    forever: bool
+    pgo: bool
+    pgo_extended: bool
+    output_on_failure: bool
+    timeout: float | None
+    verbose: int
+    quiet: bool
+    hunt_refleak: HuntRefleak | None
+    test_dir: StrPath | None
+    use_junit: bool
+    memory_limit: str | None
+    gc_threshold: int | None
+    use_resources: tuple[str, ...]
+    python_cmd: tuple[str, ...] | None
+    randomize: bool
+    random_seed: int | str
+    json_file: JsonFile | None
+
+    def copy(self, **override):
+        state = dataclasses.asdict(self)
+        state.update(override)
+        return RunTests(**state)
+
+    def get_match_tests(self, test_name) -> FilterTuple | None:
+        if self.match_tests_dict is not None:
+            return self.match_tests_dict.get(test_name, None)
+        else:
+            return None
+
+    def get_jobs(self):
+        # Number of run_single_test() calls needed to run all tests.
+        # None means that there is not bound limit (--forever option).
+        if self.forever:
+            return None
+        return len(self.tests)
+
+    def iter_tests(self):
+        if self.forever:
+            while True:
+                yield from self.tests
+        else:
+            yield from self.tests
+
+    def as_json(self) -> StrJSON:
+        return json.dumps(self, cls=_EncodeRunTests)
+
+    @staticmethod
+    def from_json(worker_json: StrJSON) -> 'RunTests':
+        return json.loads(worker_json, object_hook=_decode_runtests)
+
+    def json_file_use_stdout(self) -> bool:
+        # Use STDOUT in two cases:
+        #
+        # - If --python command line option is used;
+        # - On Emscripten and WASI.
+        #
+        # On other platforms, UNIX_FD or WINDOWS_HANDLE can be used.
+        return (
+            bool(self.python_cmd)
+            or support.is_emscripten
+            or support.is_wasi
+        )
+
+
+class _EncodeRunTests(json.JSONEncoder):
+    def default(self, o: Any) -> dict[str, Any]:
+        if isinstance(o, RunTests):
+            result = dataclasses.asdict(o)
+            result["__runtests__"] = True
+            return result
+        else:
+            return super().default(o)
+
+
+def _decode_runtests(data: dict[str, Any]) -> RunTests | dict[str, Any]:
+    if "__runtests__" in data:
+        data.pop('__runtests__')
+        if data['hunt_refleak']:
+            data['hunt_refleak'] = HuntRefleak(**data['hunt_refleak'])
+        if data['json_file']:
+            data['json_file'] = JsonFile(**data['json_file'])
+        return RunTests(**data)
+    else:
+        return data
diff --git a/Lib/test/libregrtest/save_env.py b/Lib/test/libregrtest/save_env.py
index 164fe9806b..b2cc381344 100644
--- a/Lib/test/libregrtest/save_env.py
+++ b/Lib/test/libregrtest/save_env.py
@@ -3,9 +3,11 @@
 import os
 import sys
 import threading
+
 from test import support
 from test.support import os_helper
-from test.libregrtest.utils import print_warning
+
+from .utils import print_warning
 
 
 class SkipTestEnvironment(Exception):
@@ -34,7 +36,7 @@ class saved_test_environment:
     items is also printed.
     """
 
-    def __init__(self, test_name, verbose=0, quiet=False, *, pgo=False):
+    def __init__(self, test_name, verbose, quiet, *, pgo):
         self.test_name = test_name
         self.verbose = verbose
         self.quiet = quiet
diff --git a/Lib/test/libregrtest/setup.py b/Lib/test/libregrtest/setup.py
index b76bece7ca..97edba9f87 100644
--- a/Lib/test/libregrtest/setup.py
+++ b/Lib/test/libregrtest/setup.py
@@ -1,24 +1,33 @@
-import atexit
 import faulthandler
+import gc
 import os
+import random
 import signal
 import sys
 import unittest
 from test import support
 from test.support.os_helper import TESTFN_UNDECODABLE, FS_NONASCII
-try:
-    import gc
-except ImportError:
-    gc = None
 
-from test.libregrtest.utils import (setup_unraisable_hook,
-                                    setup_threading_excepthook)
+from .filter import set_match_tests
+from .runtests import RunTests
+from .utils import (
+    setup_unraisable_hook, setup_threading_excepthook, fix_umask,
+    adjust_rlimit_nofile)
 
 
 UNICODE_GUARD_ENV = "PYTHONREGRTEST_UNICODE_GUARD"
 
 
-def setup_tests(ns):
+def setup_test_dir(testdir: str | None) -> None:
+    if testdir:
+        # Prepend test directory to sys.path, so runtest() will be able
+        # to locate tests
+        sys.path.insert(0, os.path.abspath(testdir))
+
+
+def setup_process():
+    fix_umask()
+
     try:
         stderr_fd = sys.__stderr__.fileno()
     except (ValueError, AttributeError):
@@ -40,14 +49,9 @@ def setup_tests(ns):
         for signum in signals:
             faulthandler.register(signum, chain=True, file=stderr_fd)
 
-    _adjust_resource_limits()
-    replace_stdout()
-    support.record_original_stdout(sys.stdout)
+    adjust_rlimit_nofile()
 
-    if ns.testdir:
-        # Prepend test directory to sys.path, so runtest() will be able
-        # to locate tests
-        sys.path.insert(0, os.path.abspath(ns.testdir))
+    support.record_original_stdout(sys.stdout)
 
     # Some times __path__ and __file__ are not absolute (e.g. while running from
     # Lib/) and, if we change the CWD to run the tests in a temporary dir, some
@@ -66,19 +70,6 @@ def setup_tests(ns):
         if getattr(module, '__file__', None):
             module.__file__ = os.path.abspath(module.__file__)
 
-    if ns.huntrleaks:
-        unittest.BaseTestSuite._cleanup = False
-
-    if ns.memlimit is not None:
-        support.set_memlimit(ns.memlimit)
-
-    if ns.threshold is not None:
-        gc.set_threshold(ns.threshold)
-
-    support.suppress_msvcrt_asserts(ns.verbose and ns.verbose >= 2)
-
-    support.use_resources = ns.use_resources
-
     if hasattr(sys, 'addaudithook'):
         # Add an auditing hook for all tests to ensure PySys_Audit is tested
         def _test_audit_hook(name, args):
@@ -88,21 +79,6 @@ def _test_audit_hook(name, args):
     setup_unraisable_hook()
     setup_threading_excepthook()
 
-    if ns.timeout is not None:
-        # For a slow buildbot worker, increase SHORT_TIMEOUT and LONG_TIMEOUT
-        support.SHORT_TIMEOUT = max(support.SHORT_TIMEOUT, ns.timeout / 40)
-        support.LONG_TIMEOUT = max(support.LONG_TIMEOUT, ns.timeout / 4)
-
-        # If --timeout is short: reduce timeouts
-        support.LOOPBACK_TIMEOUT = min(support.LOOPBACK_TIMEOUT, ns.timeout)
-        support.INTERNET_TIMEOUT = min(support.INTERNET_TIMEOUT, ns.timeout)
-        support.SHORT_TIMEOUT = min(support.SHORT_TIMEOUT, ns.timeout)
-        support.LONG_TIMEOUT = min(support.LONG_TIMEOUT, ns.timeout)
-
-    if ns.xmlpath:
-        from test.support.testresult import RegressionTestResult
-        RegressionTestResult.USE_XML = True
-
     # Ensure there's a non-ASCII character in env vars at all times to force
     # tests consider this case. See BPO-44647 for details.
     if TESTFN_UNDECODABLE and os.supports_bytes_environ:
@@ -111,49 +87,46 @@ def _test_audit_hook(name, args):
         os.environ.setdefault(UNICODE_GUARD_ENV, FS_NONASCII)
 
 
-def replace_stdout():
-    """Set stdout encoder error handler to backslashreplace (as stderr error
-    handler) to avoid UnicodeEncodeError when printing a traceback"""
-    stdout = sys.stdout
-    try:
-        fd = stdout.fileno()
-    except ValueError:
-        # On IDLE, sys.stdout has no file descriptor and is not a TextIOWrapper
-        # object. Leaving sys.stdout unchanged.
-        #
-        # Catch ValueError to catch io.UnsupportedOperation on TextIOBase
-        # and ValueError on a closed stream.
-        return
+def setup_tests(runtests: RunTests):
+    support.verbose = runtests.verbose
+    support.failfast = runtests.fail_fast
+    support.PGO = runtests.pgo
+    support.PGO_EXTENDED = runtests.pgo_extended
 
-    sys.stdout = open(fd, 'w',
-        encoding=stdout.encoding,
-        errors="backslashreplace",
-        closefd=False,
-        newline='\n')
+    set_match_tests(runtests.match_tests)
 
-    def restore_stdout():
-        sys.stdout.close()
-        sys.stdout = stdout
-    atexit.register(restore_stdout)
+    if runtests.use_junit:
+        support.junit_xml_list = []
+        from .testresult import RegressionTestResult
+        RegressionTestResult.USE_XML = True
+    else:
+        support.junit_xml_list = None
 
+    if runtests.memory_limit is not None:
+        support.set_memlimit(runtests.memory_limit)
 
-def _adjust_resource_limits():
-    """Adjust the system resource limits (ulimit) if needed."""
-    try:
-        import resource
-        from resource import RLIMIT_NOFILE
-    except ImportError:
-        return
-    fd_limit, max_fds = resource.getrlimit(RLIMIT_NOFILE)
-    # On macOS the default fd limit is sometimes too low (256) for our
-    # test suite to succeed.  Raise it to something more reasonable.
-    # 1024 is a common Linux default.
-    desired_fds = 1024
-    if fd_limit < desired_fds and fd_limit < max_fds:
-        new_fd_limit = min(desired_fds, max_fds)
-        try:
-            resource.setrlimit(RLIMIT_NOFILE, (new_fd_limit, max_fds))
-            print(f"Raised RLIMIT_NOFILE: {fd_limit} -> {new_fd_limit}")
-        except (ValueError, OSError) as err:
-            print(f"Unable to raise RLIMIT_NOFILE from {fd_limit} to "
-                  f"{new_fd_limit}: {err}.")
+    support.suppress_msvcrt_asserts(runtests.verbose >= 2)
+
+    support.use_resources = runtests.use_resources
+
+    timeout = runtests.timeout
+    if timeout is not None:
+        # For a slow buildbot worker, increase SHORT_TIMEOUT and LONG_TIMEOUT
+        support.LOOPBACK_TIMEOUT = max(support.LOOPBACK_TIMEOUT, timeout / 120)
+        # don't increase INTERNET_TIMEOUT
+        support.SHORT_TIMEOUT = max(support.SHORT_TIMEOUT, timeout / 40)
+        support.LONG_TIMEOUT = max(support.LONG_TIMEOUT, timeout / 4)
+
+        # If --timeout is short: reduce timeouts
+        support.LOOPBACK_TIMEOUT = min(support.LOOPBACK_TIMEOUT, timeout)
+        support.INTERNET_TIMEOUT = min(support.INTERNET_TIMEOUT, timeout)
+        support.SHORT_TIMEOUT = min(support.SHORT_TIMEOUT, timeout)
+        support.LONG_TIMEOUT = min(support.LONG_TIMEOUT, timeout)
+
+    if runtests.hunt_refleak:
+        unittest.BaseTestSuite._cleanup = False
+
+    if runtests.gc_threshold is not None:
+        gc.set_threshold(runtests.gc_threshold)
+
+    random.seed(runtests.random_seed)
diff --git a/Lib/test/libregrtest/single.py b/Lib/test/libregrtest/single.py
new file mode 100644
index 0000000000..ad75ef54a8
--- /dev/null
+++ b/Lib/test/libregrtest/single.py
@@ -0,0 +1,319 @@
+import doctest
+import faulthandler
+import gc
+import importlib
+import io
+import sys
+import time
+import traceback
+import unittest
+
+from test import support
+from test.support import threading_helper
+
+from .filter import match_test
+from .result import State, TestResult, TestStats
+from .runtests import RunTests
+from .save_env import saved_test_environment
+from .setup import setup_tests
+from .testresult import get_test_runner
+from .utils import (
+    TestName,
+    clear_caches, remove_testfn, abs_module_name, print_warning)
+
+
+# Minimum duration of a test to display its duration or to mention that
+# the test is running in background
+PROGRESS_MIN_TIME = 30.0   # seconds
+
+
+def run_unittest(test_mod):
+    loader = unittest.TestLoader()
+    tests = loader.loadTestsFromModule(test_mod)
+    for error in loader.errors:
+        print(error, file=sys.stderr)
+    if loader.errors:
+        raise Exception("errors while loading tests")
+    _filter_suite(tests, match_test)
+    return _run_suite(tests)
+
+def _filter_suite(suite, pred):
+    """Recursively filter test cases in a suite based on a predicate."""
+    newtests = []
+    for test in suite._tests:
+        if isinstance(test, unittest.TestSuite):
+            _filter_suite(test, pred)
+            newtests.append(test)
+        else:
+            if pred(test):
+                newtests.append(test)
+    suite._tests = newtests
+
+def _run_suite(suite):
+    """Run tests from a unittest.TestSuite-derived class."""
+    runner = get_test_runner(sys.stdout,
+                             verbosity=support.verbose,
+                             capture_output=(support.junit_xml_list is not None))
+
+    result = runner.run(suite)
+
+    if support.junit_xml_list is not None:
+        support.junit_xml_list.append(result.get_xml_element())
+
+    if not result.testsRun and not result.skipped and not result.errors:
+        raise support.TestDidNotRun
+    if not result.wasSuccessful():
+        stats = TestStats.from_unittest(result)
+        if len(result.errors) == 1 and not result.failures:
+            err = result.errors[0][1]
+        elif len(result.failures) == 1 and not result.errors:
+            err = result.failures[0][1]
+        else:
+            err = "multiple errors occurred"
+            if not support.verbose: err += "; run in verbose mode for details"
+        errors = [(str(tc), exc_str) for tc, exc_str in result.errors]
+        failures = [(str(tc), exc_str) for tc, exc_str in result.failures]
+        raise support.TestFailedWithDetails(err, errors, failures, stats=stats)
+    return result
+
+
+def regrtest_runner(result: TestResult, test_func, runtests: RunTests) -> None:
+    # Run test_func(), collect statistics, and detect reference and memory
+    # leaks.
+    if runtests.hunt_refleak:
+        from .refleak import runtest_refleak
+        refleak, test_result = runtest_refleak(result.test_name, test_func,
+                                               runtests.hunt_refleak,
+                                               runtests.quiet)
+    else:
+        test_result = test_func()
+        refleak = False
+
+    if refleak:
+        result.state = State.REFLEAK
+
+    stats: TestStats | None
+
+    match test_result:
+        case TestStats():
+            stats = test_result
+        case unittest.TestResult():
+            stats = TestStats.from_unittest(test_result)
+        case doctest.TestResults():
+            stats = TestStats.from_doctest(test_result)
+        case None:
+            print_warning(f"{result.test_name} test runner returned None: {test_func}")
+            stats = None
+        case _:
+            print_warning(f"Unknown test result type: {type(test_result)}")
+            stats = None
+
+    result.stats = stats
+
+
+# Storage of uncollectable GC objects (gc.garbage)
+GC_GARBAGE = []
+
+
+def _load_run_test(result: TestResult, runtests: RunTests) -> None:
+    # Load the test module and run the tests.
+    test_name = result.test_name
+    module_name = abs_module_name(test_name, runtests.test_dir)
+
+    # Remove the module from sys.module to reload it if it was already imported
+    sys.modules.pop(module_name, None)
+
+    test_mod = importlib.import_module(module_name)
+
+    if hasattr(test_mod, "test_main"):
+        # https://github.com/python/cpython/issues/89392
+        raise Exception(f"Module {test_name} defines test_main() which "
+                        f"is no longer supported by regrtest")
+    def test_func():
+        return run_unittest(test_mod)
+
+    try:
+        regrtest_runner(result, test_func, runtests)
+    finally:
+        # First kill any dangling references to open files etc.
+        # This can also issue some ResourceWarnings which would otherwise get
+        # triggered during the following test run, and possibly produce
+        # failures.
+        support.gc_collect()
+
+        remove_testfn(test_name, runtests.verbose)
+
+    if gc.garbage:
+        support.environment_altered = True
+        print_warning(f"{test_name} created {len(gc.garbage)} "
+                      f"uncollectable object(s)")
+
+        # move the uncollectable objects somewhere,
+        # so we don't see them again
+        GC_GARBAGE.extend(gc.garbage)
+        gc.garbage.clear()
+
+    support.reap_children()
+
+
+def _runtest_env_changed_exc(result: TestResult, runtests: RunTests,
+                             display_failure: bool = True) -> None:
+    # Handle exceptions, detect environment changes.
+
+    # Reset the environment_altered flag to detect if a test altered
+    # the environment
+    support.environment_altered = False
+
+    pgo = runtests.pgo
+    if pgo:
+        display_failure = False
+    quiet = runtests.quiet
+
+    test_name = result.test_name
+    try:
+        clear_caches()
+        support.gc_collect()
+
+        with saved_test_environment(test_name,
+                                    runtests.verbose, quiet, pgo=pgo):
+            _load_run_test(result, runtests)
+    except support.ResourceDenied as exc:
+        if not quiet and not pgo:
+            print(f"{test_name} skipped -- {exc}", flush=True)
+        result.state = State.RESOURCE_DENIED
+        return
+    except unittest.SkipTest as exc:
+        if not quiet and not pgo:
+            print(f"{test_name} skipped -- {exc}", flush=True)
+        result.state = State.SKIPPED
+        return
+    except support.TestFailedWithDetails as exc:
+        msg = f"test {test_name} failed"
+        if display_failure:
+            msg = f"{msg} -- {exc}"
+        print(msg, file=sys.stderr, flush=True)
+        result.state = State.FAILED
+        result.errors = exc.errors
+        result.failures = exc.failures
+        result.stats = exc.stats
+        return
+    except support.TestFailed as exc:
+        msg = f"test {test_name} failed"
+        if display_failure:
+            msg = f"{msg} -- {exc}"
+        print(msg, file=sys.stderr, flush=True)
+        result.state = State.FAILED
+        result.stats = exc.stats
+        return
+    except support.TestDidNotRun:
+        result.state = State.DID_NOT_RUN
+        return
+    except KeyboardInterrupt:
+        print()
+        result.state = State.INTERRUPTED
+        return
+    except:
+        if not pgo:
+            msg = traceback.format_exc()
+            print(f"test {test_name} crashed -- {msg}",
+                  file=sys.stderr, flush=True)
+        result.state = State.UNCAUGHT_EXC
+        return
+
+    if support.environment_altered:
+        result.set_env_changed()
+    # Don't override the state if it was already set (REFLEAK or ENV_CHANGED)
+    if result.state is None:
+        result.state = State.PASSED
+
+
+def _runtest(result: TestResult, runtests: RunTests) -> None:
+    # Capture stdout and stderr, set faulthandler timeout,
+    # and create JUnit XML report.
+    verbose = runtests.verbose
+    output_on_failure = runtests.output_on_failure
+    timeout = runtests.timeout
+
+    use_timeout = (
+        timeout is not None and threading_helper.can_start_thread
+    )
+    if use_timeout:
+        faulthandler.dump_traceback_later(timeout, exit=True)
+
+    try:
+        setup_tests(runtests)
+
+        if output_on_failure:
+            support.verbose = True
+
+            stream = io.StringIO()
+            orig_stdout = sys.stdout
+            orig_stderr = sys.stderr
+            print_warning = support.print_warning
+            orig_print_warnings_stderr = print_warning.orig_stderr
+
+            output = None
+            try:
+                sys.stdout = stream
+                sys.stderr = stream
+                # print_warning() writes into the temporary stream to preserve
+                # messages order. If support.environment_altered becomes true,
+                # warnings will be written to sys.stderr below.
+                print_warning.orig_stderr = stream
+
+                _runtest_env_changed_exc(result, runtests, display_failure=False)
+                # Ignore output if the test passed successfully
+                if result.state != State.PASSED:
+                    output = stream.getvalue()
+            finally:
+                sys.stdout = orig_stdout
+                sys.stderr = orig_stderr
+                print_warning.orig_stderr = orig_print_warnings_stderr
+
+            if output is not None:
+                sys.stderr.write(output)
+                sys.stderr.flush()
+        else:
+            # Tell tests to be moderately quiet
+            support.verbose = verbose
+            _runtest_env_changed_exc(result, runtests,
+                                     display_failure=not verbose)
+
+        xml_list = support.junit_xml_list
+        if xml_list:
+            import xml.etree.ElementTree as ET
+            result.xml_data = [ET.tostring(x).decode('us-ascii')
+                               for x in xml_list]
+    finally:
+        if use_timeout:
+            faulthandler.cancel_dump_traceback_later()
+        support.junit_xml_list = None
+
+
+def run_single_test(test_name: TestName, runtests: RunTests) -> TestResult:
+    """Run a single test.
+
+    test_name -- the name of the test
+
+    Returns a TestResult.
+
+    If runtests.use_junit, xml_data is a list containing each generated
+    testsuite element.
+    """
+    start_time = time.perf_counter()
+    result = TestResult(test_name)
+    pgo = runtests.pgo
+    try:
+        _runtest(result, runtests)
+    except:
+        if not pgo:
+            msg = traceback.format_exc()
+            print(f"test {test_name} crashed -- {msg}",
+                  file=sys.stderr, flush=True)
+        result.state = State.UNCAUGHT_EXC
+
+    sys.stdout.flush()
+    sys.stderr.flush()
+
+    result.duration = time.perf_counter() - start_time
+    return result
diff --git a/Lib/test/libregrtest/testresult.py b/Lib/test/libregrtest/testresult.py
new file mode 100644
index 0000000000..de23fdd59d
--- /dev/null
+++ b/Lib/test/libregrtest/testresult.py
@@ -0,0 +1,191 @@
+'''Test runner and result class for the regression test suite.
+
+'''
+
+import functools
+import io
+import sys
+import time
+import traceback
+import unittest
+from test import support
+
+class RegressionTestResult(unittest.TextTestResult):
+    USE_XML = False
+
+    def __init__(self, stream, descriptions, verbosity):
+        super().__init__(stream=stream, descriptions=descriptions,
+                         verbosity=2 if verbosity else 0)
+        self.buffer = True
+        if self.USE_XML:
+            from xml.etree import ElementTree as ET
+            from datetime import datetime, UTC
+            self.__ET = ET
+            self.__suite = ET.Element('testsuite')
+            self.__suite.set('start',
+                             datetime.now(UTC)
+                                     .replace(tzinfo=None)
+                                     .isoformat(' '))
+            self.__e = None
+        self.__start_time = None
+
+    @classmethod
+    def __getId(cls, test):
+        try:
+            test_id = test.id
+        except AttributeError:
+            return str(test)
+        try:
+            return test_id()
+        except TypeError:
+            return str(test_id)
+        return repr(test)
+
+    def startTest(self, test):
+        super().startTest(test)
+        if self.USE_XML:
+            self.__e = e = self.__ET.SubElement(self.__suite, 'testcase')
+        self.__start_time = time.perf_counter()
+
+    def _add_result(self, test, capture=False, **args):
+        if not self.USE_XML:
+            return
+        e = self.__e
+        self.__e = None
+        if e is None:
+            return
+        ET = self.__ET
+
+        e.set('name', args.pop('name', self.__getId(test)))
+        e.set('status', args.pop('status', 'run'))
+        e.set('result', args.pop('result', 'completed'))
+        if self.__start_time:
+            e.set('time', f'{time.perf_counter() - self.__start_time:0.6f}')
+
+        if capture:
+            if self._stdout_buffer is not None:
+                stdout = self._stdout_buffer.getvalue().rstrip()
+                ET.SubElement(e, 'system-out').text = stdout
+            if self._stderr_buffer is not None:
+                stderr = self._stderr_buffer.getvalue().rstrip()
+                ET.SubElement(e, 'system-err').text = stderr
+
+        for k, v in args.items():
+            if not k or not v:
+                continue
+            e2 = ET.SubElement(e, k)
+            if hasattr(v, 'items'):
+                for k2, v2 in v.items():
+                    if k2:
+                        e2.set(k2, str(v2))
+                    else:
+                        e2.text = str(v2)
+            else:
+                e2.text = str(v)
+
+    @classmethod
+    def __makeErrorDict(cls, err_type, err_value, err_tb):
+        if isinstance(err_type, type):
+            if err_type.__module__ == 'builtins':
+                typename = err_type.__name__
+            else:
+                typename = f'{err_type.__module__}.{err_type.__name__}'
+        else:
+            typename = repr(err_type)
+
+        msg = traceback.format_exception(err_type, err_value, None)
+        tb = traceback.format_exception(err_type, err_value, err_tb)
+
+        return {
+            'type': typename,
+            'message': ''.join(msg),
+            '': ''.join(tb),
+        }
+
+    def addError(self, test, err):
+        self._add_result(test, True, error=self.__makeErrorDict(*err))
+        super().addError(test, err)
+
+    def addExpectedFailure(self, test, err):
+        self._add_result(test, True, output=self.__makeErrorDict(*err))
+        super().addExpectedFailure(test, err)
+
+    def addFailure(self, test, err):
+        self._add_result(test, True, failure=self.__makeErrorDict(*err))
+        super().addFailure(test, err)
+        if support.failfast:
+            self.stop()
+
+    def addSkip(self, test, reason):
+        self._add_result(test, skipped=reason)
+        super().addSkip(test, reason)
+
+    def addSuccess(self, test):
+        self._add_result(test)
+        super().addSuccess(test)
+
+    def addUnexpectedSuccess(self, test):
+        self._add_result(test, outcome='UNEXPECTED_SUCCESS')
+        super().addUnexpectedSuccess(test)
+
+    def get_xml_element(self):
+        if not self.USE_XML:
+            raise ValueError("USE_XML is false")
+        e = self.__suite
+        e.set('tests', str(self.testsRun))
+        e.set('errors', str(len(self.errors)))
+        e.set('failures', str(len(self.failures)))
+        return e
+
+class QuietRegressionTestRunner:
+    def __init__(self, stream, buffer=False):
+        self.result = RegressionTestResult(stream, None, 0)
+        self.result.buffer = buffer
+
+    def run(self, test):
+        test(self.result)
+        return self.result
+
+def get_test_runner_class(verbosity, buffer=False):
+    if verbosity:
+        return functools.partial(unittest.TextTestRunner,
+                                 resultclass=RegressionTestResult,
+                                 buffer=buffer,
+                                 verbosity=verbosity)
+    return functools.partial(QuietRegressionTestRunner, buffer=buffer)
+
+def get_test_runner(stream, verbosity, capture_output=False):
+    return get_test_runner_class(verbosity, capture_output)(stream)
+
+if __name__ == '__main__':
+    import xml.etree.ElementTree as ET
+    RegressionTestResult.USE_XML = True
+
+    class TestTests(unittest.TestCase):
+        def test_pass(self):
+            pass
+
+        def test_pass_slow(self):
+            time.sleep(1.0)
+
+        def test_fail(self):
+            print('stdout', file=sys.stdout)
+            print('stderr', file=sys.stderr)
+            self.fail('failure message')
+
+        def test_error(self):
+            print('stdout', file=sys.stdout)
+            print('stderr', file=sys.stderr)
+            raise RuntimeError('error message')
+
+    suite = unittest.TestSuite()
+    suite.addTest(unittest.TestLoader().loadTestsFromTestCase(TestTests))
+    stream = io.StringIO()
+    runner_cls = get_test_runner_class(sum(a == '-v' for a in sys.argv))
+    runner = runner_cls(sys.stdout)
+    result = runner.run(suite)
+    print('Output:', stream.getvalue())
+    print('XML: ', end='')
+    for s in ET.tostringlist(result.get_xml_element()):
+        print(s.decode(), end='')
+    print()
diff --git a/Lib/test/libregrtest/utils.py b/Lib/test/libregrtest/utils.py
index 5e16b1ae05..653654de52 100644
--- a/Lib/test/libregrtest/utils.py
+++ b/Lib/test/libregrtest/utils.py
@@ -1,9 +1,60 @@
+import contextlib
+import faulthandler
+import locale
 import math
 import os.path
+import platform
+import random
+import shlex
+import signal
+import subprocess
 import sys
 import sysconfig
+import tempfile
 import textwrap
+from collections.abc import Callable
+
 from test import support
+from test.support import os_helper
+from test.support import threading_helper
+
+
+# All temporary files and temporary directories created by libregrtest should
+# use TMP_PREFIX so cleanup_temp_dir() can remove them all.
+TMP_PREFIX = 'test_python_'
+WORK_DIR_PREFIX = TMP_PREFIX
+WORKER_WORK_DIR_PREFIX = WORK_DIR_PREFIX + 'worker_'
+
+# bpo-38203: Maximum delay in seconds to exit Python (call Py_Finalize()).
+# Used to protect against threading._shutdown() hang.
+# Must be smaller than buildbot "1200 seconds without output" limit.
+EXIT_TIMEOUT = 120.0
+
+
+ALL_RESOURCES = ('audio', 'curses', 'largefile', 'network',
+                 'decimal', 'cpu', 'subprocess', 'urlfetch', 'gui', 'walltime')
+
+# Other resources excluded from --use=all:
+#
+# - extralagefile (ex: test_zipfile64): really too slow to be enabled
+#   "by default"
+# - tzdata: while needed to validate fully test_datetime, it makes
+#   test_datetime too slow (15-20 min on some buildbots) and so is disabled by
+#   default (see bpo-30822).
+RESOURCE_NAMES = ALL_RESOURCES + ('extralargefile', 'tzdata')
+
+
+# Types for types hints
+StrPath = str
+TestName = str
+StrJSON = str
+TestTuple = tuple[TestName, ...]
+TestList = list[TestName]
+# --match and --ignore options: list of patterns
+# ('*' joker character can be used)
+TestFilter = list[tuple[TestName, bool]]
+FilterTuple = tuple[TestName, ...]
+FilterDict = dict[TestName, FilterTuple]
 
 
 def format_duration(seconds):
@@ -31,7 +82,7 @@ def format_duration(seconds):
     return ' '.join(parts)
 
 
-def strip_py_suffix(names: list[str]):
+def strip_py_suffix(names: list[str] | None) -> None:
     if not names:
         return
     for idx, name in enumerate(names):
@@ -40,11 +91,20 @@ def strip_py_suffix(names: list[str]):
             names[idx] = basename
 
 
+def plural(n, singular, plural=None):
+    if n == 1:
+        return singular
+    elif plural is not None:
+        return plural
+    else:
+        return singular + 's'
+
+
 def count(n, word):
     if n == 1:
-        return "%d %s" % (n, word)
+        return f"{n} {word}"
     else:
-        return "%d %ss" % (n, word)
+        return f"{n} {word}s"
 
 
 def printlist(x, width=70, indent=4, file=None):
@@ -228,6 +288,11 @@ def get_build_info():
     ldflags_nodist = sysconfig.get_config_var('PY_LDFLAGS_NODIST') or ''
 
     build = []
+
+    # --disable-gil
+    if sysconfig.get_config_var('Py_NOGIL'):
+        build.append("nogil")
+
     if hasattr(sys, 'gettotalrefcount'):
         # --with-pydebug
         build.append('debug')
@@ -259,16 +324,8 @@ def get_build_info():
     elif '-flto' in ldflags_nodist:
         optimizations.append('LTO')
 
-    # --enable-optimizations
-    pgo_options = (
-        # GCC
-        '-fprofile-use',
-        # clang: -fprofile-instr-use=code.profclangd
-        '-fprofile-instr-use',
-        # ICC
-        "-prof-use",
-    )
-    if any(option in cflags_nodist for option in pgo_options):
+    if support.check_cflags_pgo():
+        # PGO (--enable-optimizations)
         optimizations.append('PGO')
     if optimizations:
         build.append('+'.join(optimizations))
@@ -300,3 +357,331 @@ def get_build_info():
         build.append("dtrace")
 
     return build
+
+
+def get_temp_dir(tmp_dir: StrPath | None = None) -> StrPath:
+    if tmp_dir:
+        tmp_dir = os.path.expanduser(tmp_dir)
+    else:
+        # When tests are run from the Python build directory, it is best practice
+        # to keep the test files in a subfolder.  This eases the cleanup of leftover
+        # files using the "make distclean" command.
+        if sysconfig.is_python_build():
+            if not support.is_wasi:
+                tmp_dir = sysconfig.get_config_var('abs_builddir')
+                if tmp_dir is None:
+                    tmp_dir = sysconfig.get_config_var('abs_srcdir')
+                    if not tmp_dir:
+                        # gh-74470: On Windows, only srcdir is available. Using
+                        # abs_builddir mostly matters on UNIX when building
+                        # Python out of the source tree, especially when the
+                        # source tree is read only.
+                        tmp_dir = sysconfig.get_config_var('srcdir')
+                tmp_dir = os.path.join(tmp_dir, 'build')
+            else:
+                # WASI platform
+                tmp_dir = sysconfig.get_config_var('projectbase')
+                tmp_dir = os.path.join(tmp_dir, 'build')
+
+                # When get_temp_dir() is called in a worker process,
+                # get_temp_dir() path is different than in the parent process
+                # which is not a WASI process. So the parent does not create
+                # the same "tmp_dir" than the test worker process.
+                os.makedirs(tmp_dir, exist_ok=True)
+        else:
+            tmp_dir = tempfile.gettempdir()
+
+    return os.path.abspath(tmp_dir)
+
+
+def fix_umask():
+    if support.is_emscripten:
+        # Emscripten has default umask 0o777, which breaks some tests.
+        # see https://github.com/emscripten-core/emscripten/issues/17269
+        old_mask = os.umask(0)
+        if old_mask == 0o777:
+            os.umask(0o027)
+        else:
+            os.umask(old_mask)
+
+
+def get_work_dir(parent_dir: StrPath, worker: bool = False) -> StrPath:
+    # Define a writable temp dir that will be used as cwd while running
+    # the tests. The name of the dir includes the pid to allow parallel
+    # testing (see the -j option).
+    # Emscripten and WASI have stubbed getpid(), Emscripten has only
+    # milisecond clock resolution. Use randint() instead.
+    if support.is_emscripten or support.is_wasi:
+        nounce = random.randint(0, 1_000_000)
+    else:
+        nounce = os.getpid()
+
+    if worker:
+        work_dir = WORK_DIR_PREFIX + str(nounce)
+    else:
+        work_dir = WORKER_WORK_DIR_PREFIX + str(nounce)
+    work_dir += os_helper.FS_NONASCII
+    work_dir = os.path.join(parent_dir, work_dir)
+    return work_dir
+
+
+@contextlib.contextmanager
+def exit_timeout():
+    try:
+        yield
+    except SystemExit as exc:
+        # bpo-38203: Python can hang at exit in Py_Finalize(), especially
+        # on threading._shutdown() call: put a timeout
+        if threading_helper.can_start_thread:
+            faulthandler.dump_traceback_later(EXIT_TIMEOUT, exit=True)
+        sys.exit(exc.code)
+
+
+def remove_testfn(test_name: TestName, verbose: int) -> None:
+    # Try to clean up os_helper.TESTFN if left behind.
+    #
+    # While tests shouldn't leave any files or directories behind, when a test
+    # fails that can be tedious for it to arrange.  The consequences can be
+    # especially nasty on Windows, since if a test leaves a file open, it
+    # cannot be deleted by name (while there's nothing we can do about that
+    # here either, we can display the name of the offending test, which is a
+    # real help).
+    name = os_helper.TESTFN
+    if not os.path.exists(name):
+        return
+
+    nuker: Callable[[str], None]
+    if os.path.isdir(name):
+        import shutil
+        kind, nuker = "directory", shutil.rmtree
+    elif os.path.isfile(name):
+        kind, nuker = "file", os.unlink
+    else:
+        raise RuntimeError(f"os.path says {name!r} exists but is neither "
+                           f"directory nor file")
+
+    if verbose:
+        print_warning(f"{test_name} left behind {kind} {name!r}")
+        support.environment_altered = True
+
+    try:
+        import stat
+        # fix possible permissions problems that might prevent cleanup
+        os.chmod(name, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)
+        nuker(name)
+    except Exception as exc:
+        print_warning(f"{test_name} left behind {kind} {name!r} "
+                      f"and it couldn't be removed: {exc}")
+
+
+def abs_module_name(test_name: TestName, test_dir: StrPath | None) -> TestName:
+    if test_name.startswith('test.') or test_dir:
+        return test_name
+    else:
+        # Import it from the test package
+        return 'test.' + test_name
+
+
+# gh-90681: When rerunning tests, we might need to rerun the whole
+# class or module suite if some its life-cycle hooks fail.
+# Test level hooks are not affected.
+_TEST_LIFECYCLE_HOOKS = frozenset((
+    'setUpClass', 'tearDownClass',
+    'setUpModule', 'tearDownModule',
+))
+
+def normalize_test_name(test_full_name, *, is_error=False):
+    short_name = test_full_name.split(" ")[0]
+    if is_error and short_name in _TEST_LIFECYCLE_HOOKS:
+        if test_full_name.startswith(('setUpModule (', 'tearDownModule (')):
+            # if setUpModule() or tearDownModule() failed, don't filter
+            # tests with the test file name, don't use use filters.
+            return None
+
+        # This means that we have a failure in a life-cycle hook,
+        # we need to rerun the whole module or class suite.
+        # Basically the error looks like this:
+        #    ERROR: setUpClass (test.test_reg_ex.RegTest)
+        # or
+        #    ERROR: setUpModule (test.test_reg_ex)
+        # So, we need to parse the class / module name.
+        lpar = test_full_name.index('(')
+        rpar = test_full_name.index(')')
+        return test_full_name[lpar + 1: rpar].split('.')[-1]
+    return short_name
+
+
+def adjust_rlimit_nofile():
+    """
+    On macOS the default fd limit (RLIMIT_NOFILE) is sometimes too low (256)
+    for our test suite to succeed. Raise it to something more reasonable. 1024
+    is a common Linux default.
+    """
+    try:
+        import resource
+    except ImportError:
+        return
+
+    fd_limit, max_fds = resource.getrlimit(resource.RLIMIT_NOFILE)
+
+    desired_fds = 1024
+
+    if fd_limit < desired_fds and fd_limit < max_fds:
+        new_fd_limit = min(desired_fds, max_fds)
+        try:
+            resource.setrlimit(resource.RLIMIT_NOFILE,
+                               (new_fd_limit, max_fds))
+            print(f"Raised RLIMIT_NOFILE: {fd_limit} -> {new_fd_limit}")
+        except (ValueError, OSError) as err:
+            print_warning(f"Unable to raise RLIMIT_NOFILE from {fd_limit} to "
+                          f"{new_fd_limit}: {err}.")
+
+
+def get_host_runner():
+    if (hostrunner := os.environ.get("_PYTHON_HOSTRUNNER")) is None:
+        hostrunner = sysconfig.get_config_var("HOSTRUNNER")
+    return hostrunner
+
+
+def is_cross_compiled():
+    return ('_PYTHON_HOST_PLATFORM' in os.environ)
+
+
+def format_resources(use_resources: tuple[str, ...]):
+    use_resources = set(use_resources)
+    all_resources = set(ALL_RESOURCES)
+
+    # Express resources relative to "all"
+    relative_all = ['all']
+    for name in sorted(all_resources - use_resources):
+        relative_all.append(f'-{name}')
+    for name in sorted(use_resources - all_resources):
+        relative_all.append(f'{name}')
+    all_text = ','.join(relative_all)
+    all_text = f"resources: {all_text}"
+
+    # List of enabled resources
+    text = ','.join(sorted(use_resources))
+    text = f"resources ({len(use_resources)}): {text}"
+
+    # Pick the shortest string (prefer relative to all if lengths are equal)
+    if len(all_text) <= len(text):
+        return all_text
+    else:
+        return text
+
+
+def process_cpu_count():
+    if hasattr(os, 'sched_getaffinity'):
+        return len(os.sched_getaffinity(0))
+    else:
+        return os.cpu_count()
+
+
+def display_header(use_resources: tuple[str, ...],
+                   python_cmd: tuple[str, ...] | None):
+    # Print basic platform information
+    print("==", platform.python_implementation(), *sys.version.split())
+    print("==", platform.platform(aliased=True),
+                  "%s-endian" % sys.byteorder)
+    print("== Python build:", ' '.join(get_build_info()))
+    print("== cwd:", os.getcwd())
+
+    cpu_count = os.cpu_count()
+    if cpu_count:
+        affinity = process_cpu_count()
+        if affinity and affinity != cpu_count:
+            cpu_count = f"{affinity} (process) / {cpu_count} (system)"
+        print("== CPU count:", cpu_count)
+    print("== encodings: locale=%s FS=%s"
+          % (locale.getencoding(), sys.getfilesystemencoding()))
+
+    if use_resources:
+        text = format_resources(use_resources)
+        print(f"== {text}")
+    else:
+        print("== resources: all test resources are disabled, "
+              "use -u option to unskip tests")
+
+    cross_compile = is_cross_compiled()
+    if cross_compile:
+        print("== cross compiled: Yes")
+    if python_cmd:
+        cmd = shlex.join(python_cmd)
+        print(f"== host python: {cmd}")
+
+        get_cmd = [*python_cmd, '-m', 'platform']
+        proc = subprocess.run(
+            get_cmd,
+            stdout=subprocess.PIPE,
+            text=True,
+            cwd=os_helper.SAVEDCWD)
+        stdout = proc.stdout.replace('\n', ' ').strip()
+        if stdout:
+            print(f"== host platform: {stdout}")
+        elif proc.returncode:
+            print(f"== host platform: <command failed with exit code {proc.returncode}>")
+    else:
+        hostrunner = get_host_runner()
+        if hostrunner:
+            print(f"== host runner: {hostrunner}")
+
+    # This makes it easier to remember what to set in your local
+    # environment when trying to reproduce a sanitizer failure.
+    asan = support.check_sanitizer(address=True)
+    msan = support.check_sanitizer(memory=True)
+    ubsan = support.check_sanitizer(ub=True)
+    sanitizers = []
+    if asan:
+        sanitizers.append("address")
+    if msan:
+        sanitizers.append("memory")
+    if ubsan:
+        sanitizers.append("undefined behavior")
+    if sanitizers:
+        print(f"== sanitizers: {', '.join(sanitizers)}")
+        for sanitizer, env_var in (
+            (asan, "ASAN_OPTIONS"),
+            (msan, "MSAN_OPTIONS"),
+            (ubsan, "UBSAN_OPTIONS"),
+        ):
+            options= os.environ.get(env_var)
+            if sanitizer and options is not None:
+                print(f"== {env_var}={options!r}")
+
+    print(flush=True)
+
+
+def cleanup_temp_dir(tmp_dir: StrPath):
+    import glob
+
+    path = os.path.join(glob.escape(tmp_dir), TMP_PREFIX + '*')
+    print("Cleanup %s directory" % tmp_dir)
+    for name in glob.glob(path):
+        if os.path.isdir(name):
+            print("Remove directory: %s" % name)
+            os_helper.rmtree(name)
+        else:
+            print("Remove file: %s" % name)
+            os_helper.unlink(name)
+
+WINDOWS_STATUS = {
+    0xC0000005: "STATUS_ACCESS_VIOLATION",
+    0xC00000FD: "STATUS_STACK_OVERFLOW",
+    0xC000013A: "STATUS_CONTROL_C_EXIT",
+}
+
+def get_signal_name(exitcode):
+    if exitcode < 0:
+        signum = -exitcode
+        try:
+            return signal.Signals(signum).name
+        except ValueError:
+            pass
+
+    try:
+        return WINDOWS_STATUS[exitcode]
+    except KeyError:
+        pass
+
+    return None
diff --git a/Lib/test/libregrtest/worker.py b/Lib/test/libregrtest/worker.py
new file mode 100644
index 0000000000..2eccfabc25
--- /dev/null
+++ b/Lib/test/libregrtest/worker.py
@@ -0,0 +1,116 @@
+import subprocess
+import sys
+import os
+from typing import Any, NoReturn
+
+from test import support
+from test.support import os_helper
+
+from .setup import setup_process, setup_test_dir
+from .runtests import RunTests, JsonFile, JsonFileType
+from .single import run_single_test
+from .utils import (
+    StrPath, StrJSON, TestFilter,
+    get_temp_dir, get_work_dir, exit_timeout)
+
+
+USE_PROCESS_GROUP = (hasattr(os, "setsid") and hasattr(os, "killpg"))
+
+
+def create_worker_process(runtests: RunTests, output_fd: int,
+                          tmp_dir: StrPath | None = None) -> subprocess.Popen:
+    python_cmd = runtests.python_cmd
+    worker_json = runtests.as_json()
+
+    python_opts = support.args_from_interpreter_flags()
+    if python_cmd is not None:
+        executable = python_cmd
+        # Remove -E option, since --python=COMMAND can set PYTHON environment
+        # variables, such as PYTHONPATH, in the worker process.
+        python_opts = [opt for opt in python_opts if opt != "-E"]
+    else:
+        executable = (sys.executable,)
+    cmd = [*executable, *python_opts,
+           '-u',    # Unbuffered stdout and stderr
+           '-m', 'test.libregrtest.worker',
+           worker_json]
+
+    env = dict(os.environ)
+    if tmp_dir is not None:
+        env['TMPDIR'] = tmp_dir
+        env['TEMP'] = tmp_dir
+        env['TMP'] = tmp_dir
+
+    # Running the child from the same working directory as regrtest's original
+    # invocation ensures that TEMPDIR for the child is the same when
+    # sysconfig.is_python_build() is true. See issue 15300.
+    #
+    # Emscripten and WASI Python must start in the Python source code directory
+    # to get 'python.js' or 'python.wasm' file. Then worker_process() changes
+    # to a temporary directory created to run tests.
+    work_dir = os_helper.SAVEDCWD
+
+    kwargs: dict[str, Any] = dict(
+        env=env,
+        stdout=output_fd,
+        # bpo-45410: Write stderr into stdout to keep messages order
+        stderr=output_fd,
+        text=True,
+        close_fds=True,
+        cwd=work_dir,
+    )
+    if USE_PROCESS_GROUP:
+        kwargs['start_new_session'] = True
+
+    # Pass json_file to the worker process
+    json_file = runtests.json_file
+    json_file.configure_subprocess(kwargs)
+
+    with json_file.inherit_subprocess():
+        return subprocess.Popen(cmd, **kwargs)
+
+
+def worker_process(worker_json: StrJSON) -> NoReturn:
+    runtests = RunTests.from_json(worker_json)
+    test_name = runtests.tests[0]
+    match_tests: TestFilter = runtests.match_tests
+    json_file: JsonFile = runtests.json_file
+
+    setup_test_dir(runtests.test_dir)
+    setup_process()
+
+    if runtests.rerun:
+        if match_tests:
+            matching = "matching: " + ", ".join(pattern for pattern, result in match_tests if result)
+            print(f"Re-running {test_name} in verbose mode ({matching})", flush=True)
+        else:
+            print(f"Re-running {test_name} in verbose mode", flush=True)
+
+    result = run_single_test(test_name, runtests)
+
+    if json_file.file_type == JsonFileType.STDOUT:
+        print()
+        result.write_json_into(sys.stdout)
+    else:
+        with json_file.open('w', encoding='utf-8') as json_fp:
+            result.write_json_into(json_fp)
+
+    sys.exit(0)
+
+
+def main():
+    if len(sys.argv) != 2:
+        print("usage: python -m test.libregrtest.worker JSON")
+        sys.exit(1)
+    worker_json = sys.argv[1]
+
+    tmp_dir = get_temp_dir()
+    work_dir = get_work_dir(tmp_dir, worker=True)
+
+    with exit_timeout():
+        with os_helper.temp_cwd(work_dir, quiet=True):
+            worker_process(worker_json)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/Lib/test/lock_tests.py b/Lib/test/lock_tests.py
index a4f52cb20a..024c6debcd 100644
--- a/Lib/test/lock_tests.py
+++ b/Lib/test/lock_tests.py
@@ -19,54 +19,74 @@
                                      "(no _at_fork_reinit method)")
 
 
-def _wait():
-    # A crude wait/yield function not relying on synchronization primitives.
-    time.sleep(0.01)
+def wait_threads_blocked(nthread):
+    # Arbitrary sleep to wait until N threads are blocked,
+    # like waiting for a lock.
+    time.sleep(0.010 * nthread)
+
 
 class Bunch(object):
     """
     A bunch of threads.
     """
-    def __init__(self, f, n, wait_before_exit=False):
+    def __init__(self, func, nthread, wait_before_exit=False):
         """
-        Construct a bunch of `n` threads running the same function `f`.
+        Construct a bunch of `nthread` threads running the same function `func`.
         If `wait_before_exit` is True, the threads won't terminate until
         do_finish() is called.
         """
-        self.f = f
-        self.n = n
+        self.func = func
+        self.nthread = nthread
         self.started = []
         self.finished = []
+        self.exceptions = []
         self._can_exit = not wait_before_exit
-        self.wait_thread = threading_helper.wait_threads_exit()
-        self.wait_thread.__enter__()
+        self._wait_thread = None
 
-        def task():
-            tid = threading.get_ident()
-            self.started.append(tid)
-            try:
-                f()
-            finally:
-                self.finished.append(tid)
-                while not self._can_exit:
-                    _wait()
+    def task(self):
+        tid = threading.get_ident()
+        self.started.append(tid)
+        try:
+            self.func()
+        except BaseException as exc:
+            self.exceptions.append(exc)
+        finally:
+            self.finished.append(tid)
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if self._can_exit:
+                    break
+
+    def __enter__(self):
+        self._wait_thread = threading_helper.wait_threads_exit(support.SHORT_TIMEOUT)
+        self._wait_thread.__enter__()
 
         try:
-            for i in range(n):
-                start_new_thread(task, ())
+            for _ in range(self.nthread):
+                start_new_thread(self.task, ())
         except:
             self._can_exit = True
             raise
 
-    def wait_for_started(self):
-        while len(self.started) < self.n:
-            _wait()
+        for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+            if len(self.started) >= self.nthread:
+                break
+
+        return self
+
+    def __exit__(self, exc_type, exc_value, traceback):
+        for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+            if len(self.finished) >= self.nthread:
+                break
+
+        # Wait until threads completely exit according to _thread._count()
+        self._wait_thread.__exit__(None, None, None)
 
-    def wait_for_finished(self):
-        while len(self.finished) < self.n:
-            _wait()
-        # Wait for threads exit
-        self.wait_thread.__exit__(None, None, None)
+        # Break reference cycle
+        exceptions = self.exceptions
+        self.exceptions = None
+        if exceptions:
+            raise ExceptionGroup(f"{self.func} threads raised exceptions",
+                                 exceptions)
 
     def do_finish(self):
         self._can_exit = True
@@ -94,6 +114,12 @@ class BaseLockTests(BaseTestCase):
     Tests for both recursive and non-recursive locks.
     """
 
+    def wait_phase(self, phase, expected):
+        for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+            if len(phase) >= expected:
+                break
+        self.assertEqual(len(phase), expected)
+
     def test_constructor(self):
         lock = self.locktype()
         del lock
@@ -131,41 +157,57 @@ def test_try_acquire_contended(self):
         result = []
         def f():
             result.append(lock.acquire(False))
-        Bunch(f, 1).wait_for_finished()
+        with Bunch(f, 1):
+            pass
         self.assertFalse(result[0])
         lock.release()
 
     def test_acquire_contended(self):
         lock = self.locktype()
         lock.acquire()
-        N = 5
         def f():
             lock.acquire()
             lock.release()
 
-        b = Bunch(f, N)
-        b.wait_for_started()
-        _wait()
-        self.assertEqual(len(b.finished), 0)
-        lock.release()
-        b.wait_for_finished()
-        self.assertEqual(len(b.finished), N)
+        N = 5
+        with Bunch(f, N) as bunch:
+            # Threads block on lock.acquire()
+            wait_threads_blocked(N)
+            self.assertEqual(len(bunch.finished), 0)
+
+            # Threads unblocked
+            lock.release()
+
+        self.assertEqual(len(bunch.finished), N)
 
     def test_with(self):
         lock = self.locktype()
         def f():
             lock.acquire()
             lock.release()
-        def _with(err=None):
+
+        def with_lock(err=None):
             with lock:
                 if err is not None:
                     raise err
-        _with()
-        # Check the lock is unacquired
-        Bunch(f, 1).wait_for_finished()
-        self.assertRaises(TypeError, _with, TypeError)
-        # Check the lock is unacquired
-        Bunch(f, 1).wait_for_finished()
+
+        # Acquire the lock, do nothing, with releases the lock
+        with lock:
+            pass
+
+        # Check that the lock is unacquired
+        with Bunch(f, 1):
+            pass
+
+        # Acquire the lock, raise an exception, with releases the lock
+        with self.assertRaises(TypeError):
+            with lock:
+                raise TypeError
+
+        # Check that the lock is unacquired even if after an exception
+        # was raised in the previous "with lock:" block
+        with Bunch(f, 1):
+            pass
 
     def test_thread_leak(self):
         # The lock shouldn't leak a Thread instance when used from a foreign
@@ -174,17 +216,11 @@ def test_thread_leak(self):
         def f():
             lock.acquire()
             lock.release()
-        n = len(threading.enumerate())
+
         # We run many threads in the hope that existing threads ids won't
         # be recycled.
-        Bunch(f, 15).wait_for_finished()
-        if len(threading.enumerate()) != n:
-            # There is a small window during which a Thread instance's
-            # target function has finished running, but the Thread is still
-            # alive and registered.  Avoid spurious failures by waiting a
-            # bit more (seen on a buildbot).
-            time.sleep(0.4)
-            self.assertEqual(n, len(threading.enumerate()))
+        with Bunch(f, 15):
+            pass
 
     def test_timeout(self):
         lock = self.locktype()
@@ -208,7 +244,8 @@ def f():
             results.append(lock.acquire(timeout=0.5))
             t2 = time.monotonic()
             results.append(t2 - t1)
-        Bunch(f, 1).wait_for_finished()
+        with Bunch(f, 1):
+            pass
         self.assertFalse(results[0])
         self.assertTimeout(results[1], 0.5)
 
@@ -242,15 +279,13 @@ def f():
             phase.append(None)
 
         with threading_helper.wait_threads_exit():
+            # Thread blocked on lock.acquire()
             start_new_thread(f, ())
-            while len(phase) == 0:
-                _wait()
-            _wait()
-            self.assertEqual(len(phase), 1)
+            self.wait_phase(phase, 1)
+
+            # Thread unblocked
             lock.release()
-            while len(phase) == 1:
-                _wait()
-            self.assertEqual(len(phase), 2)
+            self.wait_phase(phase, 2)
 
     def test_different_thread(self):
         # Lock can be released from a different thread.
@@ -258,8 +293,8 @@ def test_different_thread(self):
         lock.acquire()
         def f():
             lock.release()
-        b = Bunch(f, 1)
-        b.wait_for_finished()
+        with Bunch(f, 1):
+            pass
         lock.acquire()
         lock.release()
 
@@ -330,17 +365,52 @@ def test_release_save_unacquired(self):
         lock.release()
         self.assertRaises(RuntimeError, lock._release_save)
 
+    def test_recursion_count(self):
+        lock = self.locktype()
+        self.assertEqual(0, lock._recursion_count())
+        lock.acquire()
+        self.assertEqual(1, lock._recursion_count())
+        lock.acquire()
+        lock.acquire()
+        self.assertEqual(3, lock._recursion_count())
+        lock.release()
+        self.assertEqual(2, lock._recursion_count())
+        lock.release()
+        lock.release()
+        self.assertEqual(0, lock._recursion_count())
+
+        phase = []
+
+        def f():
+            lock.acquire()
+            phase.append(None)
+
+            self.wait_phase(phase, 2)
+            lock.release()
+            phase.append(None)
+
+        with threading_helper.wait_threads_exit():
+            # Thread blocked on lock.acquire()
+            start_new_thread(f, ())
+            self.wait_phase(phase, 1)
+            self.assertEqual(0, lock._recursion_count())
+
+            # Thread unblocked
+            phase.append(None)
+            self.wait_phase(phase, 3)
+            self.assertEqual(0, lock._recursion_count())
+
     def test_different_thread(self):
         # Cannot release from a different thread
         lock = self.locktype()
         def f():
             lock.acquire()
-        b = Bunch(f, 1, True)
-        try:
-            self.assertRaises(RuntimeError, lock.release)
-        finally:
-            b.do_finish()
-        b.wait_for_finished()
+
+        with Bunch(f, 1, True) as bunch:
+            try:
+                self.assertRaises(RuntimeError, lock.release)
+            finally:
+                bunch.do_finish()
 
     def test__is_owned(self):
         lock = self.locktype()
@@ -352,7 +422,8 @@ def test__is_owned(self):
         result = []
         def f():
             result.append(lock._is_owned())
-        Bunch(f, 1).wait_for_finished()
+        with Bunch(f, 1):
+            pass
         self.assertFalse(result[0])
         lock.release()
         self.assertTrue(lock._is_owned())
@@ -385,12 +456,15 @@ def _check_notify(self, evt):
         def f():
             results1.append(evt.wait())
             results2.append(evt.wait())
-        b = Bunch(f, N)
-        b.wait_for_started()
-        _wait()
-        self.assertEqual(len(results1), 0)
-        evt.set()
-        b.wait_for_finished()
+
+        with Bunch(f, N):
+            # Threads blocked on first evt.wait()
+            wait_threads_blocked(N)
+            self.assertEqual(len(results1), 0)
+
+            # Threads unblocked
+            evt.set()
+
         self.assertEqual(results1, [True] * N)
         self.assertEqual(results2, [True] * N)
 
@@ -413,35 +487,43 @@ def f():
             r = evt.wait(0.5)
             t2 = time.monotonic()
             results2.append((r, t2 - t1))
-        Bunch(f, N).wait_for_finished()
+
+        with Bunch(f, N):
+            pass
+
         self.assertEqual(results1, [False] * N)
         for r, dt in results2:
             self.assertFalse(r)
             self.assertTimeout(dt, 0.5)
+
         # The event is set
         results1 = []
         results2 = []
         evt.set()
-        Bunch(f, N).wait_for_finished()
+        with Bunch(f, N):
+            pass
+
         self.assertEqual(results1, [True] * N)
         for r, dt in results2:
             self.assertTrue(r)
 
     def test_set_and_clear(self):
-        # Issue #13502: check that wait() returns true even when the event is
+        # gh-57711: check that wait() returns true even when the event is
         # cleared before the waiting thread is woken up.
-        evt = self.eventtype()
+        event = self.eventtype()
         results = []
-        timeout = 0.250
-        N = 5
         def f():
-            results.append(evt.wait(timeout * 4))
-        b = Bunch(f, N)
-        b.wait_for_started()
-        time.sleep(timeout)
-        evt.set()
-        evt.clear()
-        b.wait_for_finished()
+            results.append(event.wait(support.LONG_TIMEOUT))
+
+        N = 5
+        with Bunch(f, N):
+            # Threads blocked on event.wait()
+            wait_threads_blocked(N)
+
+            # Threads unblocked
+            event.set()
+            event.clear()
+
         self.assertEqual(results, [True] * N)
 
     @requires_fork
@@ -497,15 +579,14 @@ def _check_notify(self, cond):
         # Note that this test is sensitive to timing.  If the worker threads
         # don't execute in a timely fashion, the main thread may think they
         # are further along then they are.  The main thread therefore issues
-        # _wait() statements to try to make sure that it doesn't race ahead
-        # of the workers.
+        # wait_threads_blocked() statements to try to make sure that it doesn't
+        # race ahead of the workers.
         # Secondly, this test assumes that condition variables are not subject
         # to spurious wakeups.  The absence of spurious wakeups is an implementation
         # detail of Condition Variables in current CPython, but in general, not
         # a guaranteed property of condition variables as a programming
         # construct.  In particular, it is possible that this can no longer
         # be conveniently guaranteed should their implementation ever change.
-        N = 5
         ready = []
         results1 = []
         results2 = []
@@ -514,58 +595,83 @@ def f():
             cond.acquire()
             ready.append(phase_num)
             result = cond.wait()
+
             cond.release()
             results1.append((result, phase_num))
+
             cond.acquire()
             ready.append(phase_num)
+
             result = cond.wait()
             cond.release()
             results2.append((result, phase_num))
-        b = Bunch(f, N)
-        b.wait_for_started()
-        # first wait, to ensure all workers settle into cond.wait() before
-        # we continue. See issues #8799 and #30727.
-        while len(ready) < 5:
-            _wait()
-        ready.clear()
-        self.assertEqual(results1, [])
-        # Notify 3 threads at first
-        cond.acquire()
-        cond.notify(3)
-        _wait()
-        phase_num = 1
-        cond.release()
-        while len(results1) < 3:
-            _wait()
-        self.assertEqual(results1, [(True, 1)] * 3)
-        self.assertEqual(results2, [])
-        # make sure all awaken workers settle into cond.wait()
-        while len(ready) < 3:
-            _wait()
-        # Notify 5 threads: they might be in their first or second wait
-        cond.acquire()
-        cond.notify(5)
-        _wait()
-        phase_num = 2
-        cond.release()
-        while len(results1) + len(results2) < 8:
-            _wait()
-        self.assertEqual(results1, [(True, 1)] * 3 + [(True, 2)] * 2)
-        self.assertEqual(results2, [(True, 2)] * 3)
-        # make sure all workers settle into cond.wait()
-        while len(ready) < 5:
-            _wait()
-        # Notify all threads: they are all in their second wait
-        cond.acquire()
-        cond.notify_all()
-        _wait()
-        phase_num = 3
-        cond.release()
-        while len(results2) < 5:
-            _wait()
-        self.assertEqual(results1, [(True, 1)] * 3 + [(True,2)] * 2)
-        self.assertEqual(results2, [(True, 2)] * 3 + [(True, 3)] * 2)
-        b.wait_for_finished()
+
+        N = 5
+        with Bunch(f, N):
+            # first wait, to ensure all workers settle into cond.wait() before
+            # we continue. See issues #8799 and #30727.
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(ready) >= N:
+                    break
+
+            ready.clear()
+            self.assertEqual(results1, [])
+
+            # Notify 3 threads at first
+            count1 = 3
+            cond.acquire()
+            cond.notify(count1)
+            wait_threads_blocked(count1)
+
+            # Phase 1
+            phase_num = 1
+            cond.release()
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(results1) >= count1:
+                    break
+
+            self.assertEqual(results1, [(True, 1)] * count1)
+            self.assertEqual(results2, [])
+
+            # Wait until awaken workers are blocked on cond.wait()
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(ready) >= count1 :
+                    break
+
+            # Notify 5 threads: they might be in their first or second wait
+            cond.acquire()
+            cond.notify(5)
+            wait_threads_blocked(N)
+
+            # Phase 2
+            phase_num = 2
+            cond.release()
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(results1) + len(results2) >= (N + count1):
+                    break
+
+            count2 = N - count1
+            self.assertEqual(results1, [(True, 1)] * count1 + [(True, 2)] * count2)
+            self.assertEqual(results2, [(True, 2)] * count1)
+
+            # Make sure all workers settle into cond.wait()
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(ready) >= N:
+                    break
+
+            # Notify all threads: they are all in their second wait
+            cond.acquire()
+            cond.notify_all()
+            wait_threads_blocked(N)
+
+            # Phase 3
+            phase_num = 3
+            cond.release()
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(results2) >= N:
+                    break
+            self.assertEqual(results1, [(True, 1)] * count1 + [(True, 2)] * count2)
+            self.assertEqual(results2, [(True, 2)] * count1 + [(True, 3)] * count2)
 
     def test_notify(self):
         cond = self.condtype()
@@ -575,19 +681,23 @@ def test_notify(self):
 
     def test_timeout(self):
         cond = self.condtype()
+        timeout = 0.5
         results = []
-        N = 5
         def f():
             cond.acquire()
             t1 = time.monotonic()
-            result = cond.wait(0.5)
+            result = cond.wait(timeout)
             t2 = time.monotonic()
             cond.release()
             results.append((t2 - t1, result))
-        Bunch(f, N).wait_for_finished()
+
+        N = 5
+        with Bunch(f, N):
+            pass
         self.assertEqual(len(results), N)
+
         for dt, result in results:
-            self.assertTimeout(dt, 0.5)
+            self.assertTimeout(dt, timeout)
             # Note that conceptually (that"s the condition variable protocol)
             # a wait() may succeed even if no one notifies us and before any
             # timeout occurs.  Spurious wakeups can occur.
@@ -600,17 +710,16 @@ def test_waitfor(self):
         state = 0
         def f():
             with cond:
-                result = cond.wait_for(lambda : state==4)
+                result = cond.wait_for(lambda: state == 4)
                 self.assertTrue(result)
                 self.assertEqual(state, 4)
-        b = Bunch(f, 1)
-        b.wait_for_started()
-        for i in range(4):
-            time.sleep(0.01)
-            with cond:
-                state += 1
-                cond.notify()
-        b.wait_for_finished()
+
+        with Bunch(f, 1):
+            for i in range(4):
+                time.sleep(0.010)
+                with cond:
+                    state += 1
+                    cond.notify()
 
     def test_waitfor_timeout(self):
         cond = self.condtype()
@@ -624,15 +733,15 @@ def f():
                 self.assertFalse(result)
                 self.assertTimeout(dt, 0.1)
                 success.append(None)
-        b = Bunch(f, 1)
-        b.wait_for_started()
-        # Only increment 3 times, so state == 4 is never reached.
-        for i in range(3):
-            time.sleep(0.01)
-            with cond:
-                state += 1
-                cond.notify()
-        b.wait_for_finished()
+
+        with Bunch(f, 1):
+            # Only increment 3 times, so state == 4 is never reached.
+            for i in range(3):
+                time.sleep(0.010)
+                with cond:
+                    state += 1
+                    cond.notify()
+
         self.assertEqual(len(success), 1)
 
 
@@ -661,73 +770,107 @@ def test_acquire_destroy(self):
         del sem
 
     def test_acquire_contended(self):
-        sem = self.semtype(7)
+        sem_value = 7
+        sem = self.semtype(sem_value)
         sem.acquire()
-        N = 10
+
         sem_results = []
         results1 = []
         results2 = []
         phase_num = 0
-        def f():
+
+        def func():
             sem_results.append(sem.acquire())
             results1.append(phase_num)
+
             sem_results.append(sem.acquire())
             results2.append(phase_num)
-        b = Bunch(f, 10)
-        b.wait_for_started()
-        while len(results1) + len(results2) < 6:
-            _wait()
-        self.assertEqual(results1 + results2, [0] * 6)
-        phase_num = 1
-        for i in range(7):
-            sem.release()
-        while len(results1) + len(results2) < 13:
-            _wait()
-        self.assertEqual(sorted(results1 + results2), [0] * 6 + [1] * 7)
-        phase_num = 2
-        for i in range(6):
+
+        def wait_count(count):
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(results1) + len(results2) >= count:
+                    break
+
+        N = 10
+        with Bunch(func, N):
+            # Phase 0
+            count1 = sem_value - 1
+            wait_count(count1)
+            self.assertEqual(results1 + results2, [0] * count1)
+
+            # Phase 1
+            phase_num = 1
+            for i in range(sem_value):
+                sem.release()
+            count2 = sem_value
+            wait_count(count1 + count2)
+            self.assertEqual(sorted(results1 + results2),
+                             [0] * count1 + [1] * count2)
+
+            # Phase 2
+            phase_num = 2
+            count3 = (sem_value - 1)
+            for i in range(count3):
+                sem.release()
+            wait_count(count1 + count2 + count3)
+            self.assertEqual(sorted(results1 + results2),
+                             [0] * count1 + [1] * count2 + [2] * count3)
+            # The semaphore is still locked
+            self.assertFalse(sem.acquire(False))
+
+            # Final release, to let the last thread finish
+            count4 = 1
             sem.release()
-        while len(results1) + len(results2) < 19:
-            _wait()
-        self.assertEqual(sorted(results1 + results2), [0] * 6 + [1] * 7 + [2] * 6)
-        # The semaphore is still locked
-        self.assertFalse(sem.acquire(False))
-        # Final release, to let the last thread finish
-        sem.release()
-        b.wait_for_finished()
-        self.assertEqual(sem_results, [True] * (6 + 7 + 6 + 1))
+
+        self.assertEqual(sem_results,
+                         [True] * (count1 + count2 + count3 + count4))
 
     def test_multirelease(self):
-        sem = self.semtype(7)
+        sem_value = 7
+        sem = self.semtype(sem_value)
         sem.acquire()
+
         results1 = []
         results2 = []
         phase_num = 0
-        def f():
+        def func():
             sem.acquire()
             results1.append(phase_num)
+
             sem.acquire()
             results2.append(phase_num)
-        b = Bunch(f, 10)
-        b.wait_for_started()
-        while len(results1) + len(results2) < 6:
-            _wait()
-        self.assertEqual(results1 + results2, [0] * 6)
-        phase_num = 1
-        sem.release(7)
-        while len(results1) + len(results2) < 13:
-            _wait()
-        self.assertEqual(sorted(results1 + results2), [0] * 6 + [1] * 7)
-        phase_num = 2
-        sem.release(6)
-        while len(results1) + len(results2) < 19:
-            _wait()
-        self.assertEqual(sorted(results1 + results2), [0] * 6 + [1] * 7 + [2] * 6)
-        # The semaphore is still locked
-        self.assertFalse(sem.acquire(False))
-        # Final release, to let the last thread finish
-        sem.release()
-        b.wait_for_finished()
+
+        def wait_count(count):
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if len(results1) + len(results2) >= count:
+                    break
+
+        with Bunch(func, 10):
+            # Phase 0
+            count1 = sem_value - 1
+            wait_count(count1)
+            self.assertEqual(results1 + results2, [0] * count1)
+
+            # Phase 1
+            phase_num = 1
+            count2 = sem_value
+            sem.release(count2)
+            wait_count(count1 + count2)
+            self.assertEqual(sorted(results1 + results2),
+                             [0] * count1 + [1] * count2)
+
+            # Phase 2
+            phase_num = 2
+            count3 = sem_value - 1
+            sem.release(count3)
+            wait_count(count1 + count2 + count3)
+            self.assertEqual(sorted(results1 + results2),
+                             [0] * count1 + [1] * count2 + [2] * count3)
+            # The semaphore is still locked
+            self.assertFalse(sem.acquire(False))
+
+            # Final release, to let the last thread finish
+            sem.release()
 
     def test_try_acquire(self):
         sem = self.semtype(2)
@@ -744,7 +887,8 @@ def test_try_acquire_contended(self):
         def f():
             results.append(sem.acquire(False))
             results.append(sem.acquire(False))
-        Bunch(f, 5).wait_for_finished()
+        with Bunch(f, 5):
+            pass
         # There can be a thread switch between acquiring the semaphore and
         # appending the result, therefore results will not necessarily be
         # ordered.
@@ -770,12 +914,14 @@ def test_default_value(self):
         def f():
             sem.acquire()
             sem.release()
-        b = Bunch(f, 1)
-        b.wait_for_started()
-        _wait()
-        self.assertFalse(b.finished)
-        sem.release()
-        b.wait_for_finished()
+
+        with Bunch(f, 1) as bunch:
+            # Thread blocked on sem.acquire()
+            wait_threads_blocked(1)
+            self.assertFalse(bunch.finished)
+
+            # Thread unblocked
+            sem.release()
 
     def test_with(self):
         sem = self.semtype(2)
@@ -846,13 +992,13 @@ class BarrierTests(BaseTestCase):
 
     def setUp(self):
         self.barrier = self.barriertype(self.N, timeout=self.defaultTimeout)
+
     def tearDown(self):
         self.barrier.abort()
 
     def run_threads(self, f):
-        b = Bunch(f, self.N-1)
-        f()
-        b.wait_for_finished()
+        with Bunch(f, self.N):
+            pass
 
     def multipass(self, results, n):
         m = self.barrier.parties
@@ -943,8 +1089,9 @@ def f():
             i = self.barrier.wait()
             if i == self.N//2:
                 # Wait until the other threads are all in the barrier.
-                while self.barrier.n_waiting < self.N-1:
-                    time.sleep(0.001)
+                for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                    if self.barrier.n_waiting >= (self.N - 1):
+                        break
                 self.barrier.reset()
             else:
                 try:
@@ -1004,25 +1151,27 @@ def f():
             i = self.barrier.wait()
             if i == self.N // 2:
                 # One thread is late!
-                time.sleep(1.0)
+                time.sleep(self.defaultTimeout / 2)
             # Default timeout is 2.0, so this is shorter.
             self.assertRaises(threading.BrokenBarrierError,
-                              self.barrier.wait, 0.5)
+                              self.barrier.wait, self.defaultTimeout / 4)
         self.run_threads(f)
 
     def test_default_timeout(self):
         """
         Test the barrier's default timeout
         """
-        # create a barrier with a low default timeout
-        barrier = self.barriertype(self.N, timeout=0.3)
+        timeout = 0.100
+        barrier = self.barriertype(2, timeout=timeout)
         def f():
-            i = barrier.wait()
-            if i == self.N // 2:
-                # One thread is later than the default timeout of 0.3s.
-                time.sleep(1.0)
-            self.assertRaises(threading.BrokenBarrierError, barrier.wait)
-        self.run_threads(f)
+            self.assertRaises(threading.BrokenBarrierError,
+                              barrier.wait)
+
+        start_time = time.monotonic()
+        with Bunch(f, 1):
+            pass
+        dt = time.monotonic() - start_time
+        self.assertGreaterEqual(dt, timeout)
 
     def test_single_thread(self):
         b = self.barriertype(1)
@@ -1030,16 +1179,28 @@ def test_single_thread(self):
         b.wait()
 
     def test_repr(self):
-        b = self.barriertype(3)
-        self.assertRegex(repr(b), r"<\w+\.Barrier at .*: waiters=0/3>")
+        barrier = self.barriertype(3)
+        timeout = support.LONG_TIMEOUT
+        self.assertRegex(repr(barrier), r"<\w+\.Barrier at .*: waiters=0/3>")
         def f():
-            b.wait(3)
-        bunch = Bunch(f, 2)
-        bunch.wait_for_started()
-        time.sleep(0.2)
-        self.assertRegex(repr(b), r"<\w+\.Barrier at .*: waiters=2/3>")
-        b.wait(3)
-        bunch.wait_for_finished()
-        self.assertRegex(repr(b), r"<\w+\.Barrier at .*: waiters=0/3>")
-        b.abort()
-        self.assertRegex(repr(b), r"<\w+\.Barrier at .*: broken>")
+            barrier.wait(timeout)
+
+        N = 2
+        with Bunch(f, N):
+            # Threads blocked on barrier.wait()
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if barrier.n_waiting >= N:
+                    break
+            self.assertRegex(repr(barrier),
+                             r"<\w+\.Barrier at .*: waiters=2/3>")
+
+            # Threads unblocked
+            barrier.wait(timeout)
+
+        self.assertRegex(repr(barrier),
+                         r"<\w+\.Barrier at .*: waiters=0/3>")
+
+        # Abort the barrier
+        barrier.abort()
+        self.assertRegex(repr(barrier),
+                         r"<\w+\.Barrier at .*: broken>")
diff --git a/Lib/test/make_ssl_certs.py b/Lib/test/make_ssl_certs.py
deleted file mode 100644
index 94a35a64ab..0000000000
--- a/Lib/test/make_ssl_certs.py
+++ /dev/null
@@ -1,312 +0,0 @@
-"""Make the custom certificate and private key files used by test_ssl
-and friends."""
-
-import os
-import pprint
-import shutil
-import tempfile
-from subprocess import *
-
-startdate = "20180829142316Z"
-enddate = "20371028142316Z"
-
-req_template = """
-    [ default ]
-    base_url               = http://testca.pythontest.net/testca
-
-    [req]
-    distinguished_name     = req_distinguished_name
-    prompt                 = no
-
-    [req_distinguished_name]
-    C                      = XY
-    L                      = Castle Anthrax
-    O                      = Python Software Foundation
-    CN                     = {hostname}
-
-    [req_x509_extensions_nosan]
-
-    [req_x509_extensions_simple]
-    subjectAltName         = @san
-
-    [req_x509_extensions_full]
-    subjectAltName         = @san
-    keyUsage               = critical,keyEncipherment,digitalSignature
-    extendedKeyUsage       = serverAuth,clientAuth
-    basicConstraints       = critical,CA:false
-    subjectKeyIdentifier   = hash
-    authorityKeyIdentifier = keyid:always,issuer:always
-    authorityInfoAccess    = @issuer_ocsp_info
-    crlDistributionPoints  = @crl_info
-
-    [ issuer_ocsp_info ]
-    caIssuers;URI.0        = $base_url/pycacert.cer
-    OCSP;URI.0             = $base_url/ocsp/
-
-    [ crl_info ]
-    URI.0                  = $base_url/revocation.crl
-
-    [san]
-    DNS.1 = {hostname}
-    {extra_san}
-
-    [dir_sect]
-    C                      = XY
-    L                      = Castle Anthrax
-    O                      = Python Software Foundation
-    CN                     = dirname example
-
-    [princ_name]
-    realm = EXP:0, GeneralString:KERBEROS.REALM
-    principal_name = EXP:1, SEQUENCE:principal_seq
-
-    [principal_seq]
-    name_type = EXP:0, INTEGER:1
-    name_string = EXP:1, SEQUENCE:principals
-
-    [principals]
-    princ1 = GeneralString:username
-
-    [ ca ]
-    default_ca      = CA_default
-
-    [ CA_default ]
-    dir = cadir
-    database  = $dir/index.txt
-    crlnumber = $dir/crl.txt
-    default_md = sha256
-    startdate = {startdate}
-    default_startdate = {startdate}
-    enddate = {enddate}
-    default_enddate = {enddate}
-    default_days = 7000
-    default_crl_days = 7000
-    certificate = pycacert.pem
-    private_key = pycakey.pem
-    serial    = $dir/serial
-    RANDFILE  = $dir/.rand
-    policy          = policy_match
-
-    [ policy_match ]
-    countryName             = match
-    stateOrProvinceName     = optional
-    organizationName        = match
-    organizationalUnitName  = optional
-    commonName              = supplied
-    emailAddress            = optional
-
-    [ policy_anything ]
-    countryName   = optional
-    stateOrProvinceName = optional
-    localityName    = optional
-    organizationName  = optional
-    organizationalUnitName  = optional
-    commonName    = supplied
-    emailAddress    = optional
-
-
-    [ v3_ca ]
-
-    subjectKeyIdentifier=hash
-    authorityKeyIdentifier=keyid:always,issuer
-    basicConstraints = CA:true
-
-    """
-
-here = os.path.abspath(os.path.dirname(__file__))
-
-
-def make_cert_key(hostname, sign=False, extra_san='',
-                  ext='req_x509_extensions_full', key='rsa:3072'):
-    print("creating cert for " + hostname)
-    tempnames = []
-    for i in range(3):
-        with tempfile.NamedTemporaryFile(delete=False) as f:
-            tempnames.append(f.name)
-    req_file, cert_file, key_file = tempnames
-    try:
-        req = req_template.format(
-            hostname=hostname,
-            extra_san=extra_san,
-            startdate=startdate,
-            enddate=enddate
-        )
-        with open(req_file, 'w') as f:
-            f.write(req)
-        args = ['req', '-new', '-nodes', '-days', '7000',
-                '-newkey', key, '-keyout', key_file,
-                '-extensions', ext,
-                '-config', req_file]
-        if sign:
-            with tempfile.NamedTemporaryFile(delete=False) as f:
-                tempnames.append(f.name)
-                reqfile = f.name
-            args += ['-out', reqfile ]
-
-        else:
-            args += ['-x509', '-out', cert_file ]
-        check_call(['openssl'] + args)
-
-        if sign:
-            args = [
-                'ca',
-                '-config', req_file,
-                '-extensions', ext,
-                '-out', cert_file,
-                '-outdir', 'cadir',
-                '-policy', 'policy_anything',
-                '-batch', '-infiles', reqfile
-            ]
-            check_call(['openssl'] + args)
-
-
-        with open(cert_file, 'r') as f:
-            cert = f.read()
-        with open(key_file, 'r') as f:
-            key = f.read()
-        return cert, key
-    finally:
-        for name in tempnames:
-            os.remove(name)
-
-TMP_CADIR = 'cadir'
-
-def unmake_ca():
-    shutil.rmtree(TMP_CADIR)
-
-def make_ca():
-    os.mkdir(TMP_CADIR)
-    with open(os.path.join('cadir','index.txt'),'a+') as f:
-        pass # empty file
-    with open(os.path.join('cadir','crl.txt'),'a+') as f:
-        f.write("00")
-    with open(os.path.join('cadir','index.txt.attr'),'w+') as f:
-        f.write('unique_subject = no')
-    # random start value for serial numbers
-    with open(os.path.join('cadir','serial'), 'w') as f:
-        f.write('CB2D80995A69525B\n')
-
-    with tempfile.NamedTemporaryFile("w") as t:
-        req = req_template.format(
-            hostname='our-ca-server',
-            extra_san='',
-            startdate=startdate,
-            enddate=enddate
-        )
-        t.write(req)
-        t.flush()
-        with tempfile.NamedTemporaryFile() as f:
-            args = ['req', '-config', t.name, '-new',
-                    '-nodes',
-                    '-newkey', 'rsa:3072',
-                    '-keyout', 'pycakey.pem',
-                    '-out', f.name,
-                    '-subj', '/C=XY/L=Castle Anthrax/O=Python Software Foundation CA/CN=our-ca-server']
-            check_call(['openssl'] + args)
-            args = ['ca', '-config', t.name,
-                    '-out', 'pycacert.pem', '-batch', '-outdir', TMP_CADIR,
-                    '-keyfile', 'pycakey.pem',
-                    '-selfsign', '-extensions', 'v3_ca', '-infiles', f.name ]
-            check_call(['openssl'] + args)
-            args = ['ca', '-config', t.name, '-gencrl', '-out', 'revocation.crl']
-            check_call(['openssl'] + args)
-
-    # capath hashes depend on subject!
-    check_call([
-        'openssl', 'x509', '-in', 'pycacert.pem', '-out', 'capath/ceff1710.0'
-    ])
-    shutil.copy('capath/ceff1710.0', 'capath/b1930218.0')
-
-
-def print_cert(path):
-    import _ssl
-    pprint.pprint(_ssl._test_decode_cert(path))
-
-
-if __name__ == '__main__':
-    os.chdir(here)
-    cert, key = make_cert_key('localhost', ext='req_x509_extensions_simple')
-    with open('ssl_cert.pem', 'w') as f:
-        f.write(cert)
-    with open('ssl_key.pem', 'w') as f:
-        f.write(key)
-    print("password protecting ssl_key.pem in ssl_key.passwd.pem")
-    check_call(['openssl','pkey','-in','ssl_key.pem','-out','ssl_key.passwd.pem','-aes256','-passout','pass:somepass'])
-    check_call(['openssl','pkey','-in','ssl_key.pem','-out','keycert.passwd.pem','-aes256','-passout','pass:somepass'])
-
-    with open('keycert.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    with open('keycert.passwd.pem', 'a+') as f:
-        f.write(cert)
-
-    # For certificate matching tests
-    make_ca()
-    cert, key = make_cert_key('fakehostname', ext='req_x509_extensions_simple')
-    with open('keycert2.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    cert, key = make_cert_key('localhost', sign=True)
-    with open('keycert3.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    cert, key = make_cert_key('fakehostname', sign=True)
-    with open('keycert4.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    cert, key = make_cert_key(
-        'localhost-ecc', sign=True, key='param:secp384r1.pem'
-    )
-    with open('keycertecc.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    extra_san = [
-        'otherName.1 = 1.2.3.4;UTF8:some other identifier',
-        'otherName.2 = 1.3.6.1.5.2.2;SEQUENCE:princ_name',
-        'email.1 = user@example.org',
-        'DNS.2 = www.example.org',
-        # GEN_X400
-        'dirName.1 = dir_sect',
-        # GEN_EDIPARTY
-        'URI.1 = https://www.python.org/',
-        'IP.1 = 127.0.0.1',
-        'IP.2 = ::1',
-        'RID.1 = 1.2.3.4.5',
-    ]
-
-    cert, key = make_cert_key('allsans', sign=True, extra_san='\n'.join(extra_san))
-    with open('allsans.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    extra_san = [
-        # könig (king)
-        'DNS.2 = xn--knig-5qa.idn.pythontest.net',
-        # königsgäßchen (king's alleyway)
-        'DNS.3 = xn--knigsgsschen-lcb0w.idna2003.pythontest.net',
-        'DNS.4 = xn--knigsgchen-b4a3dun.idna2008.pythontest.net',
-        # βόλοσ (marble)
-        'DNS.5 = xn--nxasmq6b.idna2003.pythontest.net',
-        'DNS.6 = xn--nxasmm1c.idna2008.pythontest.net',
-    ]
-
-    # IDN SANS, signed
-    cert, key = make_cert_key('idnsans', sign=True, extra_san='\n'.join(extra_san))
-    with open('idnsans.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    cert, key = make_cert_key('nosan', sign=True, ext='req_x509_extensions_nosan')
-    with open('nosan.pem', 'w') as f:
-        f.write(key)
-        f.write(cert)
-
-    unmake_ca()
-    print("update Lib/test/test_ssl.py and Lib/test/test_asyncio/utils.py")
-    print_cert('keycert.pem')
-    print_cert('keycert3.pem')
diff --git a/Lib/test/mod_generics_cache.py b/Lib/test/mod_generics_cache.py
deleted file mode 100644
index 6c1ee2fec8..0000000000
--- a/Lib/test/mod_generics_cache.py
+++ /dev/null
@@ -1,24 +0,0 @@
-"""Module for testing the behavior of generics across different modules."""
-
-from typing import TypeVar, Generic, Optional, TypeAliasType
-
-default_a: Optional['A'] = None
-default_b: Optional['B'] = None
-
-T = TypeVar('T')
-
-
-class A(Generic[T]):
-    some_b: 'B'
-
-
-class B(Generic[T]):
-    class A(Generic[T]):
-        pass
-
-    my_inner_a1: 'B.A'
-    my_inner_a2: A
-    my_outer_a: 'A'  # unless somebody calls get_type_hints with localns=B.__dict__
-
-type Alias = int
-OldStyle = TypeAliasType("OldStyle", int)
diff --git a/Lib/test/nokia.pem b/Lib/test/nokia.pem
deleted file mode 100644
index 0d044df436..0000000000
--- a/Lib/test/nokia.pem
+++ /dev/null
@@ -1,31 +0,0 @@
-# Certificate for projects.developer.nokia.com:443 (see issue 13034)
------BEGIN CERTIFICATE-----
-MIIFLDCCBBSgAwIBAgIQLubqdkCgdc7lAF9NfHlUmjANBgkqhkiG9w0BAQUFADCB
-vDELMAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQL
-ExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTswOQYDVQQLEzJUZXJtcyBvZiB1c2Ug
-YXQgaHR0cHM6Ly93d3cudmVyaXNpZ24uY29tL3JwYSAoYykxMDE2MDQGA1UEAxMt
-VmVyaVNpZ24gQ2xhc3MgMyBJbnRlcm5hdGlvbmFsIFNlcnZlciBDQSAtIEczMB4X
-DTExMDkyMTAwMDAwMFoXDTEyMDkyMDIzNTk1OVowcTELMAkGA1UEBhMCRkkxDjAM
-BgNVBAgTBUVzcG9vMQ4wDAYDVQQHFAVFc3BvbzEOMAwGA1UEChQFTm9raWExCzAJ
-BgNVBAsUAkJJMSUwIwYDVQQDFBxwcm9qZWN0cy5kZXZlbG9wZXIubm9raWEuY29t
-MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCr92w1bpHYSYxUEx8N/8Iddda2
-lYi+aXNtQfV/l2Fw9Ykv3Ipw4nLeGTj18FFlAZgMdPRlgrzF/NNXGw/9l3/qKdow
-CypkQf8lLaxb9Ze1E/KKmkRJa48QTOqvo6GqKuTI6HCeGlG1RxDb8YSKcQWLiytn
-yj3Wp4MgRQO266xmMQIDAQABo4IB9jCCAfIwQQYDVR0RBDowOIIccHJvamVjdHMu
-ZGV2ZWxvcGVyLm5va2lhLmNvbYIYcHJvamVjdHMuZm9ydW0ubm9raWEuY29tMAkG
-A1UdEwQCMAAwCwYDVR0PBAQDAgWgMEEGA1UdHwQ6MDgwNqA0oDKGMGh0dHA6Ly9T
-VlJJbnRsLUczLWNybC52ZXJpc2lnbi5jb20vU1ZSSW50bEczLmNybDBEBgNVHSAE
-PTA7MDkGC2CGSAGG+EUBBxcDMCowKAYIKwYBBQUHAgEWHGh0dHBzOi8vd3d3LnZl
-cmlzaWduLmNvbS9ycGEwKAYDVR0lBCEwHwYJYIZIAYb4QgQBBggrBgEFBQcDAQYI
-KwYBBQUHAwIwcgYIKwYBBQUHAQEEZjBkMCQGCCsGAQUFBzABhhhodHRwOi8vb2Nz
-cC52ZXJpc2lnbi5jb20wPAYIKwYBBQUHMAKGMGh0dHA6Ly9TVlJJbnRsLUczLWFp
-YS52ZXJpc2lnbi5jb20vU1ZSSW50bEczLmNlcjBuBggrBgEFBQcBDARiMGChXqBc
-MFowWDBWFglpbWFnZS9naWYwITAfMAcGBSsOAwIaBBRLa7kolgYMu9BSOJsprEsH
-iyEFGDAmFiRodHRwOi8vbG9nby52ZXJpc2lnbi5jb20vdnNsb2dvMS5naWYwDQYJ
-KoZIhvcNAQEFBQADggEBACQuPyIJqXwUyFRWw9x5yDXgMW4zYFopQYOw/ItRY522
-O5BsySTh56BWS6mQB07XVfxmYUGAvRQDA5QHpmY8jIlNwSmN3s8RKo+fAtiNRlcL
-x/mWSfuMs3D/S6ev3D6+dpEMZtjrhOdctsarMKp8n/hPbwhAbg5hVjpkW5n8vz2y
-0KxvvkA1AxpLwpVv7OlK17ttzIHw8bp9HTlHBU5s8bKz4a565V/a5HI0CSEv/+0y
-ko4/ghTnZc1CkmUngKKeFMSah/mT/xAh8XnE2l1AazFa8UKuYki1e+ArHaGZc4ix
-UYOtiRphwfuYQhRZ7qX9q2MMkCMI65XNK/SaFrAbbG0=
------END CERTIFICATE-----
diff --git a/Lib/test/nosan.pem b/Lib/test/nosan.pem
deleted file mode 100644
index ec10cdcabb..0000000000
--- a/Lib/test/nosan.pem
+++ /dev/null
@@ -1,130 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/QIBADANBgkqhkiG9w0BAQEFAASCBucwggbjAgEAAoIBgQCv3sUoOE4F7Pye
-AT2Q6XpXrGUOu1fYgdnItLLLhvn7ACuHMj7TA5UKXxsepJn5m2Ji9LvAbksr1IWd
-LZAvNgjwsUR+E4HbY108BhVt9sk3HFkvE0OOFbAa14ICtYPe18P/4Hv6Zfu/GJDU
-rwXHNCUu0p6i/mospZ5O3sx5MgVaShknGAEC3Kp7zOgusMmE8XSbkNQa3ARMkW4o
-kTqWKAeAHDjVFVyyhzZQmo+gaLzhWfJVSZhlJsuiLoZGGrVTq85EiXsE4l8rPaI+
-mKkVzWP13IZW+Fx1tiIktumdHWb1OQWrvm8AiT9b8PcFCUUrvhQFcLDSCZjKlQ0t
-RWrSSKrrVsSldOreqRLtpjGzFJpGnTcvslL7rP5pg5DjBsYmVcDjrmRuJuhGq52X
-/6HEC97GouVK8tT1LVMv1wufVPn+i9TzwxOuRWeUvVqLAJgWQ9N3yKdymH+VrpZk
-/oB9ScyDakGezZBW5CeOQbNJ8WoX58jNxefGjtqKxmyztu43r3ECAwEAAQKCAYBQ
-fVoqYCqFV8L95X9x1QljGsldhqxbsIIl811o/KtoDtndFEfgd2E8z+4vhhHaRR0w
-QOW02kWZF7jXCMVWdhp9XgQE15S0/bLsB7TDERFiIZ1HiD+AxbhFcKBV8REbahCQ
-CQN0xDwFZ47RaBDy7JCf71EfM+UP7fSYECvww83jVspQNBIyZx+3bT5OMCbqqz88
-+3m3mT52dJDADEeN9WAJZ+Ey1IYKRwu6tCJLvePEF1BrbDVNBgZogXZ+mzalxpjr
-4RpGPMMa+VWc8HmDVd+LtpwKJcQD00GvUP4fNywn+5jvNWl54FdQiTLPrieTWxas
-XUQ2crxP7Aqr2/vsU5Ruru5uF7H+ssMHp9YQDhpJ2+SVhQ9P+/loXCuKGt+BrB2Z
-MlitO3f+vfRtzATmJ8G0qFrOqZK1A/qsiyIze240C1hAl3oy2xpZqTDGp4gRWwoi
-OIN0HmH9UbP7bbNQY1x/zstTbza4/7rGb1+DZKeZIMu7QjBCU0rtsJpGtUvcQGEC
-gcEA42GMYSL/HljZMF1LsDhTX/cmP8FDNgONhWYxT+w0Csnj1usLNBaT63dYnEiW
-QKydRR4casAR1Kdy4Yfcy2lCy1kCfwqkQYk8fxSsOSHRjUfwC1SnfdYlwKFMxw4a
-oZF0R4oVCBYrfP+8kqrj+5gs/gXblsw72XkYtbCdIriKKdmUzTx7MegzSqh2PVRi
-rJzuwCZQ/O0NfhwdOHxLQDo0dgD+vv9e+KOSoJ9FDv8HH1tnolpRMdkSA8AJR/Nk
-DXt1AoHBAMYBfTKQZ2jqLKybe4tP+YKjvjVp8vJx0iNUXFN/P6hBaSBOgq85uxXL
-X3s7N/pkOCjyE95B8QusIkbnbfdyEP89O4bTbUHPXyAkHyRkR7Vny49HYuaR/aXQ
-mXC0J2z5bXVpCQ514l/R/Io3wBph+hbG3To7pp9pMOV4qzvibUZaTZFwH+q+xDwf
-SKSFy3fcomgH4/K5/QuKVj0jOUQsYjQQWb8GukS2KZK3zYJIAG1bBcsCVpSuBdW0
-eCZgqjnwjQKBwCUyUwWc9QEg5b68tGIKhNEhHDe3xOf0ItWcxxpc+JJ/Pm9tGfMW
-cnJFntBKK5I+6qdg6qMn8oLINcnhMORxvsSHNhpUQlSaP7RGTHo4JxCmoQUpfxDd
-1GUzvdyeWQrvQYdmdlRRVCHpsA6KOCtzVIDlsmtz06Ka5cjrMHl6mNeJyYbdiwW6
-B5ICBv23bUDxlzkFy5/ko51qufkAlErYeraHKSVTn1SrZZQzGdf/LkoZ6NUtUzUF
-XqYQZzRHA6oU9QKBwDslzLljC5D6ivfQxln6POV6dmJMUOd9erFVDPNgSqq/R2EA
-MueXDjzXcKFGMlWYxHHuxmKZPiEnfWHC1kWZjFxCdVq0I6oKATd/stHTJtyYseUO
-BQwtRiDXLE7PcguKgtkU1EC+lC3dc1vyhW8cH3HYW9N+aCqsaI/TuQr9e3kNlqhA
-XzhnXgU7rx5+XSZkARukZ8JlLqLY4yQGNqAXxgoZbEW1A8VsyQRr5XbqfT4td5CK
-FUT6qwGIlG+aZp9CLQKBwQCQkwdW9A/Q4Ffq8+XTL1hJ24m/q11OLAPODUypOhWw
-OCbX2fkv59pSBe6niZDBls1NpHB9mzalBrJCfU+yKC667gKcKULOnWULIoOQvmcg
-Ka3hkkW28gTnCjfDIYm3IdsLjc67zJplOixaKgxhO8NtJZGtg0oLIrofG8EYRInv
-OmtGw+XE+s4TVs6WgXnEg9zWQ5ZYtqQVn6PT5jsz+Nrvipi61HWHVBd7g+78ojps
-3suWxl0FvgzTW5HD16WRXeI=
------END PRIVATE KEY-----
-Certificate:
-    Data:
-        Version: 1 (0x0)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:61
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, L=Castle Anthrax, O=Python Software Foundation, CN=nosan
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                RSA Public-Key: (3072 bit)
-                Modulus:
-                    00:af:de:c5:28:38:4e:05:ec:fc:9e:01:3d:90:e9:
-                    7a:57:ac:65:0e:bb:57:d8:81:d9:c8:b4:b2:cb:86:
-                    f9:fb:00:2b:87:32:3e:d3:03:95:0a:5f:1b:1e:a4:
-                    99:f9:9b:62:62:f4:bb:c0:6e:4b:2b:d4:85:9d:2d:
-                    90:2f:36:08:f0:b1:44:7e:13:81:db:63:5d:3c:06:
-                    15:6d:f6:c9:37:1c:59:2f:13:43:8e:15:b0:1a:d7:
-                    82:02:b5:83:de:d7:c3:ff:e0:7b:fa:65:fb:bf:18:
-                    90:d4:af:05:c7:34:25:2e:d2:9e:a2:fe:6a:2c:a5:
-                    9e:4e:de:cc:79:32:05:5a:4a:19:27:18:01:02:dc:
-                    aa:7b:cc:e8:2e:b0:c9:84:f1:74:9b:90:d4:1a:dc:
-                    04:4c:91:6e:28:91:3a:96:28:07:80:1c:38:d5:15:
-                    5c:b2:87:36:50:9a:8f:a0:68:bc:e1:59:f2:55:49:
-                    98:65:26:cb:a2:2e:86:46:1a:b5:53:ab:ce:44:89:
-                    7b:04:e2:5f:2b:3d:a2:3e:98:a9:15:cd:63:f5:dc:
-                    86:56:f8:5c:75:b6:22:24:b6:e9:9d:1d:66:f5:39:
-                    05:ab:be:6f:00:89:3f:5b:f0:f7:05:09:45:2b:be:
-                    14:05:70:b0:d2:09:98:ca:95:0d:2d:45:6a:d2:48:
-                    aa:eb:56:c4:a5:74:ea:de:a9:12:ed:a6:31:b3:14:
-                    9a:46:9d:37:2f:b2:52:fb:ac:fe:69:83:90:e3:06:
-                    c6:26:55:c0:e3:ae:64:6e:26:e8:46:ab:9d:97:ff:
-                    a1:c4:0b:de:c6:a2:e5:4a:f2:d4:f5:2d:53:2f:d7:
-                    0b:9f:54:f9:fe:8b:d4:f3:c3:13:ae:45:67:94:bd:
-                    5a:8b:00:98:16:43:d3:77:c8:a7:72:98:7f:95:ae:
-                    96:64:fe:80:7d:49:cc:83:6a:41:9e:cd:90:56:e4:
-                    27:8e:41:b3:49:f1:6a:17:e7:c8:cd:c5:e7:c6:8e:
-                    da:8a:c6:6c:b3:b6:ee:37:af:71
-                Exponent: 65537 (0x10001)
-    Signature Algorithm: sha256WithRSAEncryption
-         91:42:c2:15:57:42:47:77:e7:0f:c5:55:26:b1:5b:c3:5e:ba:
-         81:db:e1:a4:9f:b8:42:5a:21:c9:8c:18:ae:0f:90:ab:9a:24:
-         e7:d2:78:fc:bd:97:29:b1:5c:46:1f:5b:b8:d2:a7:87:f1:50:
-         53:5b:d3:be:57:74:bd:e5:75:db:50:81:f7:37:95:0b:69:ef:
-         39:8c:5c:82:d5:64:62:d5:8b:e9:e0:31:e1:73:d2:5a:2c:de:
-         43:5a:06:e5:d3:4d:d0:35:e0:9f:c2:73:31:bc:35:69:d4:fb:
-         7d:f0:1a:33:f7:f6:25:72:9c:a6:84:05:08:f6:b5:e8:04:10:
-         f1:1f:f2:95:ad:a1:f8:d8:80:a5:eb:75:43:99:33:90:0c:79:
-         fc:c0:87:08:95:20:aa:c2:81:0b:22:6f:56:f4:8f:2a:23:f8:
-         40:47:1c:03:a5:b1:04:0a:04:4a:df:d0:88:a8:bc:31:f2:42:
-         9b:d8:11:14:9e:e3:68:ea:07:2c:15:de:d2:36:5a:15:38:ed:
-         d2:af:0e:b4:b6:1d:a0:57:94:ea:c3:c7:4c:14:57:81:00:57:
-         94:d3:b0:27:69:d7:48:02:6c:e5:97:f7:be:22:7c:38:24:af:
-         b2:b0:7b:08:75:1e:ca:2e:c7:41:ef:8b:74:cf:c9:c3:6f:39:
-         b9:52:41:18:c6:70:24:54:51:04:fe:5f:88:70:35:e5:1c:8e:
-         d6:67:69:44:44:33:9b:8c:fe:a5:b9:95:48:66:84:f3:1a:04:
-         ab:a3:57:c1:b6:b4:2f:28:12:45:2b:cb:42:d3:f4:a5:ce:7b:
-         6c:1f:e4:c8:a9:e7:d4:6d:c8:27:2d:69:26:c5:e8:73:10:54:
-         1f:c3:bf:fd:aa:f5:95:6f:f6:ca:d5:06:8f:1b:79:93:e3:86:
-         ba:8d:fe:a8:10:8f:95:3e:14:09:bf:ca:88:59:e2:93:b6:ec:
-         03:a9:7e:dd:1f:5f:13:d3:29:b3:a6:f3:6a:df:30:53:44:c8:
-         cd:e5:82:57:bc:9c
------BEGIN CERTIFICATE-----
-MIIEJDCCAowCCQDLLYCZWmlSYTANBgkqhkiG9w0BAQsFADBNMQswCQYDVQQGEwJY
-WTEmMCQGA1UECgwdUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24gQ0ExFjAUBgNV
-BAMMDW91ci1jYS1zZXJ2ZXIwHhcNMTgwODI5MTQyMzE2WhcNMzcxMDI4MTQyMzE2
-WjBbMQswCQYDVQQGEwJYWTEXMBUGA1UEBwwOQ2FzdGxlIEFudGhyYXgxIzAhBgNV
-BAoMGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMQ4wDAYDVQQDDAVub3NhbjCC
-AaIwDQYJKoZIhvcNAQEBBQADggGPADCCAYoCggGBAK/exSg4TgXs/J4BPZDpeles
-ZQ67V9iB2ci0ssuG+fsAK4cyPtMDlQpfGx6kmfmbYmL0u8BuSyvUhZ0tkC82CPCx
-RH4TgdtjXTwGFW32yTccWS8TQ44VsBrXggK1g97Xw//ge/pl+78YkNSvBcc0JS7S
-nqL+aiylnk7ezHkyBVpKGScYAQLcqnvM6C6wyYTxdJuQ1BrcBEyRbiiROpYoB4Ac
-ONUVXLKHNlCaj6BovOFZ8lVJmGUmy6IuhkYatVOrzkSJewTiXys9oj6YqRXNY/Xc
-hlb4XHW2IiS26Z0dZvU5Bau+bwCJP1vw9wUJRSu+FAVwsNIJmMqVDS1FatJIqutW
-xKV06t6pEu2mMbMUmkadNy+yUvus/mmDkOMGxiZVwOOuZG4m6EarnZf/ocQL3sai
-5Ury1PUtUy/XC59U+f6L1PPDE65FZ5S9WosAmBZD03fIp3KYf5WulmT+gH1JzINq
-QZ7NkFbkJ45Bs0nxahfnyM3F58aO2orGbLO27jevcQIDAQABMA0GCSqGSIb3DQEB
-CwUAA4IBgQCRQsIVV0JHd+cPxVUmsVvDXrqB2+Gkn7hCWiHJjBiuD5CrmiTn0nj8
-vZcpsVxGH1u40qeH8VBTW9O+V3S95XXbUIH3N5ULae85jFyC1WRi1Yvp4DHhc9Ja
-LN5DWgbl003QNeCfwnMxvDVp1Pt98Boz9/YlcpymhAUI9rXoBBDxH/KVraH42ICl
-63VDmTOQDHn8wIcIlSCqwoELIm9W9I8qI/hARxwDpbEECgRK39CIqLwx8kKb2BEU
-nuNo6gcsFd7SNloVOO3Srw60th2gV5Tqw8dMFFeBAFeU07AnaddIAmzll/e+Inw4
-JK+ysHsIdR7KLsdB74t0z8nDbzm5UkEYxnAkVFEE/l+IcDXlHI7WZ2lERDObjP6l
-uZVIZoTzGgSro1fBtrQvKBJFK8tC0/SlzntsH+TIqefUbcgnLWkmxehzEFQfw7/9
-qvWVb/bK1QaPG3mT44a6jf6oEI+VPhQJv8qIWeKTtuwDqX7dH18T0ymzpvNq3zBT
-RMjN5YJXvJw=
------END CERTIFICATE-----
diff --git a/Lib/test/nullbytecert.pem b/Lib/test/nullbytecert.pem
deleted file mode 100644
index 447186c950..0000000000
--- a/Lib/test/nullbytecert.pem
+++ /dev/null
@@ -1,90 +0,0 @@
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number: 0 (0x0)
-    Signature Algorithm: sha1WithRSAEncryption
-        Issuer: C=US, ST=Oregon, L=Beaverton, O=Python Software Foundation, OU=Python Core Development, CN=null.python.org\x00example.org/emailAddress=python-dev@python.org
-        Validity
-            Not Before: Aug  7 13:11:52 2013 GMT
-            Not After : Aug  7 13:12:52 2013 GMT
-        Subject: C=US, ST=Oregon, L=Beaverton, O=Python Software Foundation, OU=Python Core Development, CN=null.python.org\x00example.org/emailAddress=python-dev@python.org
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                Public-Key: (2048 bit)
-                Modulus:
-                    00:b5:ea:ed:c9:fb:46:7d:6f:3b:76:80:dd:3a:f3:
-                    03:94:0b:a7:a6:db:ec:1d:df:ff:23:74:08:9d:97:
-                    16:3f:a3:a4:7b:3e:1b:0e:96:59:25:03:a7:26:e2:
-                    88:a9:cf:79:cd:f7:04:56:b0:ab:79:32:6e:59:c1:
-                    32:30:54:eb:58:a8:cb:91:f0:42:a5:64:27:cb:d4:
-                    56:31:88:52:ad:cf:bd:7f:f0:06:64:1f:cc:27:b8:
-                    a3:8b:8c:f3:d8:29:1f:25:0b:f5:46:06:1b:ca:02:
-                    45:ad:7b:76:0a:9c:bf:bb:b9:ae:0d:16:ab:60:75:
-                    ae:06:3e:9c:7c:31:dc:92:2f:29:1a:e0:4b:0c:91:
-                    90:6c:e9:37:c5:90:d7:2a:d7:97:15:a3:80:8f:5d:
-                    7b:49:8f:54:30:d4:97:2c:1c:5b:37:b5:ab:69:30:
-                    68:43:d3:33:78:4b:02:60:f5:3c:44:80:a1:8f:e7:
-                    f0:0f:d1:5e:87:9e:46:cf:62:fc:f9:bf:0c:65:12:
-                    f1:93:c8:35:79:3f:c8:ec:ec:47:f5:ef:be:44:d5:
-                    ae:82:1e:2d:9a:9f:98:5a:67:65:e1:74:70:7c:cb:
-                    d3:c2:ce:0e:45:49:27:dc:e3:2d:d4:fb:48:0e:2f:
-                    9e:77:b8:14:46:c0:c4:36:ca:02:ae:6a:91:8c:da:
-                    2f:85
-                Exponent: 65537 (0x10001)
-        X509v3 extensions:
-            X509v3 Basic Constraints: critical
-                CA:FALSE
-            X509v3 Subject Key Identifier:
-                88:5A:55:C0:52:FF:61:CD:52:A3:35:0F:EA:5A:9C:24:38:22:F7:5C
-            X509v3 Key Usage:
-                Digital Signature, Non Repudiation, Key Encipherment
-            X509v3 Subject Alternative Name:
-                *************************************************************
-                WARNING: The values for DNS, email and URI are WRONG. OpenSSL
-                         doesn't print the text after a NULL byte.
-                *************************************************************
-                DNS:altnull.python.org, email:null@python.org, URI:http://null.python.org, IP Address:192.0.2.1, IP Address:2001:DB8:0:0:0:0:0:1
-    Signature Algorithm: sha1WithRSAEncryption
-         ac:4f:45:ef:7d:49:a8:21:70:8e:88:59:3e:d4:36:42:70:f5:
-         a3:bd:8b:d7:a8:d0:58:f6:31:4a:b1:a4:a6:dd:6f:d9:e8:44:
-         3c:b6:0a:71:d6:7f:b1:08:61:9d:60:ce:75:cf:77:0c:d2:37:
-         86:02:8d:5e:5d:f9:0f:71:b4:16:a8:c1:3d:23:1c:f1:11:b3:
-         56:6e:ca:d0:8d:34:94:e6:87:2a:99:f2:ae:ae:cc:c2:e8:86:
-         de:08:a8:7f:c5:05:fa:6f:81:a7:82:e6:d0:53:9d:34:f4:ac:
-         3e:40:fe:89:57:7a:29:a4:91:7e:0b:c6:51:31:e5:10:2f:a4:
-         60:76:cd:95:51:1a:be:8b:a1:b0:fd:ad:52:bd:d7:1b:87:60:
-         d2:31:c7:17:c4:18:4f:2d:08:25:a3:a7:4f:b7:92:ca:e2:f5:
-         25:f1:54:75:81:9d:b3:3d:61:a2:f7:da:ed:e1:c6:6f:2c:60:
-         1f:d8:6f:c5:92:05:ab:c9:09:62:49:a9:14:ad:55:11:cc:d6:
-         4a:19:94:99:97:37:1d:81:5f:8b:cf:a3:a8:96:44:51:08:3d:
-         0b:05:65:12:eb:b6:70:80:88:48:72:4f:c6:c2:da:cf:cd:8e:
-         5b:ba:97:2f:60:b4:96:56:49:5e:3a:43:76:63:04:be:2a:f6:
-         c1:ca:a9:94
------BEGIN CERTIFICATE-----
-MIIE2DCCA8CgAwIBAgIBADANBgkqhkiG9w0BAQUFADCBxTELMAkGA1UEBhMCVVMx
-DzANBgNVBAgMBk9yZWdvbjESMBAGA1UEBwwJQmVhdmVydG9uMSMwIQYDVQQKDBpQ
-eXRob24gU29mdHdhcmUgRm91bmRhdGlvbjEgMB4GA1UECwwXUHl0aG9uIENvcmUg
-RGV2ZWxvcG1lbnQxJDAiBgNVBAMMG251bGwucHl0aG9uLm9yZwBleGFtcGxlLm9y
-ZzEkMCIGCSqGSIb3DQEJARYVcHl0aG9uLWRldkBweXRob24ub3JnMB4XDTEzMDgw
-NzEzMTE1MloXDTEzMDgwNzEzMTI1MlowgcUxCzAJBgNVBAYTAlVTMQ8wDQYDVQQI
-DAZPcmVnb24xEjAQBgNVBAcMCUJlYXZlcnRvbjEjMCEGA1UECgwaUHl0aG9uIFNv
-ZnR3YXJlIEZvdW5kYXRpb24xIDAeBgNVBAsMF1B5dGhvbiBDb3JlIERldmVsb3Bt
-ZW50MSQwIgYDVQQDDBtudWxsLnB5dGhvbi5vcmcAZXhhbXBsZS5vcmcxJDAiBgkq
-hkiG9w0BCQEWFXB5dGhvbi1kZXZAcHl0aG9uLm9yZzCCASIwDQYJKoZIhvcNAQEB
-BQADggEPADCCAQoCggEBALXq7cn7Rn1vO3aA3TrzA5QLp6bb7B3f/yN0CJ2XFj+j
-pHs+Gw6WWSUDpybiiKnPec33BFawq3kyblnBMjBU61ioy5HwQqVkJ8vUVjGIUq3P
-vX/wBmQfzCe4o4uM89gpHyUL9UYGG8oCRa17dgqcv7u5rg0Wq2B1rgY+nHwx3JIv
-KRrgSwyRkGzpN8WQ1yrXlxWjgI9de0mPVDDUlywcWze1q2kwaEPTM3hLAmD1PESA
-oY/n8A/RXoeeRs9i/Pm/DGUS8ZPINXk/yOzsR/XvvkTVroIeLZqfmFpnZeF0cHzL
-08LODkVJJ9zjLdT7SA4vnne4FEbAxDbKAq5qkYzaL4UCAwEAAaOB0DCBzTAMBgNV
-HRMBAf8EAjAAMB0GA1UdDgQWBBSIWlXAUv9hzVKjNQ/qWpwkOCL3XDALBgNVHQ8E
-BAMCBeAwgZAGA1UdEQSBiDCBhYIeYWx0bnVsbC5weXRob24ub3JnAGV4YW1wbGUu
-Y29tgSBudWxsQHB5dGhvbi5vcmcAdXNlckBleGFtcGxlLm9yZ4YpaHR0cDovL251
-bGwucHl0aG9uLm9yZwBodHRwOi8vZXhhbXBsZS5vcmeHBMAAAgGHECABDbgAAAAA
-AAAAAAAAAAEwDQYJKoZIhvcNAQEFBQADggEBAKxPRe99SaghcI6IWT7UNkJw9aO9
-i9eo0Fj2MUqxpKbdb9noRDy2CnHWf7EIYZ1gznXPdwzSN4YCjV5d+Q9xtBaowT0j
-HPERs1ZuytCNNJTmhyqZ8q6uzMLoht4IqH/FBfpvgaeC5tBTnTT0rD5A/olXeimk
-kX4LxlEx5RAvpGB2zZVRGr6LobD9rVK91xuHYNIxxxfEGE8tCCWjp0+3ksri9SXx
-VHWBnbM9YaL32u3hxm8sYB/Yb8WSBavJCWJJqRStVRHM1koZlJmXNx2BX4vPo6iW
-RFEIPQsFZRLrtnCAiEhyT8bC2s/Njlu6ly9gtJZWSV46Q3ZjBL4q9sHKqZQ=
------END CERTIFICATE-----
diff --git a/Lib/test/nullcert.pem b/Lib/test/nullcert.pem
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/Lib/test/pycacert.pem b/Lib/test/pycacert.pem
diff --git a/Lib/test/pycacert.pem b/Lib/test/pycacert.pem
deleted file mode 100644
index 360cd57426..0000000000
--- a/Lib/test/pycacert.pem
+++ /dev/null
@@ -1,99 +0,0 @@
-Certificate:
-    Data:
-        Version: 3 (0x2)
-        Serial Number:
-            cb:2d:80:99:5a:69:52:5b
-        Signature Algorithm: sha256WithRSAEncryption
-        Issuer: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Validity
-            Not Before: Aug 29 14:23:16 2018 GMT
-            Not After : Oct 28 14:23:16 2037 GMT
-        Subject: C=XY, O=Python Software Foundation CA, CN=our-ca-server
-        Subject Public Key Info:
-            Public Key Algorithm: rsaEncryption
-                RSA Public-Key: (3072 bit)
-                Modulus:
-                    00:b1:84:d3:4f:5c:04:80:91:4f:82:49:ba:30:0b:
-                    f7:e8:cb:f9:14:ef:3d:9f:0b:3f:0a:62:fc:1b:20:
-                    a5:20:d1:60:5f:87:5a:1f:16:d1:ed:97:70:a6:da:
-                    1b:03:2c:7e:a0:5b:3c:4e:2f:16:7e:0e:89:29:89:
-                    e1:10:0d:38:da:6a:77:5f:37:13:b3:28:8f:7b:5c:
-                    76:ad:9e:e8:d3:f5:9e:f5:83:aa:10:07:8d:e6:51:
-                    98:f0:7c:0d:52:f2:0c:21:1e:d8:b9:99:26:a9:25:
-                    03:27:bb:5c:ab:2e:33:27:a2:d6:23:a8:83:87:44:
-                    29:9f:97:b5:24:6f:d7:b9:0a:fd:28:ee:bb:fb:41:
-                    58:ea:1d:99:dd:44:86:ab:98:be:1c:dc:cb:a9:89:
-                    1d:36:5c:a9:e8:47:b5:f4:52:48:aa:b5:a4:67:ef:
-                    3e:d7:e2:d3:33:de:98:29:d8:7a:b0:59:5c:e7:b1:
-                    0e:cc:fd:9f:eb:f6:d5:3a:0e:0b:cf:fe:0b:3d:a2:
-                    bf:45:18:ce:94:e7:a9:55:60:88:d4:d8:84:50:79:
-                    05:2e:41:03:74:ae:67:26:f6:5b:12:08:98:ce:0a:
-                    97:ed:01:0f:89:4f:17:5c:fa:3e:1d:35:24:47:92:
-                    32:bf:f7:a4:18:2b:3c:d0:48:99:e1:a2:cd:a3:cc:
-                    50:53:20:b5:c6:e3:66:85:7b:57:10:ec:33:4f:c1:
-                    77:e7:1b:7e:81:c6:c4:f3:45:20:c0:91:dd:13:76:
-                    7b:03:af:f6:76:8e:a2:83:63:57:dd:63:bc:bb:5a:
-                    1c:17:52:8a:d6:06:48:cc:0f:c7:d3:4f:e8:da:22:
-                    6c:86:f9:4e:5c:a6:29:07:3b:d8:56:4c:59:b3:20:
-                    49:07:7b:94:84:cf:2b:c3:1c:1a:4e:87:64:92:ba:
-                    42:e1:e6:ad:7d:1d:f6:54:90:6f:2b:e9:b3:cc:4b:
-                    2b:33:26:23:fd:65:c0:3c:f0:79:ad:c9:c1:81:ef:
-                    37:04:e0:27:3e:b0:ee:15:be:51
-                Exponent: 65537 (0x10001)
-        X509v3 extensions:
-            X509v3 Subject Key Identifier: 
-                B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-            X509v3 Authority Key Identifier: 
-                keyid:B3:8A:A0:A2:BA:71:F1:A8:24:79:D4:A4:5B:25:36:15:1E:49:C8:CD
-
-            X509v3 Basic Constraints: 
-                CA:TRUE
-    Signature Algorithm: sha256WithRSAEncryption
-         6b:32:2f:e7:05:18:ea:5c:c9:95:f4:e0:c2:0c:41:5f:1a:0a:
-         95:c9:c7:7d:05:ee:8a:56:29:35:50:40:b7:fe:9f:7b:5b:1c:
-         c3:69:2f:a0:cb:d2:b8:91:2f:50:19:62:f7:27:18:6d:95:7b:
-         53:16:15:a2:5a:dc:14:e3:fb:b1:32:a9:69:db:a6:33:47:3c:
-         bb:1f:d2:dc:70:f9:6a:2e:0c:d8:8c:6d:e5:5d:1d:43:3c:4e:
-         91:de:a0:c8:da:a0:4b:0e:9d:5e:b6:0f:4a:49:f0:7b:b6:53:
-         9e:fd:35:14:5b:e3:4d:b4:18:a6:36:61:e8:8f:33:9b:d4:05:
-         f9:54:66:df:e0:cb:18:a3:4e:dc:17:a8:a0:b3:c1:a8:f4:d6:
-         9d:ca:7f:68:53:1a:d7:95:da:e8:d3:9e:48:00:71:95:99:11:
-         07:cf:96:c0:7d:ce:7d:30:e8:4f:e1:83:16:33:a1:ff:59:9b:
-         3e:4c:e7:3a:38:01:9f:0f:67:4c:fd:2d:8b:4a:d4:01:46:37:
-         33:e8:13:6b:15:a9:1d:68:76:45:a2:82:33:69:26:30:60:05:
-         c8:8f:bd:b4:75:ab:be:7a:8b:48:68:70:40:b4:1b:51:c5:e6:
-         7a:ad:6b:4f:db:17:c0:60:67:2e:63:61:9b:2c:48:99:b8:76:
-         45:a0:9e:cc:ef:33:1e:50:4e:ab:72:c3:65:c8:b2:79:b3:35:
-         83:21:78:d3:8b:6c:3a:18:e8:65:32:39:b8:c0:9d:71:2f:35:
-         36:8a:c0:17:62:d8:8b:3e:e1:22:18:2b:4c:63:a6:0e:9d:0a:
-         fa:ab:5b:35:fb:88:91:77:4c:8d:8c:9d:a9:cf:fc:ab:c2:e6:
-         5a:05:7b:7e:04:6e:39:cf:93:ce:67:3b:7a:cb:af:b6:36:e1:
-         fb:71:64:45:d4:a6:f0:ce:ef:75:04:99:69:9a:e5:88:0a:10:
-         02:74:89:ec:75:84:44:80:48:df:c1:f7:e9:37:ce:ce:92:92:
-         5c:89:22:08:73:1f
------BEGIN CERTIFICATE-----
-MIIEbTCCAtWgAwIBAgIJAMstgJlaaVJbMA0GCSqGSIb3DQEBCwUAME0xCzAJBgNV
-BAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUgRm91bmRhdGlvbiBDQTEW
-MBQGA1UEAwwNb3VyLWNhLXNlcnZlcjAeFw0xODA4MjkxNDIzMTZaFw0zNzEwMjgx
-NDIzMTZaME0xCzAJBgNVBAYTAlhZMSYwJAYDVQQKDB1QeXRob24gU29mdHdhcmUg
-Rm91bmRhdGlvbiBDQTEWMBQGA1UEAwwNb3VyLWNhLXNlcnZlcjCCAaIwDQYJKoZI
-hvcNAQEBBQADggGPADCCAYoCggGBALGE009cBICRT4JJujAL9+jL+RTvPZ8LPwpi
-/BsgpSDRYF+HWh8W0e2XcKbaGwMsfqBbPE4vFn4OiSmJ4RANONpqd183E7Moj3tc
-dq2e6NP1nvWDqhAHjeZRmPB8DVLyDCEe2LmZJqklAye7XKsuMyei1iOog4dEKZ+X
-tSRv17kK/Sjuu/tBWOodmd1EhquYvhzcy6mJHTZcqehHtfRSSKq1pGfvPtfi0zPe
-mCnYerBZXOexDsz9n+v21ToOC8/+Cz2iv0UYzpTnqVVgiNTYhFB5BS5BA3SuZyb2
-WxIImM4Kl+0BD4lPF1z6Ph01JEeSMr/3pBgrPNBImeGizaPMUFMgtcbjZoV7VxDs
-M0/Bd+cbfoHGxPNFIMCR3RN2ewOv9naOooNjV91jvLtaHBdSitYGSMwPx9NP6Noi
-bIb5TlymKQc72FZMWbMgSQd7lITPK8McGk6HZJK6QuHmrX0d9lSQbyvps8xLKzMm
-I/1lwDzwea3JwYHvNwTgJz6w7hW+UQIDAQABo1AwTjAdBgNVHQ4EFgQUs4qgorpx
-8agkedSkWyU2FR5JyM0wHwYDVR0jBBgwFoAUs4qgorpx8agkedSkWyU2FR5JyM0w
-DAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAYEAazIv5wUY6lzJlfTgwgxB
-XxoKlcnHfQXuilYpNVBAt/6fe1scw2kvoMvSuJEvUBli9ycYbZV7UxYVolrcFOP7
-sTKpadumM0c8ux/S3HD5ai4M2Ixt5V0dQzxOkd6gyNqgSw6dXrYPSknwe7ZTnv01
-FFvjTbQYpjZh6I8zm9QF+VRm3+DLGKNO3BeooLPBqPTWncp/aFMa15Xa6NOeSABx
-lZkRB8+WwH3OfTDoT+GDFjOh/1mbPkznOjgBnw9nTP0ti0rUAUY3M+gTaxWpHWh2
-RaKCM2kmMGAFyI+9tHWrvnqLSGhwQLQbUcXmeq1rT9sXwGBnLmNhmyxImbh2RaCe
-zO8zHlBOq3LDZciyebM1gyF404tsOhjoZTI5uMCdcS81NorAF2LYiz7hIhgrTGOm
-Dp0K+qtbNfuIkXdMjYydqc/8q8LmWgV7fgRuOc+Tzmc7esuvtjbh+3FkRdSm8M7v
-dQSZaZrliAoQAnSJ7HWERIBI38H36TfOzpKSXIkiCHMf
------END CERTIFICATE-----
diff --git a/Lib/test/pycakey.pem b/Lib/test/pycakey.pem
deleted file mode 100644
index 819bdef1ff..0000000000
--- a/Lib/test/pycakey.pem
+++ /dev/null
@@ -1,40 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/gIBADANBgkqhkiG9w0BAQEFAASCBugwggbkAgEAAoIBgQCxhNNPXASAkU+C
-SbowC/foy/kU7z2fCz8KYvwbIKUg0WBfh1ofFtHtl3Cm2hsDLH6gWzxOLxZ+Dokp
-ieEQDTjaandfNxOzKI97XHatnujT9Z71g6oQB43mUZjwfA1S8gwhHti5mSapJQMn
-u1yrLjMnotYjqIOHRCmfl7Ukb9e5Cv0o7rv7QVjqHZndRIarmL4c3MupiR02XKno
-R7X0UkiqtaRn7z7X4tMz3pgp2HqwWVznsQ7M/Z/r9tU6DgvP/gs9or9FGM6U56lV
-YIjU2IRQeQUuQQN0rmcm9lsSCJjOCpftAQ+JTxdc+j4dNSRHkjK/96QYKzzQSJnh
-os2jzFBTILXG42aFe1cQ7DNPwXfnG36BxsTzRSDAkd0TdnsDr/Z2jqKDY1fdY7y7
-WhwXUorWBkjMD8fTT+jaImyG+U5cpikHO9hWTFmzIEkHe5SEzyvDHBpOh2SSukLh
-5q19HfZUkG8r6bPMSyszJiP9ZcA88HmtycGB7zcE4Cc+sO4VvlECAwEAAQKCAYB7
-gUnzALYxLOgAYYMkQm9si9zz768TpCNr+ooj5YZ9Wq6OSAEveBT+FErQCxaYErDW
-qCNA0gn4Eezj9YWcQVa4vzHmEM+n6iRJU39ONC0Qqua5Ma10EY1sHIEnb2dlufku
-YeOu3RrEu3eCgRxsDGySuvv5OxinV4kN++KPQzD3EOopPE+U81YFLCsMgsyfPlmm
-gwc/IKIuXDHp5Vp2bXkZK98CYLV8RddjUw7SrkZNwx6cI9eET0CgTs7y4SrevoOy
-jCdnA0j1HvL8AbLQuYoXo9fdGYDeq55hyYlxSMYLaEToZG3DJ0UAldrT+r7x52D8
-2QMnJUo2XHzVYPlXPJIAkFJisZZ36TkBvywCgXZMMLibPo9U6V0nfkybTtXKoory
-nmgBv+XSGSNrVWMiygpDPqpX1G6bBgqUX3CiTlxtSkYYz1M4Vgj2cux5XEPTnVCq
-CLVzvNIXZt1RyzXPxGWpPidCjOaiWBRT4u1Dol9fs3PmVvDaRxcKo9nspiUHCfEC
-gcEA4GgxZ+IJwpAMHkdYId0oxjKgTqIg+Ua+EwfUoQT10ERl/k/V4cDwJRHT8lML
-rKhTNQJMEE040jq+6mPJDl1KqMb/v05Q7fF22ToGw1HkZwK52O6CeEiJW4/J6bR1
-pZGN0irsa6GvzV65Y6gZVFEUl0JPRf8wPvQHXsWAw8/2LuXkXjV0ieIMq4pbWJf4
-kaid7dYLHnobiP9RVk7BGr7ifmCshoPjWp4TRMwYf6iIZrqMxUSX0QY8Xsqx6bch
-LLx/AoHBAMqCvvwUKTrF4gKh5jyl6T6DTZ/Dujaz7BuAJdsSSHvuTa/Y1EfsQHZN
-jABn89ZqHYDiyyCuVFO3dqhLtsPjhyFMSXj+98JYcL3FGKnqQqRTwtzzx2P2lV5X
-U0WhrNRb3iLu79Tr8pE/2EPnvTr+J5b0DHEeRyM72LWs43zrDYHorH0/Aa5Qd37F
-gDLCTBEl8jO5irRuAIq/KV9ZFnn8JDjNGVpXgHPW3354ON1YaMLnPASk7FQizSOQ
-QZAsyxtdLwKBwGUosvTYYXvygXP4x1LkpmfKFJe94E1exXpAsmovmTvcSXn9tTXC
-Sr77LWb0ZrPbYT7pHS7QEMg8MSnp941hIrG4mzs666KHkgLUdI4B0YtaIDsZMXlV
-gY3j4KpYbhxH4/2U2eSfC2fxxnKVKW3n6vdQrfmo0q/eQ6BGOgiLK7fybCLHyBQL
-8Zg2k3z5bNUEhMTdE0AW3WjBZ4IXmFcdK26616r/szJ7RcZilrydVXexqpmWlTVl
-sTst9kucAPlwswKBwQCwf7my/GNezR8Jik+fZj7edBQQfcdra+8JnOvhfpLcKLte
-2s1RjjA0q6usou1bYAsszP2bEzV97XWmgq7dFg4tUE7s/NO1d91zGDhBx2Gj1TkN
-2A5dKonOuq9iDeITB6qYqcUvvyEfxRRZQr2jj+WzZCr/4BLCO6PJ29A9jKOuKLtF
-QcfWRF2RiNMN6lffzkHFIR4p2YHxa2DEsGGtmbt8Ig3Jtl/HFmydzmxJRoev71dY
-+ODdB6PhLhZmcRPoWpMCgcEAhGArwL68GwwRMqAX79gMv8tVT0CJnDyGk5mD/ZIB
-Nzt0yQFO7rTEa1l1vAtOiVJ9IpAak2lgbEwodOfGnQst7lujNYDFzTRPTFt/lID1
-u6JBxmqawOSlqa00bt4l2YsTZV+BfSznBP6XO1PK4iR3o5G3NkoKJjZWm3e3asHk
-6eTeMLcsIJ+Fp7gG0ve2EdQwhVSVMFEu4Q4C2FcJeU++L4kYpY7sTnAjUtiLvtHn
-yp3jllEn3CBD8Uhs4B+sL/6p
------END PRIVATE KEY-----
diff --git a/Lib/test/pythoninfo.py b/Lib/test/pythoninfo.py
index 8d7fb9f4f2..4f3ebb12ed 100644
--- a/Lib/test/pythoninfo.py
+++ b/Lib/test/pythoninfo.py
@@ -1,18 +1,13 @@
 """
 Collect various information about Python to help debugging test failures.
 """
-from __future__ import print_function
 import errno
 import re
 import sys
 import traceback
-import unittest
 import warnings
 
 
-MS_WINDOWS = (sys.platform == 'win32')
-
-
 def normalize_text(text):
     if text is None:
         return None
@@ -244,6 +239,7 @@ def format_attr(attr, value):
         'getresgid',
         'getresuid',
         'getuid',
+        'process_cpu_count',
         'uname',
     ):
         call_func(info_add, 'os.%s' % func, os, func)
@@ -273,6 +269,7 @@ def format_groups(groups):
         "ARCHFLAGS",
         "ARFLAGS",
         "AUDIODEV",
+        "BUILDPYTHON",
         "CC",
         "CFLAGS",
         "COLUMNS",
@@ -317,7 +314,6 @@ def format_groups(groups):
         "TEMP",
         "TERM",
         "TILE_LIBRARY",
-        "TIX_LIBRARY",
         "TMP",
         "TMPDIR",
         "TRAVIS",
@@ -326,15 +322,24 @@ def format_groups(groups):
         "VIRTUAL_ENV",
         "WAYLAND_DISPLAY",
         "WINDIR",
+        "_PYTHON_HOSTRUNNER",
         "_PYTHON_HOST_PLATFORM",
         "_PYTHON_PROJECT_BASE",
         "_PYTHON_SYSCONFIGDATA_NAME",
         "__PYVENV_LAUNCHER__",
+
+        # Sanitizer options
+        "ASAN_OPTIONS",
+        "LSAN_OPTIONS",
+        "MSAN_OPTIONS",
+        "TSAN_OPTIONS",
+        "UBSAN_OPTIONS",
     ))
     for name, value in os.environ.items():
         uname = name.upper()
         if (uname in ENV_VARS
-           # Copy PYTHON* and LC_* variables
+           # Copy PYTHON* variables like PYTHONPATH
+           # Copy LC_* variables like LC_ALL
            or uname.startswith(("PYTHON", "LC_"))
            # Visual Studio: VS140COMNTOOLS
            or (uname.startswith("VS") and uname.endswith("COMNTOOLS"))):
@@ -487,13 +492,10 @@ def collect_datetime(info_add):
 
 
 def collect_sysconfig(info_add):
-    # On Windows, sysconfig is not reliable to get macros used
-    # to build Python
-    if MS_WINDOWS:
-        return
-
     import sysconfig
 
+    info_add('sysconfig.is_python_build', sysconfig.is_python_build())
+
     for name in (
         'ABIFLAGS',
         'ANDROID_API_LEVEL',
@@ -502,6 +504,7 @@ def collect_sysconfig(info_add):
         'CFLAGS',
         'CFLAGSFORSHARED',
         'CONFIG_ARGS',
+        'HOSTRUNNER',
         'HOST_GNU_TYPE',
         'MACHDEP',
         'MULTIARCH',
@@ -514,9 +517,13 @@ def collect_sysconfig(info_add):
         'PY_STDMODULE_CFLAGS',
         'Py_DEBUG',
         'Py_ENABLE_SHARED',
+        'Py_NOGIL',
         'SHELL',
         'SOABI',
+        'abs_builddir',
+        'abs_srcdir',
         'prefix',
+        'srcdir',
     ):
         value = sysconfig.get_config_var(name)
         if name == 'ANDROID_API_LEVEL' and not value:
@@ -663,7 +670,29 @@ def collect_testcapi(info_add):
     except ImportError:
         return
 
-    call_func(info_add, 'pymem.allocator', _testcapi, 'pymem_getallocatorsname')
+    for name in (
+        'LONG_MAX',         # always 32-bit on Windows, 64-bit on 64-bit Unix
+        'PY_SSIZE_T_MAX',
+        'Py_C_RECURSION_LIMIT',
+        'SIZEOF_TIME_T',    # 32-bit or 64-bit depending on the platform
+        'SIZEOF_WCHAR_T',   # 16-bit or 32-bit depending on the platform
+    ):
+        copy_attr(info_add, f'_testcapi.{name}', _testcapi, name)
+
+
+def collect_testinternalcapi(info_add):
+    try:
+        import _testinternalcapi
+    except ImportError:
+        return
+
+    call_func(info_add, 'pymem.allocator', _testinternalcapi, 'pymem_getallocatorsname')
+
+    for name in (
+        'SIZEOF_PYGC_HEAD',
+        'SIZEOF_PYOBJECT',
+    ):
+        copy_attr(info_add, f'_testinternalcapi.{name}', _testinternalcapi, name)
 
 
 def collect_resource(info_add):
@@ -682,6 +711,7 @@ def collect_resource(info_add):
 
 
 def collect_test_socket(info_add):
+    import unittest
     try:
         from test import test_socket
     except (ImportError, unittest.SkipTest):
@@ -693,26 +723,83 @@ def collect_test_socket(info_add):
     copy_attributes(info_add, test_socket, 'test_socket.%s', attributes)
 
 
-def collect_test_support(info_add):
+def collect_support(info_add):
     try:
         from test import support
     except ImportError:
         return
 
-    attributes = ('IPV6_ENABLED',)
-    copy_attributes(info_add, support, 'test_support.%s', attributes)
+    attributes = (
+        'MS_WINDOWS',
+        'has_fork_support',
+        'has_socket_support',
+        'has_strftime_extensions',
+        'has_subprocess_support',
+        'is_android',
+        'is_emscripten',
+        'is_jython',
+        'is_wasi',
+    )
+    copy_attributes(info_add, support, 'support.%s', attributes)
 
-    call_func(info_add, 'test_support._is_gui_available', support, '_is_gui_available')
-    call_func(info_add, 'test_support.python_is_optimized', support, 'python_is_optimized')
+    call_func(info_add, 'support._is_gui_available', support, '_is_gui_available')
+    call_func(info_add, 'support.python_is_optimized', support, 'python_is_optimized')
 
-    info_add('test_support.check_sanitizer(address=True)',
+    info_add('support.check_sanitizer(address=True)',
              support.check_sanitizer(address=True))
-    info_add('test_support.check_sanitizer(memory=True)',
+    info_add('support.check_sanitizer(memory=True)',
              support.check_sanitizer(memory=True))
-    info_add('test_support.check_sanitizer(ub=True)',
+    info_add('support.check_sanitizer(ub=True)',
              support.check_sanitizer(ub=True))
 
 
+def collect_support_os_helper(info_add):
+    try:
+        from test.support import os_helper
+    except ImportError:
+        return
+
+    for name in (
+        'can_symlink',
+        'can_xattr',
+        'can_chmod',
+        'can_dac_override',
+    ):
+        func = getattr(os_helper, name)
+        info_add(f'support_os_helper.{name}', func())
+
+
+def collect_support_socket_helper(info_add):
+    try:
+        from test.support import socket_helper
+    except ImportError:
+        return
+
+    attributes = (
+        'IPV6_ENABLED',
+        'has_gethostname',
+    )
+    copy_attributes(info_add, socket_helper, 'support_socket_helper.%s', attributes)
+
+    for name in (
+        'tcp_blackhole',
+    ):
+        func = getattr(socket_helper, name)
+        info_add(f'support_socket_helper.{name}', func())
+
+
+def collect_support_threading_helper(info_add):
+    try:
+        from test.support import threading_helper
+    except ImportError:
+        return
+
+    attributes = (
+        'can_start_thread',
+    )
+    copy_attributes(info_add, threading_helper, 'support_threading_helper.%s', attributes)
+
+
 def collect_cc(info_add):
     import subprocess
     import sysconfig
@@ -867,6 +954,21 @@ def collect_fips(info_add):
         pass
 
 
+def collect_tempfile(info_add):
+    import tempfile
+
+    info_add('tempfile.gettempdir', tempfile.gettempdir())
+
+
+def collect_libregrtest_utils(info_add):
+    try:
+        from test.libregrtest import utils
+    except ImportError:
+        return
+
+    info_add('libregrtests.build_info', ' '.join(utils.get_build_info()))
+
+
 def collect_info(info):
     error = False
     info_add = info.add
@@ -900,14 +1002,20 @@ def collect_info(info):
         collect_sys,
         collect_sysconfig,
         collect_testcapi,
+        collect_testinternalcapi,
+        collect_tempfile,
         collect_time,
         collect_tkinter,
         collect_windows,
         collect_zlib,
+        collect_libregrtest_utils,
 
         # Collecting from tests should be last as they have side effects.
         collect_test_socket,
-        collect_test_support,
+        collect_support,
+        collect_support_os_helper,
+        collect_support_socket_helper,
+        collect_support_threading_helper,
     ):
         try:
             collect_func(info_add)
diff --git a/Lib/test/regrtest.py b/Lib/test/regrtest.py
index 0ffb3ed454..46a74fe276 100755
--- a/Lib/test/regrtest.py
+++ b/Lib/test/regrtest.py
@@ -8,7 +8,7 @@
 
 import os
 import sys
-from test.libregrtest import main
+from test.libregrtest.main import main
 
 
 # Alias for backward compatibility (just in case)
diff --git a/Lib/test/revocation.crl b/Lib/test/revocation.crl
deleted file mode 100644
index 621675eb5c..0000000000
--- a/Lib/test/revocation.crl
+++ /dev/null
@@ -1,14 +0,0 @@
------BEGIN X509 CRL-----
-MIICJjCBjwIBATANBgkqhkiG9w0BAQsFADBNMQswCQYDVQQGEwJYWTEmMCQGA1UE
-CgwdUHl0aG9uIFNvZnR3YXJlIEZvdW5kYXRpb24gQ0ExFjAUBgNVBAMMDW91ci1j
-YS1zZXJ2ZXIXDTIxMDMxNzA4NDgyMFoXDTQwMDUxNjA4NDgyMFqgDjAMMAoGA1Ud
-FAQDAgEAMA0GCSqGSIb3DQEBCwUAA4IBgQCd2GrHb4zr2R8eK7YMHwlkgICxbWP1
-4nuEi55yzUcmMcCZJ6ZQV3yYqTlAULGQ9qWAUdhsyH+yu3hRKFKHQv0DAdKKxgow
-66YasAQQ99DskXOPxmRoIA7qtIWZbLtBwHQJWh+uUFlTdUXitGIX5Xie74xu5YIr
-moa3QeuZyG5+gigSTUyst5T/J/cHfBzlAJLc2k3Ty4EPYXKHCVnrZWJbRmxq199l
-A7S+eBb9qWXSYXCn6v+EZ76pUS3u/66kZ86PO3h9294BzdhxbCJ27dQXNHw6owe2
-Iyiv0aWx+TNSGSf4yCqaYTH6RtEoviI3h/inVFHNGgjlMzdaGw/0I3bkB0rt2WSR
-Vck37HnXvQvVEkgO/39C0WKZus6m4gmOgZcbJbXaR8uIR5Hmw3SEyGEPEIBu6tXV
-BLJOSOSu2vVUH5GUIrpvK9FTySKYa+MGryoPasuqZNfwpaXK+ON2G6QsmcXPWZY0
-Dry6t0w2geW6UYVGmb831i8ZP3JVVVwcwi0=
------END X509 CRL-----
diff --git a/Lib/test/secp384r1.pem b/Lib/test/secp384r1.pem
deleted file mode 100644
index eef7117af7..0000000000
--- a/Lib/test/secp384r1.pem
+++ /dev/null
@@ -1,7 +0,0 @@
-$ openssl genpkey -genparam -algorithm EC -pkeyopt ec_paramgen_curve:secp384r1 -pkeyopt ec_param_enc:named_curve -text
------BEGIN EC PARAMETERS-----
-BgUrgQQAIg==
------END EC PARAMETERS-----
-ECDSA-Parameters: (384 bit)
-ASN1 OID: secp384r1
-NIST CURVE: P-384
diff --git a/Lib/test/selfsigned_pythontestdotnet.pem b/Lib/test/selfsigned_pythontestdotnet.pem
deleted file mode 100644
index 2b1760747b..0000000000
--- a/Lib/test/selfsigned_pythontestdotnet.pem
+++ /dev/null
@@ -1,34 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIF9zCCA9+gAwIBAgIUH98b4Fw/DyugC9cV7VK7ZODzHsIwDQYJKoZIhvcNAQEL
-BQAwgYoxCzAJBgNVBAYTAlhZMRcwFQYDVQQIDA5DYXN0bGUgQW50aHJheDEYMBYG
-A1UEBwwPQXJndW1lbnQgQ2xpbmljMSMwIQYDVQQKDBpQeXRob24gU29mdHdhcmUg
-Rm91bmRhdGlvbjEjMCEGA1UEAwwac2VsZi1zaWduZWQucHl0aG9udGVzdC5uZXQw
-HhcNMTkwNTA4MDEwMjQzWhcNMjcwNzI0MDEwMjQzWjCBijELMAkGA1UEBhMCWFkx
-FzAVBgNVBAgMDkNhc3RsZSBBbnRocmF4MRgwFgYDVQQHDA9Bcmd1bWVudCBDbGlu
-aWMxIzAhBgNVBAoMGlB5dGhvbiBTb2Z0d2FyZSBGb3VuZGF0aW9uMSMwIQYDVQQD
-DBpzZWxmLXNpZ25lZC5weXRob250ZXN0Lm5ldDCCAiIwDQYJKoZIhvcNAQEBBQAD
-ggIPADCCAgoCggIBAMKdJlyCThkahwoBb7pl5q64Pe9Fn5jrIvzsveHTc97TpjV2
-RLfICnXKrltPk/ohkVl6K5SUZQZwMVzFubkyxE0nZPHYHlpiKWQxbsYVkYv01rix
-IFdLvaxxbGYke2jwQao31s4o61AdlsfK1SdpHQUynBBMssqI3SB4XPmcA7e+wEEx
-jxjVish4ixA1vuIZOx8yibu+CFCf/geEjoBMF3QPdzULzlrCSw8k/45iZCSoNbvK
-DoL4TVV07PHOxpheDh8ZQmepGvU6pVqhb9m4lgmV0OGWHgozd5Ur9CbTVDmxIEz3
-TSoRtNJK7qtyZdGNqwjksQxgZTjM/d/Lm/BJG99AiOmYOjsl9gbQMZgvQmMAtUsI
-aMJnQuZ6R+KEpW/TR5qSKLWZSG45z/op+tzI2m+cE6HwTRVAWbcuJxcAA55MZjqU
-OOOu3BBYMjS5nf2sQ9uoXsVBFH7i0mQqoW1SLzr9opI8KsWwFxQmO2vBxWYaN+lH
-OmwBZBwyODIsmI1YGXmTp09NxRYz3Qe5GCgFzYowpMrcxUC24iduIdMwwhRM7rKg
-7GtIWMSrFfuI1XCLRmSlhDbhNN6fVg2f8Bo9PdH9ihiIyxSrc+FOUasUYCCJvlSZ
-8hFUlLvcmrZlWuazohm0lsXuMK1JflmQr/DA/uXxP9xzFfRy+RU3jDyxJbRHAgMB
-AAGjUzBRMB0GA1UdDgQWBBSQJyxiPMRK01i+0BsV9zUwDiBaHzAfBgNVHSMEGDAW
-gBSQJyxiPMRK01i+0BsV9zUwDiBaHzAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3
-DQEBCwUAA4ICAQCR+7a7N/m+WLkxPPIA/CB4MOr2Uf8ixTv435Nyv6rXOun0+lTP
-ExSZ0uYQ+L0WylItI3cQHULldDueD+s8TGzxf5woaLKf6tqyr0NYhKs+UeNEzDnN
-9PHQIhX0SZw3XyXGUgPNBfRCg2ZDdtMMdOU4XlQN/IN/9hbYTrueyY7eXq9hmtI9
-1srftAMqr9SR1JP7aHI6DVgrEsZVMTDnfT8WmLSGLlY1HmGfdEn1Ip5sbo9uSkiH
-AEPgPfjYIvR5LqTOMn4KsrlZyBbFIDh9Sl99M1kZzgH6zUGVLCDg1y6Cms69fx/e
-W1HoIeVkY4b4TY7Bk7JsqyNhIuqu7ARaxkdaZWhYaA2YyknwANdFfNpfH+elCLIk
-BUt5S3f4i7DaUePTvKukCZiCq4Oyln7RcOn5If73wCeLB/ZM9Ei1HforyLWP1CN8
-XLfpHaoeoPSWIveI0XHUl65LsPN2UbMbul/F23hwl+h8+BLmyAS680Yhn4zEN6Ku
-B7Po90HoFa1Du3bmx4jsN73UkT/dwMTi6K072FbipnC1904oGlWmLwvAHvrtxxmL
-Pl3pvEaZIu8wa/PNF6Y7J7VIewikIJq6Ta6FrWeFfzMWOj2qA1ZZi6fUaDSNYvuV
-J5quYKCc/O+I/yDDf8wyBbZ/gvUXzUHTMYGG+bFrn1p7XDbYYeEJ6R/xEg==
------END CERTIFICATE-----
diff --git a/Lib/test/sgml_input.html b/Lib/test/sgml_input.html
deleted file mode 100644
index f4d2e6cc80..0000000000
--- a/Lib/test/sgml_input.html
+++ /dev/null
@@ -1,212 +0,0 @@
-<html>
- <head>
-  <meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
-  <link rel="stylesheet" type="text/css" href="http://ogame182.de/epicblue/formate.css">
-  <script language="JavaScript" src="js/flotten.js"></script>
- </head>
- <body>
-    <script language=JavaScript> if (parent.frames.length == 0) { top.location.href = "http://es.ogame.org/"; } </script> <script language="JavaScript">
-function haha(z1) {
-  eval("location='"+z1.options[z1.selectedIndex].value+"'");
-}
-</script>
-<center>
-<table>
- <tr>
-  <td></td>
-  <td>
-   <center>
-   <table>
-    <tr>
-     <td><img src="http://ogame182.de/epicblue/planeten/small/s_dschjungelplanet04.jpg" width="50" height="50"></td>
-     <td>
-      <table border="1">
-       <select size="1" onchange="haha(this)">
-                                   <option value="/game/flotten1.php?session=8912ae912fec&cp=33875341&mode=Flotte&gid=&messageziel=&re=0" selected>Alien sex friend    [2:250:6]</option> 
-                                   <option value="/game/flotten1.php?session=8912ae912fec&cp=33905100&mode=Flotte&gid=&messageziel=&re=0" >1989    [2:248:14]</option> 
-                                   <option value="/game/flotten1.php?session=8912ae912fec&cp=34570808&mode=Flotte&gid=&messageziel=&re=0" >1990    [2:248:6]</option> 
-                                   <option value="/game/flotten1.php?session=8912ae912fec&cp=34570858&mode=Flotte&gid=&messageziel=&re=0" >1991    [2:254:6]</option> 
-                                   <option value="/game/flotten1.php?session=8912ae912fec&cp=34572929&mode=Flotte&gid=&messageziel=&re=0" >Colonia    [2:253:12]</option> 
-               </select>
-      </table>
-     </td>
-    </tr>
-  </table>
-  </center>
-  </td>
-  <td>
-   <table border="0" width="100%" cellspacing="0" cellpadding="0">
-    <tr>
-     <td align="center"></td>
-     <td align="center" width="85">
-      <img border="0" src="http://ogame182.de/epicblue/images/metall.gif" width="42" height="22">
-     </td>
-     <td align="center" width="85">
-      <img border="0" src="http://ogame182.de/epicblue/images/kristall.gif" width="42" height="22">
-     </td>
-     <td align="center" width="85">
-      <img border="0" src="http://ogame182.de/epicblue/images/deuterium.gif" width="42" height="22">
-     </td>
-     <td align="center" width="85">
-      <img border="0" src="http://ogame182.de/epicblue/images/energie.gif" width="42" height="22">
-     </td>
-     <td align="center"></td>
-    </tr>
-    <tr>
-     <td align="center"><i><b>&nbsp;&nbsp;</b></i></td>
-     <td align="center" width="85"><i><b><font color="#ffffff">Metal</font></b></i></td>
-     <td align="center" width="85"><i><b><font color="#ffffff">Cristal</font></b></i></td>
-     <td align="center" width="85"><i><b><font color="#ffffff">Deuterio</font></b></i></td>
-     <td align="center" width="85"><i><b><font color="#ffffff">Energa</font></b></i></td>
-     <td align="center"><i><b>&nbsp;&nbsp;</b></i></td>
-    </tr>
-    <tr>
-     <td align="center"></td>
-     <td align="center" width="85">160.636</td>
-     <td align="center" width="85">3.406</td>
-     <td align="center" width="85">39.230</td>
-     <td align="center" width="85"><font color=#ff0000>-80</font>/3.965</td>
-     <td align="center"></td>
-    </tr>
-   </table>
-  </tr>
- </table>
-  </center>
-<br />
-  <script language="JavaScript">
-  <!--
-     function link_to_gamepay() {
-    self.location = "https://www.gamepay.de/?lang=es&serverID=8&userID=129360&gameID=ogame&gui=v2&chksum=a9751afa9e37e6b1b826356bcca45675";
-  }
-//-->
-  </script>
-<center>
-  <table width="519" border="0" cellpadding="0" cellspacing="1">
-   <tr height="20">
-  <td colspan="8" class="c">Flotas (max. 9)</td>
-   </tr>
-     <tr height="20">
-    <th>Num.</th>
-    <th>Misin</th>
-    <th>Cantidad</th>
-    <th>Comienzo</th>
-    <th>Salida</th>
-    <th>Objetivo</th>
-    <th>Llegada</th>
-    <th>Orden</th>   
-   </tr>
-     <tr height="20">
-    <th>1</th>
-    <th>  
-      <a title="">Espionaje</a>
-      <a title="Flota en el planeta">(F)</a>
-    </th>
-    <th> <a title="Sonda de espionaje: 3 
-">3</a></th>
-    <th>[2:250:6]</th>
-    <th>Wed Aug 9 18:00:02</th>
-    <th>[2:242:5]</th>
-    <th>Wed Aug 9 18:01:02</th>
-    <th>
-         <form action="flotten1.php?session=8912ae912fec" method="POST">
-	<input type="hidden" name="order_return" value="25054490" />
-        <input type="submit" value="Enviar de regreso" />
-     </form>
-            </th>
-   </tr>
-   <tr height="20">
-    <th>2</th>
-    <th>  
-      <a title="">Espionaje</a>
-      <a title="Volver al planeta">(V)</a>
-    </th>
-    <th> <a title="Sonda de espionaje: 3 
-">3</a></th>
-    <th>[2:250:6]</th>
-    <th>Wed Aug 9 17:59:55</th>
-    <th>[2:242:1]</th>
-    <th>Wed Aug 9 18:01:55</th>
-    <th>
-            </th>
-   </tr>
-  </table>
-
-
-  
-<form action="flotten2.php?session=8912ae912fec" method="POST">
-  <table width="519" border="0" cellpadding="0" cellspacing="1">
-       <tr height="20">
-  <td colspan="4" class="c">Nueva misin: elegir naves</td>
-   </tr>
-   <tr height="20">
-  <th>Naves</th>
-  <th>Disponibles</th>
-<!--    <th>Gesch.</th> -->
-    <th>-</th>
-    <th>-</th>
-   </tr>
-   <tr height="20">
-    <th><a title="Velocidad: 8500">Nave pequea de carga</a></th> 
-    <th>10<input type="hidden" name="maxship202" value="10"/></th>
-<!--    <th>8500 -->
-     <input type="hidden" name="consumption202" value="10"/>
-     <input type="hidden" name="speed202" value="8500" /></th>
-     <input type="hidden" name="capacity202" value="5000" /></th>
-     <th><a href="javascript:maxShip('ship202');" >mx</a> </th>
-     <th><input name="ship202" size="10" value="0" alt="Nave pequea de carga 10"/></th>
-   </tr>
-   <tr height="20">
-    <th><a title="Velocidad: 12750">Nave grande de carga</a></th> 
-    <th>19<input type="hidden" name="maxship203" value="19"/></th>
-<!--    <th>12750 -->
-     <input type="hidden" name="consumption203" value="50"/>
-     <input type="hidden" name="speed203" value="12750" /></th>
-     <input type="hidden" name="capacity203" value="25000" /></th>
-     <th><a href="javascript:maxShip('ship203');" >mx</a> </th>
-     <th><input name="ship203" size="10" value="0" alt="Nave grande de carga 19"/></th>
-   </tr>
-   <tr height="20">
-    <th><a title="Velocidad: 27000">Crucero</a></th> 
-    <th>6<input type="hidden" name="maxship206" value="6"/></th>
-<!--    <th>27000 -->
-     <input type="hidden" name="consumption206" value="300"/>
-     <input type="hidden" name="speed206" value="27000" /></th>
-     <input type="hidden" name="capacity206" value="800" /></th>
-     <th><a href="javascript:maxShip('ship206');" >mx</a> </th>
-     <th><input name="ship206" size="10" value="0" alt="Crucero 6"/></th>
-   </tr>
-   <tr height="20">
-    <th><a title="Velocidad: 3400">Reciclador</a></th> 
-    <th>1<input type="hidden" name="maxship209" value="1"/></th>
-<!--    <th>3400 -->
-     <input type="hidden" name="consumption209" value="300"/>
-     <input type="hidden" name="speed209" value="3400" /></th>
-     <input type="hidden" name="capacity209" value="20000" /></th>
-     <th><a href="javascript:maxShip('ship209');" >mx</a> </th>
-     <th><input name="ship209" size="10" value="0" alt="Reciclador 1"/></th>
-   </tr>
-   <tr height="20">
-    <th><a title="Velocidad: 170000000">Sonda de espionaje</a></th> 
-    <th>139<input type="hidden" name="maxship210" value="139"/></th>
-<!--    <th>170000000 -->
-     <input type="hidden" name="consumption210" value="1"/>
-     <input type="hidden" name="speed210" value="170000000" /></th>
-     <input type="hidden" name="capacity210" value="5" /></th>
-     <th><a href="javascript:maxShip('ship210');" >mx</a> </th>
-     <th><input name="ship210" size="10" value="0" alt="Sonda de espionaje 139"/></th>
-   </tr>
-   <tr height="20">
-  <th colspan="2"><a href="javascript:noShips();" >Ninguna nave</a></th>
-  <th colspan="2"><a href="javascript:maxShips();" >Todas las naves</a></th>
-   </tr>
-    <tr height="20">
-    <th colspan="4"><input type="submit" value="Continuar" /></th>
-   </tr>
-<tr><th colspan=4>
-<iframe id='a44fb522' name='a44fb522' src='http://ads.gameforgeads.de/adframe.php?n=a44fb522&amp;what=zone:578' framespacing='0' frameborder='no' scrolling='no' width='468' height='60'></iframe>
-<br><center></center></br>
-</th></tr>
-</form>
-</table>
- </body>
-</html>
diff --git a/Lib/test/signalinterproctester.py b/Lib/test/signalinterproctester.py
index cdcd92a8ba..073c078f45 100644
--- a/Lib/test/signalinterproctester.py
+++ b/Lib/test/signalinterproctester.py
@@ -1,3 +1,4 @@
+import gc
 import os
 import signal
 import subprocess
@@ -59,6 +60,13 @@ def test_interprocess_signal(self):
         self.assertEqual(self.got_signals, {'SIGHUP': 1, 'SIGUSR1': 0,
                                             'SIGALRM': 0})
 
+        # gh-110033: Make sure that the subprocess.Popen is deleted before
+        # the next test which raises an exception. Otherwise, the exception
+        # may be raised when Popen.__del__() is executed and so be logged
+        # as "Exception ignored in: <function Popen.__del__ at ...>".
+        child = None
+        gc.collect()
+
         with self.assertRaises(SIGUSR1Exception):
             with self.subprocess_send_signal(pid, "SIGUSR1") as child:
                 self.wait_signal(child, 'SIGUSR1')
diff --git a/Lib/test/ssl_cert.pem b/Lib/test/ssl_cert.pem
deleted file mode 100644
index de596717bd..0000000000
--- a/Lib/test/ssl_cert.pem
+++ /dev/null
@@ -1,26 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIEWTCCAsGgAwIBAgIJAJinz4jHSjLtMA0GCSqGSIb3DQEBCwUAMF8xCzAJBgNV
-BAYTAlhZMRcwFQYDVQQHDA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9u
-IFNvZnR3YXJlIEZvdW5kYXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODA4
-MjkxNDIzMTVaFw0yODA4MjYxNDIzMTVaMF8xCzAJBgNVBAYTAlhZMRcwFQYDVQQH
-DA5DYXN0bGUgQW50aHJheDEjMCEGA1UECgwaUHl0aG9uIFNvZnR3YXJlIEZvdW5k
-YXRpb24xEjAQBgNVBAMMCWxvY2FsaG9zdDCCAaIwDQYJKoZIhvcNAQEBBQADggGP
-ADCCAYoCggGBALKUqUtopT6E68kN+uJNEt34i2EbmG/bwjcD8IaMsgJPSsMO2Bpd
-3S6qWgkCeOyCfmAwBxK2kNbxGb63ouysEv7l8GCTJTWv3hG/HQcejJpnAEGi6K1U
-fDbyE/db6yZ12SoHVTGkadN4vYGCPd1Wj9ZO1F877SHQ8rDWX3xgTWkxN2ojBw44
-T8RHSDiG8D/CvG4uEy+VUszL+Uvny5y2poNSqvI3J56sptWSrh8nIIbkPZPBdUne
-LYMOHTFK3ZjXSmhlXgziTxK71nnzM3Y9K9gxPnRqoXbvu/wFo55hQCkETiRkYgmm
-jXcBMZ0TClQVnQWuLjMthRnWFZs4Lfmwqjs7FZD/61581R2BYehvpWbLvvuOJhwv
-DFzexL2sXcAl7SsxbzeQKRHqGbIDfbnQTXfs3/VC6Ye5P82P2ucj+XC32N9piRmO
-gCBP8L3ub+YzzdxikZN2gZXXE2jsb3QyE/R2LkWdWyshpKe+RsZP1SBRbHShUyOh
-yJ90baoiEwj2mwIDAQABoxgwFjAUBgNVHREEDTALgglsb2NhbGhvc3QwDQYJKoZI
-hvcNAQELBQADggGBAHRUO/UIHl3jXQENewYayHxkIx8t7nu40iO2DXbicSijz5bo
-5//xAB6RxhBAlsDBehgQP1uoZg+WJW+nHu3CIVOU3qZNZRaozxiCl2UFKcNqLOmx
-R3NKpo1jYf4REQIeG8Yw9+hSWLRbshNteP6bKUUf+vanhg9+axyOEOH/iOQvgk/m
-b8wA8wNa4ujWljPbTQnj7ry8RqhTM0GcAN5LSdSvcKcpzLcs3aYwh+Z8e30sQWna
-F40sa5u7izgBTOrwpcDm/w5kC46vpRQ5fnbshVw6pne2by0mdMECASid/p25N103
-jMqTFlmO7kpf/jpCSmamp3/JSEE1BJKHwQ6Ql4nzRA2N1mnvWH7Zxcv043gkHeAu
-0x8evpvwuhdIyproejNFlBpKmW8OX7yKTCPPMC/VkX8Q1rVkxU0DQ6hmvwZlhoKa
-9Wc2uXpw9xF8itV4Uvcdr3dwqByvIqn7iI/gB+4l41e0u8OmH2MKOx4Nxlly5TNW
-HcVKQHyOeyvnINuBAQ==
------END CERTIFICATE-----
diff --git a/Lib/test/ssl_key.passwd.pem b/Lib/test/ssl_key.passwd.pem
deleted file mode 100644
index 46de61ab85..0000000000
--- a/Lib/test/ssl_key.passwd.pem
+++ /dev/null
@@ -1,42 +0,0 @@
------BEGIN ENCRYPTED PRIVATE KEY-----
-MIIHbTBXBgkqhkiG9w0BBQ0wSjApBgkqhkiG9w0BBQwwHAQI072N7W+PDDMCAggA
-MAwGCCqGSIb3DQIJBQAwHQYJYIZIAWUDBAEqBBA/AuaRNi4vE4KGqI4In+70BIIH
-ENGS5Vex5NID873frmd1UZEHZ+O/Bd0wDb+NUpIqesHkRYf7kKi6Gnr+nKQ/oVVn
-Lm3JjE7c8ECP0OkOOXmiXuWL1SkzBBWqCI4stSGUPvBiHsGwNnvJAaGjUffgMlcC
-aJOA2+dnejLkzblq4CB2LQdm06N3Xoe9tyqtQaUHxfzJAf5Ydd8uj7vpKN2MMhY7
-icIPJwSyh0N7S6XWVtHEokr9Kp4y2hS5a+BgCWV1/1z0aF7agnSVndmT1VR+nWmc
-lM14k+lethmHMB+fsNSjnqeJ7XOPlOTHqhiZ9bBSTgF/xr5Bck/NiKRzHjdovBox
-TKg+xchaBhpRh7wBPBIlNJeHmIjv+8obOKjKU98Ig/7R9+IryZaNcKAH0PuOT+Sw
-QHXiCGQbOiYHB9UyhDTWiB7YVjd8KHefOFxfHzOQb/iBhbv1x3bTl3DgepvRN6VO
-dIsPLoIZe42sdf9GeMsk8mGJyZUQ6AzsfhWk3grb/XscizPSvrNsJ2VL1R7YTyT3
-3WA4ZXR1EqvXnWL7N/raemQjy62iOG6t7fcF5IdP9CMbWP+Plpsz4cQW7FtesCTq
-a5ZXraochQz361ODFNIeBEGU+0qqXUtZDlmos/EySkZykSeU/L0bImS62VGE3afo
-YXBmznTTT9kkFkqv7H0MerfJsrE/wF8puP3GM01DW2JRgXRpSWlvbPV/2LnMtRuD
-II7iH4rWDtTjCN6BWKAgDOnPkc9sZ4XulqT32lcUeV6LTdMBfq8kMEc8eDij1vUT
-maVCRpuwaq8EIT3lVgNLufHiG96ojlyYtj3orzw22IjkgC/9ee8UDik9CqbMVmFf
-fVHhsw8LNSg8Q4bmwm5Eg2w2it2gtI68+mwr75oCxuJ/8OMjW21Prj8XDh5reie2
-c0lDKQOFZ9UnLU1bXR/6qUM+JFKR4DMq+fOCuoQSVoyVUEOsJpvBOYnYZN9cxsZm
-vh9dKafMEcKZ8flsbr+gOmOw7+Py2ifSlf25E/Frb1W4gtbTb0LQVHb6+drutrZj
-8HEu4CnHYFCD4ZnOJb26XlZCb8GFBddW86yJYyUqMMV6Q1aJfAOAglsTo1LjIMOZ
-byo0BTAmwUevU/iuOXQ4qRBXXcoidDcTCrxfUSPG9wdt9l+m5SdQpWqfQ+fx5O7m
-SLlrHyZCiPSFMtC9DxqjIklHjf5W3wslGLgaD30YXa4VDYkRihf3CNsxGQ+tVvef
-l0ZjoAitF7Gaua06IESmKnpHe23dkr1cjYq+u2IV+xGH8LeExdwsQ9kpuTeXPnQs
-JOA99SsFx1ct32RrwjxnDDsiNkaViTKo9GDkV3jQTfoFgAVqfSgg9wGXpqUqhNG7
-TiSIHCowllLny2zn4XrXCy2niD3VDt0skb3l/PaegHE2z7S5YY85nQtYwpLiwB9M
-SQ08DYKxPBZYKtS2iZ/fsA1gjSRQDPg/SIxMhUC3M3qH8iWny1Lzl25F2Uq7VVEX
-LdTUtaby49jRTT3CQGr5n6z7bMbUegiY7h8WmOekuThGDH+4xZp6+rDP4GFk4FeK
-JcF70vMQYIjQZhadic6olv+9VtUP42ltGG/yP9a3eWRkzfAf2eCh6B1rYdgEWwE8
-rlcZzwM+y6eUmeNF2FVWB8iWtTMQHy+dYNPM+Jtus1KQKxiiq/yCRs7nWvzWRFWA
-HRyqV0J6/lqgm4FvfktFt1T0W+mDoLJOR2/zIwMy2lgL5zeHuR3SaMJnCikJbqKS
-HB3UvrhAWUcZqdH29+FhVWeM7ybyF1Wccmf+IIC/ePLa6gjtqPV8lG/5kbpcpnB6
-UQY8WWaKMxyr3jJ9bAX5QKshchp04cDecOLZrpFGNNQngR8RxSEkiIgAqNxWunIu
-KrdBDrupv/XAgEOclmgToY3iywLJSV5gHAyHWDUhRH4cFCLiGPl4XIcnXOuTze3H
-3j+EYSiS3v3DhHjp33YU2pXlJDjiYsKzAXejEh66++Y8qaQdCAad3ruWRCzW3kgk
-Md0A1VGzntTnQsewvExQEMZH2LtYIsPv3KCYGeSAuLabX4tbGk79PswjnjLLEOr0
-Ghf6RF6qf5/iFyJoG4vrbKT8kx6ywh0InILCdjUunuDskIBxX6tEcr9XwajoIvb2
-kcmGdjam5kKLS7QOWQTl8/r/cuFes0dj34cX5Qpq+Gd7tRq/D+b0207926Cxvftv
-qQ1cVn8HiLxKkZzd3tpf2xnoV1zkTL0oHrNg+qzxoxXUTUcwtIf1d/HRbYEAhi/d
-bBBoFeftEHWNq+sJgS9bH+XNzo/yK4u04B5miOq8v4CSkJdzu+ZdF22d4cjiGmtQ
-8BTmcn0Unzm+u5H0+QSZe54QBHJGNXXOIKMTkgnOdW27g4DbI1y7fCqJiSMbRW6L
-oHmMfbdB3GWqGbsUkhY8i6h9op0MU6WOX7ea2Rxyt4t6
------END ENCRYPTED PRIVATE KEY-----
diff --git a/Lib/test/ssl_key.pem b/Lib/test/ssl_key.pem
deleted file mode 100644
index 1ea4578d81..0000000000
--- a/Lib/test/ssl_key.pem
+++ /dev/null
@@ -1,40 +0,0 @@
------BEGIN PRIVATE KEY-----
-MIIG/wIBADANBgkqhkiG9w0BAQEFAASCBukwggblAgEAAoIBgQCylKlLaKU+hOvJ
-DfriTRLd+IthG5hv28I3A/CGjLICT0rDDtgaXd0uqloJAnjsgn5gMAcStpDW8Rm+
-t6LsrBL+5fBgkyU1r94Rvx0HHoyaZwBBouitVHw28hP3W+smddkqB1UxpGnTeL2B
-gj3dVo/WTtRfO+0h0PKw1l98YE1pMTdqIwcOOE/ER0g4hvA/wrxuLhMvlVLMy/lL
-58uctqaDUqryNyeerKbVkq4fJyCG5D2TwXVJ3i2DDh0xSt2Y10poZV4M4k8Su9Z5
-8zN2PSvYMT50aqF277v8BaOeYUApBE4kZGIJpo13ATGdEwpUFZ0Fri4zLYUZ1hWb
-OC35sKo7OxWQ/+tefNUdgWHob6Vmy777jiYcLwxc3sS9rF3AJe0rMW83kCkR6hmy
-A3250E137N/1QumHuT/Nj9rnI/lwt9jfaYkZjoAgT/C97m/mM83cYpGTdoGV1xNo
-7G90MhP0di5FnVsrIaSnvkbGT9UgUWx0oVMjocifdG2qIhMI9psCAwEAAQKCAYBT
-sHmaPmNaZj59jZCqp0YVQlpHWwBYQ5vD3pPE6oCttm0p9nXt/VkfenQRTthOtmT1
-POzDp00/feP7zeGLmqSYUjgRekPw4gdnN7Ip2PY5kdW77NWwDSzdLxuOS8Rq1MW9
-/Yu+ZPe3RBlDbT8C0IM+Atlh/BqIQ3zIxN4g0pzUlF0M33d6AYfYSzOcUhibOO7H
-j84r+YXBNkIRgYKZYbutRXuZYaGuqejRpBj3voVu0d3Ntdb6lCWuClpB9HzfGN0c
-RTv8g6UYO4sK3qyFn90ibIR/1GB9watvtoWVZqggiWeBzSWVWRsGEf9O+Cx4oJw1
-IphglhmhbgNksbj7bD24on/icldSOiVkoUemUOFmHWhCm4PnB1GmbD8YMfEdSbks
-qDr1Ps1zg4mGOinVD/4cY7vuPFO/HCH07wfeaUGzRt4g0/yLr+XjVofOA3oowyxv
-JAzr+niHA3lg5ecj4r7M68efwzN1OCyjMrVJw2RAzwvGxE+rm5NiT08SWlKQZnkC
-gcEA4wvyLpIur/UB84nV3XVJ89UMNBLm++aTFzld047BLJtMaOhvNqx6Cl5c8VuW
-l261KHjiVzpfNM3/A2LBQJcYkhX7avkqEXlj57cl+dCWAVwUzKmLJTPjfaTTZnYJ
-xeN3dMYjJz2z2WtgvfvDoJLukVwIMmhTY8wtqqYyQBJ/l06pBsfw5TNvmVIOQHds
-8ASOiFt+WRLk2bl9xrGGayqt3VV93KVRzF27cpjOgEcG74F3c0ZW9snERN7vIYwB
-JfrlAoHBAMlahPwMP2TYylG8OzHe7EiehTekSO26LGh0Cq3wTGXYsK/q8hQCzL14
-kWW638vpwXL6L9ntvrd7hjzWRO3vX/VxnYEA6f0bpqHq1tZi6lzix5CTUN5McpDg
-QnjenSJNrNjS1zEF8WeY9iLEuDI/M/iUW4y9R6s3WpgQhPDXpSvd2g3gMGRUYhxQ
-Xna8auiJeYFq0oNaOxvJj+VeOfJ3ZMJttd+Y7gTOYZcbg3SdRb/kdxYki0RMD2hF
-4ZvjJ6CTfwKBwQDiMqiZFTJGQwYqp4vWEmAW+I4r4xkUpWatoI2Fk5eI5T9+1PLX
-uYXsho56NxEU1UrOg4Cb/p+TcBc8PErkGqR0BkpxDMOInTOXSrQe6lxIBoECVXc3
-HTbrmiay0a5y5GfCgxPKqIJhfcToAceoVjovv0y7S4yoxGZKuUEe7E8JY2iqRNAO
-yOvKCCICv/hcN235E44RF+2/rDlOltagNej5tY6rIFkaDdgOF4bD7f9O5eEni1Bg
-litfoesDtQP/3rECgcEAkQfvQ7D6tIPmbqsbJBfCr6fmoqZllT4FIJN84b50+OL0
-mTGsfjdqC4tdhx3sdu7/VPbaIqm5NmX10bowWgWSY7MbVME4yQPyqSwC5NbIonEC
-d6N0mzoLR0kQ+Ai4u+2g82gicgAq2oj1uSNi3WZi48jQjHYFulCbo246o1NgeFFK
-77WshYe2R1ioQfQDOU1URKCR0uTaMHClgfu112yiGd12JAD+aF3TM0kxDXz+sXI5
-SKy311DFxECZeXRLpcC3AoHBAJkNMJWTyPYbeVu+CTQkec8Uun233EkXa2kUNZc/
-5DuXDaK+A3DMgYRufTKSPpDHGaCZ1SYPInX1Uoe2dgVjWssRL2uitR4ENabDoAOA
-ICVYXYYNagqQu5wwirF0QeaMXo1fjhuuHQh8GsMdXZvYEaAITZ9/NG5x/oY08+8H
-kr78SMBOPy3XQn964uKG+e3JwpOG14GKABdAlrHKFXNWchu/6dgcYXB87mrC/GhO
-zNwzC+QhFTZoOomFoqMgFWujng==
------END PRIVATE KEY-----
diff --git a/Lib/test/ssl_servers.py b/Lib/test/ssl_servers.py
index a4bd7455d4..15b071e04d 100644
--- a/Lib/test/ssl_servers.py
+++ b/Lib/test/ssl_servers.py
@@ -14,7 +14,7 @@
 here = os.path.dirname(__file__)
 
 HOST = socket_helper.HOST
-CERTFILE = os.path.join(here, 'keycert.pem')
+CERTFILE = os.path.join(here, 'certdata', 'keycert.pem')
 
 # This one's based on HTTPServer, which is based on socketserver
 
diff --git a/Lib/test/string_tests.py b/Lib/test/string_tests.py
index 709cac7a27..408b19338b 100644
--- a/Lib/test/string_tests.py
+++ b/Lib/test/string_tests.py
@@ -327,11 +327,12 @@ def reference_find(p, s):
             for i in range(len(s)):
                 if s.startswith(p, i):
                     return i
+            if p == '' and s == '':
+                return 0
             return -1
 
-        rr = random.randrange
-        choices = random.choices
-        for _ in range(1000):
+        def check_pattern(rr):
+            choices = random.choices
             p0 = ''.join(choices('abcde', k=rr(10))) * rr(10, 20)
             p = p0[:len(p0) - rr(10)] # pop off some characters
             left = ''.join(choices('abcdef', k=rr(2000)))
@@ -341,6 +342,13 @@ def reference_find(p, s):
                 self.checkequal(reference_find(p, text),
                                 text, 'find', p)
 
+        rr = random.randrange
+        for _ in range(1000):
+            check_pattern(rr)
+
+        # Test that empty string always work:
+        check_pattern(lambda *args: 0)
+
     def test_find_many_lengths(self):
         haystack_repeats = [a * 10**e for e in range(6) for a in (1,2,5)]
         haystacks = [(n, self.fixtype("abcab"*n + "da")) for n in haystack_repeats]
diff --git a/Lib/test/support/__init__.py b/Lib/test/support/__init__.py
index b6350e4e52..650d4aa7d4 100644
--- a/Lib/test/support/__init__.py
+++ b/Lib/test/support/__init__.py
@@ -19,8 +19,6 @@
 import unittest
 import warnings
 
-from .testresult import get_test_runner
-
 
 __all__ = [
     # globals
@@ -34,7 +32,6 @@
     "is_resource_enabled", "requires", "requires_freebsd_version",
     "requires_linux_version", "requires_mac_ver",
     "check_syntax_error",
-    "run_unittest", "run_doctest",
     "requires_gzip", "requires_bz2", "requires_lzma",
     "bigmemtest", "bigaddrspacetest", "cpython_only", "get_attribute",
     "requires_IEEE_754", "requires_zlib",
@@ -46,7 +43,7 @@
     "check_disallow_instantiation", "check_sanitizer", "skip_if_sanitizer",
     "requires_limited_api", "requires_specialization",
     # sys
-    "is_jython", "is_android", "is_emscripten", "is_wasi",
+    "MS_WINDOWS", "is_jython", "is_android", "is_emscripten", "is_wasi",
     "check_impl_detail", "unix_shell", "setswitchinterval",
     # os
     "get_pagesize",
@@ -74,13 +71,7 @@
 #
 # The timeout should be long enough for connect(), recv() and send() methods
 # of socket.socket.
-LOOPBACK_TIMEOUT = 5.0
-if sys.platform == 'win32' and ' 32 bit (ARM)' in sys.version:
-    # bpo-37553: test_socket.SendfileUsingSendTest is taking longer than 2
-    # seconds on Windows ARM32 buildbot
-    LOOPBACK_TIMEOUT = 10
-elif sys.platform == 'vxworks':
-    LOOPBACK_TIMEOUT = 10
+LOOPBACK_TIMEOUT = 10.0
 
 # Timeout in seconds for network requests going to the internet. The timeout is
 # short enough to prevent a test to wait for too long if the internet request
@@ -406,19 +397,19 @@ def check_sanitizer(*, address=False, memory=False, ub=False):
         raise ValueError('At least one of address, memory, or ub must be True')
 
 
-    _cflags = sysconfig.get_config_var('CFLAGS') or ''
-    _config_args = sysconfig.get_config_var('CONFIG_ARGS') or ''
+    cflags = sysconfig.get_config_var('CFLAGS') or ''
+    config_args = sysconfig.get_config_var('CONFIG_ARGS') or ''
     memory_sanitizer = (
-        '-fsanitize=memory' in _cflags or
-        '--with-memory-sanitizer' in _config_args
+        '-fsanitize=memory' in cflags or
+        '--with-memory-sanitizer' in config_args
     )
     address_sanitizer = (
-        '-fsanitize=address' in _cflags or
-        '--with-address-sanitizer' in _config_args
+        '-fsanitize=address' in cflags or
+        '--with-address-sanitizer' in config_args
     )
     ub_sanitizer = (
-        '-fsanitize=undefined' in _cflags or
-        '--with-undefined-behavior-sanitizer' in _config_args
+        '-fsanitize=undefined' in cflags or
+        '--with-undefined-behavior-sanitizer' in config_args
     )
     return (
         (memory and memory_sanitizer) or
@@ -434,6 +425,18 @@ def skip_if_sanitizer(reason=None, *, address=False, memory=False, ub=False):
     skip = check_sanitizer(address=address, memory=memory, ub=ub)
     return unittest.skipIf(skip, reason)
 
+# gh-89363: True if fork() can hang if Python is built with Address Sanitizer
+# (ASAN): libasan race condition, dead lock in pthread_create().
+HAVE_ASAN_FORK_BUG = check_sanitizer(address=True)
+
+
+def set_sanitizer_env_var(env, option):
+    for name in ('ASAN_OPTIONS', 'MSAN_OPTIONS', 'UBSAN_OPTIONS'):
+        if name in env:
+            env[name] += f':{option}'
+        else:
+            env[name] = option
+
 
 def system_must_validate_cert(f):
     """Skip the test on TLS certificate validation failures."""
@@ -515,6 +518,8 @@ def requires_legacy_unicode_capi():
     return unittest.skipUnless(unicode_legacy_string,
                                'requires legacy Unicode C API')
 
+MS_WINDOWS = (sys.platform == 'win32')
+
 # Is not actually used in tests, but is kept for compatibility.
 is_jython = sys.platform.startswith('java')
 
@@ -781,6 +786,24 @@ def python_is_optimized():
     return final_opt not in ('', '-O0', '-Og')
 
 
+def check_cflags_pgo():
+    # Check if Python was built with ./configure --enable-optimizations:
+    # with Profile Guided Optimization (PGO).
+    cflags_nodist = sysconfig.get_config_var('PY_CFLAGS_NODIST') or ''
+    pgo_options = [
+        # GCC
+        '-fprofile-use',
+        # clang: -fprofile-instr-use=code.profclangd
+        '-fprofile-instr-use',
+        # ICC
+        "-prof-use",
+    ]
+    PGO_PROF_USE_FLAG = sysconfig.get_config_var('PGO_PROF_USE_FLAG')
+    if PGO_PROF_USE_FLAG:
+        pgo_options.append(PGO_PROF_USE_FLAG)
+    return any(option in cflags_nodist for option in pgo_options)
+
+
 _header = 'nP'
 _align = '0n'
 if hasattr(sys, "getobjects"):
@@ -890,27 +913,31 @@ def inner(*args, **kwds):
 
 MAX_Py_ssize_t = sys.maxsize
 
-def set_memlimit(limit):
-    global max_memuse
-    global real_max_memuse
+def _parse_memlimit(limit: str) -> int:
     sizes = {
         'k': 1024,
         'm': _1M,
         'g': _1G,
         't': 1024*_1G,
     }
-    m = re.match(r'(\d+(\.\d+)?) (K|M|G|T)b?$', limit,
+    m = re.match(r'(\d+(?:\.\d+)?) (K|M|G|T)b?$', limit,
                  re.IGNORECASE | re.VERBOSE)
     if m is None:
-        raise ValueError('Invalid memory limit %r' % (limit,))
-    memlimit = int(float(m.group(1)) * sizes[m.group(3).lower()])
-    real_max_memuse = memlimit
-    if memlimit > MAX_Py_ssize_t:
-        memlimit = MAX_Py_ssize_t
+        raise ValueError(f'Invalid memory limit: {limit!r}')
+    return int(float(m.group(1)) * sizes[m.group(2).lower()])
+
+def set_memlimit(limit: str) -> None:
+    global max_memuse
+    global real_max_memuse
+    memlimit = _parse_memlimit(limit)
     if memlimit < _2G - 1:
-        raise ValueError('Memory limit %r too low to be useful' % (limit,))
+        raise ValueError('Memory limit {limit!r} too low to be useful')
+
+    real_max_memuse = memlimit
+    memlimit = min(memlimit, MAX_Py_ssize_t)
     max_memuse = memlimit
 
+
 class _MemoryWatchdog:
     """An object which periodically watches the process' memory consumption
     and prints it out.
@@ -1100,175 +1127,6 @@ def requires_specialization(test):
     return unittest.skipUnless(
         opcode.ENABLE_SPECIALIZATION, "requires specialization")(test)
 
-def _filter_suite(suite, pred):
-    """Recursively filter test cases in a suite based on a predicate."""
-    newtests = []
-    for test in suite._tests:
-        if isinstance(test, unittest.TestSuite):
-            _filter_suite(test, pred)
-            newtests.append(test)
-        else:
-            if pred(test):
-                newtests.append(test)
-    suite._tests = newtests
-
-@dataclasses.dataclass(slots=True)
-class TestStats:
-    tests_run: int = 0
-    failures: int = 0
-    skipped: int = 0
-
-    @staticmethod
-    def from_unittest(result):
-        return TestStats(result.testsRun,
-                         len(result.failures),
-                         len(result.skipped))
-
-    @staticmethod
-    def from_doctest(results):
-        return TestStats(results.attempted,
-                         results.failed)
-
-    def accumulate(self, stats):
-        self.tests_run += stats.tests_run
-        self.failures += stats.failures
-        self.skipped += stats.skipped
-
-
-def _run_suite(suite):
-    """Run tests from a unittest.TestSuite-derived class."""
-    runner = get_test_runner(sys.stdout,
-                             verbosity=verbose,
-                             capture_output=(junit_xml_list is not None))
-
-    result = runner.run(suite)
-
-    if junit_xml_list is not None:
-        junit_xml_list.append(result.get_xml_element())
-
-    if not result.testsRun and not result.skipped and not result.errors:
-        raise TestDidNotRun
-    if not result.wasSuccessful():
-        stats = TestStats.from_unittest(result)
-        if len(result.errors) == 1 and not result.failures:
-            err = result.errors[0][1]
-        elif len(result.failures) == 1 and not result.errors:
-            err = result.failures[0][1]
-        else:
-            err = "multiple errors occurred"
-            if not verbose: err += "; run in verbose mode for details"
-        errors = [(str(tc), exc_str) for tc, exc_str in result.errors]
-        failures = [(str(tc), exc_str) for tc, exc_str in result.failures]
-        raise TestFailedWithDetails(err, errors, failures, stats=stats)
-    return result
-
-
-# By default, don't filter tests
-_match_test_func = None
-
-_accept_test_patterns = None
-_ignore_test_patterns = None
-
-
-def match_test(test):
-    # Function used by support.run_unittest() and regrtest --list-cases
-    if _match_test_func is None:
-        return True
-    else:
-        return _match_test_func(test.id())
-
-
-def _is_full_match_test(pattern):
-    # If a pattern contains at least one dot, it's considered
-    # as a full test identifier.
-    # Example: 'test.test_os.FileTests.test_access'.
-    #
-    # ignore patterns which contain fnmatch patterns: '*', '?', '[...]'
-    # or '[!...]'. For example, ignore 'test_access*'.
-    return ('.' in pattern) and (not re.search(r'[?*\[\]]', pattern))
-
-
-def set_match_tests(accept_patterns=None, ignore_patterns=None):
-    global _match_test_func, _accept_test_patterns, _ignore_test_patterns
-
-    if accept_patterns is None:
-        accept_patterns = ()
-    if ignore_patterns is None:
-        ignore_patterns = ()
-
-    accept_func = ignore_func = None
-
-    if accept_patterns != _accept_test_patterns:
-        accept_patterns, accept_func = _compile_match_function(accept_patterns)
-    if ignore_patterns != _ignore_test_patterns:
-        ignore_patterns, ignore_func = _compile_match_function(ignore_patterns)
-
-    # Create a copy since patterns can be mutable and so modified later
-    _accept_test_patterns = tuple(accept_patterns)
-    _ignore_test_patterns = tuple(ignore_patterns)
-
-    if accept_func is not None or ignore_func is not None:
-        def match_function(test_id):
-            accept = True
-            ignore = False
-            if accept_func:
-                accept = accept_func(test_id)
-            if ignore_func:
-                ignore = ignore_func(test_id)
-            return accept and not ignore
-
-        _match_test_func = match_function
-
-
-def _compile_match_function(patterns):
-    if not patterns:
-        func = None
-        # set_match_tests(None) behaves as set_match_tests(())
-        patterns = ()
-    elif all(map(_is_full_match_test, patterns)):
-        # Simple case: all patterns are full test identifier.
-        # The test.bisect_cmd utility only uses such full test identifiers.
-        func = set(patterns).__contains__
-    else:
-        import fnmatch
-        regex = '|'.join(map(fnmatch.translate, patterns))
-        # The search *is* case sensitive on purpose:
-        # don't use flags=re.IGNORECASE
-        regex_match = re.compile(regex).match
-
-        def match_test_regex(test_id):
-            if regex_match(test_id):
-                # The regex matches the whole identifier, for example
-                # 'test.test_os.FileTests.test_access'.
-                return True
-            else:
-                # Try to match parts of the test identifier.
-                # For example, split 'test.test_os.FileTests.test_access'
-                # into: 'test', 'test_os', 'FileTests' and 'test_access'.
-                return any(map(regex_match, test_id.split(".")))
-
-        func = match_test_regex
-
-    return patterns, func
-
-
-def run_unittest(*classes):
-    """Run tests from unittest.TestCase-derived classes."""
-    valid_types = (unittest.TestSuite, unittest.TestCase)
-    loader = unittest.TestLoader()
-    suite = unittest.TestSuite()
-    for cls in classes:
-        if isinstance(cls, str):
-            if cls in sys.modules:
-                suite.addTest(loader.loadTestsFromModule(sys.modules[cls]))
-            else:
-                raise ValueError("str arguments must be keys in sys.modules")
-        elif isinstance(cls, valid_types):
-            suite.addTest(cls)
-        else:
-            suite.addTest(loader.loadTestsFromTestCase(cls))
-    _filter_suite(suite, match_test)
-    return _run_suite(suite)
 
 #=======================================================================
 # Check for the presence of docstrings.
@@ -1290,38 +1148,6 @@ def _check_docstrings():
                                           "test requires docstrings")
 
 
-#=======================================================================
-# doctest driver.
-
-def run_doctest(module, verbosity=None, optionflags=0):
-    """Run doctest on the given module.  Return (#failures, #tests).
-
-    If optional argument verbosity is not specified (or is None), pass
-    support's belief about verbosity on to doctest.  Else doctest's
-    usual behavior is used (it searches sys.argv for -v).
-    """
-
-    import doctest
-
-    if verbosity is None:
-        verbosity = verbose
-    else:
-        verbosity = None
-
-    results = doctest.testmod(module,
-                             verbose=verbosity,
-                             optionflags=optionflags)
-    if results.failed:
-        stats = TestStats.from_doctest(results)
-        raise TestFailed(f"{results.failed} of {results.attempted} "
-                         f"doctests failed",
-                         stats=stats)
-    if verbose:
-        print('doctest (%s) ... %d tests with zero failures' %
-              (module.__name__, results.attempted))
-    return results
-
-
 #=======================================================================
 # Support for saving and restoring the imported modules.
 
@@ -2539,3 +2365,29 @@ def adjust_int_max_str_digits(max_digits):
 #Windows doesn't have os.uname() but it doesn't support s390x.
 skip_on_s390x = unittest.skipIf(hasattr(os, 'uname') and os.uname().machine == 's390x',
                                 'skipped on s390x')
+
+_BASE_COPY_SRC_DIR_IGNORED_NAMES = frozenset({
+    # SRC_DIR/.git
+    '.git',
+    # ignore all __pycache__/ sub-directories
+    '__pycache__',
+})
+
+# Ignore function for shutil.copytree() to copy the Python source code.
+def copy_python_src_ignore(path, names):
+    ignored = _BASE_COPY_SRC_DIR_IGNORED_NAMES
+    if os.path.basename(path) == 'Doc':
+        ignored |= {
+            # SRC_DIR/Doc/build/
+            'build',
+            # SRC_DIR/Doc/venv/
+            'venv',
+        }
+
+    # check if we are at the root of the source code
+    elif 'Modules' in names:
+        ignored |= {
+            # SRC_DIR/build/
+            'build',
+        }
+    return ignored
diff --git a/Lib/test/support/import_helper.py b/Lib/test/support/import_helper.py
index 67f18e530e..3d804f2b59 100644
--- a/Lib/test/support/import_helper.py
+++ b/Lib/test/support/import_helper.py
@@ -8,7 +8,7 @@
 import unittest
 import warnings
 
-from .os_helper import unlink
+from .os_helper import unlink, temp_dir
 
 
 @contextlib.contextmanager
@@ -274,3 +274,26 @@ def mock_register_at_fork(func):
     # memory.
     from unittest import mock
     return mock.patch('os.register_at_fork', create=True)(func)
+
+
+@contextlib.contextmanager
+def ready_to_import(name=None, source=""):
+    from test.support import script_helper
+
+    # 1. Sets up a temporary directory and removes it afterwards
+    # 2. Creates the module file
+    # 3. Temporarily clears the module from sys.modules (if any)
+    # 4. Reverts or removes the module when cleaning up
+    name = name or "spam"
+    with temp_dir() as tempdir:
+        path = script_helper.make_script(tempdir, name, source)
+        old_module = sys.modules.pop(name, None)
+        try:
+            sys.path.insert(0, tempdir)
+            yield name, path
+            sys.path.remove(tempdir)
+        finally:
+            if old_module is not None:
+                sys.modules[name] = old_module
+            else:
+                sys.modules.pop(name, None)
diff --git a/Lib/test/support/testresult.py b/Lib/test/support/testresult.py
deleted file mode 100644
index de23fdd59d..0000000000
--- a/Lib/test/support/testresult.py
+++ /dev/null
@@ -1,191 +0,0 @@
-'''Test runner and result class for the regression test suite.
-
-'''
-
-import functools
-import io
-import sys
-import time
-import traceback
-import unittest
-from test import support
-
-class RegressionTestResult(unittest.TextTestResult):
-    USE_XML = False
-
-    def __init__(self, stream, descriptions, verbosity):
-        super().__init__(stream=stream, descriptions=descriptions,
-                         verbosity=2 if verbosity else 0)
-        self.buffer = True
-        if self.USE_XML:
-            from xml.etree import ElementTree as ET
-            from datetime import datetime, UTC
-            self.__ET = ET
-            self.__suite = ET.Element('testsuite')
-            self.__suite.set('start',
-                             datetime.now(UTC)
-                                     .replace(tzinfo=None)
-                                     .isoformat(' '))
-            self.__e = None
-        self.__start_time = None
-
-    @classmethod
-    def __getId(cls, test):
-        try:
-            test_id = test.id
-        except AttributeError:
-            return str(test)
-        try:
-            return test_id()
-        except TypeError:
-            return str(test_id)
-        return repr(test)
-
-    def startTest(self, test):
-        super().startTest(test)
-        if self.USE_XML:
-            self.__e = e = self.__ET.SubElement(self.__suite, 'testcase')
-        self.__start_time = time.perf_counter()
-
-    def _add_result(self, test, capture=False, **args):
-        if not self.USE_XML:
-            return
-        e = self.__e
-        self.__e = None
-        if e is None:
-            return
-        ET = self.__ET
-
-        e.set('name', args.pop('name', self.__getId(test)))
-        e.set('status', args.pop('status', 'run'))
-        e.set('result', args.pop('result', 'completed'))
-        if self.__start_time:
-            e.set('time', f'{time.perf_counter() - self.__start_time:0.6f}')
-
-        if capture:
-            if self._stdout_buffer is not None:
-                stdout = self._stdout_buffer.getvalue().rstrip()
-                ET.SubElement(e, 'system-out').text = stdout
-            if self._stderr_buffer is not None:
-                stderr = self._stderr_buffer.getvalue().rstrip()
-                ET.SubElement(e, 'system-err').text = stderr
-
-        for k, v in args.items():
-            if not k or not v:
-                continue
-            e2 = ET.SubElement(e, k)
-            if hasattr(v, 'items'):
-                for k2, v2 in v.items():
-                    if k2:
-                        e2.set(k2, str(v2))
-                    else:
-                        e2.text = str(v2)
-            else:
-                e2.text = str(v)
-
-    @classmethod
-    def __makeErrorDict(cls, err_type, err_value, err_tb):
-        if isinstance(err_type, type):
-            if err_type.__module__ == 'builtins':
-                typename = err_type.__name__
-            else:
-                typename = f'{err_type.__module__}.{err_type.__name__}'
-        else:
-            typename = repr(err_type)
-
-        msg = traceback.format_exception(err_type, err_value, None)
-        tb = traceback.format_exception(err_type, err_value, err_tb)
-
-        return {
-            'type': typename,
-            'message': ''.join(msg),
-            '': ''.join(tb),
-        }
-
-    def addError(self, test, err):
-        self._add_result(test, True, error=self.__makeErrorDict(*err))
-        super().addError(test, err)
-
-    def addExpectedFailure(self, test, err):
-        self._add_result(test, True, output=self.__makeErrorDict(*err))
-        super().addExpectedFailure(test, err)
-
-    def addFailure(self, test, err):
-        self._add_result(test, True, failure=self.__makeErrorDict(*err))
-        super().addFailure(test, err)
-        if support.failfast:
-            self.stop()
-
-    def addSkip(self, test, reason):
-        self._add_result(test, skipped=reason)
-        super().addSkip(test, reason)
-
-    def addSuccess(self, test):
-        self._add_result(test)
-        super().addSuccess(test)
-
-    def addUnexpectedSuccess(self, test):
-        self._add_result(test, outcome='UNEXPECTED_SUCCESS')
-        super().addUnexpectedSuccess(test)
-
-    def get_xml_element(self):
-        if not self.USE_XML:
-            raise ValueError("USE_XML is false")
-        e = self.__suite
-        e.set('tests', str(self.testsRun))
-        e.set('errors', str(len(self.errors)))
-        e.set('failures', str(len(self.failures)))
-        return e
-
-class QuietRegressionTestRunner:
-    def __init__(self, stream, buffer=False):
-        self.result = RegressionTestResult(stream, None, 0)
-        self.result.buffer = buffer
-
-    def run(self, test):
-        test(self.result)
-        return self.result
-
-def get_test_runner_class(verbosity, buffer=False):
-    if verbosity:
-        return functools.partial(unittest.TextTestRunner,
-                                 resultclass=RegressionTestResult,
-                                 buffer=buffer,
-                                 verbosity=verbosity)
-    return functools.partial(QuietRegressionTestRunner, buffer=buffer)
-
-def get_test_runner(stream, verbosity, capture_output=False):
-    return get_test_runner_class(verbosity, capture_output)(stream)
-
-if __name__ == '__main__':
-    import xml.etree.ElementTree as ET
-    RegressionTestResult.USE_XML = True
-
-    class TestTests(unittest.TestCase):
-        def test_pass(self):
-            pass
-
-        def test_pass_slow(self):
-            time.sleep(1.0)
-
-        def test_fail(self):
-            print('stdout', file=sys.stdout)
-            print('stderr', file=sys.stderr)
-            self.fail('failure message')
-
-        def test_error(self):
-            print('stdout', file=sys.stdout)
-            print('stderr', file=sys.stderr)
-            raise RuntimeError('error message')
-
-    suite = unittest.TestSuite()
-    suite.addTest(unittest.TestLoader().loadTestsFromTestCase(TestTests))
-    stream = io.StringIO()
-    runner_cls = get_test_runner_class(sum(a == '-v' for a in sys.argv))
-    runner = runner_cls(sys.stdout)
-    result = runner.run(suite)
-    print('Output:', stream.getvalue())
-    print('XML: ', end='')
-    for s in ET.tostringlist(result.get_xml_element()):
-        print(s.decode(), end='')
-    print()
diff --git a/Lib/test/support/threading_helper.py b/Lib/test/support/threading_helper.py
index 7f16050f32..afa25a76f6 100644
--- a/Lib/test/support/threading_helper.py
+++ b/Lib/test/support/threading_helper.py
@@ -22,34 +22,37 @@
 
 
 def threading_setup():
-    return _thread._count(), threading._dangling.copy()
+    return _thread._count(), len(threading._dangling)
 
 
 def threading_cleanup(*original_values):
-    _MAX_COUNT = 100
-
-    for count in range(_MAX_COUNT):
-        values = _thread._count(), threading._dangling
-        if values == original_values:
-            break
-
-        if not count:
-            # Display a warning at the first iteration
-            support.environment_altered = True
-            dangling_threads = values[1]
-            support.print_warning(f"threading_cleanup() failed to cleanup "
-                                  f"{values[0] - original_values[0]} threads "
-                                  f"(count: {values[0]}, "
-                                  f"dangling: {len(dangling_threads)})")
-            for thread in dangling_threads:
-                support.print_warning(f"Dangling thread: {thread!r}")
-
-            # Don't hold references to threads
-            dangling_threads = None
-        values = None
-
-        time.sleep(0.01)
-        support.gc_collect()
+    orig_count, orig_ndangling = original_values
+
+    timeout = 1.0
+    for _ in support.sleeping_retry(timeout, error=False):
+        # Copy the thread list to get a consistent output. threading._dangling
+        # is a WeakSet, its value changes when it's read.
+        dangling_threads = list(threading._dangling)
+        count = _thread._count()
+
+        if count <= orig_count:
+            return
+
+    # Timeout!
+    support.environment_altered = True
+    support.print_warning(
+        f"threading_cleanup() failed to clean up threads "
+        f"in {timeout:.1f} seconds\n"
+        f"  before: thread count={orig_count}, dangling={orig_ndangling}\n"
+        f"  after: thread count={count}, dangling={len(dangling_threads)}")
+    for thread in dangling_threads:
+        support.print_warning(f"Dangling thread: {thread!r}")
+
+    # The warning happens when a test spawns threads and some of these threads
+    # are still running after the test completes. To fix this warning, join
+    # threads explicitly to wait until they complete.
+    #
+    # To make the warning more likely, reduce the timeout.
 
 
 def reap_threads(func):
diff --git a/Lib/test/talos-2019-0758.pem b/Lib/test/talos-2019-0758.pem
deleted file mode 100644
index 13b95a77fd..0000000000
--- a/Lib/test/talos-2019-0758.pem
+++ /dev/null
@@ -1,22 +0,0 @@
------BEGIN CERTIFICATE-----
-MIIDqDCCApKgAwIBAgIBAjALBgkqhkiG9w0BAQswHzELMAkGA1UEBhMCVUsxEDAO
-BgNVBAMTB2NvZHktY2EwHhcNMTgwNjE4MTgwMDU4WhcNMjgwNjE0MTgwMDU4WjA7
-MQswCQYDVQQGEwJVSzEsMCoGA1UEAxMjY29kZW5vbWljb24tdm0tMi50ZXN0Lmxh
-bC5jaXNjby5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC63fGB
-J80A9Av1GB0bptslKRIUtJm8EeEu34HkDWbL6AJY0P8WfDtlXjlPaLqFa6sqH6ES
-V48prSm1ZUbDSVL8R6BYVYpOlK8/48xk4pGTgRzv69gf5SGtQLwHy8UPBKgjSZoD
-5a5k5wJXGswhKFFNqyyxqCvWmMnJWxXTt2XDCiWc4g4YAWi4O4+6SeeHVAV9rV7C
-1wxqjzKovVe2uZOHjKEzJbbIU6JBPb6TRfMdRdYOw98n1VXDcKVgdX2DuuqjCzHP
-WhU4Tw050M9NaK3eXp4Mh69VuiKoBGOLSOcS8reqHIU46Reg0hqeL8LIL6OhFHIF
-j7HR6V1X6F+BfRS/AgMBAAGjgdYwgdMwCQYDVR0TBAIwADAdBgNVHQ4EFgQUOktp
-HQjxDXXUg8prleY9jeLKeQ4wTwYDVR0jBEgwRoAUx6zgPygZ0ZErF9sPC4+5e2Io
-UU+hI6QhMB8xCzAJBgNVBAYTAlVLMRAwDgYDVQQDEwdjb2R5LWNhggkA1QEAuwb7
-2s0wCQYDVR0SBAIwADAuBgNVHREEJzAlgiNjb2Rlbm9taWNvbi12bS0yLnRlc3Qu
-bGFsLmNpc2NvLmNvbTAOBgNVHQ8BAf8EBAMCBaAwCwYDVR0fBAQwAjAAMAsGCSqG
-SIb3DQEBCwOCAQEAvqantx2yBlM11RoFiCfi+AfSblXPdrIrHvccepV4pYc/yO6p
-t1f2dxHQb8rWH3i6cWag/EgIZx+HJQvo0rgPY1BFJsX1WnYf1/znZpkUBGbVmlJr
-t/dW1gSkNS6sPsM0Q+7HPgEv8CPDNK5eo7vU2seE0iWOkxSyVUuiCEY9ZVGaLVit
-p0C78nZ35Pdv4I+1cosmHl28+es1WI22rrnmdBpH8J1eY6WvUw2xuZHLeNVN0TzV
-Q3qq53AaCWuLOD1AjESWuUCxMZTK9DPS4JKXTK8RLyDeqOvJGjsSWp3kL0y3GaQ+
-10T1rfkKJub2+m9A9duin1fn6tHc2wSvB7m3DA==
------END CERTIFICATE-----
diff --git a/Lib/test/test___future__.py b/Lib/test/test___future__.py
deleted file mode 100644
index 559a1873ad..0000000000
--- a/Lib/test/test___future__.py
+++ /dev/null
@@ -1,61 +0,0 @@
-import unittest
-import __future__
-
-GOOD_SERIALS = ("alpha", "beta", "candidate", "final")
-
-features = __future__.all_feature_names
-
-class FutureTest(unittest.TestCase):
-
-    def test_names(self):
-        # Verify that all_feature_names appears correct.
-        given_feature_names = features[:]
-        for name in dir(__future__):
-            obj = getattr(__future__, name, None)
-            if obj is not None and isinstance(obj, __future__._Feature):
-                self.assertTrue(
-                    name in given_feature_names,
-                    "%r should have been in all_feature_names" % name
-                )
-                given_feature_names.remove(name)
-        self.assertEqual(len(given_feature_names), 0,
-               "all_feature_names has too much: %r" % given_feature_names)
-
-    def test_attributes(self):
-        for feature in features:
-            value = getattr(__future__, feature)
-
-            optional = value.getOptionalRelease()
-            mandatory = value.getMandatoryRelease()
-
-            a = self.assertTrue
-            e = self.assertEqual
-            def check(t, name):
-                a(isinstance(t, tuple), "%s isn't tuple" % name)
-                e(len(t), 5, "%s isn't 5-tuple" % name)
-                (major, minor, micro, level, serial) = t
-                a(isinstance(major, int), "%s major isn't int"  % name)
-                a(isinstance(minor, int), "%s minor isn't int" % name)
-                a(isinstance(micro, int), "%s micro isn't int" % name)
-                a(isinstance(level, str),
-                    "%s level isn't string" % name)
-                a(level in GOOD_SERIALS,
-                       "%s level string has unknown value" % name)
-                a(isinstance(serial, int), "%s serial isn't int" % name)
-
-            check(optional, "optional")
-            if mandatory is not None:
-                check(mandatory, "mandatory")
-                a(optional < mandatory,
-                       "optional not less than mandatory, and mandatory not None")
-
-            a(hasattr(value, "compiler_flag"),
-                   "feature is missing a .compiler_flag attr")
-            # Make sure the compile accepts the flag.
-            compile("", "<test>", "exec", value.compiler_flag)
-            a(isinstance(getattr(value, "compiler_flag"), int),
-                   ".compiler_flag isn't int")
-
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_asyncio/test_base_events.py b/Lib/test/test_asyncio/test_base_events.py
index 3b4026cb73..abcb6f55c4 100644
--- a/Lib/test/test_asyncio/test_base_events.py
+++ b/Lib/test/test_asyncio/test_base_events.py
@@ -273,7 +273,7 @@ def cb():
             self.loop.stop()
 
         self.loop._process_events = mock.Mock()
-        delay = 0.1
+        delay = 0.100
 
         when = self.loop.time() + delay
         self.loop.call_at(when, cb)
@@ -282,10 +282,7 @@ def cb():
         dt = self.loop.time() - t0
 
         # 50 ms: maximum granularity of the event loop
-        self.assertGreaterEqual(dt, delay - 0.050, dt)
-        # tolerate a difference of +800 ms because some Python buildbots
-        # are really slow
-        self.assertLessEqual(dt, 0.9, dt)
+        self.assertGreaterEqual(dt, delay - test_utils.CLOCK_RES)
         with self.assertRaises(TypeError, msg="when cannot be None"):
             self.loop.call_at(None, cb)
 
diff --git a/Lib/test/test_asyncio/test_events.py b/Lib/test/test_asyncio/test_events.py
index 1647d2308c..ddc45fd99b 100644
--- a/Lib/test/test_asyncio/test_events.py
+++ b/Lib/test/test_asyncio/test_events.py
@@ -294,10 +294,11 @@ async def coro2():
     # 15.6 msec, we use fairly long sleep times here (~100 msec).
 
     def test_run_until_complete(self):
+        delay = 0.100
         t0 = self.loop.time()
-        self.loop.run_until_complete(asyncio.sleep(0.1))
-        t1 = self.loop.time()
-        self.assertTrue(0.08 <= t1-t0 <= 0.8, t1-t0)
+        self.loop.run_until_complete(asyncio.sleep(delay))
+        dt = self.loop.time() - t0
+        self.assertGreaterEqual(dt, delay - test_utils.CLOCK_RES)
 
     def test_run_until_complete_stopped(self):
 
@@ -1693,12 +1694,9 @@ async def main():
                 self.loop.stop()
             return res
 
-        start = time.monotonic()
         t = self.loop.create_task(main())
         self.loop.run_forever()
-        elapsed = time.monotonic() - start
 
-        self.assertLess(elapsed, 0.1)
         self.assertEqual(t.result(), 'cancelled')
         self.assertRaises(asyncio.CancelledError, f.result)
         if ov is not None:
@@ -1718,7 +1716,6 @@ def _run_once():
         self.loop._run_once = _run_once
 
         async def wait():
-            loop = self.loop
             await asyncio.sleep(1e-2)
             await asyncio.sleep(1e-4)
             await asyncio.sleep(1e-6)
diff --git a/Lib/test/test_asyncio/test_sendfile.py b/Lib/test/test_asyncio/test_sendfile.py
index 0198da21d7..d33ff197bb 100644
--- a/Lib/test/test_asyncio/test_sendfile.py
+++ b/Lib/test/test_asyncio/test_sendfile.py
@@ -470,8 +470,11 @@ def test_sendfile_close_peer_in_the_middle_of_receiving(self):
 
         self.assertTrue(1024 <= srv_proto.nbytes < len(self.DATA),
                         srv_proto.nbytes)
-        self.assertTrue(1024 <= self.file.tell() < len(self.DATA),
-                        self.file.tell())
+        if not (sys.platform == 'win32'
+                and isinstance(self.loop, asyncio.ProactorEventLoop)):
+            # On Windows, Proactor uses transmitFile, which does not update tell()
+            self.assertTrue(1024 <= self.file.tell() < len(self.DATA),
+                            self.file.tell())
         self.assertTrue(cli_proto.transport.is_closing())
 
     def test_sendfile_fallback_close_peer_in_the_middle_of_receiving(self):
diff --git a/Lib/test/test_asyncio/test_server.py b/Lib/test/test_asyncio/test_server.py
index 06d8b60f21..7ff3f55f4f 100644
--- a/Lib/test/test_asyncio/test_server.py
+++ b/Lib/test/test_asyncio/test_server.py
@@ -122,29 +122,59 @@ async def main(srv):
 
 class TestServer2(unittest.IsolatedAsyncioTestCase):
 
-    async def test_wait_closed(self):
+    async def test_wait_closed_basic(self):
         async def serve(*args):
             pass
 
         srv = await asyncio.start_server(serve, socket_helper.HOSTv4, 0)
+        self.addCleanup(srv.close)
 
-        # active count = 0
+        # active count = 0, not closed: should block
         task1 = asyncio.create_task(srv.wait_closed())
         await asyncio.sleep(0)
-        self.assertTrue(task1.done())
+        self.assertFalse(task1.done())
 
-        # active count != 0
+        # active count != 0, not closed: should block
         srv._attach()
         task2 = asyncio.create_task(srv.wait_closed())
         await asyncio.sleep(0)
+        self.assertFalse(task1.done())
         self.assertFalse(task2.done())
 
         srv.close()
         await asyncio.sleep(0)
+        # active count != 0, closed: should block
+        task3 = asyncio.create_task(srv.wait_closed())
+        await asyncio.sleep(0)
+        self.assertFalse(task1.done())
         self.assertFalse(task2.done())
+        self.assertFalse(task3.done())
 
         srv._detach()
+        # active count == 0, closed: should unblock
+        await task1
         await task2
+        await task3
+        await srv.wait_closed()  # Return immediately
+
+    async def test_wait_closed_race(self):
+        # Test a regression in 3.12.0, should be fixed in 3.12.1
+        async def serve(*args):
+            pass
+
+        srv = await asyncio.start_server(serve, socket_helper.HOSTv4, 0)
+        self.addCleanup(srv.close)
+
+        task = asyncio.create_task(srv.wait_closed())
+        await asyncio.sleep(0)
+        self.assertFalse(task.done())
+        srv._attach()
+        loop = asyncio.get_running_loop()
+        loop.call_soon(srv.close)
+        loop.call_soon(srv._detach)
+        await srv.wait_closed()
+
+
 
 
 @unittest.skipUnless(hasattr(asyncio, 'ProactorEventLoop'), 'Windows only')
diff --git a/Lib/test/test_asyncio/test_streams.py b/Lib/test/test_asyncio/test_streams.py
index 7f9dc62180..5a22232c00 100644
--- a/Lib/test/test_asyncio/test_streams.py
+++ b/Lib/test/test_asyncio/test_streams.py
@@ -37,8 +37,7 @@ def tearDown(self):
         # just in case if we have transport close callbacks
         test_utils.run_briefly(self.loop)
 
-        self.loop.close()
-        gc.collect()
+        # set_event_loop() takes care of closing self.loop in a safe way
         super().tearDown()
 
     def _basetest_open_connection(self, open_connection_fut):
@@ -1074,6 +1073,37 @@ def test_eof_feed_when_closing_writer(self):
 
         self.assertEqual(messages, [])
 
+    def test_unhandled_exceptions(self) -> None:
+        port = socket_helper.find_unused_port()
+
+        messages = []
+        self.loop.set_exception_handler(lambda loop, ctx: messages.append(ctx))
+
+        async def client():
+            rd, wr = await asyncio.open_connection('localhost', port)
+            wr.write(b'test msg')
+            await wr.drain()
+            wr.close()
+            await wr.wait_closed()
+
+        async def main():
+            async def handle_echo(reader, writer):
+                raise Exception('test')
+
+            server = await asyncio.start_server(
+                handle_echo, 'localhost', port)
+            await server.start_serving()
+            await client()
+            server.close()
+            await server.wait_closed()
+
+        self.loop.run_until_complete(main())
+
+        self.assertEqual(messages[0]['message'],
+                         'Unhandled exception in client_connected_cb')
+        # Break explicitly reference cycle
+        messages = None
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_asyncio/test_subprocess.py b/Lib/test/test_asyncio/test_subprocess.py
index eeeca40c15..179c8cb8cc 100644
--- a/Lib/test/test_asyncio/test_subprocess.py
+++ b/Lib/test/test_asyncio/test_subprocess.py
@@ -1,6 +1,7 @@
 import os
 import signal
 import sys
+import textwrap
 import unittest
 import warnings
 from unittest import mock
@@ -12,9 +13,13 @@
 from test import support
 from test.support import os_helper
 
-if sys.platform != 'win32':
+
+if support.MS_WINDOWS:
+    import msvcrt
+else:
     from asyncio import unix_events
 
+
 if support.check_sanitizer(address=True):
     raise unittest.SkipTest("Exposes ASAN flakiness in GitHub CI")
 
@@ -270,26 +275,43 @@ async def send_signal(proc):
         finally:
             signal.signal(signal.SIGHUP, old_handler)
 
-    def prepare_broken_pipe_test(self):
+    def test_stdin_broken_pipe(self):
         # buffer large enough to feed the whole pipe buffer
         large_data = b'x' * support.PIPE_MAX_SIZE
 
+        rfd, wfd = os.pipe()
+        self.addCleanup(os.close, rfd)
+        self.addCleanup(os.close, wfd)
+        if support.MS_WINDOWS:
+            handle = msvcrt.get_osfhandle(rfd)
+            os.set_handle_inheritable(handle, True)
+            code = textwrap.dedent(f'''
+                import os, msvcrt
+                handle = {handle}
+                fd = msvcrt.open_osfhandle(handle, os.O_RDONLY)
+                os.read(fd, 1)
+            ''')
+            from subprocess import STARTUPINFO
+            startupinfo = STARTUPINFO()
+            startupinfo.lpAttributeList = {"handle_list": [handle]}
+            kwargs = dict(startupinfo=startupinfo)
+        else:
+            code = f'import os; fd = {rfd}; os.read(fd, 1)'
+            kwargs = dict(pass_fds=(rfd,))
+
         # the program ends before the stdin can be fed
         proc = self.loop.run_until_complete(
             asyncio.create_subprocess_exec(
-                sys.executable, '-c', 'pass',
+                sys.executable, '-c', code,
                 stdin=subprocess.PIPE,
+                **kwargs
             )
         )
 
-        return (proc, large_data)
-
-    def test_stdin_broken_pipe(self):
-        proc, large_data = self.prepare_broken_pipe_test()
-
         async def write_stdin(proc, data):
-            await asyncio.sleep(0.5)
             proc.stdin.write(data)
+            # Only exit the child process once the write buffer is filled
+            os.write(wfd, b'go')
             await proc.stdin.drain()
 
         coro = write_stdin(proc, large_data)
@@ -300,7 +322,16 @@ async def write_stdin(proc, data):
         self.loop.run_until_complete(proc.wait())
 
     def test_communicate_ignore_broken_pipe(self):
-        proc, large_data = self.prepare_broken_pipe_test()
+        # buffer large enough to feed the whole pipe buffer
+        large_data = b'x' * support.PIPE_MAX_SIZE
+
+        # the program ends before the stdin can be fed
+        proc = self.loop.run_until_complete(
+            asyncio.create_subprocess_exec(
+                sys.executable, '-c', 'pass',
+                stdin=subprocess.PIPE,
+            )
+        )
 
         # communicate() must ignore BrokenPipeError when feeding stdin
         self.loop.set_exception_handler(lambda loop, msg: None)
@@ -753,21 +784,44 @@ async def main() -> None:
 
         self.loop.run_until_complete(main())
 
-    def test_subprocess_consistent_callbacks(self):
+    def test_subprocess_protocol_events(self):
+        # gh-108973: Test that all subprocess protocol methods are called.
+        # The protocol methods are not called in a determistic order.
+        # The order depends on the event loop and the operating system.
         events = []
+        fds = [1, 2]
+        expected = [
+            ('pipe_data_received', 1, b'stdout'),
+            ('pipe_data_received', 2, b'stderr'),
+            ('pipe_connection_lost', 1),
+            ('pipe_connection_lost', 2),
+            'process_exited',
+        ]
+        per_fd_expected = [
+            'pipe_data_received',
+            'pipe_connection_lost',
+        ]
+
         class MyProtocol(asyncio.SubprocessProtocol):
             def __init__(self, exit_future: asyncio.Future) -> None:
                 self.exit_future = exit_future
 
             def pipe_data_received(self, fd, data) -> None:
                 events.append(('pipe_data_received', fd, data))
+                self.exit_maybe()
 
             def pipe_connection_lost(self, fd, exc) -> None:
-                events.append('pipe_connection_lost')
+                events.append(('pipe_connection_lost', fd))
+                self.exit_maybe()
 
             def process_exited(self) -> None:
                 events.append('process_exited')
-                self.exit_future.set_result(True)
+                self.exit_maybe()
+
+            def exit_maybe(self):
+                # Only exit when we got all expected events
+                if len(events) >= len(expected):
+                    self.exit_future.set_result(True)
 
         async def main() -> None:
             loop = asyncio.get_running_loop()
@@ -777,15 +831,24 @@ async def main() -> None:
                                                       sys.executable, '-c', code, stdin=None)
             await exit_future
             transport.close()
-            self.assertEqual(events, [
-                ('pipe_data_received', 1, b'stdout'),
-                ('pipe_data_received', 2, b'stderr'),
-                'pipe_connection_lost',
-                'pipe_connection_lost',
-                'process_exited',
-            ])
 
-        self.loop.run_until_complete(main())
+            return events
+
+        events = self.loop.run_until_complete(main())
+
+        # First, make sure that we received all events
+        self.assertSetEqual(set(events), set(expected))
+
+        # Second, check order of pipe events per file descriptor
+        per_fd_events = {fd: [] for fd in fds}
+        for event in events:
+            if event == 'process_exited':
+                continue
+            name, fd = event[:2]
+            per_fd_events[fd].append(name)
+
+        for fd in fds:
+            self.assertEqual(per_fd_events[fd], per_fd_expected, (fd, events))
 
     def test_subprocess_communicate_stdout(self):
         # See https://github.com/python/cpython/issues/100133
diff --git a/Lib/test/test_asyncio/test_taskgroups.py b/Lib/test/test_asyncio/test_taskgroups.py
index 6a0231f285..7a18362b54 100644
--- a/Lib/test/test_asyncio/test_taskgroups.py
+++ b/Lib/test/test_asyncio/test_taskgroups.py
@@ -8,6 +8,8 @@
 from asyncio import taskgroups
 import unittest
 
+from test.test_asyncio.utils import await_without_task
+
 
 # To prevent a warning "test altered the execution environment"
 def tearDownModule():
@@ -779,6 +781,49 @@ async def main():
 
         await asyncio.create_task(main())
 
+    async def test_taskgroup_already_entered(self):
+        tg = taskgroups.TaskGroup()
+        async with tg:
+            with self.assertRaisesRegex(RuntimeError, "has already been entered"):
+                async with tg:
+                    pass
+
+    async def test_taskgroup_double_enter(self):
+        tg = taskgroups.TaskGroup()
+        async with tg:
+            pass
+        with self.assertRaisesRegex(RuntimeError, "has already been entered"):
+            async with tg:
+                pass
+
+    async def test_taskgroup_finished(self):
+        tg = taskgroups.TaskGroup()
+        async with tg:
+            pass
+        coro = asyncio.sleep(0)
+        with self.assertRaisesRegex(RuntimeError, "is finished"):
+            tg.create_task(coro)
+        # We still have to await coro to avoid a warning
+        await coro
+
+    async def test_taskgroup_not_entered(self):
+        tg = taskgroups.TaskGroup()
+        coro = asyncio.sleep(0)
+        with self.assertRaisesRegex(RuntimeError, "has not been entered"):
+            tg.create_task(coro)
+        # We still have to await coro to avoid a warning
+        await coro
+
+    async def test_taskgroup_without_parent_task(self):
+        tg = taskgroups.TaskGroup()
+        with self.assertRaisesRegex(RuntimeError, "parent task"):
+            await await_without_task(tg.__aenter__())
+        coro = asyncio.sleep(0)
+        with self.assertRaisesRegex(RuntimeError, "has not been entered"):
+            tg.create_task(coro)
+        # We still have to await coro to avoid a warning
+        await coro
+
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_asyncio/test_timeouts.py b/Lib/test/test_asyncio/test_timeouts.py
index 8b6b9a1fea..f54e79e4d8 100644
--- a/Lib/test/test_asyncio/test_timeouts.py
+++ b/Lib/test/test_asyncio/test_timeouts.py
@@ -5,11 +5,12 @@
 
 import asyncio
 
+from test.test_asyncio.utils import await_without_task
+
 
 def tearDownModule():
     asyncio.set_event_loop_policy(None)
 
-
 class TimeoutTests(unittest.IsolatedAsyncioTestCase):
 
     async def test_timeout_basic(self):
@@ -46,7 +47,6 @@ async def test_nested_timeouts(self):
         self.assertTrue(cm2.expired())
 
     async def test_waiter_cancelled(self):
-        loop = asyncio.get_running_loop()
         cancelled = False
         with self.assertRaises(TimeoutError):
             async with asyncio.timeout(0.01):
@@ -59,39 +59,26 @@ async def test_waiter_cancelled(self):
 
     async def test_timeout_not_called(self):
         loop = asyncio.get_running_loop()
-        t0 = loop.time()
         async with asyncio.timeout(10) as cm:
             await asyncio.sleep(0.01)
         t1 = loop.time()
 
         self.assertFalse(cm.expired())
-        # 2 sec for slow CI boxes
-        self.assertLess(t1-t0, 2)
         self.assertGreater(cm.when(), t1)
 
     async def test_timeout_disabled(self):
-        loop = asyncio.get_running_loop()
-        t0 = loop.time()
         async with asyncio.timeout(None) as cm:
             await asyncio.sleep(0.01)
-        t1 = loop.time()
 
         self.assertFalse(cm.expired())
         self.assertIsNone(cm.when())
-        # 2 sec for slow CI boxes
-        self.assertLess(t1-t0, 2)
 
     async def test_timeout_at_disabled(self):
-        loop = asyncio.get_running_loop()
-        t0 = loop.time()
         async with asyncio.timeout_at(None) as cm:
             await asyncio.sleep(0.01)
-        t1 = loop.time()
 
         self.assertFalse(cm.expired())
         self.assertIsNone(cm.when())
-        # 2 sec for slow CI boxes
-        self.assertLess(t1-t0, 2)
 
     async def test_timeout_zero(self):
         loop = asyncio.get_running_loop()
@@ -101,8 +88,6 @@ async def test_timeout_zero(self):
                 await asyncio.sleep(10)
         t1 = loop.time()
         self.assertTrue(cm.expired())
-        # 2 sec for slow CI boxes
-        self.assertLess(t1-t0, 2)
         self.assertTrue(t0 <= cm.when() <= t1)
 
     async def test_timeout_zero_sleep_zero(self):
@@ -113,8 +98,6 @@ async def test_timeout_zero_sleep_zero(self):
                 await asyncio.sleep(0)
         t1 = loop.time()
         self.assertTrue(cm.expired())
-        # 2 sec for slow CI boxes
-        self.assertLess(t1-t0, 2)
         self.assertTrue(t0 <= cm.when() <= t1)
 
     async def test_timeout_in_the_past_sleep_zero(self):
@@ -125,8 +108,6 @@ async def test_timeout_in_the_past_sleep_zero(self):
                 await asyncio.sleep(0)
         t1 = loop.time()
         self.assertTrue(cm.expired())
-        # 2 sec for slow CI boxes
-        self.assertLess(t1-t0, 2)
         self.assertTrue(t0 >= cm.when() <= t1)
 
     async def test_foreign_exception_passed(self):
@@ -277,6 +258,51 @@ async def test_timeout_exception_cause (self):
         cause = exc.exception.__cause__
         assert isinstance(cause, asyncio.CancelledError)
 
+    async def test_timeout_already_entered(self):
+        async with asyncio.timeout(0.01) as cm:
+            with self.assertRaisesRegex(RuntimeError, "has already been entered"):
+                async with cm:
+                    pass
+
+    async def test_timeout_double_enter(self):
+        async with asyncio.timeout(0.01) as cm:
+            pass
+        with self.assertRaisesRegex(RuntimeError, "has already been entered"):
+            async with cm:
+                pass
+
+    async def test_timeout_finished(self):
+        async with asyncio.timeout(0.01) as cm:
+            pass
+        with self.assertRaisesRegex(RuntimeError, "finished"):
+            cm.reschedule(0.02)
+
+    async def test_timeout_expired(self):
+        with self.assertRaises(TimeoutError):
+            async with asyncio.timeout(0.01) as cm:
+                await asyncio.sleep(1)
+        with self.assertRaisesRegex(RuntimeError, "expired"):
+            cm.reschedule(0.02)
+
+    async def test_timeout_expiring(self):
+        async with asyncio.timeout(0.01) as cm:
+            with self.assertRaises(asyncio.CancelledError):
+                await asyncio.sleep(1)
+            with self.assertRaisesRegex(RuntimeError, "expiring"):
+                cm.reschedule(0.02)
+
+    async def test_timeout_not_entered(self):
+        cm = asyncio.timeout(0.01)
+        with self.assertRaisesRegex(RuntimeError, "has not been entered"):
+            cm.reschedule(0.02)
+
+    async def test_timeout_without_task(self):
+        cm = asyncio.timeout(0.01)
+        with self.assertRaisesRegex(RuntimeError, "task"):
+            await await_without_task(cm.__aenter__())
+        with self.assertRaisesRegex(RuntimeError, "has not been entered"):
+            cm.reschedule(0.02)
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_asyncio/test_unix_events.py b/Lib/test/test_asyncio/test_unix_events.py
index cdf3eaac68..d2c8cba6ac 100644
--- a/Lib/test/test_asyncio/test_unix_events.py
+++ b/Lib/test/test_asyncio/test_unix_events.py
@@ -4,6 +4,7 @@
 import errno
 import io
 import multiprocessing
+from multiprocessing.util import _cleanup_tests as multiprocessing_cleanup_tests
 import os
 import pathlib
 import signal
@@ -11,9 +12,12 @@
 import stat
 import sys
 import threading
+import time
 import unittest
 from unittest import mock
 import warnings
+
+from test import support
 from test.support import os_helper
 from test.support import socket_helper
 from test.support import wait_process
@@ -1901,6 +1905,8 @@ async def test_fork_not_share_event_loop(self):
 
     @hashlib_helper.requires_hashdigest('md5')
     def test_fork_signal_handling(self):
+        self.addCleanup(multiprocessing_cleanup_tests)
+
         # Sending signal to the forked process should not affect the parent
         # process
         ctx = multiprocessing.get_context('fork')
@@ -1911,8 +1917,14 @@ def test_fork_signal_handling(self):
         parent_handled = manager.Event()
 
         def child_main():
-            signal.signal(signal.SIGTERM, lambda *args: child_handled.set())
+            def on_sigterm(*args):
+                child_handled.set()
+                sys.exit()
+
+            signal.signal(signal.SIGTERM, on_sigterm)
             child_started.set()
+            while True:
+                time.sleep(1)
 
         async def main():
             loop = asyncio.get_running_loop()
@@ -1922,7 +1934,7 @@ async def main():
             process.start()
             child_started.wait()
             os.kill(process.pid, signal.SIGTERM)
-            process.join()
+            process.join(timeout=support.SHORT_TIMEOUT)
 
             async def func():
                 await asyncio.sleep(0.1)
@@ -1933,11 +1945,14 @@ async def func():
 
         asyncio.run(main())
 
+        child_handled.wait(timeout=support.SHORT_TIMEOUT)
         self.assertFalse(parent_handled.is_set())
         self.assertTrue(child_handled.is_set())
 
     @hashlib_helper.requires_hashdigest('md5')
     def test_fork_asyncio_run(self):
+        self.addCleanup(multiprocessing_cleanup_tests)
+
         ctx = multiprocessing.get_context('fork')
         manager = ctx.Manager()
         self.addCleanup(manager.shutdown)
@@ -1955,6 +1970,8 @@ async def child_main():
 
     @hashlib_helper.requires_hashdigest('md5')
     def test_fork_asyncio_subprocess(self):
+        self.addCleanup(multiprocessing_cleanup_tests)
+
         ctx = multiprocessing.get_context('fork')
         manager = ctx.Manager()
         self.addCleanup(manager.shutdown)
diff --git a/Lib/test/test_asyncio/test_waitfor.py b/Lib/test/test_asyncio/test_waitfor.py
index d5c02ba4a0..d52f32534a 100644
--- a/Lib/test/test_asyncio/test_waitfor.py
+++ b/Lib/test/test_asyncio/test_waitfor.py
@@ -1,6 +1,7 @@
 import asyncio
 import unittest
 import time
+from test import support
 
 
 def tearDownModule():
@@ -65,17 +66,12 @@ async def test_wait_for_timeout_less_then_0_or_0_future_done(self):
         fut = loop.create_future()
         fut.set_result('done')
 
-        t0 = loop.time()
         ret = await asyncio.wait_for(fut, 0)
-        t1 = loop.time()
 
         self.assertEqual(ret, 'done')
         self.assertTrue(fut.done())
-        self.assertLess(t1 - t0, 0.1)
 
     async def test_wait_for_timeout_less_then_0_or_0_coroutine_do_not_started(self):
-        loop = asyncio.get_running_loop()
-
         foo_started = False
 
         async def foo():
@@ -83,12 +79,9 @@ async def foo():
             foo_started = True
 
         with self.assertRaises(asyncio.TimeoutError):
-            t0 = loop.time()
             await asyncio.wait_for(foo(), 0)
-        t1 = loop.time()
 
         self.assertEqual(foo_started, False)
-        self.assertLess(t1 - t0, 0.1)
 
     async def test_wait_for_timeout_less_then_0_or_0(self):
         loop = asyncio.get_running_loop()
@@ -112,25 +105,21 @@ async def foo():
                 await started
 
                 with self.assertRaises(asyncio.TimeoutError):
-                    t0 = loop.time()
                     await asyncio.wait_for(fut, timeout)
-                t1 = loop.time()
 
                 self.assertTrue(fut.done())
                 # it should have been cancelled due to the timeout
                 self.assertTrue(fut.cancelled())
                 self.assertEqual(foo_running, False)
-                self.assertLess(t1 - t0, 0.1)
 
     async def test_wait_for(self):
-        loop = asyncio.get_running_loop()
         foo_running = None
 
         async def foo():
             nonlocal foo_running
             foo_running = True
             try:
-                await asyncio.sleep(10)
+                await asyncio.sleep(support.LONG_TIMEOUT)
             finally:
                 foo_running = False
             return 'done'
@@ -138,13 +127,10 @@ async def foo():
         fut = asyncio.create_task(foo())
 
         with self.assertRaises(asyncio.TimeoutError):
-            t0 = loop.time()
             await asyncio.wait_for(fut, 0.1)
-        t1 = loop.time()
         self.assertTrue(fut.done())
         # it should have been cancelled due to the timeout
         self.assertTrue(fut.cancelled())
-        self.assertLess(t1 - t0, 0.5)
         self.assertEqual(foo_running, False)
 
     async def test_wait_for_blocking(self):
diff --git a/Lib/test/test_asyncio/test_windows_events.py b/Lib/test/test_asyncio/test_windows_events.py
index a36119a800..6e6c90a247 100644
--- a/Lib/test/test_asyncio/test_windows_events.py
+++ b/Lib/test/test_asyncio/test_windows_events.py
@@ -163,29 +163,25 @@ def test_wait_for_handle(self):
 
         # Wait for unset event with 0.5s timeout;
         # result should be False at timeout
-        fut = self.loop._proactor.wait_for_handle(event, 0.5)
+        timeout = 0.5
+        fut = self.loop._proactor.wait_for_handle(event, timeout)
         start = self.loop.time()
         done = self.loop.run_until_complete(fut)
         elapsed = self.loop.time() - start
 
         self.assertEqual(done, False)
         self.assertFalse(fut.result())
-        # bpo-31008: Tolerate only 450 ms (at least 500 ms expected),
-        # because of bad clock resolution on Windows
-        self.assertTrue(0.45 <= elapsed <= 0.9, elapsed)
+        self.assertGreaterEqual(elapsed, timeout - test_utils.CLOCK_RES)
 
         _overlapped.SetEvent(event)
 
         # Wait for set event;
         # result should be True immediately
         fut = self.loop._proactor.wait_for_handle(event, 10)
-        start = self.loop.time()
         done = self.loop.run_until_complete(fut)
-        elapsed = self.loop.time() - start
 
         self.assertEqual(done, True)
         self.assertTrue(fut.result())
-        self.assertTrue(0 <= elapsed < 0.3, elapsed)
 
         # asyncio issue #195: cancelling a done _WaitHandleFuture
         # must not crash
@@ -199,11 +195,8 @@ def test_wait_for_handle_cancel(self):
         # CancelledError should be raised immediately
         fut = self.loop._proactor.wait_for_handle(event, 10)
         fut.cancel()
-        start = self.loop.time()
         with self.assertRaises(asyncio.CancelledError):
             self.loop.run_until_complete(fut)
-        elapsed = self.loop.time() - start
-        self.assertTrue(0 <= elapsed < 0.1, elapsed)
 
         # asyncio issue #195: cancelling a _WaitHandleFuture twice
         # must not crash
diff --git a/Lib/test/test_asyncio/utils.py b/Lib/test/test_asyncio/utils.py
index 6dee5bb33b..ac8a8b449d 100644
--- a/Lib/test/test_asyncio/utils.py
+++ b/Lib/test/test_asyncio/utils.py
@@ -36,21 +36,27 @@
 from test.support import threading_helper
 
 
-def data_file(filename):
+# Use the maximum known clock resolution (gh-75191, gh-110088): Windows
+# GetTickCount64() has a resolution of 15.6 ms. Use 50 ms to tolerate rounding
+# issues.
+CLOCK_RES = 0.050
+
+
+def data_file(*filename):
     if hasattr(support, 'TEST_HOME_DIR'):
-        fullname = os.path.join(support.TEST_HOME_DIR, filename)
+        fullname = os.path.join(support.TEST_HOME_DIR, *filename)
         if os.path.isfile(fullname):
             return fullname
-    fullname = os.path.join(os.path.dirname(__file__), '..', filename)
+    fullname = os.path.join(os.path.dirname(__file__), '..', *filename)
     if os.path.isfile(fullname):
         return fullname
-    raise FileNotFoundError(filename)
+    raise FileNotFoundError(os.path.join(filename))
 
 
-ONLYCERT = data_file('ssl_cert.pem')
-ONLYKEY = data_file('ssl_key.pem')
-SIGNED_CERTFILE = data_file('keycert3.pem')
-SIGNING_CA = data_file('pycacert.pem')
+ONLYCERT = data_file('certdata', 'ssl_cert.pem')
+ONLYKEY = data_file('certdata', 'ssl_key.pem')
+SIGNED_CERTFILE = data_file('certdata', 'keycert3.pem')
+SIGNING_CA = data_file('certdata', 'pycacert.pem')
 PEERCERT = {
     'OCSP': ('http://testca.pythontest.net/testca/ocsp/',),
     'caIssuers': ('http://testca.pythontest.net/testca/pycacert.cer',),
@@ -541,6 +547,7 @@ def close_loop(loop):
             else:
                 loop._default_executor.shutdown(wait=True)
         loop.close()
+
         policy = support.maybe_get_event_loop_policy()
         if policy is not None:
             try:
@@ -552,9 +559,13 @@ def close_loop(loop):
                 pass
             else:
                 if isinstance(watcher, asyncio.ThreadedChildWatcher):
-                    threads = list(watcher._threads.values())
-                    for thread in threads:
-                        thread.join()
+                    # Wait for subprocess to finish, but not forever
+                    for thread in list(watcher._threads.values()):
+                        thread.join(timeout=support.SHORT_TIMEOUT)
+                        if thread.is_alive():
+                            raise RuntimeError(f"thread {thread} still alive: "
+                                               "subprocess still running")
+
 
     def set_event_loop(self, loop, *, cleanup=True):
         if loop is None:
@@ -607,3 +618,18 @@ def mock_nonblocking_socket(proto=socket.IPPROTO_TCP, type=socket.SOCK_STREAM,
     sock.family = family
     sock.gettimeout.return_value = 0.0
     return sock
+
+
+async def await_without_task(coro):
+    exc = None
+    def func():
+        try:
+            for _ in coro.__await__():
+                pass
+        except BaseException as err:
+            nonlocal exc
+            exc = err
+    asyncio.get_running_loop().call_soon(func)
+    await asyncio.sleep(0)
+    if exc is not None:
+        raise exc
diff --git a/Lib/test/test_binascii.py b/Lib/test/test_binascii.py
index a2d7d0293c..8897c4c6c6 100644
--- a/Lib/test/test_binascii.py
+++ b/Lib/test/test_binascii.py
@@ -428,6 +428,12 @@ def test_b2a_base64_newline(self):
         self.assertEqual(binascii.b2a_base64(b, newline=False),
                          b'aGVsbG8=')
 
+    def test_c_contiguity(self):
+        m = memoryview(bytearray(b'noncontig'))
+        noncontig_writable = m[::-2]
+        with self.assertRaises(BufferError):
+            binascii.b2a_hex(noncontig_writable)
+
 
 class ArrayBinASCIITest(BinASCIITest):
     def type2test(self, s):
diff --git a/Lib/test/test_builtin.py b/Lib/test/test_builtin.py
index daac100882..78d5354f9c 100644
--- a/Lib/test/test_builtin.py
+++ b/Lib/test/test_builtin.py
@@ -2178,8 +2178,6 @@ def _run_child(self, child, terminal_input):
         if pid == 0:
             # Child
             try:
-                # Make sure we don't get stuck if there's a problem
-                signal.alarm(2)
                 os.close(r)
                 with open(w, "w") as wpipe:
                     child(wpipe)
diff --git a/Lib/test/test_capi/test_abstract.py b/Lib/test/test_capi/test_abstract.py
index 116edd8d4d..d01ee66ed4 100644
--- a/Lib/test/test_capi/test_abstract.py
+++ b/Lib/test/test_capi/test_abstract.py
@@ -1,10 +1,10 @@
 import unittest
 import sys
 from collections import OrderedDict
-from test import support
 from test.support import import_helper
-import _testcapi
 
+_testcapi = import_helper.import_module('_testcapi')
+from _testcapi import PY_SSIZE_T_MIN, PY_SSIZE_T_MAX
 
 NULL = None
 
@@ -446,6 +446,8 @@ def test_sequence_getitem(self):
         self.assertEqual(getitem(lst, 1), 'b')
         self.assertEqual(getitem(lst, -1), 'c')
         self.assertRaises(IndexError, getitem, lst, 3)
+        self.assertRaises(IndexError, getitem, lst, PY_SSIZE_T_MAX)
+        self.assertRaises(IndexError, getitem, lst, PY_SSIZE_T_MIN)
 
         self.assertRaises(TypeError, getitem, 42, 1)
         self.assertRaises(TypeError, getitem, {}, 1)
@@ -470,6 +472,9 @@ def test_sequence_repeat(self):
         self.assertEqual(repeat(('a', 'b'), 2), ('a', 'b', 'a', 'b'))
         self.assertEqual(repeat(['a', 'b'], 0), [])
         self.assertEqual(repeat(['a', 'b'], -1), [])
+        self.assertEqual(repeat(['a', 'b'], PY_SSIZE_T_MIN), [])
+        self.assertEqual(repeat([], PY_SSIZE_T_MAX), [])
+        self.assertRaises(MemoryError, repeat, ['a', 'b'], PY_SSIZE_T_MAX)
 
         self.assertRaises(TypeError, repeat, set(), 2)
         self.assertRaises(TypeError, repeat, 42, 2)
@@ -503,6 +508,9 @@ def test_sequence_inplacerepeat(self):
         self.assertEqual(inplacerepeat(('a', 'b'), 2), ('a', 'b', 'a', 'b'))
         self.assertEqual(inplacerepeat(['a', 'b'], 0), [])
         self.assertEqual(inplacerepeat(['a', 'b'], -1), [])
+        self.assertEqual(inplacerepeat(['a', 'b'], PY_SSIZE_T_MIN), [])
+        self.assertEqual(inplacerepeat([], PY_SSIZE_T_MAX), [])
+        self.assertRaises(MemoryError, inplacerepeat, ['a', 'b'], PY_SSIZE_T_MAX)
 
         self.assertRaises(TypeError, inplacerepeat, set(), 2)
         self.assertRaises(TypeError, inplacerepeat, 42, 2)
@@ -519,6 +527,8 @@ def test_sequence_setitem(self):
         setitem(lst, 0, NULL)
         self.assertEqual(lst, ['x', 'y'])
         self.assertRaises(IndexError, setitem, lst, 3, 'x')
+        self.assertRaises(IndexError, setitem, lst, PY_SSIZE_T_MAX, 'x')
+        self.assertRaises(IndexError, setitem, lst, PY_SSIZE_T_MIN, 'x')
 
         self.assertRaises(TypeError, setitem, 42, 1, 'x')
         self.assertRaises(TypeError, setitem, {}, 1, 'x')
@@ -532,6 +542,8 @@ def test_sequence_delitem(self):
         delitem(lst, -1)
         self.assertEqual(lst, ['a'])
         self.assertRaises(IndexError, delitem, lst, 3)
+        self.assertRaises(IndexError, delitem, lst, PY_SSIZE_T_MAX)
+        self.assertRaises(IndexError, delitem, lst, PY_SSIZE_T_MIN)
 
         self.assertRaises(TypeError, delitem, 42, 1)
         self.assertRaises(TypeError, delitem, {}, 1)
@@ -541,13 +553,19 @@ def test_sequence_setslice(self):
         setslice = _testcapi.sequence_setslice
 
         # Correct case:
-        data = [1, 2, 3, 4, 5]
-        data_copy = data.copy()
-
-        setslice(data, 1, 3, [8, 9])
-        data_copy[1:3] = [8, 9]
-        self.assertEqual(data, data_copy)
-        self.assertEqual(data, [1, 8, 9, 4, 5])
+        for start in [*range(-6, 7), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX]:
+            for stop in [*range(-6, 7), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX]:
+                data = [1, 2, 3, 4, 5]
+                data_copy = [1, 2, 3, 4, 5]
+                setslice(data, start, stop, [8, 9])
+                data_copy[start:stop] = [8, 9]
+                self.assertEqual(data, data_copy)
+
+                data = [1, 2, 3, 4, 5]
+                data_copy = [1, 2, 3, 4, 5]
+                setslice(data, start, stop, NULL)
+                del data_copy[start:stop]
+                self.assertEqual(data, data_copy)
 
         # Custom class:
         class Custom:
@@ -573,21 +591,17 @@ def __setitem__(self, index, value):
         self.assertRaises(TypeError, setslice, object(), 1, 3, 'xy')
         self.assertRaises(SystemError, setslice, NULL, 1, 3, 'xy')
 
-        data_copy = data.copy()
-        setslice(data_copy, 1, 3, NULL)
-        self.assertEqual(data_copy, [1, 4, 5])
-
     def test_sequence_delslice(self):
         delslice = _testcapi.sequence_delslice
 
         # Correct case:
-        data = [1, 2, 3, 4, 5]
-        data_copy = data.copy()
-
-        delslice(data, 1, 3)
-        del data_copy[1:3]
-        self.assertEqual(data, data_copy)
-        self.assertEqual(data, [1, 4, 5])
+        for start in [*range(-6, 7), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX]:
+            for stop in [*range(-6, 7), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX]:
+                data = [1, 2, 3, 4, 5]
+                data_copy = [1, 2, 3, 4, 5]
+                delslice(data, start, stop)
+                del data_copy[start:stop]
+                self.assertEqual(data, data_copy)
 
         # Custom class:
         class Custom:
diff --git a/Lib/test/test_capi/test_bytearray.py b/Lib/test/test_capi/test_bytearray.py
new file mode 100644
index 0000000000..833122c4e3
--- /dev/null
+++ b/Lib/test/test_capi/test_bytearray.py
@@ -0,0 +1,164 @@
+import unittest
+from test.support import import_helper
+
+_testcapi = import_helper.import_module('_testcapi')
+from _testcapi import PY_SSIZE_T_MIN, PY_SSIZE_T_MAX
+
+NULL = None
+
+class ByteArraySubclass(bytearray):
+    pass
+
+class BytesLike:
+    def __init__(self, value):
+        self.value = value
+    def __bytes__(self):
+        return self.value
+
+
+class CAPITest(unittest.TestCase):
+    def test_check(self):
+        # Test PyByteArray_Check()
+        check = _testcapi.bytearray_check
+        self.assertTrue(check(bytearray(b'abc')))
+        self.assertFalse(check(b'abc'))
+        self.assertTrue(check(ByteArraySubclass(b'abc')))
+        self.assertFalse(check(BytesLike(b'abc')))
+        self.assertFalse(check(3))
+        self.assertFalse(check([]))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_checkexact(self):
+        # Test PyByteArray_CheckExact()
+        check = _testcapi.bytearray_checkexact
+        self.assertTrue(check(bytearray(b'abc')))
+        self.assertFalse(check(b'abc'))
+        self.assertFalse(check(ByteArraySubclass(b'abc')))
+        self.assertFalse(check(BytesLike(b'abc')))
+        self.assertFalse(check(3))
+        self.assertFalse(check([]))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_fromstringandsize(self):
+        # Test PyByteArray_FromStringAndSize()
+        fromstringandsize = _testcapi.bytearray_fromstringandsize
+
+        self.assertEqual(fromstringandsize(b'abc'), bytearray(b'abc'))
+        self.assertEqual(fromstringandsize(b'abc', 2), bytearray(b'ab'))
+        self.assertEqual(fromstringandsize(b'abc\0def'), bytearray(b'abc\0def'))
+        self.assertEqual(fromstringandsize(b'', 0), bytearray())
+        self.assertEqual(fromstringandsize(NULL, 0), bytearray())
+        self.assertEqual(len(fromstringandsize(NULL, 3)), 3)
+        self.assertRaises(MemoryError, fromstringandsize, NULL, PY_SSIZE_T_MAX)
+
+        self.assertRaises(SystemError, fromstringandsize, b'abc', -1)
+        self.assertRaises(SystemError, fromstringandsize, b'abc', PY_SSIZE_T_MIN)
+        self.assertRaises(SystemError, fromstringandsize, NULL, -1)
+        self.assertRaises(SystemError, fromstringandsize, NULL, PY_SSIZE_T_MIN)
+
+    def test_fromobject(self):
+        # Test PyByteArray_FromObject()
+        fromobject = _testcapi.bytearray_fromobject
+
+        self.assertEqual(fromobject(b'abc'), bytearray(b'abc'))
+        self.assertEqual(fromobject(bytearray(b'abc')), bytearray(b'abc'))
+        self.assertEqual(fromobject(ByteArraySubclass(b'abc')), bytearray(b'abc'))
+        self.assertEqual(fromobject([97, 98, 99]), bytearray(b'abc'))
+        self.assertEqual(fromobject(3), bytearray(b'\0\0\0'))
+        self.assertRaises(TypeError, fromobject, BytesLike(b'abc'))
+        self.assertRaises(TypeError, fromobject, 'abc')
+        self.assertRaises(TypeError, fromobject, object())
+
+        # CRASHES fromobject(NULL)
+
+    def test_size(self):
+        # Test PyByteArray_Size()
+        size = _testcapi.bytearray_size
+
+        self.assertEqual(size(bytearray(b'abc')), 3)
+        self.assertEqual(size(ByteArraySubclass(b'abc')), 3)
+
+        # CRASHES size(b'abc')
+        # CRASHES size(object())
+        # CRASHES size(NULL)
+
+    def test_asstring(self):
+        """Test PyByteArray_AsString()"""
+        asstring = _testcapi.bytearray_asstring
+
+        self.assertEqual(asstring(bytearray(b'abc'), 4), b'abc\0')
+        self.assertEqual(asstring(ByteArraySubclass(b'abc'), 4), b'abc\0')
+        self.assertEqual(asstring(bytearray(b'abc\0def'), 8), b'abc\0def\0')
+
+        # CRASHES asstring(b'abc', 0)
+        # CRASHES asstring(object()', 0)
+        # CRASHES asstring(NULL, 0)
+
+    def test_concat(self):
+        """Test PyByteArray_Concat()"""
+        concat = _testcapi.bytearray_concat
+
+        ba = bytearray(b'abc')
+        self.assertEqual(concat(ba, b'def'), bytearray(b'abcdef'))
+        self.assertEqual(ba, b'abc')
+
+        self.assertEqual(concat(b'abc', b'def'), bytearray(b'abcdef'))
+        self.assertEqual(concat(b'a\0b', b'c\0d'), bytearray(b'a\0bc\0d'))
+        self.assertEqual(concat(bytearray(b'abc'), b'def'), bytearray(b'abcdef'))
+        self.assertEqual(concat(b'abc', bytearray(b'def')), bytearray(b'abcdef'))
+        self.assertEqual(concat(bytearray(b'abc'), b''), bytearray(b'abc'))
+        self.assertEqual(concat(b'', bytearray(b'def')), bytearray(b'def'))
+        self.assertEqual(concat(memoryview(b'xabcy')[1:4], b'def'),
+                         bytearray(b'abcdef'))
+        self.assertEqual(concat(b'abc', memoryview(b'xdefy')[1:4]),
+                         bytearray(b'abcdef'))
+
+        self.assertRaises(TypeError, concat, memoryview(b'axbycz')[::2], b'def')
+        self.assertRaises(TypeError, concat, b'abc', memoryview(b'dxeyfz')[::2])
+        self.assertRaises(TypeError, concat, b'abc', 'def')
+        self.assertRaises(TypeError, concat, 'abc', b'def')
+        self.assertRaises(TypeError, concat, 'abc', 'def')
+        self.assertRaises(TypeError, concat, [], b'def')
+        self.assertRaises(TypeError, concat, b'abc', [])
+        self.assertRaises(TypeError, concat, [], [])
+
+        # CRASHES concat(NULL, bytearray(b'def'))
+        # CRASHES concat(bytearray(b'abc'), NULL)
+        # CRASHES concat(NULL, object())
+        # CRASHES concat(object(), NULL)
+
+    def test_resize(self):
+        """Test PyByteArray_Resize()"""
+        resize = _testcapi.bytearray_resize
+
+        ba = bytearray(b'abcdef')
+        self.assertEqual(resize(ba, 3), 0)
+        self.assertEqual(ba, bytearray(b'abc'))
+        self.assertEqual(resize(ba, 10), 0)
+        self.assertEqual(len(ba), 10)
+        self.assertEqual(ba[:3], bytearray(b'abc'))
+        self.assertEqual(resize(ba, 2**20), 0)
+        self.assertEqual(len(ba), 2**20)
+        self.assertEqual(ba[:3], bytearray(b'abc'))
+        self.assertEqual(resize(ba, 0), 0)
+        self.assertEqual(ba, bytearray())
+
+        ba = ByteArraySubclass(b'abcdef')
+        self.assertEqual(resize(ba, 3), 0)
+        self.assertEqual(ba, bytearray(b'abc'))
+
+        self.assertRaises(MemoryError, resize, bytearray(), PY_SSIZE_T_MAX)
+        self.assertRaises(MemoryError, resize, bytearray(1000), PY_SSIZE_T_MAX)
+
+        # CRASHES resize(bytearray(b'abc'), -1)
+        # CRASHES resize(b'abc', 0)
+        # CRASHES resize(object(), 0)
+        # CRASHES resize(NULL, 0)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_capi/test_bytes.py b/Lib/test/test_capi/test_bytes.py
new file mode 100644
index 0000000000..bb5d724ff1
--- /dev/null
+++ b/Lib/test/test_capi/test_bytes.py
@@ -0,0 +1,222 @@
+import unittest
+from test.support import import_helper
+
+_testcapi = import_helper.import_module('_testcapi')
+from _testcapi import PY_SSIZE_T_MIN, PY_SSIZE_T_MAX
+
+NULL = None
+
+class BytesSubclass(bytes):
+    pass
+
+class BytesLike:
+    def __init__(self, value):
+        self.value = value
+    def __bytes__(self):
+        return self.value
+
+
+class CAPITest(unittest.TestCase):
+    def test_check(self):
+        # Test PyBytes_Check()
+        check = _testcapi.bytes_check
+        self.assertTrue(check(b'abc'))
+        self.assertFalse(check('abc'))
+        self.assertFalse(check(bytearray(b'abc')))
+        self.assertTrue(check(BytesSubclass(b'abc')))
+        self.assertFalse(check(BytesLike(b'abc')))
+        self.assertFalse(check(3))
+        self.assertFalse(check([]))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_checkexact(self):
+        # Test PyBytes_CheckExact()
+        check = _testcapi.bytes_checkexact
+        self.assertTrue(check(b'abc'))
+        self.assertFalse(check('abc'))
+        self.assertFalse(check(bytearray(b'abc')))
+        self.assertFalse(check(BytesSubclass(b'abc')))
+        self.assertFalse(check(BytesLike(b'abc')))
+        self.assertFalse(check(3))
+        self.assertFalse(check([]))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_fromstringandsize(self):
+        # Test PyBytes_FromStringAndSize()
+        fromstringandsize = _testcapi.bytes_fromstringandsize
+
+        self.assertEqual(fromstringandsize(b'abc'), b'abc')
+        self.assertEqual(fromstringandsize(b'abc', 2), b'ab')
+        self.assertEqual(fromstringandsize(b'abc\0def'), b'abc\0def')
+        self.assertEqual(fromstringandsize(b'', 0), b'')
+        self.assertEqual(fromstringandsize(NULL, 0), b'')
+        self.assertEqual(len(fromstringandsize(NULL, 3)), 3)
+        self.assertRaises((MemoryError, OverflowError),
+                          fromstringandsize, NULL, PY_SSIZE_T_MAX)
+
+        self.assertRaises(SystemError, fromstringandsize, b'abc', -1)
+        self.assertRaises(SystemError, fromstringandsize, b'abc', PY_SSIZE_T_MIN)
+        self.assertRaises(SystemError, fromstringandsize, NULL, -1)
+        self.assertRaises(SystemError, fromstringandsize, NULL, PY_SSIZE_T_MIN)
+
+    def test_fromstring(self):
+        # Test PyBytes_FromString()
+        fromstring = _testcapi.bytes_fromstring
+
+        self.assertEqual(fromstring(b'abc\0def'), b'abc')
+        self.assertEqual(fromstring(b''), b'')
+
+        # CRASHES fromstring(NULL)
+
+    def test_fromobject(self):
+        # Test PyBytes_FromObject()
+        fromobject = _testcapi.bytes_fromobject
+
+        self.assertEqual(fromobject(b'abc'), b'abc')
+        self.assertEqual(fromobject(bytearray(b'abc')), b'abc')
+        self.assertEqual(fromobject(BytesSubclass(b'abc')), b'abc')
+        self.assertEqual(fromobject([97, 98, 99]), b'abc')
+        self.assertRaises(TypeError, fromobject, 3)
+        self.assertRaises(TypeError, fromobject, BytesLike(b'abc'))
+        self.assertRaises(TypeError, fromobject, 'abc')
+        self.assertRaises(TypeError, fromobject, object())
+        self.assertRaises(SystemError, fromobject, NULL)
+
+    def test_size(self):
+        # Test PyBytes_Size()
+        size = _testcapi.bytes_size
+
+        self.assertEqual(size(b'abc'), 3)
+        self.assertEqual(size(BytesSubclass(b'abc')), 3)
+        self.assertRaises(TypeError, size, bytearray(b'abc'))
+        self.assertRaises(TypeError, size, 'abc')
+        self.assertRaises(TypeError, size, object())
+
+        # CRASHES size(NULL)
+
+    def test_asstring(self):
+        """Test PyBytes_AsString()"""
+        asstring = _testcapi.bytes_asstring
+
+        self.assertEqual(asstring(b'abc', 4), b'abc\0')
+        self.assertEqual(asstring(b'abc\0def', 8), b'abc\0def\0')
+        self.assertRaises(TypeError, asstring, 'abc', 0)
+        self.assertRaises(TypeError, asstring, object(), 0)
+
+        # CRASHES asstring(NULL, 0)
+
+    def test_asstringandsize(self):
+        """Test PyBytes_AsStringAndSize()"""
+        asstringandsize = _testcapi.bytes_asstringandsize
+        asstringandsize_null = _testcapi.bytes_asstringandsize_null
+
+        self.assertEqual(asstringandsize(b'abc', 4), (b'abc\0', 3))
+        self.assertEqual(asstringandsize(b'abc\0def', 8), (b'abc\0def\0', 7))
+        self.assertEqual(asstringandsize_null(b'abc', 4), b'abc\0')
+        self.assertRaises(ValueError, asstringandsize_null, b'abc\0def', 8)
+        self.assertRaises(TypeError, asstringandsize, 'abc', 0)
+        self.assertRaises(TypeError, asstringandsize_null, 'abc', 0)
+        self.assertRaises(TypeError, asstringandsize, object(), 0)
+        self.assertRaises(TypeError, asstringandsize_null, object(), 0)
+
+        # CRASHES asstringandsize(NULL, 0)
+        # CRASHES asstringandsize_null(NULL, 0)
+
+    def test_repr(self):
+        # Test PyBytes_Repr()
+        bytes_repr = _testcapi.bytes_repr
+
+        self.assertEqual(bytes_repr(b'''abc''', 0), r"""b'abc'""")
+        self.assertEqual(bytes_repr(b'''abc''', 1), r"""b'abc'""")
+        self.assertEqual(bytes_repr(b'''a'b"c"d''', 0), r"""b'a\'b"c"d'""")
+        self.assertEqual(bytes_repr(b'''a'b"c"d''', 1), r"""b'a\'b"c"d'""")
+        self.assertEqual(bytes_repr(b'''a'b"c''', 0), r"""b'a\'b"c'""")
+        self.assertEqual(bytes_repr(b'''a'b"c''', 1), r"""b'a\'b"c'""")
+        self.assertEqual(bytes_repr(b'''a'b'c"d''', 0), r"""b'a\'b\'c"d'""")
+        self.assertEqual(bytes_repr(b'''a'b'c"d''', 1), r"""b'a\'b\'c"d'""")
+        self.assertEqual(bytes_repr(b'''a'b'c'd''', 0), r"""b'a\'b\'c\'d'""")
+        self.assertEqual(bytes_repr(b'''a'b'c'd''', 1), r'''b"a'b'c'd"''')
+
+        self.assertEqual(bytes_repr(BytesSubclass(b'abc'), 0), r"""b'abc'""")
+
+        # UDEFINED bytes_repr(object(), 0)
+        # CRASHES bytes_repr(NULL, 0)
+
+    def test_concat(self, concat=None):
+        """Test PyBytes_Concat()"""
+        if concat is None:
+            concat = _testcapi.bytes_concat
+
+        self.assertEqual(concat(b'abc', b'def'), b'abcdef')
+        self.assertEqual(concat(b'a\0b', b'c\0d'), b'a\0bc\0d')
+        self.assertEqual(concat(bytearray(b'abc'), b'def'), b'abcdef')
+        self.assertEqual(concat(b'abc', bytearray(b'def')), b'abcdef')
+        self.assertEqual(concat(bytearray(b'abc'), b''), b'abc')
+        self.assertEqual(concat(b'', bytearray(b'def')), b'def')
+        self.assertEqual(concat(memoryview(b'xabcy')[1:4], b'def'), b'abcdef')
+        self.assertEqual(concat(b'abc', memoryview(b'xdefy')[1:4]), b'abcdef')
+
+        self.assertEqual(concat(b'abc', b'def', True), b'abcdef')
+        self.assertEqual(concat(b'abc', bytearray(b'def'), True), b'abcdef')
+        # Check that it does not change the singleton
+        self.assertEqual(concat(bytes(), b'def', True), b'def')
+        self.assertEqual(len(bytes()), 0)
+
+        self.assertRaises(TypeError, concat, memoryview(b'axbycz')[::2], b'def')
+        self.assertRaises(TypeError, concat, b'abc', memoryview(b'dxeyfz')[::2])
+        self.assertRaises(TypeError, concat, b'abc', 'def')
+        self.assertRaises(TypeError, concat, 'abc', b'def')
+        self.assertRaises(TypeError, concat, 'abc', 'def')
+        self.assertRaises(TypeError, concat, [], b'def')
+        self.assertRaises(TypeError, concat, b'abc', [])
+        self.assertRaises(TypeError, concat, [], [])
+
+        self.assertEqual(concat(NULL, b'def'), NULL)
+        self.assertEqual(concat(b'abc', NULL), NULL)
+        self.assertEqual(concat(NULL, object()), NULL)
+        self.assertEqual(concat(object(), NULL), NULL)
+
+    def test_concatanddel(self):
+        """Test PyBytes_ConcatAndDel()"""
+        self.test_concat(_testcapi.bytes_concatanddel)
+
+    def test_decodeescape(self):
+        """Test PyBytes_DecodeEscape()"""
+        decodeescape = _testcapi.bytes_decodeescape
+
+        self.assertEqual(decodeescape(b'abc'), b'abc')
+        self.assertEqual(decodeescape(br'\t\n\r\x0b\x0c\x00\\\'\"'),
+                         b'''\t\n\r\v\f\0\\'"''')
+        self.assertEqual(decodeescape(b'\t\n\r\x0b\x0c\x00'), b'\t\n\r\v\f\0')
+        self.assertEqual(decodeescape(br'\xa1\xa2'), b'\xa1\xa2')
+        self.assertEqual(decodeescape(br'\2\24\241'), b'\x02\x14\xa1')
+        self.assertEqual(decodeescape(b'\xa1\xa2'), b'\xa1\xa2')
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(decodeescape(br'\u4f60'), br'\u4f60')
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(decodeescape(br'\z'), br'\z')
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(decodeescape(br'\541'), b'a')
+
+        for b in b'\\', br'\x', br'\xa', br'\xz', br'\xaz':
+            self.assertRaises(ValueError, decodeescape, b)
+            self.assertRaises(ValueError, decodeescape, b, 'strict')
+        self.assertEqual(decodeescape(br'x\xa', 'replace'), b'x?')
+        self.assertEqual(decodeescape(br'x\xay', 'replace'), b'x?y')
+        self.assertEqual(decodeescape(br'x\xa\xy', 'replace'), b'x??y')
+        self.assertEqual(decodeescape(br'x\xa\xy', 'ignore'), b'xy')
+        self.assertRaises(ValueError, decodeescape, b'\\', 'spam')
+        self.assertEqual(decodeescape(NULL), b'')
+        self.assertRaises(OverflowError, decodeescape, b'abc', NULL, PY_SSIZE_T_MAX)
+        self.assertRaises(OverflowError, decodeescape, NULL, NULL, PY_SSIZE_T_MAX)
+
+        # CRASHES decodeescape(b'abc', NULL, -1)
+        # CRASHES decodeescape(NULL, NULL, 1)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_capi/test_complex.py b/Lib/test/test_capi/test_complex.py
new file mode 100644
index 0000000000..9f51efb091
--- /dev/null
+++ b/Lib/test/test_capi/test_complex.py
@@ -0,0 +1,146 @@
+import unittest
+import warnings
+
+from test.test_capi.test_getargs import (BadComplex, BadComplex2, Complex,
+                                         FloatSubclass, Float, BadFloat,
+                                         BadFloat2, ComplexSubclass)
+from test.support import import_helper
+
+
+_testcapi = import_helper.import_module('_testcapi')
+
+NULL = None
+
+class BadComplex3:
+    def __complex__(self):
+        raise RuntimeError
+
+
+class CAPIComplexTest(unittest.TestCase):
+    def test_check(self):
+        # Test PyComplex_Check()
+        check = _testcapi.complex_check
+
+        self.assertTrue(check(1+2j))
+        self.assertTrue(check(ComplexSubclass(1+2j)))
+        self.assertFalse(check(Complex()))
+        self.assertFalse(check(3))
+        self.assertFalse(check(3.0))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_checkexact(self):
+        # PyComplex_CheckExact()
+        checkexact = _testcapi.complex_checkexact
+
+        self.assertTrue(checkexact(1+2j))
+        self.assertFalse(checkexact(ComplexSubclass(1+2j)))
+        self.assertFalse(checkexact(Complex()))
+        self.assertFalse(checkexact(3))
+        self.assertFalse(checkexact(3.0))
+        self.assertFalse(checkexact(object()))
+
+        # CRASHES checkexact(NULL)
+
+    def test_fromccomplex(self):
+        # Test PyComplex_FromCComplex()
+        fromccomplex = _testcapi.complex_fromccomplex
+
+        self.assertEqual(fromccomplex(1+2j), 1.0+2.0j)
+
+    def test_fromdoubles(self):
+        # Test PyComplex_FromDoubles()
+        fromdoubles = _testcapi.complex_fromdoubles
+
+        self.assertEqual(fromdoubles(1.0, 2.0), 1.0+2.0j)
+
+    def test_realasdouble(self):
+        # Test PyComplex_RealAsDouble()
+        realasdouble = _testcapi.complex_realasdouble
+
+        self.assertEqual(realasdouble(1+2j), 1.0)
+        self.assertEqual(realasdouble(-1+0j), -1.0)
+        self.assertEqual(realasdouble(4.25), 4.25)
+        self.assertEqual(realasdouble(-1.0), -1.0)
+        self.assertEqual(realasdouble(42), 42.)
+        self.assertEqual(realasdouble(-1), -1.0)
+
+        # Test subclasses of complex/float
+        self.assertEqual(realasdouble(ComplexSubclass(1+2j)), 1.0)
+        self.assertEqual(realasdouble(FloatSubclass(4.25)), 4.25)
+
+        # Test types with __complex__ dunder method
+        # Function doesn't support classes with __complex__ dunder, see #109598
+        self.assertRaises(TypeError, realasdouble, Complex())
+
+        # Test types with __float__ dunder method
+        self.assertEqual(realasdouble(Float()), 4.25)
+        self.assertRaises(TypeError, realasdouble, BadFloat())
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(realasdouble(BadFloat2()), 4.25)
+
+        self.assertRaises(TypeError, realasdouble, object())
+
+        # CRASHES realasdouble(NULL)
+
+    def test_imagasdouble(self):
+        # Test PyComplex_ImagAsDouble()
+        imagasdouble = _testcapi.complex_imagasdouble
+
+        self.assertEqual(imagasdouble(1+2j), 2.0)
+        self.assertEqual(imagasdouble(1-1j), -1.0)
+        self.assertEqual(imagasdouble(4.25), 0.0)
+        self.assertEqual(imagasdouble(42), 0.0)
+
+        # Test subclasses of complex/float
+        self.assertEqual(imagasdouble(ComplexSubclass(1+2j)), 2.0)
+        self.assertEqual(imagasdouble(FloatSubclass(4.25)), 0.0)
+
+        # Test types with __complex__ dunder method
+        # Function doesn't support classes with __complex__ dunder, see #109598
+        self.assertEqual(imagasdouble(Complex()), 0.0)
+
+        # Function returns 0.0 anyway, see #109598
+        self.assertEqual(imagasdouble(object()), 0.0)
+
+        # CRASHES imagasdouble(NULL)
+
+    def test_asccomplex(self):
+        # Test PyComplex_AsCComplex()
+        asccomplex = _testcapi.complex_asccomplex
+
+        self.assertEqual(asccomplex(1+2j), 1.0+2.0j)
+        self.assertEqual(asccomplex(-1+2j), -1.0+2.0j)
+        self.assertEqual(asccomplex(4.25), 4.25+0.0j)
+        self.assertEqual(asccomplex(-1.0), -1.0+0.0j)
+        self.assertEqual(asccomplex(42), 42+0j)
+        self.assertEqual(asccomplex(-1), -1.0+0.0j)
+
+        # Test subclasses of complex/float
+        self.assertEqual(asccomplex(ComplexSubclass(1+2j)), 1.0+2.0j)
+        self.assertEqual(asccomplex(FloatSubclass(4.25)), 4.25+0.0j)
+
+        # Test types with __complex__ dunder method
+        self.assertEqual(asccomplex(Complex()), 4.25+0.5j)
+        self.assertRaises(TypeError, asccomplex, BadComplex())
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(asccomplex(BadComplex2()), 4.25+0.5j)
+        with warnings.catch_warnings():
+            warnings.simplefilter("error", DeprecationWarning)
+            self.assertRaises(DeprecationWarning, asccomplex, BadComplex2())
+        self.assertRaises(RuntimeError, asccomplex, BadComplex3())
+
+        # Test types with __float__ dunder method
+        self.assertEqual(asccomplex(Float()), 4.25+0.0j)
+        self.assertRaises(TypeError, asccomplex, BadFloat())
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(asccomplex(BadFloat2()), 4.25+0.0j)
+
+        self.assertRaises(TypeError, asccomplex, object())
+
+        # CRASHES asccomplex(NULL)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_capi/test_exceptions.py b/Lib/test/test_capi/test_exceptions.py
index b96cc7922a..1bff65b655 100644
--- a/Lib/test/test_capi/test_exceptions.py
+++ b/Lib/test/test_capi/test_exceptions.py
@@ -17,6 +17,10 @@
 
 NULL = None
 
+class CustomError(Exception):
+    pass
+
+
 class Test_Exceptions(unittest.TestCase):
 
     def test_exception(self):
@@ -270,6 +274,47 @@ def test_setfromerrnowithfilename(self):
                          (ENOENT, 'No such file or directory', 'file'))
         # CRASHES setfromerrnowithfilename(ENOENT, NULL, b'error')
 
+    def test_err_writeunraisable(self):
+        # Test PyErr_WriteUnraisable()
+        writeunraisable = _testcapi.err_writeunraisable
+        firstline = self.test_err_writeunraisable.__code__.co_firstlineno
+
+        with support.catch_unraisable_exception() as cm:
+            writeunraisable(CustomError('oops!'), hex)
+            self.assertEqual(cm.unraisable.exc_type, CustomError)
+            self.assertEqual(str(cm.unraisable.exc_value), 'oops!')
+            self.assertEqual(cm.unraisable.exc_traceback.tb_lineno,
+                             firstline + 6)
+            self.assertIsNone(cm.unraisable.err_msg)
+            self.assertEqual(cm.unraisable.object, hex)
+
+        with support.catch_unraisable_exception() as cm:
+            writeunraisable(CustomError('oops!'), NULL)
+            self.assertEqual(cm.unraisable.exc_type, CustomError)
+            self.assertEqual(str(cm.unraisable.exc_value), 'oops!')
+            self.assertEqual(cm.unraisable.exc_traceback.tb_lineno,
+                             firstline + 15)
+            self.assertIsNone(cm.unraisable.err_msg)
+            self.assertIsNone(cm.unraisable.object)
+
+        with (support.swap_attr(sys, 'unraisablehook', None),
+              support.captured_stderr() as stderr):
+            writeunraisable(CustomError('oops!'), hex)
+        lines = stderr.getvalue().splitlines()
+        self.assertEqual(lines[0], f'Exception ignored in: {hex!r}')
+        self.assertEqual(lines[1], 'Traceback (most recent call last):')
+        self.assertEqual(lines[-1], f'{__name__}.CustomError: oops!')
+
+        with (support.swap_attr(sys, 'unraisablehook', None),
+              support.captured_stderr() as stderr):
+            writeunraisable(CustomError('oops!'), NULL)
+        lines = stderr.getvalue().splitlines()
+        self.assertEqual(lines[0], 'Traceback (most recent call last):')
+        self.assertEqual(lines[-1], f'{__name__}.CustomError: oops!')
+
+        # CRASHES writeunraisable(NULL, hex)
+        # CRASHES writeunraisable(NULL, NULL)
+
 
 class Test_PyUnstable_Exc_PrepReraiseStar(ExceptionIsLikeMixin, unittest.TestCase):
 
diff --git a/Lib/test/test_capi/test_float.py b/Lib/test/test_capi/test_float.py
new file mode 100644
index 0000000000..cb94d56264
--- /dev/null
+++ b/Lib/test/test_capi/test_float.py
@@ -0,0 +1,182 @@
+import math
+import sys
+import unittest
+import warnings
+
+from test.test_capi.test_getargs import (Float, FloatSubclass, FloatSubclass2,
+                                         BadIndex2, BadFloat2, Index, BadIndex,
+                                         BadFloat)
+from test.support import import_helper
+
+_testcapi = import_helper.import_module('_testcapi')
+
+NULL = None
+
+# For PyFloat_Pack/Unpack*
+BIG_ENDIAN = 0
+LITTLE_ENDIAN = 1
+EPSILON = {
+    2: 2.0 ** -11,  # binary16
+    4: 2.0 ** -24,  # binary32
+    8: 2.0 ** -53,  # binary64
+}
+
+HAVE_IEEE_754 = float.__getformat__("double").startswith("IEEE")
+INF = float("inf")
+NAN = float("nan")
+
+
+class CAPIFloatTest(unittest.TestCase):
+    def test_check(self):
+        # Test PyFloat_Check()
+        check = _testcapi.float_check
+
+        self.assertTrue(check(4.25))
+        self.assertTrue(check(FloatSubclass(4.25)))
+        self.assertFalse(check(Float()))
+        self.assertFalse(check(3))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_checkexact(self):
+        # Test PyFloat_CheckExact()
+        checkexact = _testcapi.float_checkexact
+
+        self.assertTrue(checkexact(4.25))
+        self.assertFalse(checkexact(FloatSubclass(4.25)))
+        self.assertFalse(checkexact(Float()))
+        self.assertFalse(checkexact(3))
+        self.assertFalse(checkexact(object()))
+
+        # CRASHES checkexact(NULL)
+
+    def test_fromstring(self):
+        # Test PyFloat_FromString()
+        fromstring = _testcapi.float_fromstring
+
+        self.assertEqual(fromstring("4.25"), 4.25)
+        self.assertEqual(fromstring(b"4.25"), 4.25)
+        self.assertRaises(ValueError, fromstring, "4.25\0")
+        self.assertRaises(ValueError, fromstring, b"4.25\0")
+
+        self.assertEqual(fromstring(bytearray(b"4.25")), 4.25)
+
+        self.assertEqual(fromstring(memoryview(b"4.25")), 4.25)
+        self.assertEqual(fromstring(memoryview(b"4.255")[:-1]), 4.25)
+        self.assertRaises(TypeError, fromstring, memoryview(b"4.25")[::2])
+
+        self.assertRaises(TypeError, fromstring, 4.25)
+
+        # CRASHES fromstring(NULL)
+
+    def test_fromdouble(self):
+        # Test PyFloat_FromDouble()
+        fromdouble = _testcapi.float_fromdouble
+
+        self.assertEqual(fromdouble(4.25), 4.25)
+
+    def test_asdouble(self):
+        # Test PyFloat_AsDouble()
+        asdouble = _testcapi.float_asdouble
+
+        class BadFloat3:
+            def __float__(self):
+                raise RuntimeError
+
+        self.assertEqual(asdouble(4.25), 4.25)
+        self.assertEqual(asdouble(-1.0), -1.0)
+        self.assertEqual(asdouble(42), 42.0)
+        self.assertEqual(asdouble(-1), -1.0)
+        self.assertEqual(asdouble(2**1000), float(2**1000))
+
+        self.assertEqual(asdouble(FloatSubclass(4.25)), 4.25)
+        self.assertEqual(asdouble(FloatSubclass2(4.25)), 4.25)
+        self.assertEqual(asdouble(Index()), 99.)
+
+        self.assertRaises(TypeError, asdouble, BadIndex())
+        self.assertRaises(TypeError, asdouble, BadFloat())
+        self.assertRaises(RuntimeError, asdouble, BadFloat3())
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(asdouble(BadIndex2()), 1.)
+        with self.assertWarns(DeprecationWarning):
+            self.assertEqual(asdouble(BadFloat2()), 4.25)
+        with warnings.catch_warnings():
+            warnings.simplefilter("error", DeprecationWarning)
+            self.assertRaises(DeprecationWarning, asdouble, BadFloat2())
+        self.assertRaises(TypeError, asdouble, object())
+        self.assertRaises(TypeError, asdouble, NULL)
+
+    def test_getinfo(self):
+        # Test PyFloat_GetInfo()
+        getinfo = _testcapi.float_getinfo
+
+        self.assertEqual(getinfo(), sys.float_info)
+
+    def test_getmax(self):
+        # Test PyFloat_GetMax()
+        getmax = _testcapi.float_getmax
+
+        self.assertEqual(getmax(), sys.float_info.max)
+
+    def test_getmin(self):
+        # Test PyFloat_GetMax()
+        getmin = _testcapi.float_getmin
+
+        self.assertEqual(getmin(), sys.float_info.min)
+
+    def test_pack(self):
+        # Test PyFloat_Pack2(), PyFloat_Pack4() and PyFloat_Pack8()
+        pack = _testcapi.float_pack
+
+        self.assertEqual(pack(2, 1.5, BIG_ENDIAN), b'>\x00')
+        self.assertEqual(pack(4, 1.5, BIG_ENDIAN), b'?\xc0\x00\x00')
+        self.assertEqual(pack(8, 1.5, BIG_ENDIAN),
+                         b'?\xf8\x00\x00\x00\x00\x00\x00')
+        self.assertEqual(pack(2, 1.5, LITTLE_ENDIAN), b'\x00>')
+        self.assertEqual(pack(4, 1.5, LITTLE_ENDIAN), b'\x00\x00\xc0?')
+        self.assertEqual(pack(8, 1.5, LITTLE_ENDIAN),
+                         b'\x00\x00\x00\x00\x00\x00\xf8?')
+
+    def test_unpack(self):
+        # Test PyFloat_Unpack2(), PyFloat_Unpack4() and PyFloat_Unpack8()
+        unpack = _testcapi.float_unpack
+
+        self.assertEqual(unpack(b'>\x00', BIG_ENDIAN), 1.5)
+        self.assertEqual(unpack(b'?\xc0\x00\x00', BIG_ENDIAN), 1.5)
+        self.assertEqual(unpack(b'?\xf8\x00\x00\x00\x00\x00\x00', BIG_ENDIAN),
+                         1.5)
+        self.assertEqual(unpack(b'\x00>', LITTLE_ENDIAN), 1.5)
+        self.assertEqual(unpack(b'\x00\x00\xc0?', LITTLE_ENDIAN), 1.5)
+        self.assertEqual(unpack(b'\x00\x00\x00\x00\x00\x00\xf8?', LITTLE_ENDIAN),
+                         1.5)
+
+    def test_pack_unpack_roundtrip(self):
+        pack = _testcapi.float_pack
+        unpack = _testcapi.float_unpack
+
+        large = 2.0 ** 100
+        values = [1.0, 1.5, large, 1.0/7, math.pi]
+        if HAVE_IEEE_754:
+            values.extend((INF, NAN))
+        for value in values:
+            for size in (2, 4, 8,):
+                if size == 2 and value == large:
+                    # too large for 16-bit float
+                    continue
+                rel_tol = EPSILON[size]
+                for endian in (BIG_ENDIAN, LITTLE_ENDIAN):
+                    with self.subTest(value=value, size=size, endian=endian):
+                        data = pack(size, value, endian)
+                        value2 = unpack(data, endian)
+                        if math.isnan(value):
+                            self.assertTrue(math.isnan(value2), (value, value2))
+                        elif size < 8:
+                            self.assertTrue(math.isclose(value2, value, rel_tol=rel_tol),
+                                            (value, value2))
+                        else:
+                            self.assertEqual(value2, value)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_capi/test_getargs.py b/Lib/test/test_capi/test_getargs.py
index ec4100e976..ea12ab196b 100644
--- a/Lib/test/test_capi/test_getargs.py
+++ b/Lib/test/test_capi/test_getargs.py
@@ -55,6 +55,8 @@
 LLONG_MIN = -2**63
 ULLONG_MAX = 2**64-1
 
+NULL = None
+
 class Index:
     def __index__(self):
         return 99
@@ -151,6 +153,8 @@ class TupleSubclass(tuple):
 class DictSubclass(dict):
     pass
 
+NONCONTIG_WRITABLE = memoryview(bytearray(b'noncontig'))[::-2]
+NONCONTIG_READONLY = memoryview(b'noncontig')[::-2]
 
 class Unsigned_TestCase(unittest.TestCase):
     def test_b(self):
@@ -835,6 +839,8 @@ def test_y_star(self):
         self.assertEqual(getargs_y_star(bytearray(b'bytearray')), b'bytearray')
         self.assertEqual(getargs_y_star(memoryview(b'memoryview')), b'memoryview')
         self.assertRaises(TypeError, getargs_y_star, None)
+        self.assertRaises(BufferError, getargs_y_star, NONCONTIG_WRITABLE)
+        self.assertRaises(BufferError, getargs_y_star, NONCONTIG_READONLY)
 
     def test_y_hash(self):
         from _testcapi import getargs_y_hash
@@ -844,6 +850,9 @@ def test_y_hash(self):
         self.assertRaises(TypeError, getargs_y_hash, bytearray(b'bytearray'))
         self.assertRaises(TypeError, getargs_y_hash, memoryview(b'memoryview'))
         self.assertRaises(TypeError, getargs_y_hash, None)
+        # TypeError: must be read-only bytes-like object, not memoryview
+        self.assertRaises(TypeError, getargs_y_hash, NONCONTIG_WRITABLE)
+        self.assertRaises(TypeError, getargs_y_hash, NONCONTIG_READONLY)
 
     def test_w_star(self):
         # getargs_w_star() modifies first and last byte
@@ -859,6 +868,8 @@ def test_w_star(self):
         self.assertEqual(getargs_w_star(memoryview(buf)), b'[emoryvie]')
         self.assertEqual(buf, bytearray(b'[emoryvie]'))
         self.assertRaises(TypeError, getargs_w_star, None)
+        self.assertRaises(TypeError, getargs_w_star, NONCONTIG_WRITABLE)
+        self.assertRaises(TypeError, getargs_w_star, NONCONTIG_READONLY)
 
 
 class String_TestCase(unittest.TestCase):
@@ -891,6 +902,8 @@ def test_s_star(self):
         self.assertEqual(getargs_s_star(bytearray(b'bytearray')), b'bytearray')
         self.assertEqual(getargs_s_star(memoryview(b'memoryview')), b'memoryview')
         self.assertRaises(TypeError, getargs_s_star, None)
+        self.assertRaises(BufferError, getargs_s_star, NONCONTIG_WRITABLE)
+        self.assertRaises(BufferError, getargs_s_star, NONCONTIG_READONLY)
 
     def test_s_hash(self):
         from _testcapi import getargs_s_hash
@@ -900,6 +913,9 @@ def test_s_hash(self):
         self.assertRaises(TypeError, getargs_s_hash, bytearray(b'bytearray'))
         self.assertRaises(TypeError, getargs_s_hash, memoryview(b'memoryview'))
         self.assertRaises(TypeError, getargs_s_hash, None)
+        # TypeError: must be read-only bytes-like object, not memoryview
+        self.assertRaises(TypeError, getargs_s_hash, NONCONTIG_WRITABLE)
+        self.assertRaises(TypeError, getargs_s_hash, NONCONTIG_READONLY)
 
     def test_s_hash_int(self):
         # "s#" without PY_SSIZE_T_CLEAN defined.
@@ -935,6 +951,8 @@ def test_z_star(self):
         self.assertEqual(getargs_z_star(bytearray(b'bytearray')), b'bytearray')
         self.assertEqual(getargs_z_star(memoryview(b'memoryview')), b'memoryview')
         self.assertIsNone(getargs_z_star(None))
+        self.assertRaises(BufferError, getargs_z_star, NONCONTIG_WRITABLE)
+        self.assertRaises(BufferError, getargs_z_star, NONCONTIG_READONLY)
 
     def test_z_hash(self):
         from _testcapi import getargs_z_hash
@@ -944,6 +962,9 @@ def test_z_hash(self):
         self.assertRaises(TypeError, getargs_z_hash, bytearray(b'bytearray'))
         self.assertRaises(TypeError, getargs_z_hash, memoryview(b'memoryview'))
         self.assertIsNone(getargs_z_hash(None))
+        # TypeError: must be read-only bytes-like object, not memoryview
+        self.assertRaises(TypeError, getargs_z_hash, NONCONTIG_WRITABLE)
+        self.assertRaises(TypeError, getargs_z_hash, NONCONTIG_READONLY)
 
     def test_es(self):
         from _testcapi import getargs_es
@@ -1241,6 +1262,27 @@ def test_parse_tuple_and_keywords(self):
         self.assertRaises(ValueError, _testcapi.parse_tuple_and_keywords,
                           (), {}, '', [42])
 
+    def test_basic(self):
+        parse = _testcapi.parse_tuple_and_keywords
+
+        self.assertEqual(parse((), {'a': 1}, 'O', ['a']), (1,))
+        self.assertEqual(parse((), {}, '|O', ['a']), (NULL,))
+        self.assertEqual(parse((1, 2), {}, 'OO', ['a', 'b']), (1, 2))
+        self.assertEqual(parse((1,), {'b': 2}, 'OO', ['a', 'b']), (1, 2))
+        self.assertEqual(parse((), {'a': 1, 'b': 2}, 'OO', ['a', 'b']), (1, 2))
+        self.assertEqual(parse((), {'b': 2}, '|OO', ['a', 'b']), (NULL, 2))
+
+        with self.assertRaisesRegex(TypeError,
+                "function missing required argument 'a'"):
+            parse((), {}, 'O', ['a'])
+        with self.assertRaisesRegex(TypeError,
+                "'b' is an invalid keyword argument"):
+            parse((), {'b': 1}, '|O', ['a'])
+        with self.assertRaisesRegex(TypeError,
+                fr"argument for function given by name \('a'\) "
+                fr"and position \(1\)"):
+            parse((1,), {'a': 2}, 'O|O', ['a', 'b'])
+
     def test_bad_use(self):
         # Test handling invalid format and keywords in
         # PyArg_ParseTupleAndKeywords()
@@ -1268,20 +1310,23 @@ def test_bad_use(self):
     def test_positional_only(self):
         parse = _testcapi.parse_tuple_and_keywords
 
-        parse((1, 2, 3), {}, 'OOO', ['', '', 'a'])
-        parse((1, 2), {'a': 3}, 'OOO', ['', '', 'a'])
+        self.assertEqual(parse((1, 2, 3), {}, 'OOO', ['', '', 'a']), (1, 2, 3))
+        self.assertEqual(parse((1, 2), {'a': 3}, 'OOO', ['', '', 'a']), (1, 2, 3))
         with self.assertRaisesRegex(TypeError,
                r'function takes at least 2 positional arguments \(1 given\)'):
             parse((1,), {'a': 3}, 'OOO', ['', '', 'a'])
-        parse((1,), {}, 'O|OO', ['', '', 'a'])
+        self.assertEqual(parse((1,), {}, 'O|OO', ['', '', 'a']),
+                         (1, NULL, NULL))
         with self.assertRaisesRegex(TypeError,
                r'function takes at least 1 positional argument \(0 given\)'):
             parse((), {}, 'O|OO', ['', '', 'a'])
-        parse((1, 2), {'a': 3}, 'OO$O', ['', '', 'a'])
+        self.assertEqual(parse((1, 2), {'a': 3}, 'OO$O', ['', '', 'a']),
+                         (1, 2, 3))
         with self.assertRaisesRegex(TypeError,
                r'function takes exactly 2 positional arguments \(1 given\)'):
             parse((1,), {'a': 3}, 'OO$O', ['', '', 'a'])
-        parse((1,), {}, 'O|O$O', ['', '', 'a'])
+        self.assertEqual(parse((1,), {}, 'O|O$O', ['', '', 'a']),
+                         (1, NULL, NULL))
         with self.assertRaisesRegex(TypeError,
                r'function takes at least 1 positional argument \(0 given\)'):
             parse((), {}, 'O|O$O', ['', '', 'a'])
diff --git a/Lib/test/test_capi/test_list.py b/Lib/test/test_capi/test_list.py
new file mode 100644
index 0000000000..197da03e07
--- /dev/null
+++ b/Lib/test/test_capi/test_list.py
@@ -0,0 +1,277 @@
+import unittest
+import sys
+from test.support import import_helper
+from collections import UserList
+_testcapi = import_helper.import_module('_testcapi')
+
+NULL = None
+PY_SSIZE_T_MIN = _testcapi.PY_SSIZE_T_MIN
+PY_SSIZE_T_MAX = _testcapi.PY_SSIZE_T_MAX
+
+class ListSubclass(list):
+    pass
+
+
+class CAPITest(unittest.TestCase):
+    def test_check(self):
+        # Test PyList_Check()
+        check = _testcapi.list_check
+        self.assertTrue(check([1, 2]))
+        self.assertTrue(check([]))
+        self.assertTrue(check(ListSubclass([1, 2])))
+        self.assertFalse(check({1: 2}))
+        self.assertFalse(check((1, 2)))
+        self.assertFalse(check(42))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+
+    def test_list_check_exact(self):
+        # Test PyList_CheckExact()
+        check = _testcapi.list_check_exact
+        self.assertTrue(check([1]))
+        self.assertTrue(check([]))
+        self.assertFalse(check(ListSubclass([1])))
+        self.assertFalse(check(UserList([1, 2])))
+        self.assertFalse(check({1: 2}))
+        self.assertFalse(check(object()))
+
+        # CRASHES check(NULL)
+
+    def test_list_new(self):
+        # Test PyList_New()
+        list_new = _testcapi.list_new
+        lst = list_new(0)
+        self.assertEqual(lst, [])
+        self.assertIs(type(lst), list)
+        lst2 = list_new(0)
+        self.assertIsNot(lst2, lst)
+        self.assertRaises(SystemError, list_new, NULL)
+        self.assertRaises(SystemError, list_new, -1)
+
+    def test_list_size(self):
+        # Test PyList_Size()
+        size = _testcapi.list_size
+        self.assertEqual(size([1, 2]), 2)
+        self.assertEqual(size(ListSubclass([1, 2])), 2)
+        self.assertRaises(SystemError, size, UserList())
+        self.assertRaises(SystemError, size, {})
+        self.assertRaises(SystemError, size, 23)
+        self.assertRaises(SystemError, size, object())
+        # CRASHES size(NULL)
+
+    def test_list_get_size(self):
+        # Test PyList_GET_SIZE()
+        size = _testcapi.list_get_size
+        self.assertEqual(size([1, 2]), 2)
+        self.assertEqual(size(ListSubclass([1, 2])), 2)
+        # CRASHES size(object())
+        # CRASHES size(23)
+        # CRASHES size({})
+        # CRASHES size(UserList())
+        # CRASHES size(NULL)
+
+
+    def test_list_getitem(self):
+        # Test PyList_GetItem()
+        getitem = _testcapi.list_getitem
+        lst = [1, 2, 3]
+        self.assertEqual(getitem(lst, 0), 1)
+        self.assertEqual(getitem(lst, 2), 3)
+        self.assertRaises(IndexError, getitem, lst, 3)
+        self.assertRaises(IndexError, getitem, lst, -1)
+        self.assertRaises(IndexError, getitem, lst, PY_SSIZE_T_MIN)
+        self.assertRaises(IndexError, getitem, lst, PY_SSIZE_T_MAX)
+        self.assertRaises(SystemError, getitem, 42, 1)
+        self.assertRaises(SystemError, getitem, (1, 2, 3), 1)
+        self.assertRaises(SystemError, getitem, {1: 2}, 1)
+
+        # CRASHES getitem(NULL, 1)
+
+    def test_list_get_item(self):
+        # Test PyList_GET_ITEM()
+        get_item = _testcapi.list_get_item
+        lst = [1, 2, [1, 2, 3]]
+        self.assertEqual(get_item(lst, 0), 1)
+        self.assertEqual(get_item(lst, 2), [1, 2, 3])
+
+        # CRASHES for out of index: get_item(lst, 3)
+        # CRASHES for get_item(lst, PY_SSIZE_T_MIN)
+        # CRASHES for get_item(lst, PY_SSIZE_T_MAX)
+        # CRASHES get_item(21, 2)
+        # CRASHES get_item(NULL, 1)
+
+
+    def test_list_setitem(self):
+        # Test PyList_SetItem()
+        setitem = _testcapi.list_setitem
+        lst = [1, 2, 3]
+        setitem(lst, 0, 10)
+        self.assertEqual(lst, [10, 2, 3])
+        setitem(lst, 2, 12)
+        self.assertEqual(lst, [10, 2, 12])
+        self.assertRaises(IndexError, setitem, lst, 3 , 5)
+        self.assertRaises(IndexError, setitem, lst, -1, 5)
+        self.assertRaises(IndexError, setitem, lst, PY_SSIZE_T_MIN, 5)
+        self.assertRaises(IndexError, setitem, lst, PY_SSIZE_T_MAX, 5)
+        self.assertRaises(SystemError, setitem, (1, 2, 3), 1, 5)
+        self.assertRaises(SystemError, setitem, {1: 2}, 1, 5)
+
+        # CRASHES setitem(NULL, 'a', 5)
+
+    def test_list_set_item(self):
+        # Test PyList_SET_ITEM()
+        set_item = _testcapi.list_set_item
+        lst = [1, 2, 3]
+        set_item(lst, 1, 10)
+        set_item(lst, 2, [1, 2, 3])
+        self.assertEqual(lst, [1, 10, [1, 2, 3]])
+
+        # CRASHES for set_item([1], -1, 5)
+        # CRASHES for set_item([1], PY_SSIZE_T_MIN, 5)
+        # CRASHES for set_item([1], PY_SSIZE_T_MAX, 5)
+        # CRASHES for set_item([], 0, 1)
+        # CRASHES for set_item(NULL, 0, 1)
+
+
+    def test_list_insert(self):
+        # Test PyList_Insert()
+        insert = _testcapi.list_insert
+        lst = [1, 2, 3]
+        insert(lst, 0, 23)
+        self.assertEqual(lst, [23, 1, 2, 3])
+        insert(lst, -1, 22)
+        self.assertEqual(lst, [23, 1, 2, 22, 3])
+        insert(lst, PY_SSIZE_T_MIN, 1)
+        self.assertEqual(lst[0], 1)
+        insert(lst, len(lst), 123)
+        self.assertEqual(lst[-1], 123)
+        insert(lst, len(lst)-1, 124)
+        self.assertEqual(lst[-2], 124)
+        insert(lst, PY_SSIZE_T_MAX, 223)
+        self.assertEqual(lst[-1], 223)
+
+        self.assertRaises(SystemError, insert, (1, 2, 3), 1, 5)
+        self.assertRaises(SystemError, insert, {1: 2}, 1, 5)
+
+        # CRASHES insert(NULL, 1, 5)
+
+    def test_list_append(self):
+        # Test PyList_Append()
+        append = _testcapi.list_append
+        lst = [1, 2, 3]
+        append(lst, 10)
+        self.assertEqual(lst, [1, 2, 3, 10])
+        append(lst, [4, 5])
+        self.assertEqual(lst, [1, 2, 3, 10, [4, 5]])
+        self.assertRaises(SystemError, append, lst, NULL)
+        self.assertRaises(SystemError, append, (), 0)
+        self.assertRaises(SystemError, append, 42, 0)
+        # CRASHES append(NULL, 0)
+
+    def test_list_getslice(self):
+        # Test PyList_GetSlice()
+        getslice = _testcapi.list_getslice
+        lst = [1, 2, 3]
+
+        # empty
+        self.assertEqual(getslice(lst, PY_SSIZE_T_MIN, 0), [])
+        self.assertEqual(getslice(lst, -1, 0), [])
+        self.assertEqual(getslice(lst, 3, PY_SSIZE_T_MAX), [])
+
+        # slice
+        self.assertEqual(getslice(lst, 1, 3), [2, 3])
+
+        # whole
+        self.assertEqual(getslice(lst, 0, len(lst)), lst)
+        self.assertEqual(getslice(lst, 0, 100), lst)
+        self.assertEqual(getslice(lst, -100, 100), lst)
+
+        self.assertRaises(SystemError, getslice, (1, 2, 3), 0, 0)
+        self.assertRaises(SystemError, getslice, 'abc', 0, 0)
+        self.assertRaises(SystemError, getslice, 42, 0, 0)
+
+        # CRASHES getslice(NULL, 0, 0)
+
+    def test_list_setslice(self):
+        # Test PyList_SetSlice()
+        setslice = _testcapi.list_setslice
+        def set_slice(lst, low, high, value):
+            lst = lst.copy()
+            self.assertEqual(setslice(lst, low, high, value), 0)
+            return lst
+
+        # insert items
+        self.assertEqual(set_slice([], 0, 0, list("abc")), list("abc"))
+        self.assertEqual(set_slice([], PY_SSIZE_T_MIN, PY_SSIZE_T_MIN, list("abc")), list("abc"))
+        self.assertEqual(set_slice([], PY_SSIZE_T_MAX, PY_SSIZE_T_MAX, list("abc")), list("abc"))
+        lst = list("abc")
+        self.assertEqual(set_slice(lst, 0, 0, ["X"]), list("Xabc"))
+        self.assertEqual(set_slice(lst, 1, 1, list("XY")), list("aXYbc"))
+        self.assertEqual(set_slice(lst, len(lst), len(lst), ["X"]), list("abcX"))
+        # self.assertEqual(set_slice(lst, PY_SSIZE_T_MAX, PY_SSIZE_T_MAX, ["X"]), list("abcX"))
+
+        # replace items
+        lst = list("abc")
+        self.assertEqual(set_slice(lst, -100, 1, list("X")), list("Xbc"))
+        self.assertEqual(set_slice(lst, 1, 2, list("X")), list("aXc"))
+        self.assertEqual(set_slice(lst, 1, 3, list("XY")), list("aXY"))
+        self.assertEqual(set_slice(lst, 0, 3, list("XYZ")), list("XYZ"))
+
+        # delete items
+        lst = list("abcdef")
+        self.assertEqual(set_slice(lst, 0, len(lst), []), [])
+        self.assertEqual(set_slice(lst, -100, 100, []), [])
+        self.assertEqual(set_slice(lst, 1, 5, []), list("af"))
+        self.assertEqual(set_slice(lst, 3, len(lst), []), list("abc"))
+
+        # delete items with NULL
+        lst = list("abcdef")
+        self.assertEqual(set_slice(lst, 0, len(lst), NULL), [])
+        self.assertEqual(set_slice(lst, 3, len(lst), NULL), list("abc"))
+
+        self.assertRaises(SystemError, setslice, (), 0, 0, [])
+        self.assertRaises(SystemError, setslice, 42, 0, 0, [])
+
+        # CRASHES setslice(NULL, 0, 0, [])
+
+    def test_list_sort(self):
+        # Test PyList_Sort()
+        sort = _testcapi.list_sort
+        lst = [4, 6, 7, 3, 1, 5, 9, 2, 0, 8]
+        sort(lst)
+        self.assertEqual(lst, list(range(10)))
+
+        lst2 = ListSubclass([4, 6, 7, 3, 1, 5, 9, 2, 0, 8])
+        sort(lst2)
+        self.assertEqual(lst2, list(range(10)))
+
+        self.assertRaises(SystemError, sort, ())
+        self.assertRaises(SystemError, sort, object())
+        self.assertRaises(SystemError, sort, NULL)
+
+
+    def test_list_reverse(self):
+        # Test PyList_Reverse()
+        reverse = _testcapi.list_reverse
+        def list_reverse(lst):
+            self.assertEqual(reverse(lst), 0)
+            return lst
+
+        self.assertEqual(list_reverse([]), [])
+        self.assertEqual(list_reverse([2, 5, 10]), [10, 5, 2])
+
+        self.assertRaises(SystemError, reverse, ())
+        self.assertRaises(SystemError, reverse, object())
+        self.assertRaises(SystemError, reverse, NULL)
+
+    def test_list_astuple(self):
+        # Test PyList_AsTuple()
+        astuple = _testcapi.list_astuple
+        self.assertEqual(astuple([]), ())
+        self.assertEqual(astuple([2, 5, 10]), (2, 5, 10))
+
+        self.assertRaises(SystemError, astuple, ())
+        self.assertRaises(SystemError, astuple, object())
+        self.assertRaises(SystemError, astuple, NULL)
diff --git a/Lib/test/test_capi/test_long.py b/Lib/test/test_capi/test_long.py
index 8928fd94a1..8261cc3829 100644
--- a/Lib/test/test_capi/test_long.py
+++ b/Lib/test/test_capi/test_long.py
@@ -6,6 +6,25 @@
 # Skip this test if the _testcapi module isn't available.
 _testcapi = import_helper.import_module('_testcapi')
 
+NULL = None
+
+class IntSubclass(int):
+    pass
+
+class Index:
+    def __init__(self, value):
+        self.value = value
+
+    def __index__(self):
+        return self.value
+
+# use __index__(), not __int__()
+class MyIndexAndInt:
+    def __index__(self):
+        return 10
+    def __int__(self):
+        return 22
+
 
 class LongTests(unittest.TestCase):
 
@@ -34,6 +53,353 @@ def test_compact_known(self):
         self.assertEqual(_testcapi.call_long_compact_api(sys.maxsize),
                          (False, -1))
 
+    def test_long_check(self):
+        # Test PyLong_Check()
+        check = _testcapi.pylong_check
+        self.assertTrue(check(1))
+        self.assertTrue(check(123456789012345678901234567890))
+        self.assertTrue(check(-1))
+        self.assertTrue(check(True))
+        self.assertTrue(check(IntSubclass(1)))
+        self.assertFalse(check(1.0))
+        self.assertFalse(check(object()))
+        # CRASHES check(NULL)
+
+    def test_long_checkexact(self):
+        # Test PyLong_CheckExact()
+        check = _testcapi.pylong_checkexact
+        self.assertTrue(check(1))
+        self.assertTrue(check(123456789012345678901234567890))
+        self.assertTrue(check(-1))
+        self.assertFalse(check(True))
+        self.assertFalse(check(IntSubclass(1)))
+        self.assertFalse(check(1.0))
+        self.assertFalse(check(object()))
+        # CRASHES check(NULL)
+
+    def test_long_fromdouble(self):
+        # Test PyLong_FromDouble()
+        fromdouble = _testcapi.pylong_fromdouble
+        float_max = sys.float_info.max
+        for value in (5.0, 5.1, 5.9, -5.1, -5.9, 0.0, -0.0, float_max, -float_max):
+            with self.subTest(value=value):
+                self.assertEqual(fromdouble(value), int(value))
+        self.assertRaises(OverflowError, fromdouble, float('inf'))
+        self.assertRaises(OverflowError, fromdouble, float('-inf'))
+        self.assertRaises(ValueError, fromdouble, float('nan'))
+
+    def test_long_fromvoidptr(self):
+        # Test PyLong_FromVoidPtr()
+        fromvoidptr = _testcapi.pylong_fromvoidptr
+        obj = object()
+        x = fromvoidptr(obj)
+        y = fromvoidptr(NULL)
+        self.assertIsInstance(x, int)
+        self.assertGreaterEqual(x, 0)
+        self.assertIsInstance(y, int)
+        self.assertEqual(y, 0)
+        self.assertNotEqual(x, y)
+
+    def test_long_fromstring(self):
+        # Test PyLong_FromString()
+        fromstring = _testcapi.pylong_fromstring
+        self.assertEqual(fromstring(b'123', 10), (123, 3))
+        self.assertEqual(fromstring(b'cafe', 16), (0xcafe, 4))
+        self.assertEqual(fromstring(b'xyz', 36), (44027, 3))
+        self.assertEqual(fromstring(b'123', 0), (123, 3))
+        self.assertEqual(fromstring(b'0xcafe', 0), (0xcafe, 6))
+        self.assertRaises(ValueError, fromstring, b'cafe', 0)
+        self.assertEqual(fromstring(b'-123', 10), (-123, 4))
+        self.assertEqual(fromstring(b' -123 ', 10), (-123, 6))
+        self.assertEqual(fromstring(b'1_23', 10), (123, 4))
+        self.assertRaises(ValueError, fromstring, b'- 123', 10)
+        self.assertRaises(ValueError, fromstring, b'', 10)
+
+        self.assertRaises(ValueError, fromstring, b'123', 1)
+        self.assertRaises(ValueError, fromstring, b'123', -1)
+        self.assertRaises(ValueError, fromstring, b'123', 37)
+
+        self.assertRaises(ValueError, fromstring, '١٢٣٤٥٦٧٨٩٠'.encode(), 0)
+        self.assertRaises(ValueError, fromstring, '١٢٣٤٥٦٧٨٩٠'.encode(), 16)
+
+        self.assertEqual(fromstring(b'123\x00', 0), (123, 3))
+        self.assertEqual(fromstring(b'123\x00456', 0), (123, 3))
+        self.assertEqual(fromstring(b'123\x00', 16), (0x123, 3))
+        self.assertEqual(fromstring(b'123\x00456', 16), (0x123, 3))
+
+        # CRASHES fromstring(NULL, 0)
+        # CRASHES fromstring(NULL, 16)
+
+    def test_long_fromunicodeobject(self):
+        # Test PyLong_FromUnicodeObject()
+        fromunicodeobject = _testcapi.pylong_fromunicodeobject
+        self.assertEqual(fromunicodeobject('123', 10), 123)
+        self.assertEqual(fromunicodeobject('cafe', 16), 0xcafe)
+        self.assertEqual(fromunicodeobject('xyz', 36), 44027)
+        self.assertEqual(fromunicodeobject('123', 0), 123)
+        self.assertEqual(fromunicodeobject('0xcafe', 0), 0xcafe)
+        self.assertRaises(ValueError, fromunicodeobject, 'cafe', 0)
+        self.assertEqual(fromunicodeobject('-123', 10), -123)
+        self.assertEqual(fromunicodeobject(' -123 ', 10), -123)
+        self.assertEqual(fromunicodeobject('1_23', 10), 123)
+        self.assertRaises(ValueError, fromunicodeobject, '- 123', 10)
+        self.assertRaises(ValueError, fromunicodeobject, '', 10)
+
+        self.assertRaises(ValueError, fromunicodeobject, '123', 1)
+        self.assertRaises(ValueError, fromunicodeobject, '123', -1)
+        self.assertRaises(ValueError, fromunicodeobject, '123', 37)
+
+        self.assertEqual(fromunicodeobject('١٢٣٤٥٦٧٨٩٠', 0), 1234567890)
+        self.assertEqual(fromunicodeobject('١٢٣٤٥٦٧٨٩٠', 16), 0x1234567890)
+
+        self.assertRaises(ValueError, fromunicodeobject, '123\x00', 0)
+        self.assertRaises(ValueError, fromunicodeobject, '123\x00456', 0)
+        self.assertRaises(ValueError, fromunicodeobject, '123\x00', 16)
+        self.assertRaises(ValueError, fromunicodeobject, '123\x00456', 16)
+
+        # CRASHES fromunicodeobject(NULL, 0)
+        # CRASHES fromunicodeobject(NULL, 16)
+
+    def test_long_aslong(self):
+        # Test PyLong_AsLong() and PyLong_FromLong()
+        aslong = _testcapi.pylong_aslong
+        from _testcapi import LONG_MIN, LONG_MAX
+        # round trip (object -> long -> object)
+        for value in (LONG_MIN, LONG_MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(aslong(value), value)
+
+        self.assertEqual(aslong(IntSubclass(42)), 42)
+        self.assertEqual(aslong(Index(42)), 42)
+        self.assertEqual(aslong(MyIndexAndInt()), 10)
+
+        self.assertRaises(OverflowError, aslong, LONG_MIN - 1)
+        self.assertRaises(OverflowError, aslong, LONG_MAX + 1)
+        self.assertRaises(TypeError, aslong, 1.0)
+        self.assertRaises(TypeError, aslong, b'2')
+        self.assertRaises(TypeError, aslong, '3')
+        self.assertRaises(SystemError, aslong, NULL)
+
+    def test_long_aslongandoverflow(self):
+        # Test PyLong_AsLongAndOverflow()
+        aslongandoverflow = _testcapi.pylong_aslongandoverflow
+        from _testcapi import LONG_MIN, LONG_MAX
+        # round trip (object -> long -> object)
+        for value in (LONG_MIN, LONG_MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(aslongandoverflow(value), (value, 0))
+
+        self.assertEqual(aslongandoverflow(IntSubclass(42)), (42, 0))
+        self.assertEqual(aslongandoverflow(Index(42)), (42, 0))
+        self.assertEqual(aslongandoverflow(MyIndexAndInt()), (10, 0))
+
+        self.assertEqual(aslongandoverflow(LONG_MIN - 1), (-1, -1))
+        self.assertEqual(aslongandoverflow(LONG_MAX + 1), (-1, 1))
+        # CRASHES aslongandoverflow(1.0)
+        # CRASHES aslongandoverflow(NULL)
+
+    def test_long_asunsignedlong(self):
+        # Test PyLong_AsUnsignedLong() and PyLong_FromUnsignedLong()
+        asunsignedlong = _testcapi.pylong_asunsignedlong
+        from _testcapi import ULONG_MAX
+        # round trip (object -> unsigned long -> object)
+        for value in (ULONG_MAX, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(asunsignedlong(value), value)
+
+        self.assertEqual(asunsignedlong(IntSubclass(42)), 42)
+        self.assertRaises(TypeError, asunsignedlong, Index(42))
+        self.assertRaises(TypeError, asunsignedlong, MyIndexAndInt())
+
+        self.assertRaises(OverflowError, asunsignedlong, -1)
+        self.assertRaises(OverflowError, asunsignedlong, ULONG_MAX + 1)
+        self.assertRaises(TypeError, asunsignedlong, 1.0)
+        self.assertRaises(TypeError, asunsignedlong, b'2')
+        self.assertRaises(TypeError, asunsignedlong, '3')
+        self.assertRaises(SystemError, asunsignedlong, NULL)
+
+    def test_long_asunsignedlongmask(self):
+        # Test PyLong_AsUnsignedLongMask()
+        asunsignedlongmask = _testcapi.pylong_asunsignedlongmask
+        from _testcapi import ULONG_MAX
+        # round trip (object -> unsigned long -> object)
+        for value in (ULONG_MAX, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(asunsignedlongmask(value), value)
+
+        self.assertEqual(asunsignedlongmask(IntSubclass(42)), 42)
+        self.assertEqual(asunsignedlongmask(Index(42)), 42)
+        self.assertEqual(asunsignedlongmask(MyIndexAndInt()), 10)
+
+        self.assertEqual(asunsignedlongmask(-1), ULONG_MAX)
+        self.assertEqual(asunsignedlongmask(ULONG_MAX + 1), 0)
+        self.assertRaises(TypeError, asunsignedlongmask, 1.0)
+        self.assertRaises(TypeError, asunsignedlongmask, b'2')
+        self.assertRaises(TypeError, asunsignedlongmask, '3')
+        self.assertRaises(SystemError, asunsignedlongmask, NULL)
+
+    def test_long_aslonglong(self):
+        # Test PyLong_AsLongLong() and PyLong_FromLongLong()
+        aslonglong = _testcapi.pylong_aslonglong
+        from _testcapi import LLONG_MIN, LLONG_MAX
+        # round trip (object -> long long -> object)
+        for value in (LLONG_MIN, LLONG_MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(aslonglong(value), value)
+
+        self.assertEqual(aslonglong(IntSubclass(42)), 42)
+        self.assertEqual(aslonglong(Index(42)), 42)
+        self.assertEqual(aslonglong(MyIndexAndInt()), 10)
+
+        self.assertRaises(OverflowError, aslonglong, LLONG_MIN - 1)
+        self.assertRaises(OverflowError, aslonglong, LLONG_MAX + 1)
+        self.assertRaises(TypeError, aslonglong, 1.0)
+        self.assertRaises(TypeError, aslonglong, b'2')
+        self.assertRaises(TypeError, aslonglong, '3')
+        self.assertRaises(SystemError, aslonglong, NULL)
+
+    def test_long_aslonglongandoverflow(self):
+        # Test PyLong_AsLongLongAndOverflow()
+        aslonglongandoverflow = _testcapi.pylong_aslonglongandoverflow
+        from _testcapi import LLONG_MIN, LLONG_MAX
+        # round trip (object -> long long -> object)
+        for value in (LLONG_MIN, LLONG_MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(aslonglongandoverflow(value), (value, 0))
+
+        self.assertEqual(aslonglongandoverflow(IntSubclass(42)), (42, 0))
+        self.assertEqual(aslonglongandoverflow(Index(42)), (42, 0))
+        self.assertEqual(aslonglongandoverflow(MyIndexAndInt()), (10, 0))
+
+        self.assertEqual(aslonglongandoverflow(LLONG_MIN - 1), (-1, -1))
+        self.assertEqual(aslonglongandoverflow(LLONG_MAX + 1), (-1, 1))
+        # CRASHES aslonglongandoverflow(1.0)
+        # CRASHES aslonglongandoverflow(NULL)
+
+    def test_long_asunsignedlonglong(self):
+        # Test PyLong_AsUnsignedLongLong() and PyLong_FromUnsignedLongLong()
+        asunsignedlonglong = _testcapi.pylong_asunsignedlonglong
+        from _testcapi import ULLONG_MAX
+        # round trip (object -> unsigned long long -> object)
+        for value in (ULLONG_MAX, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(asunsignedlonglong(value), value)
+
+        self.assertEqual(asunsignedlonglong(IntSubclass(42)), 42)
+        self.assertRaises(TypeError, asunsignedlonglong, Index(42))
+        self.assertRaises(TypeError, asunsignedlonglong, MyIndexAndInt())
+
+        self.assertRaises(OverflowError, asunsignedlonglong, -1)
+        self.assertRaises(OverflowError, asunsignedlonglong, ULLONG_MAX + 1)
+        self.assertRaises(TypeError, asunsignedlonglong, 1.0)
+        self.assertRaises(TypeError, asunsignedlonglong, b'2')
+        self.assertRaises(TypeError, asunsignedlonglong, '3')
+        self.assertRaises(SystemError, asunsignedlonglong, NULL)
+
+    def test_long_asunsignedlonglongmask(self):
+        # Test PyLong_AsUnsignedLongLongMask()
+        asunsignedlonglongmask = _testcapi.pylong_asunsignedlonglongmask
+        from _testcapi import ULLONG_MAX
+        # round trip (object -> unsigned long long -> object)
+        for value in (ULLONG_MAX, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(asunsignedlonglongmask(value), value)
+
+        self.assertEqual(asunsignedlonglongmask(IntSubclass(42)), 42)
+        self.assertEqual(asunsignedlonglongmask(Index(42)), 42)
+        self.assertEqual(asunsignedlonglongmask(MyIndexAndInt()), 10)
+
+        self.assertEqual(asunsignedlonglongmask(-1), ULLONG_MAX)
+        self.assertEqual(asunsignedlonglongmask(ULLONG_MAX + 1), 0)
+        self.assertRaises(TypeError, asunsignedlonglongmask, 1.0)
+        self.assertRaises(TypeError, asunsignedlonglongmask, b'2')
+        self.assertRaises(TypeError, asunsignedlonglongmask, '3')
+        self.assertRaises(SystemError, asunsignedlonglongmask, NULL)
+
+    def test_long_as_ssize_t(self):
+        # Test PyLong_AsSsize_t() and PyLong_FromSsize_t()
+        as_ssize_t = _testcapi.pylong_as_ssize_t
+        from _testcapi import PY_SSIZE_T_MIN, PY_SSIZE_T_MAX
+        # round trip (object -> Py_ssize_t -> object)
+        for value in (PY_SSIZE_T_MIN, PY_SSIZE_T_MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(as_ssize_t(value), value)
+
+        self.assertEqual(as_ssize_t(IntSubclass(42)), 42)
+        self.assertRaises(TypeError, as_ssize_t, Index(42))
+        self.assertRaises(TypeError, as_ssize_t, MyIndexAndInt())
+
+        self.assertRaises(OverflowError, as_ssize_t, PY_SSIZE_T_MIN - 1)
+        self.assertRaises(OverflowError, as_ssize_t, PY_SSIZE_T_MAX + 1)
+        self.assertRaises(TypeError, as_ssize_t, 1.0)
+        self.assertRaises(TypeError, as_ssize_t, b'2')
+        self.assertRaises(TypeError, as_ssize_t, '3')
+        self.assertRaises(SystemError, as_ssize_t, NULL)
+
+    def test_long_as_size_t(self):
+        # Test PyLong_AsSize_t() and PyLong_FromSize_t()
+        as_size_t = _testcapi.pylong_as_size_t
+        from _testcapi import SIZE_MAX
+        # round trip (object -> size_t -> object)
+        for value in (SIZE_MAX, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(as_size_t(value), value)
+
+        self.assertEqual(as_size_t(IntSubclass(42)), 42)
+        self.assertRaises(TypeError, as_size_t, Index(42))
+        self.assertRaises(TypeError, as_size_t, MyIndexAndInt())
+
+        self.assertRaises(OverflowError, as_size_t, -1)
+        self.assertRaises(OverflowError, as_size_t, SIZE_MAX + 1)
+        self.assertRaises(TypeError, as_size_t, 1.0)
+        self.assertRaises(TypeError, as_size_t, b'2')
+        self.assertRaises(TypeError, as_size_t, '3')
+        self.assertRaises(SystemError, as_size_t, NULL)
+
+    def test_long_asdouble(self):
+        # Test PyLong_AsDouble()
+        asdouble = _testcapi.pylong_asdouble
+        MAX = int(sys.float_info.max)
+        for value in (-MAX, MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(asdouble(value), float(value))
+                self.assertIsInstance(asdouble(value), float)
+
+        self.assertEqual(asdouble(IntSubclass(42)), 42.0)
+        self.assertRaises(TypeError, asdouble, Index(42))
+        self.assertRaises(TypeError, asdouble, MyIndexAndInt())
+
+        self.assertRaises(OverflowError, asdouble, 2 * MAX)
+        self.assertRaises(OverflowError, asdouble, -2 * MAX)
+        self.assertRaises(TypeError, asdouble, 1.0)
+        self.assertRaises(TypeError, asdouble, b'2')
+        self.assertRaises(TypeError, asdouble, '3')
+        self.assertRaises(SystemError, asdouble, NULL)
+
+    def test_long_asvoidptr(self):
+        # Test PyLong_AsVoidPtr()
+        fromvoidptr = _testcapi.pylong_fromvoidptr
+        asvoidptr = _testcapi.pylong_asvoidptr
+        obj = object()
+        x = fromvoidptr(obj)
+        y = fromvoidptr(NULL)
+        self.assertIs(asvoidptr(x), obj)
+        self.assertIs(asvoidptr(y), NULL)
+        self.assertIs(asvoidptr(IntSubclass(x)), obj)
+
+        # negative values
+        M = (1 << _testcapi.SIZEOF_VOID_P * 8)
+        if x >= M//2:
+            self.assertIs(asvoidptr(x - M), obj)
+        if y >= M//2:
+            self.assertIs(asvoidptr(y - M), NULL)
+
+        self.assertRaises(TypeError, asvoidptr, Index(x))
+        self.assertRaises(TypeError, asvoidptr, object())
+        self.assertRaises(OverflowError, asvoidptr, 2**1000)
+        self.assertRaises(OverflowError, asvoidptr, -2**1000)
+        # CRASHES asvoidptr(NULL)
+
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_capi/test_misc.py b/Lib/test/test_capi/test_misc.py
index 575635584f..5d0e036105 100644
--- a/Lib/test/test_capi/test_misc.py
+++ b/Lib/test/test_capi/test_misc.py
@@ -298,6 +298,86 @@ def test_getitem_with_error(self):
             # test _Py_CheckFunctionResult() instead.
             self.assertIn('returned a result with an exception set', err)
 
+    def test_buildvalue(self):
+        # Test Py_BuildValue() with object arguments
+        buildvalue = _testcapi.py_buildvalue
+        self.assertEqual(buildvalue(''), None)
+        self.assertEqual(buildvalue('()'), ())
+        self.assertEqual(buildvalue('[]'), [])
+        self.assertEqual(buildvalue('{}'), {})
+        self.assertEqual(buildvalue('()[]{}'), ((), [], {}))
+        self.assertEqual(buildvalue('O', 1), 1)
+        self.assertEqual(buildvalue('(O)', 1), (1,))
+        self.assertEqual(buildvalue('[O]', 1), [1])
+        self.assertRaises(SystemError, buildvalue, '{O}', 1)
+        self.assertEqual(buildvalue('OO', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('(OO)', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('[OO]', 1, 2), [1, 2])
+        self.assertEqual(buildvalue('{OO}', 1, 2), {1: 2})
+        self.assertEqual(buildvalue('{OOOO}', 1, 2, 3, 4), {1: 2, 3: 4})
+        self.assertEqual(buildvalue('((O))', 1), ((1,),))
+        self.assertEqual(buildvalue('((OO))', 1, 2), ((1, 2),))
+
+        self.assertEqual(buildvalue(' \t,:'), None)
+        self.assertEqual(buildvalue('   O   ', 1), 1)
+        self.assertEqual(buildvalue('\tO\t', 1), 1)
+        self.assertEqual(buildvalue('O,O', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('O, O', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('O,\tO', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('O O', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('O\tO', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('(O,O)', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('(O, O)', 1, 2), (1, 2))
+        self.assertEqual(buildvalue(' ( O O) ', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('\t(\tO\tO)\t', 1, 2), (1, 2))
+        self.assertEqual(buildvalue('[O,O]', 1, 2), [1, 2])
+        self.assertEqual(buildvalue('[O, O]', 1, 2), [1, 2])
+        self.assertEqual(buildvalue(' [ O O] ', 1, 2), [1, 2])
+        self.assertEqual(buildvalue('{O:O}', 1, 2), {1: 2})
+        self.assertEqual(buildvalue('{O:O,O:O}', 1, 2, 3, 4), {1: 2, 3: 4})
+        self.assertEqual(buildvalue('{O: O, O: O}', 1, 2, 3, 4), {1: 2, 3: 4})
+        self.assertEqual(buildvalue(' { O O O O} ', 1, 2, 3, 4), {1: 2, 3: 4})
+        self.assertEqual(buildvalue('\t{\tO\tO\tO\tO}\t', 1, 2, 3, 4), {1: 2, 3: 4})
+
+        self.assertRaises(SystemError, buildvalue, 'O', NULL)
+        self.assertRaises(SystemError, buildvalue, '(O)', NULL)
+        self.assertRaises(SystemError, buildvalue, '[O]', NULL)
+        self.assertRaises(SystemError, buildvalue, '{O}', NULL)
+        self.assertRaises(SystemError, buildvalue, 'OO', 1, NULL)
+        self.assertRaises(SystemError, buildvalue, 'OO', NULL, 2)
+        self.assertRaises(SystemError, buildvalue, '(OO)', 1, NULL)
+        self.assertRaises(SystemError, buildvalue, '(OO)', NULL, 2)
+        self.assertRaises(SystemError, buildvalue, '[OO]', 1, NULL)
+        self.assertRaises(SystemError, buildvalue, '[OO]', NULL, 2)
+        self.assertRaises(SystemError, buildvalue, '{OO}', 1, NULL)
+        self.assertRaises(SystemError, buildvalue, '{OO}', NULL, 2)
+
+    def test_buildvalue_ints(self):
+        # Test Py_BuildValue() with integer arguments
+        buildvalue = _testcapi.py_buildvalue_ints
+        from _testcapi import SHRT_MIN, SHRT_MAX, USHRT_MAX, INT_MIN, INT_MAX, UINT_MAX
+        self.assertEqual(buildvalue('i', INT_MAX), INT_MAX)
+        self.assertEqual(buildvalue('i', INT_MIN), INT_MIN)
+        self.assertEqual(buildvalue('I', UINT_MAX), UINT_MAX)
+
+        self.assertEqual(buildvalue('h', SHRT_MAX), SHRT_MAX)
+        self.assertEqual(buildvalue('h', SHRT_MIN), SHRT_MIN)
+        self.assertEqual(buildvalue('H', USHRT_MAX), USHRT_MAX)
+
+        self.assertEqual(buildvalue('b', 127), 127)
+        self.assertEqual(buildvalue('b', -128), -128)
+        self.assertEqual(buildvalue('B', 255), 255)
+
+        self.assertEqual(buildvalue('c', ord('A')), b'A')
+        self.assertEqual(buildvalue('c', 255), b'\xff')
+        self.assertEqual(buildvalue('c', 256), b'\x00')
+        self.assertEqual(buildvalue('c', -1), b'\xff')
+
+        self.assertEqual(buildvalue('C', 255), chr(255))
+        self.assertEqual(buildvalue('C', 256), chr(256))
+        self.assertEqual(buildvalue('C', sys.maxunicode), chr(sys.maxunicode))
+        self.assertRaises(ValueError, buildvalue, 'C', -1)
+        self.assertRaises(ValueError, buildvalue, 'C', sys.maxunicode+1)
     def test_buildvalue_N(self):
         _testcapi.test_buildvalue_N()
 
@@ -325,6 +405,8 @@ def test_negative_refcount(self):
 
     @unittest.skipUnless(hasattr(_testcapi, 'decref_freed_object'),
                          'need _testcapi.decref_freed_object()')
+    @support.skip_if_sanitizer("use after free on purpose",
+                               address=True, memory=True, ub=True)
     def test_decref_freed_object(self):
         code = """
             import _testcapi
@@ -1008,46 +1090,6 @@ class Data(_testcapi.ObjExtraData):
         del d.extra
         self.assertIsNone(d.extra)
 
-    def test_sys_getobject(self):
-        getobject = _testcapi.sys_getobject
-
-        self.assertIs(getobject(b'stdout'), sys.stdout)
-        with support.swap_attr(sys, '\U0001f40d', 42):
-            self.assertEqual(getobject('\U0001f40d'.encode()), 42)
-
-        self.assertIs(getobject(b'nonexisting'), AttributeError)
-        self.assertIs(getobject(b'\xff'), AttributeError)
-        # CRASHES getobject(NULL)
-
-    def test_sys_setobject(self):
-        setobject = _testcapi.sys_setobject
-
-        value = ['value']
-        value2 = ['value2']
-        try:
-            self.assertEqual(setobject(b'newattr', value), 0)
-            self.assertIs(sys.newattr, value)
-            self.assertEqual(setobject(b'newattr', value2), 0)
-            self.assertIs(sys.newattr, value2)
-            self.assertEqual(setobject(b'newattr', NULL), 0)
-            self.assertFalse(hasattr(sys, 'newattr'))
-            self.assertEqual(setobject(b'newattr', NULL), 0)
-        finally:
-            with contextlib.suppress(AttributeError):
-                del sys.newattr
-        try:
-            self.assertEqual(setobject('\U0001f40d'.encode(), value), 0)
-            self.assertIs(getattr(sys, '\U0001f40d'), value)
-            self.assertEqual(setobject('\U0001f40d'.encode(), NULL), 0)
-            self.assertFalse(hasattr(sys, '\U0001f40d'))
-        finally:
-            with contextlib.suppress(AttributeError):
-                delattr(sys, '\U0001f40d')
-
-        with self.assertRaises(UnicodeDecodeError):
-            setobject(b'\xff', value)
-        # CRASHES setobject(NULL, value)
-
 
 @requires_limited_api
 class TestHeapTypeRelative(unittest.TestCase):
diff --git a/Lib/test/test_capi/test_set.py b/Lib/test/test_capi/test_set.py
new file mode 100644
index 0000000000..e9165e7e68
--- /dev/null
+++ b/Lib/test/test_capi/test_set.py
@@ -0,0 +1,215 @@
+import unittest
+
+from test.support import import_helper
+
+# Skip this test if the _testcapi module isn't available.
+_testcapi = import_helper.import_module('_testcapi')
+
+class set_subclass(set):
+    pass
+
+class frozenset_subclass(frozenset):
+    pass
+
+
+class TestSetCAPI(unittest.TestCase):
+    def assertImmutable(self, action, *args):
+        self.assertRaises(SystemError, action, frozenset(), *args)
+        self.assertRaises(SystemError, action, frozenset({1}), *args)
+        self.assertRaises(SystemError, action, frozenset_subclass(), *args)
+        self.assertRaises(SystemError, action, frozenset_subclass({1}), *args)
+
+    def test_set_check(self):
+        check = _testcapi.set_check
+        self.assertTrue(check(set()))
+        self.assertTrue(check({1, 2}))
+        self.assertFalse(check(frozenset()))
+        self.assertTrue(check(set_subclass()))
+        self.assertFalse(check(frozenset_subclass()))
+        self.assertFalse(check(object()))
+        # CRASHES: check(NULL)
+
+    def test_set_check_exact(self):
+        check = _testcapi.set_checkexact
+        self.assertTrue(check(set()))
+        self.assertTrue(check({1, 2}))
+        self.assertFalse(check(frozenset()))
+        self.assertFalse(check(set_subclass()))
+        self.assertFalse(check(frozenset_subclass()))
+        self.assertFalse(check(object()))
+        # CRASHES: check(NULL)
+
+    def test_frozenset_check(self):
+        check = _testcapi.frozenset_check
+        self.assertFalse(check(set()))
+        self.assertTrue(check(frozenset()))
+        self.assertTrue(check(frozenset({1, 2})))
+        self.assertFalse(check(set_subclass()))
+        self.assertTrue(check(frozenset_subclass()))
+        self.assertFalse(check(object()))
+        # CRASHES: check(NULL)
+
+    def test_frozenset_check_exact(self):
+        check = _testcapi.frozenset_checkexact
+        self.assertFalse(check(set()))
+        self.assertTrue(check(frozenset()))
+        self.assertTrue(check(frozenset({1, 2})))
+        self.assertFalse(check(set_subclass()))
+        self.assertFalse(check(frozenset_subclass()))
+        self.assertFalse(check(object()))
+        # CRASHES: check(NULL)
+
+    def test_anyset_check(self):
+        check = _testcapi.anyset_check
+        self.assertTrue(check(set()))
+        self.assertTrue(check({1, 2}))
+        self.assertTrue(check(frozenset()))
+        self.assertTrue(check(frozenset({1, 2})))
+        self.assertTrue(check(set_subclass()))
+        self.assertTrue(check(frozenset_subclass()))
+        self.assertFalse(check(object()))
+        # CRASHES: check(NULL)
+
+    def test_anyset_check_exact(self):
+        check = _testcapi.anyset_checkexact
+        self.assertTrue(check(set()))
+        self.assertTrue(check({1, 2}))
+        self.assertTrue(check(frozenset()))
+        self.assertTrue(check(frozenset({1, 2})))
+        self.assertFalse(check(set_subclass()))
+        self.assertFalse(check(frozenset_subclass()))
+        self.assertFalse(check(object()))
+        # CRASHES: check(NULL)
+
+    def test_set_new(self):
+        set_new = _testcapi.set_new
+        self.assertEqual(set_new().__class__, set)
+        self.assertEqual(set_new(), set())
+        self.assertEqual(set_new((1, 1, 2)), {1, 2})
+        self.assertEqual(set_new([1, 1, 2]), {1, 2})
+        with self.assertRaisesRegex(TypeError, 'object is not iterable'):
+            set_new(object())
+        with self.assertRaisesRegex(TypeError, 'object is not iterable'):
+            set_new(1)
+        with self.assertRaisesRegex(TypeError, "unhashable type: 'dict'"):
+            set_new((1, {}))
+
+    def test_frozenset_new(self):
+        frozenset_new = _testcapi.frozenset_new
+        self.assertEqual(frozenset_new().__class__, frozenset)
+        self.assertEqual(frozenset_new(), frozenset())
+        self.assertEqual(frozenset_new((1, 1, 2)), frozenset({1, 2}))
+        self.assertEqual(frozenset_new([1, 1, 2]), frozenset({1, 2}))
+        with self.assertRaisesRegex(TypeError, 'object is not iterable'):
+            frozenset_new(object())
+        with self.assertRaisesRegex(TypeError, 'object is not iterable'):
+            frozenset_new(1)
+        with self.assertRaisesRegex(TypeError, "unhashable type: 'dict'"):
+            frozenset_new((1, {}))
+
+    def test_set_size(self):
+        get_size = _testcapi.set_size
+        self.assertEqual(get_size(set()), 0)
+        self.assertEqual(get_size(frozenset()), 0)
+        self.assertEqual(get_size({1, 1, 2}), 2)
+        self.assertEqual(get_size(frozenset({1, 1, 2})), 2)
+        self.assertEqual(get_size(set_subclass((1, 2, 3))), 3)
+        self.assertEqual(get_size(frozenset_subclass((1, 2, 3))), 3)
+        with self.assertRaises(SystemError):
+            get_size(object())
+        # CRASHES: get_size(NULL)
+
+    def test_set_get_size(self):
+        get_size = _testcapi.set_get_size
+        self.assertEqual(get_size(set()), 0)
+        self.assertEqual(get_size(frozenset()), 0)
+        self.assertEqual(get_size({1, 1, 2}), 2)
+        self.assertEqual(get_size(frozenset({1, 1, 2})), 2)
+        self.assertEqual(get_size(set_subclass((1, 2, 3))), 3)
+        self.assertEqual(get_size(frozenset_subclass((1, 2, 3))), 3)
+        # CRASHES: get_size(NULL)
+        # CRASHES: get_size(object())
+
+    def test_set_contains(self):
+        contains = _testcapi.set_contains
+        for cls in (set, frozenset, set_subclass, frozenset_subclass):
+            with self.subTest(cls=cls):
+                instance = cls((1, 2))
+                self.assertTrue(contains(instance, 1))
+                self.assertFalse(contains(instance, 'missing'))
+                with self.assertRaisesRegex(TypeError, "unhashable type: 'list'"):
+                    contains(instance, [])
+        # CRASHES: contains(instance, NULL)
+        # CRASHES: contains(NULL, object())
+        # CRASHES: contains(NULL, NULL)
+
+    def test_add(self):
+        add = _testcapi.set_add
+        for cls in (set, set_subclass):
+            with self.subTest(cls=cls):
+                instance = cls((1, 2))
+                self.assertEqual(add(instance, 1), 0)
+                self.assertEqual(instance, {1, 2})
+                self.assertEqual(add(instance, 3), 0)
+                self.assertEqual(instance, {1, 2, 3})
+                with self.assertRaisesRegex(TypeError, "unhashable type: 'list'"):
+                    add(instance, [])
+        with self.assertRaises(SystemError):
+            add(object(), 1)
+        self.assertImmutable(add, 1)
+        # CRASHES: add(NULL, object())
+        # CRASHES: add(instance, NULL)
+        # CRASHES: add(NULL, NULL)
+
+    def test_discard(self):
+        discard = _testcapi.set_discard
+        for cls in (set, set_subclass):
+            with self.subTest(cls=cls):
+                instance = cls((1, 2))
+                self.assertEqual(discard(instance, 3), 0)
+                self.assertEqual(instance, {1, 2})
+                self.assertEqual(discard(instance, 1), 1)
+                self.assertEqual(instance, {2})
+                self.assertEqual(discard(instance, 2), 1)
+                self.assertEqual(instance, set())
+                self.assertEqual(discard(instance, 2), 0)
+                self.assertEqual(instance, set())
+                with self.assertRaisesRegex(TypeError, "unhashable type: 'list'"):
+                    discard(instance, [])
+        with self.assertRaises(SystemError):
+            discard(object(), 1)
+        self.assertImmutable(discard, 1)
+        # CRASHES: discard(NULL, object())
+        # CRASHES: discard(instance, NULL)
+        # CRASHES: discard(NULL, NULL)
+
+    def test_pop(self):
+        pop = _testcapi.set_pop
+        orig = (1, 2)
+        for cls in (set, set_subclass):
+            with self.subTest(cls=cls):
+                instance = cls(orig)
+                self.assertIn(pop(instance), orig)
+                self.assertEqual(len(instance), 1)
+                self.assertIn(pop(instance), orig)
+                self.assertEqual(len(instance), 0)
+                with self.assertRaises(KeyError):
+                    pop(instance)
+        with self.assertRaises(SystemError):
+            pop(object())
+        self.assertImmutable(pop)
+        # CRASHES: pop(NULL)
+
+    def test_clear(self):
+        clear = _testcapi.set_clear
+        for cls in (set, set_subclass):
+            with self.subTest(cls=cls):
+                instance = cls((1, 2))
+                self.assertEqual(clear(instance), 0)
+                self.assertEqual(instance, set())
+                self.assertEqual(clear(instance), 0)
+                self.assertEqual(instance, set())
+        with self.assertRaises(SystemError):
+            clear(object())
+        self.assertImmutable(clear)
+        # CRASHES: clear(NULL)
diff --git a/Lib/test/test_capi/test_sys.py b/Lib/test/test_capi/test_sys.py
new file mode 100644
index 0000000000..e26f35f5d8
--- /dev/null
+++ b/Lib/test/test_capi/test_sys.py
@@ -0,0 +1,149 @@
+import unittest
+import contextlib
+import sys
+from test import support
+from test.support import import_helper
+
+try:
+    import _testcapi
+except ImportError:
+    _testcapi = None
+
+NULL = None
+
+class CAPITest(unittest.TestCase):
+    # TODO: Test the following functions:
+    #
+    #   PySys_Audit()
+
+    maxDiff = None
+
+    @support.cpython_only
+    @unittest.skipIf(_testcapi is None, 'need _testcapi module')
+    def test_sys_getobject(self):
+        # Test PySys_GetObject()
+        getobject = _testcapi.sys_getobject
+
+        self.assertIs(getobject(b'stdout'), sys.stdout)
+        with support.swap_attr(sys, '\U0001f40d', 42):
+            self.assertEqual(getobject('\U0001f40d'.encode()), 42)
+
+        self.assertIs(getobject(b'nonexisting'), AttributeError)
+        self.assertIs(getobject(b'\xff'), AttributeError)
+        # CRASHES getobject(NULL)
+
+    @support.cpython_only
+    @unittest.skipIf(_testcapi is None, 'need _testcapi module')
+    def test_sys_setobject(self):
+        # Test PySys_SetObject()
+        setobject = _testcapi.sys_setobject
+
+        value = ['value']
+        value2 = ['value2']
+        try:
+            self.assertEqual(setobject(b'newattr', value), 0)
+            self.assertIs(sys.newattr, value)
+            self.assertEqual(setobject(b'newattr', value2), 0)
+            self.assertIs(sys.newattr, value2)
+            self.assertEqual(setobject(b'newattr', NULL), 0)
+            self.assertFalse(hasattr(sys, 'newattr'))
+            self.assertEqual(setobject(b'newattr', NULL), 0)
+        finally:
+            with contextlib.suppress(AttributeError):
+                del sys.newattr
+        try:
+            self.assertEqual(setobject('\U0001f40d'.encode(), value), 0)
+            self.assertIs(getattr(sys, '\U0001f40d'), value)
+            self.assertEqual(setobject('\U0001f40d'.encode(), NULL), 0)
+            self.assertFalse(hasattr(sys, '\U0001f40d'))
+        finally:
+            with contextlib.suppress(AttributeError):
+                delattr(sys, '\U0001f40d')
+
+        with self.assertRaises(UnicodeDecodeError):
+            setobject(b'\xff', value)
+        # CRASHES setobject(NULL, value)
+
+    @support.cpython_only
+    @unittest.skipIf(_testcapi is None, 'need _testcapi module')
+    def test_sys_getxoptions(self):
+        # Test PySys_GetXOptions()
+        getxoptions = _testcapi.sys_getxoptions
+
+        self.assertIs(getxoptions(), sys._xoptions)
+
+        xoptions = sys._xoptions
+        try:
+            sys._xoptions = 'non-dict'
+            self.assertEqual(getxoptions(), {})
+            self.assertIs(getxoptions(), sys._xoptions)
+
+            del sys._xoptions
+            self.assertEqual(getxoptions(), {})
+            self.assertIs(getxoptions(), sys._xoptions)
+        finally:
+            sys._xoptions = xoptions
+        self.assertIs(getxoptions(), sys._xoptions)
+
+    def _test_sys_formatstream(self, funname, streamname):
+        import_helper.import_module('ctypes')
+        from ctypes import pythonapi, c_char_p, py_object
+        func = getattr(pythonapi, funname)
+        func.argtypes = (c_char_p,)
+
+        # Supports plain C types.
+        with support.captured_output(streamname) as stream:
+            func(b'Hello, %s!', c_char_p(b'world'))
+        self.assertEqual(stream.getvalue(), 'Hello, world!')
+
+        # Supports Python objects.
+        with support.captured_output(streamname) as stream:
+            func(b'Hello, %R!', py_object('world'))
+        self.assertEqual(stream.getvalue(), "Hello, 'world'!")
+
+        # The total length is not limited.
+        with support.captured_output(streamname) as stream:
+            func(b'Hello, %s!', c_char_p(b'world'*200))
+        self.assertEqual(stream.getvalue(), 'Hello, ' + 'world'*200 + '!')
+
+    def test_sys_formatstdout(self):
+        # Test PySys_FormatStdout()
+        self._test_sys_formatstream('PySys_FormatStdout', 'stdout')
+
+    def test_sys_formatstderr(self):
+        # Test PySys_FormatStderr()
+        self._test_sys_formatstream('PySys_FormatStderr', 'stderr')
+
+    def _test_sys_writestream(self, funname, streamname):
+        import_helper.import_module('ctypes')
+        from ctypes import pythonapi, c_char_p
+        func = getattr(pythonapi, funname)
+        func.argtypes = (c_char_p,)
+
+        # Supports plain C types.
+        with support.captured_output(streamname) as stream:
+            func(b'Hello, %s!', c_char_p(b'world'))
+        self.assertEqual(stream.getvalue(), 'Hello, world!')
+
+        # There is a limit on the total length.
+        with support.captured_output(streamname) as stream:
+            func(b'Hello, %s!', c_char_p(b'world'*100))
+        self.assertEqual(stream.getvalue(), 'Hello, ' + 'world'*100 + '!')
+        with support.captured_output(streamname) as stream:
+            func(b'Hello, %s!', c_char_p(b'world'*200))
+        out = stream.getvalue()
+        self.assertEqual(out[:20], 'Hello, worldworldwor')
+        self.assertEqual(out[-13:], '... truncated')
+        self.assertGreater(len(out), 1000)
+
+    def test_sys_writestdout(self):
+        # Test PySys_WriteStdout()
+        self._test_sys_writestream('PySys_WriteStdout', 'stdout')
+
+    def test_sys_writestderr(self):
+        # Test PySys_WriteStderr()
+        self._test_sys_writestream('PySys_WriteStderr', 'stderr')
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_capi/test_unicode.py b/Lib/test/test_capi/test_unicode.py
index 9c76620656..1f07f9046f 100644
--- a/Lib/test/test_capi/test_unicode.py
+++ b/Lib/test/test_capi/test_unicode.py
@@ -5,6 +5,7 @@
 
 try:
     import _testcapi
+    from _testcapi import PY_SSIZE_T_MIN, PY_SSIZE_T_MAX
 except ImportError:
     _testcapi = None
 
@@ -26,9 +27,17 @@ def test_new(self):
         for maxchar in 0, 0x61, 0xa1, 0x4f60, 0x1f600, 0x10ffff:
             self.assertEqual(new(0, maxchar), '')
             self.assertEqual(new(5, maxchar), chr(maxchar)*5)
+            self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX, maxchar)
         self.assertEqual(new(0, 0x110000), '')
+        self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX//2, 0x4f60)
+        self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX//2+1, 0x4f60)
+        self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX//2, 0x1f600)
+        self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX//2+1, 0x1f600)
+        self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX//4, 0x1f600)
+        self.assertRaises(MemoryError, new, PY_SSIZE_T_MAX//4+1, 0x1f600)
         self.assertRaises(SystemError, new, 5, 0x110000)
         self.assertRaises(SystemError, new, -1, 0)
+        self.assertRaises(SystemError, new, PY_SSIZE_T_MIN, 0)
 
     @support.cpython_only
     @unittest.skipIf(_testcapi is None, 'need _testcapi module')
@@ -49,8 +58,8 @@ def test_fill(self):
             for to in strings[:idx]:
                 self.assertRaises(ValueError, fill, to, 0, 0, fill_char)
             for to in strings[idx:]:
-                for start in range(7):
-                    for length in range(-1, 7 - start):
+                for start in [*range(7), PY_SSIZE_T_MAX]:
+                    for length in [*range(-1, 7 - start), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX]:
                         filled = max(min(length, 5 - start), 0)
                         if filled == 5 and to != strings[idx]:
                             # narrow -> wide
@@ -62,6 +71,7 @@ def test_fill(self):
 
         s = strings[0]
         self.assertRaises(IndexError, fill, s, -1, 0, 0x78)
+        self.assertRaises(IndexError, fill, s, PY_SSIZE_T_MIN, 0, 0x78)
         self.assertRaises(ValueError, fill, s, 0, 0, 0x110000)
         self.assertRaises(SystemError, fill, b'abc', 0, 0, 0x78)
         self.assertRaises(SystemError, fill, [], 0, 0, 0x78)
@@ -72,7 +82,7 @@ def test_fill(self):
     @support.cpython_only
     @unittest.skipIf(_testcapi is None, 'need _testcapi module')
     def test_writechar(self):
-        """Test PyUnicode_ReadChar()"""
+        """Test PyUnicode_WriteChar()"""
         from _testcapi import unicode_writechar as writechar
 
         strings = [
@@ -92,10 +102,12 @@ def test_writechar(self):
 
         self.assertRaises(IndexError, writechar, 'abc', 3, 0x78)
         self.assertRaises(IndexError, writechar, 'abc', -1, 0x78)
+        self.assertRaises(IndexError, writechar, 'abc', PY_SSIZE_T_MAX, 0x78)
+        self.assertRaises(IndexError, writechar, 'abc', PY_SSIZE_T_MIN, 0x78)
         self.assertRaises(TypeError, writechar, b'abc', 0, 0x78)
         self.assertRaises(TypeError, writechar, [], 0, 0x78)
         # CRASHES writechar(NULL, 0, 0x78)
-        # TODO: Test PyUnicode_CopyCharacters() with non-modifiable and legacy
+        # TODO: Test PyUnicode_WriteChar() with non-modifiable and legacy
         # unicode.
 
     @support.cpython_only
@@ -113,7 +125,11 @@ def test_resize(self):
             self.assertEqual(resize(s, 3), (s, 0))
             self.assertEqual(resize(s, 2), (s[:2], 0))
             self.assertEqual(resize(s, 4), (s + '\0', 0))
+            self.assertEqual(resize(s, 10), (s + '\0'*7, 0))
             self.assertEqual(resize(s, 0), ('', 0))
+            self.assertRaises(MemoryError, resize, s, PY_SSIZE_T_MAX)
+            self.assertRaises(SystemError, resize, s, -1)
+            self.assertRaises(SystemError, resize, s, PY_SSIZE_T_MIN)
         self.assertRaises(SystemError, resize, b'abc', 0)
         self.assertRaises(SystemError, resize, [], 0)
         self.assertRaises(SystemError, resize, NULL, 0)
@@ -192,8 +208,13 @@ def test_fromstringandsize(self):
         self.assertEqual(fromstringandsize(b'', 0), '')
         self.assertEqual(fromstringandsize(NULL, 0), '')
 
+        self.assertRaises(MemoryError, fromstringandsize, b'abc', PY_SSIZE_T_MAX)
         self.assertRaises(SystemError, fromstringandsize, b'abc', -1)
-        # TODO: Test PyUnicode_FromStringAndSize(NULL, size) for size != 0
+        self.assertRaises(SystemError, fromstringandsize, b'abc', PY_SSIZE_T_MIN)
+        self.assertRaises(SystemError, fromstringandsize, NULL, -1)
+        self.assertRaises(SystemError, fromstringandsize, NULL, PY_SSIZE_T_MIN)
+        self.assertRaises(SystemError, fromstringandsize, NULL, 3)
+        self.assertRaises(SystemError, fromstringandsize, NULL, PY_SSIZE_T_MAX)
 
     @support.cpython_only
     @unittest.skipIf(_testcapi is None, 'need _testcapi module')
@@ -241,7 +262,9 @@ def test_fromkindanddata(self):
         for kind in -1, 0, 3, 5, 8:
             self.assertRaises(SystemError, fromkindanddata, kind, b'')
         self.assertRaises(ValueError, fromkindanddata, 1, b'abc', -1)
+        self.assertRaises(ValueError, fromkindanddata, 1, b'abc', PY_SSIZE_T_MIN)
         self.assertRaises(ValueError, fromkindanddata, 1, NULL, -1)
+        self.assertRaises(ValueError, fromkindanddata, 1, NULL, PY_SSIZE_T_MIN)
         # CRASHES fromkindanddata(1, NULL, 1)
         # CRASHES fromkindanddata(4, b'\xff\xff\xff\xff')
 
@@ -257,12 +280,14 @@ def test_substring(self):
             'ab\xa1\xa2\u4f60\u597d\U0001f600\U0001f601'
         ]
         for s in strings:
-            for start in range(0, len(s) + 2):
-                for end in range(max(start-1, 0), len(s) + 2):
+            for start in [*range(0, len(s) + 2), PY_SSIZE_T_MAX]:
+                for end in [*range(max(start-1, 0), len(s) + 2), PY_SSIZE_T_MAX]:
                     self.assertEqual(substring(s, start, end), s[start:end])
 
         self.assertRaises(IndexError, substring, 'abc', -1, 0)
+        self.assertRaises(IndexError, substring, 'abc', PY_SSIZE_T_MIN, 0)
         self.assertRaises(IndexError, substring, 'abc', 0, -1)
+        self.assertRaises(IndexError, substring, 'abc', 0, PY_SSIZE_T_MIN)
         # CRASHES substring(b'abc', 0, 0)
         # CRASHES substring([], 0, 0)
         # CRASHES substring(NULL, 0, 0)
@@ -292,7 +317,9 @@ def test_readchar(self):
             for i, c in enumerate(s):
                 self.assertEqual(readchar(s, i), ord(c))
             self.assertRaises(IndexError, readchar, s, len(s))
+            self.assertRaises(IndexError, readchar, s, PY_SSIZE_T_MAX)
             self.assertRaises(IndexError, readchar, s, -1)
+            self.assertRaises(IndexError, readchar, s, PY_SSIZE_T_MIN)
 
         self.assertRaises(TypeError, readchar, b'abc', 0)
         self.assertRaises(TypeError, readchar, [], 0)
@@ -727,10 +754,15 @@ def test_fromwidechar(self):
         if SIZEOF_WCHAR_T == 2:
             self.assertEqual(fromwidechar('a\U0001f600'.encode(encoding), 2), 'a\ud83d')
 
+        self.assertRaises(MemoryError, fromwidechar, b'', PY_SSIZE_T_MAX)
         self.assertRaises(SystemError, fromwidechar, b'\0'*SIZEOF_WCHAR_T, -2)
+        self.assertRaises(SystemError, fromwidechar, b'\0'*SIZEOF_WCHAR_T, PY_SSIZE_T_MIN)
         self.assertEqual(fromwidechar(NULL, 0), '')
         self.assertRaises(SystemError, fromwidechar, NULL, 1)
+        self.assertRaises(SystemError, fromwidechar, NULL, PY_SSIZE_T_MAX)
         self.assertRaises(SystemError, fromwidechar, NULL, -1)
+        self.assertRaises(SystemError, fromwidechar, NULL, -2)
+        self.assertRaises(SystemError, fromwidechar, NULL, PY_SSIZE_T_MIN)
 
     @support.cpython_only
     @unittest.skipIf(_testcapi is None, 'need _testcapi module')
@@ -902,7 +934,11 @@ def test_asutf8andsize(self):
         self.assertRaises(UnicodeEncodeError, unicode_asutf8andsize, '\ud8ff', 0)
         self.assertRaises(TypeError, unicode_asutf8andsize, b'abc', 0)
         self.assertRaises(TypeError, unicode_asutf8andsize, [], 0)
+        self.assertRaises(UnicodeEncodeError, unicode_asutf8andsize_null, '\ud8ff', 0)
+        self.assertRaises(TypeError, unicode_asutf8andsize_null, b'abc', 0)
+        self.assertRaises(TypeError, unicode_asutf8andsize_null, [], 0)
         # CRASHES unicode_asutf8andsize(NULL, 0)
+        # CRASHES unicode_asutf8andsize_null(NULL, 0)
 
     @support.cpython_only
     @unittest.skipIf(_testcapi is None, 'need _testcapi module')
@@ -961,6 +997,11 @@ def test_split(self):
 
         self.assertEqual(split('a|b|c|d', '|'), ['a', 'b', 'c', 'd'])
         self.assertEqual(split('a|b|c|d', '|', 2), ['a', 'b', 'c|d'])
+        self.assertEqual(split('a|b|c|d', '|', PY_SSIZE_T_MAX),
+                         ['a', 'b', 'c', 'd'])
+        self.assertEqual(split('a|b|c|d', '|', -1), ['a', 'b', 'c', 'd'])
+        self.assertEqual(split('a|b|c|d', '|', PY_SSIZE_T_MIN),
+                         ['a', 'b', 'c', 'd'])
         self.assertEqual(split('a|b|c|d', '\u20ac'), ['a|b|c|d'])
         self.assertEqual(split('a||b|c||d', '||'), ['a', 'b|c', 'd'])
         self.assertEqual(split('а|б|в|г', '|'), ['а', 'б', 'в', 'г'])
@@ -984,6 +1025,11 @@ def test_rsplit(self):
 
         self.assertEqual(rsplit('a|b|c|d', '|'), ['a', 'b', 'c', 'd'])
         self.assertEqual(rsplit('a|b|c|d', '|', 2), ['a|b', 'c', 'd'])
+        self.assertEqual(rsplit('a|b|c|d', '|', PY_SSIZE_T_MAX),
+                         ['a', 'b', 'c', 'd'])
+        self.assertEqual(rsplit('a|b|c|d', '|', -1), ['a', 'b', 'c', 'd'])
+        self.assertEqual(rsplit('a|b|c|d', '|', PY_SSIZE_T_MIN),
+                         ['a', 'b', 'c', 'd'])
         self.assertEqual(rsplit('a|b|c|d', '\u20ac'), ['a|b|c|d'])
         self.assertEqual(rsplit('a||b|c||d', '||'), ['a', 'b|c', 'd'])
         self.assertEqual(rsplit('а|б|в|г', '|'), ['а', 'б', 'в', 'г'])
@@ -1116,11 +1162,14 @@ def test_count(self):
         self.assertEqual(unicode_count(str, '', 0, len(str)), len(str)+1)
         # start < end
         self.assertEqual(unicode_count(str, '!', 1, len(str)+1), 1)
+        self.assertEqual(unicode_count(str, '!', 1, PY_SSIZE_T_MAX), 1)
         # start >= end
         self.assertEqual(unicode_count(str, '!', 0, 0), 0)
         self.assertEqual(unicode_count(str, '!', len(str), 0), 0)
         # negative
         self.assertEqual(unicode_count(str, '!', -len(str), -1), 1)
+        self.assertEqual(unicode_count(str, '!', -len(str)-1, -1), 1)
+        self.assertEqual(unicode_count(str, '!', PY_SSIZE_T_MIN, -1), 1)
         # bad arguments
         self.assertRaises(TypeError, unicode_count, str, b'!', 0, len(str))
         self.assertRaises(TypeError, unicode_count, b"!>_<!", '!', 0, len(str))
@@ -1139,11 +1188,11 @@ def test_tailmatch(self):
         self.assertEqual(tailmatch(str, 'aba', 0, len(str), -1), 1)
         self.assertEqual(tailmatch(str, 'aha', 0, len(str), 1), 1)
 
-        self.assertEqual(tailmatch(str, 'aba', 0, sys.maxsize, -1), 1)
-        self.assertEqual(tailmatch(str, 'aba', -len(str), sys.maxsize, -1), 1)
-        self.assertEqual(tailmatch(str, 'aba', -sys.maxsize-1, len(str), -1), 1)
-        self.assertEqual(tailmatch(str, 'aha', 0, sys.maxsize, 1), 1)
-        self.assertEqual(tailmatch(str, 'aha', -sys.maxsize-1, len(str), 1), 1)
+        self.assertEqual(tailmatch(str, 'aba', 0, PY_SSIZE_T_MAX, -1), 1)
+        self.assertEqual(tailmatch(str, 'aba', -len(str), PY_SSIZE_T_MAX, -1), 1)
+        self.assertEqual(tailmatch(str, 'aba', PY_SSIZE_T_MIN, len(str), -1), 1)
+        self.assertEqual(tailmatch(str, 'aha', 0, PY_SSIZE_T_MAX, 1), 1)
+        self.assertEqual(tailmatch(str, 'aha', PY_SSIZE_T_MIN, len(str), 1), 1)
 
         self.assertEqual(tailmatch(str, 'z', 0, len(str), 1), 0)
         self.assertEqual(tailmatch(str, 'z', 0, len(str), -1), 0)
@@ -1182,13 +1231,21 @@ def test_find(self):
         self.assertEqual(find(str, '', 0, len(str), -1), len(str))
         # start < end
         self.assertEqual(find(str, '!', 1, len(str)+1, 1), 4)
-        self.assertEqual(find(str, '!', 1, len(str)+1, -1), 4)
+        self.assertEqual(find(str, '!', 1, PY_SSIZE_T_MAX, 1), 4)
+        self.assertEqual(find(str, '!', 0, len(str)+1, -1), 4)
+        self.assertEqual(find(str, '!', 0, PY_SSIZE_T_MAX, -1), 4)
         # start >= end
         self.assertEqual(find(str, '!', 0, 0, 1), -1)
+        self.assertEqual(find(str, '!', 0, 0, -1), -1)
         self.assertEqual(find(str, '!', len(str), 0, 1), -1)
+        self.assertEqual(find(str, '!', len(str), 0, -1), -1)
         # negative
         self.assertEqual(find(str, '!', -len(str), -1, 1), 0)
         self.assertEqual(find(str, '!', -len(str), -1, -1), 0)
+        self.assertEqual(find(str, '!', PY_SSIZE_T_MIN, -1, 1), 0)
+        self.assertEqual(find(str, '!', PY_SSIZE_T_MIN, -1, -1), 0)
+        self.assertEqual(find(str, '!', PY_SSIZE_T_MIN, PY_SSIZE_T_MAX, 1), 0)
+        self.assertEqual(find(str, '!', PY_SSIZE_T_MIN, PY_SSIZE_T_MAX, -1), 4)
         # bad arguments
         self.assertRaises(TypeError, find, str, b'!', 0, len(str), 1)
         self.assertRaises(TypeError, find, b"!>_<!", '!', 0, len(str), 1)
@@ -1213,13 +1270,21 @@ def test_findchar(self):
         self.assertEqual(unicode_findchar(str, 0x110000, 0, len(str), -1), -1)
         # start < end
         self.assertEqual(unicode_findchar(str, ord('!'), 1, len(str)+1, 1), 4)
-        self.assertEqual(unicode_findchar(str, ord('!'), 1, len(str)+1, -1), 4)
+        self.assertEqual(unicode_findchar(str, ord('!'), 1, PY_SSIZE_T_MAX, 1), 4)
+        self.assertEqual(unicode_findchar(str, ord('!'), 0, len(str)+1, -1), 4)
+        self.assertEqual(unicode_findchar(str, ord('!'), 0, PY_SSIZE_T_MAX, -1), 4)
         # start >= end
         self.assertEqual(unicode_findchar(str, ord('!'), 0, 0, 1), -1)
+        self.assertEqual(unicode_findchar(str, ord('!'), 0, 0, -1), -1)
         self.assertEqual(unicode_findchar(str, ord('!'), len(str), 0, 1), -1)
+        self.assertEqual(unicode_findchar(str, ord('!'), len(str), 0, -1), -1)
         # negative
         self.assertEqual(unicode_findchar(str, ord('!'), -len(str), -1, 1), 0)
         self.assertEqual(unicode_findchar(str, ord('!'), -len(str), -1, -1), 0)
+        self.assertEqual(unicode_findchar(str, ord('!'), PY_SSIZE_T_MIN, -1, 1), 0)
+        self.assertEqual(unicode_findchar(str, ord('!'), PY_SSIZE_T_MIN, -1, -1), 0)
+        self.assertEqual(unicode_findchar(str, ord('!'), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX, 1), 0)
+        self.assertEqual(unicode_findchar(str, ord('!'), PY_SSIZE_T_MIN, PY_SSIZE_T_MAX, -1), 4)
         # bad arguments
         # CRASHES unicode_findchar(b"!>_<!", ord('!'), 0, len(str), 1)
         # CRASHES unicode_findchar([], ord('!'), 0, len(str), 1)
@@ -1237,7 +1302,9 @@ def test_replace(self):
         self.assertEqual(replace(str, 'abra', '='), '=cad=')
         self.assertEqual(replace(str, 'a', '=', 2), '=br=cadabra')
         self.assertEqual(replace(str, 'a', '=', 0), str)
-        self.assertEqual(replace(str, 'a', '=', sys.maxsize), '=br=c=d=br=')
+        self.assertEqual(replace(str, 'a', '=', PY_SSIZE_T_MAX), '=br=c=d=br=')
+        self.assertEqual(replace(str, 'a', '=', -1), '=br=c=d=br=')
+        self.assertEqual(replace(str, 'a', '=', PY_SSIZE_T_MIN), '=br=c=d=br=')
         self.assertEqual(replace(str, 'z', '='), str)
         self.assertEqual(replace(str, '', '='), '=a=b=r=a=c=a=d=a=b=r=a=')
         self.assertEqual(replace(str, 'a', 'ж'), 'жbrжcжdжbrж')
@@ -1416,11 +1483,17 @@ def test_copycharacters(self):
 
         s = strings[0]
         self.assertRaises(IndexError, unicode_copycharacters, s, 6, s, 0, 5)
+        self.assertRaises(IndexError, unicode_copycharacters, s, PY_SSIZE_T_MAX, s, 0, 5)
         self.assertRaises(IndexError, unicode_copycharacters, s, -1, s, 0, 5)
+        self.assertRaises(IndexError, unicode_copycharacters, s, PY_SSIZE_T_MIN, s, 0, 5)
         self.assertRaises(IndexError, unicode_copycharacters, s, 0, s, 6, 5)
+        self.assertRaises(IndexError, unicode_copycharacters, s, 0, s, PY_SSIZE_T_MAX, 5)
         self.assertRaises(IndexError, unicode_copycharacters, s, 0, s, -1, 5)
+        self.assertRaises(IndexError, unicode_copycharacters, s, 0, s, PY_SSIZE_T_MIN, 5)
         self.assertRaises(SystemError, unicode_copycharacters, s, 1, s, 0, 5)
+        self.assertRaises(SystemError, unicode_copycharacters, s, 1, s, 0, PY_SSIZE_T_MAX)
         self.assertRaises(SystemError, unicode_copycharacters, s, 0, s, 0, -1)
+        self.assertRaises(SystemError, unicode_copycharacters, s, 0, s, 0, PY_SSIZE_T_MIN)
         self.assertRaises(SystemError, unicode_copycharacters, s, 0, b'', 0, 0)
         self.assertRaises(SystemError, unicode_copycharacters, s, 0, [], 0, 0)
         # CRASHES unicode_copycharacters(s, 0, NULL, 0, 0)
diff --git a/Lib/test/test_clinic.py b/Lib/test/test_clinic.py
index 520cc51302..05eea78a0c 100644
--- a/Lib/test/test_clinic.py
+++ b/Lib/test/test_clinic.py
@@ -4,7 +4,6 @@
 
 from test import support, test_tools
 from test.support import os_helper
-from test.support import SHORT_TIMEOUT, requires_subprocess
 from test.support.os_helper import TESTFN, unlink
 from textwrap import dedent
 from unittest import TestCase
@@ -600,7 +599,6 @@ def test_param_no_docstring(self):
                 follow_symlinks: bool = True
                 something_else: str = ''
         """)
-        p = function.parameters['follow_symlinks']
         self.assertEqual(3, len(function.parameters))
         conv = function.parameters['something_else'].converter
         self.assertIsInstance(conv, clinic.str_converter)
@@ -1396,7 +1394,7 @@ def expect_failure(self, *args):
     def test_external(self):
         CLINIC_TEST = 'clinic.test.c'
         source = support.findfile(CLINIC_TEST)
-        with open(source, 'r', encoding='utf-8') as f:
+        with open(source, encoding='utf-8') as f:
             orig_contents = f.read()
 
         # Run clinic CLI and verify that it does not complain.
@@ -1404,7 +1402,7 @@ def test_external(self):
         out = self.expect_success("-f", "-o", TESTFN, source)
         self.assertEqual(out, "")
 
-        with open(TESTFN, 'r', encoding='utf-8') as f:
+        with open(TESTFN, encoding='utf-8') as f:
             new_contents = f.read()
 
         self.assertEqual(new_contents, orig_contents)
@@ -1465,7 +1463,7 @@ def test_cli_force(self):
                 "/*[clinic end generated code: "
                 "output=2124c291eb067d76 input=9543a8d2da235301]*/\n"
             )
-            with open(fn, 'r', encoding='utf-8') as f:
+            with open(fn, encoding='utf-8') as f:
                 generated = f.read()
             self.assertTrue(generated.endswith(checksum))
 
diff --git a/Lib/test/test_cmd.py b/Lib/test/test_cmd.py
index 319801c71f..28f8076667 100644
--- a/Lib/test/test_cmd.py
+++ b/Lib/test/test_cmd.py
@@ -248,19 +248,9 @@ def load_tests(loader, tests, pattern):
     tests.addTest(doctest.DocTestSuite())
     return tests
 
-def test_coverage(coverdir):
-    trace = support.import_module('trace')
-    tracer=trace.Trace(ignoredirs=[sys.base_prefix, sys.base_exec_prefix,],
-                        trace=0, count=1)
-    tracer.run('import importlib; importlib.reload(cmd); test_main()')
-    r=tracer.results()
-    print("Writing coverage results...")
-    r.write_results(show_missing=True, summary=True, coverdir=coverdir)
 
 if __name__ == "__main__":
-    if "-c" in sys.argv:
-        test_coverage('/tmp/cmd.cover')
-    elif "-i" in sys.argv:
+    if "-i" in sys.argv:
         samplecmdclass().cmdloop()
     else:
         unittest.main()
diff --git a/Lib/test/test_codecencodings_iso2022.py b/Lib/test/test_codecencodings_iso2022.py
index 00ea1c39dd..027dbecc61 100644
--- a/Lib/test/test_codecencodings_iso2022.py
+++ b/Lib/test/test_codecencodings_iso2022.py
@@ -24,6 +24,52 @@ class Test_ISO2022_JP2(multibytecodec_support.TestBase, unittest.TestCase):
         (b'ab\x1BNdef', 'replace', 'abdef'),
     )
 
+class Test_ISO2022_JP3(multibytecodec_support.TestBase, unittest.TestCase):
+    encoding = 'iso2022_jp_3'
+    tstring = multibytecodec_support.load_teststring('iso2022_jp')
+    codectests = COMMON_CODEC_TESTS + (
+        (b'ab\x1BNdef', 'replace', 'ab\x1BNdef'),
+        (b'\x1B$(O\x2E\x23\x1B(B', 'strict', '\u3402'      ),
+        (b'\x1B$(O\x2E\x22\x1B(B', 'strict', '\U0002000B'  ),
+        (b'\x1B$(O\x24\x77\x1B(B', 'strict', '\u304B\u309A'),
+        (b'\x1B$(P\x21\x22\x1B(B', 'strict', '\u4E02'      ),
+        (b'\x1B$(P\x7E\x76\x1B(B', 'strict', '\U0002A6B2'  ),
+        ('\u3402',       'strict', b'\x1B$(O\x2E\x23\x1B(B'),
+        ('\U0002000B',   'strict', b'\x1B$(O\x2E\x22\x1B(B'),
+        ('\u304B\u309A', 'strict', b'\x1B$(O\x24\x77\x1B(B'),
+        ('\u4E02',       'strict', b'\x1B$(P\x21\x22\x1B(B'),
+        ('\U0002A6B2',   'strict', b'\x1B$(P\x7E\x76\x1B(B'),
+        (b'ab\x1B$(O\x2E\x21\x1B(Bdef', 'replace', 'ab\uFFFDdef'),
+        ('ab\u4FF1def', 'replace', b'ab?def'),
+    )
+    xmlcharnametest = (
+        '\xAB\u211C\xBB = \u2329\u1234\u232A',
+        b'\x1B$(O\x29\x28\x1B(B&real;\x1B$(O\x29\x32\x1B(B = &lang;&#4660;&rang;'
+    )
+
+class Test_ISO2022_JP2004(multibytecodec_support.TestBase, unittest.TestCase):
+    encoding = 'iso2022_jp_2004'
+    tstring = multibytecodec_support.load_teststring('iso2022_jp')
+    codectests = COMMON_CODEC_TESTS + (
+        (b'ab\x1BNdef', 'replace', 'ab\x1BNdef'),
+        (b'\x1B$(Q\x2E\x23\x1B(B', 'strict', '\u3402'      ),
+        (b'\x1B$(Q\x2E\x22\x1B(B', 'strict', '\U0002000B'  ),
+        (b'\x1B$(Q\x24\x77\x1B(B', 'strict', '\u304B\u309A'),
+        (b'\x1B$(P\x21\x22\x1B(B', 'strict', '\u4E02'      ),
+        (b'\x1B$(P\x7E\x76\x1B(B', 'strict', '\U0002A6B2'  ),
+        ('\u3402',       'strict', b'\x1B$(Q\x2E\x23\x1B(B'),
+        ('\U0002000B',   'strict', b'\x1B$(Q\x2E\x22\x1B(B'),
+        ('\u304B\u309A', 'strict', b'\x1B$(Q\x24\x77\x1B(B'),
+        ('\u4E02',       'strict', b'\x1B$(P\x21\x22\x1B(B'),
+        ('\U0002A6B2',   'strict', b'\x1B$(P\x7E\x76\x1B(B'),
+        (b'ab\x1B$(Q\x2E\x21\x1B(Bdef', 'replace', 'ab\u4FF1def'),
+        ('ab\u4FF1def', 'replace', b'ab\x1B$(Q\x2E\x21\x1B(Bdef'),
+    )
+    xmlcharnametest = (
+        '\xAB\u211C\xBB = \u2329\u1234\u232A',
+        b'\x1B$(Q\x29\x28\x1B(B&real;\x1B$(Q\x29\x32\x1B(B = &lang;&#4660;&rang;'
+    )
+
 class Test_ISO2022_KR(multibytecodec_support.TestBase, unittest.TestCase):
     encoding = 'iso2022_kr'
     tstring = multibytecodec_support.load_teststring('iso2022_kr')
diff --git a/Lib/test/test_codecs.py b/Lib/test/test_codecs.py
index 91d7eaf997..5dc5b1acf1 100644
--- a/Lib/test/test_codecs.py
+++ b/Lib/test/test_codecs.py
@@ -1,7 +1,9 @@
 import codecs
 import contextlib
+import copy
 import io
 import locale
+import pickle
 import sys
 import unittest
 import encodings
@@ -1771,6 +1773,61 @@ def test_readlines(self):
         f = self.reader(self.stream)
         self.assertEqual(f.readlines(), ['\ud55c\n', '\uae00'])
 
+    def test_copy(self):
+        f = self.reader(Queue(b'\xed\x95\x9c\n\xea\xb8\x80'))
+        with self.assertRaisesRegex(TypeError, 'StreamReader'):
+            copy.copy(f)
+        with self.assertRaisesRegex(TypeError, 'StreamReader'):
+            copy.deepcopy(f)
+
+    def test_pickle(self):
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(protocol=proto):
+                f = self.reader(Queue(b'\xed\x95\x9c\n\xea\xb8\x80'))
+                with self.assertRaisesRegex(TypeError, 'StreamReader'):
+                    pickle.dumps(f, proto)
+
+
+class StreamWriterTest(unittest.TestCase):
+
+    def setUp(self):
+        self.writer = codecs.getwriter('utf-8')
+
+    def test_copy(self):
+        f = self.writer(Queue(b''))
+        with self.assertRaisesRegex(TypeError, 'StreamWriter'):
+            copy.copy(f)
+        with self.assertRaisesRegex(TypeError, 'StreamWriter'):
+            copy.deepcopy(f)
+
+    def test_pickle(self):
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(protocol=proto):
+                f = self.writer(Queue(b''))
+                with self.assertRaisesRegex(TypeError, 'StreamWriter'):
+                    pickle.dumps(f, proto)
+
+
+class StreamReaderWriterTest(unittest.TestCase):
+
+    def setUp(self):
+        self.reader = codecs.getreader('latin1')
+        self.writer = codecs.getwriter('utf-8')
+
+    def test_copy(self):
+        f = codecs.StreamReaderWriter(Queue(b''), self.reader, self.writer)
+        with self.assertRaisesRegex(TypeError, 'StreamReaderWriter'):
+            copy.copy(f)
+        with self.assertRaisesRegex(TypeError, 'StreamReaderWriter'):
+            copy.deepcopy(f)
+
+    def test_pickle(self):
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(protocol=proto):
+                f = codecs.StreamReaderWriter(Queue(b''), self.reader, self.writer)
+                with self.assertRaisesRegex(TypeError, 'StreamReaderWriter'):
+                    pickle.dumps(f, proto)
+
 
 class EncodedFileTest(unittest.TestCase):
 
@@ -3346,6 +3403,28 @@ def test_seeking_write(self):
         self.assertEqual(sr.readline(), b'abc\n')
         self.assertEqual(sr.readline(), b'789\n')
 
+    def test_copy(self):
+        bio = io.BytesIO()
+        codec = codecs.lookup('ascii')
+        sr = codecs.StreamRecoder(bio, codec.encode, codec.decode,
+                                  encodings.ascii.StreamReader, encodings.ascii.StreamWriter)
+
+        with self.assertRaisesRegex(TypeError, 'StreamRecoder'):
+            copy.copy(sr)
+        with self.assertRaisesRegex(TypeError, 'StreamRecoder'):
+            copy.deepcopy(sr)
+
+    def test_pickle(self):
+        q = Queue(b'')
+        codec = codecs.lookup('ascii')
+        sr = codecs.StreamRecoder(q, codec.encode, codec.decode,
+                                  encodings.ascii.StreamReader, encodings.ascii.StreamWriter)
+
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(protocol=proto):
+                with self.assertRaisesRegex(TypeError, 'StreamRecoder'):
+                    pickle.dumps(sr, proto)
+
 
 @unittest.skipIf(_testinternalcapi is None, 'need _testinternalcapi module')
 class LocaleCodecTest(unittest.TestCase):
@@ -3488,9 +3567,10 @@ class Rot13UtilTest(unittest.TestCase):
     $ echo "Hello World" | python -m encodings.rot_13
     """
     def test_rot13_func(self):
+        from encodings.rot_13 import rot13
         infile = io.StringIO('Gb or, be abg gb or, gung vf gur dhrfgvba')
         outfile = io.StringIO()
-        encodings.rot_13.rot13(infile, outfile)
+        rot13(infile, outfile)
         outfile.seek(0)
         plain_text = outfile.read()
         self.assertEqual(
diff --git a/Lib/test/test_codeop.py b/Lib/test/test_codeop.py
index e3c382266f..2abb6c6d93 100644
--- a/Lib/test/test_codeop.py
+++ b/Lib/test/test_codeop.py
@@ -5,6 +5,7 @@
 import unittest
 import warnings
 from test.support import warnings_helper
+from textwrap import dedent
 
 from codeop import compile_command, PyCF_DONT_IMPLY_DEDENT
 
@@ -308,6 +309,19 @@ def test_invalid_warning(self):
         self.assertRegex(str(w[0].message), 'invalid escape sequence')
         self.assertEqual(w[0].filename, '<input>')
 
+    def assertSyntaxErrorMatches(self, code, message):
+        with self.subTest(code):
+            with self.assertRaisesRegex(SyntaxError, message):
+                compile_command(code, symbol='exec')
+
+    def test_syntax_errors(self):
+        self.assertSyntaxErrorMatches(
+            dedent("""\
+                def foo(x,x):
+                   pass
+            """), "duplicate argument 'x' in function definition")
+
+
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_compile.py b/Lib/test/test_compile.py
index e377620a0c..42df670fe0 100644
--- a/Lib/test/test_compile.py
+++ b/Lib/test/test_compile.py
@@ -443,6 +443,33 @@ def f():
         self.assertIn("_A__mangled_mod", A.f.__code__.co_varnames)
         self.assertIn("__package__", A.f.__code__.co_varnames)
 
+    def test_compile_invalid_namedexpr(self):
+        # gh-109351
+        m = ast.Module(
+            body=[
+                ast.Expr(
+                    value=ast.ListComp(
+                        elt=ast.NamedExpr(
+                            target=ast.Constant(value=1),
+                            value=ast.Constant(value=3),
+                        ),
+                        generators=[
+                            ast.comprehension(
+                                target=ast.Name(id="x", ctx=ast.Store()),
+                                iter=ast.Name(id="y", ctx=ast.Load()),
+                                ifs=[],
+                                is_async=0,
+                            )
+                        ],
+                    )
+                )
+            ],
+            type_ignores=[],
+        )
+
+        with self.assertRaisesRegex(TypeError, "NamedExpr target must be a Name"):
+            compile(ast.fix_missing_locations(m), "<file>", "exec")
+
     def test_compile_ast(self):
         fname = __file__
         if fname.lower().endswith('pyc'):
@@ -1242,6 +1269,11 @@ def f(x):
             while x:
                 0 if 1 else 0
 
+    def test_remove_redundant_nop_edge_case(self):
+        # See gh-109889
+        def f():
+            a if (1 if b else c) else d
+
 @requires_debug_ranges()
 class TestSourcePositions(unittest.TestCase):
     # Ensure that compiled code snippets have correct line and column numbers
diff --git a/Lib/test/test_concurrent_futures/test_as_completed.py b/Lib/test/test_concurrent_futures/test_as_completed.py
index 2b3bec8caf..c90b0021d8 100644
--- a/Lib/test/test_concurrent_futures/test_as_completed.py
+++ b/Lib/test/test_concurrent_futures/test_as_completed.py
@@ -42,11 +42,14 @@ def test_future_times_out(self):
                              EXCEPTION_FUTURE,
                              SUCCESSFUL_FUTURE}
 
-        for timeout in (0, 0.01):
+        # Windows clock resolution is around 15.6 ms
+        short_timeout = 0.100
+        for timeout in (0, short_timeout):
             with self.subTest(timeout):
 
-                future = self.executor.submit(time.sleep, 0.1)
                 completed_futures = set()
+                future = self.executor.submit(time.sleep, short_timeout * 10)
+
                 try:
                     for f in futures.as_completed(
                         already_completed | {future},
diff --git a/Lib/test/test_concurrent_futures/test_deadlock.py b/Lib/test/test_concurrent_futures/test_deadlock.py
index 6b78b360d1..1db4cd0099 100644
--- a/Lib/test/test_concurrent_futures/test_deadlock.py
+++ b/Lib/test/test_concurrent_futures/test_deadlock.py
@@ -1,10 +1,13 @@
 import contextlib
+import queue
+import signal
 import sys
 import time
 import unittest
+import unittest.mock
 from pickle import PicklingError
 from concurrent import futures
-from concurrent.futures.process import BrokenProcessPool
+from concurrent.futures.process import BrokenProcessPool, _ThreadWakeup
 
 from test import support
 
@@ -88,7 +91,7 @@ def __reduce__(self):
 
 
 class ExecutorDeadlockTest:
-    TIMEOUT = support.SHORT_TIMEOUT
+    TIMEOUT = support.LONG_TIMEOUT
 
     def _fail_on_deadlock(self, executor):
         # If we did not recover before TIMEOUT seconds, consider that the
@@ -142,6 +145,9 @@ def test_exit_at_task_unpickle(self):
         self._check_crash(BrokenProcessPool, id, ExitAtUnpickle())
 
     def test_error_at_task_unpickle(self):
+        # gh-109832: Restore stderr overriden by _raise_error_ignore_stderr()
+        self.addCleanup(setattr, sys, 'stderr', sys.stderr)
+
         # Check problem occurring while unpickling a task on workers
         self._check_crash(BrokenProcessPool, id, ErrorAtUnpickle())
 
@@ -177,6 +183,9 @@ def test_error_during_result_pickle_on_worker(self):
         self._check_crash(PicklingError, _return_instance, ErrorAtPickle)
 
     def test_error_during_result_unpickle_in_result_handler(self):
+        # gh-109832: Restore stderr overriden by _raise_error_ignore_stderr()
+        self.addCleanup(setattr, sys, 'stderr', sys.stderr)
+
         # Check problem occurring while unpickling a task in
         # the result_handler thread
         self._check_crash(BrokenProcessPool,
@@ -239,6 +248,74 @@ def test_crash_big_data(self):
             with self.assertRaises(BrokenProcessPool):
                 list(executor.map(_crash_with_data, [data] * 10))
 
+    def test_gh105829_should_not_deadlock_if_wakeup_pipe_full(self):
+        # Issue #105829: The _ExecutorManagerThread wakeup pipe could
+        # fill up and block. See: https://github.com/python/cpython/issues/105829
+
+        # Lots of cargo culting while writing this test, apologies if
+        # something is really stupid...
+
+        self.executor.shutdown(wait=True)
+
+        if not hasattr(signal, 'alarm'):
+            raise unittest.SkipTest(
+                "Tested platform does not support the alarm signal")
+
+        def timeout(_signum, _frame):
+            import faulthandler
+            faulthandler.dump_traceback()
+
+            raise RuntimeError("timed out while submitting jobs?")
+
+        thread_run = futures.process._ExecutorManagerThread.run
+        def mock_run(self):
+            # Delay thread startup so the wakeup pipe can fill up and block
+            time.sleep(3)
+            thread_run(self)
+
+        class MockWakeup(_ThreadWakeup):
+            """Mock wakeup object to force the wakeup to block"""
+            def __init__(self):
+                super().__init__()
+                self._dummy_queue = queue.Queue(maxsize=1)
+
+            def wakeup(self):
+                self._dummy_queue.put(None, block=True)
+                super().wakeup()
+
+            def clear(self):
+                super().clear()
+                try:
+                    while True:
+                        self._dummy_queue.get_nowait()
+                except queue.Empty:
+                    pass
+
+        with (unittest.mock.patch.object(futures.process._ExecutorManagerThread,
+                                         'run', mock_run),
+              unittest.mock.patch('concurrent.futures.process._ThreadWakeup',
+                                  MockWakeup)):
+            with self.executor_type(max_workers=2,
+                                    mp_context=self.get_context()) as executor:
+                self.executor = executor  # Allow clean up in fail_on_deadlock
+
+                job_num = 100
+                job_data = range(job_num)
+
+                # Need to use sigalarm for timeout detection because
+                # Executor.submit is not guarded by any timeout (both
+                # self._work_ids.put(self._queue_count) and
+                # self._executor_manager_thread_wakeup.wakeup() might
+                # timeout, maybe more?). In this specific case it was
+                # the wakeup call that deadlocked on a blocking pipe.
+                old_handler = signal.signal(signal.SIGALRM, timeout)
+                try:
+                    signal.alarm(int(self.TIMEOUT))
+                    self.assertEqual(job_num, len(list(executor.map(int, job_data))))
+                finally:
+                    signal.alarm(0)
+                    signal.signal(signal.SIGALRM, old_handler)
+
 
 create_executor_tests(globals(), ExecutorDeadlockTest,
                       executor_mixins=(ProcessPoolForkMixin,
diff --git a/Lib/test/test_concurrent_futures/test_process_pool.py b/Lib/test/test_concurrent_futures/test_process_pool.py
index 7763a4946f..c73c2da1a0 100644
--- a/Lib/test/test_concurrent_futures/test_process_pool.py
+++ b/Lib/test/test_concurrent_futures/test_process_pool.py
@@ -1,5 +1,6 @@
 import os
 import sys
+import threading
 import time
 import unittest
 from concurrent import futures
@@ -187,6 +188,34 @@ def test_max_tasks_early_shutdown(self):
         for i, future in enumerate(futures):
             self.assertEqual(future.result(), mul(i, i))
 
+    def test_python_finalization_error(self):
+        # gh-109047: Catch RuntimeError on thread creation
+        # during Python finalization.
+
+        context = self.get_context()
+
+        # gh-109047: Mock the threading.start_new_thread() function to inject
+        # RuntimeError: simulate the error raised during Python finalization.
+        # Block the second creation: create _ExecutorManagerThread, but block
+        # QueueFeederThread.
+        orig_start_new_thread = threading._start_new_thread
+        nthread = 0
+        def mock_start_new_thread(func, *args):
+            nonlocal nthread
+            if nthread >= 1:
+                raise RuntimeError("can't create new thread at "
+                                   "interpreter shutdown")
+            nthread += 1
+            return orig_start_new_thread(func, *args)
+
+        with support.swap_attr(threading, '_start_new_thread',
+                               mock_start_new_thread):
+            executor = self.executor_type(max_workers=2, mp_context=context)
+            with executor:
+                with self.assertRaises(BrokenProcessPool):
+                    list(executor.map(mul, [(2, 3)] * 10))
+            executor.shutdown()
+
 
 create_executor_tests(globals(), ProcessPoolExecutorTest,
                       executor_mixins=(ProcessPoolForkMixin,
diff --git a/Lib/test/test_concurrent_futures/test_wait.py b/Lib/test/test_concurrent_futures/test_wait.py
index 3f64ca173c..ff48620209 100644
--- a/Lib/test/test_concurrent_futures/test_wait.py
+++ b/Lib/test/test_concurrent_futures/test_wait.py
@@ -112,24 +112,25 @@ def test_all_completed(self):
                               future2]), finished)
         self.assertEqual(set(), pending)
 
-    @support.requires_resource('walltime')
     def test_timeout(self):
-        future1 = self.executor.submit(mul, 6, 7)
-        future2 = self.executor.submit(time.sleep, 6)
+        short_timeout = 0.050
+        long_timeout = short_timeout * 10
+
+        future = self.executor.submit(time.sleep, long_timeout)
 
         finished, pending = futures.wait(
                 [CANCELLED_AND_NOTIFIED_FUTURE,
                  EXCEPTION_FUTURE,
                  SUCCESSFUL_FUTURE,
-                 future1, future2],
-                timeout=5,
+                 future],
+                timeout=short_timeout,
                 return_when=futures.ALL_COMPLETED)
 
         self.assertEqual(set([CANCELLED_AND_NOTIFIED_FUTURE,
                               EXCEPTION_FUTURE,
-                              SUCCESSFUL_FUTURE,
-                              future1]), finished)
-        self.assertEqual(set([future2]), pending)
+                              SUCCESSFUL_FUTURE]),
+                         finished)
+        self.assertEqual(set([future]), pending)
 
 
 class ThreadPoolWaitTests(ThreadPoolMixin, WaitTests, BaseTestCase):
diff --git a/Lib/test/test_contextlib.py b/Lib/test/test_contextlib.py
index 0f8351ab81..3cc194417f 100644
--- a/Lib/test/test_contextlib.py
+++ b/Lib/test/test_contextlib.py
@@ -157,9 +157,46 @@ def whoo():
                 yield
         ctx = whoo()
         ctx.__enter__()
-        self.assertRaises(
-            RuntimeError, ctx.__exit__, TypeError, TypeError("foo"), None
-        )
+        with self.assertRaises(RuntimeError):
+            ctx.__exit__(TypeError, TypeError("foo"), None)
+        if support.check_impl_detail(cpython=True):
+            # The "gen" attribute is an implementation detail.
+            self.assertFalse(ctx.gen.gi_suspended)
+
+    def test_contextmanager_trap_no_yield(self):
+        @contextmanager
+        def whoo():
+            if False:
+                yield
+        ctx = whoo()
+        with self.assertRaises(RuntimeError):
+            ctx.__enter__()
+
+    def test_contextmanager_trap_second_yield(self):
+        @contextmanager
+        def whoo():
+            yield
+            yield
+        ctx = whoo()
+        ctx.__enter__()
+        with self.assertRaises(RuntimeError):
+            ctx.__exit__(None, None, None)
+        if support.check_impl_detail(cpython=True):
+            # The "gen" attribute is an implementation detail.
+            self.assertFalse(ctx.gen.gi_suspended)
+
+    def test_contextmanager_non_normalised(self):
+        @contextmanager
+        def whoo():
+            try:
+                yield
+            except RuntimeError:
+                raise SyntaxError
+
+        ctx = whoo()
+        ctx.__enter__()
+        with self.assertRaises(SyntaxError):
+            ctx.__exit__(RuntimeError, None, None)
 
     def test_contextmanager_except(self):
         state = []
@@ -240,6 +277,25 @@ def test_issue29692():
             self.assertEqual(ex.args[0], 'issue29692:Unchained')
             self.assertIsNone(ex.__cause__)
 
+    def test_contextmanager_wrap_runtimeerror(self):
+        @contextmanager
+        def woohoo():
+            try:
+                yield
+            except Exception as exc:
+                raise RuntimeError(f'caught {exc}') from exc
+
+        with self.assertRaises(RuntimeError):
+            with woohoo():
+                1 / 0
+
+        # If the context manager wrapped StopIteration in a RuntimeError,
+        # we also unwrap it, because we can't tell whether the wrapping was
+        # done by the generator machinery or by the generator itself.
+        with self.assertRaises(StopIteration):
+            with woohoo():
+                raise StopIteration
+
     def _create_contextmanager_attribs(self):
         def attribs(**kw):
             def decorate(func):
@@ -251,6 +307,7 @@ def decorate(func):
         @attribs(foo='bar')
         def baz(spam):
             """Whee!"""
+            yield
         return baz
 
     def test_contextmanager_attribs(self):
@@ -307,8 +364,11 @@ def woohoo(a, *, b):
 
     def test_recursive(self):
         depth = 0
+        ncols = 0
         @contextmanager
         def woohoo():
+            nonlocal ncols
+            ncols += 1
             nonlocal depth
             before = depth
             depth += 1
@@ -322,6 +382,7 @@ def recursive():
                 recursive()
 
         recursive()
+        self.assertEqual(ncols, 10)
         self.assertEqual(depth, 0)
 
 
diff --git a/Lib/test/test_contextlib_async.py b/Lib/test/test_contextlib_async.py
index 3d43ed0fca..02d3fe7f31 100644
--- a/Lib/test/test_contextlib_async.py
+++ b/Lib/test/test_contextlib_async.py
@@ -49,15 +49,11 @@ async def gen():
             async with ctx():
                 yield 11
 
-        ret = []
-        exc = ValueError(22)
-        with self.assertRaises(ValueError):
-            async with ctx():
-                async for val in gen():
-                    ret.append(val)
-                    raise exc
-
-        self.assertEqual(ret, [11])
+        g = gen()
+        async for val in g:
+            self.assertEqual(val, 11)
+            break
+        await g.aclose()
 
     def test_exit_is_abstract(self):
         class MissingAexit(AbstractAsyncContextManager):
@@ -204,6 +200,9 @@ async def whoo():
         await ctx.__aenter__()
         with self.assertRaises(RuntimeError):
             await ctx.__aexit__(TypeError, TypeError('foo'), None)
+        if support.check_impl_detail(cpython=True):
+            # The "gen" attribute is an implementation detail.
+            self.assertFalse(ctx.gen.ag_suspended)
 
     @_async_test
     async def test_contextmanager_trap_no_yield(self):
@@ -225,6 +224,9 @@ async def whoo():
         await ctx.__aenter__()
         with self.assertRaises(RuntimeError):
             await ctx.__aexit__(None, None, None)
+        if support.check_impl_detail(cpython=True):
+            # The "gen" attribute is an implementation detail.
+            self.assertFalse(ctx.gen.ag_suspended)
 
     @_async_test
     async def test_contextmanager_non_normalised(self):
diff --git a/Lib/test/test_cppext/__init__.py b/Lib/test/test_cppext/__init__.py
index a322f417a7..f02a823bd2 100644
--- a/Lib/test/test_cppext/__init__.py
+++ b/Lib/test/test_cppext/__init__.py
@@ -10,7 +10,6 @@
 from test.support import os_helper
 
 
-MS_WINDOWS = (sys.platform == 'win32')
 SOURCE = os.path.join(os.path.dirname(__file__), 'extension.cpp')
 SETUP = os.path.join(os.path.dirname(__file__), 'setup.py')
 
@@ -27,7 +26,7 @@ def test_build_cpp03(self):
 
     # With MSVC, the linker fails with: cannot open file 'python311.lib'
     # https://github.com/python/cpython/pull/32175#issuecomment-1111175897
-    @unittest.skipIf(MS_WINDOWS, 'test fails on Windows')
+    @unittest.skipIf(support.MS_WINDOWS, 'test fails on Windows')
     # Building and running an extension in clang sanitizing mode is not
     # straightforward
     @unittest.skipIf(
diff --git a/Lib/test/test_cppext/setup.py b/Lib/test/test_cppext/setup.py
index 976633bc33..c7ba1efb4d 100644
--- a/Lib/test/test_cppext/setup.py
+++ b/Lib/test/test_cppext/setup.py
@@ -4,15 +4,13 @@
 import shlex
 import sys
 import sysconfig
+from test import support
 
 from setuptools import setup, Extension
 
 
-MS_WINDOWS = (sys.platform == 'win32')
-
-
 SOURCE = 'extension.cpp'
-if not MS_WINDOWS:
+if not support.MS_WINDOWS:
     # C++ compiler flags for GCC and clang
     CPPFLAGS = [
         # gh-91321: The purpose of _testcppext extension is to check that building
diff --git a/Lib/test/test_ctypes/test_arrays.py b/Lib/test/test_ctypes/test_arrays.py
index 415a5785a9..78aead26da 100644
--- a/Lib/test/test_ctypes/test_arrays.py
+++ b/Lib/test/test_ctypes/test_arrays.py
@@ -178,10 +178,10 @@ def test_bad_subclass(self):
             class T(Array):
                 pass
         with self.assertRaises(AttributeError):
-            class T(Array):
+            class T2(Array):
                 _type_ = c_int
         with self.assertRaises(AttributeError):
-            class T(Array):
+            class T3(Array):
                 _length_ = 13
 
     def test_bad_length(self):
@@ -190,15 +190,15 @@ class T(Array):
                 _type_ = c_int
                 _length_ = - sys.maxsize * 2
         with self.assertRaises(ValueError):
-            class T(Array):
+            class T2(Array):
                 _type_ = c_int
                 _length_ = -1
         with self.assertRaises(TypeError):
-            class T(Array):
+            class T3(Array):
                 _type_ = c_int
                 _length_ = 1.87
         with self.assertRaises(OverflowError):
-            class T(Array):
+            class T4(Array):
                 _type_ = c_int
                 _length_ = sys.maxsize * 2
 
diff --git a/Lib/test/test_ctypes/test_functions.py b/Lib/test/test_ctypes/test_functions.py
index 703bd2c601..bc7f211e53 100644
--- a/Lib/test/test_ctypes/test_functions.py
+++ b/Lib/test/test_ctypes/test_functions.py
@@ -42,16 +42,16 @@ class X(object, Array):
 
         from _ctypes import _Pointer
         with self.assertRaises(TypeError):
-            class X(object, _Pointer):
+            class X2(object, _Pointer):
                 pass
 
         from _ctypes import _SimpleCData
         with self.assertRaises(TypeError):
-            class X(object, _SimpleCData):
+            class X3(object, _SimpleCData):
                 _type_ = "i"
 
         with self.assertRaises(TypeError):
-            class X(object, Structure):
+            class X4(object, Structure):
                 _fields_ = []
 
     def test_c_char_parm(self):
diff --git a/Lib/test/test_dataclasses.py b/Lib/test/test_dataclasses.py
deleted file mode 100644
index 6669f1c57e..0000000000
--- a/Lib/test/test_dataclasses.py
+++ /dev/null
@@ -1,4547 +0,0 @@
-# Deliberately use "from dataclasses import *".  Every name in __all__
-# is tested, so they all must be present.  This is a way to catch
-# missing ones.
-
-from dataclasses import *
-
-import abc
-import io
-import pickle
-import inspect
-import builtins
-import types
-import weakref
-import traceback
-import unittest
-from unittest.mock import Mock
-from typing import ClassVar, Any, List, Union, Tuple, Dict, Generic, TypeVar, Optional, Protocol, DefaultDict
-from typing import get_type_hints
-from collections import deque, OrderedDict, namedtuple, defaultdict
-from functools import total_ordering
-
-import typing       # Needed for the string "typing.ClassVar[int]" to work as an annotation.
-import dataclasses  # Needed for the string "dataclasses.InitVar[int]" to work as an annotation.
-
-# Just any custom exception we can catch.
-class CustomError(Exception): pass
-
-class TestCase(unittest.TestCase):
-    def test_no_fields(self):
-        @dataclass
-        class C:
-            pass
-
-        o = C()
-        self.assertEqual(len(fields(C)), 0)
-
-    def test_no_fields_but_member_variable(self):
-        @dataclass
-        class C:
-            i = 0
-
-        o = C()
-        self.assertEqual(len(fields(C)), 0)
-
-    def test_one_field_no_default(self):
-        @dataclass
-        class C:
-            x: int
-
-        o = C(42)
-        self.assertEqual(o.x, 42)
-
-    def test_field_default_default_factory_error(self):
-        msg = "cannot specify both default and default_factory"
-        with self.assertRaisesRegex(ValueError, msg):
-            @dataclass
-            class C:
-                x: int = field(default=1, default_factory=int)
-
-    def test_field_repr(self):
-        int_field = field(default=1, init=True, repr=False)
-        int_field.name = "id"
-        repr_output = repr(int_field)
-        expected_output = "Field(name='id',type=None," \
-                           f"default=1,default_factory={MISSING!r}," \
-                           "init=True,repr=False,hash=None," \
-                           "compare=True,metadata=mappingproxy({})," \
-                           f"kw_only={MISSING!r}," \
-                           "_field_type=None)"
-
-        self.assertEqual(repr_output, expected_output)
-
-    def test_field_recursive_repr(self):
-        rec_field = field()
-        rec_field.type = rec_field
-        rec_field.name = "id"
-        repr_output = repr(rec_field)
-
-        self.assertIn(",type=...,", repr_output)
-
-    def test_recursive_annotation(self):
-        class C:
-            pass
-
-        @dataclass
-        class D:
-            C: C = field()
-
-        self.assertIn(",type=...,", repr(D.__dataclass_fields__["C"]))
-
-    def test_dataclass_params_repr(self):
-        # Even though this is testing an internal implementation detail,
-        # it's testing a feature we want to make sure is correctly implemented
-        # for the sake of dataclasses itself
-        @dataclass(slots=True, frozen=True)
-        class Some: pass
-
-        repr_output = repr(Some.__dataclass_params__)
-        expected_output = "_DataclassParams(init=True,repr=True," \
-                          "eq=True,order=False,unsafe_hash=False,frozen=True," \
-                          "match_args=True,kw_only=False," \
-                          "slots=True,weakref_slot=False)"
-        self.assertEqual(repr_output, expected_output)
-
-    def test_dataclass_params_signature(self):
-        # Even though this is testing an internal implementation detail,
-        # it's testing a feature we want to make sure is correctly implemented
-        # for the sake of dataclasses itself
-        @dataclass
-        class Some: pass
-
-        for param in inspect.signature(dataclass).parameters:
-            if param == 'cls':
-                continue
-            self.assertTrue(hasattr(Some.__dataclass_params__, param), msg=param)
-
-    def test_named_init_params(self):
-        @dataclass
-        class C:
-            x: int
-
-        o = C(x=32)
-        self.assertEqual(o.x, 32)
-
-    def test_two_fields_one_default(self):
-        @dataclass
-        class C:
-            x: int
-            y: int = 0
-
-        o = C(3)
-        self.assertEqual((o.x, o.y), (3, 0))
-
-        # Non-defaults following defaults.
-        with self.assertRaisesRegex(TypeError,
-                                    "non-default argument 'y' follows "
-                                    "default argument"):
-            @dataclass
-            class C:
-                x: int = 0
-                y: int
-
-        # A derived class adds a non-default field after a default one.
-        with self.assertRaisesRegex(TypeError,
-                                    "non-default argument 'y' follows "
-                                    "default argument"):
-            @dataclass
-            class B:
-                x: int = 0
-
-            @dataclass
-            class C(B):
-                y: int
-
-        # Override a base class field and add a default to
-        #  a field which didn't use to have a default.
-        with self.assertRaisesRegex(TypeError,
-                                    "non-default argument 'y' follows "
-                                    "default argument"):
-            @dataclass
-            class B:
-                x: int
-                y: int
-
-            @dataclass
-            class C(B):
-                x: int = 0
-
-    def test_overwrite_hash(self):
-        # Test that declaring this class isn't an error.  It should
-        #  use the user-provided __hash__.
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            def __hash__(self):
-                return 301
-        self.assertEqual(hash(C(100)), 301)
-
-        # Test that declaring this class isn't an error.  It should
-        #  use the generated __hash__.
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            def __eq__(self, other):
-                return False
-        self.assertEqual(hash(C(100)), hash((100,)))
-
-        # But this one should generate an exception, because with
-        #  unsafe_hash=True, it's an error to have a __hash__ defined.
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __hash__'):
-            @dataclass(unsafe_hash=True)
-            class C:
-                def __hash__(self):
-                    pass
-
-        # Creating this class should not generate an exception,
-        #  because even though __hash__ exists before @dataclass is
-        #  called, (due to __eq__ being defined), since it's None
-        #  that's okay.
-        @dataclass(unsafe_hash=True)
-        class C:
-            x: int
-            def __eq__(self):
-                pass
-        # The generated hash function works as we'd expect.
-        self.assertEqual(hash(C(10)), hash((10,)))
-
-        # Creating this class should generate an exception, because
-        #  __hash__ exists and is not None, which it would be if it
-        #  had been auto-generated due to __eq__ being defined.
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __hash__'):
-            @dataclass(unsafe_hash=True)
-            class C:
-                x: int
-                def __eq__(self):
-                    pass
-                def __hash__(self):
-                    pass
-
-    def test_overwrite_fields_in_derived_class(self):
-        # Note that x from C1 replaces x in Base, but the order remains
-        #  the same as defined in Base.
-        @dataclass
-        class Base:
-            x: Any = 15.0
-            y: int = 0
-
-        @dataclass
-        class C1(Base):
-            z: int = 10
-            x: int = 15
-
-        o = Base()
-        self.assertEqual(repr(o), 'TestCase.test_overwrite_fields_in_derived_class.<locals>.Base(x=15.0, y=0)')
-
-        o = C1()
-        self.assertEqual(repr(o), 'TestCase.test_overwrite_fields_in_derived_class.<locals>.C1(x=15, y=0, z=10)')
-
-        o = C1(x=5)
-        self.assertEqual(repr(o), 'TestCase.test_overwrite_fields_in_derived_class.<locals>.C1(x=5, y=0, z=10)')
-
-    def test_field_named_self(self):
-        @dataclass
-        class C:
-            self: str
-        c=C('foo')
-        self.assertEqual(c.self, 'foo')
-
-        # Make sure the first parameter is not named 'self'.
-        sig = inspect.signature(C.__init__)
-        first = next(iter(sig.parameters))
-        self.assertNotEqual('self', first)
-
-        # But we do use 'self' if no field named self.
-        @dataclass
-        class C:
-            selfx: str
-
-        # Make sure the first parameter is named 'self'.
-        sig = inspect.signature(C.__init__)
-        first = next(iter(sig.parameters))
-        self.assertEqual('self', first)
-
-    def test_field_named_object(self):
-        @dataclass
-        class C:
-            object: str
-        c = C('foo')
-        self.assertEqual(c.object, 'foo')
-
-    def test_field_named_object_frozen(self):
-        @dataclass(frozen=True)
-        class C:
-            object: str
-        c = C('foo')
-        self.assertEqual(c.object, 'foo')
-
-    def test_field_named_BUILTINS_frozen(self):
-        # gh-96151
-        @dataclass(frozen=True)
-        class C:
-            BUILTINS: int
-        c = C(5)
-        self.assertEqual(c.BUILTINS, 5)
-
-    def test_field_with_special_single_underscore_names(self):
-        # gh-98886
-
-        @dataclass
-        class X:
-            x: int = field(default_factory=lambda: 111)
-            _dflt_x: int = field(default_factory=lambda: 222)
-
-        X()
-
-        @dataclass
-        class Y:
-            y: int = field(default_factory=lambda: 111)
-            _HAS_DEFAULT_FACTORY: int = 222
-
-        assert Y(y=222).y == 222
-
-    def test_field_named_like_builtin(self):
-        # Attribute names can shadow built-in names
-        # since code generation is used.
-        # Ensure that this is not happening.
-        exclusions = {'None', 'True', 'False'}
-        builtins_names = sorted(
-            b for b in builtins.__dict__.keys()
-            if not b.startswith('__') and b not in exclusions
-        )
-        attributes = [(name, str) for name in builtins_names]
-        C = make_dataclass('C', attributes)
-
-        c = C(*[name for name in builtins_names])
-
-        for name in builtins_names:
-            self.assertEqual(getattr(c, name), name)
-
-    def test_field_named_like_builtin_frozen(self):
-        # Attribute names can shadow built-in names
-        # since code generation is used.
-        # Ensure that this is not happening
-        # for frozen data classes.
-        exclusions = {'None', 'True', 'False'}
-        builtins_names = sorted(
-            b for b in builtins.__dict__.keys()
-            if not b.startswith('__') and b not in exclusions
-        )
-        attributes = [(name, str) for name in builtins_names]
-        C = make_dataclass('C', attributes, frozen=True)
-
-        c = C(*[name for name in builtins_names])
-
-        for name in builtins_names:
-            self.assertEqual(getattr(c, name), name)
-
-    def test_0_field_compare(self):
-        # Ensure that order=False is the default.
-        @dataclass
-        class C0:
-            pass
-
-        @dataclass(order=False)
-        class C1:
-            pass
-
-        for cls in [C0, C1]:
-            with self.subTest(cls=cls):
-                self.assertEqual(cls(), cls())
-                for idx, fn in enumerate([lambda a, b: a < b,
-                                          lambda a, b: a <= b,
-                                          lambda a, b: a > b,
-                                          lambda a, b: a >= b]):
-                    with self.subTest(idx=idx):
-                        with self.assertRaisesRegex(TypeError,
-                                                    f"not supported between instances of '{cls.__name__}' and '{cls.__name__}'"):
-                            fn(cls(), cls())
-
-        @dataclass(order=True)
-        class C:
-            pass
-        self.assertLessEqual(C(), C())
-        self.assertGreaterEqual(C(), C())
-
-    def test_1_field_compare(self):
-        # Ensure that order=False is the default.
-        @dataclass
-        class C0:
-            x: int
-
-        @dataclass(order=False)
-        class C1:
-            x: int
-
-        for cls in [C0, C1]:
-            with self.subTest(cls=cls):
-                self.assertEqual(cls(1), cls(1))
-                self.assertNotEqual(cls(0), cls(1))
-                for idx, fn in enumerate([lambda a, b: a < b,
-                                          lambda a, b: a <= b,
-                                          lambda a, b: a > b,
-                                          lambda a, b: a >= b]):
-                    with self.subTest(idx=idx):
-                        with self.assertRaisesRegex(TypeError,
-                                                    f"not supported between instances of '{cls.__name__}' and '{cls.__name__}'"):
-                            fn(cls(0), cls(0))
-
-        @dataclass(order=True)
-        class C:
-            x: int
-        self.assertLess(C(0), C(1))
-        self.assertLessEqual(C(0), C(1))
-        self.assertLessEqual(C(1), C(1))
-        self.assertGreater(C(1), C(0))
-        self.assertGreaterEqual(C(1), C(0))
-        self.assertGreaterEqual(C(1), C(1))
-
-    def test_simple_compare(self):
-        # Ensure that order=False is the default.
-        @dataclass
-        class C0:
-            x: int
-            y: int
-
-        @dataclass(order=False)
-        class C1:
-            x: int
-            y: int
-
-        for cls in [C0, C1]:
-            with self.subTest(cls=cls):
-                self.assertEqual(cls(0, 0), cls(0, 0))
-                self.assertEqual(cls(1, 2), cls(1, 2))
-                self.assertNotEqual(cls(1, 0), cls(0, 0))
-                self.assertNotEqual(cls(1, 0), cls(1, 1))
-                for idx, fn in enumerate([lambda a, b: a < b,
-                                          lambda a, b: a <= b,
-                                          lambda a, b: a > b,
-                                          lambda a, b: a >= b]):
-                    with self.subTest(idx=idx):
-                        with self.assertRaisesRegex(TypeError,
-                                                    f"not supported between instances of '{cls.__name__}' and '{cls.__name__}'"):
-                            fn(cls(0, 0), cls(0, 0))
-
-        @dataclass(order=True)
-        class C:
-            x: int
-            y: int
-
-        for idx, fn in enumerate([lambda a, b: a == b,
-                                  lambda a, b: a <= b,
-                                  lambda a, b: a >= b]):
-            with self.subTest(idx=idx):
-                self.assertTrue(fn(C(0, 0), C(0, 0)))
-
-        for idx, fn in enumerate([lambda a, b: a < b,
-                                  lambda a, b: a <= b,
-                                  lambda a, b: a != b]):
-            with self.subTest(idx=idx):
-                self.assertTrue(fn(C(0, 0), C(0, 1)))
-                self.assertTrue(fn(C(0, 1), C(1, 0)))
-                self.assertTrue(fn(C(1, 0), C(1, 1)))
-
-        for idx, fn in enumerate([lambda a, b: a > b,
-                                  lambda a, b: a >= b,
-                                  lambda a, b: a != b]):
-            with self.subTest(idx=idx):
-                self.assertTrue(fn(C(0, 1), C(0, 0)))
-                self.assertTrue(fn(C(1, 0), C(0, 1)))
-                self.assertTrue(fn(C(1, 1), C(1, 0)))
-
-    def test_compare_subclasses(self):
-        # Comparisons fail for subclasses, even if no fields
-        #  are added.
-        @dataclass
-        class B:
-            i: int
-
-        @dataclass
-        class C(B):
-            pass
-
-        for idx, (fn, expected) in enumerate([(lambda a, b: a == b, False),
-                                              (lambda a, b: a != b, True)]):
-            with self.subTest(idx=idx):
-                self.assertEqual(fn(B(0), C(0)), expected)
-
-        for idx, fn in enumerate([lambda a, b: a < b,
-                                  lambda a, b: a <= b,
-                                  lambda a, b: a > b,
-                                  lambda a, b: a >= b]):
-            with self.subTest(idx=idx):
-                with self.assertRaisesRegex(TypeError,
-                                            "not supported between instances of 'B' and 'C'"):
-                    fn(B(0), C(0))
-
-    def test_eq_order(self):
-        # Test combining eq and order.
-        for (eq,    order, result   ) in [
-            (False, False, 'neither'),
-            (False, True,  'exception'),
-            (True,  False, 'eq_only'),
-            (True,  True,  'both'),
-        ]:
-            with self.subTest(eq=eq, order=order):
-                if result == 'exception':
-                    with self.assertRaisesRegex(ValueError, 'eq must be true if order is true'):
-                        @dataclass(eq=eq, order=order)
-                        class C:
-                            pass
-                else:
-                    @dataclass(eq=eq, order=order)
-                    class C:
-                        pass
-
-                    if result == 'neither':
-                        self.assertNotIn('__eq__', C.__dict__)
-                        self.assertNotIn('__lt__', C.__dict__)
-                        self.assertNotIn('__le__', C.__dict__)
-                        self.assertNotIn('__gt__', C.__dict__)
-                        self.assertNotIn('__ge__', C.__dict__)
-                    elif result == 'both':
-                        self.assertIn('__eq__', C.__dict__)
-                        self.assertIn('__lt__', C.__dict__)
-                        self.assertIn('__le__', C.__dict__)
-                        self.assertIn('__gt__', C.__dict__)
-                        self.assertIn('__ge__', C.__dict__)
-                    elif result == 'eq_only':
-                        self.assertIn('__eq__', C.__dict__)
-                        self.assertNotIn('__lt__', C.__dict__)
-                        self.assertNotIn('__le__', C.__dict__)
-                        self.assertNotIn('__gt__', C.__dict__)
-                        self.assertNotIn('__ge__', C.__dict__)
-                    else:
-                        assert False, f'unknown result {result!r}'
-
-    def test_field_no_default(self):
-        @dataclass
-        class C:
-            x: int = field()
-
-        self.assertEqual(C(5).x, 5)
-
-        with self.assertRaisesRegex(TypeError,
-                                    r"__init__\(\) missing 1 required "
-                                    "positional argument: 'x'"):
-            C()
-
-    def test_field_default(self):
-        default = object()
-        @dataclass
-        class C:
-            x: object = field(default=default)
-
-        self.assertIs(C.x, default)
-        c = C(10)
-        self.assertEqual(c.x, 10)
-
-        # If we delete the instance attribute, we should then see the
-        #  class attribute.
-        del c.x
-        self.assertIs(c.x, default)
-
-        self.assertIs(C().x, default)
-
-    def test_not_in_repr(self):
-        @dataclass
-        class C:
-            x: int = field(repr=False)
-        with self.assertRaises(TypeError):
-            C()
-        c = C(10)
-        self.assertEqual(repr(c), 'TestCase.test_not_in_repr.<locals>.C()')
-
-        @dataclass
-        class C:
-            x: int = field(repr=False)
-            y: int
-        c = C(10, 20)
-        self.assertEqual(repr(c), 'TestCase.test_not_in_repr.<locals>.C(y=20)')
-
-    def test_not_in_compare(self):
-        @dataclass
-        class C:
-            x: int = 0
-            y: int = field(compare=False, default=4)
-
-        self.assertEqual(C(), C(0, 20))
-        self.assertEqual(C(1, 10), C(1, 20))
-        self.assertNotEqual(C(3), C(4, 10))
-        self.assertNotEqual(C(3, 10), C(4, 10))
-
-    def test_no_unhashable_default(self):
-        # See bpo-44674.
-        class Unhashable:
-            __hash__ = None
-
-        unhashable_re = 'mutable default .* for field a is not allowed'
-        with self.assertRaisesRegex(ValueError, unhashable_re):
-            @dataclass
-            class A:
-                a: dict = {}
-
-        with self.assertRaisesRegex(ValueError, unhashable_re):
-            @dataclass
-            class A:
-                a: Any = Unhashable()
-
-        # Make sure that the machinery looking for hashability is using the
-        # class's __hash__, not the instance's __hash__.
-        with self.assertRaisesRegex(ValueError, unhashable_re):
-            unhashable = Unhashable()
-            # This shouldn't make the variable hashable.
-            unhashable.__hash__ = lambda: 0
-            @dataclass
-            class A:
-                a: Any = unhashable
-
-    def test_hash_field_rules(self):
-        # Test all 6 cases of:
-        #  hash=True/False/None
-        #  compare=True/False
-        for (hash_,    compare, result  ) in [
-            (True,     False,   'field' ),
-            (True,     True,    'field' ),
-            (False,    False,   'absent'),
-            (False,    True,    'absent'),
-            (None,     False,   'absent'),
-            (None,     True,    'field' ),
-            ]:
-            with self.subTest(hash=hash_, compare=compare):
-                @dataclass(unsafe_hash=True)
-                class C:
-                    x: int = field(compare=compare, hash=hash_, default=5)
-
-                if result == 'field':
-                    # __hash__ contains the field.
-                    self.assertEqual(hash(C(5)), hash((5,)))
-                elif result == 'absent':
-                    # The field is not present in the hash.
-                    self.assertEqual(hash(C(5)), hash(()))
-                else:
-                    assert False, f'unknown result {result!r}'
-
-    def test_init_false_no_default(self):
-        # If init=False and no default value, then the field won't be
-        #  present in the instance.
-        @dataclass
-        class C:
-            x: int = field(init=False)
-
-        self.assertNotIn('x', C().__dict__)
-
-        @dataclass
-        class C:
-            x: int
-            y: int = 0
-            z: int = field(init=False)
-            t: int = 10
-
-        self.assertNotIn('z', C(0).__dict__)
-        self.assertEqual(vars(C(5)), {'t': 10, 'x': 5, 'y': 0})
-
-    def test_class_marker(self):
-        @dataclass
-        class C:
-            x: int
-            y: str = field(init=False, default=None)
-            z: str = field(repr=False)
-
-        the_fields = fields(C)
-        # the_fields is a tuple of 3 items, each value
-        #  is in __annotations__.
-        self.assertIsInstance(the_fields, tuple)
-        for f in the_fields:
-            self.assertIs(type(f), Field)
-            self.assertIn(f.name, C.__annotations__)
-
-        self.assertEqual(len(the_fields), 3)
-
-        self.assertEqual(the_fields[0].name, 'x')
-        self.assertEqual(the_fields[0].type, int)
-        self.assertFalse(hasattr(C, 'x'))
-        self.assertTrue (the_fields[0].init)
-        self.assertTrue (the_fields[0].repr)
-        self.assertEqual(the_fields[1].name, 'y')
-        self.assertEqual(the_fields[1].type, str)
-        self.assertIsNone(getattr(C, 'y'))
-        self.assertFalse(the_fields[1].init)
-        self.assertTrue (the_fields[1].repr)
-        self.assertEqual(the_fields[2].name, 'z')
-        self.assertEqual(the_fields[2].type, str)
-        self.assertFalse(hasattr(C, 'z'))
-        self.assertTrue (the_fields[2].init)
-        self.assertFalse(the_fields[2].repr)
-
-    def test_field_order(self):
-        @dataclass
-        class B:
-            a: str = 'B:a'
-            b: str = 'B:b'
-            c: str = 'B:c'
-
-        @dataclass
-        class C(B):
-            b: str = 'C:b'
-
-        self.assertEqual([(f.name, f.default) for f in fields(C)],
-                         [('a', 'B:a'),
-                          ('b', 'C:b'),
-                          ('c', 'B:c')])
-
-        @dataclass
-        class D(B):
-            c: str = 'D:c'
-
-        self.assertEqual([(f.name, f.default) for f in fields(D)],
-                         [('a', 'B:a'),
-                          ('b', 'B:b'),
-                          ('c', 'D:c')])
-
-        @dataclass
-        class E(D):
-            a: str = 'E:a'
-            d: str = 'E:d'
-
-        self.assertEqual([(f.name, f.default) for f in fields(E)],
-                         [('a', 'E:a'),
-                          ('b', 'B:b'),
-                          ('c', 'D:c'),
-                          ('d', 'E:d')])
-
-    def test_class_attrs(self):
-        # We only have a class attribute if a default value is
-        #  specified, either directly or via a field with a default.
-        default = object()
-        @dataclass
-        class C:
-            x: int
-            y: int = field(repr=False)
-            z: object = default
-            t: int = field(default=100)
-
-        self.assertFalse(hasattr(C, 'x'))
-        self.assertFalse(hasattr(C, 'y'))
-        self.assertIs   (C.z, default)
-        self.assertEqual(C.t, 100)
-
-    def test_disallowed_mutable_defaults(self):
-        # For the known types, don't allow mutable default values.
-        for typ, empty, non_empty in [(list, [], [1]),
-                                      (dict, {}, {0:1}),
-                                      (set, set(), set([1])),
-                                      ]:
-            with self.subTest(typ=typ):
-                # Can't use a zero-length value.
-                with self.assertRaisesRegex(ValueError,
-                                            f'mutable default {typ} for field '
-                                            'x is not allowed'):
-                    @dataclass
-                    class Point:
-                        x: typ = empty
-
-
-                # Nor a non-zero-length value
-                with self.assertRaisesRegex(ValueError,
-                                            f'mutable default {typ} for field '
-                                            'y is not allowed'):
-                    @dataclass
-                    class Point:
-                        y: typ = non_empty
-
-                # Check subtypes also fail.
-                class Subclass(typ): pass
-
-                with self.assertRaisesRegex(ValueError,
-                                            "mutable default .*Subclass'>"
-                                            " for field z is not allowed"
-                                            ):
-                    @dataclass
-                    class Point:
-                        z: typ = Subclass()
-
-                # Because this is a ClassVar, it can be mutable.
-                @dataclass
-                class C:
-                    z: ClassVar[typ] = typ()
-
-                # Because this is a ClassVar, it can be mutable.
-                @dataclass
-                class C:
-                    x: ClassVar[typ] = Subclass()
-
-    def test_deliberately_mutable_defaults(self):
-        # If a mutable default isn't in the known list of
-        #  (list, dict, set), then it's okay.
-        class Mutable:
-            def __init__(self):
-                self.l = []
-
-        @dataclass
-        class C:
-            x: Mutable
-
-        # These 2 instances will share this value of x.
-        lst = Mutable()
-        o1 = C(lst)
-        o2 = C(lst)
-        self.assertEqual(o1, o2)
-        o1.x.l.extend([1, 2])
-        self.assertEqual(o1, o2)
-        self.assertEqual(o1.x.l, [1, 2])
-        self.assertIs(o1.x, o2.x)
-
-    def test_no_options(self):
-        # Call with dataclass().
-        @dataclass()
-        class C:
-            x: int
-
-        self.assertEqual(C(42).x, 42)
-
-    def test_not_tuple(self):
-        # Make sure we can't be compared to a tuple.
-        @dataclass
-        class Point:
-            x: int
-            y: int
-        self.assertNotEqual(Point(1, 2), (1, 2))
-
-        # And that we can't compare to another unrelated dataclass.
-        @dataclass
-        class C:
-            x: int
-            y: int
-        self.assertNotEqual(Point(1, 3), C(1, 3))
-
-    def test_not_other_dataclass(self):
-        # Test that some of the problems with namedtuple don't happen
-        #  here.
-        @dataclass
-        class Point3D:
-            x: int
-            y: int
-            z: int
-
-        @dataclass
-        class Date:
-            year: int
-            month: int
-            day: int
-
-        self.assertNotEqual(Point3D(2017, 6, 3), Date(2017, 6, 3))
-        self.assertNotEqual(Point3D(1, 2, 3), (1, 2, 3))
-
-        # Make sure we can't unpack.
-        with self.assertRaisesRegex(TypeError, 'unpack'):
-            x, y, z = Point3D(4, 5, 6)
-
-        # Make sure another class with the same field names isn't
-        #  equal.
-        @dataclass
-        class Point3Dv1:
-            x: int = 0
-            y: int = 0
-            z: int = 0
-        self.assertNotEqual(Point3D(0, 0, 0), Point3Dv1())
-
-    def test_function_annotations(self):
-        # Some dummy class and instance to use as a default.
-        class F:
-            pass
-        f = F()
-
-        def validate_class(cls):
-            # First, check __annotations__, even though they're not
-            #  function annotations.
-            self.assertEqual(cls.__annotations__['i'], int)
-            self.assertEqual(cls.__annotations__['j'], str)
-            self.assertEqual(cls.__annotations__['k'], F)
-            self.assertEqual(cls.__annotations__['l'], float)
-            self.assertEqual(cls.__annotations__['z'], complex)
-
-            # Verify __init__.
-
-            signature = inspect.signature(cls.__init__)
-            # Check the return type, should be None.
-            self.assertIs(signature.return_annotation, None)
-
-            # Check each parameter.
-            params = iter(signature.parameters.values())
-            param = next(params)
-            # This is testing an internal name, and probably shouldn't be tested.
-            self.assertEqual(param.name, 'self')
-            param = next(params)
-            self.assertEqual(param.name, 'i')
-            self.assertIs   (param.annotation, int)
-            self.assertEqual(param.default, inspect.Parameter.empty)
-            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
-            param = next(params)
-            self.assertEqual(param.name, 'j')
-            self.assertIs   (param.annotation, str)
-            self.assertEqual(param.default, inspect.Parameter.empty)
-            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
-            param = next(params)
-            self.assertEqual(param.name, 'k')
-            self.assertIs   (param.annotation, F)
-            # Don't test for the default, since it's set to MISSING.
-            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
-            param = next(params)
-            self.assertEqual(param.name, 'l')
-            self.assertIs   (param.annotation, float)
-            # Don't test for the default, since it's set to MISSING.
-            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
-            self.assertRaises(StopIteration, next, params)
-
-
-        @dataclass
-        class C:
-            i: int
-            j: str
-            k: F = f
-            l: float=field(default=None)
-            z: complex=field(default=3+4j, init=False)
-
-        validate_class(C)
-
-        # Now repeat with __hash__.
-        @dataclass(frozen=True, unsafe_hash=True)
-        class C:
-            i: int
-            j: str
-            k: F = f
-            l: float=field(default=None)
-            z: complex=field(default=3+4j, init=False)
-
-        validate_class(C)
-
-    def test_missing_default(self):
-        # Test that MISSING works the same as a default not being
-        #  specified.
-        @dataclass
-        class C:
-            x: int=field(default=MISSING)
-        with self.assertRaisesRegex(TypeError,
-                                    r'__init__\(\) missing 1 required '
-                                    'positional argument'):
-            C()
-        self.assertNotIn('x', C.__dict__)
-
-        @dataclass
-        class D:
-            x: int
-        with self.assertRaisesRegex(TypeError,
-                                    r'__init__\(\) missing 1 required '
-                                    'positional argument'):
-            D()
-        self.assertNotIn('x', D.__dict__)
-
-    def test_missing_default_factory(self):
-        # Test that MISSING works the same as a default factory not
-        #  being specified (which is really the same as a default not
-        #  being specified, too).
-        @dataclass
-        class C:
-            x: int=field(default_factory=MISSING)
-        with self.assertRaisesRegex(TypeError,
-                                    r'__init__\(\) missing 1 required '
-                                    'positional argument'):
-            C()
-        self.assertNotIn('x', C.__dict__)
-
-        @dataclass
-        class D:
-            x: int=field(default=MISSING, default_factory=MISSING)
-        with self.assertRaisesRegex(TypeError,
-                                    r'__init__\(\) missing 1 required '
-                                    'positional argument'):
-            D()
-        self.assertNotIn('x', D.__dict__)
-
-    def test_missing_repr(self):
-        self.assertIn('MISSING_TYPE object', repr(MISSING))
-
-    def test_dont_include_other_annotations(self):
-        @dataclass
-        class C:
-            i: int
-            def foo(self) -> int:
-                return 4
-            @property
-            def bar(self) -> int:
-                return 5
-        self.assertEqual(list(C.__annotations__), ['i'])
-        self.assertEqual(C(10).foo(), 4)
-        self.assertEqual(C(10).bar, 5)
-        self.assertEqual(C(10).i, 10)
-
-    def test_post_init(self):
-        # Just make sure it gets called
-        @dataclass
-        class C:
-            def __post_init__(self):
-                raise CustomError()
-        with self.assertRaises(CustomError):
-            C()
-
-        @dataclass
-        class C:
-            i: int = 10
-            def __post_init__(self):
-                if self.i == 10:
-                    raise CustomError()
-        with self.assertRaises(CustomError):
-            C()
-        # post-init gets called, but doesn't raise. This is just
-        #  checking that self is used correctly.
-        C(5)
-
-        # If there's not an __init__, then post-init won't get called.
-        @dataclass(init=False)
-        class C:
-            def __post_init__(self):
-                raise CustomError()
-        # Creating the class won't raise
-        C()
-
-        @dataclass
-        class C:
-            x: int = 0
-            def __post_init__(self):
-                self.x *= 2
-        self.assertEqual(C().x, 0)
-        self.assertEqual(C(2).x, 4)
-
-        # Make sure that if we're frozen, post-init can't set
-        #  attributes.
-        @dataclass(frozen=True)
-        class C:
-            x: int = 0
-            def __post_init__(self):
-                self.x *= 2
-        with self.assertRaises(FrozenInstanceError):
-            C()
-
-    def test_post_init_super(self):
-        # Make sure super() post-init isn't called by default.
-        class B:
-            def __post_init__(self):
-                raise CustomError()
-
-        @dataclass
-        class C(B):
-            def __post_init__(self):
-                self.x = 5
-
-        self.assertEqual(C().x, 5)
-
-        # Now call super(), and it will raise.
-        @dataclass
-        class C(B):
-            def __post_init__(self):
-                super().__post_init__()
-
-        with self.assertRaises(CustomError):
-            C()
-
-        # Make sure post-init is called, even if not defined in our
-        #  class.
-        @dataclass
-        class C(B):
-            pass
-
-        with self.assertRaises(CustomError):
-            C()
-
-    def test_post_init_staticmethod(self):
-        flag = False
-        @dataclass
-        class C:
-            x: int
-            y: int
-            @staticmethod
-            def __post_init__():
-                nonlocal flag
-                flag = True
-
-        self.assertFalse(flag)
-        c = C(3, 4)
-        self.assertEqual((c.x, c.y), (3, 4))
-        self.assertTrue(flag)
-
-    def test_post_init_classmethod(self):
-        @dataclass
-        class C:
-            flag = False
-            x: int
-            y: int
-            @classmethod
-            def __post_init__(cls):
-                cls.flag = True
-
-        self.assertFalse(C.flag)
-        c = C(3, 4)
-        self.assertEqual((c.x, c.y), (3, 4))
-        self.assertTrue(C.flag)
-
-    def test_post_init_not_auto_added(self):
-        # See bpo-46757, which had proposed always adding __post_init__.  As
-        # Raymond Hettinger pointed out, that would be a breaking change.  So,
-        # add a test to make sure that the current behavior doesn't change.
-
-        @dataclass
-        class A0:
-            pass
-
-        @dataclass
-        class B0:
-            b_called: bool = False
-            def __post_init__(self):
-                self.b_called = True
-
-        @dataclass
-        class C0(A0, B0):
-            c_called: bool = False
-            def __post_init__(self):
-                super().__post_init__()
-                self.c_called = True
-
-        # Since A0 has no __post_init__, and one wasn't automatically added
-        # (because that's the rule: it's never added by @dataclass, it's only
-        # the class author that can add it), then B0.__post_init__ is called.
-        # Verify that.
-        c = C0()
-        self.assertTrue(c.b_called)
-        self.assertTrue(c.c_called)
-
-        ######################################
-        # Now, the same thing, except A1 defines __post_init__.
-        @dataclass
-        class A1:
-            def __post_init__(self):
-                pass
-
-        @dataclass
-        class B1:
-            b_called: bool = False
-            def __post_init__(self):
-                self.b_called = True
-
-        @dataclass
-        class C1(A1, B1):
-            c_called: bool = False
-            def __post_init__(self):
-                super().__post_init__()
-                self.c_called = True
-
-        # This time, B1.__post_init__ isn't being called.  This mimics what
-        # would happen if A1.__post_init__ had been automatically added,
-        # instead of manually added as we see here.  This test isn't really
-        # needed, but I'm including it just to demonstrate the changed
-        # behavior when A1 does define __post_init__.
-        c = C1()
-        self.assertFalse(c.b_called)
-        self.assertTrue(c.c_called)
-
-    def test_class_var(self):
-        # Make sure ClassVars are ignored in __init__, __repr__, etc.
-        @dataclass
-        class C:
-            x: int
-            y: int = 10
-            z: ClassVar[int] = 1000
-            w: ClassVar[int] = 2000
-            t: ClassVar[int] = 3000
-            s: ClassVar      = 4000
-
-        c = C(5)
-        self.assertEqual(repr(c), 'TestCase.test_class_var.<locals>.C(x=5, y=10)')
-        self.assertEqual(len(fields(C)), 2)                 # We have 2 fields.
-        self.assertEqual(len(C.__annotations__), 6)         # And 4 ClassVars.
-        self.assertEqual(c.z, 1000)
-        self.assertEqual(c.w, 2000)
-        self.assertEqual(c.t, 3000)
-        self.assertEqual(c.s, 4000)
-        C.z += 1
-        self.assertEqual(c.z, 1001)
-        c = C(20)
-        self.assertEqual((c.x, c.y), (20, 10))
-        self.assertEqual(c.z, 1001)
-        self.assertEqual(c.w, 2000)
-        self.assertEqual(c.t, 3000)
-        self.assertEqual(c.s, 4000)
-
-    def test_class_var_no_default(self):
-        # If a ClassVar has no default value, it should not be set on the class.
-        @dataclass
-        class C:
-            x: ClassVar[int]
-
-        self.assertNotIn('x', C.__dict__)
-
-    def test_class_var_default_factory(self):
-        # It makes no sense for a ClassVar to have a default factory. When
-        #  would it be called? Call it yourself, since it's class-wide.
-        with self.assertRaisesRegex(TypeError,
-                                    'cannot have a default factory'):
-            @dataclass
-            class C:
-                x: ClassVar[int] = field(default_factory=int)
-
-            self.assertNotIn('x', C.__dict__)
-
-    def test_class_var_with_default(self):
-        # If a ClassVar has a default value, it should be set on the class.
-        @dataclass
-        class C:
-            x: ClassVar[int] = 10
-        self.assertEqual(C.x, 10)
-
-        @dataclass
-        class C:
-            x: ClassVar[int] = field(default=10)
-        self.assertEqual(C.x, 10)
-
-    def test_class_var_frozen(self):
-        # Make sure ClassVars work even if we're frozen.
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            y: int = 10
-            z: ClassVar[int] = 1000
-            w: ClassVar[int] = 2000
-            t: ClassVar[int] = 3000
-
-        c = C(5)
-        self.assertEqual(repr(C(5)), 'TestCase.test_class_var_frozen.<locals>.C(x=5, y=10)')
-        self.assertEqual(len(fields(C)), 2)                 # We have 2 fields
-        self.assertEqual(len(C.__annotations__), 5)         # And 3 ClassVars
-        self.assertEqual(c.z, 1000)
-        self.assertEqual(c.w, 2000)
-        self.assertEqual(c.t, 3000)
-        # We can still modify the ClassVar, it's only instances that are
-        #  frozen.
-        C.z += 1
-        self.assertEqual(c.z, 1001)
-        c = C(20)
-        self.assertEqual((c.x, c.y), (20, 10))
-        self.assertEqual(c.z, 1001)
-        self.assertEqual(c.w, 2000)
-        self.assertEqual(c.t, 3000)
-
-    def test_init_var_no_default(self):
-        # If an InitVar has no default value, it should not be set on the class.
-        @dataclass
-        class C:
-            x: InitVar[int]
-
-        self.assertNotIn('x', C.__dict__)
-
-    def test_init_var_default_factory(self):
-        # It makes no sense for an InitVar to have a default factory. When
-        #  would it be called? Call it yourself, since it's class-wide.
-        with self.assertRaisesRegex(TypeError,
-                                    'cannot have a default factory'):
-            @dataclass
-            class C:
-                x: InitVar[int] = field(default_factory=int)
-
-            self.assertNotIn('x', C.__dict__)
-
-    def test_init_var_with_default(self):
-        # If an InitVar has a default value, it should be set on the class.
-        @dataclass
-        class C:
-            x: InitVar[int] = 10
-        self.assertEqual(C.x, 10)
-
-        @dataclass
-        class C:
-            x: InitVar[int] = field(default=10)
-        self.assertEqual(C.x, 10)
-
-    def test_init_var(self):
-        @dataclass
-        class C:
-            x: int = None
-            init_param: InitVar[int] = None
-
-            def __post_init__(self, init_param):
-                if self.x is None:
-                    self.x = init_param*2
-
-        c = C(init_param=10)
-        self.assertEqual(c.x, 20)
-
-    def test_init_var_preserve_type(self):
-        self.assertEqual(InitVar[int].type, int)
-
-        # Make sure the repr is correct.
-        self.assertEqual(repr(InitVar[int]), 'dataclasses.InitVar[int]')
-        self.assertEqual(repr(InitVar[List[int]]),
-                         'dataclasses.InitVar[typing.List[int]]')
-        self.assertEqual(repr(InitVar[list[int]]),
-                         'dataclasses.InitVar[list[int]]')
-        self.assertEqual(repr(InitVar[int|str]),
-                         'dataclasses.InitVar[int | str]')
-
-    def test_init_var_inheritance(self):
-        # Note that this deliberately tests that a dataclass need not
-        #  have a __post_init__ function if it has an InitVar field.
-        #  It could just be used in a derived class, as shown here.
-        @dataclass
-        class Base:
-            x: int
-            init_base: InitVar[int]
-
-        # We can instantiate by passing the InitVar, even though
-        #  it's not used.
-        b = Base(0, 10)
-        self.assertEqual(vars(b), {'x': 0})
-
-        @dataclass
-        class C(Base):
-            y: int
-            init_derived: InitVar[int]
-
-            def __post_init__(self, init_base, init_derived):
-                self.x = self.x + init_base
-                self.y = self.y + init_derived
-
-        c = C(10, 11, 50, 51)
-        self.assertEqual(vars(c), {'x': 21, 'y': 101})
-
-    def test_default_factory(self):
-        # Test a factory that returns a new list.
-        @dataclass
-        class C:
-            x: int
-            y: list = field(default_factory=list)
-
-        c0 = C(3)
-        c1 = C(3)
-        self.assertEqual(c0.x, 3)
-        self.assertEqual(c0.y, [])
-        self.assertEqual(c0, c1)
-        self.assertIsNot(c0.y, c1.y)
-        self.assertEqual(astuple(C(5, [1])), (5, [1]))
-
-        # Test a factory that returns a shared list.
-        l = []
-        @dataclass
-        class C:
-            x: int
-            y: list = field(default_factory=lambda: l)
-
-        c0 = C(3)
-        c1 = C(3)
-        self.assertEqual(c0.x, 3)
-        self.assertEqual(c0.y, [])
-        self.assertEqual(c0, c1)
-        self.assertIs(c0.y, c1.y)
-        self.assertEqual(astuple(C(5, [1])), (5, [1]))
-
-        # Test various other field flags.
-        # repr
-        @dataclass
-        class C:
-            x: list = field(default_factory=list, repr=False)
-        self.assertEqual(repr(C()), 'TestCase.test_default_factory.<locals>.C()')
-        self.assertEqual(C().x, [])
-
-        # hash
-        @dataclass(unsafe_hash=True)
-        class C:
-            x: list = field(default_factory=list, hash=False)
-        self.assertEqual(astuple(C()), ([],))
-        self.assertEqual(hash(C()), hash(()))
-
-        # init (see also test_default_factory_with_no_init)
-        @dataclass
-        class C:
-            x: list = field(default_factory=list, init=False)
-        self.assertEqual(astuple(C()), ([],))
-
-        # compare
-        @dataclass
-        class C:
-            x: list = field(default_factory=list, compare=False)
-        self.assertEqual(C(), C([1]))
-
-    def test_default_factory_with_no_init(self):
-        # We need a factory with a side effect.
-        factory = Mock()
-
-        @dataclass
-        class C:
-            x: list = field(default_factory=factory, init=False)
-
-        # Make sure the default factory is called for each new instance.
-        C().x
-        self.assertEqual(factory.call_count, 1)
-        C().x
-        self.assertEqual(factory.call_count, 2)
-
-    def test_default_factory_not_called_if_value_given(self):
-        # We need a factory that we can test if it's been called.
-        factory = Mock()
-
-        @dataclass
-        class C:
-            x: int = field(default_factory=factory)
-
-        # Make sure that if a field has a default factory function,
-        #  it's not called if a value is specified.
-        C().x
-        self.assertEqual(factory.call_count, 1)
-        self.assertEqual(C(10).x, 10)
-        self.assertEqual(factory.call_count, 1)
-        C().x
-        self.assertEqual(factory.call_count, 2)
-
-    def test_default_factory_derived(self):
-        # See bpo-32896.
-        @dataclass
-        class Foo:
-            x: dict = field(default_factory=dict)
-
-        @dataclass
-        class Bar(Foo):
-            y: int = 1
-
-        self.assertEqual(Foo().x, {})
-        self.assertEqual(Bar().x, {})
-        self.assertEqual(Bar().y, 1)
-
-        @dataclass
-        class Baz(Foo):
-            pass
-        self.assertEqual(Baz().x, {})
-
-    def test_intermediate_non_dataclass(self):
-        # Test that an intermediate class that defines
-        #  annotations does not define fields.
-
-        @dataclass
-        class A:
-            x: int
-
-        class B(A):
-            y: int
-
-        @dataclass
-        class C(B):
-            z: int
-
-        c = C(1, 3)
-        self.assertEqual((c.x, c.z), (1, 3))
-
-        # .y was not initialized.
-        with self.assertRaisesRegex(AttributeError,
-                                    'object has no attribute'):
-            c.y
-
-        # And if we again derive a non-dataclass, no fields are added.
-        class D(C):
-            t: int
-        d = D(4, 5)
-        self.assertEqual((d.x, d.z), (4, 5))
-
-    def test_classvar_default_factory(self):
-        # It's an error for a ClassVar to have a factory function.
-        with self.assertRaisesRegex(TypeError,
-                                    'cannot have a default factory'):
-            @dataclass
-            class C:
-                x: ClassVar[int] = field(default_factory=int)
-
-    def test_is_dataclass(self):
-        class NotDataClass:
-            pass
-
-        self.assertFalse(is_dataclass(0))
-        self.assertFalse(is_dataclass(int))
-        self.assertFalse(is_dataclass(NotDataClass))
-        self.assertFalse(is_dataclass(NotDataClass()))
-
-        @dataclass
-        class C:
-            x: int
-
-        @dataclass
-        class D:
-            d: C
-            e: int
-
-        c = C(10)
-        d = D(c, 4)
-
-        self.assertTrue(is_dataclass(C))
-        self.assertTrue(is_dataclass(c))
-        self.assertFalse(is_dataclass(c.x))
-        self.assertTrue(is_dataclass(d.d))
-        self.assertFalse(is_dataclass(d.e))
-
-    def test_is_dataclass_when_getattr_always_returns(self):
-        # See bpo-37868.
-        class A:
-            def __getattr__(self, key):
-                return 0
-        self.assertFalse(is_dataclass(A))
-        a = A()
-
-        # Also test for an instance attribute.
-        class B:
-            pass
-        b = B()
-        b.__dataclass_fields__ = []
-
-        for obj in a, b:
-            with self.subTest(obj=obj):
-                self.assertFalse(is_dataclass(obj))
-
-                # Indirect tests for _is_dataclass_instance().
-                with self.assertRaisesRegex(TypeError, 'should be called on dataclass instances'):
-                    asdict(obj)
-                with self.assertRaisesRegex(TypeError, 'should be called on dataclass instances'):
-                    astuple(obj)
-                with self.assertRaisesRegex(TypeError, 'should be called on dataclass instances'):
-                    replace(obj, x=0)
-
-    def test_is_dataclass_genericalias(self):
-        @dataclass
-        class A(types.GenericAlias):
-            origin: type
-            args: type
-        self.assertTrue(is_dataclass(A))
-        a = A(list, int)
-        self.assertTrue(is_dataclass(type(a)))
-        self.assertTrue(is_dataclass(a))
-
-
-    def test_helper_fields_with_class_instance(self):
-        # Check that we can call fields() on either a class or instance,
-        #  and get back the same thing.
-        @dataclass
-        class C:
-            x: int
-            y: float
-
-        self.assertEqual(fields(C), fields(C(0, 0.0)))
-
-    def test_helper_fields_exception(self):
-        # Check that TypeError is raised if not passed a dataclass or
-        #  instance.
-        with self.assertRaisesRegex(TypeError, 'dataclass type or instance'):
-            fields(0)
-
-        class C: pass
-        with self.assertRaisesRegex(TypeError, 'dataclass type or instance'):
-            fields(C)
-        with self.assertRaisesRegex(TypeError, 'dataclass type or instance'):
-            fields(C())
-
-    def test_clean_traceback_from_fields_exception(self):
-        stdout = io.StringIO()
-        try:
-            fields(object)
-        except TypeError as exc:
-            traceback.print_exception(exc, file=stdout)
-        printed_traceback = stdout.getvalue()
-        self.assertNotIn("AttributeError", printed_traceback)
-        self.assertNotIn("__dataclass_fields__", printed_traceback)
-
-    def test_helper_asdict(self):
-        # Basic tests for asdict(), it should return a new dictionary.
-        @dataclass
-        class C:
-            x: int
-            y: int
-        c = C(1, 2)
-
-        self.assertEqual(asdict(c), {'x': 1, 'y': 2})
-        self.assertEqual(asdict(c), asdict(c))
-        self.assertIsNot(asdict(c), asdict(c))
-        c.x = 42
-        self.assertEqual(asdict(c), {'x': 42, 'y': 2})
-        self.assertIs(type(asdict(c)), dict)
-
-    def test_helper_asdict_raises_on_classes(self):
-        # asdict() should raise on a class object.
-        @dataclass
-        class C:
-            x: int
-            y: int
-        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
-            asdict(C)
-        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
-            asdict(int)
-
-    def test_helper_asdict_copy_values(self):
-        @dataclass
-        class C:
-            x: int
-            y: List[int] = field(default_factory=list)
-        initial = []
-        c = C(1, initial)
-        d = asdict(c)
-        self.assertEqual(d['y'], initial)
-        self.assertIsNot(d['y'], initial)
-        c = C(1)
-        d = asdict(c)
-        d['y'].append(1)
-        self.assertEqual(c.y, [])
-
-    def test_helper_asdict_nested(self):
-        @dataclass
-        class UserId:
-            token: int
-            group: int
-        @dataclass
-        class User:
-            name: str
-            id: UserId
-        u = User('Joe', UserId(123, 1))
-        d = asdict(u)
-        self.assertEqual(d, {'name': 'Joe', 'id': {'token': 123, 'group': 1}})
-        self.assertIsNot(asdict(u), asdict(u))
-        u.id.group = 2
-        self.assertEqual(asdict(u), {'name': 'Joe',
-                                     'id': {'token': 123, 'group': 2}})
-
-    def test_helper_asdict_builtin_containers(self):
-        @dataclass
-        class User:
-            name: str
-            id: int
-        @dataclass
-        class GroupList:
-            id: int
-            users: List[User]
-        @dataclass
-        class GroupTuple:
-            id: int
-            users: Tuple[User, ...]
-        @dataclass
-        class GroupDict:
-            id: int
-            users: Dict[str, User]
-        a = User('Alice', 1)
-        b = User('Bob', 2)
-        gl = GroupList(0, [a, b])
-        gt = GroupTuple(0, (a, b))
-        gd = GroupDict(0, {'first': a, 'second': b})
-        self.assertEqual(asdict(gl), {'id': 0, 'users': [{'name': 'Alice', 'id': 1},
-                                                         {'name': 'Bob', 'id': 2}]})
-        self.assertEqual(asdict(gt), {'id': 0, 'users': ({'name': 'Alice', 'id': 1},
-                                                         {'name': 'Bob', 'id': 2})})
-        self.assertEqual(asdict(gd), {'id': 0, 'users': {'first': {'name': 'Alice', 'id': 1},
-                                                         'second': {'name': 'Bob', 'id': 2}}})
-
-    def test_helper_asdict_builtin_object_containers(self):
-        @dataclass
-        class Child:
-            d: object
-
-        @dataclass
-        class Parent:
-            child: Child
-
-        self.assertEqual(asdict(Parent(Child([1]))), {'child': {'d': [1]}})
-        self.assertEqual(asdict(Parent(Child({1: 2}))), {'child': {'d': {1: 2}}})
-
-    def test_helper_asdict_factory(self):
-        @dataclass
-        class C:
-            x: int
-            y: int
-        c = C(1, 2)
-        d = asdict(c, dict_factory=OrderedDict)
-        self.assertEqual(d, OrderedDict([('x', 1), ('y', 2)]))
-        self.assertIsNot(d, asdict(c, dict_factory=OrderedDict))
-        c.x = 42
-        d = asdict(c, dict_factory=OrderedDict)
-        self.assertEqual(d, OrderedDict([('x', 42), ('y', 2)]))
-        self.assertIs(type(d), OrderedDict)
-
-    def test_helper_asdict_namedtuple(self):
-        T = namedtuple('T', 'a b c')
-        @dataclass
-        class C:
-            x: str
-            y: T
-        c = C('outer', T(1, C('inner', T(11, 12, 13)), 2))
-
-        d = asdict(c)
-        self.assertEqual(d, {'x': 'outer',
-                             'y': T(1,
-                                    {'x': 'inner',
-                                     'y': T(11, 12, 13)},
-                                    2),
-                             }
-                         )
-
-        # Now with a dict_factory.  OrderedDict is convenient, but
-        # since it compares to dicts, we also need to have separate
-        # assertIs tests.
-        d = asdict(c, dict_factory=OrderedDict)
-        self.assertEqual(d, {'x': 'outer',
-                             'y': T(1,
-                                    {'x': 'inner',
-                                     'y': T(11, 12, 13)},
-                                    2),
-                             }
-                         )
-
-        # Make sure that the returned dicts are actually OrderedDicts.
-        self.assertIs(type(d), OrderedDict)
-        self.assertIs(type(d['y'][1]), OrderedDict)
-
-    def test_helper_asdict_namedtuple_key(self):
-        # Ensure that a field that contains a dict which has a
-        # namedtuple as a key works with asdict().
-
-        @dataclass
-        class C:
-            f: dict
-        T = namedtuple('T', 'a')
-
-        c = C({T('an a'): 0})
-
-        self.assertEqual(asdict(c), {'f': {T(a='an a'): 0}})
-
-    def test_helper_asdict_namedtuple_derived(self):
-        class T(namedtuple('Tbase', 'a')):
-            def my_a(self):
-                return self.a
-
-        @dataclass
-        class C:
-            f: T
-
-        t = T(6)
-        c = C(t)
-
-        d = asdict(c)
-        self.assertEqual(d, {'f': T(a=6)})
-        # Make sure that t has been copied, not used directly.
-        self.assertIsNot(d['f'], t)
-        self.assertEqual(d['f'].my_a(), 6)
-
-    def test_helper_asdict_defaultdict(self):
-        # Ensure asdict() does not throw exceptions when a
-        # defaultdict is a member of a dataclass
-        @dataclass
-        class C:
-            mp: DefaultDict[str, List]
-
-        dd = defaultdict(list)
-        dd["x"].append(12)
-        c = C(mp=dd)
-        d = asdict(c)
-
-        self.assertEqual(d, {"mp": {"x": [12]}})
-        self.assertTrue(d["mp"] is not c.mp)  # make sure defaultdict is copied
-
-    def test_helper_astuple(self):
-        # Basic tests for astuple(), it should return a new tuple.
-        @dataclass
-        class C:
-            x: int
-            y: int = 0
-        c = C(1)
-
-        self.assertEqual(astuple(c), (1, 0))
-        self.assertEqual(astuple(c), astuple(c))
-        self.assertIsNot(astuple(c), astuple(c))
-        c.y = 42
-        self.assertEqual(astuple(c), (1, 42))
-        self.assertIs(type(astuple(c)), tuple)
-
-    def test_helper_astuple_raises_on_classes(self):
-        # astuple() should raise on a class object.
-        @dataclass
-        class C:
-            x: int
-            y: int
-        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
-            astuple(C)
-        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
-            astuple(int)
-
-    def test_helper_astuple_copy_values(self):
-        @dataclass
-        class C:
-            x: int
-            y: List[int] = field(default_factory=list)
-        initial = []
-        c = C(1, initial)
-        t = astuple(c)
-        self.assertEqual(t[1], initial)
-        self.assertIsNot(t[1], initial)
-        c = C(1)
-        t = astuple(c)
-        t[1].append(1)
-        self.assertEqual(c.y, [])
-
-    def test_helper_astuple_nested(self):
-        @dataclass
-        class UserId:
-            token: int
-            group: int
-        @dataclass
-        class User:
-            name: str
-            id: UserId
-        u = User('Joe', UserId(123, 1))
-        t = astuple(u)
-        self.assertEqual(t, ('Joe', (123, 1)))
-        self.assertIsNot(astuple(u), astuple(u))
-        u.id.group = 2
-        self.assertEqual(astuple(u), ('Joe', (123, 2)))
-
-    def test_helper_astuple_builtin_containers(self):
-        @dataclass
-        class User:
-            name: str
-            id: int
-        @dataclass
-        class GroupList:
-            id: int
-            users: List[User]
-        @dataclass
-        class GroupTuple:
-            id: int
-            users: Tuple[User, ...]
-        @dataclass
-        class GroupDict:
-            id: int
-            users: Dict[str, User]
-        a = User('Alice', 1)
-        b = User('Bob', 2)
-        gl = GroupList(0, [a, b])
-        gt = GroupTuple(0, (a, b))
-        gd = GroupDict(0, {'first': a, 'second': b})
-        self.assertEqual(astuple(gl), (0, [('Alice', 1), ('Bob', 2)]))
-        self.assertEqual(astuple(gt), (0, (('Alice', 1), ('Bob', 2))))
-        self.assertEqual(astuple(gd), (0, {'first': ('Alice', 1), 'second': ('Bob', 2)}))
-
-    def test_helper_astuple_builtin_object_containers(self):
-        @dataclass
-        class Child:
-            d: object
-
-        @dataclass
-        class Parent:
-            child: Child
-
-        self.assertEqual(astuple(Parent(Child([1]))), (([1],),))
-        self.assertEqual(astuple(Parent(Child({1: 2}))), (({1: 2},),))
-
-    def test_helper_astuple_factory(self):
-        @dataclass
-        class C:
-            x: int
-            y: int
-        NT = namedtuple('NT', 'x y')
-        def nt(lst):
-            return NT(*lst)
-        c = C(1, 2)
-        t = astuple(c, tuple_factory=nt)
-        self.assertEqual(t, NT(1, 2))
-        self.assertIsNot(t, astuple(c, tuple_factory=nt))
-        c.x = 42
-        t = astuple(c, tuple_factory=nt)
-        self.assertEqual(t, NT(42, 2))
-        self.assertIs(type(t), NT)
-
-    def test_helper_astuple_namedtuple(self):
-        T = namedtuple('T', 'a b c')
-        @dataclass
-        class C:
-            x: str
-            y: T
-        c = C('outer', T(1, C('inner', T(11, 12, 13)), 2))
-
-        t = astuple(c)
-        self.assertEqual(t, ('outer', T(1, ('inner', (11, 12, 13)), 2)))
-
-        # Now, using a tuple_factory.  list is convenient here.
-        t = astuple(c, tuple_factory=list)
-        self.assertEqual(t, ['outer', T(1, ['inner', T(11, 12, 13)], 2)])
-
-    def test_helper_astuple_defaultdict(self):
-        # Ensure astuple() does not throw exceptions when a
-        # defaultdict is a member of a dataclass
-        @dataclass
-        class C:
-            mp: DefaultDict[str, List]
-
-        dd = defaultdict(list)
-        dd["x"].append(12)
-        c = C(mp=dd)
-        t = astuple(c)
-
-        self.assertEqual(t, ({"x": [12]},))
-        self.assertTrue(t[0] is not dd) # make sure defaultdict is copied
-
-    def test_dynamic_class_creation(self):
-        cls_dict = {'__annotations__': {'x': int, 'y': int},
-                    }
-
-        # Create the class.
-        cls = type('C', (), cls_dict)
-
-        # Make it a dataclass.
-        cls1 = dataclass(cls)
-
-        self.assertEqual(cls1, cls)
-        self.assertEqual(asdict(cls(1, 2)), {'x': 1, 'y': 2})
-
-    def test_dynamic_class_creation_using_field(self):
-        cls_dict = {'__annotations__': {'x': int, 'y': int},
-                    'y': field(default=5),
-                    }
-
-        # Create the class.
-        cls = type('C', (), cls_dict)
-
-        # Make it a dataclass.
-        cls1 = dataclass(cls)
-
-        self.assertEqual(cls1, cls)
-        self.assertEqual(asdict(cls1(1)), {'x': 1, 'y': 5})
-
-    def test_init_in_order(self):
-        @dataclass
-        class C:
-            a: int
-            b: int = field()
-            c: list = field(default_factory=list, init=False)
-            d: list = field(default_factory=list)
-            e: int = field(default=4, init=False)
-            f: int = 4
-
-        calls = []
-        def setattr(self, name, value):
-            calls.append((name, value))
-
-        C.__setattr__ = setattr
-        c = C(0, 1)
-        self.assertEqual(('a', 0), calls[0])
-        self.assertEqual(('b', 1), calls[1])
-        self.assertEqual(('c', []), calls[2])
-        self.assertEqual(('d', []), calls[3])
-        self.assertNotIn(('e', 4), calls)
-        self.assertEqual(('f', 4), calls[4])
-
-    def test_items_in_dicts(self):
-        @dataclass
-        class C:
-            a: int
-            b: list = field(default_factory=list, init=False)
-            c: list = field(default_factory=list)
-            d: int = field(default=4, init=False)
-            e: int = 0
-
-        c = C(0)
-        # Class dict
-        self.assertNotIn('a', C.__dict__)
-        self.assertNotIn('b', C.__dict__)
-        self.assertNotIn('c', C.__dict__)
-        self.assertIn('d', C.__dict__)
-        self.assertEqual(C.d, 4)
-        self.assertIn('e', C.__dict__)
-        self.assertEqual(C.e, 0)
-        # Instance dict
-        self.assertIn('a', c.__dict__)
-        self.assertEqual(c.a, 0)
-        self.assertIn('b', c.__dict__)
-        self.assertEqual(c.b, [])
-        self.assertIn('c', c.__dict__)
-        self.assertEqual(c.c, [])
-        self.assertNotIn('d', c.__dict__)
-        self.assertIn('e', c.__dict__)
-        self.assertEqual(c.e, 0)
-
-    def test_alternate_classmethod_constructor(self):
-        # Since __post_init__ can't take params, use a classmethod
-        #  alternate constructor.  This is mostly an example to show
-        #  how to use this technique.
-        @dataclass
-        class C:
-            x: int
-            @classmethod
-            def from_file(cls, filename):
-                # In a real example, create a new instance
-                #  and populate 'x' from contents of a file.
-                value_in_file = 20
-                return cls(value_in_file)
-
-        self.assertEqual(C.from_file('filename').x, 20)
-
-    def test_field_metadata_default(self):
-        # Make sure the default metadata is read-only and of
-        #  zero length.
-        @dataclass
-        class C:
-            i: int
-
-        self.assertFalse(fields(C)[0].metadata)
-        self.assertEqual(len(fields(C)[0].metadata), 0)
-        with self.assertRaisesRegex(TypeError,
-                                    'does not support item assignment'):
-            fields(C)[0].metadata['test'] = 3
-
-    def test_field_metadata_mapping(self):
-        # Make sure only a mapping can be passed as metadata
-        #  zero length.
-        with self.assertRaises(TypeError):
-            @dataclass
-            class C:
-                i: int = field(metadata=0)
-
-        # Make sure an empty dict works.
-        d = {}
-        @dataclass
-        class C:
-            i: int = field(metadata=d)
-        self.assertFalse(fields(C)[0].metadata)
-        self.assertEqual(len(fields(C)[0].metadata), 0)
-        # Update should work (see bpo-35960).
-        d['foo'] = 1
-        self.assertEqual(len(fields(C)[0].metadata), 1)
-        self.assertEqual(fields(C)[0].metadata['foo'], 1)
-        with self.assertRaisesRegex(TypeError,
-                                    'does not support item assignment'):
-            fields(C)[0].metadata['test'] = 3
-
-        # Make sure a non-empty dict works.
-        d = {'test': 10, 'bar': '42', 3: 'three'}
-        @dataclass
-        class C:
-            i: int = field(metadata=d)
-        self.assertEqual(len(fields(C)[0].metadata), 3)
-        self.assertEqual(fields(C)[0].metadata['test'], 10)
-        self.assertEqual(fields(C)[0].metadata['bar'], '42')
-        self.assertEqual(fields(C)[0].metadata[3], 'three')
-        # Update should work.
-        d['foo'] = 1
-        self.assertEqual(len(fields(C)[0].metadata), 4)
-        self.assertEqual(fields(C)[0].metadata['foo'], 1)
-        with self.assertRaises(KeyError):
-            # Non-existent key.
-            fields(C)[0].metadata['baz']
-        with self.assertRaisesRegex(TypeError,
-                                    'does not support item assignment'):
-            fields(C)[0].metadata['test'] = 3
-
-    def test_field_metadata_custom_mapping(self):
-        # Try a custom mapping.
-        class SimpleNameSpace:
-            def __init__(self, **kw):
-                self.__dict__.update(kw)
-
-            def __getitem__(self, item):
-                if item == 'xyzzy':
-                    return 'plugh'
-                return getattr(self, item)
-
-            def __len__(self):
-                return self.__dict__.__len__()
-
-        @dataclass
-        class C:
-            i: int = field(metadata=SimpleNameSpace(a=10))
-
-        self.assertEqual(len(fields(C)[0].metadata), 1)
-        self.assertEqual(fields(C)[0].metadata['a'], 10)
-        with self.assertRaises(AttributeError):
-            fields(C)[0].metadata['b']
-        # Make sure we're still talking to our custom mapping.
-        self.assertEqual(fields(C)[0].metadata['xyzzy'], 'plugh')
-
-    def test_generic_dataclasses(self):
-        T = TypeVar('T')
-
-        @dataclass
-        class LabeledBox(Generic[T]):
-            content: T
-            label: str = '<unknown>'
-
-        box = LabeledBox(42)
-        self.assertEqual(box.content, 42)
-        self.assertEqual(box.label, '<unknown>')
-
-        # Subscripting the resulting class should work, etc.
-        Alias = List[LabeledBox[int]]
-
-    def test_generic_extending(self):
-        S = TypeVar('S')
-        T = TypeVar('T')
-
-        @dataclass
-        class Base(Generic[T, S]):
-            x: T
-            y: S
-
-        @dataclass
-        class DataDerived(Base[int, T]):
-            new_field: str
-        Alias = DataDerived[str]
-        c = Alias(0, 'test1', 'test2')
-        self.assertEqual(astuple(c), (0, 'test1', 'test2'))
-
-        class NonDataDerived(Base[int, T]):
-            def new_method(self):
-                return self.y
-        Alias = NonDataDerived[float]
-        c = Alias(10, 1.0)
-        self.assertEqual(c.new_method(), 1.0)
-
-    def test_generic_dynamic(self):
-        T = TypeVar('T')
-
-        @dataclass
-        class Parent(Generic[T]):
-            x: T
-        Child = make_dataclass('Child', [('y', T), ('z', Optional[T], None)],
-                               bases=(Parent[int], Generic[T]), namespace={'other': 42})
-        self.assertIs(Child[int](1, 2).z, None)
-        self.assertEqual(Child[int](1, 2, 3).z, 3)
-        self.assertEqual(Child[int](1, 2, 3).other, 42)
-        # Check that type aliases work correctly.
-        Alias = Child[T]
-        self.assertEqual(Alias[int](1, 2).x, 1)
-        # Check MRO resolution.
-        self.assertEqual(Child.__mro__, (Child, Parent, Generic, object))
-
-    def test_dataclasses_pickleable(self):
-        global P, Q, R
-        @dataclass
-        class P:
-            x: int
-            y: int = 0
-        @dataclass
-        class Q:
-            x: int
-            y: int = field(default=0, init=False)
-        @dataclass
-        class R:
-            x: int
-            y: List[int] = field(default_factory=list)
-        q = Q(1)
-        q.y = 2
-        samples = [P(1), P(1, 2), Q(1), q, R(1), R(1, [2, 3, 4])]
-        for sample in samples:
-            for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-                with self.subTest(sample=sample, proto=proto):
-                    new_sample = pickle.loads(pickle.dumps(sample, proto))
-                    self.assertEqual(sample.x, new_sample.x)
-                    self.assertEqual(sample.y, new_sample.y)
-                    self.assertIsNot(sample, new_sample)
-                    new_sample.x = 42
-                    another_new_sample = pickle.loads(pickle.dumps(new_sample, proto))
-                    self.assertEqual(new_sample.x, another_new_sample.x)
-                    self.assertEqual(sample.y, another_new_sample.y)
-
-    def test_dataclasses_qualnames(self):
-        @dataclass(order=True, unsafe_hash=True, frozen=True)
-        class A:
-            x: int
-            y: int
-
-        self.assertEqual(A.__init__.__name__, "__init__")
-        for function in (
-            '__eq__',
-            '__lt__',
-            '__le__',
-            '__gt__',
-            '__ge__',
-            '__hash__',
-            '__init__',
-            '__repr__',
-            '__setattr__',
-            '__delattr__',
-        ):
-            self.assertEqual(getattr(A, function).__qualname__, f"TestCase.test_dataclasses_qualnames.<locals>.A.{function}")
-
-        with self.assertRaisesRegex(TypeError, r"A\.__init__\(\) missing"):
-            A()
-
-
-class TestFieldNoAnnotation(unittest.TestCase):
-    def test_field_without_annotation(self):
-        with self.assertRaisesRegex(TypeError,
-                                    "'f' is a field but has no type annotation"):
-            @dataclass
-            class C:
-                f = field()
-
-    def test_field_without_annotation_but_annotation_in_base(self):
-        @dataclass
-        class B:
-            f: int
-
-        with self.assertRaisesRegex(TypeError,
-                                    "'f' is a field but has no type annotation"):
-            # This is still an error: make sure we don't pick up the
-            #  type annotation in the base class.
-            @dataclass
-            class C(B):
-                f = field()
-
-    def test_field_without_annotation_but_annotation_in_base_not_dataclass(self):
-        # Same test, but with the base class not a dataclass.
-        class B:
-            f: int
-
-        with self.assertRaisesRegex(TypeError,
-                                    "'f' is a field but has no type annotation"):
-            # This is still an error: make sure we don't pick up the
-            #  type annotation in the base class.
-            @dataclass
-            class C(B):
-                f = field()
-
-
-class TestDocString(unittest.TestCase):
-    def assertDocStrEqual(self, a, b):
-        # Because 3.6 and 3.7 differ in how inspect.signature work
-        #  (see bpo #32108), for the time being just compare them with
-        #  whitespace stripped.
-        self.assertEqual(a.replace(' ', ''), b.replace(' ', ''))
-
-    def test_existing_docstring_not_overridden(self):
-        @dataclass
-        class C:
-            """Lorem ipsum"""
-            x: int
-
-        self.assertEqual(C.__doc__, "Lorem ipsum")
-
-    def test_docstring_no_fields(self):
-        @dataclass
-        class C:
-            pass
-
-        self.assertDocStrEqual(C.__doc__, "C()")
-
-    def test_docstring_one_field(self):
-        @dataclass
-        class C:
-            x: int
-
-        self.assertDocStrEqual(C.__doc__, "C(x:int)")
-
-    def test_docstring_two_fields(self):
-        @dataclass
-        class C:
-            x: int
-            y: int
-
-        self.assertDocStrEqual(C.__doc__, "C(x:int, y:int)")
-
-    def test_docstring_three_fields(self):
-        @dataclass
-        class C:
-            x: int
-            y: int
-            z: str
-
-        self.assertDocStrEqual(C.__doc__, "C(x:int, y:int, z:str)")
-
-    def test_docstring_one_field_with_default(self):
-        @dataclass
-        class C:
-            x: int = 3
-
-        self.assertDocStrEqual(C.__doc__, "C(x:int=3)")
-
-    def test_docstring_one_field_with_default_none(self):
-        @dataclass
-        class C:
-            x: Union[int, type(None)] = None
-
-        self.assertDocStrEqual(C.__doc__, "C(x:Optional[int]=None)")
-
-    def test_docstring_list_field(self):
-        @dataclass
-        class C:
-            x: List[int]
-
-        self.assertDocStrEqual(C.__doc__, "C(x:List[int])")
-
-    def test_docstring_list_field_with_default_factory(self):
-        @dataclass
-        class C:
-            x: List[int] = field(default_factory=list)
-
-        self.assertDocStrEqual(C.__doc__, "C(x:List[int]=<factory>)")
-
-    def test_docstring_deque_field(self):
-        @dataclass
-        class C:
-            x: deque
-
-        self.assertDocStrEqual(C.__doc__, "C(x:collections.deque)")
-
-    def test_docstring_deque_field_with_default_factory(self):
-        @dataclass
-        class C:
-            x: deque = field(default_factory=deque)
-
-        self.assertDocStrEqual(C.__doc__, "C(x:collections.deque=<factory>)")
-
-    def test_docstring_with_no_signature(self):
-        # See https://github.com/python/cpython/issues/103449
-        class Meta(type):
-            __call__ = dict
-        class Base(metaclass=Meta):
-            pass
-
-        @dataclass
-        class C(Base):
-            pass
-
-        self.assertDocStrEqual(C.__doc__, "C")
-
-
-class TestInit(unittest.TestCase):
-    def test_base_has_init(self):
-        class B:
-            def __init__(self):
-                self.z = 100
-
-        # Make sure that declaring this class doesn't raise an error.
-        #  The issue is that we can't override __init__ in our class,
-        #  but it should be okay to add __init__ to us if our base has
-        #  an __init__.
-        @dataclass
-        class C(B):
-            x: int = 0
-        c = C(10)
-        self.assertEqual(c.x, 10)
-        self.assertNotIn('z', vars(c))
-
-        # Make sure that if we don't add an init, the base __init__
-        #  gets called.
-        @dataclass(init=False)
-        class C(B):
-            x: int = 10
-        c = C()
-        self.assertEqual(c.x, 10)
-        self.assertEqual(c.z, 100)
-
-    def test_no_init(self):
-        @dataclass(init=False)
-        class C:
-            i: int = 0
-        self.assertEqual(C().i, 0)
-
-        @dataclass(init=False)
-        class C:
-            i: int = 2
-            def __init__(self):
-                self.i = 3
-        self.assertEqual(C().i, 3)
-
-    def test_overwriting_init(self):
-        # If the class has __init__, use it no matter the value of
-        #  init=.
-
-        @dataclass
-        class C:
-            x: int
-            def __init__(self, x):
-                self.x = 2 * x
-        self.assertEqual(C(3).x, 6)
-
-        @dataclass(init=True)
-        class C:
-            x: int
-            def __init__(self, x):
-                self.x = 2 * x
-        self.assertEqual(C(4).x, 8)
-
-        @dataclass(init=False)
-        class C:
-            x: int
-            def __init__(self, x):
-                self.x = 2 * x
-        self.assertEqual(C(5).x, 10)
-
-    def test_inherit_from_protocol(self):
-        # Dataclasses inheriting from protocol should preserve their own `__init__`.
-        # See bpo-45081.
-
-        class P(Protocol):
-            a: int
-
-        @dataclass
-        class C(P):
-            a: int
-
-        self.assertEqual(C(5).a, 5)
-
-        @dataclass
-        class D(P):
-            def __init__(self, a):
-                self.a = a * 2
-
-        self.assertEqual(D(5).a, 10)
-
-
-class TestRepr(unittest.TestCase):
-    def test_repr(self):
-        @dataclass
-        class B:
-            x: int
-
-        @dataclass
-        class C(B):
-            y: int = 10
-
-        o = C(4)
-        self.assertEqual(repr(o), 'TestRepr.test_repr.<locals>.C(x=4, y=10)')
-
-        @dataclass
-        class D(C):
-            x: int = 20
-        self.assertEqual(repr(D()), 'TestRepr.test_repr.<locals>.D(x=20, y=10)')
-
-        @dataclass
-        class C:
-            @dataclass
-            class D:
-                i: int
-            @dataclass
-            class E:
-                pass
-        self.assertEqual(repr(C.D(0)), 'TestRepr.test_repr.<locals>.C.D(i=0)')
-        self.assertEqual(repr(C.E()), 'TestRepr.test_repr.<locals>.C.E()')
-
-    def test_no_repr(self):
-        # Test a class with no __repr__ and repr=False.
-        @dataclass(repr=False)
-        class C:
-            x: int
-        self.assertIn(f'{__name__}.TestRepr.test_no_repr.<locals>.C object at',
-                      repr(C(3)))
-
-        # Test a class with a __repr__ and repr=False.
-        @dataclass(repr=False)
-        class C:
-            x: int
-            def __repr__(self):
-                return 'C-class'
-        self.assertEqual(repr(C(3)), 'C-class')
-
-    def test_overwriting_repr(self):
-        # If the class has __repr__, use it no matter the value of
-        #  repr=.
-
-        @dataclass
-        class C:
-            x: int
-            def __repr__(self):
-                return 'x'
-        self.assertEqual(repr(C(0)), 'x')
-
-        @dataclass(repr=True)
-        class C:
-            x: int
-            def __repr__(self):
-                return 'x'
-        self.assertEqual(repr(C(0)), 'x')
-
-        @dataclass(repr=False)
-        class C:
-            x: int
-            def __repr__(self):
-                return 'x'
-        self.assertEqual(repr(C(0)), 'x')
-
-
-class TestEq(unittest.TestCase):
-    def test_no_eq(self):
-        # Test a class with no __eq__ and eq=False.
-        @dataclass(eq=False)
-        class C:
-            x: int
-        self.assertNotEqual(C(0), C(0))
-        c = C(3)
-        self.assertEqual(c, c)
-
-        # Test a class with an __eq__ and eq=False.
-        @dataclass(eq=False)
-        class C:
-            x: int
-            def __eq__(self, other):
-                return other == 10
-        self.assertEqual(C(3), 10)
-
-    def test_overwriting_eq(self):
-        # If the class has __eq__, use it no matter the value of
-        #  eq=.
-
-        @dataclass
-        class C:
-            x: int
-            def __eq__(self, other):
-                return other == 3
-        self.assertEqual(C(1), 3)
-        self.assertNotEqual(C(1), 1)
-
-        @dataclass(eq=True)
-        class C:
-            x: int
-            def __eq__(self, other):
-                return other == 4
-        self.assertEqual(C(1), 4)
-        self.assertNotEqual(C(1), 1)
-
-        @dataclass(eq=False)
-        class C:
-            x: int
-            def __eq__(self, other):
-                return other == 5
-        self.assertEqual(C(1), 5)
-        self.assertNotEqual(C(1), 1)
-
-
-class TestOrdering(unittest.TestCase):
-    def test_functools_total_ordering(self):
-        # Test that functools.total_ordering works with this class.
-        @total_ordering
-        @dataclass
-        class C:
-            x: int
-            def __lt__(self, other):
-                # Perform the test "backward", just to make
-                #  sure this is being called.
-                return self.x >= other
-
-        self.assertLess(C(0), -1)
-        self.assertLessEqual(C(0), -1)
-        self.assertGreater(C(0), 1)
-        self.assertGreaterEqual(C(0), 1)
-
-    def test_no_order(self):
-        # Test that no ordering functions are added by default.
-        @dataclass(order=False)
-        class C:
-            x: int
-        # Make sure no order methods are added.
-        self.assertNotIn('__le__', C.__dict__)
-        self.assertNotIn('__lt__', C.__dict__)
-        self.assertNotIn('__ge__', C.__dict__)
-        self.assertNotIn('__gt__', C.__dict__)
-
-        # Test that __lt__ is still called
-        @dataclass(order=False)
-        class C:
-            x: int
-            def __lt__(self, other):
-                return False
-        # Make sure other methods aren't added.
-        self.assertNotIn('__le__', C.__dict__)
-        self.assertNotIn('__ge__', C.__dict__)
-        self.assertNotIn('__gt__', C.__dict__)
-
-    def test_overwriting_order(self):
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __lt__'
-                                    '.*using functools.total_ordering'):
-            @dataclass(order=True)
-            class C:
-                x: int
-                def __lt__(self):
-                    pass
-
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __le__'
-                                    '.*using functools.total_ordering'):
-            @dataclass(order=True)
-            class C:
-                x: int
-                def __le__(self):
-                    pass
-
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __gt__'
-                                    '.*using functools.total_ordering'):
-            @dataclass(order=True)
-            class C:
-                x: int
-                def __gt__(self):
-                    pass
-
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __ge__'
-                                    '.*using functools.total_ordering'):
-            @dataclass(order=True)
-            class C:
-                x: int
-                def __ge__(self):
-                    pass
-
-class TestHash(unittest.TestCase):
-    def test_unsafe_hash(self):
-        @dataclass(unsafe_hash=True)
-        class C:
-            x: int
-            y: str
-        self.assertEqual(hash(C(1, 'foo')), hash((1, 'foo')))
-
-    def test_hash_rules(self):
-        def non_bool(value):
-            # Map to something else that's True, but not a bool.
-            if value is None:
-                return None
-            if value:
-                return (3,)
-            return 0
-
-        def test(case, unsafe_hash, eq, frozen, with_hash, result):
-            with self.subTest(case=case, unsafe_hash=unsafe_hash, eq=eq,
-                              frozen=frozen):
-                if result != 'exception':
-                    if with_hash:
-                        @dataclass(unsafe_hash=unsafe_hash, eq=eq, frozen=frozen)
-                        class C:
-                            def __hash__(self):
-                                return 0
-                    else:
-                        @dataclass(unsafe_hash=unsafe_hash, eq=eq, frozen=frozen)
-                        class C:
-                            pass
-
-                # See if the result matches what's expected.
-                if result == 'fn':
-                    # __hash__ contains the function we generated.
-                    self.assertIn('__hash__', C.__dict__)
-                    self.assertIsNotNone(C.__dict__['__hash__'])
-
-                elif result == '':
-                    # __hash__ is not present in our class.
-                    if not with_hash:
-                        self.assertNotIn('__hash__', C.__dict__)
-
-                elif result == 'none':
-                    # __hash__ is set to None.
-                    self.assertIn('__hash__', C.__dict__)
-                    self.assertIsNone(C.__dict__['__hash__'])
-
-                elif result == 'exception':
-                    # Creating the class should cause an exception.
-                    #  This only happens with with_hash==True.
-                    assert(with_hash)
-                    with self.assertRaisesRegex(TypeError, 'Cannot overwrite attribute __hash__'):
-                        @dataclass(unsafe_hash=unsafe_hash, eq=eq, frozen=frozen)
-                        class C:
-                            def __hash__(self):
-                                return 0
-
-                else:
-                    assert False, f'unknown result {result!r}'
-
-        # There are 8 cases of:
-        #  unsafe_hash=True/False
-        #  eq=True/False
-        #  frozen=True/False
-        # And for each of these, a different result if
-        #  __hash__ is defined or not.
-        for case, (unsafe_hash,  eq,    frozen, res_no_defined_hash, res_defined_hash) in enumerate([
-                  (False,        False, False,  '',                  ''),
-                  (False,        False, True,   '',                  ''),
-                  (False,        True,  False,  'none',              ''),
-                  (False,        True,  True,   'fn',                ''),
-                  (True,         False, False,  'fn',                'exception'),
-                  (True,         False, True,   'fn',                'exception'),
-                  (True,         True,  False,  'fn',                'exception'),
-                  (True,         True,  True,   'fn',                'exception'),
-                  ], 1):
-            test(case, unsafe_hash, eq, frozen, False, res_no_defined_hash)
-            test(case, unsafe_hash, eq, frozen, True,  res_defined_hash)
-
-            # Test non-bool truth values, too.  This is just to
-            #  make sure the data-driven table in the decorator
-            #  handles non-bool values.
-            test(case, non_bool(unsafe_hash), non_bool(eq), non_bool(frozen), False, res_no_defined_hash)
-            test(case, non_bool(unsafe_hash), non_bool(eq), non_bool(frozen), True,  res_defined_hash)
-
-
-    def test_eq_only(self):
-        # If a class defines __eq__, __hash__ is automatically added
-        #  and set to None.  This is normal Python behavior, not
-        #  related to dataclasses.  Make sure we don't interfere with
-        #  that (see bpo=32546).
-
-        @dataclass
-        class C:
-            i: int
-            def __eq__(self, other):
-                return self.i == other.i
-        self.assertEqual(C(1), C(1))
-        self.assertNotEqual(C(1), C(4))
-
-        # And make sure things work in this case if we specify
-        #  unsafe_hash=True.
-        @dataclass(unsafe_hash=True)
-        class C:
-            i: int
-            def __eq__(self, other):
-                return self.i == other.i
-        self.assertEqual(C(1), C(1.0))
-        self.assertEqual(hash(C(1)), hash(C(1.0)))
-
-        # And check that the classes __eq__ is being used, despite
-        #  specifying eq=True.
-        @dataclass(unsafe_hash=True, eq=True)
-        class C:
-            i: int
-            def __eq__(self, other):
-                return self.i == 3 and self.i == other.i
-        self.assertEqual(C(3), C(3))
-        self.assertNotEqual(C(1), C(1))
-        self.assertEqual(hash(C(1)), hash(C(1.0)))
-
-    def test_0_field_hash(self):
-        @dataclass(frozen=True)
-        class C:
-            pass
-        self.assertEqual(hash(C()), hash(()))
-
-        @dataclass(unsafe_hash=True)
-        class C:
-            pass
-        self.assertEqual(hash(C()), hash(()))
-
-    def test_1_field_hash(self):
-        @dataclass(frozen=True)
-        class C:
-            x: int
-        self.assertEqual(hash(C(4)), hash((4,)))
-        self.assertEqual(hash(C(42)), hash((42,)))
-
-        @dataclass(unsafe_hash=True)
-        class C:
-            x: int
-        self.assertEqual(hash(C(4)), hash((4,)))
-        self.assertEqual(hash(C(42)), hash((42,)))
-
-    def test_hash_no_args(self):
-        # Test dataclasses with no hash= argument.  This exists to
-        #  make sure that if the @dataclass parameter name is changed
-        #  or the non-default hashing behavior changes, the default
-        #  hashability keeps working the same way.
-
-        class Base:
-            def __hash__(self):
-                return 301
-
-        # If frozen or eq is None, then use the default value (do not
-        #  specify any value in the decorator).
-        for frozen, eq,    base,   expected       in [
-            (None,  None,  object, 'unhashable'),
-            (None,  None,  Base,   'unhashable'),
-            (None,  False, object, 'object'),
-            (None,  False, Base,   'base'),
-            (None,  True,  object, 'unhashable'),
-            (None,  True,  Base,   'unhashable'),
-            (False, None,  object, 'unhashable'),
-            (False, None,  Base,   'unhashable'),
-            (False, False, object, 'object'),
-            (False, False, Base,   'base'),
-            (False, True,  object, 'unhashable'),
-            (False, True,  Base,   'unhashable'),
-            (True,  None,  object, 'tuple'),
-            (True,  None,  Base,   'tuple'),
-            (True,  False, object, 'object'),
-            (True,  False, Base,   'base'),
-            (True,  True,  object, 'tuple'),
-            (True,  True,  Base,   'tuple'),
-            ]:
-
-            with self.subTest(frozen=frozen, eq=eq, base=base, expected=expected):
-                # First, create the class.
-                if frozen is None and eq is None:
-                    @dataclass
-                    class C(base):
-                        i: int
-                elif frozen is None:
-                    @dataclass(eq=eq)
-                    class C(base):
-                        i: int
-                elif eq is None:
-                    @dataclass(frozen=frozen)
-                    class C(base):
-                        i: int
-                else:
-                    @dataclass(frozen=frozen, eq=eq)
-                    class C(base):
-                        i: int
-
-                # Now, make sure it hashes as expected.
-                if expected == 'unhashable':
-                    c = C(10)
-                    with self.assertRaisesRegex(TypeError, 'unhashable type'):
-                        hash(c)
-
-                elif expected == 'base':
-                    self.assertEqual(hash(C(10)), 301)
-
-                elif expected == 'object':
-                    # I'm not sure what test to use here.  object's
-                    #  hash isn't based on id(), so calling hash()
-                    #  won't tell us much.  So, just check the
-                    #  function used is object's.
-                    self.assertIs(C.__hash__, object.__hash__)
-
-                elif expected == 'tuple':
-                    self.assertEqual(hash(C(42)), hash((42,)))
-
-                else:
-                    assert False, f'unknown value for expected={expected!r}'
-
-
-class TestFrozen(unittest.TestCase):
-    def test_frozen(self):
-        @dataclass(frozen=True)
-        class C:
-            i: int
-
-        c = C(10)
-        self.assertEqual(c.i, 10)
-        with self.assertRaises(FrozenInstanceError):
-            c.i = 5
-        self.assertEqual(c.i, 10)
-
-    def test_frozen_empty(self):
-        @dataclass(frozen=True)
-        class C:
-            pass
-
-        c = C()
-        self.assertFalse(hasattr(c, 'i'))
-        with self.assertRaises(FrozenInstanceError):
-            c.i = 5
-        self.assertFalse(hasattr(c, 'i'))
-        with self.assertRaises(FrozenInstanceError):
-            del c.i
-
-    def test_inherit(self):
-        @dataclass(frozen=True)
-        class C:
-            i: int
-
-        @dataclass(frozen=True)
-        class D(C):
-            j: int
-
-        d = D(0, 10)
-        with self.assertRaises(FrozenInstanceError):
-            d.i = 5
-        with self.assertRaises(FrozenInstanceError):
-            d.j = 6
-        self.assertEqual(d.i, 0)
-        self.assertEqual(d.j, 10)
-
-    def test_inherit_nonfrozen_from_empty_frozen(self):
-        @dataclass(frozen=True)
-        class C:
-            pass
-
-        with self.assertRaisesRegex(TypeError,
-                                    'cannot inherit non-frozen dataclass from a frozen one'):
-            @dataclass
-            class D(C):
-                j: int
-
-    def test_inherit_nonfrozen_from_empty(self):
-        @dataclass
-        class C:
-            pass
-
-        @dataclass
-        class D(C):
-            j: int
-
-        d = D(3)
-        self.assertEqual(d.j, 3)
-        self.assertIsInstance(d, C)
-
-    # Test both ways: with an intermediate normal (non-dataclass)
-    #  class and without an intermediate class.
-    def test_inherit_nonfrozen_from_frozen(self):
-        for intermediate_class in [True, False]:
-            with self.subTest(intermediate_class=intermediate_class):
-                @dataclass(frozen=True)
-                class C:
-                    i: int
-
-                if intermediate_class:
-                    class I(C): pass
-                else:
-                    I = C
-
-                with self.assertRaisesRegex(TypeError,
-                                            'cannot inherit non-frozen dataclass from a frozen one'):
-                    @dataclass
-                    class D(I):
-                        pass
-
-    def test_inherit_frozen_from_nonfrozen(self):
-        for intermediate_class in [True, False]:
-            with self.subTest(intermediate_class=intermediate_class):
-                @dataclass
-                class C:
-                    i: int
-
-                if intermediate_class:
-                    class I(C): pass
-                else:
-                    I = C
-
-                with self.assertRaisesRegex(TypeError,
-                                            'cannot inherit frozen dataclass from a non-frozen one'):
-                    @dataclass(frozen=True)
-                    class D(I):
-                        pass
-
-    def test_inherit_from_normal_class(self):
-        for intermediate_class in [True, False]:
-            with self.subTest(intermediate_class=intermediate_class):
-                class C:
-                    pass
-
-                if intermediate_class:
-                    class I(C): pass
-                else:
-                    I = C
-
-                @dataclass(frozen=True)
-                class D(I):
-                    i: int
-
-            d = D(10)
-            with self.assertRaises(FrozenInstanceError):
-                d.i = 5
-
-    def test_non_frozen_normal_derived(self):
-        # See bpo-32953.
-
-        @dataclass(frozen=True)
-        class D:
-            x: int
-            y: int = 10
-
-        class S(D):
-            pass
-
-        s = S(3)
-        self.assertEqual(s.x, 3)
-        self.assertEqual(s.y, 10)
-        s.cached = True
-
-        # But can't change the frozen attributes.
-        with self.assertRaises(FrozenInstanceError):
-            s.x = 5
-        with self.assertRaises(FrozenInstanceError):
-            s.y = 5
-        self.assertEqual(s.x, 3)
-        self.assertEqual(s.y, 10)
-        self.assertEqual(s.cached, True)
-
-        with self.assertRaises(FrozenInstanceError):
-            del s.x
-        self.assertEqual(s.x, 3)
-        with self.assertRaises(FrozenInstanceError):
-            del s.y
-        self.assertEqual(s.y, 10)
-        del s.cached
-        self.assertFalse(hasattr(s, 'cached'))
-        with self.assertRaises(AttributeError) as cm:
-            del s.cached
-        self.assertNotIsInstance(cm.exception, FrozenInstanceError)
-
-    def test_non_frozen_normal_derived_from_empty_frozen(self):
-        @dataclass(frozen=True)
-        class D:
-            pass
-
-        class S(D):
-            pass
-
-        s = S()
-        self.assertFalse(hasattr(s, 'x'))
-        s.x = 5
-        self.assertEqual(s.x, 5)
-
-        del s.x
-        self.assertFalse(hasattr(s, 'x'))
-        with self.assertRaises(AttributeError) as cm:
-            del s.x
-        self.assertNotIsInstance(cm.exception, FrozenInstanceError)
-
-    def test_overwriting_frozen(self):
-        # frozen uses __setattr__ and __delattr__.
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __setattr__'):
-            @dataclass(frozen=True)
-            class C:
-                x: int
-                def __setattr__(self):
-                    pass
-
-        with self.assertRaisesRegex(TypeError,
-                                    'Cannot overwrite attribute __delattr__'):
-            @dataclass(frozen=True)
-            class C:
-                x: int
-                def __delattr__(self):
-                    pass
-
-        @dataclass(frozen=False)
-        class C:
-            x: int
-            def __setattr__(self, name, value):
-                self.__dict__['x'] = value * 2
-        self.assertEqual(C(10).x, 20)
-
-    def test_frozen_hash(self):
-        @dataclass(frozen=True)
-        class C:
-            x: Any
-
-        # If x is immutable, we can compute the hash.  No exception is
-        # raised.
-        hash(C(3))
-
-        # If x is mutable, computing the hash is an error.
-        with self.assertRaisesRegex(TypeError, 'unhashable type'):
-            hash(C({}))
-
-
-class TestSlots(unittest.TestCase):
-    def test_simple(self):
-        @dataclass
-        class C:
-            __slots__ = ('x',)
-            x: Any
-
-        # There was a bug where a variable in a slot was assumed to
-        #  also have a default value (of type
-        #  types.MemberDescriptorType).
-        with self.assertRaisesRegex(TypeError,
-                                    r"__init__\(\) missing 1 required positional argument: 'x'"):
-            C()
-
-        # We can create an instance, and assign to x.
-        c = C(10)
-        self.assertEqual(c.x, 10)
-        c.x = 5
-        self.assertEqual(c.x, 5)
-
-        # We can't assign to anything else.
-        with self.assertRaisesRegex(AttributeError, "'C' object has no attribute 'y'"):
-            c.y = 5
-
-    def test_derived_added_field(self):
-        # See bpo-33100.
-        @dataclass
-        class Base:
-            __slots__ = ('x',)
-            x: Any
-
-        @dataclass
-        class Derived(Base):
-            x: int
-            y: int
-
-        d = Derived(1, 2)
-        self.assertEqual((d.x, d.y), (1, 2))
-
-        # We can add a new field to the derived instance.
-        d.z = 10
-
-    def test_generated_slots(self):
-        @dataclass(slots=True)
-        class C:
-            x: int
-            y: int
-
-        c = C(1, 2)
-        self.assertEqual((c.x, c.y), (1, 2))
-
-        c.x = 3
-        c.y = 4
-        self.assertEqual((c.x, c.y), (3, 4))
-
-        with self.assertRaisesRegex(AttributeError, "'C' object has no attribute 'z'"):
-            c.z = 5
-
-    def test_add_slots_when_slots_exists(self):
-        with self.assertRaisesRegex(TypeError, '^C already specifies __slots__$'):
-            @dataclass(slots=True)
-            class C:
-                __slots__ = ('x',)
-                x: int
-
-    def test_generated_slots_value(self):
-
-        class Root:
-            __slots__ = {'x'}
-
-        class Root2(Root):
-            __slots__ = {'k': '...', 'j': ''}
-
-        class Root3(Root2):
-            __slots__ = ['h']
-
-        class Root4(Root3):
-            __slots__ = 'aa'
-
-        @dataclass(slots=True)
-        class Base(Root4):
-            y: int
-            j: str
-            h: str
-
-        self.assertEqual(Base.__slots__, ('y', ))
-
-        @dataclass(slots=True)
-        class Derived(Base):
-            aa: float
-            x: str
-            z: int
-            k: str
-            h: str
-
-        self.assertEqual(Derived.__slots__, ('z', ))
-
-        @dataclass
-        class AnotherDerived(Base):
-            z: int
-
-        self.assertNotIn('__slots__', AnotherDerived.__dict__)
-
-    def test_cant_inherit_from_iterator_slots(self):
-
-        class Root:
-            __slots__ = iter(['a'])
-
-        class Root2(Root):
-            __slots__ = ('b', )
-
-        with self.assertRaisesRegex(
-           TypeError,
-            "^Slots of 'Root' cannot be determined"
-        ):
-            @dataclass(slots=True)
-            class C(Root2):
-                x: int
-
-    def test_returns_new_class(self):
-        class A:
-            x: int
-
-        B = dataclass(A, slots=True)
-        self.assertIsNot(A, B)
-
-        self.assertFalse(hasattr(A, "__slots__"))
-        self.assertTrue(hasattr(B, "__slots__"))
-
-    # Can't be local to test_frozen_pickle.
-    @dataclass(frozen=True, slots=True)
-    class FrozenSlotsClass:
-        foo: str
-        bar: int
-
-    @dataclass(frozen=True)
-    class FrozenWithoutSlotsClass:
-        foo: str
-        bar: int
-
-    def test_frozen_pickle(self):
-        # bpo-43999
-
-        self.assertEqual(self.FrozenSlotsClass.__slots__, ("foo", "bar"))
-        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(proto=proto):
-                obj = self.FrozenSlotsClass("a", 1)
-                p = pickle.loads(pickle.dumps(obj, protocol=proto))
-                self.assertIsNot(obj, p)
-                self.assertEqual(obj, p)
-
-                obj = self.FrozenWithoutSlotsClass("a", 1)
-                p = pickle.loads(pickle.dumps(obj, protocol=proto))
-                self.assertIsNot(obj, p)
-                self.assertEqual(obj, p)
-
-    @dataclass(frozen=True, slots=True)
-    class FrozenSlotsGetStateClass:
-        foo: str
-        bar: int
-
-        getstate_called: bool = field(default=False, compare=False)
-
-        def __getstate__(self):
-            object.__setattr__(self, 'getstate_called', True)
-            return [self.foo, self.bar]
-
-    @dataclass(frozen=True, slots=True)
-    class FrozenSlotsSetStateClass:
-        foo: str
-        bar: int
-
-        setstate_called: bool = field(default=False, compare=False)
-
-        def __setstate__(self, state):
-            object.__setattr__(self, 'setstate_called', True)
-            object.__setattr__(self, 'foo', state[0])
-            object.__setattr__(self, 'bar', state[1])
-
-    @dataclass(frozen=True, slots=True)
-    class FrozenSlotsAllStateClass:
-        foo: str
-        bar: int
-
-        getstate_called: bool = field(default=False, compare=False)
-        setstate_called: bool = field(default=False, compare=False)
-
-        def __getstate__(self):
-            object.__setattr__(self, 'getstate_called', True)
-            return [self.foo, self.bar]
-
-        def __setstate__(self, state):
-            object.__setattr__(self, 'setstate_called', True)
-            object.__setattr__(self, 'foo', state[0])
-            object.__setattr__(self, 'bar', state[1])
-
-    def test_frozen_slots_pickle_custom_state(self):
-        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(proto=proto):
-                obj = self.FrozenSlotsGetStateClass('a', 1)
-                dumped = pickle.dumps(obj, protocol=proto)
-
-                self.assertTrue(obj.getstate_called)
-                self.assertEqual(obj, pickle.loads(dumped))
-
-        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(proto=proto):
-                obj = self.FrozenSlotsSetStateClass('a', 1)
-                obj2 = pickle.loads(pickle.dumps(obj, protocol=proto))
-
-                self.assertTrue(obj2.setstate_called)
-                self.assertEqual(obj, obj2)
-
-        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(proto=proto):
-                obj = self.FrozenSlotsAllStateClass('a', 1)
-                dumped = pickle.dumps(obj, protocol=proto)
-
-                self.assertTrue(obj.getstate_called)
-
-                obj2 = pickle.loads(dumped)
-                self.assertTrue(obj2.setstate_called)
-                self.assertEqual(obj, obj2)
-
-    def test_slots_with_default_no_init(self):
-        # Originally reported in bpo-44649.
-        @dataclass(slots=True)
-        class A:
-            a: str
-            b: str = field(default='b', init=False)
-
-        obj = A("a")
-        self.assertEqual(obj.a, 'a')
-        self.assertEqual(obj.b, 'b')
-
-    def test_slots_with_default_factory_no_init(self):
-        # Originally reported in bpo-44649.
-        @dataclass(slots=True)
-        class A:
-            a: str
-            b: str = field(default_factory=lambda:'b', init=False)
-
-        obj = A("a")
-        self.assertEqual(obj.a, 'a')
-        self.assertEqual(obj.b, 'b')
-
-    def test_slots_no_weakref(self):
-        @dataclass(slots=True)
-        class A:
-            # No weakref.
-            pass
-
-        self.assertNotIn("__weakref__", A.__slots__)
-        a = A()
-        with self.assertRaisesRegex(TypeError,
-                                    "cannot create weak reference"):
-            weakref.ref(a)
-        with self.assertRaises(AttributeError):
-            a.__weakref__
-
-    def test_slots_weakref(self):
-        @dataclass(slots=True, weakref_slot=True)
-        class A:
-            a: int
-
-        self.assertIn("__weakref__", A.__slots__)
-        a = A(1)
-        a_ref = weakref.ref(a)
-
-        self.assertIs(a.__weakref__, a_ref)
-
-    def test_slots_weakref_base_str(self):
-        class Base:
-            __slots__ = '__weakref__'
-
-        @dataclass(slots=True)
-        class A(Base):
-            a: int
-
-        # __weakref__ is in the base class, not A.  But an A is still weakref-able.
-        self.assertIn("__weakref__", Base.__slots__)
-        self.assertNotIn("__weakref__", A.__slots__)
-        a = A(1)
-        weakref.ref(a)
-
-    def test_slots_weakref_base_tuple(self):
-        # Same as test_slots_weakref_base, but use a tuple instead of a string
-        # in the base class.
-        class Base:
-            __slots__ = ('__weakref__',)
-
-        @dataclass(slots=True)
-        class A(Base):
-            a: int
-
-        # __weakref__ is in the base class, not A.  But an A is still
-        # weakref-able.
-        self.assertIn("__weakref__", Base.__slots__)
-        self.assertNotIn("__weakref__", A.__slots__)
-        a = A(1)
-        weakref.ref(a)
-
-    def test_weakref_slot_without_slot(self):
-        with self.assertRaisesRegex(TypeError,
-                                    "weakref_slot is True but slots is False"):
-            @dataclass(weakref_slot=True)
-            class A:
-                a: int
-
-    def test_weakref_slot_make_dataclass(self):
-        A = make_dataclass('A', [('a', int),], slots=True, weakref_slot=True)
-        self.assertIn("__weakref__", A.__slots__)
-        a = A(1)
-        weakref.ref(a)
-
-        # And make sure if raises if slots=True is not given.
-        with self.assertRaisesRegex(TypeError,
-                                    "weakref_slot is True but slots is False"):
-            B = make_dataclass('B', [('a', int),], weakref_slot=True)
-
-    def test_weakref_slot_subclass_weakref_slot(self):
-        @dataclass(slots=True, weakref_slot=True)
-        class Base:
-            field: int
-
-        # A *can* also specify weakref_slot=True if it wants to (gh-93521)
-        @dataclass(slots=True, weakref_slot=True)
-        class A(Base):
-            ...
-
-        # __weakref__ is in the base class, not A.  But an instance of A
-        # is still weakref-able.
-        self.assertIn("__weakref__", Base.__slots__)
-        self.assertNotIn("__weakref__", A.__slots__)
-        a = A(1)
-        a_ref = weakref.ref(a)
-        self.assertIs(a.__weakref__, a_ref)
-
-    def test_weakref_slot_subclass_no_weakref_slot(self):
-        @dataclass(slots=True, weakref_slot=True)
-        class Base:
-            field: int
-
-        @dataclass(slots=True)
-        class A(Base):
-            ...
-
-        # __weakref__ is in the base class, not A.  Even though A doesn't
-        # specify weakref_slot, it should still be weakref-able.
-        self.assertIn("__weakref__", Base.__slots__)
-        self.assertNotIn("__weakref__", A.__slots__)
-        a = A(1)
-        a_ref = weakref.ref(a)
-        self.assertIs(a.__weakref__, a_ref)
-
-    def test_weakref_slot_normal_base_weakref_slot(self):
-        class Base:
-            __slots__ = ('__weakref__',)
-
-        @dataclass(slots=True, weakref_slot=True)
-        class A(Base):
-            field: int
-
-        # __weakref__ is in the base class, not A.  But an instance of
-        # A is still weakref-able.
-        self.assertIn("__weakref__", Base.__slots__)
-        self.assertNotIn("__weakref__", A.__slots__)
-        a = A(1)
-        a_ref = weakref.ref(a)
-        self.assertIs(a.__weakref__, a_ref)
-
-
-class TestDescriptors(unittest.TestCase):
-    def test_set_name(self):
-        # See bpo-33141.
-
-        # Create a descriptor.
-        class D:
-            def __set_name__(self, owner, name):
-                self.name = name + 'x'
-            def __get__(self, instance, owner):
-                if instance is not None:
-                    return 1
-                return self
-
-        # This is the case of just normal descriptor behavior, no
-        #  dataclass code is involved in initializing the descriptor.
-        @dataclass
-        class C:
-            c: int=D()
-        self.assertEqual(C.c.name, 'cx')
-
-        # Now test with a default value and init=False, which is the
-        #  only time this is really meaningful.  If not using
-        #  init=False, then the descriptor will be overwritten, anyway.
-        @dataclass
-        class C:
-            c: int=field(default=D(), init=False)
-        self.assertEqual(C.c.name, 'cx')
-        self.assertEqual(C().c, 1)
-
-    def test_non_descriptor(self):
-        # PEP 487 says __set_name__ should work on non-descriptors.
-        # Create a descriptor.
-
-        class D:
-            def __set_name__(self, owner, name):
-                self.name = name + 'x'
-
-        @dataclass
-        class C:
-            c: int=field(default=D(), init=False)
-        self.assertEqual(C.c.name, 'cx')
-
-    def test_lookup_on_instance(self):
-        # See bpo-33175.
-        class D:
-            pass
-
-        d = D()
-        # Create an attribute on the instance, not type.
-        d.__set_name__ = Mock()
-
-        # Make sure d.__set_name__ is not called.
-        @dataclass
-        class C:
-            i: int=field(default=d, init=False)
-
-        self.assertEqual(d.__set_name__.call_count, 0)
-
-    def test_lookup_on_class(self):
-        # See bpo-33175.
-        class D:
-            pass
-        D.__set_name__ = Mock()
-
-        # Make sure D.__set_name__ is called.
-        @dataclass
-        class C:
-            i: int=field(default=D(), init=False)
-
-        self.assertEqual(D.__set_name__.call_count, 1)
-
-    def test_init_calls_set(self):
-        class D:
-            pass
-
-        D.__set__ = Mock()
-
-        @dataclass
-        class C:
-            i: D = D()
-
-        # Make sure D.__set__ is called.
-        D.__set__.reset_mock()
-        c = C(5)
-        self.assertEqual(D.__set__.call_count, 1)
-
-    def test_getting_field_calls_get(self):
-        class D:
-            pass
-
-        D.__set__ = Mock()
-        D.__get__ = Mock()
-
-        @dataclass
-        class C:
-            i: D = D()
-
-        c = C(5)
-
-        # Make sure D.__get__ is called.
-        D.__get__.reset_mock()
-        value = c.i
-        self.assertEqual(D.__get__.call_count, 1)
-
-    def test_setting_field_calls_set(self):
-        class D:
-            pass
-
-        D.__set__ = Mock()
-
-        @dataclass
-        class C:
-            i: D = D()
-
-        c = C(5)
-
-        # Make sure D.__set__ is called.
-        D.__set__.reset_mock()
-        c.i = 10
-        self.assertEqual(D.__set__.call_count, 1)
-
-    def test_setting_uninitialized_descriptor_field(self):
-        class D:
-            pass
-
-        D.__set__ = Mock()
-
-        @dataclass
-        class C:
-            i: D
-
-        # D.__set__ is not called because there's no D instance to call it on
-        D.__set__.reset_mock()
-        c = C(5)
-        self.assertEqual(D.__set__.call_count, 0)
-
-        # D.__set__ still isn't called after setting i to an instance of D
-        # because descriptors don't behave like that when stored as instance vars
-        c.i = D()
-        c.i = 5
-        self.assertEqual(D.__set__.call_count, 0)
-
-    def test_default_value(self):
-        class D:
-            def __get__(self, instance: Any, owner: object) -> int:
-                if instance is None:
-                    return 100
-
-                return instance._x
-
-            def __set__(self, instance: Any, value: int) -> None:
-                instance._x = value
-
-        @dataclass
-        class C:
-            i: D = D()
-
-        c = C()
-        self.assertEqual(c.i, 100)
-
-        c = C(5)
-        self.assertEqual(c.i, 5)
-
-    def test_no_default_value(self):
-        class D:
-            def __get__(self, instance: Any, owner: object) -> int:
-                if instance is None:
-                    raise AttributeError()
-
-                return instance._x
-
-            def __set__(self, instance: Any, value: int) -> None:
-                instance._x = value
-
-        @dataclass
-        class C:
-            i: D = D()
-
-        with self.assertRaisesRegex(TypeError, 'missing 1 required positional argument'):
-            c = C()
-
-class TestStringAnnotations(unittest.TestCase):
-    def test_classvar(self):
-        # Some expressions recognized as ClassVar really aren't.  But
-        #  if you're using string annotations, it's not an exact
-        #  science.
-        # These tests assume that both "import typing" and "from
-        # typing import *" have been run in this file.
-        for typestr in ('ClassVar[int]',
-                        'ClassVar [int]',
-                        ' ClassVar [int]',
-                        'ClassVar',
-                        ' ClassVar ',
-                        'typing.ClassVar[int]',
-                        'typing.ClassVar[str]',
-                        ' typing.ClassVar[str]',
-                        'typing .ClassVar[str]',
-                        'typing. ClassVar[str]',
-                        'typing.ClassVar [str]',
-                        'typing.ClassVar [ str]',
-
-                        # Not syntactically valid, but these will
-                        #  be treated as ClassVars.
-                        'typing.ClassVar.[int]',
-                        'typing.ClassVar+',
-                        ):
-            with self.subTest(typestr=typestr):
-                @dataclass
-                class C:
-                    x: typestr
-
-                # x is a ClassVar, so C() takes no args.
-                C()
-
-                # And it won't appear in the class's dict because it doesn't
-                # have a default.
-                self.assertNotIn('x', C.__dict__)
-
-    def test_isnt_classvar(self):
-        for typestr in ('CV',
-                        't.ClassVar',
-                        't.ClassVar[int]',
-                        'typing..ClassVar[int]',
-                        'Classvar',
-                        'Classvar[int]',
-                        'typing.ClassVarx[int]',
-                        'typong.ClassVar[int]',
-                        'dataclasses.ClassVar[int]',
-                        'typingxClassVar[str]',
-                        ):
-            with self.subTest(typestr=typestr):
-                @dataclass
-                class C:
-                    x: typestr
-
-                # x is not a ClassVar, so C() takes one arg.
-                self.assertEqual(C(10).x, 10)
-
-    def test_initvar(self):
-        # These tests assume that both "import dataclasses" and "from
-        #  dataclasses import *" have been run in this file.
-        for typestr in ('InitVar[int]',
-                        'InitVar [int]'
-                        ' InitVar [int]',
-                        'InitVar',
-                        ' InitVar ',
-                        'dataclasses.InitVar[int]',
-                        'dataclasses.InitVar[str]',
-                        ' dataclasses.InitVar[str]',
-                        'dataclasses .InitVar[str]',
-                        'dataclasses. InitVar[str]',
-                        'dataclasses.InitVar [str]',
-                        'dataclasses.InitVar [ str]',
-
-                        # Not syntactically valid, but these will
-                        #  be treated as InitVars.
-                        'dataclasses.InitVar.[int]',
-                        'dataclasses.InitVar+',
-                        ):
-            with self.subTest(typestr=typestr):
-                @dataclass
-                class C:
-                    x: typestr
-
-                # x is an InitVar, so doesn't create a member.
-                with self.assertRaisesRegex(AttributeError,
-                                            "object has no attribute 'x'"):
-                    C(1).x
-
-    def test_isnt_initvar(self):
-        for typestr in ('IV',
-                        'dc.InitVar',
-                        'xdataclasses.xInitVar',
-                        'typing.xInitVar[int]',
-                        ):
-            with self.subTest(typestr=typestr):
-                @dataclass
-                class C:
-                    x: typestr
-
-                # x is not an InitVar, so there will be a member x.
-                self.assertEqual(C(10).x, 10)
-
-    def test_classvar_module_level_import(self):
-        from test import dataclass_module_1
-        from test import dataclass_module_1_str
-        from test import dataclass_module_2
-        from test import dataclass_module_2_str
-
-        for m in (dataclass_module_1, dataclass_module_1_str,
-                  dataclass_module_2, dataclass_module_2_str,
-                  ):
-            with self.subTest(m=m):
-                # There's a difference in how the ClassVars are
-                # interpreted when using string annotations or
-                # not. See the imported modules for details.
-                if m.USING_STRINGS:
-                    c = m.CV(10)
-                else:
-                    c = m.CV()
-                self.assertEqual(c.cv0, 20)
-
-
-                # There's a difference in how the InitVars are
-                # interpreted when using string annotations or
-                # not. See the imported modules for details.
-                c = m.IV(0, 1, 2, 3, 4)
-
-                for field_name in ('iv0', 'iv1', 'iv2', 'iv3'):
-                    with self.subTest(field_name=field_name):
-                        with self.assertRaisesRegex(AttributeError, f"object has no attribute '{field_name}'"):
-                            # Since field_name is an InitVar, it's
-                            # not an instance field.
-                            getattr(c, field_name)
-
-                if m.USING_STRINGS:
-                    # iv4 is interpreted as a normal field.
-                    self.assertIn('not_iv4', c.__dict__)
-                    self.assertEqual(c.not_iv4, 4)
-                else:
-                    # iv4 is interpreted as an InitVar, so it
-                    # won't exist on the instance.
-                    self.assertNotIn('not_iv4', c.__dict__)
-
-    def test_text_annotations(self):
-        from test import dataclass_textanno
-
-        self.assertEqual(
-            get_type_hints(dataclass_textanno.Bar),
-            {'foo': dataclass_textanno.Foo})
-        self.assertEqual(
-            get_type_hints(dataclass_textanno.Bar.__init__),
-            {'foo': dataclass_textanno.Foo,
-             'return': type(None)})
-
-
-ByMakeDataClass = make_dataclass('ByMakeDataClass', [('x', int)])
-ManualModuleMakeDataClass = make_dataclass('ManualModuleMakeDataClass',
-                                           [('x', int)],
-                                           module=__name__)
-WrongNameMakeDataclass = make_dataclass('Wrong', [('x', int)])
-WrongModuleMakeDataclass = make_dataclass('WrongModuleMakeDataclass',
-                                          [('x', int)],
-                                          module='custom')
-
-class TestMakeDataclass(unittest.TestCase):
-    def test_simple(self):
-        C = make_dataclass('C',
-                           [('x', int),
-                            ('y', int, field(default=5))],
-                           namespace={'add_one': lambda self: self.x + 1})
-        c = C(10)
-        self.assertEqual((c.x, c.y), (10, 5))
-        self.assertEqual(c.add_one(), 11)
-
-
-    def test_no_mutate_namespace(self):
-        # Make sure a provided namespace isn't mutated.
-        ns = {}
-        C = make_dataclass('C',
-                           [('x', int),
-                            ('y', int, field(default=5))],
-                           namespace=ns)
-        self.assertEqual(ns, {})
-
-    def test_base(self):
-        class Base1:
-            pass
-        class Base2:
-            pass
-        C = make_dataclass('C',
-                           [('x', int)],
-                           bases=(Base1, Base2))
-        c = C(2)
-        self.assertIsInstance(c, C)
-        self.assertIsInstance(c, Base1)
-        self.assertIsInstance(c, Base2)
-
-    def test_base_dataclass(self):
-        @dataclass
-        class Base1:
-            x: int
-        class Base2:
-            pass
-        C = make_dataclass('C',
-                           [('y', int)],
-                           bases=(Base1, Base2))
-        with self.assertRaisesRegex(TypeError, 'required positional'):
-            c = C(2)
-        c = C(1, 2)
-        self.assertIsInstance(c, C)
-        self.assertIsInstance(c, Base1)
-        self.assertIsInstance(c, Base2)
-
-        self.assertEqual((c.x, c.y), (1, 2))
-
-    def test_init_var(self):
-        def post_init(self, y):
-            self.x *= y
-
-        C = make_dataclass('C',
-                           [('x', int),
-                            ('y', InitVar[int]),
-                            ],
-                           namespace={'__post_init__': post_init},
-                           )
-        c = C(2, 3)
-        self.assertEqual(vars(c), {'x': 6})
-        self.assertEqual(len(fields(c)), 1)
-
-    def test_class_var(self):
-        C = make_dataclass('C',
-                           [('x', int),
-                            ('y', ClassVar[int], 10),
-                            ('z', ClassVar[int], field(default=20)),
-                            ])
-        c = C(1)
-        self.assertEqual(vars(c), {'x': 1})
-        self.assertEqual(len(fields(c)), 1)
-        self.assertEqual(C.y, 10)
-        self.assertEqual(C.z, 20)
-
-    def test_other_params(self):
-        C = make_dataclass('C',
-                           [('x', int),
-                            ('y', ClassVar[int], 10),
-                            ('z', ClassVar[int], field(default=20)),
-                            ],
-                           init=False)
-        # Make sure we have a repr, but no init.
-        self.assertNotIn('__init__', vars(C))
-        self.assertIn('__repr__', vars(C))
-
-        # Make sure random other params don't work.
-        with self.assertRaisesRegex(TypeError, 'unexpected keyword argument'):
-            C = make_dataclass('C',
-                               [],
-                               xxinit=False)
-
-    def test_no_types(self):
-        C = make_dataclass('Point', ['x', 'y', 'z'])
-        c = C(1, 2, 3)
-        self.assertEqual(vars(c), {'x': 1, 'y': 2, 'z': 3})
-        self.assertEqual(C.__annotations__, {'x': 'typing.Any',
-                                             'y': 'typing.Any',
-                                             'z': 'typing.Any'})
-
-        C = make_dataclass('Point', ['x', ('y', int), 'z'])
-        c = C(1, 2, 3)
-        self.assertEqual(vars(c), {'x': 1, 'y': 2, 'z': 3})
-        self.assertEqual(C.__annotations__, {'x': 'typing.Any',
-                                             'y': int,
-                                             'z': 'typing.Any'})
-
-    def test_module_attr(self):
-        self.assertEqual(ByMakeDataClass.__module__, __name__)
-        self.assertEqual(ByMakeDataClass(1).__module__, __name__)
-        self.assertEqual(WrongModuleMakeDataclass.__module__, "custom")
-        Nested = make_dataclass('Nested', [])
-        self.assertEqual(Nested.__module__, __name__)
-        self.assertEqual(Nested().__module__, __name__)
-
-    def test_pickle_support(self):
-        for klass in [ByMakeDataClass, ManualModuleMakeDataClass]:
-            for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-                with self.subTest(proto=proto):
-                    self.assertEqual(
-                        pickle.loads(pickle.dumps(klass, proto)),
-                        klass,
-                    )
-                    self.assertEqual(
-                        pickle.loads(pickle.dumps(klass(1), proto)),
-                        klass(1),
-                    )
-
-    def test_cannot_be_pickled(self):
-        for klass in [WrongNameMakeDataclass, WrongModuleMakeDataclass]:
-            for proto in range(pickle.HIGHEST_PROTOCOL + 1):
-                with self.subTest(proto=proto):
-                    with self.assertRaises(pickle.PickleError):
-                        pickle.dumps(klass, proto)
-                    with self.assertRaises(pickle.PickleError):
-                        pickle.dumps(klass(1), proto)
-
-    def test_invalid_type_specification(self):
-        for bad_field in [(),
-                          (1, 2, 3, 4),
-                          ]:
-            with self.subTest(bad_field=bad_field):
-                with self.assertRaisesRegex(TypeError, r'Invalid field: '):
-                    make_dataclass('C', ['a', bad_field])
-
-        # And test for things with no len().
-        for bad_field in [float,
-                          lambda x:x,
-                          ]:
-            with self.subTest(bad_field=bad_field):
-                with self.assertRaisesRegex(TypeError, r'has no len\(\)'):
-                    make_dataclass('C', ['a', bad_field])
-
-    def test_duplicate_field_names(self):
-        for field in ['a', 'ab']:
-            with self.subTest(field=field):
-                with self.assertRaisesRegex(TypeError, 'Field name duplicated'):
-                    make_dataclass('C', [field, 'a', field])
-
-    def test_keyword_field_names(self):
-        for field in ['for', 'async', 'await', 'as']:
-            with self.subTest(field=field):
-                with self.assertRaisesRegex(TypeError, 'must not be keywords'):
-                    make_dataclass('C', ['a', field])
-                with self.assertRaisesRegex(TypeError, 'must not be keywords'):
-                    make_dataclass('C', [field])
-                with self.assertRaisesRegex(TypeError, 'must not be keywords'):
-                    make_dataclass('C', [field, 'a'])
-
-    def test_non_identifier_field_names(self):
-        for field in ['()', 'x,y', '*', '2@3', '', 'little johnny tables']:
-            with self.subTest(field=field):
-                with self.assertRaisesRegex(TypeError, 'must be valid identifiers'):
-                    make_dataclass('C', ['a', field])
-                with self.assertRaisesRegex(TypeError, 'must be valid identifiers'):
-                    make_dataclass('C', [field])
-                with self.assertRaisesRegex(TypeError, 'must be valid identifiers'):
-                    make_dataclass('C', [field, 'a'])
-
-    def test_underscore_field_names(self):
-        # Unlike namedtuple, it's okay if dataclass field names have
-        # an underscore.
-        make_dataclass('C', ['_', '_a', 'a_a', 'a_'])
-
-    def test_funny_class_names_names(self):
-        # No reason to prevent weird class names, since
-        # types.new_class allows them.
-        for classname in ['()', 'x,y', '*', '2@3', '']:
-            with self.subTest(classname=classname):
-                C = make_dataclass(classname, ['a', 'b'])
-                self.assertEqual(C.__name__, classname)
-
-class TestReplace(unittest.TestCase):
-    def test(self):
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            y: int
-
-        c = C(1, 2)
-        c1 = replace(c, x=3)
-        self.assertEqual(c1.x, 3)
-        self.assertEqual(c1.y, 2)
-
-    def test_frozen(self):
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            y: int
-            z: int = field(init=False, default=10)
-            t: int = field(init=False, default=100)
-
-        c = C(1, 2)
-        c1 = replace(c, x=3)
-        self.assertEqual((c.x, c.y, c.z, c.t), (1, 2, 10, 100))
-        self.assertEqual((c1.x, c1.y, c1.z, c1.t), (3, 2, 10, 100))
-
-
-        with self.assertRaisesRegex(ValueError, 'init=False'):
-            replace(c, x=3, z=20, t=50)
-        with self.assertRaisesRegex(ValueError, 'init=False'):
-            replace(c, z=20)
-            replace(c, x=3, z=20, t=50)
-
-        # Make sure the result is still frozen.
-        with self.assertRaisesRegex(FrozenInstanceError, "cannot assign to field 'x'"):
-            c1.x = 3
-
-        # Make sure we can't replace an attribute that doesn't exist,
-        #  if we're also replacing one that does exist.  Test this
-        #  here, because setting attributes on frozen instances is
-        #  handled slightly differently from non-frozen ones.
-        with self.assertRaisesRegex(TypeError, r"__init__\(\) got an unexpected "
-                                             "keyword argument 'a'"):
-            c1 = replace(c, x=20, a=5)
-
-    def test_invalid_field_name(self):
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            y: int
-
-        c = C(1, 2)
-        with self.assertRaisesRegex(TypeError, r"__init__\(\) got an unexpected "
-                                    "keyword argument 'z'"):
-            c1 = replace(c, z=3)
-
-    def test_invalid_object(self):
-        @dataclass(frozen=True)
-        class C:
-            x: int
-            y: int
-
-        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
-            replace(C, x=3)
-
-        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
-            replace(0, x=3)
-
-    def test_no_init(self):
-        @dataclass
-        class C:
-            x: int
-            y: int = field(init=False, default=10)
-
-        c = C(1)
-        c.y = 20
-
-        # Make sure y gets the default value.
-        c1 = replace(c, x=5)
-        self.assertEqual((c1.x, c1.y), (5, 10))
-
-        # Trying to replace y is an error.
-        with self.assertRaisesRegex(ValueError, 'init=False'):
-            replace(c, x=2, y=30)
-
-        with self.assertRaisesRegex(ValueError, 'init=False'):
-            replace(c, y=30)
-
-    def test_classvar(self):
-        @dataclass
-        class C:
-            x: int
-            y: ClassVar[int] = 1000
-
-        c = C(1)
-        d = C(2)
-
-        self.assertIs(c.y, d.y)
-        self.assertEqual(c.y, 1000)
-
-        # Trying to replace y is an error: can't replace ClassVars.
-        with self.assertRaisesRegex(TypeError, r"__init__\(\) got an "
-                                    "unexpected keyword argument 'y'"):
-            replace(c, y=30)
-
-        replace(c, x=5)
-
-    def test_initvar_is_specified(self):
-        @dataclass
-        class C:
-            x: int
-            y: InitVar[int]
-
-            def __post_init__(self, y):
-                self.x *= y
-
-        c = C(1, 10)
-        self.assertEqual(c.x, 10)
-        with self.assertRaisesRegex(ValueError, r"InitVar 'y' must be "
-                                    "specified with replace()"):
-            replace(c, x=3)
-        c = replace(c, x=3, y=5)
-        self.assertEqual(c.x, 15)
-
-    def test_initvar_with_default_value(self):
-        @dataclass
-        class C:
-            x: int
-            y: InitVar[int] = None
-            z: InitVar[int] = 42
-
-            def __post_init__(self, y, z):
-                if y is not None:
-                    self.x += y
-                if z is not None:
-                    self.x += z
-
-        c = C(x=1, y=10, z=1)
-        self.assertEqual(replace(c), C(x=12))
-        self.assertEqual(replace(c, y=4), C(x=12, y=4, z=42))
-        self.assertEqual(replace(c, y=4, z=1), C(x=12, y=4, z=1))
-
-    def test_recursive_repr(self):
-        @dataclass
-        class C:
-            f: "C"
-
-        c = C(None)
-        c.f = c
-        self.assertEqual(repr(c), "TestReplace.test_recursive_repr.<locals>.C(f=...)")
-
-    def test_recursive_repr_two_attrs(self):
-        @dataclass
-        class C:
-            f: "C"
-            g: "C"
-
-        c = C(None, None)
-        c.f = c
-        c.g = c
-        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_two_attrs"
-                                  ".<locals>.C(f=..., g=...)")
-
-    def test_recursive_repr_indirection(self):
-        @dataclass
-        class C:
-            f: "D"
-
-        @dataclass
-        class D:
-            f: "C"
-
-        c = C(None)
-        d = D(None)
-        c.f = d
-        d.f = c
-        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_indirection"
-                                  ".<locals>.C(f=TestReplace.test_recursive_repr_indirection"
-                                  ".<locals>.D(f=...))")
-
-    def test_recursive_repr_indirection_two(self):
-        @dataclass
-        class C:
-            f: "D"
-
-        @dataclass
-        class D:
-            f: "E"
-
-        @dataclass
-        class E:
-            f: "C"
-
-        c = C(None)
-        d = D(None)
-        e = E(None)
-        c.f = d
-        d.f = e
-        e.f = c
-        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_indirection_two"
-                                  ".<locals>.C(f=TestReplace.test_recursive_repr_indirection_two"
-                                  ".<locals>.D(f=TestReplace.test_recursive_repr_indirection_two"
-                                  ".<locals>.E(f=...)))")
-
-    def test_recursive_repr_misc_attrs(self):
-        @dataclass
-        class C:
-            f: "C"
-            g: int
-
-        c = C(None, 1)
-        c.f = c
-        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_misc_attrs"
-                                  ".<locals>.C(f=..., g=1)")
-
-    ## def test_initvar(self):
-    ##     @dataclass
-    ##     class C:
-    ##         x: int
-    ##         y: InitVar[int]
-
-    ##     c = C(1, 10)
-    ##     d = C(2, 20)
-
-    ##     # In our case, replacing an InitVar is a no-op
-    ##     self.assertEqual(c, replace(c, y=5))
-
-    ##     replace(c, x=5)
-
-class TestAbstract(unittest.TestCase):
-    def test_abc_implementation(self):
-        class Ordered(abc.ABC):
-            @abc.abstractmethod
-            def __lt__(self, other):
-                pass
-
-            @abc.abstractmethod
-            def __le__(self, other):
-                pass
-
-        @dataclass(order=True)
-        class Date(Ordered):
-            year: int
-            month: 'Month'
-            day: 'int'
-
-        self.assertFalse(inspect.isabstract(Date))
-        self.assertGreater(Date(2020,12,25), Date(2020,8,31))
-
-    def test_maintain_abc(self):
-        class A(abc.ABC):
-            @abc.abstractmethod
-            def foo(self):
-                pass
-
-        @dataclass
-        class Date(A):
-            year: int
-            month: 'Month'
-            day: 'int'
-
-        self.assertTrue(inspect.isabstract(Date))
-        msg = "class Date without an implementation for abstract method 'foo'"
-        self.assertRaisesRegex(TypeError, msg, Date)
-
-
-class TestMatchArgs(unittest.TestCase):
-    def test_match_args(self):
-        @dataclass
-        class C:
-            a: int
-        self.assertEqual(C(42).__match_args__, ('a',))
-
-    def test_explicit_match_args(self):
-        ma = ()
-        @dataclass
-        class C:
-            a: int
-            __match_args__ = ma
-        self.assertIs(C(42).__match_args__, ma)
-
-    def test_bpo_43764(self):
-        @dataclass(repr=False, eq=False, init=False)
-        class X:
-            a: int
-            b: int
-            c: int
-        self.assertEqual(X.__match_args__, ("a", "b", "c"))
-
-    def test_match_args_argument(self):
-        @dataclass(match_args=False)
-        class X:
-            a: int
-        self.assertNotIn('__match_args__', X.__dict__)
-
-        @dataclass(match_args=False)
-        class Y:
-            a: int
-            __match_args__ = ('b',)
-        self.assertEqual(Y.__match_args__, ('b',))
-
-        @dataclass(match_args=False)
-        class Z(Y):
-            z: int
-        self.assertEqual(Z.__match_args__, ('b',))
-
-        # Ensure parent dataclass __match_args__ is seen, if child class
-        # specifies match_args=False.
-        @dataclass
-        class A:
-            a: int
-            z: int
-        @dataclass(match_args=False)
-        class B(A):
-            b: int
-        self.assertEqual(B.__match_args__, ('a', 'z'))
-
-    def test_make_dataclasses(self):
-        C = make_dataclass('C', [('x', int), ('y', int)])
-        self.assertEqual(C.__match_args__, ('x', 'y'))
-
-        C = make_dataclass('C', [('x', int), ('y', int)], match_args=True)
-        self.assertEqual(C.__match_args__, ('x', 'y'))
-
-        C = make_dataclass('C', [('x', int), ('y', int)], match_args=False)
-        self.assertNotIn('__match__args__', C.__dict__)
-
-        C = make_dataclass('C', [('x', int), ('y', int)], namespace={'__match_args__': ('z',)})
-        self.assertEqual(C.__match_args__, ('z',))
-
-
-class TestKeywordArgs(unittest.TestCase):
-    def test_no_classvar_kwarg(self):
-        msg = 'field a is a ClassVar but specifies kw_only'
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass
-            class A:
-                a: ClassVar[int] = field(kw_only=True)
-
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass
-            class A:
-                a: ClassVar[int] = field(kw_only=False)
-
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass(kw_only=True)
-            class A:
-                a: ClassVar[int] = field(kw_only=False)
-
-    def test_field_marked_as_kwonly(self):
-        #######################
-        # Using dataclass(kw_only=True)
-        @dataclass(kw_only=True)
-        class A:
-            a: int
-        self.assertTrue(fields(A)[0].kw_only)
-
-        @dataclass(kw_only=True)
-        class A:
-            a: int = field(kw_only=True)
-        self.assertTrue(fields(A)[0].kw_only)
-
-        @dataclass(kw_only=True)
-        class A:
-            a: int = field(kw_only=False)
-        self.assertFalse(fields(A)[0].kw_only)
-
-        #######################
-        # Using dataclass(kw_only=False)
-        @dataclass(kw_only=False)
-        class A:
-            a: int
-        self.assertFalse(fields(A)[0].kw_only)
-
-        @dataclass(kw_only=False)
-        class A:
-            a: int = field(kw_only=True)
-        self.assertTrue(fields(A)[0].kw_only)
-
-        @dataclass(kw_only=False)
-        class A:
-            a: int = field(kw_only=False)
-        self.assertFalse(fields(A)[0].kw_only)
-
-        #######################
-        # Not specifying dataclass(kw_only)
-        @dataclass
-        class A:
-            a: int
-        self.assertFalse(fields(A)[0].kw_only)
-
-        @dataclass
-        class A:
-            a: int = field(kw_only=True)
-        self.assertTrue(fields(A)[0].kw_only)
-
-        @dataclass
-        class A:
-            a: int = field(kw_only=False)
-        self.assertFalse(fields(A)[0].kw_only)
-
-    def test_match_args(self):
-        # kw fields don't show up in __match_args__.
-        @dataclass(kw_only=True)
-        class C:
-            a: int
-        self.assertEqual(C(a=42).__match_args__, ())
-
-        @dataclass
-        class C:
-            a: int
-            b: int = field(kw_only=True)
-        self.assertEqual(C(42, b=10).__match_args__, ('a',))
-
-    def test_KW_ONLY(self):
-        @dataclass
-        class A:
-            a: int
-            _: KW_ONLY
-            b: int
-            c: int
-        A(3, c=5, b=4)
-        msg = "takes 2 positional arguments but 4 were given"
-        with self.assertRaisesRegex(TypeError, msg):
-            A(3, 4, 5)
-
-
-        @dataclass(kw_only=True)
-        class B:
-            a: int
-            _: KW_ONLY
-            b: int
-            c: int
-        B(a=3, b=4, c=5)
-        msg = "takes 1 positional argument but 4 were given"
-        with self.assertRaisesRegex(TypeError, msg):
-            B(3, 4, 5)
-
-        # Explicitly make a field that follows KW_ONLY be non-keyword-only.
-        @dataclass
-        class C:
-            a: int
-            _: KW_ONLY
-            b: int
-            c: int = field(kw_only=False)
-        c = C(1, 2, b=3)
-        self.assertEqual(c.a, 1)
-        self.assertEqual(c.b, 3)
-        self.assertEqual(c.c, 2)
-        c = C(1, b=3, c=2)
-        self.assertEqual(c.a, 1)
-        self.assertEqual(c.b, 3)
-        self.assertEqual(c.c, 2)
-        c = C(1, b=3, c=2)
-        self.assertEqual(c.a, 1)
-        self.assertEqual(c.b, 3)
-        self.assertEqual(c.c, 2)
-        c = C(c=2, b=3, a=1)
-        self.assertEqual(c.a, 1)
-        self.assertEqual(c.b, 3)
-        self.assertEqual(c.c, 2)
-
-    def test_KW_ONLY_as_string(self):
-        @dataclass
-        class A:
-            a: int
-            _: 'dataclasses.KW_ONLY'
-            b: int
-            c: int
-        A(3, c=5, b=4)
-        msg = "takes 2 positional arguments but 4 were given"
-        with self.assertRaisesRegex(TypeError, msg):
-            A(3, 4, 5)
-
-    def test_KW_ONLY_twice(self):
-        msg = "'Y' is KW_ONLY, but KW_ONLY has already been specified"
-
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass
-            class A:
-                a: int
-                X: KW_ONLY
-                Y: KW_ONLY
-                b: int
-                c: int
-
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass
-            class A:
-                a: int
-                X: KW_ONLY
-                b: int
-                Y: KW_ONLY
-                c: int
-
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass
-            class A:
-                a: int
-                X: KW_ONLY
-                b: int
-                c: int
-                Y: KW_ONLY
-
-        # But this usage is okay, since it's not using KW_ONLY.
-        @dataclass
-        class A:
-            a: int
-            _: KW_ONLY
-            b: int
-            c: int = field(kw_only=True)
-
-        # And if inheriting, it's okay.
-        @dataclass
-        class A:
-            a: int
-            _: KW_ONLY
-            b: int
-            c: int
-        @dataclass
-        class B(A):
-            _: KW_ONLY
-            d: int
-
-        # Make sure the error is raised in a derived class.
-        with self.assertRaisesRegex(TypeError, msg):
-            @dataclass
-            class A:
-                a: int
-                _: KW_ONLY
-                b: int
-                c: int
-            @dataclass
-            class B(A):
-                X: KW_ONLY
-                d: int
-                Y: KW_ONLY
-
-
-    def test_post_init(self):
-        @dataclass
-        class A:
-            a: int
-            _: KW_ONLY
-            b: InitVar[int]
-            c: int
-            d: InitVar[int]
-            def __post_init__(self, b, d):
-                raise CustomError(f'{b=} {d=}')
-        with self.assertRaisesRegex(CustomError, 'b=3 d=4'):
-            A(1, c=2, b=3, d=4)
-
-        @dataclass
-        class B:
-            a: int
-            _: KW_ONLY
-            b: InitVar[int]
-            c: int
-            d: InitVar[int]
-            def __post_init__(self, b, d):
-                self.a = b
-                self.c = d
-        b = B(1, c=2, b=3, d=4)
-        self.assertEqual(asdict(b), {'a': 3, 'c': 4})
-
-    def test_defaults(self):
-        # For kwargs, make sure we can have defaults after non-defaults.
-        @dataclass
-        class A:
-            a: int = 0
-            _: KW_ONLY
-            b: int
-            c: int = 1
-            d: int
-
-        a = A(d=4, b=3)
-        self.assertEqual(a.a, 0)
-        self.assertEqual(a.b, 3)
-        self.assertEqual(a.c, 1)
-        self.assertEqual(a.d, 4)
-
-        # Make sure we still check for non-kwarg non-defaults not following
-        # defaults.
-        err_regex = "non-default argument 'z' follows default argument"
-        with self.assertRaisesRegex(TypeError, err_regex):
-            @dataclass
-            class A:
-                a: int = 0
-                z: int
-                _: KW_ONLY
-                b: int
-                c: int = 1
-                d: int
-
-    def test_make_dataclass(self):
-        A = make_dataclass("A", ['a'], kw_only=True)
-        self.assertTrue(fields(A)[0].kw_only)
-
-        B = make_dataclass("B",
-                           ['a', ('b', int, field(kw_only=False))],
-                           kw_only=True)
-        self.assertTrue(fields(B)[0].kw_only)
-        self.assertFalse(fields(B)[1].kw_only)
-
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/Lib/test/test_dataclasses/__init__.py b/Lib/test/test_dataclasses/__init__.py
new file mode 100644
index 0000000000..2b09db03d4
--- /dev/null
+++ b/Lib/test/test_dataclasses/__init__.py
@@ -0,0 +1,4547 @@
+# Deliberately use "from dataclasses import *".  Every name in __all__
+# is tested, so they all must be present.  This is a way to catch
+# missing ones.
+
+from dataclasses import *
+
+import abc
+import io
+import pickle
+import inspect
+import builtins
+import types
+import weakref
+import traceback
+import unittest
+from unittest.mock import Mock
+from typing import ClassVar, Any, List, Union, Tuple, Dict, Generic, TypeVar, Optional, Protocol, DefaultDict
+from typing import get_type_hints
+from collections import deque, OrderedDict, namedtuple, defaultdict
+from functools import total_ordering
+
+import typing       # Needed for the string "typing.ClassVar[int]" to work as an annotation.
+import dataclasses  # Needed for the string "dataclasses.InitVar[int]" to work as an annotation.
+
+# Just any custom exception we can catch.
+class CustomError(Exception): pass
+
+class TestCase(unittest.TestCase):
+    def test_no_fields(self):
+        @dataclass
+        class C:
+            pass
+
+        o = C()
+        self.assertEqual(len(fields(C)), 0)
+
+    def test_no_fields_but_member_variable(self):
+        @dataclass
+        class C:
+            i = 0
+
+        o = C()
+        self.assertEqual(len(fields(C)), 0)
+
+    def test_one_field_no_default(self):
+        @dataclass
+        class C:
+            x: int
+
+        o = C(42)
+        self.assertEqual(o.x, 42)
+
+    def test_field_default_default_factory_error(self):
+        msg = "cannot specify both default and default_factory"
+        with self.assertRaisesRegex(ValueError, msg):
+            @dataclass
+            class C:
+                x: int = field(default=1, default_factory=int)
+
+    def test_field_repr(self):
+        int_field = field(default=1, init=True, repr=False)
+        int_field.name = "id"
+        repr_output = repr(int_field)
+        expected_output = "Field(name='id',type=None," \
+                           f"default=1,default_factory={MISSING!r}," \
+                           "init=True,repr=False,hash=None," \
+                           "compare=True,metadata=mappingproxy({})," \
+                           f"kw_only={MISSING!r}," \
+                           "_field_type=None)"
+
+        self.assertEqual(repr_output, expected_output)
+
+    def test_field_recursive_repr(self):
+        rec_field = field()
+        rec_field.type = rec_field
+        rec_field.name = "id"
+        repr_output = repr(rec_field)
+
+        self.assertIn(",type=...,", repr_output)
+
+    def test_recursive_annotation(self):
+        class C:
+            pass
+
+        @dataclass
+        class D:
+            C: C = field()
+
+        self.assertIn(",type=...,", repr(D.__dataclass_fields__["C"]))
+
+    def test_dataclass_params_repr(self):
+        # Even though this is testing an internal implementation detail,
+        # it's testing a feature we want to make sure is correctly implemented
+        # for the sake of dataclasses itself
+        @dataclass(slots=True, frozen=True)
+        class Some: pass
+
+        repr_output = repr(Some.__dataclass_params__)
+        expected_output = "_DataclassParams(init=True,repr=True," \
+                          "eq=True,order=False,unsafe_hash=False,frozen=True," \
+                          "match_args=True,kw_only=False," \
+                          "slots=True,weakref_slot=False)"
+        self.assertEqual(repr_output, expected_output)
+
+    def test_dataclass_params_signature(self):
+        # Even though this is testing an internal implementation detail,
+        # it's testing a feature we want to make sure is correctly implemented
+        # for the sake of dataclasses itself
+        @dataclass
+        class Some: pass
+
+        for param in inspect.signature(dataclass).parameters:
+            if param == 'cls':
+                continue
+            self.assertTrue(hasattr(Some.__dataclass_params__, param), msg=param)
+
+    def test_named_init_params(self):
+        @dataclass
+        class C:
+            x: int
+
+        o = C(x=32)
+        self.assertEqual(o.x, 32)
+
+    def test_two_fields_one_default(self):
+        @dataclass
+        class C:
+            x: int
+            y: int = 0
+
+        o = C(3)
+        self.assertEqual((o.x, o.y), (3, 0))
+
+        # Non-defaults following defaults.
+        with self.assertRaisesRegex(TypeError,
+                                    "non-default argument 'y' follows "
+                                    "default argument"):
+            @dataclass
+            class C:
+                x: int = 0
+                y: int
+
+        # A derived class adds a non-default field after a default one.
+        with self.assertRaisesRegex(TypeError,
+                                    "non-default argument 'y' follows "
+                                    "default argument"):
+            @dataclass
+            class B:
+                x: int = 0
+
+            @dataclass
+            class C(B):
+                y: int
+
+        # Override a base class field and add a default to
+        #  a field which didn't use to have a default.
+        with self.assertRaisesRegex(TypeError,
+                                    "non-default argument 'y' follows "
+                                    "default argument"):
+            @dataclass
+            class B:
+                x: int
+                y: int
+
+            @dataclass
+            class C(B):
+                x: int = 0
+
+    def test_overwrite_hash(self):
+        # Test that declaring this class isn't an error.  It should
+        #  use the user-provided __hash__.
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            def __hash__(self):
+                return 301
+        self.assertEqual(hash(C(100)), 301)
+
+        # Test that declaring this class isn't an error.  It should
+        #  use the generated __hash__.
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            def __eq__(self, other):
+                return False
+        self.assertEqual(hash(C(100)), hash((100,)))
+
+        # But this one should generate an exception, because with
+        #  unsafe_hash=True, it's an error to have a __hash__ defined.
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __hash__'):
+            @dataclass(unsafe_hash=True)
+            class C:
+                def __hash__(self):
+                    pass
+
+        # Creating this class should not generate an exception,
+        #  because even though __hash__ exists before @dataclass is
+        #  called, (due to __eq__ being defined), since it's None
+        #  that's okay.
+        @dataclass(unsafe_hash=True)
+        class C:
+            x: int
+            def __eq__(self):
+                pass
+        # The generated hash function works as we'd expect.
+        self.assertEqual(hash(C(10)), hash((10,)))
+
+        # Creating this class should generate an exception, because
+        #  __hash__ exists and is not None, which it would be if it
+        #  had been auto-generated due to __eq__ being defined.
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __hash__'):
+            @dataclass(unsafe_hash=True)
+            class C:
+                x: int
+                def __eq__(self):
+                    pass
+                def __hash__(self):
+                    pass
+
+    def test_overwrite_fields_in_derived_class(self):
+        # Note that x from C1 replaces x in Base, but the order remains
+        #  the same as defined in Base.
+        @dataclass
+        class Base:
+            x: Any = 15.0
+            y: int = 0
+
+        @dataclass
+        class C1(Base):
+            z: int = 10
+            x: int = 15
+
+        o = Base()
+        self.assertEqual(repr(o), 'TestCase.test_overwrite_fields_in_derived_class.<locals>.Base(x=15.0, y=0)')
+
+        o = C1()
+        self.assertEqual(repr(o), 'TestCase.test_overwrite_fields_in_derived_class.<locals>.C1(x=15, y=0, z=10)')
+
+        o = C1(x=5)
+        self.assertEqual(repr(o), 'TestCase.test_overwrite_fields_in_derived_class.<locals>.C1(x=5, y=0, z=10)')
+
+    def test_field_named_self(self):
+        @dataclass
+        class C:
+            self: str
+        c=C('foo')
+        self.assertEqual(c.self, 'foo')
+
+        # Make sure the first parameter is not named 'self'.
+        sig = inspect.signature(C.__init__)
+        first = next(iter(sig.parameters))
+        self.assertNotEqual('self', first)
+
+        # But we do use 'self' if no field named self.
+        @dataclass
+        class C:
+            selfx: str
+
+        # Make sure the first parameter is named 'self'.
+        sig = inspect.signature(C.__init__)
+        first = next(iter(sig.parameters))
+        self.assertEqual('self', first)
+
+    def test_field_named_object(self):
+        @dataclass
+        class C:
+            object: str
+        c = C('foo')
+        self.assertEqual(c.object, 'foo')
+
+    def test_field_named_object_frozen(self):
+        @dataclass(frozen=True)
+        class C:
+            object: str
+        c = C('foo')
+        self.assertEqual(c.object, 'foo')
+
+    def test_field_named_BUILTINS_frozen(self):
+        # gh-96151
+        @dataclass(frozen=True)
+        class C:
+            BUILTINS: int
+        c = C(5)
+        self.assertEqual(c.BUILTINS, 5)
+
+    def test_field_with_special_single_underscore_names(self):
+        # gh-98886
+
+        @dataclass
+        class X:
+            x: int = field(default_factory=lambda: 111)
+            _dflt_x: int = field(default_factory=lambda: 222)
+
+        X()
+
+        @dataclass
+        class Y:
+            y: int = field(default_factory=lambda: 111)
+            _HAS_DEFAULT_FACTORY: int = 222
+
+        assert Y(y=222).y == 222
+
+    def test_field_named_like_builtin(self):
+        # Attribute names can shadow built-in names
+        # since code generation is used.
+        # Ensure that this is not happening.
+        exclusions = {'None', 'True', 'False'}
+        builtins_names = sorted(
+            b for b in builtins.__dict__.keys()
+            if not b.startswith('__') and b not in exclusions
+        )
+        attributes = [(name, str) for name in builtins_names]
+        C = make_dataclass('C', attributes)
+
+        c = C(*[name for name in builtins_names])
+
+        for name in builtins_names:
+            self.assertEqual(getattr(c, name), name)
+
+    def test_field_named_like_builtin_frozen(self):
+        # Attribute names can shadow built-in names
+        # since code generation is used.
+        # Ensure that this is not happening
+        # for frozen data classes.
+        exclusions = {'None', 'True', 'False'}
+        builtins_names = sorted(
+            b for b in builtins.__dict__.keys()
+            if not b.startswith('__') and b not in exclusions
+        )
+        attributes = [(name, str) for name in builtins_names]
+        C = make_dataclass('C', attributes, frozen=True)
+
+        c = C(*[name for name in builtins_names])
+
+        for name in builtins_names:
+            self.assertEqual(getattr(c, name), name)
+
+    def test_0_field_compare(self):
+        # Ensure that order=False is the default.
+        @dataclass
+        class C0:
+            pass
+
+        @dataclass(order=False)
+        class C1:
+            pass
+
+        for cls in [C0, C1]:
+            with self.subTest(cls=cls):
+                self.assertEqual(cls(), cls())
+                for idx, fn in enumerate([lambda a, b: a < b,
+                                          lambda a, b: a <= b,
+                                          lambda a, b: a > b,
+                                          lambda a, b: a >= b]):
+                    with self.subTest(idx=idx):
+                        with self.assertRaisesRegex(TypeError,
+                                                    f"not supported between instances of '{cls.__name__}' and '{cls.__name__}'"):
+                            fn(cls(), cls())
+
+        @dataclass(order=True)
+        class C:
+            pass
+        self.assertLessEqual(C(), C())
+        self.assertGreaterEqual(C(), C())
+
+    def test_1_field_compare(self):
+        # Ensure that order=False is the default.
+        @dataclass
+        class C0:
+            x: int
+
+        @dataclass(order=False)
+        class C1:
+            x: int
+
+        for cls in [C0, C1]:
+            with self.subTest(cls=cls):
+                self.assertEqual(cls(1), cls(1))
+                self.assertNotEqual(cls(0), cls(1))
+                for idx, fn in enumerate([lambda a, b: a < b,
+                                          lambda a, b: a <= b,
+                                          lambda a, b: a > b,
+                                          lambda a, b: a >= b]):
+                    with self.subTest(idx=idx):
+                        with self.assertRaisesRegex(TypeError,
+                                                    f"not supported between instances of '{cls.__name__}' and '{cls.__name__}'"):
+                            fn(cls(0), cls(0))
+
+        @dataclass(order=True)
+        class C:
+            x: int
+        self.assertLess(C(0), C(1))
+        self.assertLessEqual(C(0), C(1))
+        self.assertLessEqual(C(1), C(1))
+        self.assertGreater(C(1), C(0))
+        self.assertGreaterEqual(C(1), C(0))
+        self.assertGreaterEqual(C(1), C(1))
+
+    def test_simple_compare(self):
+        # Ensure that order=False is the default.
+        @dataclass
+        class C0:
+            x: int
+            y: int
+
+        @dataclass(order=False)
+        class C1:
+            x: int
+            y: int
+
+        for cls in [C0, C1]:
+            with self.subTest(cls=cls):
+                self.assertEqual(cls(0, 0), cls(0, 0))
+                self.assertEqual(cls(1, 2), cls(1, 2))
+                self.assertNotEqual(cls(1, 0), cls(0, 0))
+                self.assertNotEqual(cls(1, 0), cls(1, 1))
+                for idx, fn in enumerate([lambda a, b: a < b,
+                                          lambda a, b: a <= b,
+                                          lambda a, b: a > b,
+                                          lambda a, b: a >= b]):
+                    with self.subTest(idx=idx):
+                        with self.assertRaisesRegex(TypeError,
+                                                    f"not supported between instances of '{cls.__name__}' and '{cls.__name__}'"):
+                            fn(cls(0, 0), cls(0, 0))
+
+        @dataclass(order=True)
+        class C:
+            x: int
+            y: int
+
+        for idx, fn in enumerate([lambda a, b: a == b,
+                                  lambda a, b: a <= b,
+                                  lambda a, b: a >= b]):
+            with self.subTest(idx=idx):
+                self.assertTrue(fn(C(0, 0), C(0, 0)))
+
+        for idx, fn in enumerate([lambda a, b: a < b,
+                                  lambda a, b: a <= b,
+                                  lambda a, b: a != b]):
+            with self.subTest(idx=idx):
+                self.assertTrue(fn(C(0, 0), C(0, 1)))
+                self.assertTrue(fn(C(0, 1), C(1, 0)))
+                self.assertTrue(fn(C(1, 0), C(1, 1)))
+
+        for idx, fn in enumerate([lambda a, b: a > b,
+                                  lambda a, b: a >= b,
+                                  lambda a, b: a != b]):
+            with self.subTest(idx=idx):
+                self.assertTrue(fn(C(0, 1), C(0, 0)))
+                self.assertTrue(fn(C(1, 0), C(0, 1)))
+                self.assertTrue(fn(C(1, 1), C(1, 0)))
+
+    def test_compare_subclasses(self):
+        # Comparisons fail for subclasses, even if no fields
+        #  are added.
+        @dataclass
+        class B:
+            i: int
+
+        @dataclass
+        class C(B):
+            pass
+
+        for idx, (fn, expected) in enumerate([(lambda a, b: a == b, False),
+                                              (lambda a, b: a != b, True)]):
+            with self.subTest(idx=idx):
+                self.assertEqual(fn(B(0), C(0)), expected)
+
+        for idx, fn in enumerate([lambda a, b: a < b,
+                                  lambda a, b: a <= b,
+                                  lambda a, b: a > b,
+                                  lambda a, b: a >= b]):
+            with self.subTest(idx=idx):
+                with self.assertRaisesRegex(TypeError,
+                                            "not supported between instances of 'B' and 'C'"):
+                    fn(B(0), C(0))
+
+    def test_eq_order(self):
+        # Test combining eq and order.
+        for (eq,    order, result   ) in [
+            (False, False, 'neither'),
+            (False, True,  'exception'),
+            (True,  False, 'eq_only'),
+            (True,  True,  'both'),
+        ]:
+            with self.subTest(eq=eq, order=order):
+                if result == 'exception':
+                    with self.assertRaisesRegex(ValueError, 'eq must be true if order is true'):
+                        @dataclass(eq=eq, order=order)
+                        class C:
+                            pass
+                else:
+                    @dataclass(eq=eq, order=order)
+                    class C:
+                        pass
+
+                    if result == 'neither':
+                        self.assertNotIn('__eq__', C.__dict__)
+                        self.assertNotIn('__lt__', C.__dict__)
+                        self.assertNotIn('__le__', C.__dict__)
+                        self.assertNotIn('__gt__', C.__dict__)
+                        self.assertNotIn('__ge__', C.__dict__)
+                    elif result == 'both':
+                        self.assertIn('__eq__', C.__dict__)
+                        self.assertIn('__lt__', C.__dict__)
+                        self.assertIn('__le__', C.__dict__)
+                        self.assertIn('__gt__', C.__dict__)
+                        self.assertIn('__ge__', C.__dict__)
+                    elif result == 'eq_only':
+                        self.assertIn('__eq__', C.__dict__)
+                        self.assertNotIn('__lt__', C.__dict__)
+                        self.assertNotIn('__le__', C.__dict__)
+                        self.assertNotIn('__gt__', C.__dict__)
+                        self.assertNotIn('__ge__', C.__dict__)
+                    else:
+                        assert False, f'unknown result {result!r}'
+
+    def test_field_no_default(self):
+        @dataclass
+        class C:
+            x: int = field()
+
+        self.assertEqual(C(5).x, 5)
+
+        with self.assertRaisesRegex(TypeError,
+                                    r"__init__\(\) missing 1 required "
+                                    "positional argument: 'x'"):
+            C()
+
+    def test_field_default(self):
+        default = object()
+        @dataclass
+        class C:
+            x: object = field(default=default)
+
+        self.assertIs(C.x, default)
+        c = C(10)
+        self.assertEqual(c.x, 10)
+
+        # If we delete the instance attribute, we should then see the
+        #  class attribute.
+        del c.x
+        self.assertIs(c.x, default)
+
+        self.assertIs(C().x, default)
+
+    def test_not_in_repr(self):
+        @dataclass
+        class C:
+            x: int = field(repr=False)
+        with self.assertRaises(TypeError):
+            C()
+        c = C(10)
+        self.assertEqual(repr(c), 'TestCase.test_not_in_repr.<locals>.C()')
+
+        @dataclass
+        class C:
+            x: int = field(repr=False)
+            y: int
+        c = C(10, 20)
+        self.assertEqual(repr(c), 'TestCase.test_not_in_repr.<locals>.C(y=20)')
+
+    def test_not_in_compare(self):
+        @dataclass
+        class C:
+            x: int = 0
+            y: int = field(compare=False, default=4)
+
+        self.assertEqual(C(), C(0, 20))
+        self.assertEqual(C(1, 10), C(1, 20))
+        self.assertNotEqual(C(3), C(4, 10))
+        self.assertNotEqual(C(3, 10), C(4, 10))
+
+    def test_no_unhashable_default(self):
+        # See bpo-44674.
+        class Unhashable:
+            __hash__ = None
+
+        unhashable_re = 'mutable default .* for field a is not allowed'
+        with self.assertRaisesRegex(ValueError, unhashable_re):
+            @dataclass
+            class A:
+                a: dict = {}
+
+        with self.assertRaisesRegex(ValueError, unhashable_re):
+            @dataclass
+            class A:
+                a: Any = Unhashable()
+
+        # Make sure that the machinery looking for hashability is using the
+        # class's __hash__, not the instance's __hash__.
+        with self.assertRaisesRegex(ValueError, unhashable_re):
+            unhashable = Unhashable()
+            # This shouldn't make the variable hashable.
+            unhashable.__hash__ = lambda: 0
+            @dataclass
+            class A:
+                a: Any = unhashable
+
+    def test_hash_field_rules(self):
+        # Test all 6 cases of:
+        #  hash=True/False/None
+        #  compare=True/False
+        for (hash_,    compare, result  ) in [
+            (True,     False,   'field' ),
+            (True,     True,    'field' ),
+            (False,    False,   'absent'),
+            (False,    True,    'absent'),
+            (None,     False,   'absent'),
+            (None,     True,    'field' ),
+            ]:
+            with self.subTest(hash=hash_, compare=compare):
+                @dataclass(unsafe_hash=True)
+                class C:
+                    x: int = field(compare=compare, hash=hash_, default=5)
+
+                if result == 'field':
+                    # __hash__ contains the field.
+                    self.assertEqual(hash(C(5)), hash((5,)))
+                elif result == 'absent':
+                    # The field is not present in the hash.
+                    self.assertEqual(hash(C(5)), hash(()))
+                else:
+                    assert False, f'unknown result {result!r}'
+
+    def test_init_false_no_default(self):
+        # If init=False and no default value, then the field won't be
+        #  present in the instance.
+        @dataclass
+        class C:
+            x: int = field(init=False)
+
+        self.assertNotIn('x', C().__dict__)
+
+        @dataclass
+        class C:
+            x: int
+            y: int = 0
+            z: int = field(init=False)
+            t: int = 10
+
+        self.assertNotIn('z', C(0).__dict__)
+        self.assertEqual(vars(C(5)), {'t': 10, 'x': 5, 'y': 0})
+
+    def test_class_marker(self):
+        @dataclass
+        class C:
+            x: int
+            y: str = field(init=False, default=None)
+            z: str = field(repr=False)
+
+        the_fields = fields(C)
+        # the_fields is a tuple of 3 items, each value
+        #  is in __annotations__.
+        self.assertIsInstance(the_fields, tuple)
+        for f in the_fields:
+            self.assertIs(type(f), Field)
+            self.assertIn(f.name, C.__annotations__)
+
+        self.assertEqual(len(the_fields), 3)
+
+        self.assertEqual(the_fields[0].name, 'x')
+        self.assertEqual(the_fields[0].type, int)
+        self.assertFalse(hasattr(C, 'x'))
+        self.assertTrue (the_fields[0].init)
+        self.assertTrue (the_fields[0].repr)
+        self.assertEqual(the_fields[1].name, 'y')
+        self.assertEqual(the_fields[1].type, str)
+        self.assertIsNone(getattr(C, 'y'))
+        self.assertFalse(the_fields[1].init)
+        self.assertTrue (the_fields[1].repr)
+        self.assertEqual(the_fields[2].name, 'z')
+        self.assertEqual(the_fields[2].type, str)
+        self.assertFalse(hasattr(C, 'z'))
+        self.assertTrue (the_fields[2].init)
+        self.assertFalse(the_fields[2].repr)
+
+    def test_field_order(self):
+        @dataclass
+        class B:
+            a: str = 'B:a'
+            b: str = 'B:b'
+            c: str = 'B:c'
+
+        @dataclass
+        class C(B):
+            b: str = 'C:b'
+
+        self.assertEqual([(f.name, f.default) for f in fields(C)],
+                         [('a', 'B:a'),
+                          ('b', 'C:b'),
+                          ('c', 'B:c')])
+
+        @dataclass
+        class D(B):
+            c: str = 'D:c'
+
+        self.assertEqual([(f.name, f.default) for f in fields(D)],
+                         [('a', 'B:a'),
+                          ('b', 'B:b'),
+                          ('c', 'D:c')])
+
+        @dataclass
+        class E(D):
+            a: str = 'E:a'
+            d: str = 'E:d'
+
+        self.assertEqual([(f.name, f.default) for f in fields(E)],
+                         [('a', 'E:a'),
+                          ('b', 'B:b'),
+                          ('c', 'D:c'),
+                          ('d', 'E:d')])
+
+    def test_class_attrs(self):
+        # We only have a class attribute if a default value is
+        #  specified, either directly or via a field with a default.
+        default = object()
+        @dataclass
+        class C:
+            x: int
+            y: int = field(repr=False)
+            z: object = default
+            t: int = field(default=100)
+
+        self.assertFalse(hasattr(C, 'x'))
+        self.assertFalse(hasattr(C, 'y'))
+        self.assertIs   (C.z, default)
+        self.assertEqual(C.t, 100)
+
+    def test_disallowed_mutable_defaults(self):
+        # For the known types, don't allow mutable default values.
+        for typ, empty, non_empty in [(list, [], [1]),
+                                      (dict, {}, {0:1}),
+                                      (set, set(), set([1])),
+                                      ]:
+            with self.subTest(typ=typ):
+                # Can't use a zero-length value.
+                with self.assertRaisesRegex(ValueError,
+                                            f'mutable default {typ} for field '
+                                            'x is not allowed'):
+                    @dataclass
+                    class Point:
+                        x: typ = empty
+
+
+                # Nor a non-zero-length value
+                with self.assertRaisesRegex(ValueError,
+                                            f'mutable default {typ} for field '
+                                            'y is not allowed'):
+                    @dataclass
+                    class Point:
+                        y: typ = non_empty
+
+                # Check subtypes also fail.
+                class Subclass(typ): pass
+
+                with self.assertRaisesRegex(ValueError,
+                                            "mutable default .*Subclass'>"
+                                            " for field z is not allowed"
+                                            ):
+                    @dataclass
+                    class Point:
+                        z: typ = Subclass()
+
+                # Because this is a ClassVar, it can be mutable.
+                @dataclass
+                class C:
+                    z: ClassVar[typ] = typ()
+
+                # Because this is a ClassVar, it can be mutable.
+                @dataclass
+                class C:
+                    x: ClassVar[typ] = Subclass()
+
+    def test_deliberately_mutable_defaults(self):
+        # If a mutable default isn't in the known list of
+        #  (list, dict, set), then it's okay.
+        class Mutable:
+            def __init__(self):
+                self.l = []
+
+        @dataclass
+        class C:
+            x: Mutable
+
+        # These 2 instances will share this value of x.
+        lst = Mutable()
+        o1 = C(lst)
+        o2 = C(lst)
+        self.assertEqual(o1, o2)
+        o1.x.l.extend([1, 2])
+        self.assertEqual(o1, o2)
+        self.assertEqual(o1.x.l, [1, 2])
+        self.assertIs(o1.x, o2.x)
+
+    def test_no_options(self):
+        # Call with dataclass().
+        @dataclass()
+        class C:
+            x: int
+
+        self.assertEqual(C(42).x, 42)
+
+    def test_not_tuple(self):
+        # Make sure we can't be compared to a tuple.
+        @dataclass
+        class Point:
+            x: int
+            y: int
+        self.assertNotEqual(Point(1, 2), (1, 2))
+
+        # And that we can't compare to another unrelated dataclass.
+        @dataclass
+        class C:
+            x: int
+            y: int
+        self.assertNotEqual(Point(1, 3), C(1, 3))
+
+    def test_not_other_dataclass(self):
+        # Test that some of the problems with namedtuple don't happen
+        #  here.
+        @dataclass
+        class Point3D:
+            x: int
+            y: int
+            z: int
+
+        @dataclass
+        class Date:
+            year: int
+            month: int
+            day: int
+
+        self.assertNotEqual(Point3D(2017, 6, 3), Date(2017, 6, 3))
+        self.assertNotEqual(Point3D(1, 2, 3), (1, 2, 3))
+
+        # Make sure we can't unpack.
+        with self.assertRaisesRegex(TypeError, 'unpack'):
+            x, y, z = Point3D(4, 5, 6)
+
+        # Make sure another class with the same field names isn't
+        #  equal.
+        @dataclass
+        class Point3Dv1:
+            x: int = 0
+            y: int = 0
+            z: int = 0
+        self.assertNotEqual(Point3D(0, 0, 0), Point3Dv1())
+
+    def test_function_annotations(self):
+        # Some dummy class and instance to use as a default.
+        class F:
+            pass
+        f = F()
+
+        def validate_class(cls):
+            # First, check __annotations__, even though they're not
+            #  function annotations.
+            self.assertEqual(cls.__annotations__['i'], int)
+            self.assertEqual(cls.__annotations__['j'], str)
+            self.assertEqual(cls.__annotations__['k'], F)
+            self.assertEqual(cls.__annotations__['l'], float)
+            self.assertEqual(cls.__annotations__['z'], complex)
+
+            # Verify __init__.
+
+            signature = inspect.signature(cls.__init__)
+            # Check the return type, should be None.
+            self.assertIs(signature.return_annotation, None)
+
+            # Check each parameter.
+            params = iter(signature.parameters.values())
+            param = next(params)
+            # This is testing an internal name, and probably shouldn't be tested.
+            self.assertEqual(param.name, 'self')
+            param = next(params)
+            self.assertEqual(param.name, 'i')
+            self.assertIs   (param.annotation, int)
+            self.assertEqual(param.default, inspect.Parameter.empty)
+            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
+            param = next(params)
+            self.assertEqual(param.name, 'j')
+            self.assertIs   (param.annotation, str)
+            self.assertEqual(param.default, inspect.Parameter.empty)
+            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
+            param = next(params)
+            self.assertEqual(param.name, 'k')
+            self.assertIs   (param.annotation, F)
+            # Don't test for the default, since it's set to MISSING.
+            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
+            param = next(params)
+            self.assertEqual(param.name, 'l')
+            self.assertIs   (param.annotation, float)
+            # Don't test for the default, since it's set to MISSING.
+            self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_OR_KEYWORD)
+            self.assertRaises(StopIteration, next, params)
+
+
+        @dataclass
+        class C:
+            i: int
+            j: str
+            k: F = f
+            l: float=field(default=None)
+            z: complex=field(default=3+4j, init=False)
+
+        validate_class(C)
+
+        # Now repeat with __hash__.
+        @dataclass(frozen=True, unsafe_hash=True)
+        class C:
+            i: int
+            j: str
+            k: F = f
+            l: float=field(default=None)
+            z: complex=field(default=3+4j, init=False)
+
+        validate_class(C)
+
+    def test_missing_default(self):
+        # Test that MISSING works the same as a default not being
+        #  specified.
+        @dataclass
+        class C:
+            x: int=field(default=MISSING)
+        with self.assertRaisesRegex(TypeError,
+                                    r'__init__\(\) missing 1 required '
+                                    'positional argument'):
+            C()
+        self.assertNotIn('x', C.__dict__)
+
+        @dataclass
+        class D:
+            x: int
+        with self.assertRaisesRegex(TypeError,
+                                    r'__init__\(\) missing 1 required '
+                                    'positional argument'):
+            D()
+        self.assertNotIn('x', D.__dict__)
+
+    def test_missing_default_factory(self):
+        # Test that MISSING works the same as a default factory not
+        #  being specified (which is really the same as a default not
+        #  being specified, too).
+        @dataclass
+        class C:
+            x: int=field(default_factory=MISSING)
+        with self.assertRaisesRegex(TypeError,
+                                    r'__init__\(\) missing 1 required '
+                                    'positional argument'):
+            C()
+        self.assertNotIn('x', C.__dict__)
+
+        @dataclass
+        class D:
+            x: int=field(default=MISSING, default_factory=MISSING)
+        with self.assertRaisesRegex(TypeError,
+                                    r'__init__\(\) missing 1 required '
+                                    'positional argument'):
+            D()
+        self.assertNotIn('x', D.__dict__)
+
+    def test_missing_repr(self):
+        self.assertIn('MISSING_TYPE object', repr(MISSING))
+
+    def test_dont_include_other_annotations(self):
+        @dataclass
+        class C:
+            i: int
+            def foo(self) -> int:
+                return 4
+            @property
+            def bar(self) -> int:
+                return 5
+        self.assertEqual(list(C.__annotations__), ['i'])
+        self.assertEqual(C(10).foo(), 4)
+        self.assertEqual(C(10).bar, 5)
+        self.assertEqual(C(10).i, 10)
+
+    def test_post_init(self):
+        # Just make sure it gets called
+        @dataclass
+        class C:
+            def __post_init__(self):
+                raise CustomError()
+        with self.assertRaises(CustomError):
+            C()
+
+        @dataclass
+        class C:
+            i: int = 10
+            def __post_init__(self):
+                if self.i == 10:
+                    raise CustomError()
+        with self.assertRaises(CustomError):
+            C()
+        # post-init gets called, but doesn't raise. This is just
+        #  checking that self is used correctly.
+        C(5)
+
+        # If there's not an __init__, then post-init won't get called.
+        @dataclass(init=False)
+        class C:
+            def __post_init__(self):
+                raise CustomError()
+        # Creating the class won't raise
+        C()
+
+        @dataclass
+        class C:
+            x: int = 0
+            def __post_init__(self):
+                self.x *= 2
+        self.assertEqual(C().x, 0)
+        self.assertEqual(C(2).x, 4)
+
+        # Make sure that if we're frozen, post-init can't set
+        #  attributes.
+        @dataclass(frozen=True)
+        class C:
+            x: int = 0
+            def __post_init__(self):
+                self.x *= 2
+        with self.assertRaises(FrozenInstanceError):
+            C()
+
+    def test_post_init_super(self):
+        # Make sure super() post-init isn't called by default.
+        class B:
+            def __post_init__(self):
+                raise CustomError()
+
+        @dataclass
+        class C(B):
+            def __post_init__(self):
+                self.x = 5
+
+        self.assertEqual(C().x, 5)
+
+        # Now call super(), and it will raise.
+        @dataclass
+        class C(B):
+            def __post_init__(self):
+                super().__post_init__()
+
+        with self.assertRaises(CustomError):
+            C()
+
+        # Make sure post-init is called, even if not defined in our
+        #  class.
+        @dataclass
+        class C(B):
+            pass
+
+        with self.assertRaises(CustomError):
+            C()
+
+    def test_post_init_staticmethod(self):
+        flag = False
+        @dataclass
+        class C:
+            x: int
+            y: int
+            @staticmethod
+            def __post_init__():
+                nonlocal flag
+                flag = True
+
+        self.assertFalse(flag)
+        c = C(3, 4)
+        self.assertEqual((c.x, c.y), (3, 4))
+        self.assertTrue(flag)
+
+    def test_post_init_classmethod(self):
+        @dataclass
+        class C:
+            flag = False
+            x: int
+            y: int
+            @classmethod
+            def __post_init__(cls):
+                cls.flag = True
+
+        self.assertFalse(C.flag)
+        c = C(3, 4)
+        self.assertEqual((c.x, c.y), (3, 4))
+        self.assertTrue(C.flag)
+
+    def test_post_init_not_auto_added(self):
+        # See bpo-46757, which had proposed always adding __post_init__.  As
+        # Raymond Hettinger pointed out, that would be a breaking change.  So,
+        # add a test to make sure that the current behavior doesn't change.
+
+        @dataclass
+        class A0:
+            pass
+
+        @dataclass
+        class B0:
+            b_called: bool = False
+            def __post_init__(self):
+                self.b_called = True
+
+        @dataclass
+        class C0(A0, B0):
+            c_called: bool = False
+            def __post_init__(self):
+                super().__post_init__()
+                self.c_called = True
+
+        # Since A0 has no __post_init__, and one wasn't automatically added
+        # (because that's the rule: it's never added by @dataclass, it's only
+        # the class author that can add it), then B0.__post_init__ is called.
+        # Verify that.
+        c = C0()
+        self.assertTrue(c.b_called)
+        self.assertTrue(c.c_called)
+
+        ######################################
+        # Now, the same thing, except A1 defines __post_init__.
+        @dataclass
+        class A1:
+            def __post_init__(self):
+                pass
+
+        @dataclass
+        class B1:
+            b_called: bool = False
+            def __post_init__(self):
+                self.b_called = True
+
+        @dataclass
+        class C1(A1, B1):
+            c_called: bool = False
+            def __post_init__(self):
+                super().__post_init__()
+                self.c_called = True
+
+        # This time, B1.__post_init__ isn't being called.  This mimics what
+        # would happen if A1.__post_init__ had been automatically added,
+        # instead of manually added as we see here.  This test isn't really
+        # needed, but I'm including it just to demonstrate the changed
+        # behavior when A1 does define __post_init__.
+        c = C1()
+        self.assertFalse(c.b_called)
+        self.assertTrue(c.c_called)
+
+    def test_class_var(self):
+        # Make sure ClassVars are ignored in __init__, __repr__, etc.
+        @dataclass
+        class C:
+            x: int
+            y: int = 10
+            z: ClassVar[int] = 1000
+            w: ClassVar[int] = 2000
+            t: ClassVar[int] = 3000
+            s: ClassVar      = 4000
+
+        c = C(5)
+        self.assertEqual(repr(c), 'TestCase.test_class_var.<locals>.C(x=5, y=10)')
+        self.assertEqual(len(fields(C)), 2)                 # We have 2 fields.
+        self.assertEqual(len(C.__annotations__), 6)         # And 4 ClassVars.
+        self.assertEqual(c.z, 1000)
+        self.assertEqual(c.w, 2000)
+        self.assertEqual(c.t, 3000)
+        self.assertEqual(c.s, 4000)
+        C.z += 1
+        self.assertEqual(c.z, 1001)
+        c = C(20)
+        self.assertEqual((c.x, c.y), (20, 10))
+        self.assertEqual(c.z, 1001)
+        self.assertEqual(c.w, 2000)
+        self.assertEqual(c.t, 3000)
+        self.assertEqual(c.s, 4000)
+
+    def test_class_var_no_default(self):
+        # If a ClassVar has no default value, it should not be set on the class.
+        @dataclass
+        class C:
+            x: ClassVar[int]
+
+        self.assertNotIn('x', C.__dict__)
+
+    def test_class_var_default_factory(self):
+        # It makes no sense for a ClassVar to have a default factory. When
+        #  would it be called? Call it yourself, since it's class-wide.
+        with self.assertRaisesRegex(TypeError,
+                                    'cannot have a default factory'):
+            @dataclass
+            class C:
+                x: ClassVar[int] = field(default_factory=int)
+
+            self.assertNotIn('x', C.__dict__)
+
+    def test_class_var_with_default(self):
+        # If a ClassVar has a default value, it should be set on the class.
+        @dataclass
+        class C:
+            x: ClassVar[int] = 10
+        self.assertEqual(C.x, 10)
+
+        @dataclass
+        class C:
+            x: ClassVar[int] = field(default=10)
+        self.assertEqual(C.x, 10)
+
+    def test_class_var_frozen(self):
+        # Make sure ClassVars work even if we're frozen.
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            y: int = 10
+            z: ClassVar[int] = 1000
+            w: ClassVar[int] = 2000
+            t: ClassVar[int] = 3000
+
+        c = C(5)
+        self.assertEqual(repr(C(5)), 'TestCase.test_class_var_frozen.<locals>.C(x=5, y=10)')
+        self.assertEqual(len(fields(C)), 2)                 # We have 2 fields
+        self.assertEqual(len(C.__annotations__), 5)         # And 3 ClassVars
+        self.assertEqual(c.z, 1000)
+        self.assertEqual(c.w, 2000)
+        self.assertEqual(c.t, 3000)
+        # We can still modify the ClassVar, it's only instances that are
+        #  frozen.
+        C.z += 1
+        self.assertEqual(c.z, 1001)
+        c = C(20)
+        self.assertEqual((c.x, c.y), (20, 10))
+        self.assertEqual(c.z, 1001)
+        self.assertEqual(c.w, 2000)
+        self.assertEqual(c.t, 3000)
+
+    def test_init_var_no_default(self):
+        # If an InitVar has no default value, it should not be set on the class.
+        @dataclass
+        class C:
+            x: InitVar[int]
+
+        self.assertNotIn('x', C.__dict__)
+
+    def test_init_var_default_factory(self):
+        # It makes no sense for an InitVar to have a default factory. When
+        #  would it be called? Call it yourself, since it's class-wide.
+        with self.assertRaisesRegex(TypeError,
+                                    'cannot have a default factory'):
+            @dataclass
+            class C:
+                x: InitVar[int] = field(default_factory=int)
+
+            self.assertNotIn('x', C.__dict__)
+
+    def test_init_var_with_default(self):
+        # If an InitVar has a default value, it should be set on the class.
+        @dataclass
+        class C:
+            x: InitVar[int] = 10
+        self.assertEqual(C.x, 10)
+
+        @dataclass
+        class C:
+            x: InitVar[int] = field(default=10)
+        self.assertEqual(C.x, 10)
+
+    def test_init_var(self):
+        @dataclass
+        class C:
+            x: int = None
+            init_param: InitVar[int] = None
+
+            def __post_init__(self, init_param):
+                if self.x is None:
+                    self.x = init_param*2
+
+        c = C(init_param=10)
+        self.assertEqual(c.x, 20)
+
+    def test_init_var_preserve_type(self):
+        self.assertEqual(InitVar[int].type, int)
+
+        # Make sure the repr is correct.
+        self.assertEqual(repr(InitVar[int]), 'dataclasses.InitVar[int]')
+        self.assertEqual(repr(InitVar[List[int]]),
+                         'dataclasses.InitVar[typing.List[int]]')
+        self.assertEqual(repr(InitVar[list[int]]),
+                         'dataclasses.InitVar[list[int]]')
+        self.assertEqual(repr(InitVar[int|str]),
+                         'dataclasses.InitVar[int | str]')
+
+    def test_init_var_inheritance(self):
+        # Note that this deliberately tests that a dataclass need not
+        #  have a __post_init__ function if it has an InitVar field.
+        #  It could just be used in a derived class, as shown here.
+        @dataclass
+        class Base:
+            x: int
+            init_base: InitVar[int]
+
+        # We can instantiate by passing the InitVar, even though
+        #  it's not used.
+        b = Base(0, 10)
+        self.assertEqual(vars(b), {'x': 0})
+
+        @dataclass
+        class C(Base):
+            y: int
+            init_derived: InitVar[int]
+
+            def __post_init__(self, init_base, init_derived):
+                self.x = self.x + init_base
+                self.y = self.y + init_derived
+
+        c = C(10, 11, 50, 51)
+        self.assertEqual(vars(c), {'x': 21, 'y': 101})
+
+    def test_default_factory(self):
+        # Test a factory that returns a new list.
+        @dataclass
+        class C:
+            x: int
+            y: list = field(default_factory=list)
+
+        c0 = C(3)
+        c1 = C(3)
+        self.assertEqual(c0.x, 3)
+        self.assertEqual(c0.y, [])
+        self.assertEqual(c0, c1)
+        self.assertIsNot(c0.y, c1.y)
+        self.assertEqual(astuple(C(5, [1])), (5, [1]))
+
+        # Test a factory that returns a shared list.
+        l = []
+        @dataclass
+        class C:
+            x: int
+            y: list = field(default_factory=lambda: l)
+
+        c0 = C(3)
+        c1 = C(3)
+        self.assertEqual(c0.x, 3)
+        self.assertEqual(c0.y, [])
+        self.assertEqual(c0, c1)
+        self.assertIs(c0.y, c1.y)
+        self.assertEqual(astuple(C(5, [1])), (5, [1]))
+
+        # Test various other field flags.
+        # repr
+        @dataclass
+        class C:
+            x: list = field(default_factory=list, repr=False)
+        self.assertEqual(repr(C()), 'TestCase.test_default_factory.<locals>.C()')
+        self.assertEqual(C().x, [])
+
+        # hash
+        @dataclass(unsafe_hash=True)
+        class C:
+            x: list = field(default_factory=list, hash=False)
+        self.assertEqual(astuple(C()), ([],))
+        self.assertEqual(hash(C()), hash(()))
+
+        # init (see also test_default_factory_with_no_init)
+        @dataclass
+        class C:
+            x: list = field(default_factory=list, init=False)
+        self.assertEqual(astuple(C()), ([],))
+
+        # compare
+        @dataclass
+        class C:
+            x: list = field(default_factory=list, compare=False)
+        self.assertEqual(C(), C([1]))
+
+    def test_default_factory_with_no_init(self):
+        # We need a factory with a side effect.
+        factory = Mock()
+
+        @dataclass
+        class C:
+            x: list = field(default_factory=factory, init=False)
+
+        # Make sure the default factory is called for each new instance.
+        C().x
+        self.assertEqual(factory.call_count, 1)
+        C().x
+        self.assertEqual(factory.call_count, 2)
+
+    def test_default_factory_not_called_if_value_given(self):
+        # We need a factory that we can test if it's been called.
+        factory = Mock()
+
+        @dataclass
+        class C:
+            x: int = field(default_factory=factory)
+
+        # Make sure that if a field has a default factory function,
+        #  it's not called if a value is specified.
+        C().x
+        self.assertEqual(factory.call_count, 1)
+        self.assertEqual(C(10).x, 10)
+        self.assertEqual(factory.call_count, 1)
+        C().x
+        self.assertEqual(factory.call_count, 2)
+
+    def test_default_factory_derived(self):
+        # See bpo-32896.
+        @dataclass
+        class Foo:
+            x: dict = field(default_factory=dict)
+
+        @dataclass
+        class Bar(Foo):
+            y: int = 1
+
+        self.assertEqual(Foo().x, {})
+        self.assertEqual(Bar().x, {})
+        self.assertEqual(Bar().y, 1)
+
+        @dataclass
+        class Baz(Foo):
+            pass
+        self.assertEqual(Baz().x, {})
+
+    def test_intermediate_non_dataclass(self):
+        # Test that an intermediate class that defines
+        #  annotations does not define fields.
+
+        @dataclass
+        class A:
+            x: int
+
+        class B(A):
+            y: int
+
+        @dataclass
+        class C(B):
+            z: int
+
+        c = C(1, 3)
+        self.assertEqual((c.x, c.z), (1, 3))
+
+        # .y was not initialized.
+        with self.assertRaisesRegex(AttributeError,
+                                    'object has no attribute'):
+            c.y
+
+        # And if we again derive a non-dataclass, no fields are added.
+        class D(C):
+            t: int
+        d = D(4, 5)
+        self.assertEqual((d.x, d.z), (4, 5))
+
+    def test_classvar_default_factory(self):
+        # It's an error for a ClassVar to have a factory function.
+        with self.assertRaisesRegex(TypeError,
+                                    'cannot have a default factory'):
+            @dataclass
+            class C:
+                x: ClassVar[int] = field(default_factory=int)
+
+    def test_is_dataclass(self):
+        class NotDataClass:
+            pass
+
+        self.assertFalse(is_dataclass(0))
+        self.assertFalse(is_dataclass(int))
+        self.assertFalse(is_dataclass(NotDataClass))
+        self.assertFalse(is_dataclass(NotDataClass()))
+
+        @dataclass
+        class C:
+            x: int
+
+        @dataclass
+        class D:
+            d: C
+            e: int
+
+        c = C(10)
+        d = D(c, 4)
+
+        self.assertTrue(is_dataclass(C))
+        self.assertTrue(is_dataclass(c))
+        self.assertFalse(is_dataclass(c.x))
+        self.assertTrue(is_dataclass(d.d))
+        self.assertFalse(is_dataclass(d.e))
+
+    def test_is_dataclass_when_getattr_always_returns(self):
+        # See bpo-37868.
+        class A:
+            def __getattr__(self, key):
+                return 0
+        self.assertFalse(is_dataclass(A))
+        a = A()
+
+        # Also test for an instance attribute.
+        class B:
+            pass
+        b = B()
+        b.__dataclass_fields__ = []
+
+        for obj in a, b:
+            with self.subTest(obj=obj):
+                self.assertFalse(is_dataclass(obj))
+
+                # Indirect tests for _is_dataclass_instance().
+                with self.assertRaisesRegex(TypeError, 'should be called on dataclass instances'):
+                    asdict(obj)
+                with self.assertRaisesRegex(TypeError, 'should be called on dataclass instances'):
+                    astuple(obj)
+                with self.assertRaisesRegex(TypeError, 'should be called on dataclass instances'):
+                    replace(obj, x=0)
+
+    def test_is_dataclass_genericalias(self):
+        @dataclass
+        class A(types.GenericAlias):
+            origin: type
+            args: type
+        self.assertTrue(is_dataclass(A))
+        a = A(list, int)
+        self.assertTrue(is_dataclass(type(a)))
+        self.assertTrue(is_dataclass(a))
+
+
+    def test_helper_fields_with_class_instance(self):
+        # Check that we can call fields() on either a class or instance,
+        #  and get back the same thing.
+        @dataclass
+        class C:
+            x: int
+            y: float
+
+        self.assertEqual(fields(C), fields(C(0, 0.0)))
+
+    def test_helper_fields_exception(self):
+        # Check that TypeError is raised if not passed a dataclass or
+        #  instance.
+        with self.assertRaisesRegex(TypeError, 'dataclass type or instance'):
+            fields(0)
+
+        class C: pass
+        with self.assertRaisesRegex(TypeError, 'dataclass type or instance'):
+            fields(C)
+        with self.assertRaisesRegex(TypeError, 'dataclass type or instance'):
+            fields(C())
+
+    def test_clean_traceback_from_fields_exception(self):
+        stdout = io.StringIO()
+        try:
+            fields(object)
+        except TypeError as exc:
+            traceback.print_exception(exc, file=stdout)
+        printed_traceback = stdout.getvalue()
+        self.assertNotIn("AttributeError", printed_traceback)
+        self.assertNotIn("__dataclass_fields__", printed_traceback)
+
+    def test_helper_asdict(self):
+        # Basic tests for asdict(), it should return a new dictionary.
+        @dataclass
+        class C:
+            x: int
+            y: int
+        c = C(1, 2)
+
+        self.assertEqual(asdict(c), {'x': 1, 'y': 2})
+        self.assertEqual(asdict(c), asdict(c))
+        self.assertIsNot(asdict(c), asdict(c))
+        c.x = 42
+        self.assertEqual(asdict(c), {'x': 42, 'y': 2})
+        self.assertIs(type(asdict(c)), dict)
+
+    def test_helper_asdict_raises_on_classes(self):
+        # asdict() should raise on a class object.
+        @dataclass
+        class C:
+            x: int
+            y: int
+        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
+            asdict(C)
+        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
+            asdict(int)
+
+    def test_helper_asdict_copy_values(self):
+        @dataclass
+        class C:
+            x: int
+            y: List[int] = field(default_factory=list)
+        initial = []
+        c = C(1, initial)
+        d = asdict(c)
+        self.assertEqual(d['y'], initial)
+        self.assertIsNot(d['y'], initial)
+        c = C(1)
+        d = asdict(c)
+        d['y'].append(1)
+        self.assertEqual(c.y, [])
+
+    def test_helper_asdict_nested(self):
+        @dataclass
+        class UserId:
+            token: int
+            group: int
+        @dataclass
+        class User:
+            name: str
+            id: UserId
+        u = User('Joe', UserId(123, 1))
+        d = asdict(u)
+        self.assertEqual(d, {'name': 'Joe', 'id': {'token': 123, 'group': 1}})
+        self.assertIsNot(asdict(u), asdict(u))
+        u.id.group = 2
+        self.assertEqual(asdict(u), {'name': 'Joe',
+                                     'id': {'token': 123, 'group': 2}})
+
+    def test_helper_asdict_builtin_containers(self):
+        @dataclass
+        class User:
+            name: str
+            id: int
+        @dataclass
+        class GroupList:
+            id: int
+            users: List[User]
+        @dataclass
+        class GroupTuple:
+            id: int
+            users: Tuple[User, ...]
+        @dataclass
+        class GroupDict:
+            id: int
+            users: Dict[str, User]
+        a = User('Alice', 1)
+        b = User('Bob', 2)
+        gl = GroupList(0, [a, b])
+        gt = GroupTuple(0, (a, b))
+        gd = GroupDict(0, {'first': a, 'second': b})
+        self.assertEqual(asdict(gl), {'id': 0, 'users': [{'name': 'Alice', 'id': 1},
+                                                         {'name': 'Bob', 'id': 2}]})
+        self.assertEqual(asdict(gt), {'id': 0, 'users': ({'name': 'Alice', 'id': 1},
+                                                         {'name': 'Bob', 'id': 2})})
+        self.assertEqual(asdict(gd), {'id': 0, 'users': {'first': {'name': 'Alice', 'id': 1},
+                                                         'second': {'name': 'Bob', 'id': 2}}})
+
+    def test_helper_asdict_builtin_object_containers(self):
+        @dataclass
+        class Child:
+            d: object
+
+        @dataclass
+        class Parent:
+            child: Child
+
+        self.assertEqual(asdict(Parent(Child([1]))), {'child': {'d': [1]}})
+        self.assertEqual(asdict(Parent(Child({1: 2}))), {'child': {'d': {1: 2}}})
+
+    def test_helper_asdict_factory(self):
+        @dataclass
+        class C:
+            x: int
+            y: int
+        c = C(1, 2)
+        d = asdict(c, dict_factory=OrderedDict)
+        self.assertEqual(d, OrderedDict([('x', 1), ('y', 2)]))
+        self.assertIsNot(d, asdict(c, dict_factory=OrderedDict))
+        c.x = 42
+        d = asdict(c, dict_factory=OrderedDict)
+        self.assertEqual(d, OrderedDict([('x', 42), ('y', 2)]))
+        self.assertIs(type(d), OrderedDict)
+
+    def test_helper_asdict_namedtuple(self):
+        T = namedtuple('T', 'a b c')
+        @dataclass
+        class C:
+            x: str
+            y: T
+        c = C('outer', T(1, C('inner', T(11, 12, 13)), 2))
+
+        d = asdict(c)
+        self.assertEqual(d, {'x': 'outer',
+                             'y': T(1,
+                                    {'x': 'inner',
+                                     'y': T(11, 12, 13)},
+                                    2),
+                             }
+                         )
+
+        # Now with a dict_factory.  OrderedDict is convenient, but
+        # since it compares to dicts, we also need to have separate
+        # assertIs tests.
+        d = asdict(c, dict_factory=OrderedDict)
+        self.assertEqual(d, {'x': 'outer',
+                             'y': T(1,
+                                    {'x': 'inner',
+                                     'y': T(11, 12, 13)},
+                                    2),
+                             }
+                         )
+
+        # Make sure that the returned dicts are actually OrderedDicts.
+        self.assertIs(type(d), OrderedDict)
+        self.assertIs(type(d['y'][1]), OrderedDict)
+
+    def test_helper_asdict_namedtuple_key(self):
+        # Ensure that a field that contains a dict which has a
+        # namedtuple as a key works with asdict().
+
+        @dataclass
+        class C:
+            f: dict
+        T = namedtuple('T', 'a')
+
+        c = C({T('an a'): 0})
+
+        self.assertEqual(asdict(c), {'f': {T(a='an a'): 0}})
+
+    def test_helper_asdict_namedtuple_derived(self):
+        class T(namedtuple('Tbase', 'a')):
+            def my_a(self):
+                return self.a
+
+        @dataclass
+        class C:
+            f: T
+
+        t = T(6)
+        c = C(t)
+
+        d = asdict(c)
+        self.assertEqual(d, {'f': T(a=6)})
+        # Make sure that t has been copied, not used directly.
+        self.assertIsNot(d['f'], t)
+        self.assertEqual(d['f'].my_a(), 6)
+
+    def test_helper_asdict_defaultdict(self):
+        # Ensure asdict() does not throw exceptions when a
+        # defaultdict is a member of a dataclass
+        @dataclass
+        class C:
+            mp: DefaultDict[str, List]
+
+        dd = defaultdict(list)
+        dd["x"].append(12)
+        c = C(mp=dd)
+        d = asdict(c)
+
+        self.assertEqual(d, {"mp": {"x": [12]}})
+        self.assertTrue(d["mp"] is not c.mp)  # make sure defaultdict is copied
+
+    def test_helper_astuple(self):
+        # Basic tests for astuple(), it should return a new tuple.
+        @dataclass
+        class C:
+            x: int
+            y: int = 0
+        c = C(1)
+
+        self.assertEqual(astuple(c), (1, 0))
+        self.assertEqual(astuple(c), astuple(c))
+        self.assertIsNot(astuple(c), astuple(c))
+        c.y = 42
+        self.assertEqual(astuple(c), (1, 42))
+        self.assertIs(type(astuple(c)), tuple)
+
+    def test_helper_astuple_raises_on_classes(self):
+        # astuple() should raise on a class object.
+        @dataclass
+        class C:
+            x: int
+            y: int
+        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
+            astuple(C)
+        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
+            astuple(int)
+
+    def test_helper_astuple_copy_values(self):
+        @dataclass
+        class C:
+            x: int
+            y: List[int] = field(default_factory=list)
+        initial = []
+        c = C(1, initial)
+        t = astuple(c)
+        self.assertEqual(t[1], initial)
+        self.assertIsNot(t[1], initial)
+        c = C(1)
+        t = astuple(c)
+        t[1].append(1)
+        self.assertEqual(c.y, [])
+
+    def test_helper_astuple_nested(self):
+        @dataclass
+        class UserId:
+            token: int
+            group: int
+        @dataclass
+        class User:
+            name: str
+            id: UserId
+        u = User('Joe', UserId(123, 1))
+        t = astuple(u)
+        self.assertEqual(t, ('Joe', (123, 1)))
+        self.assertIsNot(astuple(u), astuple(u))
+        u.id.group = 2
+        self.assertEqual(astuple(u), ('Joe', (123, 2)))
+
+    def test_helper_astuple_builtin_containers(self):
+        @dataclass
+        class User:
+            name: str
+            id: int
+        @dataclass
+        class GroupList:
+            id: int
+            users: List[User]
+        @dataclass
+        class GroupTuple:
+            id: int
+            users: Tuple[User, ...]
+        @dataclass
+        class GroupDict:
+            id: int
+            users: Dict[str, User]
+        a = User('Alice', 1)
+        b = User('Bob', 2)
+        gl = GroupList(0, [a, b])
+        gt = GroupTuple(0, (a, b))
+        gd = GroupDict(0, {'first': a, 'second': b})
+        self.assertEqual(astuple(gl), (0, [('Alice', 1), ('Bob', 2)]))
+        self.assertEqual(astuple(gt), (0, (('Alice', 1), ('Bob', 2))))
+        self.assertEqual(astuple(gd), (0, {'first': ('Alice', 1), 'second': ('Bob', 2)}))
+
+    def test_helper_astuple_builtin_object_containers(self):
+        @dataclass
+        class Child:
+            d: object
+
+        @dataclass
+        class Parent:
+            child: Child
+
+        self.assertEqual(astuple(Parent(Child([1]))), (([1],),))
+        self.assertEqual(astuple(Parent(Child({1: 2}))), (({1: 2},),))
+
+    def test_helper_astuple_factory(self):
+        @dataclass
+        class C:
+            x: int
+            y: int
+        NT = namedtuple('NT', 'x y')
+        def nt(lst):
+            return NT(*lst)
+        c = C(1, 2)
+        t = astuple(c, tuple_factory=nt)
+        self.assertEqual(t, NT(1, 2))
+        self.assertIsNot(t, astuple(c, tuple_factory=nt))
+        c.x = 42
+        t = astuple(c, tuple_factory=nt)
+        self.assertEqual(t, NT(42, 2))
+        self.assertIs(type(t), NT)
+
+    def test_helper_astuple_namedtuple(self):
+        T = namedtuple('T', 'a b c')
+        @dataclass
+        class C:
+            x: str
+            y: T
+        c = C('outer', T(1, C('inner', T(11, 12, 13)), 2))
+
+        t = astuple(c)
+        self.assertEqual(t, ('outer', T(1, ('inner', (11, 12, 13)), 2)))
+
+        # Now, using a tuple_factory.  list is convenient here.
+        t = astuple(c, tuple_factory=list)
+        self.assertEqual(t, ['outer', T(1, ['inner', T(11, 12, 13)], 2)])
+
+    def test_helper_astuple_defaultdict(self):
+        # Ensure astuple() does not throw exceptions when a
+        # defaultdict is a member of a dataclass
+        @dataclass
+        class C:
+            mp: DefaultDict[str, List]
+
+        dd = defaultdict(list)
+        dd["x"].append(12)
+        c = C(mp=dd)
+        t = astuple(c)
+
+        self.assertEqual(t, ({"x": [12]},))
+        self.assertTrue(t[0] is not dd) # make sure defaultdict is copied
+
+    def test_dynamic_class_creation(self):
+        cls_dict = {'__annotations__': {'x': int, 'y': int},
+                    }
+
+        # Create the class.
+        cls = type('C', (), cls_dict)
+
+        # Make it a dataclass.
+        cls1 = dataclass(cls)
+
+        self.assertEqual(cls1, cls)
+        self.assertEqual(asdict(cls(1, 2)), {'x': 1, 'y': 2})
+
+    def test_dynamic_class_creation_using_field(self):
+        cls_dict = {'__annotations__': {'x': int, 'y': int},
+                    'y': field(default=5),
+                    }
+
+        # Create the class.
+        cls = type('C', (), cls_dict)
+
+        # Make it a dataclass.
+        cls1 = dataclass(cls)
+
+        self.assertEqual(cls1, cls)
+        self.assertEqual(asdict(cls1(1)), {'x': 1, 'y': 5})
+
+    def test_init_in_order(self):
+        @dataclass
+        class C:
+            a: int
+            b: int = field()
+            c: list = field(default_factory=list, init=False)
+            d: list = field(default_factory=list)
+            e: int = field(default=4, init=False)
+            f: int = 4
+
+        calls = []
+        def setattr(self, name, value):
+            calls.append((name, value))
+
+        C.__setattr__ = setattr
+        c = C(0, 1)
+        self.assertEqual(('a', 0), calls[0])
+        self.assertEqual(('b', 1), calls[1])
+        self.assertEqual(('c', []), calls[2])
+        self.assertEqual(('d', []), calls[3])
+        self.assertNotIn(('e', 4), calls)
+        self.assertEqual(('f', 4), calls[4])
+
+    def test_items_in_dicts(self):
+        @dataclass
+        class C:
+            a: int
+            b: list = field(default_factory=list, init=False)
+            c: list = field(default_factory=list)
+            d: int = field(default=4, init=False)
+            e: int = 0
+
+        c = C(0)
+        # Class dict
+        self.assertNotIn('a', C.__dict__)
+        self.assertNotIn('b', C.__dict__)
+        self.assertNotIn('c', C.__dict__)
+        self.assertIn('d', C.__dict__)
+        self.assertEqual(C.d, 4)
+        self.assertIn('e', C.__dict__)
+        self.assertEqual(C.e, 0)
+        # Instance dict
+        self.assertIn('a', c.__dict__)
+        self.assertEqual(c.a, 0)
+        self.assertIn('b', c.__dict__)
+        self.assertEqual(c.b, [])
+        self.assertIn('c', c.__dict__)
+        self.assertEqual(c.c, [])
+        self.assertNotIn('d', c.__dict__)
+        self.assertIn('e', c.__dict__)
+        self.assertEqual(c.e, 0)
+
+    def test_alternate_classmethod_constructor(self):
+        # Since __post_init__ can't take params, use a classmethod
+        #  alternate constructor.  This is mostly an example to show
+        #  how to use this technique.
+        @dataclass
+        class C:
+            x: int
+            @classmethod
+            def from_file(cls, filename):
+                # In a real example, create a new instance
+                #  and populate 'x' from contents of a file.
+                value_in_file = 20
+                return cls(value_in_file)
+
+        self.assertEqual(C.from_file('filename').x, 20)
+
+    def test_field_metadata_default(self):
+        # Make sure the default metadata is read-only and of
+        #  zero length.
+        @dataclass
+        class C:
+            i: int
+
+        self.assertFalse(fields(C)[0].metadata)
+        self.assertEqual(len(fields(C)[0].metadata), 0)
+        with self.assertRaisesRegex(TypeError,
+                                    'does not support item assignment'):
+            fields(C)[0].metadata['test'] = 3
+
+    def test_field_metadata_mapping(self):
+        # Make sure only a mapping can be passed as metadata
+        #  zero length.
+        with self.assertRaises(TypeError):
+            @dataclass
+            class C:
+                i: int = field(metadata=0)
+
+        # Make sure an empty dict works.
+        d = {}
+        @dataclass
+        class C:
+            i: int = field(metadata=d)
+        self.assertFalse(fields(C)[0].metadata)
+        self.assertEqual(len(fields(C)[0].metadata), 0)
+        # Update should work (see bpo-35960).
+        d['foo'] = 1
+        self.assertEqual(len(fields(C)[0].metadata), 1)
+        self.assertEqual(fields(C)[0].metadata['foo'], 1)
+        with self.assertRaisesRegex(TypeError,
+                                    'does not support item assignment'):
+            fields(C)[0].metadata['test'] = 3
+
+        # Make sure a non-empty dict works.
+        d = {'test': 10, 'bar': '42', 3: 'three'}
+        @dataclass
+        class C:
+            i: int = field(metadata=d)
+        self.assertEqual(len(fields(C)[0].metadata), 3)
+        self.assertEqual(fields(C)[0].metadata['test'], 10)
+        self.assertEqual(fields(C)[0].metadata['bar'], '42')
+        self.assertEqual(fields(C)[0].metadata[3], 'three')
+        # Update should work.
+        d['foo'] = 1
+        self.assertEqual(len(fields(C)[0].metadata), 4)
+        self.assertEqual(fields(C)[0].metadata['foo'], 1)
+        with self.assertRaises(KeyError):
+            # Non-existent key.
+            fields(C)[0].metadata['baz']
+        with self.assertRaisesRegex(TypeError,
+                                    'does not support item assignment'):
+            fields(C)[0].metadata['test'] = 3
+
+    def test_field_metadata_custom_mapping(self):
+        # Try a custom mapping.
+        class SimpleNameSpace:
+            def __init__(self, **kw):
+                self.__dict__.update(kw)
+
+            def __getitem__(self, item):
+                if item == 'xyzzy':
+                    return 'plugh'
+                return getattr(self, item)
+
+            def __len__(self):
+                return self.__dict__.__len__()
+
+        @dataclass
+        class C:
+            i: int = field(metadata=SimpleNameSpace(a=10))
+
+        self.assertEqual(len(fields(C)[0].metadata), 1)
+        self.assertEqual(fields(C)[0].metadata['a'], 10)
+        with self.assertRaises(AttributeError):
+            fields(C)[0].metadata['b']
+        # Make sure we're still talking to our custom mapping.
+        self.assertEqual(fields(C)[0].metadata['xyzzy'], 'plugh')
+
+    def test_generic_dataclasses(self):
+        T = TypeVar('T')
+
+        @dataclass
+        class LabeledBox(Generic[T]):
+            content: T
+            label: str = '<unknown>'
+
+        box = LabeledBox(42)
+        self.assertEqual(box.content, 42)
+        self.assertEqual(box.label, '<unknown>')
+
+        # Subscripting the resulting class should work, etc.
+        Alias = List[LabeledBox[int]]
+
+    def test_generic_extending(self):
+        S = TypeVar('S')
+        T = TypeVar('T')
+
+        @dataclass
+        class Base(Generic[T, S]):
+            x: T
+            y: S
+
+        @dataclass
+        class DataDerived(Base[int, T]):
+            new_field: str
+        Alias = DataDerived[str]
+        c = Alias(0, 'test1', 'test2')
+        self.assertEqual(astuple(c), (0, 'test1', 'test2'))
+
+        class NonDataDerived(Base[int, T]):
+            def new_method(self):
+                return self.y
+        Alias = NonDataDerived[float]
+        c = Alias(10, 1.0)
+        self.assertEqual(c.new_method(), 1.0)
+
+    def test_generic_dynamic(self):
+        T = TypeVar('T')
+
+        @dataclass
+        class Parent(Generic[T]):
+            x: T
+        Child = make_dataclass('Child', [('y', T), ('z', Optional[T], None)],
+                               bases=(Parent[int], Generic[T]), namespace={'other': 42})
+        self.assertIs(Child[int](1, 2).z, None)
+        self.assertEqual(Child[int](1, 2, 3).z, 3)
+        self.assertEqual(Child[int](1, 2, 3).other, 42)
+        # Check that type aliases work correctly.
+        Alias = Child[T]
+        self.assertEqual(Alias[int](1, 2).x, 1)
+        # Check MRO resolution.
+        self.assertEqual(Child.__mro__, (Child, Parent, Generic, object))
+
+    def test_dataclasses_pickleable(self):
+        global P, Q, R
+        @dataclass
+        class P:
+            x: int
+            y: int = 0
+        @dataclass
+        class Q:
+            x: int
+            y: int = field(default=0, init=False)
+        @dataclass
+        class R:
+            x: int
+            y: List[int] = field(default_factory=list)
+        q = Q(1)
+        q.y = 2
+        samples = [P(1), P(1, 2), Q(1), q, R(1), R(1, [2, 3, 4])]
+        for sample in samples:
+            for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+                with self.subTest(sample=sample, proto=proto):
+                    new_sample = pickle.loads(pickle.dumps(sample, proto))
+                    self.assertEqual(sample.x, new_sample.x)
+                    self.assertEqual(sample.y, new_sample.y)
+                    self.assertIsNot(sample, new_sample)
+                    new_sample.x = 42
+                    another_new_sample = pickle.loads(pickle.dumps(new_sample, proto))
+                    self.assertEqual(new_sample.x, another_new_sample.x)
+                    self.assertEqual(sample.y, another_new_sample.y)
+
+    def test_dataclasses_qualnames(self):
+        @dataclass(order=True, unsafe_hash=True, frozen=True)
+        class A:
+            x: int
+            y: int
+
+        self.assertEqual(A.__init__.__name__, "__init__")
+        for function in (
+            '__eq__',
+            '__lt__',
+            '__le__',
+            '__gt__',
+            '__ge__',
+            '__hash__',
+            '__init__',
+            '__repr__',
+            '__setattr__',
+            '__delattr__',
+        ):
+            self.assertEqual(getattr(A, function).__qualname__, f"TestCase.test_dataclasses_qualnames.<locals>.A.{function}")
+
+        with self.assertRaisesRegex(TypeError, r"A\.__init__\(\) missing"):
+            A()
+
+
+class TestFieldNoAnnotation(unittest.TestCase):
+    def test_field_without_annotation(self):
+        with self.assertRaisesRegex(TypeError,
+                                    "'f' is a field but has no type annotation"):
+            @dataclass
+            class C:
+                f = field()
+
+    def test_field_without_annotation_but_annotation_in_base(self):
+        @dataclass
+        class B:
+            f: int
+
+        with self.assertRaisesRegex(TypeError,
+                                    "'f' is a field but has no type annotation"):
+            # This is still an error: make sure we don't pick up the
+            #  type annotation in the base class.
+            @dataclass
+            class C(B):
+                f = field()
+
+    def test_field_without_annotation_but_annotation_in_base_not_dataclass(self):
+        # Same test, but with the base class not a dataclass.
+        class B:
+            f: int
+
+        with self.assertRaisesRegex(TypeError,
+                                    "'f' is a field but has no type annotation"):
+            # This is still an error: make sure we don't pick up the
+            #  type annotation in the base class.
+            @dataclass
+            class C(B):
+                f = field()
+
+
+class TestDocString(unittest.TestCase):
+    def assertDocStrEqual(self, a, b):
+        # Because 3.6 and 3.7 differ in how inspect.signature work
+        #  (see bpo #32108), for the time being just compare them with
+        #  whitespace stripped.
+        self.assertEqual(a.replace(' ', ''), b.replace(' ', ''))
+
+    def test_existing_docstring_not_overridden(self):
+        @dataclass
+        class C:
+            """Lorem ipsum"""
+            x: int
+
+        self.assertEqual(C.__doc__, "Lorem ipsum")
+
+    def test_docstring_no_fields(self):
+        @dataclass
+        class C:
+            pass
+
+        self.assertDocStrEqual(C.__doc__, "C()")
+
+    def test_docstring_one_field(self):
+        @dataclass
+        class C:
+            x: int
+
+        self.assertDocStrEqual(C.__doc__, "C(x:int)")
+
+    def test_docstring_two_fields(self):
+        @dataclass
+        class C:
+            x: int
+            y: int
+
+        self.assertDocStrEqual(C.__doc__, "C(x:int, y:int)")
+
+    def test_docstring_three_fields(self):
+        @dataclass
+        class C:
+            x: int
+            y: int
+            z: str
+
+        self.assertDocStrEqual(C.__doc__, "C(x:int, y:int, z:str)")
+
+    def test_docstring_one_field_with_default(self):
+        @dataclass
+        class C:
+            x: int = 3
+
+        self.assertDocStrEqual(C.__doc__, "C(x:int=3)")
+
+    def test_docstring_one_field_with_default_none(self):
+        @dataclass
+        class C:
+            x: Union[int, type(None)] = None
+
+        self.assertDocStrEqual(C.__doc__, "C(x:Optional[int]=None)")
+
+    def test_docstring_list_field(self):
+        @dataclass
+        class C:
+            x: List[int]
+
+        self.assertDocStrEqual(C.__doc__, "C(x:List[int])")
+
+    def test_docstring_list_field_with_default_factory(self):
+        @dataclass
+        class C:
+            x: List[int] = field(default_factory=list)
+
+        self.assertDocStrEqual(C.__doc__, "C(x:List[int]=<factory>)")
+
+    def test_docstring_deque_field(self):
+        @dataclass
+        class C:
+            x: deque
+
+        self.assertDocStrEqual(C.__doc__, "C(x:collections.deque)")
+
+    def test_docstring_deque_field_with_default_factory(self):
+        @dataclass
+        class C:
+            x: deque = field(default_factory=deque)
+
+        self.assertDocStrEqual(C.__doc__, "C(x:collections.deque=<factory>)")
+
+    def test_docstring_with_no_signature(self):
+        # See https://github.com/python/cpython/issues/103449
+        class Meta(type):
+            __call__ = dict
+        class Base(metaclass=Meta):
+            pass
+
+        @dataclass
+        class C(Base):
+            pass
+
+        self.assertDocStrEqual(C.__doc__, "C")
+
+
+class TestInit(unittest.TestCase):
+    def test_base_has_init(self):
+        class B:
+            def __init__(self):
+                self.z = 100
+
+        # Make sure that declaring this class doesn't raise an error.
+        #  The issue is that we can't override __init__ in our class,
+        #  but it should be okay to add __init__ to us if our base has
+        #  an __init__.
+        @dataclass
+        class C(B):
+            x: int = 0
+        c = C(10)
+        self.assertEqual(c.x, 10)
+        self.assertNotIn('z', vars(c))
+
+        # Make sure that if we don't add an init, the base __init__
+        #  gets called.
+        @dataclass(init=False)
+        class C(B):
+            x: int = 10
+        c = C()
+        self.assertEqual(c.x, 10)
+        self.assertEqual(c.z, 100)
+
+    def test_no_init(self):
+        @dataclass(init=False)
+        class C:
+            i: int = 0
+        self.assertEqual(C().i, 0)
+
+        @dataclass(init=False)
+        class C:
+            i: int = 2
+            def __init__(self):
+                self.i = 3
+        self.assertEqual(C().i, 3)
+
+    def test_overwriting_init(self):
+        # If the class has __init__, use it no matter the value of
+        #  init=.
+
+        @dataclass
+        class C:
+            x: int
+            def __init__(self, x):
+                self.x = 2 * x
+        self.assertEqual(C(3).x, 6)
+
+        @dataclass(init=True)
+        class C:
+            x: int
+            def __init__(self, x):
+                self.x = 2 * x
+        self.assertEqual(C(4).x, 8)
+
+        @dataclass(init=False)
+        class C:
+            x: int
+            def __init__(self, x):
+                self.x = 2 * x
+        self.assertEqual(C(5).x, 10)
+
+    def test_inherit_from_protocol(self):
+        # Dataclasses inheriting from protocol should preserve their own `__init__`.
+        # See bpo-45081.
+
+        class P(Protocol):
+            a: int
+
+        @dataclass
+        class C(P):
+            a: int
+
+        self.assertEqual(C(5).a, 5)
+
+        @dataclass
+        class D(P):
+            def __init__(self, a):
+                self.a = a * 2
+
+        self.assertEqual(D(5).a, 10)
+
+
+class TestRepr(unittest.TestCase):
+    def test_repr(self):
+        @dataclass
+        class B:
+            x: int
+
+        @dataclass
+        class C(B):
+            y: int = 10
+
+        o = C(4)
+        self.assertEqual(repr(o), 'TestRepr.test_repr.<locals>.C(x=4, y=10)')
+
+        @dataclass
+        class D(C):
+            x: int = 20
+        self.assertEqual(repr(D()), 'TestRepr.test_repr.<locals>.D(x=20, y=10)')
+
+        @dataclass
+        class C:
+            @dataclass
+            class D:
+                i: int
+            @dataclass
+            class E:
+                pass
+        self.assertEqual(repr(C.D(0)), 'TestRepr.test_repr.<locals>.C.D(i=0)')
+        self.assertEqual(repr(C.E()), 'TestRepr.test_repr.<locals>.C.E()')
+
+    def test_no_repr(self):
+        # Test a class with no __repr__ and repr=False.
+        @dataclass(repr=False)
+        class C:
+            x: int
+        self.assertIn(f'{__name__}.TestRepr.test_no_repr.<locals>.C object at',
+                      repr(C(3)))
+
+        # Test a class with a __repr__ and repr=False.
+        @dataclass(repr=False)
+        class C:
+            x: int
+            def __repr__(self):
+                return 'C-class'
+        self.assertEqual(repr(C(3)), 'C-class')
+
+    def test_overwriting_repr(self):
+        # If the class has __repr__, use it no matter the value of
+        #  repr=.
+
+        @dataclass
+        class C:
+            x: int
+            def __repr__(self):
+                return 'x'
+        self.assertEqual(repr(C(0)), 'x')
+
+        @dataclass(repr=True)
+        class C:
+            x: int
+            def __repr__(self):
+                return 'x'
+        self.assertEqual(repr(C(0)), 'x')
+
+        @dataclass(repr=False)
+        class C:
+            x: int
+            def __repr__(self):
+                return 'x'
+        self.assertEqual(repr(C(0)), 'x')
+
+
+class TestEq(unittest.TestCase):
+    def test_no_eq(self):
+        # Test a class with no __eq__ and eq=False.
+        @dataclass(eq=False)
+        class C:
+            x: int
+        self.assertNotEqual(C(0), C(0))
+        c = C(3)
+        self.assertEqual(c, c)
+
+        # Test a class with an __eq__ and eq=False.
+        @dataclass(eq=False)
+        class C:
+            x: int
+            def __eq__(self, other):
+                return other == 10
+        self.assertEqual(C(3), 10)
+
+    def test_overwriting_eq(self):
+        # If the class has __eq__, use it no matter the value of
+        #  eq=.
+
+        @dataclass
+        class C:
+            x: int
+            def __eq__(self, other):
+                return other == 3
+        self.assertEqual(C(1), 3)
+        self.assertNotEqual(C(1), 1)
+
+        @dataclass(eq=True)
+        class C:
+            x: int
+            def __eq__(self, other):
+                return other == 4
+        self.assertEqual(C(1), 4)
+        self.assertNotEqual(C(1), 1)
+
+        @dataclass(eq=False)
+        class C:
+            x: int
+            def __eq__(self, other):
+                return other == 5
+        self.assertEqual(C(1), 5)
+        self.assertNotEqual(C(1), 1)
+
+
+class TestOrdering(unittest.TestCase):
+    def test_functools_total_ordering(self):
+        # Test that functools.total_ordering works with this class.
+        @total_ordering
+        @dataclass
+        class C:
+            x: int
+            def __lt__(self, other):
+                # Perform the test "backward", just to make
+                #  sure this is being called.
+                return self.x >= other
+
+        self.assertLess(C(0), -1)
+        self.assertLessEqual(C(0), -1)
+        self.assertGreater(C(0), 1)
+        self.assertGreaterEqual(C(0), 1)
+
+    def test_no_order(self):
+        # Test that no ordering functions are added by default.
+        @dataclass(order=False)
+        class C:
+            x: int
+        # Make sure no order methods are added.
+        self.assertNotIn('__le__', C.__dict__)
+        self.assertNotIn('__lt__', C.__dict__)
+        self.assertNotIn('__ge__', C.__dict__)
+        self.assertNotIn('__gt__', C.__dict__)
+
+        # Test that __lt__ is still called
+        @dataclass(order=False)
+        class C:
+            x: int
+            def __lt__(self, other):
+                return False
+        # Make sure other methods aren't added.
+        self.assertNotIn('__le__', C.__dict__)
+        self.assertNotIn('__ge__', C.__dict__)
+        self.assertNotIn('__gt__', C.__dict__)
+
+    def test_overwriting_order(self):
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __lt__'
+                                    '.*using functools.total_ordering'):
+            @dataclass(order=True)
+            class C:
+                x: int
+                def __lt__(self):
+                    pass
+
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __le__'
+                                    '.*using functools.total_ordering'):
+            @dataclass(order=True)
+            class C:
+                x: int
+                def __le__(self):
+                    pass
+
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __gt__'
+                                    '.*using functools.total_ordering'):
+            @dataclass(order=True)
+            class C:
+                x: int
+                def __gt__(self):
+                    pass
+
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __ge__'
+                                    '.*using functools.total_ordering'):
+            @dataclass(order=True)
+            class C:
+                x: int
+                def __ge__(self):
+                    pass
+
+class TestHash(unittest.TestCase):
+    def test_unsafe_hash(self):
+        @dataclass(unsafe_hash=True)
+        class C:
+            x: int
+            y: str
+        self.assertEqual(hash(C(1, 'foo')), hash((1, 'foo')))
+
+    def test_hash_rules(self):
+        def non_bool(value):
+            # Map to something else that's True, but not a bool.
+            if value is None:
+                return None
+            if value:
+                return (3,)
+            return 0
+
+        def test(case, unsafe_hash, eq, frozen, with_hash, result):
+            with self.subTest(case=case, unsafe_hash=unsafe_hash, eq=eq,
+                              frozen=frozen):
+                if result != 'exception':
+                    if with_hash:
+                        @dataclass(unsafe_hash=unsafe_hash, eq=eq, frozen=frozen)
+                        class C:
+                            def __hash__(self):
+                                return 0
+                    else:
+                        @dataclass(unsafe_hash=unsafe_hash, eq=eq, frozen=frozen)
+                        class C:
+                            pass
+
+                # See if the result matches what's expected.
+                if result == 'fn':
+                    # __hash__ contains the function we generated.
+                    self.assertIn('__hash__', C.__dict__)
+                    self.assertIsNotNone(C.__dict__['__hash__'])
+
+                elif result == '':
+                    # __hash__ is not present in our class.
+                    if not with_hash:
+                        self.assertNotIn('__hash__', C.__dict__)
+
+                elif result == 'none':
+                    # __hash__ is set to None.
+                    self.assertIn('__hash__', C.__dict__)
+                    self.assertIsNone(C.__dict__['__hash__'])
+
+                elif result == 'exception':
+                    # Creating the class should cause an exception.
+                    #  This only happens with with_hash==True.
+                    assert(with_hash)
+                    with self.assertRaisesRegex(TypeError, 'Cannot overwrite attribute __hash__'):
+                        @dataclass(unsafe_hash=unsafe_hash, eq=eq, frozen=frozen)
+                        class C:
+                            def __hash__(self):
+                                return 0
+
+                else:
+                    assert False, f'unknown result {result!r}'
+
+        # There are 8 cases of:
+        #  unsafe_hash=True/False
+        #  eq=True/False
+        #  frozen=True/False
+        # And for each of these, a different result if
+        #  __hash__ is defined or not.
+        for case, (unsafe_hash,  eq,    frozen, res_no_defined_hash, res_defined_hash) in enumerate([
+                  (False,        False, False,  '',                  ''),
+                  (False,        False, True,   '',                  ''),
+                  (False,        True,  False,  'none',              ''),
+                  (False,        True,  True,   'fn',                ''),
+                  (True,         False, False,  'fn',                'exception'),
+                  (True,         False, True,   'fn',                'exception'),
+                  (True,         True,  False,  'fn',                'exception'),
+                  (True,         True,  True,   'fn',                'exception'),
+                  ], 1):
+            test(case, unsafe_hash, eq, frozen, False, res_no_defined_hash)
+            test(case, unsafe_hash, eq, frozen, True,  res_defined_hash)
+
+            # Test non-bool truth values, too.  This is just to
+            #  make sure the data-driven table in the decorator
+            #  handles non-bool values.
+            test(case, non_bool(unsafe_hash), non_bool(eq), non_bool(frozen), False, res_no_defined_hash)
+            test(case, non_bool(unsafe_hash), non_bool(eq), non_bool(frozen), True,  res_defined_hash)
+
+
+    def test_eq_only(self):
+        # If a class defines __eq__, __hash__ is automatically added
+        #  and set to None.  This is normal Python behavior, not
+        #  related to dataclasses.  Make sure we don't interfere with
+        #  that (see bpo=32546).
+
+        @dataclass
+        class C:
+            i: int
+            def __eq__(self, other):
+                return self.i == other.i
+        self.assertEqual(C(1), C(1))
+        self.assertNotEqual(C(1), C(4))
+
+        # And make sure things work in this case if we specify
+        #  unsafe_hash=True.
+        @dataclass(unsafe_hash=True)
+        class C:
+            i: int
+            def __eq__(self, other):
+                return self.i == other.i
+        self.assertEqual(C(1), C(1.0))
+        self.assertEqual(hash(C(1)), hash(C(1.0)))
+
+        # And check that the classes __eq__ is being used, despite
+        #  specifying eq=True.
+        @dataclass(unsafe_hash=True, eq=True)
+        class C:
+            i: int
+            def __eq__(self, other):
+                return self.i == 3 and self.i == other.i
+        self.assertEqual(C(3), C(3))
+        self.assertNotEqual(C(1), C(1))
+        self.assertEqual(hash(C(1)), hash(C(1.0)))
+
+    def test_0_field_hash(self):
+        @dataclass(frozen=True)
+        class C:
+            pass
+        self.assertEqual(hash(C()), hash(()))
+
+        @dataclass(unsafe_hash=True)
+        class C:
+            pass
+        self.assertEqual(hash(C()), hash(()))
+
+    def test_1_field_hash(self):
+        @dataclass(frozen=True)
+        class C:
+            x: int
+        self.assertEqual(hash(C(4)), hash((4,)))
+        self.assertEqual(hash(C(42)), hash((42,)))
+
+        @dataclass(unsafe_hash=True)
+        class C:
+            x: int
+        self.assertEqual(hash(C(4)), hash((4,)))
+        self.assertEqual(hash(C(42)), hash((42,)))
+
+    def test_hash_no_args(self):
+        # Test dataclasses with no hash= argument.  This exists to
+        #  make sure that if the @dataclass parameter name is changed
+        #  or the non-default hashing behavior changes, the default
+        #  hashability keeps working the same way.
+
+        class Base:
+            def __hash__(self):
+                return 301
+
+        # If frozen or eq is None, then use the default value (do not
+        #  specify any value in the decorator).
+        for frozen, eq,    base,   expected       in [
+            (None,  None,  object, 'unhashable'),
+            (None,  None,  Base,   'unhashable'),
+            (None,  False, object, 'object'),
+            (None,  False, Base,   'base'),
+            (None,  True,  object, 'unhashable'),
+            (None,  True,  Base,   'unhashable'),
+            (False, None,  object, 'unhashable'),
+            (False, None,  Base,   'unhashable'),
+            (False, False, object, 'object'),
+            (False, False, Base,   'base'),
+            (False, True,  object, 'unhashable'),
+            (False, True,  Base,   'unhashable'),
+            (True,  None,  object, 'tuple'),
+            (True,  None,  Base,   'tuple'),
+            (True,  False, object, 'object'),
+            (True,  False, Base,   'base'),
+            (True,  True,  object, 'tuple'),
+            (True,  True,  Base,   'tuple'),
+            ]:
+
+            with self.subTest(frozen=frozen, eq=eq, base=base, expected=expected):
+                # First, create the class.
+                if frozen is None and eq is None:
+                    @dataclass
+                    class C(base):
+                        i: int
+                elif frozen is None:
+                    @dataclass(eq=eq)
+                    class C(base):
+                        i: int
+                elif eq is None:
+                    @dataclass(frozen=frozen)
+                    class C(base):
+                        i: int
+                else:
+                    @dataclass(frozen=frozen, eq=eq)
+                    class C(base):
+                        i: int
+
+                # Now, make sure it hashes as expected.
+                if expected == 'unhashable':
+                    c = C(10)
+                    with self.assertRaisesRegex(TypeError, 'unhashable type'):
+                        hash(c)
+
+                elif expected == 'base':
+                    self.assertEqual(hash(C(10)), 301)
+
+                elif expected == 'object':
+                    # I'm not sure what test to use here.  object's
+                    #  hash isn't based on id(), so calling hash()
+                    #  won't tell us much.  So, just check the
+                    #  function used is object's.
+                    self.assertIs(C.__hash__, object.__hash__)
+
+                elif expected == 'tuple':
+                    self.assertEqual(hash(C(42)), hash((42,)))
+
+                else:
+                    assert False, f'unknown value for expected={expected!r}'
+
+
+class TestFrozen(unittest.TestCase):
+    def test_frozen(self):
+        @dataclass(frozen=True)
+        class C:
+            i: int
+
+        c = C(10)
+        self.assertEqual(c.i, 10)
+        with self.assertRaises(FrozenInstanceError):
+            c.i = 5
+        self.assertEqual(c.i, 10)
+
+    def test_frozen_empty(self):
+        @dataclass(frozen=True)
+        class C:
+            pass
+
+        c = C()
+        self.assertFalse(hasattr(c, 'i'))
+        with self.assertRaises(FrozenInstanceError):
+            c.i = 5
+        self.assertFalse(hasattr(c, 'i'))
+        with self.assertRaises(FrozenInstanceError):
+            del c.i
+
+    def test_inherit(self):
+        @dataclass(frozen=True)
+        class C:
+            i: int
+
+        @dataclass(frozen=True)
+        class D(C):
+            j: int
+
+        d = D(0, 10)
+        with self.assertRaises(FrozenInstanceError):
+            d.i = 5
+        with self.assertRaises(FrozenInstanceError):
+            d.j = 6
+        self.assertEqual(d.i, 0)
+        self.assertEqual(d.j, 10)
+
+    def test_inherit_nonfrozen_from_empty_frozen(self):
+        @dataclass(frozen=True)
+        class C:
+            pass
+
+        with self.assertRaisesRegex(TypeError,
+                                    'cannot inherit non-frozen dataclass from a frozen one'):
+            @dataclass
+            class D(C):
+                j: int
+
+    def test_inherit_nonfrozen_from_empty(self):
+        @dataclass
+        class C:
+            pass
+
+        @dataclass
+        class D(C):
+            j: int
+
+        d = D(3)
+        self.assertEqual(d.j, 3)
+        self.assertIsInstance(d, C)
+
+    # Test both ways: with an intermediate normal (non-dataclass)
+    #  class and without an intermediate class.
+    def test_inherit_nonfrozen_from_frozen(self):
+        for intermediate_class in [True, False]:
+            with self.subTest(intermediate_class=intermediate_class):
+                @dataclass(frozen=True)
+                class C:
+                    i: int
+
+                if intermediate_class:
+                    class I(C): pass
+                else:
+                    I = C
+
+                with self.assertRaisesRegex(TypeError,
+                                            'cannot inherit non-frozen dataclass from a frozen one'):
+                    @dataclass
+                    class D(I):
+                        pass
+
+    def test_inherit_frozen_from_nonfrozen(self):
+        for intermediate_class in [True, False]:
+            with self.subTest(intermediate_class=intermediate_class):
+                @dataclass
+                class C:
+                    i: int
+
+                if intermediate_class:
+                    class I(C): pass
+                else:
+                    I = C
+
+                with self.assertRaisesRegex(TypeError,
+                                            'cannot inherit frozen dataclass from a non-frozen one'):
+                    @dataclass(frozen=True)
+                    class D(I):
+                        pass
+
+    def test_inherit_from_normal_class(self):
+        for intermediate_class in [True, False]:
+            with self.subTest(intermediate_class=intermediate_class):
+                class C:
+                    pass
+
+                if intermediate_class:
+                    class I(C): pass
+                else:
+                    I = C
+
+                @dataclass(frozen=True)
+                class D(I):
+                    i: int
+
+            d = D(10)
+            with self.assertRaises(FrozenInstanceError):
+                d.i = 5
+
+    def test_non_frozen_normal_derived(self):
+        # See bpo-32953.
+
+        @dataclass(frozen=True)
+        class D:
+            x: int
+            y: int = 10
+
+        class S(D):
+            pass
+
+        s = S(3)
+        self.assertEqual(s.x, 3)
+        self.assertEqual(s.y, 10)
+        s.cached = True
+
+        # But can't change the frozen attributes.
+        with self.assertRaises(FrozenInstanceError):
+            s.x = 5
+        with self.assertRaises(FrozenInstanceError):
+            s.y = 5
+        self.assertEqual(s.x, 3)
+        self.assertEqual(s.y, 10)
+        self.assertEqual(s.cached, True)
+
+        with self.assertRaises(FrozenInstanceError):
+            del s.x
+        self.assertEqual(s.x, 3)
+        with self.assertRaises(FrozenInstanceError):
+            del s.y
+        self.assertEqual(s.y, 10)
+        del s.cached
+        self.assertFalse(hasattr(s, 'cached'))
+        with self.assertRaises(AttributeError) as cm:
+            del s.cached
+        self.assertNotIsInstance(cm.exception, FrozenInstanceError)
+
+    def test_non_frozen_normal_derived_from_empty_frozen(self):
+        @dataclass(frozen=True)
+        class D:
+            pass
+
+        class S(D):
+            pass
+
+        s = S()
+        self.assertFalse(hasattr(s, 'x'))
+        s.x = 5
+        self.assertEqual(s.x, 5)
+
+        del s.x
+        self.assertFalse(hasattr(s, 'x'))
+        with self.assertRaises(AttributeError) as cm:
+            del s.x
+        self.assertNotIsInstance(cm.exception, FrozenInstanceError)
+
+    def test_overwriting_frozen(self):
+        # frozen uses __setattr__ and __delattr__.
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __setattr__'):
+            @dataclass(frozen=True)
+            class C:
+                x: int
+                def __setattr__(self):
+                    pass
+
+        with self.assertRaisesRegex(TypeError,
+                                    'Cannot overwrite attribute __delattr__'):
+            @dataclass(frozen=True)
+            class C:
+                x: int
+                def __delattr__(self):
+                    pass
+
+        @dataclass(frozen=False)
+        class C:
+            x: int
+            def __setattr__(self, name, value):
+                self.__dict__['x'] = value * 2
+        self.assertEqual(C(10).x, 20)
+
+    def test_frozen_hash(self):
+        @dataclass(frozen=True)
+        class C:
+            x: Any
+
+        # If x is immutable, we can compute the hash.  No exception is
+        # raised.
+        hash(C(3))
+
+        # If x is mutable, computing the hash is an error.
+        with self.assertRaisesRegex(TypeError, 'unhashable type'):
+            hash(C({}))
+
+
+class TestSlots(unittest.TestCase):
+    def test_simple(self):
+        @dataclass
+        class C:
+            __slots__ = ('x',)
+            x: Any
+
+        # There was a bug where a variable in a slot was assumed to
+        #  also have a default value (of type
+        #  types.MemberDescriptorType).
+        with self.assertRaisesRegex(TypeError,
+                                    r"__init__\(\) missing 1 required positional argument: 'x'"):
+            C()
+
+        # We can create an instance, and assign to x.
+        c = C(10)
+        self.assertEqual(c.x, 10)
+        c.x = 5
+        self.assertEqual(c.x, 5)
+
+        # We can't assign to anything else.
+        with self.assertRaisesRegex(AttributeError, "'C' object has no attribute 'y'"):
+            c.y = 5
+
+    def test_derived_added_field(self):
+        # See bpo-33100.
+        @dataclass
+        class Base:
+            __slots__ = ('x',)
+            x: Any
+
+        @dataclass
+        class Derived(Base):
+            x: int
+            y: int
+
+        d = Derived(1, 2)
+        self.assertEqual((d.x, d.y), (1, 2))
+
+        # We can add a new field to the derived instance.
+        d.z = 10
+
+    def test_generated_slots(self):
+        @dataclass(slots=True)
+        class C:
+            x: int
+            y: int
+
+        c = C(1, 2)
+        self.assertEqual((c.x, c.y), (1, 2))
+
+        c.x = 3
+        c.y = 4
+        self.assertEqual((c.x, c.y), (3, 4))
+
+        with self.assertRaisesRegex(AttributeError, "'C' object has no attribute 'z'"):
+            c.z = 5
+
+    def test_add_slots_when_slots_exists(self):
+        with self.assertRaisesRegex(TypeError, '^C already specifies __slots__$'):
+            @dataclass(slots=True)
+            class C:
+                __slots__ = ('x',)
+                x: int
+
+    def test_generated_slots_value(self):
+
+        class Root:
+            __slots__ = {'x'}
+
+        class Root2(Root):
+            __slots__ = {'k': '...', 'j': ''}
+
+        class Root3(Root2):
+            __slots__ = ['h']
+
+        class Root4(Root3):
+            __slots__ = 'aa'
+
+        @dataclass(slots=True)
+        class Base(Root4):
+            y: int
+            j: str
+            h: str
+
+        self.assertEqual(Base.__slots__, ('y', ))
+
+        @dataclass(slots=True)
+        class Derived(Base):
+            aa: float
+            x: str
+            z: int
+            k: str
+            h: str
+
+        self.assertEqual(Derived.__slots__, ('z', ))
+
+        @dataclass
+        class AnotherDerived(Base):
+            z: int
+
+        self.assertNotIn('__slots__', AnotherDerived.__dict__)
+
+    def test_cant_inherit_from_iterator_slots(self):
+
+        class Root:
+            __slots__ = iter(['a'])
+
+        class Root2(Root):
+            __slots__ = ('b', )
+
+        with self.assertRaisesRegex(
+           TypeError,
+            "^Slots of 'Root' cannot be determined"
+        ):
+            @dataclass(slots=True)
+            class C(Root2):
+                x: int
+
+    def test_returns_new_class(self):
+        class A:
+            x: int
+
+        B = dataclass(A, slots=True)
+        self.assertIsNot(A, B)
+
+        self.assertFalse(hasattr(A, "__slots__"))
+        self.assertTrue(hasattr(B, "__slots__"))
+
+    # Can't be local to test_frozen_pickle.
+    @dataclass(frozen=True, slots=True)
+    class FrozenSlotsClass:
+        foo: str
+        bar: int
+
+    @dataclass(frozen=True)
+    class FrozenWithoutSlotsClass:
+        foo: str
+        bar: int
+
+    def test_frozen_pickle(self):
+        # bpo-43999
+
+        self.assertEqual(self.FrozenSlotsClass.__slots__, ("foo", "bar"))
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(proto=proto):
+                obj = self.FrozenSlotsClass("a", 1)
+                p = pickle.loads(pickle.dumps(obj, protocol=proto))
+                self.assertIsNot(obj, p)
+                self.assertEqual(obj, p)
+
+                obj = self.FrozenWithoutSlotsClass("a", 1)
+                p = pickle.loads(pickle.dumps(obj, protocol=proto))
+                self.assertIsNot(obj, p)
+                self.assertEqual(obj, p)
+
+    @dataclass(frozen=True, slots=True)
+    class FrozenSlotsGetStateClass:
+        foo: str
+        bar: int
+
+        getstate_called: bool = field(default=False, compare=False)
+
+        def __getstate__(self):
+            object.__setattr__(self, 'getstate_called', True)
+            return [self.foo, self.bar]
+
+    @dataclass(frozen=True, slots=True)
+    class FrozenSlotsSetStateClass:
+        foo: str
+        bar: int
+
+        setstate_called: bool = field(default=False, compare=False)
+
+        def __setstate__(self, state):
+            object.__setattr__(self, 'setstate_called', True)
+            object.__setattr__(self, 'foo', state[0])
+            object.__setattr__(self, 'bar', state[1])
+
+    @dataclass(frozen=True, slots=True)
+    class FrozenSlotsAllStateClass:
+        foo: str
+        bar: int
+
+        getstate_called: bool = field(default=False, compare=False)
+        setstate_called: bool = field(default=False, compare=False)
+
+        def __getstate__(self):
+            object.__setattr__(self, 'getstate_called', True)
+            return [self.foo, self.bar]
+
+        def __setstate__(self, state):
+            object.__setattr__(self, 'setstate_called', True)
+            object.__setattr__(self, 'foo', state[0])
+            object.__setattr__(self, 'bar', state[1])
+
+    def test_frozen_slots_pickle_custom_state(self):
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(proto=proto):
+                obj = self.FrozenSlotsGetStateClass('a', 1)
+                dumped = pickle.dumps(obj, protocol=proto)
+
+                self.assertTrue(obj.getstate_called)
+                self.assertEqual(obj, pickle.loads(dumped))
+
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(proto=proto):
+                obj = self.FrozenSlotsSetStateClass('a', 1)
+                obj2 = pickle.loads(pickle.dumps(obj, protocol=proto))
+
+                self.assertTrue(obj2.setstate_called)
+                self.assertEqual(obj, obj2)
+
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(proto=proto):
+                obj = self.FrozenSlotsAllStateClass('a', 1)
+                dumped = pickle.dumps(obj, protocol=proto)
+
+                self.assertTrue(obj.getstate_called)
+
+                obj2 = pickle.loads(dumped)
+                self.assertTrue(obj2.setstate_called)
+                self.assertEqual(obj, obj2)
+
+    def test_slots_with_default_no_init(self):
+        # Originally reported in bpo-44649.
+        @dataclass(slots=True)
+        class A:
+            a: str
+            b: str = field(default='b', init=False)
+
+        obj = A("a")
+        self.assertEqual(obj.a, 'a')
+        self.assertEqual(obj.b, 'b')
+
+    def test_slots_with_default_factory_no_init(self):
+        # Originally reported in bpo-44649.
+        @dataclass(slots=True)
+        class A:
+            a: str
+            b: str = field(default_factory=lambda:'b', init=False)
+
+        obj = A("a")
+        self.assertEqual(obj.a, 'a')
+        self.assertEqual(obj.b, 'b')
+
+    def test_slots_no_weakref(self):
+        @dataclass(slots=True)
+        class A:
+            # No weakref.
+            pass
+
+        self.assertNotIn("__weakref__", A.__slots__)
+        a = A()
+        with self.assertRaisesRegex(TypeError,
+                                    "cannot create weak reference"):
+            weakref.ref(a)
+        with self.assertRaises(AttributeError):
+            a.__weakref__
+
+    def test_slots_weakref(self):
+        @dataclass(slots=True, weakref_slot=True)
+        class A:
+            a: int
+
+        self.assertIn("__weakref__", A.__slots__)
+        a = A(1)
+        a_ref = weakref.ref(a)
+
+        self.assertIs(a.__weakref__, a_ref)
+
+    def test_slots_weakref_base_str(self):
+        class Base:
+            __slots__ = '__weakref__'
+
+        @dataclass(slots=True)
+        class A(Base):
+            a: int
+
+        # __weakref__ is in the base class, not A.  But an A is still weakref-able.
+        self.assertIn("__weakref__", Base.__slots__)
+        self.assertNotIn("__weakref__", A.__slots__)
+        a = A(1)
+        weakref.ref(a)
+
+    def test_slots_weakref_base_tuple(self):
+        # Same as test_slots_weakref_base, but use a tuple instead of a string
+        # in the base class.
+        class Base:
+            __slots__ = ('__weakref__',)
+
+        @dataclass(slots=True)
+        class A(Base):
+            a: int
+
+        # __weakref__ is in the base class, not A.  But an A is still
+        # weakref-able.
+        self.assertIn("__weakref__", Base.__slots__)
+        self.assertNotIn("__weakref__", A.__slots__)
+        a = A(1)
+        weakref.ref(a)
+
+    def test_weakref_slot_without_slot(self):
+        with self.assertRaisesRegex(TypeError,
+                                    "weakref_slot is True but slots is False"):
+            @dataclass(weakref_slot=True)
+            class A:
+                a: int
+
+    def test_weakref_slot_make_dataclass(self):
+        A = make_dataclass('A', [('a', int),], slots=True, weakref_slot=True)
+        self.assertIn("__weakref__", A.__slots__)
+        a = A(1)
+        weakref.ref(a)
+
+        # And make sure if raises if slots=True is not given.
+        with self.assertRaisesRegex(TypeError,
+                                    "weakref_slot is True but slots is False"):
+            B = make_dataclass('B', [('a', int),], weakref_slot=True)
+
+    def test_weakref_slot_subclass_weakref_slot(self):
+        @dataclass(slots=True, weakref_slot=True)
+        class Base:
+            field: int
+
+        # A *can* also specify weakref_slot=True if it wants to (gh-93521)
+        @dataclass(slots=True, weakref_slot=True)
+        class A(Base):
+            ...
+
+        # __weakref__ is in the base class, not A.  But an instance of A
+        # is still weakref-able.
+        self.assertIn("__weakref__", Base.__slots__)
+        self.assertNotIn("__weakref__", A.__slots__)
+        a = A(1)
+        a_ref = weakref.ref(a)
+        self.assertIs(a.__weakref__, a_ref)
+
+    def test_weakref_slot_subclass_no_weakref_slot(self):
+        @dataclass(slots=True, weakref_slot=True)
+        class Base:
+            field: int
+
+        @dataclass(slots=True)
+        class A(Base):
+            ...
+
+        # __weakref__ is in the base class, not A.  Even though A doesn't
+        # specify weakref_slot, it should still be weakref-able.
+        self.assertIn("__weakref__", Base.__slots__)
+        self.assertNotIn("__weakref__", A.__slots__)
+        a = A(1)
+        a_ref = weakref.ref(a)
+        self.assertIs(a.__weakref__, a_ref)
+
+    def test_weakref_slot_normal_base_weakref_slot(self):
+        class Base:
+            __slots__ = ('__weakref__',)
+
+        @dataclass(slots=True, weakref_slot=True)
+        class A(Base):
+            field: int
+
+        # __weakref__ is in the base class, not A.  But an instance of
+        # A is still weakref-able.
+        self.assertIn("__weakref__", Base.__slots__)
+        self.assertNotIn("__weakref__", A.__slots__)
+        a = A(1)
+        a_ref = weakref.ref(a)
+        self.assertIs(a.__weakref__, a_ref)
+
+
+class TestDescriptors(unittest.TestCase):
+    def test_set_name(self):
+        # See bpo-33141.
+
+        # Create a descriptor.
+        class D:
+            def __set_name__(self, owner, name):
+                self.name = name + 'x'
+            def __get__(self, instance, owner):
+                if instance is not None:
+                    return 1
+                return self
+
+        # This is the case of just normal descriptor behavior, no
+        #  dataclass code is involved in initializing the descriptor.
+        @dataclass
+        class C:
+            c: int=D()
+        self.assertEqual(C.c.name, 'cx')
+
+        # Now test with a default value and init=False, which is the
+        #  only time this is really meaningful.  If not using
+        #  init=False, then the descriptor will be overwritten, anyway.
+        @dataclass
+        class C:
+            c: int=field(default=D(), init=False)
+        self.assertEqual(C.c.name, 'cx')
+        self.assertEqual(C().c, 1)
+
+    def test_non_descriptor(self):
+        # PEP 487 says __set_name__ should work on non-descriptors.
+        # Create a descriptor.
+
+        class D:
+            def __set_name__(self, owner, name):
+                self.name = name + 'x'
+
+        @dataclass
+        class C:
+            c: int=field(default=D(), init=False)
+        self.assertEqual(C.c.name, 'cx')
+
+    def test_lookup_on_instance(self):
+        # See bpo-33175.
+        class D:
+            pass
+
+        d = D()
+        # Create an attribute on the instance, not type.
+        d.__set_name__ = Mock()
+
+        # Make sure d.__set_name__ is not called.
+        @dataclass
+        class C:
+            i: int=field(default=d, init=False)
+
+        self.assertEqual(d.__set_name__.call_count, 0)
+
+    def test_lookup_on_class(self):
+        # See bpo-33175.
+        class D:
+            pass
+        D.__set_name__ = Mock()
+
+        # Make sure D.__set_name__ is called.
+        @dataclass
+        class C:
+            i: int=field(default=D(), init=False)
+
+        self.assertEqual(D.__set_name__.call_count, 1)
+
+    def test_init_calls_set(self):
+        class D:
+            pass
+
+        D.__set__ = Mock()
+
+        @dataclass
+        class C:
+            i: D = D()
+
+        # Make sure D.__set__ is called.
+        D.__set__.reset_mock()
+        c = C(5)
+        self.assertEqual(D.__set__.call_count, 1)
+
+    def test_getting_field_calls_get(self):
+        class D:
+            pass
+
+        D.__set__ = Mock()
+        D.__get__ = Mock()
+
+        @dataclass
+        class C:
+            i: D = D()
+
+        c = C(5)
+
+        # Make sure D.__get__ is called.
+        D.__get__.reset_mock()
+        value = c.i
+        self.assertEqual(D.__get__.call_count, 1)
+
+    def test_setting_field_calls_set(self):
+        class D:
+            pass
+
+        D.__set__ = Mock()
+
+        @dataclass
+        class C:
+            i: D = D()
+
+        c = C(5)
+
+        # Make sure D.__set__ is called.
+        D.__set__.reset_mock()
+        c.i = 10
+        self.assertEqual(D.__set__.call_count, 1)
+
+    def test_setting_uninitialized_descriptor_field(self):
+        class D:
+            pass
+
+        D.__set__ = Mock()
+
+        @dataclass
+        class C:
+            i: D
+
+        # D.__set__ is not called because there's no D instance to call it on
+        D.__set__.reset_mock()
+        c = C(5)
+        self.assertEqual(D.__set__.call_count, 0)
+
+        # D.__set__ still isn't called after setting i to an instance of D
+        # because descriptors don't behave like that when stored as instance vars
+        c.i = D()
+        c.i = 5
+        self.assertEqual(D.__set__.call_count, 0)
+
+    def test_default_value(self):
+        class D:
+            def __get__(self, instance: Any, owner: object) -> int:
+                if instance is None:
+                    return 100
+
+                return instance._x
+
+            def __set__(self, instance: Any, value: int) -> None:
+                instance._x = value
+
+        @dataclass
+        class C:
+            i: D = D()
+
+        c = C()
+        self.assertEqual(c.i, 100)
+
+        c = C(5)
+        self.assertEqual(c.i, 5)
+
+    def test_no_default_value(self):
+        class D:
+            def __get__(self, instance: Any, owner: object) -> int:
+                if instance is None:
+                    raise AttributeError()
+
+                return instance._x
+
+            def __set__(self, instance: Any, value: int) -> None:
+                instance._x = value
+
+        @dataclass
+        class C:
+            i: D = D()
+
+        with self.assertRaisesRegex(TypeError, 'missing 1 required positional argument'):
+            c = C()
+
+class TestStringAnnotations(unittest.TestCase):
+    def test_classvar(self):
+        # Some expressions recognized as ClassVar really aren't.  But
+        #  if you're using string annotations, it's not an exact
+        #  science.
+        # These tests assume that both "import typing" and "from
+        # typing import *" have been run in this file.
+        for typestr in ('ClassVar[int]',
+                        'ClassVar [int]',
+                        ' ClassVar [int]',
+                        'ClassVar',
+                        ' ClassVar ',
+                        'typing.ClassVar[int]',
+                        'typing.ClassVar[str]',
+                        ' typing.ClassVar[str]',
+                        'typing .ClassVar[str]',
+                        'typing. ClassVar[str]',
+                        'typing.ClassVar [str]',
+                        'typing.ClassVar [ str]',
+
+                        # Not syntactically valid, but these will
+                        #  be treated as ClassVars.
+                        'typing.ClassVar.[int]',
+                        'typing.ClassVar+',
+                        ):
+            with self.subTest(typestr=typestr):
+                @dataclass
+                class C:
+                    x: typestr
+
+                # x is a ClassVar, so C() takes no args.
+                C()
+
+                # And it won't appear in the class's dict because it doesn't
+                # have a default.
+                self.assertNotIn('x', C.__dict__)
+
+    def test_isnt_classvar(self):
+        for typestr in ('CV',
+                        't.ClassVar',
+                        't.ClassVar[int]',
+                        'typing..ClassVar[int]',
+                        'Classvar',
+                        'Classvar[int]',
+                        'typing.ClassVarx[int]',
+                        'typong.ClassVar[int]',
+                        'dataclasses.ClassVar[int]',
+                        'typingxClassVar[str]',
+                        ):
+            with self.subTest(typestr=typestr):
+                @dataclass
+                class C:
+                    x: typestr
+
+                # x is not a ClassVar, so C() takes one arg.
+                self.assertEqual(C(10).x, 10)
+
+    def test_initvar(self):
+        # These tests assume that both "import dataclasses" and "from
+        #  dataclasses import *" have been run in this file.
+        for typestr in ('InitVar[int]',
+                        'InitVar [int]'
+                        ' InitVar [int]',
+                        'InitVar',
+                        ' InitVar ',
+                        'dataclasses.InitVar[int]',
+                        'dataclasses.InitVar[str]',
+                        ' dataclasses.InitVar[str]',
+                        'dataclasses .InitVar[str]',
+                        'dataclasses. InitVar[str]',
+                        'dataclasses.InitVar [str]',
+                        'dataclasses.InitVar [ str]',
+
+                        # Not syntactically valid, but these will
+                        #  be treated as InitVars.
+                        'dataclasses.InitVar.[int]',
+                        'dataclasses.InitVar+',
+                        ):
+            with self.subTest(typestr=typestr):
+                @dataclass
+                class C:
+                    x: typestr
+
+                # x is an InitVar, so doesn't create a member.
+                with self.assertRaisesRegex(AttributeError,
+                                            "object has no attribute 'x'"):
+                    C(1).x
+
+    def test_isnt_initvar(self):
+        for typestr in ('IV',
+                        'dc.InitVar',
+                        'xdataclasses.xInitVar',
+                        'typing.xInitVar[int]',
+                        ):
+            with self.subTest(typestr=typestr):
+                @dataclass
+                class C:
+                    x: typestr
+
+                # x is not an InitVar, so there will be a member x.
+                self.assertEqual(C(10).x, 10)
+
+    def test_classvar_module_level_import(self):
+        from test.test_dataclasses import dataclass_module_1
+        from test.test_dataclasses import dataclass_module_1_str
+        from test.test_dataclasses import dataclass_module_2
+        from test.test_dataclasses import dataclass_module_2_str
+
+        for m in (dataclass_module_1, dataclass_module_1_str,
+                  dataclass_module_2, dataclass_module_2_str,
+                  ):
+            with self.subTest(m=m):
+                # There's a difference in how the ClassVars are
+                # interpreted when using string annotations or
+                # not. See the imported modules for details.
+                if m.USING_STRINGS:
+                    c = m.CV(10)
+                else:
+                    c = m.CV()
+                self.assertEqual(c.cv0, 20)
+
+
+                # There's a difference in how the InitVars are
+                # interpreted when using string annotations or
+                # not. See the imported modules for details.
+                c = m.IV(0, 1, 2, 3, 4)
+
+                for field_name in ('iv0', 'iv1', 'iv2', 'iv3'):
+                    with self.subTest(field_name=field_name):
+                        with self.assertRaisesRegex(AttributeError, f"object has no attribute '{field_name}'"):
+                            # Since field_name is an InitVar, it's
+                            # not an instance field.
+                            getattr(c, field_name)
+
+                if m.USING_STRINGS:
+                    # iv4 is interpreted as a normal field.
+                    self.assertIn('not_iv4', c.__dict__)
+                    self.assertEqual(c.not_iv4, 4)
+                else:
+                    # iv4 is interpreted as an InitVar, so it
+                    # won't exist on the instance.
+                    self.assertNotIn('not_iv4', c.__dict__)
+
+    def test_text_annotations(self):
+        from test.test_dataclasses import dataclass_textanno
+
+        self.assertEqual(
+            get_type_hints(dataclass_textanno.Bar),
+            {'foo': dataclass_textanno.Foo})
+        self.assertEqual(
+            get_type_hints(dataclass_textanno.Bar.__init__),
+            {'foo': dataclass_textanno.Foo,
+             'return': type(None)})
+
+
+ByMakeDataClass = make_dataclass('ByMakeDataClass', [('x', int)])
+ManualModuleMakeDataClass = make_dataclass('ManualModuleMakeDataClass',
+                                           [('x', int)],
+                                           module=__name__)
+WrongNameMakeDataclass = make_dataclass('Wrong', [('x', int)])
+WrongModuleMakeDataclass = make_dataclass('WrongModuleMakeDataclass',
+                                          [('x', int)],
+                                          module='custom')
+
+class TestMakeDataclass(unittest.TestCase):
+    def test_simple(self):
+        C = make_dataclass('C',
+                           [('x', int),
+                            ('y', int, field(default=5))],
+                           namespace={'add_one': lambda self: self.x + 1})
+        c = C(10)
+        self.assertEqual((c.x, c.y), (10, 5))
+        self.assertEqual(c.add_one(), 11)
+
+
+    def test_no_mutate_namespace(self):
+        # Make sure a provided namespace isn't mutated.
+        ns = {}
+        C = make_dataclass('C',
+                           [('x', int),
+                            ('y', int, field(default=5))],
+                           namespace=ns)
+        self.assertEqual(ns, {})
+
+    def test_base(self):
+        class Base1:
+            pass
+        class Base2:
+            pass
+        C = make_dataclass('C',
+                           [('x', int)],
+                           bases=(Base1, Base2))
+        c = C(2)
+        self.assertIsInstance(c, C)
+        self.assertIsInstance(c, Base1)
+        self.assertIsInstance(c, Base2)
+
+    def test_base_dataclass(self):
+        @dataclass
+        class Base1:
+            x: int
+        class Base2:
+            pass
+        C = make_dataclass('C',
+                           [('y', int)],
+                           bases=(Base1, Base2))
+        with self.assertRaisesRegex(TypeError, 'required positional'):
+            c = C(2)
+        c = C(1, 2)
+        self.assertIsInstance(c, C)
+        self.assertIsInstance(c, Base1)
+        self.assertIsInstance(c, Base2)
+
+        self.assertEqual((c.x, c.y), (1, 2))
+
+    def test_init_var(self):
+        def post_init(self, y):
+            self.x *= y
+
+        C = make_dataclass('C',
+                           [('x', int),
+                            ('y', InitVar[int]),
+                            ],
+                           namespace={'__post_init__': post_init},
+                           )
+        c = C(2, 3)
+        self.assertEqual(vars(c), {'x': 6})
+        self.assertEqual(len(fields(c)), 1)
+
+    def test_class_var(self):
+        C = make_dataclass('C',
+                           [('x', int),
+                            ('y', ClassVar[int], 10),
+                            ('z', ClassVar[int], field(default=20)),
+                            ])
+        c = C(1)
+        self.assertEqual(vars(c), {'x': 1})
+        self.assertEqual(len(fields(c)), 1)
+        self.assertEqual(C.y, 10)
+        self.assertEqual(C.z, 20)
+
+    def test_other_params(self):
+        C = make_dataclass('C',
+                           [('x', int),
+                            ('y', ClassVar[int], 10),
+                            ('z', ClassVar[int], field(default=20)),
+                            ],
+                           init=False)
+        # Make sure we have a repr, but no init.
+        self.assertNotIn('__init__', vars(C))
+        self.assertIn('__repr__', vars(C))
+
+        # Make sure random other params don't work.
+        with self.assertRaisesRegex(TypeError, 'unexpected keyword argument'):
+            C = make_dataclass('C',
+                               [],
+                               xxinit=False)
+
+    def test_no_types(self):
+        C = make_dataclass('Point', ['x', 'y', 'z'])
+        c = C(1, 2, 3)
+        self.assertEqual(vars(c), {'x': 1, 'y': 2, 'z': 3})
+        self.assertEqual(C.__annotations__, {'x': 'typing.Any',
+                                             'y': 'typing.Any',
+                                             'z': 'typing.Any'})
+
+        C = make_dataclass('Point', ['x', ('y', int), 'z'])
+        c = C(1, 2, 3)
+        self.assertEqual(vars(c), {'x': 1, 'y': 2, 'z': 3})
+        self.assertEqual(C.__annotations__, {'x': 'typing.Any',
+                                             'y': int,
+                                             'z': 'typing.Any'})
+
+    def test_module_attr(self):
+        self.assertEqual(ByMakeDataClass.__module__, __name__)
+        self.assertEqual(ByMakeDataClass(1).__module__, __name__)
+        self.assertEqual(WrongModuleMakeDataclass.__module__, "custom")
+        Nested = make_dataclass('Nested', [])
+        self.assertEqual(Nested.__module__, __name__)
+        self.assertEqual(Nested().__module__, __name__)
+
+    def test_pickle_support(self):
+        for klass in [ByMakeDataClass, ManualModuleMakeDataClass]:
+            for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+                with self.subTest(proto=proto):
+                    self.assertEqual(
+                        pickle.loads(pickle.dumps(klass, proto)),
+                        klass,
+                    )
+                    self.assertEqual(
+                        pickle.loads(pickle.dumps(klass(1), proto)),
+                        klass(1),
+                    )
+
+    def test_cannot_be_pickled(self):
+        for klass in [WrongNameMakeDataclass, WrongModuleMakeDataclass]:
+            for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+                with self.subTest(proto=proto):
+                    with self.assertRaises(pickle.PickleError):
+                        pickle.dumps(klass, proto)
+                    with self.assertRaises(pickle.PickleError):
+                        pickle.dumps(klass(1), proto)
+
+    def test_invalid_type_specification(self):
+        for bad_field in [(),
+                          (1, 2, 3, 4),
+                          ]:
+            with self.subTest(bad_field=bad_field):
+                with self.assertRaisesRegex(TypeError, r'Invalid field: '):
+                    make_dataclass('C', ['a', bad_field])
+
+        # And test for things with no len().
+        for bad_field in [float,
+                          lambda x:x,
+                          ]:
+            with self.subTest(bad_field=bad_field):
+                with self.assertRaisesRegex(TypeError, r'has no len\(\)'):
+                    make_dataclass('C', ['a', bad_field])
+
+    def test_duplicate_field_names(self):
+        for field in ['a', 'ab']:
+            with self.subTest(field=field):
+                with self.assertRaisesRegex(TypeError, 'Field name duplicated'):
+                    make_dataclass('C', [field, 'a', field])
+
+    def test_keyword_field_names(self):
+        for field in ['for', 'async', 'await', 'as']:
+            with self.subTest(field=field):
+                with self.assertRaisesRegex(TypeError, 'must not be keywords'):
+                    make_dataclass('C', ['a', field])
+                with self.assertRaisesRegex(TypeError, 'must not be keywords'):
+                    make_dataclass('C', [field])
+                with self.assertRaisesRegex(TypeError, 'must not be keywords'):
+                    make_dataclass('C', [field, 'a'])
+
+    def test_non_identifier_field_names(self):
+        for field in ['()', 'x,y', '*', '2@3', '', 'little johnny tables']:
+            with self.subTest(field=field):
+                with self.assertRaisesRegex(TypeError, 'must be valid identifiers'):
+                    make_dataclass('C', ['a', field])
+                with self.assertRaisesRegex(TypeError, 'must be valid identifiers'):
+                    make_dataclass('C', [field])
+                with self.assertRaisesRegex(TypeError, 'must be valid identifiers'):
+                    make_dataclass('C', [field, 'a'])
+
+    def test_underscore_field_names(self):
+        # Unlike namedtuple, it's okay if dataclass field names have
+        # an underscore.
+        make_dataclass('C', ['_', '_a', 'a_a', 'a_'])
+
+    def test_funny_class_names_names(self):
+        # No reason to prevent weird class names, since
+        # types.new_class allows them.
+        for classname in ['()', 'x,y', '*', '2@3', '']:
+            with self.subTest(classname=classname):
+                C = make_dataclass(classname, ['a', 'b'])
+                self.assertEqual(C.__name__, classname)
+
+class TestReplace(unittest.TestCase):
+    def test(self):
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            y: int
+
+        c = C(1, 2)
+        c1 = replace(c, x=3)
+        self.assertEqual(c1.x, 3)
+        self.assertEqual(c1.y, 2)
+
+    def test_frozen(self):
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            y: int
+            z: int = field(init=False, default=10)
+            t: int = field(init=False, default=100)
+
+        c = C(1, 2)
+        c1 = replace(c, x=3)
+        self.assertEqual((c.x, c.y, c.z, c.t), (1, 2, 10, 100))
+        self.assertEqual((c1.x, c1.y, c1.z, c1.t), (3, 2, 10, 100))
+
+
+        with self.assertRaisesRegex(ValueError, 'init=False'):
+            replace(c, x=3, z=20, t=50)
+        with self.assertRaisesRegex(ValueError, 'init=False'):
+            replace(c, z=20)
+            replace(c, x=3, z=20, t=50)
+
+        # Make sure the result is still frozen.
+        with self.assertRaisesRegex(FrozenInstanceError, "cannot assign to field 'x'"):
+            c1.x = 3
+
+        # Make sure we can't replace an attribute that doesn't exist,
+        #  if we're also replacing one that does exist.  Test this
+        #  here, because setting attributes on frozen instances is
+        #  handled slightly differently from non-frozen ones.
+        with self.assertRaisesRegex(TypeError, r"__init__\(\) got an unexpected "
+                                             "keyword argument 'a'"):
+            c1 = replace(c, x=20, a=5)
+
+    def test_invalid_field_name(self):
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            y: int
+
+        c = C(1, 2)
+        with self.assertRaisesRegex(TypeError, r"__init__\(\) got an unexpected "
+                                    "keyword argument 'z'"):
+            c1 = replace(c, z=3)
+
+    def test_invalid_object(self):
+        @dataclass(frozen=True)
+        class C:
+            x: int
+            y: int
+
+        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
+            replace(C, x=3)
+
+        with self.assertRaisesRegex(TypeError, 'dataclass instance'):
+            replace(0, x=3)
+
+    def test_no_init(self):
+        @dataclass
+        class C:
+            x: int
+            y: int = field(init=False, default=10)
+
+        c = C(1)
+        c.y = 20
+
+        # Make sure y gets the default value.
+        c1 = replace(c, x=5)
+        self.assertEqual((c1.x, c1.y), (5, 10))
+
+        # Trying to replace y is an error.
+        with self.assertRaisesRegex(ValueError, 'init=False'):
+            replace(c, x=2, y=30)
+
+        with self.assertRaisesRegex(ValueError, 'init=False'):
+            replace(c, y=30)
+
+    def test_classvar(self):
+        @dataclass
+        class C:
+            x: int
+            y: ClassVar[int] = 1000
+
+        c = C(1)
+        d = C(2)
+
+        self.assertIs(c.y, d.y)
+        self.assertEqual(c.y, 1000)
+
+        # Trying to replace y is an error: can't replace ClassVars.
+        with self.assertRaisesRegex(TypeError, r"__init__\(\) got an "
+                                    "unexpected keyword argument 'y'"):
+            replace(c, y=30)
+
+        replace(c, x=5)
+
+    def test_initvar_is_specified(self):
+        @dataclass
+        class C:
+            x: int
+            y: InitVar[int]
+
+            def __post_init__(self, y):
+                self.x *= y
+
+        c = C(1, 10)
+        self.assertEqual(c.x, 10)
+        with self.assertRaisesRegex(ValueError, r"InitVar 'y' must be "
+                                    "specified with replace()"):
+            replace(c, x=3)
+        c = replace(c, x=3, y=5)
+        self.assertEqual(c.x, 15)
+
+    def test_initvar_with_default_value(self):
+        @dataclass
+        class C:
+            x: int
+            y: InitVar[int] = None
+            z: InitVar[int] = 42
+
+            def __post_init__(self, y, z):
+                if y is not None:
+                    self.x += y
+                if z is not None:
+                    self.x += z
+
+        c = C(x=1, y=10, z=1)
+        self.assertEqual(replace(c), C(x=12))
+        self.assertEqual(replace(c, y=4), C(x=12, y=4, z=42))
+        self.assertEqual(replace(c, y=4, z=1), C(x=12, y=4, z=1))
+
+    def test_recursive_repr(self):
+        @dataclass
+        class C:
+            f: "C"
+
+        c = C(None)
+        c.f = c
+        self.assertEqual(repr(c), "TestReplace.test_recursive_repr.<locals>.C(f=...)")
+
+    def test_recursive_repr_two_attrs(self):
+        @dataclass
+        class C:
+            f: "C"
+            g: "C"
+
+        c = C(None, None)
+        c.f = c
+        c.g = c
+        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_two_attrs"
+                                  ".<locals>.C(f=..., g=...)")
+
+    def test_recursive_repr_indirection(self):
+        @dataclass
+        class C:
+            f: "D"
+
+        @dataclass
+        class D:
+            f: "C"
+
+        c = C(None)
+        d = D(None)
+        c.f = d
+        d.f = c
+        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_indirection"
+                                  ".<locals>.C(f=TestReplace.test_recursive_repr_indirection"
+                                  ".<locals>.D(f=...))")
+
+    def test_recursive_repr_indirection_two(self):
+        @dataclass
+        class C:
+            f: "D"
+
+        @dataclass
+        class D:
+            f: "E"
+
+        @dataclass
+        class E:
+            f: "C"
+
+        c = C(None)
+        d = D(None)
+        e = E(None)
+        c.f = d
+        d.f = e
+        e.f = c
+        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_indirection_two"
+                                  ".<locals>.C(f=TestReplace.test_recursive_repr_indirection_two"
+                                  ".<locals>.D(f=TestReplace.test_recursive_repr_indirection_two"
+                                  ".<locals>.E(f=...)))")
+
+    def test_recursive_repr_misc_attrs(self):
+        @dataclass
+        class C:
+            f: "C"
+            g: int
+
+        c = C(None, 1)
+        c.f = c
+        self.assertEqual(repr(c), "TestReplace.test_recursive_repr_misc_attrs"
+                                  ".<locals>.C(f=..., g=1)")
+
+    ## def test_initvar(self):
+    ##     @dataclass
+    ##     class C:
+    ##         x: int
+    ##         y: InitVar[int]
+
+    ##     c = C(1, 10)
+    ##     d = C(2, 20)
+
+    ##     # In our case, replacing an InitVar is a no-op
+    ##     self.assertEqual(c, replace(c, y=5))
+
+    ##     replace(c, x=5)
+
+class TestAbstract(unittest.TestCase):
+    def test_abc_implementation(self):
+        class Ordered(abc.ABC):
+            @abc.abstractmethod
+            def __lt__(self, other):
+                pass
+
+            @abc.abstractmethod
+            def __le__(self, other):
+                pass
+
+        @dataclass(order=True)
+        class Date(Ordered):
+            year: int
+            month: 'Month'
+            day: 'int'
+
+        self.assertFalse(inspect.isabstract(Date))
+        self.assertGreater(Date(2020,12,25), Date(2020,8,31))
+
+    def test_maintain_abc(self):
+        class A(abc.ABC):
+            @abc.abstractmethod
+            def foo(self):
+                pass
+
+        @dataclass
+        class Date(A):
+            year: int
+            month: 'Month'
+            day: 'int'
+
+        self.assertTrue(inspect.isabstract(Date))
+        msg = "class Date without an implementation for abstract method 'foo'"
+        self.assertRaisesRegex(TypeError, msg, Date)
+
+
+class TestMatchArgs(unittest.TestCase):
+    def test_match_args(self):
+        @dataclass
+        class C:
+            a: int
+        self.assertEqual(C(42).__match_args__, ('a',))
+
+    def test_explicit_match_args(self):
+        ma = ()
+        @dataclass
+        class C:
+            a: int
+            __match_args__ = ma
+        self.assertIs(C(42).__match_args__, ma)
+
+    def test_bpo_43764(self):
+        @dataclass(repr=False, eq=False, init=False)
+        class X:
+            a: int
+            b: int
+            c: int
+        self.assertEqual(X.__match_args__, ("a", "b", "c"))
+
+    def test_match_args_argument(self):
+        @dataclass(match_args=False)
+        class X:
+            a: int
+        self.assertNotIn('__match_args__', X.__dict__)
+
+        @dataclass(match_args=False)
+        class Y:
+            a: int
+            __match_args__ = ('b',)
+        self.assertEqual(Y.__match_args__, ('b',))
+
+        @dataclass(match_args=False)
+        class Z(Y):
+            z: int
+        self.assertEqual(Z.__match_args__, ('b',))
+
+        # Ensure parent dataclass __match_args__ is seen, if child class
+        # specifies match_args=False.
+        @dataclass
+        class A:
+            a: int
+            z: int
+        @dataclass(match_args=False)
+        class B(A):
+            b: int
+        self.assertEqual(B.__match_args__, ('a', 'z'))
+
+    def test_make_dataclasses(self):
+        C = make_dataclass('C', [('x', int), ('y', int)])
+        self.assertEqual(C.__match_args__, ('x', 'y'))
+
+        C = make_dataclass('C', [('x', int), ('y', int)], match_args=True)
+        self.assertEqual(C.__match_args__, ('x', 'y'))
+
+        C = make_dataclass('C', [('x', int), ('y', int)], match_args=False)
+        self.assertNotIn('__match__args__', C.__dict__)
+
+        C = make_dataclass('C', [('x', int), ('y', int)], namespace={'__match_args__': ('z',)})
+        self.assertEqual(C.__match_args__, ('z',))
+
+
+class TestKeywordArgs(unittest.TestCase):
+    def test_no_classvar_kwarg(self):
+        msg = 'field a is a ClassVar but specifies kw_only'
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass
+            class A:
+                a: ClassVar[int] = field(kw_only=True)
+
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass
+            class A:
+                a: ClassVar[int] = field(kw_only=False)
+
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass(kw_only=True)
+            class A:
+                a: ClassVar[int] = field(kw_only=False)
+
+    def test_field_marked_as_kwonly(self):
+        #######################
+        # Using dataclass(kw_only=True)
+        @dataclass(kw_only=True)
+        class A:
+            a: int
+        self.assertTrue(fields(A)[0].kw_only)
+
+        @dataclass(kw_only=True)
+        class A:
+            a: int = field(kw_only=True)
+        self.assertTrue(fields(A)[0].kw_only)
+
+        @dataclass(kw_only=True)
+        class A:
+            a: int = field(kw_only=False)
+        self.assertFalse(fields(A)[0].kw_only)
+
+        #######################
+        # Using dataclass(kw_only=False)
+        @dataclass(kw_only=False)
+        class A:
+            a: int
+        self.assertFalse(fields(A)[0].kw_only)
+
+        @dataclass(kw_only=False)
+        class A:
+            a: int = field(kw_only=True)
+        self.assertTrue(fields(A)[0].kw_only)
+
+        @dataclass(kw_only=False)
+        class A:
+            a: int = field(kw_only=False)
+        self.assertFalse(fields(A)[0].kw_only)
+
+        #######################
+        # Not specifying dataclass(kw_only)
+        @dataclass
+        class A:
+            a: int
+        self.assertFalse(fields(A)[0].kw_only)
+
+        @dataclass
+        class A:
+            a: int = field(kw_only=True)
+        self.assertTrue(fields(A)[0].kw_only)
+
+        @dataclass
+        class A:
+            a: int = field(kw_only=False)
+        self.assertFalse(fields(A)[0].kw_only)
+
+    def test_match_args(self):
+        # kw fields don't show up in __match_args__.
+        @dataclass(kw_only=True)
+        class C:
+            a: int
+        self.assertEqual(C(a=42).__match_args__, ())
+
+        @dataclass
+        class C:
+            a: int
+            b: int = field(kw_only=True)
+        self.assertEqual(C(42, b=10).__match_args__, ('a',))
+
+    def test_KW_ONLY(self):
+        @dataclass
+        class A:
+            a: int
+            _: KW_ONLY
+            b: int
+            c: int
+        A(3, c=5, b=4)
+        msg = "takes 2 positional arguments but 4 were given"
+        with self.assertRaisesRegex(TypeError, msg):
+            A(3, 4, 5)
+
+
+        @dataclass(kw_only=True)
+        class B:
+            a: int
+            _: KW_ONLY
+            b: int
+            c: int
+        B(a=3, b=4, c=5)
+        msg = "takes 1 positional argument but 4 were given"
+        with self.assertRaisesRegex(TypeError, msg):
+            B(3, 4, 5)
+
+        # Explicitly make a field that follows KW_ONLY be non-keyword-only.
+        @dataclass
+        class C:
+            a: int
+            _: KW_ONLY
+            b: int
+            c: int = field(kw_only=False)
+        c = C(1, 2, b=3)
+        self.assertEqual(c.a, 1)
+        self.assertEqual(c.b, 3)
+        self.assertEqual(c.c, 2)
+        c = C(1, b=3, c=2)
+        self.assertEqual(c.a, 1)
+        self.assertEqual(c.b, 3)
+        self.assertEqual(c.c, 2)
+        c = C(1, b=3, c=2)
+        self.assertEqual(c.a, 1)
+        self.assertEqual(c.b, 3)
+        self.assertEqual(c.c, 2)
+        c = C(c=2, b=3, a=1)
+        self.assertEqual(c.a, 1)
+        self.assertEqual(c.b, 3)
+        self.assertEqual(c.c, 2)
+
+    def test_KW_ONLY_as_string(self):
+        @dataclass
+        class A:
+            a: int
+            _: 'dataclasses.KW_ONLY'
+            b: int
+            c: int
+        A(3, c=5, b=4)
+        msg = "takes 2 positional arguments but 4 were given"
+        with self.assertRaisesRegex(TypeError, msg):
+            A(3, 4, 5)
+
+    def test_KW_ONLY_twice(self):
+        msg = "'Y' is KW_ONLY, but KW_ONLY has already been specified"
+
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass
+            class A:
+                a: int
+                X: KW_ONLY
+                Y: KW_ONLY
+                b: int
+                c: int
+
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass
+            class A:
+                a: int
+                X: KW_ONLY
+                b: int
+                Y: KW_ONLY
+                c: int
+
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass
+            class A:
+                a: int
+                X: KW_ONLY
+                b: int
+                c: int
+                Y: KW_ONLY
+
+        # But this usage is okay, since it's not using KW_ONLY.
+        @dataclass
+        class A:
+            a: int
+            _: KW_ONLY
+            b: int
+            c: int = field(kw_only=True)
+
+        # And if inheriting, it's okay.
+        @dataclass
+        class A:
+            a: int
+            _: KW_ONLY
+            b: int
+            c: int
+        @dataclass
+        class B(A):
+            _: KW_ONLY
+            d: int
+
+        # Make sure the error is raised in a derived class.
+        with self.assertRaisesRegex(TypeError, msg):
+            @dataclass
+            class A:
+                a: int
+                _: KW_ONLY
+                b: int
+                c: int
+            @dataclass
+            class B(A):
+                X: KW_ONLY
+                d: int
+                Y: KW_ONLY
+
+
+    def test_post_init(self):
+        @dataclass
+        class A:
+            a: int
+            _: KW_ONLY
+            b: InitVar[int]
+            c: int
+            d: InitVar[int]
+            def __post_init__(self, b, d):
+                raise CustomError(f'{b=} {d=}')
+        with self.assertRaisesRegex(CustomError, 'b=3 d=4'):
+            A(1, c=2, b=3, d=4)
+
+        @dataclass
+        class B:
+            a: int
+            _: KW_ONLY
+            b: InitVar[int]
+            c: int
+            d: InitVar[int]
+            def __post_init__(self, b, d):
+                self.a = b
+                self.c = d
+        b = B(1, c=2, b=3, d=4)
+        self.assertEqual(asdict(b), {'a': 3, 'c': 4})
+
+    def test_defaults(self):
+        # For kwargs, make sure we can have defaults after non-defaults.
+        @dataclass
+        class A:
+            a: int = 0
+            _: KW_ONLY
+            b: int
+            c: int = 1
+            d: int
+
+        a = A(d=4, b=3)
+        self.assertEqual(a.a, 0)
+        self.assertEqual(a.b, 3)
+        self.assertEqual(a.c, 1)
+        self.assertEqual(a.d, 4)
+
+        # Make sure we still check for non-kwarg non-defaults not following
+        # defaults.
+        err_regex = "non-default argument 'z' follows default argument"
+        with self.assertRaisesRegex(TypeError, err_regex):
+            @dataclass
+            class A:
+                a: int = 0
+                z: int
+                _: KW_ONLY
+                b: int
+                c: int = 1
+                d: int
+
+    def test_make_dataclass(self):
+        A = make_dataclass("A", ['a'], kw_only=True)
+        self.assertTrue(fields(A)[0].kw_only)
+
+        B = make_dataclass("B",
+                           ['a', ('b', int, field(kw_only=False))],
+                           kw_only=True)
+        self.assertTrue(fields(B)[0].kw_only)
+        self.assertFalse(fields(B)[1].kw_only)
+
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/Lib/test/test_dataclasses/dataclass_module_1.py b/Lib/test/test_dataclasses/dataclass_module_1.py
new file mode 100644
index 0000000000..87a33f8191
--- /dev/null
+++ b/Lib/test/test_dataclasses/dataclass_module_1.py
@@ -0,0 +1,32 @@
+#from __future__ import annotations
+USING_STRINGS = False
+
+# dataclass_module_1.py and dataclass_module_1_str.py are identical
+# except only the latter uses string annotations.
+
+import dataclasses
+import typing
+
+T_CV2 = typing.ClassVar[int]
+T_CV3 = typing.ClassVar
+
+T_IV2 = dataclasses.InitVar[int]
+T_IV3 = dataclasses.InitVar
+
+@dataclasses.dataclass
+class CV:
+    T_CV4 = typing.ClassVar
+    cv0: typing.ClassVar[int] = 20
+    cv1: typing.ClassVar = 30
+    cv2: T_CV2
+    cv3: T_CV3
+    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
+
+@dataclasses.dataclass
+class IV:
+    T_IV4 = dataclasses.InitVar
+    iv0: dataclasses.InitVar[int]
+    iv1: dataclasses.InitVar
+    iv2: T_IV2
+    iv3: T_IV3
+    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/test_dataclasses/dataclass_module_1_str.py b/Lib/test/test_dataclasses/dataclass_module_1_str.py
new file mode 100644
index 0000000000..6de490b7ad
--- /dev/null
+++ b/Lib/test/test_dataclasses/dataclass_module_1_str.py
@@ -0,0 +1,32 @@
+from __future__ import annotations
+USING_STRINGS = True
+
+# dataclass_module_1.py and dataclass_module_1_str.py are identical
+# except only the latter uses string annotations.
+
+import dataclasses
+import typing
+
+T_CV2 = typing.ClassVar[int]
+T_CV3 = typing.ClassVar
+
+T_IV2 = dataclasses.InitVar[int]
+T_IV3 = dataclasses.InitVar
+
+@dataclasses.dataclass
+class CV:
+    T_CV4 = typing.ClassVar
+    cv0: typing.ClassVar[int] = 20
+    cv1: typing.ClassVar = 30
+    cv2: T_CV2
+    cv3: T_CV3
+    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
+
+@dataclasses.dataclass
+class IV:
+    T_IV4 = dataclasses.InitVar
+    iv0: dataclasses.InitVar[int]
+    iv1: dataclasses.InitVar
+    iv2: T_IV2
+    iv3: T_IV3
+    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/test_dataclasses/dataclass_module_2.py b/Lib/test/test_dataclasses/dataclass_module_2.py
new file mode 100644
index 0000000000..68fb733e29
--- /dev/null
+++ b/Lib/test/test_dataclasses/dataclass_module_2.py
@@ -0,0 +1,32 @@
+#from __future__ import annotations
+USING_STRINGS = False
+
+# dataclass_module_2.py and dataclass_module_2_str.py are identical
+# except only the latter uses string annotations.
+
+from dataclasses import dataclass, InitVar
+from typing import ClassVar
+
+T_CV2 = ClassVar[int]
+T_CV3 = ClassVar
+
+T_IV2 = InitVar[int]
+T_IV3 = InitVar
+
+@dataclass
+class CV:
+    T_CV4 = ClassVar
+    cv0: ClassVar[int] = 20
+    cv1: ClassVar = 30
+    cv2: T_CV2
+    cv3: T_CV3
+    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
+
+@dataclass
+class IV:
+    T_IV4 = InitVar
+    iv0: InitVar[int]
+    iv1: InitVar
+    iv2: T_IV2
+    iv3: T_IV3
+    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/test_dataclasses/dataclass_module_2_str.py b/Lib/test/test_dataclasses/dataclass_module_2_str.py
new file mode 100644
index 0000000000..b363d17c17
--- /dev/null
+++ b/Lib/test/test_dataclasses/dataclass_module_2_str.py
@@ -0,0 +1,32 @@
+from __future__ import annotations
+USING_STRINGS = True
+
+# dataclass_module_2.py and dataclass_module_2_str.py are identical
+# except only the latter uses string annotations.
+
+from dataclasses import dataclass, InitVar
+from typing import ClassVar
+
+T_CV2 = ClassVar[int]
+T_CV3 = ClassVar
+
+T_IV2 = InitVar[int]
+T_IV3 = InitVar
+
+@dataclass
+class CV:
+    T_CV4 = ClassVar
+    cv0: ClassVar[int] = 20
+    cv1: ClassVar = 30
+    cv2: T_CV2
+    cv3: T_CV3
+    not_cv4: T_CV4  # When using string annotations, this field is not recognized as a ClassVar.
+
+@dataclass
+class IV:
+    T_IV4 = InitVar
+    iv0: InitVar[int]
+    iv1: InitVar
+    iv2: T_IV2
+    iv3: T_IV3
+    not_iv4: T_IV4  # When using string annotations, this field is not recognized as an InitVar.
diff --git a/Lib/test/test_dataclasses/dataclass_textanno.py b/Lib/test/test_dataclasses/dataclass_textanno.py
new file mode 100644
index 0000000000..3eb6c943d4
--- /dev/null
+++ b/Lib/test/test_dataclasses/dataclass_textanno.py
@@ -0,0 +1,12 @@
+from __future__ import annotations
+
+import dataclasses
+
+
+class Foo:
+    pass
+
+
+@dataclasses.dataclass
+class Bar:
+    foo: Foo
diff --git a/Lib/test/test_descr.py b/Lib/test/test_descr.py
index 9d8b149733..bf4b8f9572 100644
--- a/Lib/test/test_descr.py
+++ b/Lib/test/test_descr.py
@@ -1989,7 +1989,7 @@ def __getattr__(self, attr):
         ns = {}
         exec(code, ns)
         number_attrs = ns["number_attrs"]
-        # Warm up the the function for quickening (PEP 659)
+        # Warm up the function for quickening (PEP 659)
         for _ in range(30):
             self.assertEqual(number_attrs(Numbers()), list(range(280)))
 
diff --git a/Lib/test/test_doctest.py b/Lib/test/test_doctest.py
index bca4915e0f..0706049a90 100644
--- a/Lib/test/test_doctest.py
+++ b/Lib/test/test_doctest.py
@@ -3168,25 +3168,173 @@ def test_run_doctestsuite_multiple_times():
     """
 
 
+def test_exception_with_note(note):
+    """
+    >>> test_exception_with_note('Note')
+    Traceback (most recent call last):
+      ...
+    ValueError: Text
+    Note
+
+    >>> test_exception_with_note('Note')  # doctest: +IGNORE_EXCEPTION_DETAIL
+    Traceback (most recent call last):
+      ...
+    ValueError: Text
+    Note
+
+    >>> test_exception_with_note('''Note
+    ... multiline
+    ... example''')
+    Traceback (most recent call last):
+    ValueError: Text
+    Note
+    multiline
+    example
+
+    Different note will fail the test:
+
+    >>> def f(x):
+    ...     r'''
+    ...     >>> exc = ValueError('message')
+    ...     >>> exc.add_note('note')
+    ...     >>> raise exc
+    ...     Traceback (most recent call last):
+    ...     ValueError: message
+    ...     wrong note
+    ...     '''
+    >>> test = doctest.DocTestFinder().find(f)[0]
+    >>> doctest.DocTestRunner(verbose=False).run(test)
+    ... # doctest: +ELLIPSIS
+    **********************************************************************
+    File "...", line 5, in f
+    Failed example:
+        raise exc
+    Expected:
+        Traceback (most recent call last):
+        ValueError: message
+        wrong note
+    Got:
+        Traceback (most recent call last):
+          ...
+        ValueError: message
+        note
+    TestResults(failed=1, attempted=...)
+    """
+    exc = ValueError('Text')
+    exc.add_note(note)
+    raise exc
+
+
+def test_exception_with_multiple_notes():
+    """
+    >>> test_exception_with_multiple_notes()
+    Traceback (most recent call last):
+      ...
+    ValueError: Text
+    One
+    Two
+    """
+    exc = ValueError('Text')
+    exc.add_note('One')
+    exc.add_note('Two')
+    raise exc
+
+
+def test_syntax_error_with_note(cls, multiline=False):
+    """
+    >>> test_syntax_error_with_note(SyntaxError)
+    Traceback (most recent call last):
+      ...
+    SyntaxError: error
+    Note
+
+    >>> test_syntax_error_with_note(SyntaxError)
+    Traceback (most recent call last):
+    SyntaxError: error
+    Note
+
+    >>> test_syntax_error_with_note(SyntaxError)
+    Traceback (most recent call last):
+      ...
+      File "x.py", line 23
+        bad syntax
+    SyntaxError: error
+    Note
+
+    >>> test_syntax_error_with_note(IndentationError)
+    Traceback (most recent call last):
+      ...
+    IndentationError: error
+    Note
+
+    >>> test_syntax_error_with_note(TabError, multiline=True)
+    Traceback (most recent call last):
+      ...
+    TabError: error
+    Note
+    Line
+    """
+    exc = cls("error", ("x.py", 23, None, "bad syntax"))
+    exc.add_note('Note\nLine' if multiline else 'Note')
+    raise exc
+
+
+def test_syntax_error_subclass_from_stdlib():
+    """
+    `ParseError` is a subclass of `SyntaxError`, but it is not a builtin:
+
+    >>> test_syntax_error_subclass_from_stdlib()
+    Traceback (most recent call last):
+      ...
+    xml.etree.ElementTree.ParseError: error
+    error
+    Note
+    Line
+    """
+    from xml.etree.ElementTree import ParseError
+    exc = ParseError("error\nerror")
+    exc.add_note('Note\nLine')
+    raise exc
+
+
+def test_syntax_error_with_incorrect_expected_note():
+    """
+    >>> def f(x):
+    ...     r'''
+    ...     >>> exc = SyntaxError("error", ("x.py", 23, None, "bad syntax"))
+    ...     >>> exc.add_note('note1')
+    ...     >>> exc.add_note('note2')
+    ...     >>> raise exc
+    ...     Traceback (most recent call last):
+    ...     SyntaxError: error
+    ...     wrong note
+    ...     '''
+    >>> test = doctest.DocTestFinder().find(f)[0]
+    >>> doctest.DocTestRunner(verbose=False).run(test)
+    ... # doctest: +ELLIPSIS
+    **********************************************************************
+    File "...", line 6, in f
+    Failed example:
+        raise exc
+    Expected:
+        Traceback (most recent call last):
+        SyntaxError: error
+        wrong note
+    Got:
+        Traceback (most recent call last):
+          ...
+        SyntaxError: error
+        note1
+        note2
+    TestResults(failed=1, attempted=...)
+    """
+
+
 def load_tests(loader, tests, pattern):
     tests.addTest(doctest.DocTestSuite(doctest))
     tests.addTest(doctest.DocTestSuite())
     return tests
 
 
-def test_coverage(coverdir):
-    trace = import_helper.import_module('trace')
-    tracer = trace.Trace(ignoredirs=[sys.base_prefix, sys.base_exec_prefix,],
-                         trace=0, count=1)
-    tracer.run('test_main()')
-    r = tracer.results()
-    print('Writing coverage results...')
-    r.write_results(show_missing=True, summary=True,
-                    coverdir=coverdir)
-
-
 if __name__ == '__main__':
-    if '-c' in sys.argv:
-        test_coverage('/tmp/doctest.cover')
-    else:
-        unittest.main()
+    unittest.main(module='test.test_doctest')
diff --git a/Lib/test/test_dynamic.py b/Lib/test/test_dynamic.py
index 7e12d428e0..0aa3be6a1b 100644
--- a/Lib/test/test_dynamic.py
+++ b/Lib/test/test_dynamic.py
@@ -145,7 +145,7 @@ def __missing__(self, key):
         code = "lambda: " + "+".join(f"_number_{i}" for i in range(variables))
         sum_func = eval(code, MyGlobals())
         expected = sum(range(variables))
-        # Warm up the the function for quickening (PEP 659)
+        # Warm up the function for quickening (PEP 659)
         for _ in range(30):
             self.assertEqual(sum_func(), expected)
 
diff --git a/Lib/test/test_email/test_utils.py b/Lib/test/test_email/test_utils.py
index 25fa48c5ee..c9d973df0a 100644
--- a/Lib/test/test_email/test_utils.py
+++ b/Lib/test/test_email/test_utils.py
@@ -5,6 +5,7 @@
 import unittest
 import sys
 import os.path
+import zoneinfo
 
 class DateTimeTests(unittest.TestCase):
 
@@ -142,13 +143,9 @@ def test_localtime_epoch_notz_daylight_false(self):
         t2 = utils.localtime(t0.replace(tzinfo=None))
         self.assertEqual(t1, t2)
 
-    # XXX: Need a more robust test for Olson's tzdata
-    @unittest.skipIf(sys.platform.startswith('win'),
-                     "Windows does not use Olson's TZ database")
-    @unittest.skipUnless(os.path.exists('/usr/share/zoneinfo') or
-                         os.path.exists('/usr/lib/zoneinfo'),
-                         "Can't find the Olson's TZ database")
-    @test.support.run_with_tz('Europe/Kiev')
+    @unittest.skipUnless("Europe/Kyiv" in zoneinfo.available_timezones(),
+                         "Can't find a Kyiv timezone database")
+    @test.support.run_with_tz('Europe/Kyiv')
     def test_variable_tzname(self):
         t0 = datetime.datetime(1984, 1, 1, tzinfo=datetime.timezone.utc)
         t1 = utils.localtime(t0)
diff --git a/Lib/test/test_embed.py b/Lib/test/test_embed.py
index 582392ecdd..24617ab24c 100644
--- a/Lib/test/test_embed.py
+++ b/Lib/test/test_embed.py
@@ -1,8 +1,6 @@
 # Run the tests in Programs/_testembed.c (tests for the CPython embedding APIs)
 from test import support
-from test.support import import_helper
-from test.support import os_helper
-from test.support import requires_specialization
+from test.support import import_helper, os_helper, MS_WINDOWS
 import unittest
 
 from collections import namedtuple
@@ -21,7 +19,6 @@
 if not support.has_subprocess_support:
     raise unittest.SkipTest("test module requires subprocess")
 
-MS_WINDOWS = (os.name == 'nt')
 MACOS = (sys.platform == 'darwin')
 PYMEM_ALLOCATOR_NOT_SET = 0
 PYMEM_ALLOCATOR_DEBUG = 2
@@ -347,7 +344,7 @@ def test_simple_initialization_api(self):
         out, err = self.run_embedded_interpreter("test_repeated_simple_init")
         self.assertEqual(out, 'Finalized\n' * INIT_LOOPS)
 
-    @requires_specialization
+    @support.requires_specialization
     def test_specialized_static_code_gets_unspecialized_at_Py_FINALIZE(self):
         # https://github.com/python/cpython/issues/92031
 
diff --git a/Lib/test/test_enum.py b/Lib/test/test_enum.py
index 14f16f7f26..3bd918fb94 100644
--- a/Lib/test/test_enum.py
+++ b/Lib/test/test_enum.py
@@ -18,7 +18,7 @@
 from io import StringIO
 from pickle import dumps, loads, PicklingError, HIGHEST_PROTOCOL
 from test import support
-from test.support import ALWAYS_EQ
+from test.support import ALWAYS_EQ, REPO_ROOT
 from test.support import threading_helper
 from datetime import timedelta
 
@@ -26,14 +26,19 @@
 
 def load_tests(loader, tests, ignore):
     tests.addTests(doctest.DocTestSuite(enum))
-    if os.path.exists('Doc/library/enum.rst'):
+
+    lib_tests = os.path.join(REPO_ROOT, 'Doc/library/enum.rst')
+    if os.path.exists(lib_tests):
         tests.addTests(doctest.DocFileSuite(
-                '../../Doc/library/enum.rst',
+                lib_tests,
+                module_relative=False,
                 optionflags=doctest.ELLIPSIS|doctest.NORMALIZE_WHITESPACE,
                 ))
-    if os.path.exists('Doc/howto/enum.rst'):
+    howto_tests = os.path.join(REPO_ROOT, 'Doc/howto/enum.rst')
+    if os.path.exists(howto_tests):
         tests.addTests(doctest.DocFileSuite(
-                '../../Doc/howto/enum.rst',
+                howto_tests,
+                module_relative=False,
                 optionflags=doctest.ELLIPSIS|doctest.NORMALIZE_WHITESPACE,
                 ))
     return tests
@@ -5127,7 +5132,7 @@ def member_dir(member):
                     allowed.add(name)
                 else:
                     allowed.discard(name)
-            else:
+            elif name not in member._member_map_:
                 allowed.add(name)
     return sorted(allowed)
 
diff --git a/Lib/test/test_exceptions.py b/Lib/test/test_exceptions.py
index 72afb3b0fb..ad0b7c2154 100644
--- a/Lib/test/test_exceptions.py
+++ b/Lib/test/test_exceptions.py
@@ -18,6 +18,12 @@
 from test.support.warnings_helper import check_warnings
 from test import support
 
+try:
+    from _testcapi import INT_MAX
+except ImportError:
+    INT_MAX = 2**31 - 1
+
+
 
 class NaiveException(Exception):
     def __init__(self, x):
@@ -318,6 +324,14 @@ def baz():
         check('(yield i) = 2', 1, 2)
         check('def f(*):\n  pass', 1, 7)
 
+    @unittest.skipIf(INT_MAX >= sys.maxsize, "Downcasting to int is safe for col_offset")
+    @support.requires_resource('cpu')
+    @support.bigmemtest(INT_MAX, memuse=2, dry_run=False)
+    def testMemoryErrorBigSource(self, size):
+        src = b"if True:\n%*s" % (size, b"pass")
+        with self.assertRaisesRegex(OverflowError, "Parser column offset overflow"):
+            compile(src, '<fragment>', 'exec')
+
     @cpython_only
     def testSettingException(self):
         # test that setting an exception at the C level works even if the
@@ -1810,6 +1824,13 @@ def f():
         self.assertIn("nonsense", err.getvalue())
         self.assertIn("ZeroDivisionError", err.getvalue())
 
+    def test_gh_111654(self):
+        def f():
+            class TestClass:
+                TestClass
+
+        self.assertRaises(NameError, f)
+
     # Note: name suggestion tests live in `test_traceback`.
 
 
diff --git a/Lib/test/test_faulthandler.py b/Lib/test/test_faulthandler.py
index cfc7ce5a86..d0473500a1 100644
--- a/Lib/test/test_faulthandler.py
+++ b/Lib/test/test_faulthandler.py
@@ -7,9 +7,7 @@
 import subprocess
 import sys
 from test import support
-from test.support import os_helper
-from test.support import script_helper, is_android
-from test.support import skip_if_sanitizer
+from test.support import os_helper, script_helper, is_android, MS_WINDOWS
 import tempfile
 import unittest
 from textwrap import dedent
@@ -23,7 +21,6 @@
     raise unittest.SkipTest("test module requires subprocess")
 
 TIMEOUT = 0.5
-MS_WINDOWS = (os.name == 'nt')
 
 
 def expected_traceback(lineno1, lineno2, header, min_count=1):
@@ -36,7 +33,7 @@ def expected_traceback(lineno1, lineno2, header, min_count=1):
         return '^' + regex + '$'
 
 def skip_segfault_on_android(test):
-    # Issue #32138: Raising SIGSEGV on Android may not cause a crash.
+    # gh-76319: Raising SIGSEGV on Android may not cause a crash.
     return unittest.skipIf(is_android,
                            'raising SIGSEGV on Android is unreliable')(test)
 
@@ -64,8 +61,16 @@ def get_output(self, code, filename=None, fd=None):
         pass_fds = []
         if fd is not None:
             pass_fds.append(fd)
+        env = dict(os.environ)
+
+        # Sanitizers must not handle SIGSEGV (ex: for test_enable_fd())
+        option = 'handle_segv=0'
+        support.set_sanitizer_env_var(env, option)
+
         with support.SuppressCrashReport():
-            process = script_helper.spawn_python('-c', code, pass_fds=pass_fds)
+            process = script_helper.spawn_python('-c', code,
+                                                 pass_fds=pass_fds,
+                                                 env=env)
             with process:
                 output, stderr = process.communicate()
                 exitcode = process.wait()
@@ -304,8 +309,6 @@ def test_gil_released(self):
             3,
             'Segmentation fault')
 
-    @skip_if_sanitizer(memory=True, ub=True, reason="sanitizer "
-                       "builds change crashing process output.")
     @skip_segfault_on_android
     def test_enable_file(self):
         with temporary_filename() as filename:
@@ -321,8 +324,6 @@ def test_enable_file(self):
 
     @unittest.skipIf(sys.platform == "win32",
                      "subprocess doesn't support pass_fds on Windows")
-    @skip_if_sanitizer(memory=True, ub=True, reason="sanitizer "
-                       "builds change crashing process output.")
     @skip_segfault_on_android
     def test_enable_fd(self):
         with tempfile.TemporaryFile('wb+') as fp:
diff --git a/Lib/test/test_float.py b/Lib/test/test_float.py
index c4ee1e0825..32aaf3a80a 100644
--- a/Lib/test/test_float.py
+++ b/Lib/test/test_float.py
@@ -18,7 +18,6 @@
 except ImportError:
     _testcapi = None
 
-HAVE_IEEE_754 = float.__getformat__("double").startswith("IEEE")
 INF = float("inf")
 NAN = float("nan")
 
@@ -733,8 +732,13 @@ def test_format_testfile(self):
 
                 lhs, rhs = map(str.strip, line.split('->'))
                 fmt, arg = lhs.split()
-                self.assertEqual(fmt % float(arg), rhs)
-                self.assertEqual(fmt % -float(arg), '-' + rhs)
+                f = float(arg)
+                self.assertEqual(fmt % f, rhs)
+                self.assertEqual(fmt % -f, '-' + rhs)
+                if fmt != '%r':
+                    fmt2 = fmt[1:]
+                    self.assertEqual(format(f, fmt2), rhs)
+                    self.assertEqual(format(-f, fmt2), '-' + rhs)
 
     def test_issue5864(self):
         self.assertEqual(format(123.456, '.4'), '123.5')
@@ -1499,69 +1503,5 @@ def __init__(self, value):
         self.assertEqual(getattr(f, 'foo', 'none'), 'bar')
 
 
-# Test PyFloat_Pack2(), PyFloat_Pack4() and PyFloat_Pack8()
-# Test PyFloat_Unpack2(), PyFloat_Unpack4() and PyFloat_Unpack8()
-BIG_ENDIAN = 0
-LITTLE_ENDIAN = 1
-EPSILON = {
-    2: 2.0 ** -11,  # binary16
-    4: 2.0 ** -24,  # binary32
-    8: 2.0 ** -53,  # binary64
-}
-
-@unittest.skipIf(_testcapi is None, 'needs _testcapi')
-class PackTests(unittest.TestCase):
-    def test_pack(self):
-        self.assertEqual(_testcapi.float_pack(2, 1.5, BIG_ENDIAN),
-                         b'>\x00')
-        self.assertEqual(_testcapi.float_pack(4, 1.5, BIG_ENDIAN),
-                         b'?\xc0\x00\x00')
-        self.assertEqual(_testcapi.float_pack(8, 1.5, BIG_ENDIAN),
-                         b'?\xf8\x00\x00\x00\x00\x00\x00')
-        self.assertEqual(_testcapi.float_pack(2, 1.5, LITTLE_ENDIAN),
-                         b'\x00>')
-        self.assertEqual(_testcapi.float_pack(4, 1.5, LITTLE_ENDIAN),
-                         b'\x00\x00\xc0?')
-        self.assertEqual(_testcapi.float_pack(8, 1.5, LITTLE_ENDIAN),
-                         b'\x00\x00\x00\x00\x00\x00\xf8?')
-
-    def test_unpack(self):
-        self.assertEqual(_testcapi.float_unpack(b'>\x00', BIG_ENDIAN),
-                         1.5)
-        self.assertEqual(_testcapi.float_unpack(b'?\xc0\x00\x00', BIG_ENDIAN),
-                         1.5)
-        self.assertEqual(_testcapi.float_unpack(b'?\xf8\x00\x00\x00\x00\x00\x00', BIG_ENDIAN),
-                         1.5)
-        self.assertEqual(_testcapi.float_unpack(b'\x00>', LITTLE_ENDIAN),
-                         1.5)
-        self.assertEqual(_testcapi.float_unpack(b'\x00\x00\xc0?', LITTLE_ENDIAN),
-                         1.5)
-        self.assertEqual(_testcapi.float_unpack(b'\x00\x00\x00\x00\x00\x00\xf8?', LITTLE_ENDIAN),
-                         1.5)
-
-    def test_roundtrip(self):
-        large = 2.0 ** 100
-        values = [1.0, 1.5, large, 1.0/7, math.pi]
-        if HAVE_IEEE_754:
-            values.extend((INF, NAN))
-        for value in values:
-            for size in (2, 4, 8,):
-                if size == 2 and value == large:
-                    # too large for 16-bit float
-                    continue
-                rel_tol = EPSILON[size]
-                for endian in (BIG_ENDIAN, LITTLE_ENDIAN):
-                    with self.subTest(value=value, size=size, endian=endian):
-                        data = _testcapi.float_pack(size, value, endian)
-                        value2 = _testcapi.float_unpack(data, endian)
-                        if isnan(value):
-                            self.assertTrue(isnan(value2), (value, value2))
-                        elif size < 8:
-                            self.assertTrue(math.isclose(value2, value, rel_tol=rel_tol),
-                                            (value, value2))
-                        else:
-                            self.assertEqual(value2, value)
-
-
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_fractions.py b/Lib/test/test_fractions.py
index e112f49d2e..4f4ea7c03f 100644
--- a/Lib/test/test_fractions.py
+++ b/Lib/test/test_fractions.py
@@ -7,6 +7,7 @@
 import operator
 import fractions
 import functools
+import os
 import sys
 import typing
 import unittest
@@ -15,6 +16,9 @@
 from pickle import dumps, loads
 F = fractions.Fraction
 
+#locate file with float format test values
+test_dir = os.path.dirname(__file__) or os.curdir
+format_testfile = os.path.join(test_dir, 'formatfloat_testcases.txt')
 
 class DummyFloat(object):
     """Dummy float class for testing comparisons with Fractions"""
@@ -1220,6 +1224,30 @@ def test_invalid_formats(self):
                 with self.assertRaises(ValueError):
                     format(fraction, spec)
 
+    @requires_IEEE_754
+    def test_float_format_testfile(self):
+        with open(format_testfile, encoding="utf-8") as testfile:
+            for line in testfile:
+                if line.startswith('--'):
+                    continue
+                line = line.strip()
+                if not line:
+                    continue
+
+                lhs, rhs = map(str.strip, line.split('->'))
+                fmt, arg = lhs.split()
+                if fmt == '%r':
+                    continue
+                fmt2 = fmt[1:]
+                with self.subTest(fmt=fmt, arg=arg):
+                    f = F(float(arg))
+                    self.assertEqual(format(f, fmt2), rhs)
+                    if f:  # skip negative zero
+                        self.assertEqual(format(-f, fmt2), '-' + rhs)
+                    f = F(arg)
+                    self.assertEqual(float(format(f, fmt2)), float(rhs))
+                    self.assertEqual(float(format(-f, fmt2)), float('-' + rhs))
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_frame.py b/Lib/test/test_frame.py
index 6bb0144e9b..9491c7facd 100644
--- a/Lib/test/test_frame.py
+++ b/Lib/test/test_frame.py
@@ -322,7 +322,7 @@ def f():
             sneaky_frame_object = None
             gc.enable()
             next(g)
-            # g.gi_frame should be the the frame object from the callback (the
+            # g.gi_frame should be the frame object from the callback (the
             # one that was *requested* second, but *created* first):
             self.assertIs(g.gi_frame, sneaky_frame_object)
         finally:
diff --git a/Lib/test/test_ftplib.py b/Lib/test/test_ftplib.py
index 544228e3ba..2f191ea7a4 100644
--- a/Lib/test/test_ftplib.py
+++ b/Lib/test/test_ftplib.py
@@ -32,7 +32,7 @@
 DEFAULT_ENCODING = 'utf-8'
 # the dummy data returned by server over the data channel when
 # RETR, LIST, NLST, MLSD commands are issued
-RETR_DATA = 'abcde12345\r\n' * 1000 + 'non-ascii char \xAE\r\n'
+RETR_DATA = 'abcde\xB9\xB2\xB3\xA4\xA6\r\n' * 1000
 LIST_DATA = 'foo\r\nbar\r\n non-ascii char \xAE\r\n'
 NLST_DATA = 'foo\r\nbar\r\n non-ascii char \xAE\r\n'
 MLSD_DATA = ("type=cdir;perm=el;unique==keVO1+ZF4; test\r\n"
@@ -67,11 +67,11 @@ class DummyDTPHandler(asynchat.async_chat):
     def __init__(self, conn, baseclass):
         asynchat.async_chat.__init__(self, conn)
         self.baseclass = baseclass
-        self.baseclass.last_received_data = ''
+        self.baseclass.last_received_data = bytearray()
         self.encoding = baseclass.encoding
 
     def handle_read(self):
-        new_data = self.recv(1024).decode(self.encoding, 'replace')
+        new_data = self.recv(1024)
         self.baseclass.last_received_data += new_data
 
     def handle_close(self):
@@ -107,7 +107,7 @@ def __init__(self, conn, encoding=DEFAULT_ENCODING):
         self.in_buffer = []
         self.dtp = None
         self.last_received_cmd = None
-        self.last_received_data = ''
+        self.last_received_data = bytearray()
         self.next_response = ''
         self.next_data = None
         self.rest = None
@@ -325,8 +325,8 @@ def handle_error(self):
 
 if ssl is not None:
 
-    CERTFILE = os.path.join(os.path.dirname(__file__), "keycert3.pem")
-    CAFILE = os.path.join(os.path.dirname(__file__), "pycacert.pem")
+    CERTFILE = os.path.join(os.path.dirname(__file__), "certdata", "keycert3.pem")
+    CAFILE = os.path.join(os.path.dirname(__file__), "certdata", "pycacert.pem")
 
     class SSLConnection(asyncore.dispatcher):
         """An asyncore.dispatcher subclass supporting TLS/SSL."""
@@ -590,19 +590,17 @@ def test_abort(self):
         self.client.abort()
 
     def test_retrbinary(self):
-        def callback(data):
-            received.append(data.decode(self.client.encoding))
         received = []
-        self.client.retrbinary('retr', callback)
-        self.check_data(''.join(received), RETR_DATA)
+        self.client.retrbinary('retr', received.append)
+        self.check_data(b''.join(received),
+                        RETR_DATA.encode(self.client.encoding))
 
     def test_retrbinary_rest(self):
-        def callback(data):
-            received.append(data.decode(self.client.encoding))
         for rest in (0, 10, 20):
             received = []
-            self.client.retrbinary('retr', callback, rest=rest)
-            self.check_data(''.join(received), RETR_DATA[rest:])
+            self.client.retrbinary('retr', received.append, rest=rest)
+            self.check_data(b''.join(received),
+                            RETR_DATA[rest:].encode(self.client.encoding))
 
     def test_retrlines(self):
         received = []
@@ -612,7 +610,8 @@ def test_retrlines(self):
     def test_storbinary(self):
         f = io.BytesIO(RETR_DATA.encode(self.client.encoding))
         self.client.storbinary('stor', f)
-        self.check_data(self.server.handler_instance.last_received_data, RETR_DATA)
+        self.check_data(self.server.handler_instance.last_received_data,
+                        RETR_DATA.encode(self.server.encoding))
         # test new callback arg
         flag = []
         f.seek(0)
@@ -631,7 +630,8 @@ def test_storlines(self):
         data = RETR_DATA.replace('\r\n', '\n').encode(self.client.encoding)
         f = io.BytesIO(data)
         self.client.storlines('stor', f)
-        self.check_data(self.server.handler_instance.last_received_data, RETR_DATA)
+        self.check_data(self.server.handler_instance.last_received_data,
+                        RETR_DATA.encode(self.server.encoding))
         # test new callback arg
         flag = []
         f.seek(0)
@@ -649,7 +649,7 @@ def test_nlst(self):
 
     def test_dir(self):
         l = []
-        self.client.dir(lambda x: l.append(x))
+        self.client.dir(l.append)
         self.assertEqual(''.join(l), LIST_DATA.replace('\r\n', ''))
 
     def test_mlsd(self):
@@ -889,12 +889,10 @@ def test_makepasv(self):
 
     def test_transfer(self):
         def retr():
-            def callback(data):
-                received.append(data.decode(self.client.encoding))
             received = []
-            self.client.retrbinary('retr', callback)
-            self.assertEqual(len(''.join(received)), len(RETR_DATA))
-            self.assertEqual(''.join(received), RETR_DATA)
+            self.client.retrbinary('retr', received.append)
+            self.assertEqual(b''.join(received),
+                             RETR_DATA.encode(self.client.encoding))
         self.client.set_pasv(True)
         retr()
         self.client.set_pasv(False)
diff --git a/Lib/test/test_future.py b/Lib/test/test_future.py
deleted file mode 100644
index 4730bfafbd..0000000000
--- a/Lib/test/test_future.py
+++ /dev/null
@@ -1,450 +0,0 @@
-# Test various flavors of legal and illegal future statements
-
-import __future__
-import ast
-import unittest
-from test.support import import_helper
-from test.support.script_helper import spawn_python, kill_python
-from textwrap import dedent
-import os
-import re
-import sys
-
-rx = re.compile(r'\((\S+).py, line (\d+)')
-
-def get_error_location(msg):
-    mo = rx.search(str(msg))
-    return mo.group(1, 2)
-
-class FutureTest(unittest.TestCase):
-
-    def check_syntax_error(self, err, basename, lineno, offset=1):
-        self.assertIn('%s.py, line %d' % (basename, lineno), str(err))
-        self.assertEqual(os.path.basename(err.filename), basename + '.py')
-        self.assertEqual(err.lineno, lineno)
-        self.assertEqual(err.offset, offset)
-
-    def test_future1(self):
-        with import_helper.CleanImport('future_test1'):
-            from test import future_test1
-            self.assertEqual(future_test1.result, 6)
-
-    def test_future2(self):
-        with import_helper.CleanImport('future_test2'):
-            from test import future_test2
-            self.assertEqual(future_test2.result, 6)
-
-    def test_future3(self):
-        with import_helper.CleanImport('test_future3'):
-            from test import test_future3
-
-    def test_badfuture3(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future3
-        self.check_syntax_error(cm.exception, "badsyntax_future3", 3)
-
-    def test_badfuture4(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future4
-        self.check_syntax_error(cm.exception, "badsyntax_future4", 3)
-
-    def test_badfuture5(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future5
-        self.check_syntax_error(cm.exception, "badsyntax_future5", 4)
-
-    def test_badfuture6(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future6
-        self.check_syntax_error(cm.exception, "badsyntax_future6", 3)
-
-    def test_badfuture7(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future7
-        self.check_syntax_error(cm.exception, "badsyntax_future7", 3, 54)
-
-    def test_badfuture8(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future8
-        self.check_syntax_error(cm.exception, "badsyntax_future8", 3)
-
-    def test_badfuture9(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future9
-        self.check_syntax_error(cm.exception, "badsyntax_future9", 3)
-
-    def test_badfuture10(self):
-        with self.assertRaises(SyntaxError) as cm:
-            from test import badsyntax_future10
-        self.check_syntax_error(cm.exception, "badsyntax_future10", 3)
-
-    def test_ensure_flags_dont_clash(self):
-        # bpo-39562: test that future flags and compiler flags doesn't clash
-
-        # obtain future flags (CO_FUTURE_***) from the __future__ module
-        flags = {
-            f"CO_FUTURE_{future.upper()}": getattr(__future__, future).compiler_flag
-            for future in __future__.all_feature_names
-        }
-        # obtain some of the exported compiler flags (PyCF_***) from the ast module
-        flags |= {
-            flag: getattr(ast, flag)
-            for flag in dir(ast) if flag.startswith("PyCF_")
-        }
-        self.assertCountEqual(set(flags.values()), flags.values())
-
-    def test_parserhack(self):
-        # test that the parser.c::future_hack function works as expected
-        # Note: although this test must pass, it's not testing the original
-        #       bug as of 2.6 since the with statement is not optional and
-        #       the parser hack disabled. If a new keyword is introduced in
-        #       2.6, change this to refer to the new future import.
-        try:
-            exec("from __future__ import print_function; print 0")
-        except SyntaxError:
-            pass
-        else:
-            self.fail("syntax error didn't occur")
-
-        try:
-            exec("from __future__ import (print_function); print 0")
-        except SyntaxError:
-            pass
-        else:
-            self.fail("syntax error didn't occur")
-
-    def test_multiple_features(self):
-        with import_helper.CleanImport("test.test_future5"):
-            from test import test_future5
-
-    def test_unicode_literals_exec(self):
-        scope = {}
-        exec("from __future__ import unicode_literals; x = ''", {}, scope)
-        self.assertIsInstance(scope["x"], str)
-
-    def test_syntactical_future_repl(self):
-        p = spawn_python('-i')
-        p.stdin.write(b"from __future__ import barry_as_FLUFL\n")
-        p.stdin.write(b"2 <> 3\n")
-        out = kill_python(p)
-        self.assertNotIn(b'SyntaxError: invalid syntax', out)
-
-class AnnotationsFutureTestCase(unittest.TestCase):
-    template = dedent(
-        """
-        from __future__ import annotations
-        def f() -> {ann}:
-            ...
-        def g(arg: {ann}) -> None:
-            ...
-        async def f2() -> {ann}:
-            ...
-        async def g2(arg: {ann}) -> None:
-            ...
-        class H:
-            var: {ann}
-            object.attr: {ann}
-        var: {ann}
-        var2: {ann} = None
-        object.attr: {ann}
-        """
-    )
-
-    def getActual(self, annotation):
-        scope = {}
-        exec(self.template.format(ann=annotation), {}, scope)
-        func_ret_ann = scope['f'].__annotations__['return']
-        func_arg_ann = scope['g'].__annotations__['arg']
-        async_func_ret_ann = scope['f2'].__annotations__['return']
-        async_func_arg_ann = scope['g2'].__annotations__['arg']
-        var_ann1 = scope['__annotations__']['var']
-        var_ann2 = scope['__annotations__']['var2']
-        self.assertEqual(func_ret_ann, func_arg_ann)
-        self.assertEqual(func_ret_ann, async_func_ret_ann)
-        self.assertEqual(func_ret_ann, async_func_arg_ann)
-        self.assertEqual(func_ret_ann, var_ann1)
-        self.assertEqual(func_ret_ann, var_ann2)
-        return func_ret_ann
-
-    def assertAnnotationEqual(
-        self, annotation, expected=None, drop_parens=False, is_tuple=False,
-    ):
-        actual = self.getActual(annotation)
-        if expected is None:
-            expected = annotation if not is_tuple else annotation[1:-1]
-        if drop_parens:
-            self.assertNotEqual(actual, expected)
-            actual = actual.replace("(", "").replace(")", "")
-
-        self.assertEqual(actual, expected)
-
-    def _exec_future(self, code):
-        scope = {}
-        exec(
-            "from __future__ import annotations\n"
-            + code, scope
-        )
-        return scope
-
-    def test_annotations(self):
-        eq = self.assertAnnotationEqual
-        eq('...')
-        eq("'some_string'")
-        eq("u'some_string'")
-        eq("b'\\xa3'")
-        eq('Name')
-        eq('None')
-        eq('True')
-        eq('False')
-        eq('1')
-        eq('1.0')
-        eq('1j')
-        eq('True or False')
-        eq('True or False or None')
-        eq('True and False')
-        eq('True and False and None')
-        eq('Name1 and Name2 or Name3')
-        eq('Name1 and (Name2 or Name3)')
-        eq('Name1 or Name2 and Name3')
-        eq('(Name1 or Name2) and Name3')
-        eq('Name1 and Name2 or Name3 and Name4')
-        eq('Name1 or Name2 and Name3 or Name4')
-        eq('a + b + (c + d)')
-        eq('a * b * (c * d)')
-        eq('(a ** b) ** c ** d')
-        eq('v1 << 2')
-        eq('1 >> v2')
-        eq('1 % finished')
-        eq('1 + v2 - v3 * 4 ^ 5 ** v6 / 7 // 8')
-        eq('not great')
-        eq('not not great')
-        eq('~great')
-        eq('+value')
-        eq('++value')
-        eq('-1')
-        eq('~int and not v1 ^ 123 + v2 | True')
-        eq('a + (not b)')
-        eq('lambda: None')
-        eq('lambda arg: None')
-        eq('lambda a=True: a')
-        eq('lambda a, b, c=True: a')
-        eq("lambda a, b, c=True, *, d=1 << v2, e='str': a")
-        eq("lambda a, b, c=True, *vararg, d, e='str', **kwargs: a + b")
-        eq("lambda a, /, b, c=True, *vararg, d, e='str', **kwargs: a + b")
-        eq('lambda x, /: x')
-        eq('lambda x=1, /: x')
-        eq('lambda x, /, y: x + y')
-        eq('lambda x=1, /, y=2: x + y')
-        eq('lambda x, /, y=1: x + y')
-        eq('lambda x, /, y=1, *, z=3: x + y + z')
-        eq('lambda x=1, /, y=2, *, z=3: x + y + z')
-        eq('lambda x=1, /, y=2, *, z: x + y + z')
-        eq('lambda x=1, y=2, z=3, /, w=4, *, l, l2: x + y + z + w + l + l2')
-        eq('lambda x=1, y=2, z=3, /, w=4, *, l, l2, **kwargs: x + y + z + w + l + l2')
-        eq('lambda x, /, y=1, *, z: x + y + z')
-        eq('lambda x: lambda y: x + y')
-        eq('1 if True else 2')
-        eq('str or None if int or True else str or bytes or None')
-        eq('str or None if (1 if True else 2) else str or bytes or None')
-        eq("0 if not x else 1 if x > 0 else -1")
-        eq("(1 if x > 0 else -1) if x else 0")
-        eq("{'2.7': dead, '3.7': long_live or die_hard}")
-        eq("{'2.7': dead, '3.7': long_live or die_hard, **{'3.6': verygood}}")
-        eq("{**a, **b, **c}")
-        eq("{'2.7', '3.6', '3.7', '3.8', '3.9', '4.0' if gilectomy else '3.10'}")
-        eq("{*a, *b, *c}")
-        eq("({'a': 'b'}, True or False, +value, 'string', b'bytes') or None")
-        eq("()")
-        eq("(a,)")
-        eq("(a, b)")
-        eq("(a, b, c)")
-        eq("(*a, *b, *c)")
-        eq("[]")
-        eq("[1, 2, 3, 4, 5, 6, 7, 8, 9, 10 or A, 11 or B, 12 or C]")
-        eq("[*a, *b, *c]")
-        eq("{i for i in (1, 2, 3)}")
-        eq("{i ** 2 for i in (1, 2, 3)}")
-        eq("{i ** 2 for i, _ in ((1, 'a'), (2, 'b'), (3, 'c'))}")
-        eq("{i ** 2 + j for i in (1, 2, 3) for j in (1, 2, 3)}")
-        eq("[i for i in (1, 2, 3)]")
-        eq("[i ** 2 for i in (1, 2, 3)]")
-        eq("[i ** 2 for i, _ in ((1, 'a'), (2, 'b'), (3, 'c'))]")
-        eq("[i ** 2 + j for i in (1, 2, 3) for j in (1, 2, 3)]")
-        eq("(i for i in (1, 2, 3))")
-        eq("(i ** 2 for i in (1, 2, 3))")
-        eq("(i ** 2 for i, _ in ((1, 'a'), (2, 'b'), (3, 'c')))")
-        eq("(i ** 2 + j for i in (1, 2, 3) for j in (1, 2, 3))")
-        eq("{i: 0 for i in (1, 2, 3)}")
-        eq("{i: j for i, j in ((1, 'a'), (2, 'b'), (3, 'c'))}")
-        eq("[(x, y) for x, y in (a, b)]")
-        eq("[(x,) for x, in (a,)]")
-        eq("Python3 > Python2 > COBOL")
-        eq("Life is Life")
-        eq("call()")
-        eq("call(arg)")
-        eq("call(kwarg='hey')")
-        eq("call(arg, kwarg='hey')")
-        eq("call(arg, *args, another, kwarg='hey')")
-        eq("call(arg, another, kwarg='hey', **kwargs, kwarg2='ho')")
-        eq("lukasz.langa.pl")
-        eq("call.me(maybe)")
-        eq("1 .real")
-        eq("1.0.real")
-        eq("....__class__")
-        eq("list[str]")
-        eq("dict[str, int]")
-        eq("set[str,]")
-        eq("tuple[()]")
-        eq("tuple[str, ...]")
-        eq("tuple[str, *types]")
-        eq("tuple[str, int, (str, int)]")
-        eq("tuple[*int, str, str, (str, int)]")
-        eq("tuple[str, int, float, dict[str, int]]")
-        eq("slice[0]")
-        eq("slice[0:1]")
-        eq("slice[0:1:2]")
-        eq("slice[:]")
-        eq("slice[:-1]")
-        eq("slice[1:]")
-        eq("slice[::-1]")
-        eq("slice[:,]")
-        eq("slice[1:2,]")
-        eq("slice[1:2:3,]")
-        eq("slice[1:2, 1]")
-        eq("slice[1:2, 2, 3]")
-        eq("slice[()]")
-        # Note that `slice[*Ts]`, `slice[*Ts,]`, and `slice[(*Ts,)]` all have
-        # the same AST, but only `slice[*Ts,]` passes this test, because that's
-        # what the unparser produces.
-        eq("slice[*Ts,]")
-        eq("slice[1, *Ts]")
-        eq("slice[*Ts, 2]")
-        eq("slice[1, *Ts, 2]")
-        eq("slice[*Ts, *Ts]")
-        eq("slice[1, *Ts, *Ts]")
-        eq("slice[*Ts, 1, *Ts]")
-        eq("slice[*Ts, *Ts, 1]")
-        eq("slice[1, *Ts, *Ts, 2]")
-        eq("slice[1:2, *Ts]")
-        eq("slice[*Ts, 1:2]")
-        eq("slice[1:2, *Ts, 3:4]")
-        eq("slice[a, b:c, d:e:f]")
-        eq("slice[(x for x in a)]")
-        eq('str or None if sys.version_info[0] > (3,) else str or bytes or None')
-        eq("f'f-string without formatted values is just a string'")
-        eq("f'{{NOT a formatted value}}'")
-        eq("f'some f-string with {a} {few():.2f} {formatted.values!r}'")
-        eq('''f"{f'{nested} inner'} outer"''')
-        eq("f'space between opening braces: { {a for a in (1, 2, 3)}}'")
-        eq("f'{(lambda x: x)}'")
-        eq("f'{(None if a else lambda x: x)}'")
-        eq("f'{x}'")
-        eq("f'{x!r}'")
-        eq("f'{x!a}'")
-        eq('[x for x in (a if b else c)]')
-        eq('[x for x in a if (b if c else d)]')
-        eq('f(x for x in a)')
-        eq('f(1, (x for x in a))')
-        eq('f((x for x in a), 2)')
-        eq('(((a)))', 'a')
-        eq('(((a, b)))', '(a, b)')
-        eq("1 + 2 + 3")
-
-    def test_fstring_debug_annotations(self):
-        # f-strings with '=' don't round trip very well, so set the expected
-        # result explicitly.
-        self.assertAnnotationEqual("f'{x=!r}'", expected="f'x={x!r}'")
-        self.assertAnnotationEqual("f'{x=:}'", expected="f'x={x:}'")
-        self.assertAnnotationEqual("f'{x=:.2f}'", expected="f'x={x:.2f}'")
-        self.assertAnnotationEqual("f'{x=!r}'", expected="f'x={x!r}'")
-        self.assertAnnotationEqual("f'{x=!a}'", expected="f'x={x!a}'")
-        self.assertAnnotationEqual("f'{x=!s:*^20}'", expected="f'x={x!s:*^20}'")
-
-    def test_infinity_numbers(self):
-        inf = "1e" + repr(sys.float_info.max_10_exp + 1)
-        infj = f"{inf}j"
-        self.assertAnnotationEqual("1e1000", expected=inf)
-        self.assertAnnotationEqual("1e1000j", expected=infj)
-        self.assertAnnotationEqual("-1e1000", expected=f"-{inf}")
-        self.assertAnnotationEqual("3+1e1000j", expected=f"3 + {infj}")
-        self.assertAnnotationEqual("(1e1000, 1e1000j)", expected=f"({inf}, {infj})")
-        self.assertAnnotationEqual("'inf'")
-        self.assertAnnotationEqual("('inf', 1e1000, 'infxxx', 1e1000j)", expected=f"('inf', {inf}, 'infxxx', {infj})")
-        self.assertAnnotationEqual("(1e1000, (1e1000j,))", expected=f"({inf}, ({infj},))")
-
-    def test_annotation_with_complex_target(self):
-        with self.assertRaises(SyntaxError):
-            exec(
-                "from __future__ import annotations\n"
-                "object.__debug__: int"
-            )
-
-    def test_annotations_symbol_table_pass(self):
-        namespace = self._exec_future(dedent("""
-        from __future__ import annotations
-
-        def foo():
-            outer = 1
-            def bar():
-                inner: outer = 1
-            return bar
-        """))
-
-        foo = namespace.pop("foo")
-        self.assertIsNone(foo().__closure__)
-        self.assertEqual(foo.__code__.co_cellvars, ())
-        self.assertEqual(foo().__code__.co_freevars, ())
-
-    def test_annotations_forbidden(self):
-        with self.assertRaises(SyntaxError):
-            self._exec_future("test: (yield)")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("test.test: (yield a + b)")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("test[something]: (yield from x)")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("def func(test: (yield from outside_of_generator)): pass")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("def test() -> (await y): pass")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("async def test() -> something((a := b)): pass")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("test: await some.complicated[0].call(with_args=True or 1 is not 1)")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future("test: f'{(x := 10):=10}'")
-
-        with self.assertRaises(SyntaxError):
-            self._exec_future(dedent("""\
-            def foo():
-                def bar(arg: (yield)): pass
-            """))
-
-    def test_get_type_hints_on_func_with_variadic_arg(self):
-        # `typing.get_type_hints` might break on a function with a variadic
-        # annotation (e.g. `f(*args: *Ts)`) if `from __future__ import
-        # annotations`, because it could try to evaluate `*Ts` as an expression,
-        # which on its own isn't value syntax.
-        namespace = self._exec_future(dedent("""\
-        class StarredC: pass
-        class C:
-          def __iter__(self):
-            yield StarredC()
-        c = C()
-        def f(*args: *c): pass
-        import typing
-        hints = typing.get_type_hints(f)
-        """))
-
-        hints = namespace.pop('hints')
-        self.assertIsInstance(hints['args'], namespace['StarredC'])
-
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_future3.py b/Lib/test/test_future3.py
deleted file mode 100644
index 09f1c78fa3..0000000000
--- a/Lib/test/test_future3.py
+++ /dev/null
@@ -1,26 +0,0 @@
-from __future__ import nested_scopes
-from __future__ import division
-
-import unittest
-
-x = 2
-def nester():
-    x = 3
-    def inner():
-        return x
-    return inner()
-
-
-class TestFuture(unittest.TestCase):
-
-    def test_floor_div_operator(self):
-        self.assertEqual(7 // 2, 3)
-
-    def test_true_div_as_default(self):
-        self.assertAlmostEqual(7 / 2, 3.5)
-
-    def test_nested_scopes(self):
-        self.assertEqual(nester(), 3)
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_future4.py b/Lib/test/test_future4.py
deleted file mode 100644
index b27ca40d2e..0000000000
--- a/Lib/test/test_future4.py
+++ /dev/null
@@ -1,11 +0,0 @@
-from __future__ import unicode_literals
-import unittest
-
-
-class Tests(unittest.TestCase):
-    def test_unicode_literals(self):
-        self.assertIsInstance("literal", str)
-
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_future5.py b/Lib/test/test_future5.py
deleted file mode 100644
index b44b97e63e..0000000000
--- a/Lib/test/test_future5.py
+++ /dev/null
@@ -1,21 +0,0 @@
-# Check that multiple features can be enabled.
-from __future__ import unicode_literals, print_function
-
-import sys
-import unittest
-from test import support
-
-
-class TestMultipleFeatures(unittest.TestCase):
-
-    def test_unicode_literals(self):
-        self.assertIsInstance("", str)
-
-    def test_print_function(self):
-        with support.captured_output("stderr") as s:
-            print("foo", file=sys.stderr)
-        self.assertEqual(s.getvalue(), "foo\n")
-
-
-if __name__ == '__main__':
-    unittest.main()
diff --git a/Lib/test/test_future_stmt/__init__.py b/Lib/test/test_future_stmt/__init__.py
new file mode 100644
index 0000000000..f2a39a3fe2
--- /dev/null
+++ b/Lib/test/test_future_stmt/__init__.py
@@ -0,0 +1,6 @@
+import os
+from test import support
+
+
+def load_tests(*args):
+    return support.load_package_tests(os.path.dirname(__file__), *args)
diff --git a/Lib/test/test_future_stmt/badsyntax_future10.py b/Lib/test/test_future_stmt/badsyntax_future10.py
new file mode 100644
index 0000000000..fa5ab67a98
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future10.py
@@ -0,0 +1,3 @@
+from __future__ import absolute_import
+"spam, bar, blah"
+from __future__ import print_function
diff --git a/Lib/test/test_future_stmt/badsyntax_future3.py b/Lib/test/test_future_stmt/badsyntax_future3.py
new file mode 100644
index 0000000000..f1c8417eda
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future3.py
@@ -0,0 +1,10 @@
+"""This is a test"""
+from __future__ import nested_scopes
+from __future__ import rested_snopes
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/badsyntax_future4.py b/Lib/test/test_future_stmt/badsyntax_future4.py
new file mode 100644
index 0000000000..b5f4c98e92
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future4.py
@@ -0,0 +1,10 @@
+"""This is a test"""
+import __future__
+from __future__ import nested_scopes
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/badsyntax_future5.py b/Lib/test/test_future_stmt/badsyntax_future5.py
new file mode 100644
index 0000000000..8a7e5fcb70
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future5.py
@@ -0,0 +1,12 @@
+"""This is a test"""
+from __future__ import nested_scopes
+import foo
+from __future__ import nested_scopes
+
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/badsyntax_future6.py b/Lib/test/test_future_stmt/badsyntax_future6.py
new file mode 100644
index 0000000000..5a8b55a02c
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future6.py
@@ -0,0 +1,10 @@
+"""This is a test"""
+"this isn't a doc string"
+from __future__ import nested_scopes
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/badsyntax_future7.py b/Lib/test/test_future_stmt/badsyntax_future7.py
new file mode 100644
index 0000000000..131db2c216
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future7.py
@@ -0,0 +1,11 @@
+"""This is a test"""
+
+from __future__ import nested_scopes; import string; from __future__ import \
+     nested_scopes
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/badsyntax_future8.py b/Lib/test/test_future_stmt/badsyntax_future8.py
new file mode 100644
index 0000000000..ca45289e2e
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future8.py
@@ -0,0 +1,10 @@
+"""This is a test"""
+
+from __future__ import *
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+print(f(2)(4))
diff --git a/Lib/test/test_future_stmt/badsyntax_future9.py b/Lib/test/test_future_stmt/badsyntax_future9.py
new file mode 100644
index 0000000000..916de06ab7
--- /dev/null
+++ b/Lib/test/test_future_stmt/badsyntax_future9.py
@@ -0,0 +1,10 @@
+"""This is a test"""
+
+from __future__ import nested_scopes, braces
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+print(f(2)(4))
diff --git a/Lib/test/test_future_stmt/future_test1.py b/Lib/test/test_future_stmt/future_test1.py
new file mode 100644
index 0000000000..297c2e087c
--- /dev/null
+++ b/Lib/test/test_future_stmt/future_test1.py
@@ -0,0 +1,11 @@
+"""This is a test"""
+
+# Import the name nested_scopes twice to trigger SF bug #407394 (regression).
+from __future__ import nested_scopes, nested_scopes
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/future_test2.py b/Lib/test/test_future_stmt/future_test2.py
new file mode 100644
index 0000000000..3d7fc860a3
--- /dev/null
+++ b/Lib/test/test_future_stmt/future_test2.py
@@ -0,0 +1,10 @@
+"""This is a test"""
+
+from __future__ import nested_scopes; import site
+
+def f(x):
+    def g(y):
+        return x + y
+    return g
+
+result = f(2)(4)
diff --git a/Lib/test/test_future_stmt/test_future.py b/Lib/test/test_future_stmt/test_future.py
new file mode 100644
index 0000000000..8e67bcd72c
--- /dev/null
+++ b/Lib/test/test_future_stmt/test_future.py
@@ -0,0 +1,460 @@
+# Test various flavors of legal and illegal future statements
+
+import __future__
+import ast
+import unittest
+from test.support import import_helper
+from test.support.script_helper import spawn_python, kill_python
+from textwrap import dedent
+import os
+import re
+import sys
+
+rx = re.compile(r'\((\S+).py, line (\d+)')
+
+def get_error_location(msg):
+    mo = rx.search(str(msg))
+    return mo.group(1, 2)
+
+class FutureTest(unittest.TestCase):
+
+    def check_syntax_error(self, err, basename, lineno, offset=1):
+        self.assertIn('%s.py, line %d' % (basename, lineno), str(err))
+        self.assertEqual(os.path.basename(err.filename), basename + '.py')
+        self.assertEqual(err.lineno, lineno)
+        self.assertEqual(err.offset, offset)
+
+    def test_future1(self):
+        with import_helper.CleanImport('test.test_future_stmt.future_test1'):
+            from test.test_future_stmt import future_test1
+            self.assertEqual(future_test1.result, 6)
+
+    def test_future2(self):
+        with import_helper.CleanImport('test.test_future_stmt.future_test2'):
+            from test.test_future_stmt import future_test2
+            self.assertEqual(future_test2.result, 6)
+
+    def test_future_single_import(self):
+        with import_helper.CleanImport(
+            'test.test_future_stmt.test_future_single_import',
+        ):
+            from test.test_future_stmt import test_future_single_import
+
+    def test_future_multiple_imports(self):
+        with import_helper.CleanImport(
+            'test.test_future_stmt.test_future_multiple_imports',
+        ):
+            from test.test_future_stmt import test_future_multiple_imports
+
+    def test_future_multiple_features(self):
+        with import_helper.CleanImport(
+            "test.test_future_stmt.test_future_multiple_features",
+        ):
+            from test.test_future_stmt import test_future_multiple_features
+
+    def test_badfuture3(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future3
+        self.check_syntax_error(cm.exception, "badsyntax_future3", 3)
+
+    def test_badfuture4(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future4
+        self.check_syntax_error(cm.exception, "badsyntax_future4", 3)
+
+    def test_badfuture5(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future5
+        self.check_syntax_error(cm.exception, "badsyntax_future5", 4)
+
+    def test_badfuture6(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future6
+        self.check_syntax_error(cm.exception, "badsyntax_future6", 3)
+
+    def test_badfuture7(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future7
+        self.check_syntax_error(cm.exception, "badsyntax_future7", 3, 54)
+
+    def test_badfuture8(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future8
+        self.check_syntax_error(cm.exception, "badsyntax_future8", 3)
+
+    def test_badfuture9(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future9
+        self.check_syntax_error(cm.exception, "badsyntax_future9", 3)
+
+    def test_badfuture10(self):
+        with self.assertRaises(SyntaxError) as cm:
+            from test.test_future_stmt import badsyntax_future10
+        self.check_syntax_error(cm.exception, "badsyntax_future10", 3)
+
+    def test_ensure_flags_dont_clash(self):
+        # bpo-39562: test that future flags and compiler flags doesn't clash
+
+        # obtain future flags (CO_FUTURE_***) from the __future__ module
+        flags = {
+            f"CO_FUTURE_{future.upper()}": getattr(__future__, future).compiler_flag
+            for future in __future__.all_feature_names
+        }
+        # obtain some of the exported compiler flags (PyCF_***) from the ast module
+        flags |= {
+            flag: getattr(ast, flag)
+            for flag in dir(ast) if flag.startswith("PyCF_")
+        }
+        self.assertCountEqual(set(flags.values()), flags.values())
+
+    def test_parserhack(self):
+        # test that the parser.c::future_hack function works as expected
+        # Note: although this test must pass, it's not testing the original
+        #       bug as of 2.6 since the with statement is not optional and
+        #       the parser hack disabled. If a new keyword is introduced in
+        #       2.6, change this to refer to the new future import.
+        try:
+            exec("from __future__ import print_function; print 0")
+        except SyntaxError:
+            pass
+        else:
+            self.fail("syntax error didn't occur")
+
+        try:
+            exec("from __future__ import (print_function); print 0")
+        except SyntaxError:
+            pass
+        else:
+            self.fail("syntax error didn't occur")
+
+    def test_unicode_literals_exec(self):
+        scope = {}
+        exec("from __future__ import unicode_literals; x = ''", {}, scope)
+        self.assertIsInstance(scope["x"], str)
+
+    def test_syntactical_future_repl(self):
+        p = spawn_python('-i')
+        p.stdin.write(b"from __future__ import barry_as_FLUFL\n")
+        p.stdin.write(b"2 <> 3\n")
+        out = kill_python(p)
+        self.assertNotIn(b'SyntaxError: invalid syntax', out)
+
+class AnnotationsFutureTestCase(unittest.TestCase):
+    template = dedent(
+        """
+        from __future__ import annotations
+        def f() -> {ann}:
+            ...
+        def g(arg: {ann}) -> None:
+            ...
+        async def f2() -> {ann}:
+            ...
+        async def g2(arg: {ann}) -> None:
+            ...
+        class H:
+            var: {ann}
+            object.attr: {ann}
+        var: {ann}
+        var2: {ann} = None
+        object.attr: {ann}
+        """
+    )
+
+    def getActual(self, annotation):
+        scope = {}
+        exec(self.template.format(ann=annotation), {}, scope)
+        func_ret_ann = scope['f'].__annotations__['return']
+        func_arg_ann = scope['g'].__annotations__['arg']
+        async_func_ret_ann = scope['f2'].__annotations__['return']
+        async_func_arg_ann = scope['g2'].__annotations__['arg']
+        var_ann1 = scope['__annotations__']['var']
+        var_ann2 = scope['__annotations__']['var2']
+        self.assertEqual(func_ret_ann, func_arg_ann)
+        self.assertEqual(func_ret_ann, async_func_ret_ann)
+        self.assertEqual(func_ret_ann, async_func_arg_ann)
+        self.assertEqual(func_ret_ann, var_ann1)
+        self.assertEqual(func_ret_ann, var_ann2)
+        return func_ret_ann
+
+    def assertAnnotationEqual(
+        self, annotation, expected=None, drop_parens=False, is_tuple=False,
+    ):
+        actual = self.getActual(annotation)
+        if expected is None:
+            expected = annotation if not is_tuple else annotation[1:-1]
+        if drop_parens:
+            self.assertNotEqual(actual, expected)
+            actual = actual.replace("(", "").replace(")", "")
+
+        self.assertEqual(actual, expected)
+
+    def _exec_future(self, code):
+        scope = {}
+        exec(
+            "from __future__ import annotations\n"
+            + code, scope
+        )
+        return scope
+
+    def test_annotations(self):
+        eq = self.assertAnnotationEqual
+        eq('...')
+        eq("'some_string'")
+        eq("u'some_string'")
+        eq("b'\\xa3'")
+        eq('Name')
+        eq('None')
+        eq('True')
+        eq('False')
+        eq('1')
+        eq('1.0')
+        eq('1j')
+        eq('True or False')
+        eq('True or False or None')
+        eq('True and False')
+        eq('True and False and None')
+        eq('Name1 and Name2 or Name3')
+        eq('Name1 and (Name2 or Name3)')
+        eq('Name1 or Name2 and Name3')
+        eq('(Name1 or Name2) and Name3')
+        eq('Name1 and Name2 or Name3 and Name4')
+        eq('Name1 or Name2 and Name3 or Name4')
+        eq('a + b + (c + d)')
+        eq('a * b * (c * d)')
+        eq('(a ** b) ** c ** d')
+        eq('v1 << 2')
+        eq('1 >> v2')
+        eq('1 % finished')
+        eq('1 + v2 - v3 * 4 ^ 5 ** v6 / 7 // 8')
+        eq('not great')
+        eq('not not great')
+        eq('~great')
+        eq('+value')
+        eq('++value')
+        eq('-1')
+        eq('~int and not v1 ^ 123 + v2 | True')
+        eq('a + (not b)')
+        eq('lambda: None')
+        eq('lambda arg: None')
+        eq('lambda a=True: a')
+        eq('lambda a, b, c=True: a')
+        eq("lambda a, b, c=True, *, d=1 << v2, e='str': a")
+        eq("lambda a, b, c=True, *vararg, d, e='str', **kwargs: a + b")
+        eq("lambda a, /, b, c=True, *vararg, d, e='str', **kwargs: a + b")
+        eq('lambda x, /: x')
+        eq('lambda x=1, /: x')
+        eq('lambda x, /, y: x + y')
+        eq('lambda x=1, /, y=2: x + y')
+        eq('lambda x, /, y=1: x + y')
+        eq('lambda x, /, y=1, *, z=3: x + y + z')
+        eq('lambda x=1, /, y=2, *, z=3: x + y + z')
+        eq('lambda x=1, /, y=2, *, z: x + y + z')
+        eq('lambda x=1, y=2, z=3, /, w=4, *, l, l2: x + y + z + w + l + l2')
+        eq('lambda x=1, y=2, z=3, /, w=4, *, l, l2, **kwargs: x + y + z + w + l + l2')
+        eq('lambda x, /, y=1, *, z: x + y + z')
+        eq('lambda x: lambda y: x + y')
+        eq('1 if True else 2')
+        eq('str or None if int or True else str or bytes or None')
+        eq('str or None if (1 if True else 2) else str or bytes or None')
+        eq("0 if not x else 1 if x > 0 else -1")
+        eq("(1 if x > 0 else -1) if x else 0")
+        eq("{'2.7': dead, '3.7': long_live or die_hard}")
+        eq("{'2.7': dead, '3.7': long_live or die_hard, **{'3.6': verygood}}")
+        eq("{**a, **b, **c}")
+        eq("{'2.7', '3.6', '3.7', '3.8', '3.9', '4.0' if gilectomy else '3.10'}")
+        eq("{*a, *b, *c}")
+        eq("({'a': 'b'}, True or False, +value, 'string', b'bytes') or None")
+        eq("()")
+        eq("(a,)")
+        eq("(a, b)")
+        eq("(a, b, c)")
+        eq("(*a, *b, *c)")
+        eq("[]")
+        eq("[1, 2, 3, 4, 5, 6, 7, 8, 9, 10 or A, 11 or B, 12 or C]")
+        eq("[*a, *b, *c]")
+        eq("{i for i in (1, 2, 3)}")
+        eq("{i ** 2 for i in (1, 2, 3)}")
+        eq("{i ** 2 for i, _ in ((1, 'a'), (2, 'b'), (3, 'c'))}")
+        eq("{i ** 2 + j for i in (1, 2, 3) for j in (1, 2, 3)}")
+        eq("[i for i in (1, 2, 3)]")
+        eq("[i ** 2 for i in (1, 2, 3)]")
+        eq("[i ** 2 for i, _ in ((1, 'a'), (2, 'b'), (3, 'c'))]")
+        eq("[i ** 2 + j for i in (1, 2, 3) for j in (1, 2, 3)]")
+        eq("(i for i in (1, 2, 3))")
+        eq("(i ** 2 for i in (1, 2, 3))")
+        eq("(i ** 2 for i, _ in ((1, 'a'), (2, 'b'), (3, 'c')))")
+        eq("(i ** 2 + j for i in (1, 2, 3) for j in (1, 2, 3))")
+        eq("{i: 0 for i in (1, 2, 3)}")
+        eq("{i: j for i, j in ((1, 'a'), (2, 'b'), (3, 'c'))}")
+        eq("[(x, y) for x, y in (a, b)]")
+        eq("[(x,) for x, in (a,)]")
+        eq("Python3 > Python2 > COBOL")
+        eq("Life is Life")
+        eq("call()")
+        eq("call(arg)")
+        eq("call(kwarg='hey')")
+        eq("call(arg, kwarg='hey')")
+        eq("call(arg, *args, another, kwarg='hey')")
+        eq("call(arg, another, kwarg='hey', **kwargs, kwarg2='ho')")
+        eq("lukasz.langa.pl")
+        eq("call.me(maybe)")
+        eq("1 .real")
+        eq("1.0.real")
+        eq("....__class__")
+        eq("list[str]")
+        eq("dict[str, int]")
+        eq("set[str,]")
+        eq("tuple[()]")
+        eq("tuple[str, ...]")
+        eq("tuple[str, *types]")
+        eq("tuple[str, int, (str, int)]")
+        eq("tuple[*int, str, str, (str, int)]")
+        eq("tuple[str, int, float, dict[str, int]]")
+        eq("slice[0]")
+        eq("slice[0:1]")
+        eq("slice[0:1:2]")
+        eq("slice[:]")
+        eq("slice[:-1]")
+        eq("slice[1:]")
+        eq("slice[::-1]")
+        eq("slice[:,]")
+        eq("slice[1:2,]")
+        eq("slice[1:2:3,]")
+        eq("slice[1:2, 1]")
+        eq("slice[1:2, 2, 3]")
+        eq("slice[()]")
+        # Note that `slice[*Ts]`, `slice[*Ts,]`, and `slice[(*Ts,)]` all have
+        # the same AST, but only `slice[*Ts,]` passes this test, because that's
+        # what the unparser produces.
+        eq("slice[*Ts,]")
+        eq("slice[1, *Ts]")
+        eq("slice[*Ts, 2]")
+        eq("slice[1, *Ts, 2]")
+        eq("slice[*Ts, *Ts]")
+        eq("slice[1, *Ts, *Ts]")
+        eq("slice[*Ts, 1, *Ts]")
+        eq("slice[*Ts, *Ts, 1]")
+        eq("slice[1, *Ts, *Ts, 2]")
+        eq("slice[1:2, *Ts]")
+        eq("slice[*Ts, 1:2]")
+        eq("slice[1:2, *Ts, 3:4]")
+        eq("slice[a, b:c, d:e:f]")
+        eq("slice[(x for x in a)]")
+        eq('str or None if sys.version_info[0] > (3,) else str or bytes or None')
+        eq("f'f-string without formatted values is just a string'")
+        eq("f'{{NOT a formatted value}}'")
+        eq("f'some f-string with {a} {few():.2f} {formatted.values!r}'")
+        eq('''f"{f'{nested} inner'} outer"''')
+        eq("f'space between opening braces: { {a for a in (1, 2, 3)}}'")
+        eq("f'{(lambda x: x)}'")
+        eq("f'{(None if a else lambda x: x)}'")
+        eq("f'{x}'")
+        eq("f'{x!r}'")
+        eq("f'{x!a}'")
+        eq('[x for x in (a if b else c)]')
+        eq('[x for x in a if (b if c else d)]')
+        eq('f(x for x in a)')
+        eq('f(1, (x for x in a))')
+        eq('f((x for x in a), 2)')
+        eq('(((a)))', 'a')
+        eq('(((a, b)))', '(a, b)')
+        eq("1 + 2 + 3")
+
+    def test_fstring_debug_annotations(self):
+        # f-strings with '=' don't round trip very well, so set the expected
+        # result explicitly.
+        self.assertAnnotationEqual("f'{x=!r}'", expected="f'x={x!r}'")
+        self.assertAnnotationEqual("f'{x=:}'", expected="f'x={x:}'")
+        self.assertAnnotationEqual("f'{x=:.2f}'", expected="f'x={x:.2f}'")
+        self.assertAnnotationEqual("f'{x=!r}'", expected="f'x={x!r}'")
+        self.assertAnnotationEqual("f'{x=!a}'", expected="f'x={x!a}'")
+        self.assertAnnotationEqual("f'{x=!s:*^20}'", expected="f'x={x!s:*^20}'")
+
+    def test_infinity_numbers(self):
+        inf = "1e" + repr(sys.float_info.max_10_exp + 1)
+        infj = f"{inf}j"
+        self.assertAnnotationEqual("1e1000", expected=inf)
+        self.assertAnnotationEqual("1e1000j", expected=infj)
+        self.assertAnnotationEqual("-1e1000", expected=f"-{inf}")
+        self.assertAnnotationEqual("3+1e1000j", expected=f"3 + {infj}")
+        self.assertAnnotationEqual("(1e1000, 1e1000j)", expected=f"({inf}, {infj})")
+        self.assertAnnotationEqual("'inf'")
+        self.assertAnnotationEqual("('inf', 1e1000, 'infxxx', 1e1000j)", expected=f"('inf', {inf}, 'infxxx', {infj})")
+        self.assertAnnotationEqual("(1e1000, (1e1000j,))", expected=f"({inf}, ({infj},))")
+
+    def test_annotation_with_complex_target(self):
+        with self.assertRaises(SyntaxError):
+            exec(
+                "from __future__ import annotations\n"
+                "object.__debug__: int"
+            )
+
+    def test_annotations_symbol_table_pass(self):
+        namespace = self._exec_future(dedent("""
+        from __future__ import annotations
+
+        def foo():
+            outer = 1
+            def bar():
+                inner: outer = 1
+            return bar
+        """))
+
+        foo = namespace.pop("foo")
+        self.assertIsNone(foo().__closure__)
+        self.assertEqual(foo.__code__.co_cellvars, ())
+        self.assertEqual(foo().__code__.co_freevars, ())
+
+    def test_annotations_forbidden(self):
+        with self.assertRaises(SyntaxError):
+            self._exec_future("test: (yield)")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("test.test: (yield a + b)")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("test[something]: (yield from x)")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("def func(test: (yield from outside_of_generator)): pass")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("def test() -> (await y): pass")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("async def test() -> something((a := b)): pass")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("test: await some.complicated[0].call(with_args=True or 1 is not 1)")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future("test: f'{(x := 10):=10}'")
+
+        with self.assertRaises(SyntaxError):
+            self._exec_future(dedent("""\
+            def foo():
+                def bar(arg: (yield)): pass
+            """))
+
+    def test_get_type_hints_on_func_with_variadic_arg(self):
+        # `typing.get_type_hints` might break on a function with a variadic
+        # annotation (e.g. `f(*args: *Ts)`) if `from __future__ import
+        # annotations`, because it could try to evaluate `*Ts` as an expression,
+        # which on its own isn't value syntax.
+        namespace = self._exec_future(dedent("""\
+        class StarredC: pass
+        class C:
+          def __iter__(self):
+            yield StarredC()
+        c = C()
+        def f(*args: *c): pass
+        import typing
+        hints = typing.get_type_hints(f)
+        """))
+
+        hints = namespace.pop('hints')
+        self.assertIsInstance(hints['args'], namespace['StarredC'])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_future_stmt/test_future_flags.py b/Lib/test/test_future_stmt/test_future_flags.py
new file mode 100644
index 0000000000..559a1873ad
--- /dev/null
+++ b/Lib/test/test_future_stmt/test_future_flags.py
@@ -0,0 +1,61 @@
+import unittest
+import __future__
+
+GOOD_SERIALS = ("alpha", "beta", "candidate", "final")
+
+features = __future__.all_feature_names
+
+class FutureTest(unittest.TestCase):
+
+    def test_names(self):
+        # Verify that all_feature_names appears correct.
+        given_feature_names = features[:]
+        for name in dir(__future__):
+            obj = getattr(__future__, name, None)
+            if obj is not None and isinstance(obj, __future__._Feature):
+                self.assertTrue(
+                    name in given_feature_names,
+                    "%r should have been in all_feature_names" % name
+                )
+                given_feature_names.remove(name)
+        self.assertEqual(len(given_feature_names), 0,
+               "all_feature_names has too much: %r" % given_feature_names)
+
+    def test_attributes(self):
+        for feature in features:
+            value = getattr(__future__, feature)
+
+            optional = value.getOptionalRelease()
+            mandatory = value.getMandatoryRelease()
+
+            a = self.assertTrue
+            e = self.assertEqual
+            def check(t, name):
+                a(isinstance(t, tuple), "%s isn't tuple" % name)
+                e(len(t), 5, "%s isn't 5-tuple" % name)
+                (major, minor, micro, level, serial) = t
+                a(isinstance(major, int), "%s major isn't int"  % name)
+                a(isinstance(minor, int), "%s minor isn't int" % name)
+                a(isinstance(micro, int), "%s micro isn't int" % name)
+                a(isinstance(level, str),
+                    "%s level isn't string" % name)
+                a(level in GOOD_SERIALS,
+                       "%s level string has unknown value" % name)
+                a(isinstance(serial, int), "%s serial isn't int" % name)
+
+            check(optional, "optional")
+            if mandatory is not None:
+                check(mandatory, "mandatory")
+                a(optional < mandatory,
+                       "optional not less than mandatory, and mandatory not None")
+
+            a(hasattr(value, "compiler_flag"),
+                   "feature is missing a .compiler_flag attr")
+            # Make sure the compile accepts the flag.
+            compile("", "<test>", "exec", value.compiler_flag)
+            a(isinstance(getattr(value, "compiler_flag"), int),
+                   ".compiler_flag isn't int")
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_future_stmt/test_future_multiple_features.py b/Lib/test/test_future_stmt/test_future_multiple_features.py
new file mode 100644
index 0000000000..b44b97e63e
--- /dev/null
+++ b/Lib/test/test_future_stmt/test_future_multiple_features.py
@@ -0,0 +1,21 @@
+# Check that multiple features can be enabled.
+from __future__ import unicode_literals, print_function
+
+import sys
+import unittest
+from test import support
+
+
+class TestMultipleFeatures(unittest.TestCase):
+
+    def test_unicode_literals(self):
+        self.assertIsInstance("", str)
+
+    def test_print_function(self):
+        with support.captured_output("stderr") as s:
+            print("foo", file=sys.stderr)
+        self.assertEqual(s.getvalue(), "foo\n")
+
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/Lib/test/test_future_stmt/test_future_multiple_imports.py b/Lib/test/test_future_stmt/test_future_multiple_imports.py
new file mode 100644
index 0000000000..b27ca40d2e
--- /dev/null
+++ b/Lib/test/test_future_stmt/test_future_multiple_imports.py
@@ -0,0 +1,11 @@
+from __future__ import unicode_literals
+import unittest
+
+
+class Tests(unittest.TestCase):
+    def test_unicode_literals(self):
+        self.assertIsInstance("literal", str)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_future_stmt/test_future_single_import.py b/Lib/test/test_future_stmt/test_future_single_import.py
new file mode 100644
index 0000000000..09f1c78fa3
--- /dev/null
+++ b/Lib/test/test_future_stmt/test_future_single_import.py
@@ -0,0 +1,26 @@
+from __future__ import nested_scopes
+from __future__ import division
+
+import unittest
+
+x = 2
+def nester():
+    x = 3
+    def inner():
+        return x
+    return inner()
+
+
+class TestFuture(unittest.TestCase):
+
+    def test_floor_div_operator(self):
+        self.assertEqual(7 // 2, 3)
+
+    def test_true_div_as_default(self):
+        self.assertAlmostEqual(7 / 2, 3.5)
+
+    def test_nested_scopes(self):
+        self.assertEqual(nester(), 3)
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_gdb.py b/Lib/test/test_gdb.py
deleted file mode 100644
index b99e0abaa5..0000000000
--- a/Lib/test/test_gdb.py
+++ /dev/null
@@ -1,1066 +0,0 @@
-# Verify that gdb can pretty-print the various PyObject* types
-#
-# The code for testing gdb was adapted from similar work in Unladen Swallow's
-# Lib/test/test_jit_gdb.py
-
-import os
-import platform
-import re
-import subprocess
-import sys
-import sysconfig
-import textwrap
-import unittest
-
-from test import support
-from test.support import findfile, python_is_optimized
-
-def get_gdb_version():
-    try:
-        cmd = ["gdb", "-nx", "--version"]
-        proc = subprocess.Popen(cmd,
-                                stdout=subprocess.PIPE,
-                                stderr=subprocess.PIPE,
-                                universal_newlines=True)
-        with proc:
-            version, stderr = proc.communicate()
-
-        if proc.returncode:
-            raise Exception(f"Command {' '.join(cmd)!r} failed "
-                            f"with exit code {proc.returncode}: "
-                            f"stdout={version!r} stderr={stderr!r}")
-    except OSError:
-        # This is what "no gdb" looks like.  There may, however, be other
-        # errors that manifest this way too.
-        raise unittest.SkipTest("Couldn't find gdb on the path")
-
-    # Regex to parse:
-    # 'GNU gdb (GDB; SUSE Linux Enterprise 12) 7.7\n' -> 7.7
-    # 'GNU gdb (GDB) Fedora 7.9.1-17.fc22\n' -> 7.9
-    # 'GNU gdb 6.1.1 [FreeBSD]\n' -> 6.1
-    # 'GNU gdb (GDB) Fedora (7.5.1-37.fc18)\n' -> 7.5
-    # 'HP gdb 6.7 for HP Itanium (32 or 64 bit) and target HP-UX 11iv2 and 11iv3.\n' -> 6.7
-    match = re.search(r"^(?:GNU|HP) gdb.*?\b(\d+)\.(\d+)", version)
-    if match is None:
-        raise Exception("unable to parse GDB version: %r" % version)
-    return (version, int(match.group(1)), int(match.group(2)))
-
-gdb_version, gdb_major_version, gdb_minor_version = get_gdb_version()
-if gdb_major_version < 7:
-    raise unittest.SkipTest("gdb versions before 7.0 didn't support python "
-                            "embedding. Saw %s.%s:\n%s"
-                            % (gdb_major_version, gdb_minor_version,
-                               gdb_version))
-
-if not sysconfig.is_python_build():
-    raise unittest.SkipTest("test_gdb only works on source builds at the moment.")
-
-if ((sysconfig.get_config_var('PGO_PROF_USE_FLAG') or 'xxx') in
-    (sysconfig.get_config_var('PY_CORE_CFLAGS') or '')):
-    raise unittest.SkipTest("test_gdb is not reliable on PGO builds")
-
-# Location of custom hooks file in a repository checkout.
-checkout_hook_path = os.path.join(os.path.dirname(sys.executable),
-                                  'python-gdb.py')
-
-PYTHONHASHSEED = '123'
-
-
-def cet_protection():
-    cflags = sysconfig.get_config_var('CFLAGS')
-    if not cflags:
-        return False
-    flags = cflags.split()
-    # True if "-mcet -fcf-protection" options are found, but false
-    # if "-fcf-protection=none" or "-fcf-protection=return" is found.
-    return (('-mcet' in flags)
-            and any((flag.startswith('-fcf-protection')
-                     and not flag.endswith(("=none", "=return")))
-                    for flag in flags))
-
-# Control-flow enforcement technology
-CET_PROTECTION = cet_protection()
-
-
-def run_gdb(*args, **env_vars):
-    """Runs gdb in --batch mode with the additional arguments given by *args.
-
-    Returns its (stdout, stderr) decoded from utf-8 using the replace handler.
-    """
-    if env_vars:
-        env = os.environ.copy()
-        env.update(env_vars)
-    else:
-        env = None
-    # -nx: Do not execute commands from any .gdbinit initialization files
-    #      (issue #22188)
-    base_cmd = ('gdb', '--batch', '-nx')
-    if (gdb_major_version, gdb_minor_version) >= (7, 4):
-        base_cmd += ('-iex', 'add-auto-load-safe-path ' + checkout_hook_path)
-    proc = subprocess.Popen(base_cmd + args,
-                            # Redirect stdin to prevent GDB from messing with
-                            # the terminal settings
-                            stdin=subprocess.PIPE,
-                            stdout=subprocess.PIPE,
-                            stderr=subprocess.PIPE,
-                            env=env)
-    with proc:
-        out, err = proc.communicate()
-    return out.decode('utf-8', 'replace'), err.decode('utf-8', 'replace')
-
-# Verify that "gdb" was built with the embedded python support enabled:
-gdbpy_version, _ = run_gdb("--eval-command=python import sys; print(sys.version_info)")
-if not gdbpy_version:
-    raise unittest.SkipTest("gdb not built with embedded python support")
-
-if "major=2" in gdbpy_version:
-    raise unittest.SkipTest("gdb built with Python 2")
-
-# Verify that "gdb" can load our custom hooks, as OS security settings may
-# disallow this without a customized .gdbinit.
-_, gdbpy_errors = run_gdb('--args', sys.executable)
-if "auto-loading has been declined" in gdbpy_errors:
-    msg = "gdb security settings prevent use of custom hooks: "
-    raise unittest.SkipTest(msg + gdbpy_errors.rstrip())
-
-def gdb_has_frame_select():
-    # Does this build of gdb have gdb.Frame.select ?
-    stdout, _ = run_gdb("--eval-command=python print(dir(gdb.Frame))")
-    m = re.match(r'.*\[(.*)\].*', stdout)
-    if not m:
-        raise unittest.SkipTest("Unable to parse output from gdb.Frame.select test")
-    gdb_frame_dir = m.group(1).split(', ')
-    return "'select'" in gdb_frame_dir
-
-HAS_PYUP_PYDOWN = gdb_has_frame_select()
-
-BREAKPOINT_FN='builtin_id'
-
-@unittest.skipIf(support.PGO, "not useful for PGO")
-class DebuggerTests(unittest.TestCase):
-
-    """Test that the debugger can debug Python."""
-
-    def get_stack_trace(self, source=None, script=None,
-                        breakpoint=BREAKPOINT_FN,
-                        cmds_after_breakpoint=None,
-                        import_site=False,
-                        ignore_stderr=False):
-        '''
-        Run 'python -c SOURCE' under gdb with a breakpoint.
-
-        Support injecting commands after the breakpoint is reached
-
-        Returns the stdout from gdb
-
-        cmds_after_breakpoint: if provided, a list of strings: gdb commands
-        '''
-        # We use "set breakpoint pending yes" to avoid blocking with a:
-        #   Function "foo" not defined.
-        #   Make breakpoint pending on future shared library load? (y or [n])
-        # error, which typically happens python is dynamically linked (the
-        # breakpoints of interest are to be found in the shared library)
-        # When this happens, we still get:
-        #   Function "textiowrapper_write" not defined.
-        # emitted to stderr each time, alas.
-
-        # Initially I had "--eval-command=continue" here, but removed it to
-        # avoid repeated print breakpoints when traversing hierarchical data
-        # structures
-
-        # Generate a list of commands in gdb's language:
-        commands = ['set breakpoint pending yes',
-                    'break %s' % breakpoint,
-
-                    # The tests assume that the first frame of printed
-                    #  backtrace will not contain program counter,
-                    #  that is however not guaranteed by gdb
-                    #  therefore we need to use 'set print address off' to
-                    #  make sure the counter is not there. For example:
-                    # #0 in PyObject_Print ...
-                    #  is assumed, but sometimes this can be e.g.
-                    # #0 0x00003fffb7dd1798 in PyObject_Print ...
-                    'set print address off',
-
-                    'run']
-
-        # GDB as of 7.4 onwards can distinguish between the
-        # value of a variable at entry vs current value:
-        #   http://sourceware.org/gdb/onlinedocs/gdb/Variables.html
-        # which leads to the selftests failing with errors like this:
-        #   AssertionError: 'v@entry=()' != '()'
-        # Disable this:
-        if (gdb_major_version, gdb_minor_version) >= (7, 4):
-            commands += ['set print entry-values no']
-
-        if cmds_after_breakpoint:
-            if CET_PROTECTION:
-                # bpo-32962: When Python is compiled with -mcet
-                # -fcf-protection, function arguments are unusable before
-                # running the first instruction of the function entry point.
-                # The 'next' command makes the required first step.
-                commands += ['next']
-            commands += cmds_after_breakpoint
-        else:
-            commands += ['backtrace']
-
-        # print commands
-
-        # Use "commands" to generate the arguments with which to invoke "gdb":
-        args = ['--eval-command=%s' % cmd for cmd in commands]
-        args += ["--args",
-                 sys.executable]
-        args.extend(subprocess._args_from_interpreter_flags())
-
-        if not import_site:
-            # -S suppresses the default 'import site'
-            args += ["-S"]
-
-        if source:
-            args += ["-c", source]
-        elif script:
-            args += [script]
-
-        # Use "args" to invoke gdb, capturing stdout, stderr:
-        out, err = run_gdb(*args, PYTHONHASHSEED=PYTHONHASHSEED)
-
-        if not ignore_stderr:
-            for line in err.splitlines():
-                print(line, file=sys.stderr)
-
-        # bpo-34007: Sometimes some versions of the shared libraries that
-        # are part of the traceback are compiled in optimised mode and the
-        # Program Counter (PC) is not present, not allowing gdb to walk the
-        # frames back. When this happens, the Python bindings of gdb raise
-        # an exception, making the test impossible to succeed.
-        if "PC not saved" in err:
-            raise unittest.SkipTest("gdb cannot walk the frame object"
-                                    " because the Program Counter is"
-                                    " not present")
-
-        # bpo-40019: Skip the test if gdb failed to read debug information
-        # because the Python binary is optimized.
-        for pattern in (
-            '(frame information optimized out)',
-            'Unable to read information on python frame',
-            # gh-91960: On Python built with "clang -Og", gdb gets
-            # "frame=<optimized out>" for _PyEval_EvalFrameDefault() parameter
-            '(unable to read python frame information)',
-            # gh-104736: On Python built with "clang -Og" on ppc64le,
-            # "py-bt" displays a truncated or not traceback, but "where"
-            # logs this error message:
-            'Backtrace stopped: frame did not save the PC',
-            # gh-104736: When "bt" command displays something like:
-            # "#1  0x0000000000000000 in ?? ()", the traceback is likely
-            # truncated or wrong.
-            ' ?? ()',
-        ):
-            if pattern in out:
-                raise unittest.SkipTest(f"{pattern!r} found in gdb output")
-
-        return out
-
-    def get_gdb_repr(self, source,
-                     cmds_after_breakpoint=None,
-                     import_site=False):
-        # Given an input python source representation of data,
-        # run "python -c'id(DATA)'" under gdb with a breakpoint on
-        # builtin_id and scrape out gdb's representation of the "op"
-        # parameter, and verify that the gdb displays the same string
-        #
-        # Verify that the gdb displays the expected string
-        #
-        # For a nested structure, the first time we hit the breakpoint will
-        # give us the top-level structure
-
-        # NOTE: avoid decoding too much of the traceback as some
-        # undecodable characters may lurk there in optimized mode
-        # (issue #19743).
-        cmds_after_breakpoint = cmds_after_breakpoint or ["backtrace 1"]
-        gdb_output = self.get_stack_trace(source, breakpoint=BREAKPOINT_FN,
-                                          cmds_after_breakpoint=cmds_after_breakpoint,
-                                          import_site=import_site)
-        # gdb can insert additional '\n' and space characters in various places
-        # in its output, depending on the width of the terminal it's connected
-        # to (using its "wrap_here" function)
-        m = re.search(
-            # Match '#0 builtin_id(self=..., v=...)'
-            r'#0\s+builtin_id\s+\(self\=.*,\s+v=\s*(.*?)?\)'
-            # Match ' at Python/bltinmodule.c'.
-            # bpo-38239: builtin_id() is defined in Python/bltinmodule.c,
-            # but accept any "Directory\file.c" to support Link Time
-            # Optimization (LTO).
-            r'\s+at\s+\S*[A-Za-z]+/[A-Za-z0-9_-]+\.c',
-            gdb_output, re.DOTALL)
-        if not m:
-            self.fail('Unexpected gdb output: %r\n%s' % (gdb_output, gdb_output))
-        return m.group(1), gdb_output
-
-    def assertEndsWith(self, actual, exp_end):
-        '''Ensure that the given "actual" string ends with "exp_end"'''
-        self.assertTrue(actual.endswith(exp_end),
-                        msg='%r did not end with %r' % (actual, exp_end))
-
-    def assertMultilineMatches(self, actual, pattern):
-        m = re.match(pattern, actual, re.DOTALL)
-        if not m:
-            self.fail(msg='%r did not match %r' % (actual, pattern))
-
-    def get_sample_script(self):
-        return findfile('gdb_sample.py')
-
-class PrettyPrintTests(DebuggerTests):
-    def test_getting_backtrace(self):
-        gdb_output = self.get_stack_trace('id(42)')
-        self.assertTrue(BREAKPOINT_FN in gdb_output)
-
-    def assertGdbRepr(self, val, exp_repr=None):
-        # Ensure that gdb's rendering of the value in a debugged process
-        # matches repr(value) in this process:
-        gdb_repr, gdb_output = self.get_gdb_repr('id(' + ascii(val) + ')')
-        if not exp_repr:
-            exp_repr = repr(val)
-        self.assertEqual(gdb_repr, exp_repr,
-                         ('%r did not equal expected %r; full output was:\n%s'
-                          % (gdb_repr, exp_repr, gdb_output)))
-
-    @support.requires_resource('cpu')
-    def test_int(self):
-        'Verify the pretty-printing of various int values'
-        self.assertGdbRepr(42)
-        self.assertGdbRepr(0)
-        self.assertGdbRepr(-7)
-        self.assertGdbRepr(1000000000000)
-        self.assertGdbRepr(-1000000000000000)
-
-    def test_singletons(self):
-        'Verify the pretty-printing of True, False and None'
-        self.assertGdbRepr(True)
-        self.assertGdbRepr(False)
-        self.assertGdbRepr(None)
-
-    def test_dicts(self):
-        'Verify the pretty-printing of dictionaries'
-        self.assertGdbRepr({})
-        self.assertGdbRepr({'foo': 'bar'}, "{'foo': 'bar'}")
-        # Python preserves insertion order since 3.6
-        self.assertGdbRepr({'foo': 'bar', 'douglas': 42}, "{'foo': 'bar', 'douglas': 42}")
-
-    def test_lists(self):
-        'Verify the pretty-printing of lists'
-        self.assertGdbRepr([])
-        self.assertGdbRepr(list(range(5)))
-
-    @support.requires_resource('cpu')
-    def test_bytes(self):
-        'Verify the pretty-printing of bytes'
-        self.assertGdbRepr(b'')
-        self.assertGdbRepr(b'And now for something hopefully the same')
-        self.assertGdbRepr(b'string with embedded NUL here \0 and then some more text')
-        self.assertGdbRepr(b'this is a tab:\t'
-                           b' this is a slash-N:\n'
-                           b' this is a slash-R:\r'
-                           )
-
-        self.assertGdbRepr(b'this is byte 255:\xff and byte 128:\x80')
-
-        self.assertGdbRepr(bytes([b for b in range(255)]))
-
-    @support.requires_resource('cpu')
-    def test_strings(self):
-        'Verify the pretty-printing of unicode strings'
-        # We cannot simply call locale.getpreferredencoding() here,
-        # as GDB might have been linked against a different version
-        # of Python with a different encoding and coercion policy
-        # with respect to PEP 538 and PEP 540.
-        out, err = run_gdb(
-            '--eval-command',
-            'python import locale; print(locale.getpreferredencoding())')
-
-        encoding = out.rstrip()
-        if err or not encoding:
-            raise RuntimeError(
-                f'unable to determine the preferred encoding '
-                f'of embedded Python in GDB: {err}')
-
-        def check_repr(text):
-            try:
-                text.encode(encoding)
-            except UnicodeEncodeError:
-                self.assertGdbRepr(text, ascii(text))
-            else:
-                self.assertGdbRepr(text)
-
-        self.assertGdbRepr('')
-        self.assertGdbRepr('And now for something hopefully the same')
-        self.assertGdbRepr('string with embedded NUL here \0 and then some more text')
-
-        # Test printing a single character:
-        #    U+2620 SKULL AND CROSSBONES
-        check_repr('\u2620')
-
-        # Test printing a Japanese unicode string
-        # (I believe this reads "mojibake", using 3 characters from the CJK
-        # Unified Ideographs area, followed by U+3051 HIRAGANA LETTER KE)
-        check_repr('\u6587\u5b57\u5316\u3051')
-
-        # Test a character outside the BMP:
-        #    U+1D121 MUSICAL SYMBOL C CLEF
-        # This is:
-        # UTF-8: 0xF0 0x9D 0x84 0xA1
-        # UTF-16: 0xD834 0xDD21
-        check_repr(chr(0x1D121))
-
-    def test_tuples(self):
-        'Verify the pretty-printing of tuples'
-        self.assertGdbRepr(tuple(), '()')
-        self.assertGdbRepr((1,), '(1,)')
-        self.assertGdbRepr(('foo', 'bar', 'baz'))
-
-    @support.requires_resource('cpu')
-    def test_sets(self):
-        'Verify the pretty-printing of sets'
-        if (gdb_major_version, gdb_minor_version) < (7, 3):
-            self.skipTest("pretty-printing of sets needs gdb 7.3 or later")
-        self.assertGdbRepr(set(), "set()")
-        self.assertGdbRepr(set(['a']), "{'a'}")
-        # PYTHONHASHSEED is need to get the exact frozenset item order
-        if not sys.flags.ignore_environment:
-            self.assertGdbRepr(set(['a', 'b']), "{'a', 'b'}")
-            self.assertGdbRepr(set([4, 5, 6]), "{4, 5, 6}")
-
-        # Ensure that we handle sets containing the "dummy" key value,
-        # which happens on deletion:
-        gdb_repr, gdb_output = self.get_gdb_repr('''s = set(['a','b'])
-s.remove('a')
-id(s)''')
-        self.assertEqual(gdb_repr, "{'b'}")
-
-    @support.requires_resource('cpu')
-    def test_frozensets(self):
-        'Verify the pretty-printing of frozensets'
-        if (gdb_major_version, gdb_minor_version) < (7, 3):
-            self.skipTest("pretty-printing of frozensets needs gdb 7.3 or later")
-        self.assertGdbRepr(frozenset(), "frozenset()")
-        self.assertGdbRepr(frozenset(['a']), "frozenset({'a'})")
-        # PYTHONHASHSEED is need to get the exact frozenset item order
-        if not sys.flags.ignore_environment:
-            self.assertGdbRepr(frozenset(['a', 'b']), "frozenset({'a', 'b'})")
-            self.assertGdbRepr(frozenset([4, 5, 6]), "frozenset({4, 5, 6})")
-
-    def test_exceptions(self):
-        # Test a RuntimeError
-        gdb_repr, gdb_output = self.get_gdb_repr('''
-try:
-    raise RuntimeError("I am an error")
-except RuntimeError as e:
-    id(e)
-''')
-        self.assertEqual(gdb_repr,
-                         "RuntimeError('I am an error',)")
-
-
-        # Test division by zero:
-        gdb_repr, gdb_output = self.get_gdb_repr('''
-try:
-    a = 1 / 0
-except ZeroDivisionError as e:
-    id(e)
-''')
-        self.assertEqual(gdb_repr,
-                         "ZeroDivisionError('division by zero',)")
-
-    def test_modern_class(self):
-        'Verify the pretty-printing of new-style class instances'
-        gdb_repr, gdb_output = self.get_gdb_repr('''
-class Foo:
-    pass
-foo = Foo()
-foo.an_int = 42
-id(foo)''')
-        m = re.match(r'<Foo\(an_int=42\) at remote 0x-?[0-9a-f]+>', gdb_repr)
-        self.assertTrue(m,
-                        msg='Unexpected new-style class rendering %r' % gdb_repr)
-
-    def test_subclassing_list(self):
-        'Verify the pretty-printing of an instance of a list subclass'
-        gdb_repr, gdb_output = self.get_gdb_repr('''
-class Foo(list):
-    pass
-foo = Foo()
-foo += [1, 2, 3]
-foo.an_int = 42
-id(foo)''')
-        m = re.match(r'<Foo\(an_int=42\) at remote 0x-?[0-9a-f]+>', gdb_repr)
-
-        self.assertTrue(m,
-                        msg='Unexpected new-style class rendering %r' % gdb_repr)
-
-    def test_subclassing_tuple(self):
-        'Verify the pretty-printing of an instance of a tuple subclass'
-        # This should exercise the negative tp_dictoffset code in the
-        # new-style class support
-        gdb_repr, gdb_output = self.get_gdb_repr('''
-class Foo(tuple):
-    pass
-foo = Foo((1, 2, 3))
-foo.an_int = 42
-id(foo)''')
-        m = re.match(r'<Foo\(an_int=42\) at remote 0x-?[0-9a-f]+>', gdb_repr)
-
-        self.assertTrue(m,
-                        msg='Unexpected new-style class rendering %r' % gdb_repr)
-
-    def assertSane(self, source, corruption, exprepr=None):
-        '''Run Python under gdb, corrupting variables in the inferior process
-        immediately before taking a backtrace.
-
-        Verify that the variable's representation is the expected failsafe
-        representation'''
-        if corruption:
-            cmds_after_breakpoint=[corruption, 'backtrace']
-        else:
-            cmds_after_breakpoint=['backtrace']
-
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr(source,
-                              cmds_after_breakpoint=cmds_after_breakpoint)
-        if exprepr:
-            if gdb_repr == exprepr:
-                # gdb managed to print the value in spite of the corruption;
-                # this is good (see http://bugs.python.org/issue8330)
-                return
-
-        # Match anything for the type name; 0xDEADBEEF could point to
-        # something arbitrary (see  http://bugs.python.org/issue8330)
-        pattern = '<.* at remote 0x-?[0-9a-f]+>'
-
-        m = re.match(pattern, gdb_repr)
-        if not m:
-            self.fail('Unexpected gdb representation: %r\n%s' % \
-                          (gdb_repr, gdb_output))
-
-    def test_NULL_ptr(self):
-        'Ensure that a NULL PyObject* is handled gracefully'
-        gdb_repr, gdb_output = (
-            self.get_gdb_repr('id(42)',
-                              cmds_after_breakpoint=['set variable v=0',
-                                                     'backtrace'])
-            )
-
-        self.assertEqual(gdb_repr, '0x0')
-
-    def test_NULL_ob_type(self):
-        'Ensure that a PyObject* with NULL ob_type is handled gracefully'
-        self.assertSane('id(42)',
-                        'set v->ob_type=0')
-
-    def test_corrupt_ob_type(self):
-        'Ensure that a PyObject* with a corrupt ob_type is handled gracefully'
-        self.assertSane('id(42)',
-                        'set v->ob_type=0xDEADBEEF',
-                        exprepr='42')
-
-    def test_corrupt_tp_flags(self):
-        'Ensure that a PyObject* with a type with corrupt tp_flags is handled'
-        self.assertSane('id(42)',
-                        'set v->ob_type->tp_flags=0x0',
-                        exprepr='42')
-
-    def test_corrupt_tp_name(self):
-        'Ensure that a PyObject* with a type with corrupt tp_name is handled'
-        self.assertSane('id(42)',
-                        'set v->ob_type->tp_name=0xDEADBEEF',
-                        exprepr='42')
-
-    def test_builtins_help(self):
-        'Ensure that the new-style class _Helper in site.py can be handled'
-
-        if sys.flags.no_site:
-            self.skipTest("need site module, but -S option was used")
-
-        # (this was the issue causing tracebacks in
-        #  http://bugs.python.org/issue8032#msg100537 )
-        gdb_repr, gdb_output = self.get_gdb_repr('id(__builtins__.help)', import_site=True)
-
-        m = re.match(r'<_Helper\(\) at remote 0x-?[0-9a-f]+>', gdb_repr)
-        self.assertTrue(m,
-                        msg='Unexpected rendering %r' % gdb_repr)
-
-    def test_selfreferential_list(self):
-        '''Ensure that a reference loop involving a list doesn't lead proxyval
-        into an infinite loop:'''
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr("a = [3, 4, 5] ; a.append(a) ; id(a)")
-        self.assertEqual(gdb_repr, '[3, 4, 5, [...]]')
-
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr("a = [3, 4, 5] ; b = [a] ; a.append(b) ; id(a)")
-        self.assertEqual(gdb_repr, '[3, 4, 5, [[...]]]')
-
-    def test_selfreferential_dict(self):
-        '''Ensure that a reference loop involving a dict doesn't lead proxyval
-        into an infinite loop:'''
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr("a = {} ; b = {'bar':a} ; a['foo'] = b ; id(a)")
-
-        self.assertEqual(gdb_repr, "{'foo': {'bar': {...}}}")
-
-    def test_selfreferential_old_style_instance(self):
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr('''
-class Foo:
-    pass
-foo = Foo()
-foo.an_attr = foo
-id(foo)''')
-        self.assertTrue(re.match(r'<Foo\(an_attr=<\.\.\.>\) at remote 0x-?[0-9a-f]+>',
-                                 gdb_repr),
-                        'Unexpected gdb representation: %r\n%s' % \
-                            (gdb_repr, gdb_output))
-
-    def test_selfreferential_new_style_instance(self):
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr('''
-class Foo(object):
-    pass
-foo = Foo()
-foo.an_attr = foo
-id(foo)''')
-        self.assertTrue(re.match(r'<Foo\(an_attr=<\.\.\.>\) at remote 0x-?[0-9a-f]+>',
-                                 gdb_repr),
-                        'Unexpected gdb representation: %r\n%s' % \
-                            (gdb_repr, gdb_output))
-
-        gdb_repr, gdb_output = \
-            self.get_gdb_repr('''
-class Foo(object):
-    pass
-a = Foo()
-b = Foo()
-a.an_attr = b
-b.an_attr = a
-id(a)''')
-        self.assertTrue(re.match(r'<Foo\(an_attr=<Foo\(an_attr=<\.\.\.>\) at remote 0x-?[0-9a-f]+>\) at remote 0x-?[0-9a-f]+>',
-                                 gdb_repr),
-                        'Unexpected gdb representation: %r\n%s' % \
-                            (gdb_repr, gdb_output))
-
-    def test_truncation(self):
-        'Verify that very long output is truncated'
-        gdb_repr, gdb_output = self.get_gdb_repr('id(list(range(1000)))')
-        self.assertEqual(gdb_repr,
-                         "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, "
-                         "14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, "
-                         "27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, "
-                         "40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, "
-                         "53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, "
-                         "66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, "
-                         "79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, "
-                         "92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, "
-                         "104, 105, 106, 107, 108, 109, 110, 111, 112, 113, "
-                         "114, 115, 116, 117, 118, 119, 120, 121, 122, 123, "
-                         "124, 125, 126, 127, 128, 129, 130, 131, 132, 133, "
-                         "134, 135, 136, 137, 138, 139, 140, 141, 142, 143, "
-                         "144, 145, 146, 147, 148, 149, 150, 151, 152, 153, "
-                         "154, 155, 156, 157, 158, 159, 160, 161, 162, 163, "
-                         "164, 165, 166, 167, 168, 169, 170, 171, 172, 173, "
-                         "174, 175, 176, 177, 178, 179, 180, 181, 182, 183, "
-                         "184, 185, 186, 187, 188, 189, 190, 191, 192, 193, "
-                         "194, 195, 196, 197, 198, 199, 200, 201, 202, 203, "
-                         "204, 205, 206, 207, 208, 209, 210, 211, 212, 213, "
-                         "214, 215, 216, 217, 218, 219, 220, 221, 222, 223, "
-                         "224, 225, 226...(truncated)")
-        self.assertEqual(len(gdb_repr),
-                         1024 + len('...(truncated)'))
-
-    def test_builtin_method(self):
-        gdb_repr, gdb_output = self.get_gdb_repr('import sys; id(sys.stdout.readlines)')
-        self.assertTrue(re.match(r'<built-in method readlines of _io.TextIOWrapper object at remote 0x-?[0-9a-f]+>',
-                                 gdb_repr),
-                        'Unexpected gdb representation: %r\n%s' % \
-                            (gdb_repr, gdb_output))
-
-    def test_frames(self):
-        gdb_output = self.get_stack_trace('''
-import sys
-def foo(a, b, c):
-    return sys._getframe(0)
-
-f = foo(3, 4, 5)
-id(f)''',
-                                          breakpoint='builtin_id',
-                                          cmds_after_breakpoint=['print (PyFrameObject*)v']
-                                          )
-        self.assertTrue(re.match(r'.*\s+\$1 =\s+Frame 0x-?[0-9a-f]+, for file <string>, line 4, in foo \(a=3.*',
-                                 gdb_output,
-                                 re.DOTALL),
-                        'Unexpected gdb representation: %r\n%s' % (gdb_output, gdb_output))
-
-@unittest.skipIf(python_is_optimized(),
-                 "Python was compiled with optimizations")
-class PyListTests(DebuggerTests):
-    def assertListing(self, expected, actual):
-        self.assertEndsWith(actual, expected)
-
-    def test_basic_command(self):
-        'Verify that the "py-list" command works'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-list'])
-
-        self.assertListing('   5    \n'
-                           '   6    def bar(a, b, c):\n'
-                           '   7        baz(a, b, c)\n'
-                           '   8    \n'
-                           '   9    def baz(*args):\n'
-                           ' >10        id(42)\n'
-                           '  11    \n'
-                           '  12    foo(1, 2, 3)\n',
-                           bt)
-
-    def test_one_abs_arg(self):
-        'Verify the "py-list" command with one absolute argument'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-list 9'])
-
-        self.assertListing('   9    def baz(*args):\n'
-                           ' >10        id(42)\n'
-                           '  11    \n'
-                           '  12    foo(1, 2, 3)\n',
-                           bt)
-
-    def test_two_abs_args(self):
-        'Verify the "py-list" command with two absolute arguments'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-list 1,3'])
-
-        self.assertListing('   1    # Sample script for use by test_gdb.py\n'
-                           '   2    \n'
-                           '   3    def foo(a, b, c):\n',
-                           bt)
-
-SAMPLE_WITH_C_CALL = """
-
-from _testcapi import pyobject_fastcall
-
-def foo(a, b, c):
-    bar(a, b, c)
-
-def bar(a, b, c):
-    pyobject_fastcall(baz, (a, b, c))
-
-def baz(*args):
-    id(42)
-
-foo(1, 2, 3)
-
-"""
-
-
-class StackNavigationTests(DebuggerTests):
-    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_pyup_command(self):
-        'Verify that the "py-up" command works'
-        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
-                                  cmds_after_breakpoint=['py-up', 'py-up'])
-        self.assertMultilineMatches(bt,
-                                    r'''^.*
-#[0-9]+ Frame 0x-?[0-9a-f]+, for file <string>, line 12, in baz \(args=\(1, 2, 3\)\)
-#[0-9]+ <built-in method pyobject_fastcall of module object at remote 0x[0-9a-f]+>
-$''')
-
-    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
-    def test_down_at_bottom(self):
-        'Verify handling of "py-down" at the bottom of the stack'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-down'])
-        self.assertEndsWith(bt,
-                            'Unable to find a newer python frame\n')
-
-    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
-    def test_up_at_top(self):
-        'Verify handling of "py-up" at the top of the stack'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-up'] * 5)
-        self.assertEndsWith(bt,
-                            'Unable to find an older python frame\n')
-
-    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_up_then_down(self):
-        'Verify "py-up" followed by "py-down"'
-        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
-                                  cmds_after_breakpoint=['py-up', 'py-up', 'py-down'])
-        self.assertMultilineMatches(bt,
-                                    r'''^.*
-#[0-9]+ Frame 0x-?[0-9a-f]+, for file <string>, line 12, in baz \(args=\(1, 2, 3\)\)
-#[0-9]+ <built-in method pyobject_fastcall of module object at remote 0x[0-9a-f]+>
-#[0-9]+ Frame 0x-?[0-9a-f]+, for file <string>, line 12, in baz \(args=\(1, 2, 3\)\)
-$''')
-
-class PyBtTests(DebuggerTests):
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_bt(self):
-        'Verify that the "py-bt" command works'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-bt'])
-        self.assertMultilineMatches(bt,
-                                    r'''^.*
-Traceback \(most recent call first\):
-  <built-in method id of module object .*>
-  File ".*gdb_sample.py", line 10, in baz
-    id\(42\)
-  File ".*gdb_sample.py", line 7, in bar
-    baz\(a, b, c\)
-  File ".*gdb_sample.py", line 4, in foo
-    bar\(a=a, b=b, c=c\)
-  File ".*gdb_sample.py", line 12, in <module>
-    foo\(1, 2, 3\)
-''')
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_bt_full(self):
-        'Verify that the "py-bt-full" command works'
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-bt-full'])
-        self.assertMultilineMatches(bt,
-                                    r'''^.*
-#[0-9]+ Frame 0x-?[0-9a-f]+, for file .*gdb_sample.py, line 7, in bar \(a=1, b=2, c=3\)
-    baz\(a, b, c\)
-#[0-9]+ Frame 0x-?[0-9a-f]+, for file .*gdb_sample.py, line 4, in foo \(a=1, b=2, c=3\)
-    bar\(a=a, b=b, c=c\)
-#[0-9]+ Frame 0x-?[0-9a-f]+, for file .*gdb_sample.py, line 12, in <module> \(\)
-    foo\(1, 2, 3\)
-''')
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    @support.requires_resource('cpu')
-    def test_threads(self):
-        'Verify that "py-bt" indicates threads that are waiting for the GIL'
-        cmd = '''
-from threading import Thread
-
-class TestThread(Thread):
-    # These threads would run forever, but we'll interrupt things with the
-    # debugger
-    def run(self):
-        i = 0
-        while 1:
-             i += 1
-
-t = {}
-for i in range(4):
-   t[i] = TestThread()
-   t[i].start()
-
-# Trigger a breakpoint on the main thread
-id(42)
-
-'''
-        # Verify with "py-bt":
-        gdb_output = self.get_stack_trace(cmd,
-                                          cmds_after_breakpoint=['thread apply all py-bt'])
-        self.assertIn('Waiting for the GIL', gdb_output)
-
-        # Verify with "py-bt-full":
-        gdb_output = self.get_stack_trace(cmd,
-                                          cmds_after_breakpoint=['thread apply all py-bt-full'])
-        self.assertIn('Waiting for the GIL', gdb_output)
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    # Some older versions of gdb will fail with
-    #  "Cannot find new threads: generic error"
-    # unless we add LD_PRELOAD=PATH-TO-libpthread.so.1 as a workaround
-    def test_gc(self):
-        'Verify that "py-bt" indicates if a thread is garbage-collecting'
-        cmd = ('from gc import collect\n'
-               'id(42)\n'
-               'def foo():\n'
-               '    collect()\n'
-               'def bar():\n'
-               '    foo()\n'
-               'bar()\n')
-        # Verify with "py-bt":
-        gdb_output = self.get_stack_trace(cmd,
-                                          cmds_after_breakpoint=['break update_refs', 'continue', 'py-bt'],
-                                          )
-        self.assertIn('Garbage-collecting', gdb_output)
-
-        # Verify with "py-bt-full":
-        gdb_output = self.get_stack_trace(cmd,
-                                          cmds_after_breakpoint=['break update_refs', 'continue', 'py-bt-full'],
-                                          )
-        self.assertIn('Garbage-collecting', gdb_output)
-
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    @support.requires_resource('cpu')
-    # Some older versions of gdb will fail with
-    #  "Cannot find new threads: generic error"
-    # unless we add LD_PRELOAD=PATH-TO-libpthread.so.1 as a workaround
-    #
-    # gdb will also generate many erroneous errors such as:
-    #     Function "meth_varargs" not defined.
-    # This is because we are calling functions from an "external" module
-    # (_testcapimodule) rather than compiled-in functions. It seems difficult
-    # to suppress these. See also the comment in DebuggerTests.get_stack_trace
-    def test_pycfunction(self):
-        'Verify that "py-bt" displays invocations of PyCFunction instances'
-        # bpo-46600: If the compiler inlines _null_to_none() in meth_varargs()
-        # (ex: clang -Og), _null_to_none() is the frame #1. Otherwise,
-        # meth_varargs() is the frame #1.
-        expected_frame = r'#(1|2)'
-        # Various optimizations multiply the code paths by which these are
-        # called, so test a variety of calling conventions.
-        for func_name, args in (
-            ('meth_varargs', ''),
-            ('meth_varargs_keywords', ''),
-            ('meth_o', '[]'),
-            ('meth_noargs', ''),
-            ('meth_fastcall', ''),
-            ('meth_fastcall_keywords', ''),
-        ):
-            for obj in (
-                '_testcapi',
-                '_testcapi.MethClass',
-                '_testcapi.MethClass()',
-                '_testcapi.MethStatic()',
-
-                # XXX: bound methods don't yet give nice tracebacks
-                # '_testcapi.MethInstance()',
-            ):
-                with self.subTest(f'{obj}.{func_name}'):
-                    cmd = textwrap.dedent(f'''
-                        import _testcapi
-                        def foo():
-                            {obj}.{func_name}({args})
-                        def bar():
-                            foo()
-                        bar()
-                    ''')
-                    # Verify with "py-bt":
-                    gdb_output = self.get_stack_trace(
-                        cmd,
-                        breakpoint=func_name,
-                        cmds_after_breakpoint=['bt', 'py-bt'],
-                        # bpo-45207: Ignore 'Function "meth_varargs" not
-                        # defined.' message in stderr.
-                        ignore_stderr=True,
-                    )
-                    self.assertIn(f'<built-in method {func_name}', gdb_output)
-
-                    # Verify with "py-bt-full":
-                    gdb_output = self.get_stack_trace(
-                        cmd,
-                        breakpoint=func_name,
-                        cmds_after_breakpoint=['py-bt-full'],
-                        # bpo-45207: Ignore 'Function "meth_varargs" not
-                        # defined.' message in stderr.
-                        ignore_stderr=True,
-                    )
-                    regex = expected_frame
-                    regex += re.escape(f' <built-in method {func_name}')
-                    self.assertRegex(gdb_output, regex)
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_wrapper_call(self):
-        cmd = textwrap.dedent('''
-            class MyList(list):
-                def __init__(self):
-                    super(*[]).__init__()   # wrapper_call()
-
-            id("first break point")
-            l = MyList()
-        ''')
-        cmds_after_breakpoint = ['break wrapper_call', 'continue']
-        if CET_PROTECTION:
-            # bpo-32962: same case as in get_stack_trace():
-            # we need an additional 'next' command in order to read
-            # arguments of the innermost function of the call stack.
-            cmds_after_breakpoint.append('next')
-        cmds_after_breakpoint.append('py-bt')
-
-        # Verify with "py-bt":
-        gdb_output = self.get_stack_trace(cmd,
-                                          cmds_after_breakpoint=cmds_after_breakpoint)
-        self.assertRegex(gdb_output,
-                         r"<method-wrapper u?'__init__' of MyList object at ")
-
-class PyPrintTests(DebuggerTests):
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_basic_command(self):
-        'Verify that the "py-print" command works'
-        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
-                                  cmds_after_breakpoint=['py-up', 'py-print args'])
-        self.assertMultilineMatches(bt,
-                                    r".*\nlocal 'args' = \(1, 2, 3\)\n.*")
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
-    def test_print_after_up(self):
-        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
-                                  cmds_after_breakpoint=['py-up', 'py-up', 'py-print c', 'py-print b', 'py-print a'])
-        self.assertMultilineMatches(bt,
-                                    r".*\nlocal 'c' = 3\nlocal 'b' = 2\nlocal 'a' = 1\n.*")
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_printing_global(self):
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-up', 'py-print __name__'])
-        self.assertMultilineMatches(bt,
-                                    r".*\nglobal '__name__' = '__main__'\n.*")
-
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_printing_builtin(self):
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-up', 'py-print len'])
-        self.assertMultilineMatches(bt,
-                                    r".*\nbuiltin 'len' = <built-in method len of module object at remote 0x-?[0-9a-f]+>\n.*")
-
-class PyLocalsTests(DebuggerTests):
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_basic_command(self):
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-up', 'py-locals'])
-        self.assertMultilineMatches(bt,
-                                    r".*\nargs = \(1, 2, 3\)\n.*")
-
-    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
-    @unittest.skipIf(python_is_optimized(),
-                     "Python was compiled with optimizations")
-    def test_locals_after_up(self):
-        bt = self.get_stack_trace(script=self.get_sample_script(),
-                                  cmds_after_breakpoint=['py-up', 'py-up', 'py-locals'])
-        self.assertMultilineMatches(bt,
-                                    r'''^.*
-Locals for foo
-a = 1
-b = 2
-c = 3
-Locals for <module>
-.*$''')
-
-
-def setUpModule():
-    if support.verbose:
-        print("GDB version %s.%s:" % (gdb_major_version, gdb_minor_version))
-        for line in gdb_version.splitlines():
-            print(" " * 4 + line)
-
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_gdb/__init__.py b/Lib/test/test_gdb/__init__.py
new file mode 100644
index 0000000000..99557739af
--- /dev/null
+++ b/Lib/test/test_gdb/__init__.py
@@ -0,0 +1,29 @@
+# Verify that gdb can pretty-print the various PyObject* types
+#
+# The code for testing gdb was adapted from similar work in Unladen Swallow's
+# Lib/test/test_jit_gdb.py
+
+import os
+import sysconfig
+import unittest
+from test import support
+
+
+if support.MS_WINDOWS:
+    # On Windows, Python is usually built by MSVC. Passing /p:DebugSymbols=true
+    # option to MSBuild produces PDB debug symbols, but gdb doesn't support PDB
+    # debug symbol files.
+    raise unittest.SkipTest("test_gdb doesn't work on Windows")
+
+if support.PGO:
+    raise unittest.SkipTest("test_gdb is not useful for PGO")
+
+if not sysconfig.is_python_build():
+    raise unittest.SkipTest("test_gdb only works on source builds at the moment.")
+
+if support.check_cflags_pgo():
+    raise unittest.SkipTest("test_gdb is not reliable on PGO builds")
+
+
+def load_tests(*args):
+    return support.load_package_tests(os.path.dirname(__file__), *args)
diff --git a/Lib/test/test_gdb/gdb_sample.py b/Lib/test/test_gdb/gdb_sample.py
new file mode 100644
index 0000000000..a7f23db73e
--- /dev/null
+++ b/Lib/test/test_gdb/gdb_sample.py
@@ -0,0 +1,12 @@
+# Sample script for use by test_gdb
+
+def foo(a, b, c):
+    bar(a=a, b=b, c=c)
+
+def bar(a, b, c):
+    baz(a, b, c)
+
+def baz(*args):
+    id(42)
+
+foo(1, 2, 3)
diff --git a/Lib/test/test_gdb/test_backtrace.py b/Lib/test/test_gdb/test_backtrace.py
new file mode 100644
index 0000000000..c41e7cb7c2
--- /dev/null
+++ b/Lib/test/test_gdb/test_backtrace.py
@@ -0,0 +1,134 @@
+import textwrap
+import unittest
+from test import support
+from test.support import python_is_optimized
+
+from .util import setup_module, DebuggerTests, CET_PROTECTION, SAMPLE_SCRIPT
+
+
+def setUpModule():
+    setup_module()
+
+
+class PyBtTests(DebuggerTests):
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_bt(self):
+        'Verify that the "py-bt" command works'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-bt'])
+        self.assertMultilineMatches(bt,
+                                    r'''^.*
+Traceback \(most recent call first\):
+  <built-in method id of module object .*>
+  File ".*gdb_sample.py", line 10, in baz
+    id\(42\)
+  File ".*gdb_sample.py", line 7, in bar
+    baz\(a, b, c\)
+  File ".*gdb_sample.py", line 4, in foo
+    bar\(a=a, b=b, c=c\)
+  File ".*gdb_sample.py", line 12, in <module>
+    foo\(1, 2, 3\)
+''')
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_bt_full(self):
+        'Verify that the "py-bt-full" command works'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-bt-full'])
+        self.assertMultilineMatches(bt,
+                                    r'''^.*
+#[0-9]+ Frame 0x-?[0-9a-f]+, for file .*gdb_sample.py, line 7, in bar \(a=1, b=2, c=3\)
+    baz\(a, b, c\)
+#[0-9]+ Frame 0x-?[0-9a-f]+, for file .*gdb_sample.py, line 4, in foo \(a=1, b=2, c=3\)
+    bar\(a=a, b=b, c=c\)
+#[0-9]+ Frame 0x-?[0-9a-f]+, for file .*gdb_sample.py, line 12, in <module> \(\)
+    foo\(1, 2, 3\)
+''')
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    @support.requires_resource('cpu')
+    def test_threads(self):
+        'Verify that "py-bt" indicates threads that are waiting for the GIL'
+        cmd = '''
+from threading import Thread
+
+class TestThread(Thread):
+    # These threads would run forever, but we'll interrupt things with the
+    # debugger
+    def run(self):
+        i = 0
+        while 1:
+             i += 1
+
+t = {}
+for i in range(4):
+   t[i] = TestThread()
+   t[i].start()
+
+# Trigger a breakpoint on the main thread
+id(42)
+
+'''
+        # Verify with "py-bt":
+        gdb_output = self.get_stack_trace(cmd,
+                                          cmds_after_breakpoint=['thread apply all py-bt'])
+        self.assertIn('Waiting for the GIL', gdb_output)
+
+        # Verify with "py-bt-full":
+        gdb_output = self.get_stack_trace(cmd,
+                                          cmds_after_breakpoint=['thread apply all py-bt-full'])
+        self.assertIn('Waiting for the GIL', gdb_output)
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    # Some older versions of gdb will fail with
+    #  "Cannot find new threads: generic error"
+    # unless we add LD_PRELOAD=PATH-TO-libpthread.so.1 as a workaround
+    def test_gc(self):
+        'Verify that "py-bt" indicates if a thread is garbage-collecting'
+        cmd = ('from gc import collect\n'
+               'id(42)\n'
+               'def foo():\n'
+               '    collect()\n'
+               'def bar():\n'
+               '    foo()\n'
+               'bar()\n')
+        # Verify with "py-bt":
+        gdb_output = self.get_stack_trace(cmd,
+                                          cmds_after_breakpoint=['break update_refs', 'continue', 'py-bt'],
+                                          )
+        self.assertIn('Garbage-collecting', gdb_output)
+
+        # Verify with "py-bt-full":
+        gdb_output = self.get_stack_trace(cmd,
+                                          cmds_after_breakpoint=['break update_refs', 'continue', 'py-bt-full'],
+                                          )
+        self.assertIn('Garbage-collecting', gdb_output)
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_wrapper_call(self):
+        cmd = textwrap.dedent('''
+            class MyList(list):
+                def __init__(self):
+                    super(*[]).__init__()   # wrapper_call()
+
+            id("first break point")
+            l = MyList()
+        ''')
+        cmds_after_breakpoint = ['break wrapper_call', 'continue']
+        if CET_PROTECTION:
+            # bpo-32962: same case as in get_stack_trace():
+            # we need an additional 'next' command in order to read
+            # arguments of the innermost function of the call stack.
+            cmds_after_breakpoint.append('next')
+        cmds_after_breakpoint.append('py-bt')
+
+        # Verify with "py-bt":
+        gdb_output = self.get_stack_trace(cmd,
+                                          cmds_after_breakpoint=cmds_after_breakpoint)
+        self.assertRegex(gdb_output,
+                         r"<method-wrapper u?'__init__' of MyList object at ")
diff --git a/Lib/test/test_gdb/test_cfunction.py b/Lib/test/test_gdb/test_cfunction.py
new file mode 100644
index 0000000000..0a62014923
--- /dev/null
+++ b/Lib/test/test_gdb/test_cfunction.py
@@ -0,0 +1,85 @@
+import textwrap
+import unittest
+from test import support
+
+from .util import setup_module, DebuggerTests
+
+
+def setUpModule():
+    setup_module()
+
+
+@unittest.skipIf(support.python_is_optimized(),
+                 "Python was compiled with optimizations")
+@support.requires_resource('cpu')
+class CFunctionTests(DebuggerTests):
+    def check(self, func_name, cmd):
+        # Verify with "py-bt":
+        gdb_output = self.get_stack_trace(
+            cmd,
+            breakpoint=func_name,
+            cmds_after_breakpoint=['bt', 'py-bt'],
+            # bpo-45207: Ignore 'Function "meth_varargs" not
+            # defined.' message in stderr.
+            ignore_stderr=True,
+        )
+        self.assertIn(f'<built-in method {func_name}', gdb_output)
+
+    # Some older versions of gdb will fail with
+    #  "Cannot find new threads: generic error"
+    # unless we add LD_PRELOAD=PATH-TO-libpthread.so.1 as a workaround
+    #
+    # gdb will also generate many erroneous errors such as:
+    #     Function "meth_varargs" not defined.
+    # This is because we are calling functions from an "external" module
+    # (_testcapimodule) rather than compiled-in functions. It seems difficult
+    # to suppress these. See also the comment in DebuggerTests.get_stack_trace
+    def check_pycfunction(self, func_name, args):
+        'Verify that "py-bt" displays invocations of PyCFunction instances'
+
+        if support.verbose:
+            print()
+
+        # Various optimizations multiply the code paths by which these are
+        # called, so test a variety of calling conventions.
+        for obj in (
+            '_testcapi',
+            '_testcapi.MethClass',
+            '_testcapi.MethClass()',
+            '_testcapi.MethStatic()',
+
+            # XXX: bound methods don't yet give nice tracebacks
+            # '_testcapi.MethInstance()',
+        ):
+            with self.subTest(f'{obj}.{func_name}'):
+                call = f'{obj}.{func_name}({args})'
+                cmd = textwrap.dedent(f'''
+                    import _testcapi
+                    def foo():
+                        {call}
+                    def bar():
+                        foo()
+                    bar()
+                ''')
+                if support.verbose:
+                    print(f'  test call: {call}', flush=True)
+
+                self.check(func_name, cmd)
+
+    def test_pycfunction_noargs(self):
+        self.check_pycfunction('meth_noargs', '')
+
+    def test_pycfunction_o(self):
+        self.check_pycfunction('meth_o', '[]')
+
+    def test_pycfunction_varargs(self):
+        self.check_pycfunction('meth_varargs', '')
+
+    def test_pycfunction_varargs_keywords(self):
+        self.check_pycfunction('meth_varargs_keywords', '')
+
+    def test_pycfunction_fastcall(self):
+        self.check_pycfunction('meth_fastcall', '')
+
+    def test_pycfunction_fastcall_keywords(self):
+        self.check_pycfunction('meth_fastcall_keywords', '')
diff --git a/Lib/test/test_gdb/test_cfunction_full.py b/Lib/test/test_gdb/test_cfunction_full.py
new file mode 100644
index 0000000000..572cbdab5d
--- /dev/null
+++ b/Lib/test/test_gdb/test_cfunction_full.py
@@ -0,0 +1,36 @@
+"""
+Similar to test_cfunction but test "py-bt-full" command.
+"""
+
+import re
+
+from .util import setup_module
+from .test_cfunction import CFunctionTests
+
+
+def setUpModule():
+    setup_module()
+
+
+class CFunctionFullTests(CFunctionTests):
+    def check(self, func_name, cmd):
+        # Verify with "py-bt-full":
+        gdb_output = self.get_stack_trace(
+            cmd,
+            breakpoint=func_name,
+            cmds_after_breakpoint=['bt', 'py-bt-full'],
+            # bpo-45207: Ignore 'Function "meth_varargs" not
+            # defined.' message in stderr.
+            ignore_stderr=True,
+        )
+
+        # bpo-46600: If the compiler inlines _null_to_none() in
+        # meth_varargs() (ex: clang -Og), _null_to_none() is the
+        # frame #1. Otherwise, meth_varargs() is the frame #1.
+        regex = r'#(1|2)'
+        regex += re.escape(f' <built-in method {func_name}')
+        self.assertRegex(gdb_output, regex)
+
+
+# Delete the test case, otherwise it's executed twice
+del CFunctionTests
diff --git a/Lib/test/test_gdb/test_misc.py b/Lib/test/test_gdb/test_misc.py
new file mode 100644
index 0000000000..1047f4867c
--- /dev/null
+++ b/Lib/test/test_gdb/test_misc.py
@@ -0,0 +1,188 @@
+import re
+import unittest
+from test.support import python_is_optimized
+
+from .util import run_gdb, setup_module, DebuggerTests, SAMPLE_SCRIPT
+
+
+def setUpModule():
+    setup_module()
+
+
+def gdb_has_frame_select():
+    # Does this build of gdb have gdb.Frame.select ?
+    stdout, stderr = run_gdb("--eval-command=python print(dir(gdb.Frame))")
+    m = re.match(r'.*\[(.*)\].*', stdout)
+    if not m:
+        raise unittest.SkipTest(
+            f"Unable to parse output from gdb.Frame.select test\n"
+            f"stdout={stdout!r}\n"
+            f"stderr={stderr!r}\n")
+    gdb_frame_dir = m.group(1).split(', ')
+    return "'select'" in gdb_frame_dir
+
+HAS_PYUP_PYDOWN = gdb_has_frame_select()
+
+
+@unittest.skipIf(python_is_optimized(),
+                 "Python was compiled with optimizations")
+class PyListTests(DebuggerTests):
+    def assertListing(self, expected, actual):
+        self.assertEndsWith(actual, expected)
+
+    def test_basic_command(self):
+        'Verify that the "py-list" command works'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-list'])
+
+        self.assertListing('   5    \n'
+                           '   6    def bar(a, b, c):\n'
+                           '   7        baz(a, b, c)\n'
+                           '   8    \n'
+                           '   9    def baz(*args):\n'
+                           ' >10        id(42)\n'
+                           '  11    \n'
+                           '  12    foo(1, 2, 3)\n',
+                           bt)
+
+    def test_one_abs_arg(self):
+        'Verify the "py-list" command with one absolute argument'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-list 9'])
+
+        self.assertListing('   9    def baz(*args):\n'
+                           ' >10        id(42)\n'
+                           '  11    \n'
+                           '  12    foo(1, 2, 3)\n',
+                           bt)
+
+    def test_two_abs_args(self):
+        'Verify the "py-list" command with two absolute arguments'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-list 1,3'])
+
+        self.assertListing('   1    # Sample script for use by test_gdb\n'
+                           '   2    \n'
+                           '   3    def foo(a, b, c):\n',
+                           bt)
+
+SAMPLE_WITH_C_CALL = """
+
+from _testcapi import pyobject_vectorcall
+
+def foo(a, b, c):
+    bar(a, b, c)
+
+def bar(a, b, c):
+    pyobject_vectorcall(baz, (a, b, c), None)
+
+def baz(*args):
+    id(42)
+
+foo(1, 2, 3)
+
+"""
+
+
+class StackNavigationTests(DebuggerTests):
+    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_pyup_command(self):
+        'Verify that the "py-up" command works'
+        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
+                                  cmds_after_breakpoint=['py-up', 'py-up'])
+        self.assertMultilineMatches(bt,
+                                    r'''^.*
+#[0-9]+ Frame 0x-?[0-9a-f]+, for file <string>, line 12, in baz \(args=\(1, 2, 3\)\)
+#[0-9]+ <built-in method pyobject_vectorcall of module object at remote 0x[0-9a-f]+>
+$''')
+
+    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
+    def test_down_at_bottom(self):
+        'Verify handling of "py-down" at the bottom of the stack'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-down'])
+        self.assertEndsWith(bt,
+                            'Unable to find a newer python frame\n')
+
+    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
+    def test_up_at_top(self):
+        'Verify handling of "py-up" at the top of the stack'
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-up'] * 5)
+        self.assertEndsWith(bt,
+                            'Unable to find an older python frame\n')
+
+    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_up_then_down(self):
+        'Verify "py-up" followed by "py-down"'
+        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
+                                  cmds_after_breakpoint=['py-up', 'py-up', 'py-down'])
+        self.assertMultilineMatches(bt,
+                                    r'''^.*
+#[0-9]+ Frame 0x-?[0-9a-f]+, for file <string>, line 12, in baz \(args=\(1, 2, 3\)\)
+#[0-9]+ <built-in method pyobject_vectorcall of module object at remote 0x[0-9a-f]+>
+#[0-9]+ Frame 0x-?[0-9a-f]+, for file <string>, line 12, in baz \(args=\(1, 2, 3\)\)
+$''')
+
+class PyPrintTests(DebuggerTests):
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_basic_command(self):
+        'Verify that the "py-print" command works'
+        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
+                                  cmds_after_breakpoint=['py-up', 'py-print args'])
+        self.assertMultilineMatches(bt,
+                                    r".*\nlocal 'args' = \(1, 2, 3\)\n.*")
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
+    def test_print_after_up(self):
+        bt = self.get_stack_trace(source=SAMPLE_WITH_C_CALL,
+                                  cmds_after_breakpoint=['py-up', 'py-up', 'py-print c', 'py-print b', 'py-print a'])
+        self.assertMultilineMatches(bt,
+                                    r".*\nlocal 'c' = 3\nlocal 'b' = 2\nlocal 'a' = 1\n.*")
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_printing_global(self):
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-up', 'py-print __name__'])
+        self.assertMultilineMatches(bt,
+                                    r".*\nglobal '__name__' = '__main__'\n.*")
+
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_printing_builtin(self):
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-up', 'py-print len'])
+        self.assertMultilineMatches(bt,
+                                    r".*\nbuiltin 'len' = <built-in method len of module object at remote 0x-?[0-9a-f]+>\n.*")
+
+class PyLocalsTests(DebuggerTests):
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_basic_command(self):
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-up', 'py-locals'])
+        self.assertMultilineMatches(bt,
+                                    r".*\nargs = \(1, 2, 3\)\n.*")
+
+    @unittest.skipUnless(HAS_PYUP_PYDOWN, "test requires py-up/py-down commands")
+    @unittest.skipIf(python_is_optimized(),
+                     "Python was compiled with optimizations")
+    def test_locals_after_up(self):
+        bt = self.get_stack_trace(script=SAMPLE_SCRIPT,
+                                  cmds_after_breakpoint=['py-up', 'py-up', 'py-locals'])
+        self.assertMultilineMatches(bt,
+                                    r'''^.*
+Locals for foo
+a = 1
+b = 2
+c = 3
+Locals for <module>
+.*$''')
diff --git a/Lib/test/test_gdb/test_pretty_print.py b/Lib/test/test_gdb/test_pretty_print.py
new file mode 100644
index 0000000000..dfc77d65ab
--- /dev/null
+++ b/Lib/test/test_gdb/test_pretty_print.py
@@ -0,0 +1,438 @@
+import re
+import sys
+from test import support
+
+from .util import (
+    BREAKPOINT_FN, GDB_VERSION,
+    run_gdb, setup_module, DebuggerTests)
+
+
+def setUpModule():
+    setup_module()
+
+
+class PrettyPrintTests(DebuggerTests):
+    def get_gdb_repr(self, source,
+                     cmds_after_breakpoint=None,
+                     import_site=False):
+        # Given an input python source representation of data,
+        # run "python -c'id(DATA)'" under gdb with a breakpoint on
+        # builtin_id and scrape out gdb's representation of the "op"
+        # parameter, and verify that the gdb displays the same string
+        #
+        # Verify that the gdb displays the expected string
+        #
+        # For a nested structure, the first time we hit the breakpoint will
+        # give us the top-level structure
+
+        # NOTE: avoid decoding too much of the traceback as some
+        # undecodable characters may lurk there in optimized mode
+        # (issue #19743).
+        cmds_after_breakpoint = cmds_after_breakpoint or ["backtrace 1"]
+        gdb_output = self.get_stack_trace(source, breakpoint=BREAKPOINT_FN,
+                                          cmds_after_breakpoint=cmds_after_breakpoint,
+                                          import_site=import_site)
+        # gdb can insert additional '\n' and space characters in various places
+        # in its output, depending on the width of the terminal it's connected
+        # to (using its "wrap_here" function)
+        m = re.search(
+            # Match '#0 builtin_id(self=..., v=...)'
+            r'#0\s+builtin_id\s+\(self\=.*,\s+v=\s*(.*?)?\)'
+            # Match ' at Python/bltinmodule.c'.
+            # bpo-38239: builtin_id() is defined in Python/bltinmodule.c,
+            # but accept any "Directory\file.c" to support Link Time
+            # Optimization (LTO).
+            r'\s+at\s+\S*[A-Za-z]+/[A-Za-z0-9_-]+\.c',
+            gdb_output, re.DOTALL)
+        if not m:
+            self.fail('Unexpected gdb output: %r\n%s' % (gdb_output, gdb_output))
+        return m.group(1), gdb_output
+
+    def test_getting_backtrace(self):
+        gdb_output = self.get_stack_trace('id(42)')
+        self.assertTrue(BREAKPOINT_FN in gdb_output)
+
+    def assertGdbRepr(self, val, exp_repr=None):
+        # Ensure that gdb's rendering of the value in a debugged process
+        # matches repr(value) in this process:
+        gdb_repr, gdb_output = self.get_gdb_repr('id(' + ascii(val) + ')')
+        if not exp_repr:
+            exp_repr = repr(val)
+        self.assertEqual(gdb_repr, exp_repr,
+                         ('%r did not equal expected %r; full output was:\n%s'
+                          % (gdb_repr, exp_repr, gdb_output)))
+
+    @support.requires_resource('cpu')
+    def test_int(self):
+        'Verify the pretty-printing of various int values'
+        self.assertGdbRepr(42)
+        self.assertGdbRepr(0)
+        self.assertGdbRepr(-7)
+        self.assertGdbRepr(1000000000000)
+        self.assertGdbRepr(-1000000000000000)
+
+    def test_singletons(self):
+        'Verify the pretty-printing of True, False and None'
+        self.assertGdbRepr(True)
+        self.assertGdbRepr(False)
+        self.assertGdbRepr(None)
+
+    def test_dicts(self):
+        'Verify the pretty-printing of dictionaries'
+        self.assertGdbRepr({})
+        self.assertGdbRepr({'foo': 'bar'}, "{'foo': 'bar'}")
+        # Python preserves insertion order since 3.6
+        self.assertGdbRepr({'foo': 'bar', 'douglas': 42}, "{'foo': 'bar', 'douglas': 42}")
+
+    def test_lists(self):
+        'Verify the pretty-printing of lists'
+        self.assertGdbRepr([])
+        self.assertGdbRepr(list(range(5)))
+
+    @support.requires_resource('cpu')
+    def test_bytes(self):
+        'Verify the pretty-printing of bytes'
+        self.assertGdbRepr(b'')
+        self.assertGdbRepr(b'And now for something hopefully the same')
+        self.assertGdbRepr(b'string with embedded NUL here \0 and then some more text')
+        self.assertGdbRepr(b'this is a tab:\t'
+                           b' this is a slash-N:\n'
+                           b' this is a slash-R:\r'
+                           )
+
+        self.assertGdbRepr(b'this is byte 255:\xff and byte 128:\x80')
+
+        self.assertGdbRepr(bytes([b for b in range(255)]))
+
+    @support.requires_resource('cpu')
+    def test_strings(self):
+        'Verify the pretty-printing of unicode strings'
+        # We cannot simply call locale.getpreferredencoding() here,
+        # as GDB might have been linked against a different version
+        # of Python with a different encoding and coercion policy
+        # with respect to PEP 538 and PEP 540.
+        stdout, stderr = run_gdb(
+            '--eval-command',
+            'python import locale; print(locale.getpreferredencoding())')
+
+        encoding = stdout
+        if stderr or not encoding:
+            raise RuntimeError(
+                f'unable to determine the Python locale preferred encoding '
+                f'of embedded Python in GDB\n'
+                f'stdout={stdout!r}\n'
+                f'stderr={stderr!r}')
+
+        def check_repr(text):
+            try:
+                text.encode(encoding)
+            except UnicodeEncodeError:
+                self.assertGdbRepr(text, ascii(text))
+            else:
+                self.assertGdbRepr(text)
+
+        self.assertGdbRepr('')
+        self.assertGdbRepr('And now for something hopefully the same')
+        self.assertGdbRepr('string with embedded NUL here \0 and then some more text')
+
+        # Test printing a single character:
+        #    U+2620 SKULL AND CROSSBONES
+        check_repr('\u2620')
+
+        # Test printing a Japanese unicode string
+        # (I believe this reads "mojibake", using 3 characters from the CJK
+        # Unified Ideographs area, followed by U+3051 HIRAGANA LETTER KE)
+        check_repr('\u6587\u5b57\u5316\u3051')
+
+        # Test a character outside the BMP:
+        #    U+1D121 MUSICAL SYMBOL C CLEF
+        # This is:
+        # UTF-8: 0xF0 0x9D 0x84 0xA1
+        # UTF-16: 0xD834 0xDD21
+        check_repr(chr(0x1D121))
+
+    def test_tuples(self):
+        'Verify the pretty-printing of tuples'
+        self.assertGdbRepr(tuple(), '()')
+        self.assertGdbRepr((1,), '(1,)')
+        self.assertGdbRepr(('foo', 'bar', 'baz'))
+
+    @support.requires_resource('cpu')
+    def test_sets(self):
+        'Verify the pretty-printing of sets'
+        if GDB_VERSION < (7, 3):
+            self.skipTest("pretty-printing of sets needs gdb 7.3 or later")
+        self.assertGdbRepr(set(), "set()")
+        self.assertGdbRepr(set(['a']), "{'a'}")
+        # PYTHONHASHSEED is need to get the exact frozenset item order
+        if not sys.flags.ignore_environment:
+            self.assertGdbRepr(set(['a', 'b']), "{'a', 'b'}")
+            self.assertGdbRepr(set([4, 5, 6]), "{4, 5, 6}")
+
+        # Ensure that we handle sets containing the "dummy" key value,
+        # which happens on deletion:
+        gdb_repr, gdb_output = self.get_gdb_repr('''s = set(['a','b'])
+s.remove('a')
+id(s)''')
+        self.assertEqual(gdb_repr, "{'b'}")
+
+    @support.requires_resource('cpu')
+    def test_frozensets(self):
+        'Verify the pretty-printing of frozensets'
+        if GDB_VERSION < (7, 3):
+            self.skipTest("pretty-printing of frozensets needs gdb 7.3 or later")
+        self.assertGdbRepr(frozenset(), "frozenset()")
+        self.assertGdbRepr(frozenset(['a']), "frozenset({'a'})")
+        # PYTHONHASHSEED is need to get the exact frozenset item order
+        if not sys.flags.ignore_environment:
+            self.assertGdbRepr(frozenset(['a', 'b']), "frozenset({'a', 'b'})")
+            self.assertGdbRepr(frozenset([4, 5, 6]), "frozenset({4, 5, 6})")
+
+    def test_exceptions(self):
+        # Test a RuntimeError
+        gdb_repr, gdb_output = self.get_gdb_repr('''
+try:
+    raise RuntimeError("I am an error")
+except RuntimeError as e:
+    id(e)
+''')
+        self.assertEqual(gdb_repr,
+                         "RuntimeError('I am an error',)")
+
+
+        # Test division by zero:
+        gdb_repr, gdb_output = self.get_gdb_repr('''
+try:
+    a = 1 / 0
+except ZeroDivisionError as e:
+    id(e)
+''')
+        self.assertEqual(gdb_repr,
+                         "ZeroDivisionError('division by zero',)")
+
+    def test_modern_class(self):
+        'Verify the pretty-printing of new-style class instances'
+        gdb_repr, gdb_output = self.get_gdb_repr('''
+class Foo:
+    pass
+foo = Foo()
+foo.an_int = 42
+id(foo)''')
+        m = re.match(r'<Foo\(an_int=42\) at remote 0x-?[0-9a-f]+>', gdb_repr)
+        self.assertTrue(m,
+                        msg='Unexpected new-style class rendering %r' % gdb_repr)
+
+    def test_subclassing_list(self):
+        'Verify the pretty-printing of an instance of a list subclass'
+        gdb_repr, gdb_output = self.get_gdb_repr('''
+class Foo(list):
+    pass
+foo = Foo()
+foo += [1, 2, 3]
+foo.an_int = 42
+id(foo)''')
+        m = re.match(r'<Foo\(an_int=42\) at remote 0x-?[0-9a-f]+>', gdb_repr)
+
+        self.assertTrue(m,
+                        msg='Unexpected new-style class rendering %r' % gdb_repr)
+
+    def test_subclassing_tuple(self):
+        'Verify the pretty-printing of an instance of a tuple subclass'
+        # This should exercise the negative tp_dictoffset code in the
+        # new-style class support
+        gdb_repr, gdb_output = self.get_gdb_repr('''
+class Foo(tuple):
+    pass
+foo = Foo((1, 2, 3))
+foo.an_int = 42
+id(foo)''')
+        m = re.match(r'<Foo\(an_int=42\) at remote 0x-?[0-9a-f]+>', gdb_repr)
+
+        self.assertTrue(m,
+                        msg='Unexpected new-style class rendering %r' % gdb_repr)
+
+    def assertSane(self, source, corruption, exprepr=None):
+        '''Run Python under gdb, corrupting variables in the inferior process
+        immediately before taking a backtrace.
+
+        Verify that the variable's representation is the expected failsafe
+        representation'''
+        if corruption:
+            cmds_after_breakpoint=[corruption, 'backtrace']
+        else:
+            cmds_after_breakpoint=['backtrace']
+
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr(source,
+                              cmds_after_breakpoint=cmds_after_breakpoint)
+        if exprepr:
+            if gdb_repr == exprepr:
+                # gdb managed to print the value in spite of the corruption;
+                # this is good (see http://bugs.python.org/issue8330)
+                return
+
+        # Match anything for the type name; 0xDEADBEEF could point to
+        # something arbitrary (see  http://bugs.python.org/issue8330)
+        pattern = '<.* at remote 0x-?[0-9a-f]+>'
+
+        m = re.match(pattern, gdb_repr)
+        if not m:
+            self.fail('Unexpected gdb representation: %r\n%s' % \
+                          (gdb_repr, gdb_output))
+
+    def test_NULL_ptr(self):
+        'Ensure that a NULL PyObject* is handled gracefully'
+        gdb_repr, gdb_output = (
+            self.get_gdb_repr('id(42)',
+                              cmds_after_breakpoint=['set variable v=0',
+                                                     'backtrace'])
+            )
+
+        self.assertEqual(gdb_repr, '0x0')
+
+    def test_NULL_ob_type(self):
+        'Ensure that a PyObject* with NULL ob_type is handled gracefully'
+        self.assertSane('id(42)',
+                        'set v->ob_type=0')
+
+    def test_corrupt_ob_type(self):
+        'Ensure that a PyObject* with a corrupt ob_type is handled gracefully'
+        self.assertSane('id(42)',
+                        'set v->ob_type=0xDEADBEEF',
+                        exprepr='42')
+
+    def test_corrupt_tp_flags(self):
+        'Ensure that a PyObject* with a type with corrupt tp_flags is handled'
+        self.assertSane('id(42)',
+                        'set v->ob_type->tp_flags=0x0',
+                        exprepr='42')
+
+    def test_corrupt_tp_name(self):
+        'Ensure that a PyObject* with a type with corrupt tp_name is handled'
+        self.assertSane('id(42)',
+                        'set v->ob_type->tp_name=0xDEADBEEF',
+                        exprepr='42')
+
+    def test_builtins_help(self):
+        'Ensure that the new-style class _Helper in site.py can be handled'
+
+        if sys.flags.no_site:
+            self.skipTest("need site module, but -S option was used")
+
+        # (this was the issue causing tracebacks in
+        #  http://bugs.python.org/issue8032#msg100537 )
+        gdb_repr, gdb_output = self.get_gdb_repr('id(__builtins__.help)', import_site=True)
+
+        m = re.match(r'<_Helper\(\) at remote 0x-?[0-9a-f]+>', gdb_repr)
+        self.assertTrue(m,
+                        msg='Unexpected rendering %r' % gdb_repr)
+
+    def test_selfreferential_list(self):
+        '''Ensure that a reference loop involving a list doesn't lead proxyval
+        into an infinite loop:'''
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr("a = [3, 4, 5] ; a.append(a) ; id(a)")
+        self.assertEqual(gdb_repr, '[3, 4, 5, [...]]')
+
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr("a = [3, 4, 5] ; b = [a] ; a.append(b) ; id(a)")
+        self.assertEqual(gdb_repr, '[3, 4, 5, [[...]]]')
+
+    def test_selfreferential_dict(self):
+        '''Ensure that a reference loop involving a dict doesn't lead proxyval
+        into an infinite loop:'''
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr("a = {} ; b = {'bar':a} ; a['foo'] = b ; id(a)")
+
+        self.assertEqual(gdb_repr, "{'foo': {'bar': {...}}}")
+
+    def test_selfreferential_old_style_instance(self):
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr('''
+class Foo:
+    pass
+foo = Foo()
+foo.an_attr = foo
+id(foo)''')
+        self.assertTrue(re.match(r'<Foo\(an_attr=<\.\.\.>\) at remote 0x-?[0-9a-f]+>',
+                                 gdb_repr),
+                        'Unexpected gdb representation: %r\n%s' % \
+                            (gdb_repr, gdb_output))
+
+    def test_selfreferential_new_style_instance(self):
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr('''
+class Foo(object):
+    pass
+foo = Foo()
+foo.an_attr = foo
+id(foo)''')
+        self.assertTrue(re.match(r'<Foo\(an_attr=<\.\.\.>\) at remote 0x-?[0-9a-f]+>',
+                                 gdb_repr),
+                        'Unexpected gdb representation: %r\n%s' % \
+                            (gdb_repr, gdb_output))
+
+        gdb_repr, gdb_output = \
+            self.get_gdb_repr('''
+class Foo(object):
+    pass
+a = Foo()
+b = Foo()
+a.an_attr = b
+b.an_attr = a
+id(a)''')
+        self.assertTrue(re.match(r'<Foo\(an_attr=<Foo\(an_attr=<\.\.\.>\) at remote 0x-?[0-9a-f]+>\) at remote 0x-?[0-9a-f]+>',
+                                 gdb_repr),
+                        'Unexpected gdb representation: %r\n%s' % \
+                            (gdb_repr, gdb_output))
+
+    def test_truncation(self):
+        'Verify that very long output is truncated'
+        gdb_repr, gdb_output = self.get_gdb_repr('id(list(range(1000)))')
+        self.assertEqual(gdb_repr,
+                         "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, "
+                         "14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, "
+                         "27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, "
+                         "40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, "
+                         "53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, "
+                         "66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, "
+                         "79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, "
+                         "92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, "
+                         "104, 105, 106, 107, 108, 109, 110, 111, 112, 113, "
+                         "114, 115, 116, 117, 118, 119, 120, 121, 122, 123, "
+                         "124, 125, 126, 127, 128, 129, 130, 131, 132, 133, "
+                         "134, 135, 136, 137, 138, 139, 140, 141, 142, 143, "
+                         "144, 145, 146, 147, 148, 149, 150, 151, 152, 153, "
+                         "154, 155, 156, 157, 158, 159, 160, 161, 162, 163, "
+                         "164, 165, 166, 167, 168, 169, 170, 171, 172, 173, "
+                         "174, 175, 176, 177, 178, 179, 180, 181, 182, 183, "
+                         "184, 185, 186, 187, 188, 189, 190, 191, 192, 193, "
+                         "194, 195, 196, 197, 198, 199, 200, 201, 202, 203, "
+                         "204, 205, 206, 207, 208, 209, 210, 211, 212, 213, "
+                         "214, 215, 216, 217, 218, 219, 220, 221, 222, 223, "
+                         "224, 225, 226...(truncated)")
+        self.assertEqual(len(gdb_repr),
+                         1024 + len('...(truncated)'))
+
+    def test_builtin_method(self):
+        gdb_repr, gdb_output = self.get_gdb_repr('import sys; id(sys.stdout.readlines)')
+        self.assertTrue(re.match(r'<built-in method readlines of _io.TextIOWrapper object at remote 0x-?[0-9a-f]+>',
+                                 gdb_repr),
+                        'Unexpected gdb representation: %r\n%s' % \
+                            (gdb_repr, gdb_output))
+
+    def test_frames(self):
+        gdb_output = self.get_stack_trace('''
+import sys
+def foo(a, b, c):
+    return sys._getframe(0)
+
+f = foo(3, 4, 5)
+id(f)''',
+                                          breakpoint='builtin_id',
+                                          cmds_after_breakpoint=['print (PyFrameObject*)v']
+                                          )
+        self.assertTrue(re.match(r'.*\s+\$1 =\s+Frame 0x-?[0-9a-f]+, for file <string>, line 4, in foo \(a=3.*',
+                                 gdb_output,
+                                 re.DOTALL),
+                        'Unexpected gdb representation: %r\n%s' % (gdb_output, gdb_output))
diff --git a/Lib/test/test_gdb/util.py b/Lib/test/test_gdb/util.py
new file mode 100644
index 0000000000..8fe9cfc543
--- /dev/null
+++ b/Lib/test/test_gdb/util.py
@@ -0,0 +1,291 @@
+import os
+import re
+import shlex
+import shutil
+import subprocess
+import sys
+import sysconfig
+import unittest
+from test import support
+
+
+GDB_PROGRAM = shutil.which('gdb') or 'gdb'
+
+# Location of custom hooks file in a repository checkout.
+CHECKOUT_HOOK_PATH = os.path.join(os.path.dirname(sys.executable),
+                                  'python-gdb.py')
+
+SAMPLE_SCRIPT = os.path.join(os.path.dirname(__file__), 'gdb_sample.py')
+BREAKPOINT_FN = 'builtin_id'
+
+PYTHONHASHSEED = '123'
+
+
+def clean_environment():
+    # Remove PYTHON* environment variables such as PYTHONHOME
+    return {name: value for name, value in os.environ.items()
+            if not name.startswith('PYTHON')}
+
+
+# Temporary value until it's initialized by get_gdb_version() below
+GDB_VERSION = (0, 0)
+
+def run_gdb(*args, exitcode=0, check=True, **env_vars):
+    """Runs gdb in --batch mode with the additional arguments given by *args.
+
+    Returns its (stdout, stderr) decoded from utf-8 using the replace handler.
+    """
+    env = clean_environment()
+    if env_vars:
+        env.update(env_vars)
+
+    cmd = [GDB_PROGRAM,
+           # Batch mode: Exit after processing all the command files
+           # specified with -x/--command
+           '--batch',
+            # -nx: Do not execute commands from any .gdbinit initialization
+            # files (gh-66384)
+           '-nx']
+    if GDB_VERSION >= (7, 4):
+        cmd.extend(('--init-eval-command',
+                    f'add-auto-load-safe-path {CHECKOUT_HOOK_PATH}'))
+    cmd.extend(args)
+
+    proc = subprocess.run(
+        cmd,
+        # Redirect stdin to prevent gdb from messing with the terminal settings
+        stdin=subprocess.PIPE,
+        stdout=subprocess.PIPE,
+        stderr=subprocess.PIPE,
+        encoding="utf8", errors="backslashreplace",
+        env=env)
+
+    stdout = proc.stdout
+    stderr = proc.stderr
+    if check and proc.returncode != exitcode:
+        cmd_text = shlex.join(cmd)
+        raise Exception(f"{cmd_text} failed with exit code {proc.returncode}, "
+                        f"expected exit code {exitcode}:\n"
+                        f"stdout={stdout!r}\n"
+                        f"stderr={stderr!r}")
+
+    return (stdout, stderr)
+
+
+def get_gdb_version():
+    try:
+        stdout, stderr = run_gdb('--version')
+    except OSError as exc:
+        # This is what "no gdb" looks like.  There may, however, be other
+        # errors that manifest this way too.
+        raise unittest.SkipTest(f"Couldn't find gdb program on the path: {exc}")
+
+    # Regex to parse:
+    # 'GNU gdb (GDB; SUSE Linux Enterprise 12) 7.7\n' -> 7.7
+    # 'GNU gdb (GDB) Fedora 7.9.1-17.fc22\n' -> 7.9
+    # 'GNU gdb 6.1.1 [FreeBSD]\n' -> 6.1
+    # 'GNU gdb (GDB) Fedora (7.5.1-37.fc18)\n' -> 7.5
+    # 'HP gdb 6.7 for HP Itanium (32 or 64 bit) and target HP-UX 11iv2 and 11iv3.\n' -> 6.7
+    match = re.search(r"^(?:GNU|HP) gdb.*?\b(\d+)\.(\d+)", stdout)
+    if match is None:
+        raise Exception("unable to parse gdb version: %r" % stdout)
+    version_text = stdout
+    major = int(match.group(1))
+    minor = int(match.group(2))
+    version = (major, minor)
+    return (version_text, version)
+
+GDB_VERSION_TEXT, GDB_VERSION = get_gdb_version()
+if GDB_VERSION < (7, 0):
+    raise unittest.SkipTest(
+        f"gdb versions before 7.0 didn't support python embedding. "
+        f"Saw gdb version {GDB_VERSION[0]}.{GDB_VERSION[1]}:\n"
+        f"{GDB_VERSION_TEXT}")
+
+
+def check_usable_gdb():
+    # Verify that "gdb" was built with the embedded Python support enabled and
+    # verify that "gdb" can load our custom hooks, as OS security settings may
+    # disallow this without a customized .gdbinit.
+    stdout, stderr = run_gdb(
+        '--eval-command=python import sys; print(sys.version_info)',
+        '--args', sys.executable,
+        check=False)
+
+    if "auto-loading has been declined" in stderr:
+        raise unittest.SkipTest(
+            f"gdb security settings prevent use of custom hooks; "
+            f"stderr: {stderr!r}")
+
+    if not stdout:
+        raise unittest.SkipTest(
+            f"gdb not built with embedded python support; "
+            f"stderr: {stderr!r}")
+
+    if "major=2" in stdout:
+        raise unittest.SkipTest("gdb built with Python 2")
+
+check_usable_gdb()
+
+
+# Control-flow enforcement technology
+def cet_protection():
+    cflags = sysconfig.get_config_var('CFLAGS')
+    if not cflags:
+        return False
+    flags = cflags.split()
+    # True if "-mcet -fcf-protection" options are found, but false
+    # if "-fcf-protection=none" or "-fcf-protection=return" is found.
+    return (('-mcet' in flags)
+            and any((flag.startswith('-fcf-protection')
+                     and not flag.endswith(("=none", "=return")))
+                    for flag in flags))
+CET_PROTECTION = cet_protection()
+
+
+def setup_module():
+    if support.verbose:
+        print(f"gdb version {GDB_VERSION[0]}.{GDB_VERSION[1]}:")
+        for line in GDB_VERSION_TEXT.splitlines():
+            print(" " * 4 + line)
+        print(f"    path: {GDB_PROGRAM}")
+        print()
+
+
+class DebuggerTests(unittest.TestCase):
+
+    """Test that the debugger can debug Python."""
+
+    def get_stack_trace(self, source=None, script=None,
+                        breakpoint=BREAKPOINT_FN,
+                        cmds_after_breakpoint=None,
+                        import_site=False,
+                        ignore_stderr=False):
+        '''
+        Run 'python -c SOURCE' under gdb with a breakpoint.
+
+        Support injecting commands after the breakpoint is reached
+
+        Returns the stdout from gdb
+
+        cmds_after_breakpoint: if provided, a list of strings: gdb commands
+        '''
+        # We use "set breakpoint pending yes" to avoid blocking with a:
+        #   Function "foo" not defined.
+        #   Make breakpoint pending on future shared library load? (y or [n])
+        # error, which typically happens python is dynamically linked (the
+        # breakpoints of interest are to be found in the shared library)
+        # When this happens, we still get:
+        #   Function "textiowrapper_write" not defined.
+        # emitted to stderr each time, alas.
+
+        # Initially I had "--eval-command=continue" here, but removed it to
+        # avoid repeated print breakpoints when traversing hierarchical data
+        # structures
+
+        # Generate a list of commands in gdb's language:
+        commands = [
+            'set breakpoint pending yes',
+            'break %s' % breakpoint,
+
+            # The tests assume that the first frame of printed
+            #  backtrace will not contain program counter,
+            #  that is however not guaranteed by gdb
+            #  therefore we need to use 'set print address off' to
+            #  make sure the counter is not there. For example:
+            # #0 in PyObject_Print ...
+            #  is assumed, but sometimes this can be e.g.
+            # #0 0x00003fffb7dd1798 in PyObject_Print ...
+            'set print address off',
+
+            'run',
+        ]
+
+        # GDB as of 7.4 onwards can distinguish between the
+        # value of a variable at entry vs current value:
+        #   http://sourceware.org/gdb/onlinedocs/gdb/Variables.html
+        # which leads to the selftests failing with errors like this:
+        #   AssertionError: 'v@entry=()' != '()'
+        # Disable this:
+        if GDB_VERSION >= (7, 4):
+            commands += ['set print entry-values no']
+
+        if cmds_after_breakpoint:
+            if CET_PROTECTION:
+                # bpo-32962: When Python is compiled with -mcet
+                # -fcf-protection, function arguments are unusable before
+                # running the first instruction of the function entry point.
+                # The 'next' command makes the required first step.
+                commands += ['next']
+            commands += cmds_after_breakpoint
+        else:
+            commands += ['backtrace']
+
+        # print commands
+
+        # Use "commands" to generate the arguments with which to invoke "gdb":
+        args = ['--eval-command=%s' % cmd for cmd in commands]
+        args += ["--args",
+                 sys.executable]
+        args.extend(subprocess._args_from_interpreter_flags())
+
+        if not import_site:
+            # -S suppresses the default 'import site'
+            args += ["-S"]
+
+        if source:
+            args += ["-c", source]
+        elif script:
+            args += [script]
+
+        # Use "args" to invoke gdb, capturing stdout, stderr:
+        out, err = run_gdb(*args, PYTHONHASHSEED=PYTHONHASHSEED)
+
+        if not ignore_stderr:
+            for line in err.splitlines():
+                print(line, file=sys.stderr)
+
+        # bpo-34007: Sometimes some versions of the shared libraries that
+        # are part of the traceback are compiled in optimised mode and the
+        # Program Counter (PC) is not present, not allowing gdb to walk the
+        # frames back. When this happens, the Python bindings of gdb raise
+        # an exception, making the test impossible to succeed.
+        if "PC not saved" in err:
+            raise unittest.SkipTest("gdb cannot walk the frame object"
+                                    " because the Program Counter is"
+                                    " not present")
+
+        # bpo-40019: Skip the test if gdb failed to read debug information
+        # because the Python binary is optimized.
+        for pattern in (
+            '(frame information optimized out)',
+            'Unable to read information on python frame',
+
+            # gh-91960: On Python built with "clang -Og", gdb gets
+            # "frame=<optimized out>" for _PyEval_EvalFrameDefault() parameter
+            '(unable to read python frame information)',
+
+            # gh-104736: On Python built with "clang -Og" on ppc64le,
+            # "py-bt" displays a truncated or not traceback, but "where"
+            # logs this error message:
+            'Backtrace stopped: frame did not save the PC',
+
+            # gh-104736: When "bt" command displays something like:
+            # "#1  0x0000000000000000 in ?? ()", the traceback is likely
+            # truncated or wrong.
+            ' ?? ()',
+        ):
+            if pattern in out:
+                raise unittest.SkipTest(f"{pattern!r} found in gdb output")
+
+        return out
+
+    def assertEndsWith(self, actual, exp_end):
+        '''Ensure that the given "actual" string ends with "exp_end"'''
+        self.assertTrue(actual.endswith(exp_end),
+                        msg='%r did not end with %r' % (actual, exp_end))
+
+    def assertMultilineMatches(self, actual, pattern):
+        m = re.match(pattern, actual, re.DOTALL)
+        if not m:
+            self.fail(msg='%r did not match %r' % (actual, pattern))
diff --git a/Lib/test/test_genericclass.py b/Lib/test/test_genericclass.py
index d8bb37f69e..aece757fc1 100644
--- a/Lib/test/test_genericclass.py
+++ b/Lib/test/test_genericclass.py
@@ -98,7 +98,7 @@ def __mro_entries__(self):
                 return ()
         d = C_too_few()
         with self.assertRaises(TypeError):
-            class D(d): ...
+            class E(d): ...
 
     def test_mro_entry_errors_2(self):
         class C_not_callable:
@@ -111,7 +111,7 @@ def __mro_entries__(self):
                 return object
         c = C_not_tuple()
         with self.assertRaises(TypeError):
-            class D(c): ...
+            class E(c): ...
 
     def test_mro_entry_metaclass(self):
         meta_args = []
diff --git a/Lib/test/test_gettext.py b/Lib/test/test_gettext.py
index 8430fc234d..dd33b9b88f 100644
--- a/Lib/test/test_gettext.py
+++ b/Lib/test/test_gettext.py
@@ -2,6 +2,7 @@
 import base64
 import gettext
 import unittest
+from functools import partial
 
 from test import support
 from test.support import os_helper
@@ -115,9 +116,16 @@
 MMOFILE = os.path.join(LOCALEDIR, 'metadata.mo')
 
 
+def reset_gettext():
+    gettext._localedirs.clear()
+    gettext._current_domain = 'messages'
+    gettext._translations.clear()
+
+
 class GettextBaseTest(unittest.TestCase):
-    def setUp(self):
-        self.addCleanup(os_helper.rmtree, os.path.split(LOCALEDIR)[0])
+    @classmethod
+    def setUpClass(cls):
+        cls.addClassCleanup(os_helper.rmtree, os.path.split(LOCALEDIR)[0])
         if not os.path.isdir(LOCALEDIR):
             os.makedirs(LOCALEDIR)
         with open(MOFILE, 'wb') as fp:
@@ -130,9 +138,12 @@ def setUp(self):
             fp.write(base64.decodebytes(UMO_DATA))
         with open(MMOFILE, 'wb') as fp:
             fp.write(base64.decodebytes(MMO_DATA))
+
+    def setUp(self):
         self.env = self.enterContext(os_helper.EnvironmentVarGuard())
         self.env['LANGUAGE'] = 'xx'
-        gettext._translations.clear()
+        reset_gettext()
+        self.addCleanup(reset_gettext)
 
 
 GNU_MO_DATA_ISSUE_17898 = b'''\
@@ -309,55 +320,137 @@ def test_multiline_strings(self):
 trggrkg zrffntr pngnybt yvoenel.''')
 
 
-class PluralFormsTestCase(GettextBaseTest):
+class PluralFormsTests:
+
+    def _test_plural_forms(self, ngettext, gettext,
+                           singular, plural, tsingular, tplural,
+                           numbers_only=True):
+        x = ngettext(singular, plural, 1)
+        self.assertEqual(x, tsingular)
+        x = ngettext(singular, plural, 2)
+        self.assertEqual(x, tplural)
+        x = gettext(singular)
+        self.assertEqual(x, tsingular)
+
+        if numbers_only:
+            lineno = self._test_plural_forms.__code__.co_firstlineno + 9
+            with self.assertWarns(DeprecationWarning) as cm:
+                x = ngettext(singular, plural, 1.0)
+            self.assertEqual(cm.filename, __file__)
+            self.assertEqual(cm.lineno, lineno + 4)
+            self.assertEqual(x, tsingular)
+            with self.assertWarns(DeprecationWarning) as cm:
+                x = ngettext(singular, plural, 1.1)
+            self.assertEqual(cm.filename, __file__)
+            self.assertEqual(cm.lineno, lineno + 9)
+            self.assertEqual(x, tplural)
+            with self.assertRaises(TypeError):
+                ngettext(singular, plural, None)
+        else:
+            x = ngettext(singular, plural, None)
+            self.assertEqual(x, tplural)
+
+    def test_plural_forms(self):
+        self._test_plural_forms(
+            self.ngettext, self.gettext,
+            'There is %s file', 'There are %s files',
+            'Hay %s fichero', 'Hay %s ficheros')
+        self._test_plural_forms(
+            self.ngettext, self.gettext,
+            '%d file deleted', '%d files deleted',
+            '%d file deleted', '%d files deleted')
+
+    def test_plural_context_forms(self):
+        ngettext = partial(self.npgettext, 'With context')
+        gettext = partial(self.pgettext, 'With context')
+        self._test_plural_forms(
+            ngettext, gettext,
+            'There is %s file', 'There are %s files',
+            'Hay %s fichero (context)', 'Hay %s ficheros (context)')
+        self._test_plural_forms(
+            ngettext, gettext,
+            '%d file deleted', '%d files deleted',
+            '%d file deleted', '%d files deleted')
+
+    def test_plural_wrong_context_forms(self):
+        self._test_plural_forms(
+            partial(self.npgettext, 'Unknown context'),
+            partial(self.pgettext, 'Unknown context'),
+            'There is %s file', 'There are %s files',
+            'There is %s file', 'There are %s files')
+
+
+class GNUTranslationsPluralFormsTestCase(PluralFormsTests, GettextBaseTest):
     def setUp(self):
         GettextBaseTest.setUp(self)
-        self.mofile = MOFILE
+        # Set up the bindings
+        gettext.bindtextdomain('gettext', os.curdir)
+        gettext.textdomain('gettext')
 
-    def test_plural_forms1(self):
-        eq = self.assertEqual
-        x = gettext.ngettext('There is %s file', 'There are %s files', 1)
-        eq(x, 'Hay %s fichero')
-        x = gettext.ngettext('There is %s file', 'There are %s files', 2)
-        eq(x, 'Hay %s ficheros')
-        x = gettext.gettext('There is %s file')
-        eq(x, 'Hay %s fichero')
-
-    def test_plural_context_forms1(self):
-        eq = self.assertEqual
-        x = gettext.npgettext('With context',
-                              'There is %s file', 'There are %s files', 1)
-        eq(x, 'Hay %s fichero (context)')
-        x = gettext.npgettext('With context',
-                              'There is %s file', 'There are %s files', 2)
-        eq(x, 'Hay %s ficheros (context)')
-        x = gettext.pgettext('With context', 'There is %s file')
-        eq(x, 'Hay %s fichero (context)')
-
-    def test_plural_forms2(self):
-        eq = self.assertEqual
-        with open(self.mofile, 'rb') as fp:
-            t = gettext.GNUTranslations(fp)
-        x = t.ngettext('There is %s file', 'There are %s files', 1)
-        eq(x, 'Hay %s fichero')
-        x = t.ngettext('There is %s file', 'There are %s files', 2)
-        eq(x, 'Hay %s ficheros')
-        x = t.gettext('There is %s file')
-        eq(x, 'Hay %s fichero')
-
-    def test_plural_context_forms2(self):
-        eq = self.assertEqual
-        with open(self.mofile, 'rb') as fp:
+        self.gettext = gettext.gettext
+        self.ngettext = gettext.ngettext
+        self.pgettext = gettext.pgettext
+        self.npgettext = gettext.npgettext
+
+
+class GNUTranslationsWithDomainPluralFormsTestCase(PluralFormsTests, GettextBaseTest):
+    def setUp(self):
+        GettextBaseTest.setUp(self)
+        # Set up the bindings
+        gettext.bindtextdomain('gettext', os.curdir)
+
+        self.gettext = partial(gettext.dgettext, 'gettext')
+        self.ngettext = partial(gettext.dngettext, 'gettext')
+        self.pgettext = partial(gettext.dpgettext, 'gettext')
+        self.npgettext = partial(gettext.dnpgettext, 'gettext')
+
+    def test_plural_forms_wrong_domain(self):
+        self._test_plural_forms(
+            partial(gettext.dngettext, 'unknown'),
+            partial(gettext.dgettext, 'unknown'),
+            'There is %s file', 'There are %s files',
+            'There is %s file', 'There are %s files',
+            numbers_only=False)
+
+    def test_plural_context_forms_wrong_domain(self):
+        self._test_plural_forms(
+            partial(gettext.dnpgettext, 'unknown', 'With context'),
+            partial(gettext.dpgettext, 'unknown', 'With context'),
+            'There is %s file', 'There are %s files',
+            'There is %s file', 'There are %s files',
+            numbers_only=False)
+
+
+class GNUTranslationsClassPluralFormsTestCase(PluralFormsTests, GettextBaseTest):
+    def setUp(self):
+        GettextBaseTest.setUp(self)
+        with open(MOFILE, 'rb') as fp:
             t = gettext.GNUTranslations(fp)
-        x = t.npgettext('With context',
-                        'There is %s file', 'There are %s files', 1)
-        eq(x, 'Hay %s fichero (context)')
-        x = t.npgettext('With context',
-                        'There is %s file', 'There are %s files', 2)
-        eq(x, 'Hay %s ficheros (context)')
-        x = gettext.pgettext('With context', 'There is %s file')
-        eq(x, 'Hay %s fichero (context)')
 
+        self.gettext = t.gettext
+        self.ngettext = t.ngettext
+        self.pgettext = t.pgettext
+        self.npgettext = t.npgettext
+
+    def test_plural_forms_null_translations(self):
+        t = gettext.NullTranslations()
+        self._test_plural_forms(
+            t.ngettext, t.gettext,
+            'There is %s file', 'There are %s files',
+            'There is %s file', 'There are %s files',
+            numbers_only=False)
+
+    def test_plural_context_forms_null_translations(self):
+        t = gettext.NullTranslations()
+        self._test_plural_forms(
+            partial(t.npgettext, 'With context'),
+            partial(t.pgettext, 'With context'),
+            'There is %s file', 'There are %s files',
+            'There is %s file', 'There are %s files',
+            numbers_only=False)
+
+
+class PluralFormsInternalTestCase:
     # Examples from http://www.gnu.org/software/gettext/manual/gettext.html
 
     def test_ja(self):
diff --git a/Lib/test/test_grammar.py b/Lib/test/test_grammar.py
index b2415d5791..8501006b79 100644
--- a/Lib/test/test_grammar.py
+++ b/Lib/test/test_grammar.py
@@ -12,9 +12,9 @@
 
 # different import patterns to check that __annotations__ does not interfere
 # with import machinery
-import test.ann_module as ann_module
+import test.typinganndata.ann_module as ann_module
 import typing
-from test import ann_module2
+from test.typinganndata import ann_module2
 import test
 
 # These are shared with test_tokenize and other test modules.
@@ -236,6 +236,10 @@ def check(test, error=False):
             check(f"[{num}for x in ()]")
             check(f"{num}spam", error=True)
 
+            # gh-88943: Invalid non-ASCII character following a numerical literal.
+            with self.assertRaisesRegex(SyntaxError, r"invalid character '⁄' \(U\+2044\)"):
+                compile(f"{num}⁄7", "<testcase>", "eval")
+
             with self.assertWarnsRegex(SyntaxWarning, r'invalid \w+ literal'):
                 compile(f"{num}is x", "<testcase>", "eval")
             with warnings.catch_warnings():
@@ -463,7 +467,7 @@ def test_var_annot_module_semantics(self):
     def test_var_annot_in_module(self):
         # check that functions fail the same way when executed
         # outside of module where they were defined
-        ann_module3 = import_helper.import_fresh_module("test.ann_module3")
+        ann_module3 = import_helper.import_fresh_module("test.typinganndata.ann_module3")
         with self.assertRaises(NameError):
             ann_module3.f_bad_ann()
         with self.assertRaises(NameError):
diff --git a/Lib/test/test_httplib.py b/Lib/test/test_httplib.py
index 676725c46e..5d5832b62b 100644
--- a/Lib/test/test_httplib.py
+++ b/Lib/test/test_httplib.py
@@ -21,11 +21,13 @@
 
 here = os.path.dirname(__file__)
 # Self-signed cert file for 'localhost'
-CERT_localhost = os.path.join(here, 'keycert.pem')
+CERT_localhost = os.path.join(here, 'certdata', 'keycert.pem')
 # Self-signed cert file for 'fakehostname'
-CERT_fakehostname = os.path.join(here, 'keycert2.pem')
+CERT_fakehostname = os.path.join(here, 'certdata', 'keycert2.pem')
 # Self-signed cert file for self-signed.pythontest.net
-CERT_selfsigned_pythontestdotnet = os.path.join(here, 'selfsigned_pythontestdotnet.pem')
+CERT_selfsigned_pythontestdotnet = os.path.join(
+    here, 'certdata', 'selfsigned_pythontestdotnet.pem',
+)
 
 # constants for testing chunked encoding
 chunked_start = (
diff --git a/Lib/test/test_imaplib.py b/Lib/test/test_imaplib.py
index 4b38355c37..def9f45d63 100644
--- a/Lib/test/test_imaplib.py
+++ b/Lib/test/test_imaplib.py
@@ -23,8 +23,8 @@
 
 support.requires_working_socket(module=True)
 
-CERTFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "keycert3.pem")
-CAFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "pycacert.pem")
+CERTFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "certdata", "keycert3.pem")
+CAFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "certdata", "pycacert.pem")
 
 
 class TestImaplib(unittest.TestCase):
diff --git a/Lib/test/test_import/__init__.py b/Lib/test/test_import/__init__.py
index 62585b23a7..67904cf425 100644
--- a/Lib/test/test_import/__init__.py
+++ b/Lib/test/test_import/__init__.py
@@ -1,5 +1,4 @@
 import builtins
-import contextlib
 import errno
 import glob
 import json
@@ -30,9 +29,10 @@
     STDLIB_DIR, swap_attr, swap_item, cpython_only, is_emscripten,
     is_wasi, run_in_subinterp, run_in_subinterp_with_config)
 from test.support.import_helper import (
-    forget, make_legacy_pyc, unlink, unload, DirsOnSysPath, CleanImport)
+    forget, make_legacy_pyc, unlink, unload, ready_to_import,
+    DirsOnSysPath, CleanImport)
 from test.support.os_helper import (
-    TESTFN, rmtree, temp_umask, TESTFN_UNENCODABLE, temp_dir)
+    TESTFN, rmtree, temp_umask, TESTFN_UNENCODABLE)
 from test.support import script_helper
 from test.support import threading_helper
 from test.test_importlib.util import uncache
@@ -125,27 +125,6 @@ def wrapper(self):
     return deco
 
 
-@contextlib.contextmanager
-def _ready_to_import(name=None, source=""):
-    # sets up a temporary directory and removes it
-    # creates the module file
-    # temporarily clears the module from sys.modules (if any)
-    # reverts or removes the module when cleaning up
-    name = name or "spam"
-    with temp_dir() as tempdir:
-        path = script_helper.make_script(tempdir, name, source)
-        old_module = sys.modules.pop(name, None)
-        try:
-            sys.path.insert(0, tempdir)
-            yield name, path
-            sys.path.remove(tempdir)
-        finally:
-            if old_module is not None:
-                sys.modules[name] = old_module
-            elif name in sys.modules:
-                del sys.modules[name]
-
-
 if _testsinglephase is not None:
     def restore__testsinglephase(*, _orig=_testsinglephase):
         # We started with the module imported and want to restore
@@ -401,7 +380,7 @@ def test_from_import_missing_attr_path_is_canonical(self):
 
     def test_from_import_star_invalid_type(self):
         import re
-        with _ready_to_import() as (name, path):
+        with ready_to_import() as (name, path):
             with open(path, 'w', encoding='utf-8') as f:
                 f.write("__all__ = [b'invalid_type']")
             globals = {}
@@ -410,7 +389,7 @@ def test_from_import_star_invalid_type(self):
             ):
                 exec(f"from {name} import *", globals)
             self.assertNotIn(b"invalid_type", globals)
-        with _ready_to_import() as (name, path):
+        with ready_to_import() as (name, path):
             with open(path, 'w', encoding='utf-8') as f:
                 f.write("globals()[b'invalid_type'] = object()")
             globals = {}
@@ -818,7 +797,7 @@ class FilePermissionTests(unittest.TestCase):
     )
     def test_creation_mode(self):
         mask = 0o022
-        with temp_umask(mask), _ready_to_import() as (name, path):
+        with temp_umask(mask), ready_to_import() as (name, path):
             cached_path = importlib.util.cache_from_source(path)
             module = __import__(name)
             if not os.path.exists(cached_path):
@@ -837,7 +816,7 @@ def test_creation_mode(self):
     def test_cached_mode_issue_2051(self):
         # permissions of .pyc should match those of .py, regardless of mask
         mode = 0o600
-        with temp_umask(0o022), _ready_to_import() as (name, path):
+        with temp_umask(0o022), ready_to_import() as (name, path):
             cached_path = importlib.util.cache_from_source(path)
             os.chmod(path, mode)
             __import__(name)
@@ -853,7 +832,7 @@ def test_cached_mode_issue_2051(self):
     @os_helper.skip_unless_working_chmod
     def test_cached_readonly(self):
         mode = 0o400
-        with temp_umask(0o022), _ready_to_import() as (name, path):
+        with temp_umask(0o022), ready_to_import() as (name, path):
             cached_path = importlib.util.cache_from_source(path)
             os.chmod(path, mode)
             __import__(name)
@@ -868,7 +847,7 @@ def test_cached_readonly(self):
     def test_pyc_always_writable(self):
         # Initially read-only .pyc files on Windows used to cause problems
         # with later updates, see issue #6074 for details
-        with _ready_to_import() as (name, path):
+        with ready_to_import() as (name, path):
             # Write a Python file, make it read-only and import it
             with open(path, 'w', encoding='utf-8') as f:
                 f.write("x = 'original'\n")
diff --git a/Lib/test/test_importlib/test_locks.py b/Lib/test/test_importlib/test_locks.py
index ba9cf51c26..befac5d62b 100644
--- a/Lib/test/test_importlib/test_locks.py
+++ b/Lib/test/test_importlib/test_locks.py
@@ -29,6 +29,8 @@ class ModuleLockAsRLockTests:
     test_timeout = None
     # _release_save() unsupported
     test_release_save_unacquired = None
+    # _recursion_count() unsupported
+    test_recursion_count = None
     # lock status in repr unsupported
     test_repr = None
     test_locked_repr = None
@@ -91,7 +93,8 @@ def f():
                 b.release()
             if ra:
                 a.release()
-        lock_tests.Bunch(f, NTHREADS).wait_for_finished()
+        with lock_tests.Bunch(f, NTHREADS):
+            pass
         self.assertEqual(len(results), NTHREADS)
         return results
 
diff --git a/Lib/test/test_inspect.py b/Lib/test/test_inspect.py
deleted file mode 100644
index d89953ab60..0000000000
--- a/Lib/test/test_inspect.py
+++ /dev/null
@@ -1,4751 +0,0 @@
-import asyncio
-import builtins
-import collections
-import datetime
-import functools
-import importlib
-import inspect
-import io
-import linecache
-import os
-import dis
-from os.path import normcase
-import _pickle
-import pickle
-import shutil
-import sys
-import types
-import textwrap
-import unicodedata
-import unittest
-import unittest.mock
-import warnings
-
-try:
-    from concurrent.futures import ThreadPoolExecutor
-except ImportError:
-    ThreadPoolExecutor = None
-
-from test.support import cpython_only
-from test.support import MISSING_C_DOCSTRINGS, ALWAYS_EQ
-from test.support.import_helper import DirsOnSysPath
-from test.support.os_helper import TESTFN
-from test.support.script_helper import assert_python_ok, assert_python_failure
-from test import inspect_fodder as mod
-from test import inspect_fodder2 as mod2
-from test import support
-from test import inspect_stock_annotations
-from test import inspect_stringized_annotations
-from test import inspect_stringized_annotations_2
-
-from test.test_import import _ready_to_import
-
-
-# Functions tested in this suite:
-# ismodule, isclass, ismethod, isfunction, istraceback, isframe, iscode,
-# isbuiltin, isroutine, isgenerator, isgeneratorfunction, getmembers,
-# getdoc, getfile, getmodule, getsourcefile, getcomments, getsource,
-# getclasstree, getargvalues, formatargvalues,
-# currentframe, stack, trace, isdatadescriptor,
-# ismethodwrapper
-
-# NOTE: There are some additional tests relating to interaction with
-#       zipimport in the test_zipimport_support test module.
-
-modfile = mod.__file__
-if modfile.endswith(('c', 'o')):
-    modfile = modfile[:-1]
-
-# Normalize file names: on Windows, the case of file names of compiled
-# modules depends on the path used to start the python executable.
-modfile = normcase(modfile)
-
-def revise(filename, *args):
-    return (normcase(filename),) + args
-
-git = mod.StupidGit()
-
-
-def tearDownModule():
-    if support.has_socket_support:
-        asyncio.set_event_loop_policy(None)
-
-
-def signatures_with_lexicographic_keyword_only_parameters():
-    """
-    Yields a whole bunch of functions with only keyword-only parameters,
-    where those parameters are always in lexicographically sorted order.
-    """
-    parameters = ['a', 'bar', 'c', 'delta', 'ephraim', 'magical', 'yoyo', 'z']
-    for i in range(1, 2**len(parameters)):
-        p = []
-        bit = 1
-        for j in range(len(parameters)):
-            if i & (bit << j):
-                p.append(parameters[j])
-        fn_text = "def foo(*, " + ", ".join(p) + "): pass"
-        symbols = {}
-        exec(fn_text, symbols, symbols)
-        yield symbols['foo']
-
-
-def unsorted_keyword_only_parameters_fn(*, throw, out, the, baby, with_,
-                                        the_, bathwater):
-    pass
-
-unsorted_keyword_only_parameters = 'throw out the baby with_ the_ bathwater'.split()
-
-class IsTestBase(unittest.TestCase):
-    predicates = set([inspect.isbuiltin, inspect.isclass, inspect.iscode,
-                      inspect.isframe, inspect.isfunction, inspect.ismethod,
-                      inspect.ismodule, inspect.istraceback,
-                      inspect.isgenerator, inspect.isgeneratorfunction,
-                      inspect.iscoroutine, inspect.iscoroutinefunction,
-                      inspect.isasyncgen, inspect.isasyncgenfunction,
-                      inspect.ismethodwrapper])
-
-    def istest(self, predicate, exp):
-        obj = eval(exp)
-        self.assertTrue(predicate(obj), '%s(%s)' % (predicate.__name__, exp))
-
-        for other in self.predicates - set([predicate]):
-            if (predicate == inspect.isgeneratorfunction or \
-               predicate == inspect.isasyncgenfunction or \
-               predicate == inspect.iscoroutinefunction) and \
-               other == inspect.isfunction:
-                continue
-            self.assertFalse(other(obj), 'not %s(%s)' % (other.__name__, exp))
-
-    def test__all__(self):
-        support.check__all__(self, inspect, not_exported=("modulesbyfile",))
-
-def generator_function_example(self):
-    for i in range(2):
-        yield i
-
-async def async_generator_function_example(self):
-    async for i in range(2):
-        yield i
-
-async def coroutine_function_example(self):
-    return 'spam'
-
-@types.coroutine
-def gen_coroutine_function_example(self):
-    yield
-    return 'spam'
-
-class TestPredicates(IsTestBase):
-
-    def test_excluding_predicates(self):
-        global tb
-        self.istest(inspect.isbuiltin, 'sys.exit')
-        self.istest(inspect.isbuiltin, '[].append')
-        self.istest(inspect.iscode, 'mod.spam.__code__')
-        try:
-            1/0
-        except Exception as e:
-            tb = e.__traceback__
-            self.istest(inspect.isframe, 'tb.tb_frame')
-            self.istest(inspect.istraceback, 'tb')
-            if hasattr(types, 'GetSetDescriptorType'):
-                self.istest(inspect.isgetsetdescriptor,
-                            'type(tb.tb_frame).f_locals')
-            else:
-                self.assertFalse(inspect.isgetsetdescriptor(type(tb.tb_frame).f_locals))
-        finally:
-            # Clear traceback and all the frames and local variables hanging to it.
-            tb = None
-        self.istest(inspect.isfunction, 'mod.spam')
-        self.istest(inspect.isfunction, 'mod.StupidGit.abuse')
-        self.istest(inspect.ismethod, 'git.argue')
-        self.istest(inspect.ismethod, 'mod.custom_method')
-        self.istest(inspect.ismodule, 'mod')
-        self.istest(inspect.isdatadescriptor, 'collections.defaultdict.default_factory')
-        self.istest(inspect.isgenerator, '(x for x in range(2))')
-        self.istest(inspect.isgeneratorfunction, 'generator_function_example')
-        self.istest(inspect.isasyncgen,
-                    'async_generator_function_example(1)')
-        self.istest(inspect.isasyncgenfunction,
-                    'async_generator_function_example')
-
-        with warnings.catch_warnings():
-            warnings.simplefilter("ignore")
-            self.istest(inspect.iscoroutine, 'coroutine_function_example(1)')
-            self.istest(inspect.iscoroutinefunction, 'coroutine_function_example')
-
-        if hasattr(types, 'MemberDescriptorType'):
-            self.istest(inspect.ismemberdescriptor, 'datetime.timedelta.days')
-        else:
-            self.assertFalse(inspect.ismemberdescriptor(datetime.timedelta.days))
-        self.istest(inspect.ismethodwrapper, "object().__str__")
-        self.istest(inspect.ismethodwrapper, "object().__eq__")
-        self.istest(inspect.ismethodwrapper, "object().__repr__")
-        self.assertFalse(inspect.ismethodwrapper(type))
-        self.assertFalse(inspect.ismethodwrapper(int))
-        self.assertFalse(inspect.ismethodwrapper(type("AnyClass", (), {})))
-
-
-
-    def test_iscoroutine(self):
-        async_gen_coro = async_generator_function_example(1)
-        gen_coro = gen_coroutine_function_example(1)
-        coro = coroutine_function_example(1)
-
-        self.assertFalse(
-            inspect.iscoroutinefunction(gen_coroutine_function_example))
-        self.assertFalse(
-            inspect.iscoroutinefunction(
-                functools.partial(functools.partial(
-                    gen_coroutine_function_example))))
-        self.assertFalse(inspect.iscoroutine(gen_coro))
-
-        self.assertTrue(
-            inspect.isgeneratorfunction(gen_coroutine_function_example))
-        self.assertTrue(
-            inspect.isgeneratorfunction(
-                functools.partial(functools.partial(
-                    gen_coroutine_function_example))))
-        self.assertTrue(inspect.isgenerator(gen_coro))
-
-        async def _fn3():
-            pass
-
-        @inspect.markcoroutinefunction
-        def fn3():
-            return _fn3()
-
-        self.assertTrue(inspect.iscoroutinefunction(fn3))
-        self.assertTrue(
-            inspect.iscoroutinefunction(
-                inspect.markcoroutinefunction(lambda: _fn3())
-            )
-        )
-
-        class Cl:
-            async def __call__(self):
-                pass
-
-        self.assertFalse(inspect.iscoroutinefunction(Cl))
-        # instances with async def __call__ are NOT recognised.
-        self.assertFalse(inspect.iscoroutinefunction(Cl()))
-        # unless explicitly marked.
-        self.assertTrue(inspect.iscoroutinefunction(
-            inspect.markcoroutinefunction(Cl())
-        ))
-
-        class Cl2:
-            @inspect.markcoroutinefunction
-            def __call__(self):
-                pass
-
-        self.assertFalse(inspect.iscoroutinefunction(Cl2))
-        # instances with marked __call__ are NOT recognised.
-        self.assertFalse(inspect.iscoroutinefunction(Cl2()))
-        # unless explicitly marked.
-        self.assertTrue(inspect.iscoroutinefunction(
-            inspect.markcoroutinefunction(Cl2())
-        ))
-
-        class Cl3:
-            @inspect.markcoroutinefunction
-            @classmethod
-            def do_something_classy(cls):
-                pass
-
-            @inspect.markcoroutinefunction
-            @staticmethod
-            def do_something_static():
-                pass
-
-        self.assertTrue(inspect.iscoroutinefunction(Cl3.do_something_classy))
-        self.assertTrue(inspect.iscoroutinefunction(Cl3.do_something_static))
-
-        self.assertFalse(
-            inspect.iscoroutinefunction(unittest.mock.Mock()))
-        self.assertTrue(
-            inspect.iscoroutinefunction(unittest.mock.AsyncMock()))
-        self.assertTrue(
-            inspect.iscoroutinefunction(coroutine_function_example))
-        self.assertTrue(
-            inspect.iscoroutinefunction(
-                functools.partial(functools.partial(
-                    coroutine_function_example))))
-        self.assertTrue(inspect.iscoroutine(coro))
-
-        self.assertFalse(
-            inspect.isgeneratorfunction(unittest.mock.Mock()))
-        self.assertFalse(
-            inspect.isgeneratorfunction(unittest.mock.AsyncMock()))
-        self.assertFalse(
-            inspect.isgeneratorfunction(coroutine_function_example))
-        self.assertFalse(
-            inspect.isgeneratorfunction(
-                functools.partial(functools.partial(
-                    coroutine_function_example))))
-        self.assertFalse(inspect.isgenerator(coro))
-
-        self.assertFalse(
-            inspect.isasyncgenfunction(unittest.mock.Mock()))
-        self.assertFalse(
-            inspect.isasyncgenfunction(unittest.mock.AsyncMock()))
-        self.assertFalse(
-            inspect.isasyncgenfunction(coroutine_function_example))
-        self.assertTrue(
-            inspect.isasyncgenfunction(async_generator_function_example))
-        self.assertTrue(
-            inspect.isasyncgenfunction(
-                functools.partial(functools.partial(
-                    async_generator_function_example))))
-        self.assertTrue(inspect.isasyncgen(async_gen_coro))
-
-        coro.close(); gen_coro.close(); # silence warnings
-
-    def test_isawaitable(self):
-        def gen(): yield
-        self.assertFalse(inspect.isawaitable(gen()))
-
-        coro = coroutine_function_example(1)
-        gen_coro = gen_coroutine_function_example(1)
-
-        self.assertTrue(inspect.isawaitable(coro))
-        self.assertTrue(inspect.isawaitable(gen_coro))
-
-        class Future:
-            def __await__():
-                pass
-        self.assertTrue(inspect.isawaitable(Future()))
-        self.assertFalse(inspect.isawaitable(Future))
-
-        class NotFuture: pass
-        not_fut = NotFuture()
-        not_fut.__await__ = lambda: None
-        self.assertFalse(inspect.isawaitable(not_fut))
-
-        coro.close(); gen_coro.close() # silence warnings
-
-    def test_isroutine(self):
-        # method
-        self.assertTrue(inspect.isroutine(git.argue))
-        self.assertTrue(inspect.isroutine(mod.custom_method))
-        self.assertTrue(inspect.isroutine([].count))
-        # function
-        self.assertTrue(inspect.isroutine(mod.spam))
-        self.assertTrue(inspect.isroutine(mod.StupidGit.abuse))
-        # slot-wrapper
-        self.assertTrue(inspect.isroutine(object.__init__))
-        self.assertTrue(inspect.isroutine(object.__str__))
-        self.assertTrue(inspect.isroutine(object.__lt__))
-        self.assertTrue(inspect.isroutine(int.__lt__))
-        # method-wrapper
-        self.assertTrue(inspect.isroutine(object().__init__))
-        self.assertTrue(inspect.isroutine(object().__str__))
-        self.assertTrue(inspect.isroutine(object().__lt__))
-        self.assertTrue(inspect.isroutine((42).__lt__))
-        # method-descriptor
-        self.assertTrue(inspect.isroutine(str.join))
-        self.assertTrue(inspect.isroutine(list.append))
-        self.assertTrue(inspect.isroutine(''.join))
-        self.assertTrue(inspect.isroutine([].append))
-        # object
-        self.assertFalse(inspect.isroutine(object))
-        self.assertFalse(inspect.isroutine(object()))
-        self.assertFalse(inspect.isroutine(str()))
-        # module
-        self.assertFalse(inspect.isroutine(mod))
-        # type
-        self.assertFalse(inspect.isroutine(type))
-        self.assertFalse(inspect.isroutine(int))
-        self.assertFalse(inspect.isroutine(type('some_class', (), {})))
-
-    def test_isclass(self):
-        self.istest(inspect.isclass, 'mod.StupidGit')
-        self.assertTrue(inspect.isclass(list))
-
-        class CustomGetattr(object):
-            def __getattr__(self, attr):
-                return None
-        self.assertFalse(inspect.isclass(CustomGetattr()))
-
-    def test_get_slot_members(self):
-        class C(object):
-            __slots__ = ("a", "b")
-        x = C()
-        x.a = 42
-        members = dict(inspect.getmembers(x))
-        self.assertIn('a', members)
-        self.assertNotIn('b', members)
-
-    def test_isabstract(self):
-        from abc import ABCMeta, abstractmethod
-
-        class AbstractClassExample(metaclass=ABCMeta):
-
-            @abstractmethod
-            def foo(self):
-                pass
-
-        class ClassExample(AbstractClassExample):
-            def foo(self):
-                pass
-
-        a = ClassExample()
-
-        # Test general behaviour.
-        self.assertTrue(inspect.isabstract(AbstractClassExample))
-        self.assertFalse(inspect.isabstract(ClassExample))
-        self.assertFalse(inspect.isabstract(a))
-        self.assertFalse(inspect.isabstract(int))
-        self.assertFalse(inspect.isabstract(5))
-
-    def test_isabstract_during_init_subclass(self):
-        from abc import ABCMeta, abstractmethod
-        isabstract_checks = []
-        class AbstractChecker(metaclass=ABCMeta):
-            def __init_subclass__(cls):
-                isabstract_checks.append(inspect.isabstract(cls))
-        class AbstractClassExample(AbstractChecker):
-            @abstractmethod
-            def foo(self):
-                pass
-        class ClassExample(AbstractClassExample):
-            def foo(self):
-                pass
-        self.assertEqual(isabstract_checks, [True, False])
-
-        isabstract_checks.clear()
-        class AbstractChild(AbstractClassExample):
-            pass
-        class AbstractGrandchild(AbstractChild):
-            pass
-        class ConcreteGrandchild(ClassExample):
-            pass
-        self.assertEqual(isabstract_checks, [True, True, False])
-
-
-class TestInterpreterStack(IsTestBase):
-    def __init__(self, *args, **kwargs):
-        unittest.TestCase.__init__(self, *args, **kwargs)
-
-        git.abuse(7, 8, 9)
-
-    def test_abuse_done(self):
-        self.istest(inspect.istraceback, 'git.ex.__traceback__')
-        self.istest(inspect.isframe, 'mod.fr')
-
-    def test_stack(self):
-        self.assertTrue(len(mod.st) >= 5)
-        frame1, frame2, frame3, frame4, *_ = mod.st
-        frameinfo = revise(*frame1[1:])
-        self.assertEqual(frameinfo,
-             (modfile, 16, 'eggs', ['    st = inspect.stack()\n'], 0))
-        self.assertEqual(frame1.positions, dis.Positions(16, 16, 9, 24))
-        frameinfo = revise(*frame2[1:])
-        self.assertEqual(frameinfo,
-             (modfile, 9, 'spam', ['    eggs(b + d, c + f)\n'], 0))
-        self.assertEqual(frame2.positions, dis.Positions(9, 9, 4, 22))
-        frameinfo = revise(*frame3[1:])
-        self.assertEqual(frameinfo,
-             (modfile, 43, 'argue', ['            spam(a, b, c)\n'], 0))
-        self.assertEqual(frame3.positions, dis.Positions(43, 43, 12, 25))
-        frameinfo = revise(*frame4[1:])
-        self.assertEqual(frameinfo,
-             (modfile, 39, 'abuse', ['        self.argue(a, b, c)\n'], 0))
-        self.assertEqual(frame4.positions, dis.Positions(39, 39, 8, 27))
-        # Test named tuple fields
-        record = mod.st[0]
-        self.assertIs(record.frame, mod.fr)
-        self.assertEqual(record.lineno, 16)
-        self.assertEqual(record.filename, mod.__file__)
-        self.assertEqual(record.function, 'eggs')
-        self.assertIn('inspect.stack()', record.code_context[0])
-        self.assertEqual(record.index, 0)
-
-    def test_trace(self):
-        self.assertEqual(len(git.tr), 3)
-        frame1, frame2, frame3, = git.tr
-        self.assertEqual(revise(*frame1[1:]),
-             (modfile, 43, 'argue', ['            spam(a, b, c)\n'], 0))
-        self.assertEqual(frame1.positions, dis.Positions(43, 43, 12, 25))
-        self.assertEqual(revise(*frame2[1:]),
-             (modfile, 9, 'spam', ['    eggs(b + d, c + f)\n'], 0))
-        self.assertEqual(frame2.positions, dis.Positions(9, 9, 4, 22))
-        self.assertEqual(revise(*frame3[1:]),
-             (modfile, 18, 'eggs', ['    q = y / 0\n'], 0))
-        self.assertEqual(frame3.positions, dis.Positions(18, 18, 8, 13))
-
-    def test_frame(self):
-        args, varargs, varkw, locals = inspect.getargvalues(mod.fr)
-        self.assertEqual(args, ['x', 'y'])
-        self.assertEqual(varargs, None)
-        self.assertEqual(varkw, None)
-        self.assertEqual(locals, {'x': 11, 'p': 11, 'y': 14})
-        self.assertEqual(inspect.formatargvalues(args, varargs, varkw, locals),
-                         '(x=11, y=14)')
-
-    def test_previous_frame(self):
-        args, varargs, varkw, locals = inspect.getargvalues(mod.fr.f_back)
-        self.assertEqual(args, ['a', 'b', 'c', 'd', 'e', 'f'])
-        self.assertEqual(varargs, 'g')
-        self.assertEqual(varkw, 'h')
-        self.assertEqual(inspect.formatargvalues(args, varargs, varkw, locals),
-             '(a=7, b=8, c=9, d=3, e=4, f=5, *g=(), **h={})')
-
-class GetSourceBase(unittest.TestCase):
-    # Subclasses must override.
-    fodderModule = None
-
-    def setUp(self):
-        with open(inspect.getsourcefile(self.fodderModule), encoding="utf-8") as fp:
-            self.source = fp.read()
-
-    def sourcerange(self, top, bottom):
-        lines = self.source.split("\n")
-        return "\n".join(lines[top-1:bottom]) + ("\n" if bottom else "")
-
-    def assertSourceEqual(self, obj, top, bottom):
-        self.assertEqual(inspect.getsource(obj),
-                         self.sourcerange(top, bottom))
-
-class SlotUser:
-    'Docstrings for __slots__'
-    __slots__ = {'power': 'measured in kilowatts',
-                 'distance': 'measured in kilometers'}
-
-class TestRetrievingSourceCode(GetSourceBase):
-    fodderModule = mod
-
-    def test_getclasses(self):
-        classes = inspect.getmembers(mod, inspect.isclass)
-        self.assertEqual(classes,
-                         [('FesteringGob', mod.FesteringGob),
-                          ('MalodorousPervert', mod.MalodorousPervert),
-                          ('ParrotDroppings', mod.ParrotDroppings),
-                          ('StupidGit', mod.StupidGit),
-                          ('Tit', mod.MalodorousPervert),
-                          ('WhichComments', mod.WhichComments),
-                         ])
-        tree = inspect.getclasstree([cls[1] for cls in classes])
-        self.assertEqual(tree,
-                         [(object, ()),
-                          [(mod.ParrotDroppings, (object,)),
-                           [(mod.FesteringGob, (mod.MalodorousPervert,
-                                                   mod.ParrotDroppings))
-                            ],
-                           (mod.StupidGit, (object,)),
-                           [(mod.MalodorousPervert, (mod.StupidGit,)),
-                            [(mod.FesteringGob, (mod.MalodorousPervert,
-                                                    mod.ParrotDroppings))
-                             ]
-                            ],
-                            (mod.WhichComments, (object,),)
-                           ]
-                          ])
-        tree = inspect.getclasstree([cls[1] for cls in classes], True)
-        self.assertEqual(tree,
-                         [(object, ()),
-                          [(mod.ParrotDroppings, (object,)),
-                           (mod.StupidGit, (object,)),
-                           [(mod.MalodorousPervert, (mod.StupidGit,)),
-                            [(mod.FesteringGob, (mod.MalodorousPervert,
-                                                    mod.ParrotDroppings))
-                             ]
-                            ],
-                            (mod.WhichComments, (object,),)
-                           ]
-                          ])
-
-    def test_getfunctions(self):
-        functions = inspect.getmembers(mod, inspect.isfunction)
-        self.assertEqual(functions, [('after_closing', mod.after_closing),
-                                     ('eggs', mod.eggs),
-                                     ('lobbest', mod.lobbest),
-                                     ('spam', mod.spam)])
-
-    @unittest.skipIf(sys.flags.optimize >= 2,
-                     "Docstrings are omitted with -O2 and above")
-    def test_getdoc(self):
-        self.assertEqual(inspect.getdoc(mod), 'A module docstring.')
-        self.assertEqual(inspect.getdoc(mod.StupidGit),
-                         'A longer,\n\nindented\n\ndocstring.')
-        self.assertEqual(inspect.getdoc(git.abuse),
-                         'Another\n\ndocstring\n\ncontaining\n\ntabs')
-        self.assertEqual(inspect.getdoc(SlotUser.power),
-                         'measured in kilowatts')
-        self.assertEqual(inspect.getdoc(SlotUser.distance),
-                         'measured in kilometers')
-
-    @unittest.skipIf(sys.flags.optimize >= 2,
-                     "Docstrings are omitted with -O2 and above")
-    def test_getdoc_inherited(self):
-        self.assertEqual(inspect.getdoc(mod.FesteringGob),
-                         'A longer,\n\nindented\n\ndocstring.')
-        self.assertEqual(inspect.getdoc(mod.FesteringGob.abuse),
-                         'Another\n\ndocstring\n\ncontaining\n\ntabs')
-        self.assertEqual(inspect.getdoc(mod.FesteringGob().abuse),
-                         'Another\n\ndocstring\n\ncontaining\n\ntabs')
-        self.assertEqual(inspect.getdoc(mod.FesteringGob.contradiction),
-                         'The automatic gainsaying.')
-
-    @unittest.skipIf(MISSING_C_DOCSTRINGS, "test requires docstrings")
-    def test_finddoc(self):
-        finddoc = inspect._finddoc
-        self.assertEqual(finddoc(int), int.__doc__)
-        self.assertEqual(finddoc(int.to_bytes), int.to_bytes.__doc__)
-        self.assertEqual(finddoc(int().to_bytes), int.to_bytes.__doc__)
-        self.assertEqual(finddoc(int.from_bytes), int.from_bytes.__doc__)
-        self.assertEqual(finddoc(int.real), int.real.__doc__)
-
-    def test_cleandoc(self):
-        self.assertEqual(inspect.cleandoc('An\n    indented\n    docstring.'),
-                         'An\nindented\ndocstring.')
-
-    def test_getcomments(self):
-        self.assertEqual(inspect.getcomments(mod), '# line 1\n')
-        self.assertEqual(inspect.getcomments(mod.StupidGit), '# line 20\n')
-        self.assertEqual(inspect.getcomments(mod2.cls160), '# line 159\n')
-        # If the object source file is not available, return None.
-        co = compile('x=1', '_non_existing_filename.py', 'exec')
-        self.assertIsNone(inspect.getcomments(co))
-        # If the object has been defined in C, return None.
-        self.assertIsNone(inspect.getcomments(list))
-
-    def test_getmodule(self):
-        # Check actual module
-        self.assertEqual(inspect.getmodule(mod), mod)
-        # Check class (uses __module__ attribute)
-        self.assertEqual(inspect.getmodule(mod.StupidGit), mod)
-        # Check a method (no __module__ attribute, falls back to filename)
-        self.assertEqual(inspect.getmodule(mod.StupidGit.abuse), mod)
-        # Do it again (check the caching isn't broken)
-        self.assertEqual(inspect.getmodule(mod.StupidGit.abuse), mod)
-        # Check a builtin
-        self.assertEqual(inspect.getmodule(str), sys.modules["builtins"])
-        # Check filename override
-        self.assertEqual(inspect.getmodule(None, modfile), mod)
-
-    def test_getmodule_file_not_found(self):
-        # See bpo-45406
-        def _getabsfile(obj, _filename):
-            raise FileNotFoundError('bad file')
-        with unittest.mock.patch('inspect.getabsfile', _getabsfile):
-            f = inspect.currentframe()
-            self.assertIsNone(inspect.getmodule(f))
-            inspect.getouterframes(f)  # smoke test
-
-    def test_getframeinfo_get_first_line(self):
-        frame_info = inspect.getframeinfo(self.fodderModule.fr, 50)
-        self.assertEqual(frame_info.code_context[0], "# line 1\n")
-        self.assertEqual(frame_info.code_context[1], "'A module docstring.'\n")
-
-    def test_getsource(self):
-        self.assertSourceEqual(git.abuse, 29, 39)
-        self.assertSourceEqual(mod.StupidGit, 21, 51)
-        self.assertSourceEqual(mod.lobbest, 75, 76)
-        self.assertSourceEqual(mod.after_closing, 120, 120)
-
-    def test_getsourcefile(self):
-        self.assertEqual(normcase(inspect.getsourcefile(mod.spam)), modfile)
-        self.assertEqual(normcase(inspect.getsourcefile(git.abuse)), modfile)
-        fn = "_non_existing_filename_used_for_sourcefile_test.py"
-        co = compile("x=1", fn, "exec")
-        self.assertEqual(inspect.getsourcefile(co), None)
-        linecache.cache[co.co_filename] = (1, None, "None", co.co_filename)
-        try:
-            self.assertEqual(normcase(inspect.getsourcefile(co)), fn)
-        finally:
-            del linecache.cache[co.co_filename]
-
-    def test_getfile(self):
-        self.assertEqual(inspect.getfile(mod.StupidGit), mod.__file__)
-
-    def test_getfile_builtin_module(self):
-        with self.assertRaises(TypeError) as e:
-            inspect.getfile(sys)
-        self.assertTrue(str(e.exception).startswith('<module'))
-
-    def test_getfile_builtin_class(self):
-        with self.assertRaises(TypeError) as e:
-            inspect.getfile(int)
-        self.assertTrue(str(e.exception).startswith('<class'))
-
-    def test_getfile_builtin_function_or_method(self):
-        with self.assertRaises(TypeError) as e_abs:
-            inspect.getfile(abs)
-        self.assertIn('expected, got', str(e_abs.exception))
-        with self.assertRaises(TypeError) as e_append:
-            inspect.getfile(list.append)
-        self.assertIn('expected, got', str(e_append.exception))
-
-    def test_getfile_class_without_module(self):
-        class CM(type):
-            @property
-            def __module__(cls):
-                raise AttributeError
-        class C(metaclass=CM):
-            pass
-        with self.assertRaises(TypeError):
-            inspect.getfile(C)
-
-    def test_getfile_broken_repr(self):
-        class ErrorRepr:
-            def __repr__(self):
-                raise Exception('xyz')
-        er = ErrorRepr()
-        with self.assertRaises(TypeError):
-            inspect.getfile(er)
-
-    def test_getmodule_recursion(self):
-        from types import ModuleType
-        name = '__inspect_dummy'
-        m = sys.modules[name] = ModuleType(name)
-        m.__file__ = "<string>" # hopefully not a real filename...
-        m.__loader__ = "dummy"  # pretend the filename is understood by a loader
-        exec("def x(): pass", m.__dict__)
-        self.assertEqual(inspect.getsourcefile(m.x.__code__), '<string>')
-        del sys.modules[name]
-        inspect.getmodule(compile('a=10','','single'))
-
-    def test_proceed_with_fake_filename(self):
-        '''doctest monkeypatches linecache to enable inspection'''
-        fn, source = '<test>', 'def x(): pass\n'
-        getlines = linecache.getlines
-        def monkey(filename, module_globals=None):
-            if filename == fn:
-                return source.splitlines(keepends=True)
-            else:
-                return getlines(filename, module_globals)
-        linecache.getlines = monkey
-        try:
-            ns = {}
-            exec(compile(source, fn, 'single'), ns)
-            inspect.getsource(ns["x"])
-        finally:
-            linecache.getlines = getlines
-
-    def test_getsource_on_code_object(self):
-        self.assertSourceEqual(mod.eggs.__code__, 12, 18)
-
-class TestGetsourceInteractive(unittest.TestCase):
-    def test_getclasses_interactive(self):
-        # bpo-44648: simulate a REPL session;
-        # there is no `__file__` in the __main__ module
-        code = "import sys, inspect; \
-                assert not hasattr(sys.modules['__main__'], '__file__'); \
-                A = type('A', (), {}); \
-                inspect.getsource(A)"
-        _, _, stderr = assert_python_failure("-c", code, __isolated=True)
-        self.assertIn(b'OSError: source code not available', stderr)
-
-class TestGettingSourceOfToplevelFrames(GetSourceBase):
-    fodderModule = mod
-
-    def test_range_toplevel_frame(self):
-        self.maxDiff = None
-        self.assertSourceEqual(mod.currentframe, 1, None)
-
-    def test_range_traceback_toplevel_frame(self):
-        self.assertSourceEqual(mod.tb, 1, None)
-
-class TestDecorators(GetSourceBase):
-    fodderModule = mod2
-
-    def test_wrapped_decorator(self):
-        self.assertSourceEqual(mod2.wrapped, 14, 17)
-
-    def test_replacing_decorator(self):
-        self.assertSourceEqual(mod2.gone, 9, 10)
-
-    def test_getsource_unwrap(self):
-        self.assertSourceEqual(mod2.real, 130, 132)
-
-    def test_decorator_with_lambda(self):
-        self.assertSourceEqual(mod2.func114, 113, 115)
-
-class TestOneliners(GetSourceBase):
-    fodderModule = mod2
-    def test_oneline_lambda(self):
-        # Test inspect.getsource with a one-line lambda function.
-        self.assertSourceEqual(mod2.oll, 25, 25)
-
-    def test_threeline_lambda(self):
-        # Test inspect.getsource with a three-line lambda function,
-        # where the second and third lines are _not_ indented.
-        self.assertSourceEqual(mod2.tll, 28, 30)
-
-    def test_twoline_indented_lambda(self):
-        # Test inspect.getsource with a two-line lambda function,
-        # where the second line _is_ indented.
-        self.assertSourceEqual(mod2.tlli, 33, 34)
-
-    def test_parenthesized_multiline_lambda(self):
-        # Test inspect.getsource with a parenthesized multi-line lambda
-        # function.
-        self.assertSourceEqual(mod2.parenthesized_lambda, 279, 279)
-        self.assertSourceEqual(mod2.parenthesized_lambda2, 281, 281)
-        self.assertSourceEqual(mod2.parenthesized_lambda3, 283, 283)
-
-    def test_post_line_parenthesized_lambda(self):
-        # Test inspect.getsource with a parenthesized multi-line lambda
-        # function.
-        self.assertSourceEqual(mod2.post_line_parenthesized_lambda1, 286, 287)
-
-    def test_nested_lambda(self):
-        # Test inspect.getsource with a nested lambda function.
-        self.assertSourceEqual(mod2.nested_lambda, 291, 292)
-
-    def test_onelinefunc(self):
-        # Test inspect.getsource with a regular one-line function.
-        self.assertSourceEqual(mod2.onelinefunc, 37, 37)
-
-    def test_manyargs(self):
-        # Test inspect.getsource with a regular function where
-        # the arguments are on two lines and _not_ indented and
-        # the body on the second line with the last arguments.
-        self.assertSourceEqual(mod2.manyargs, 40, 41)
-
-    def test_twolinefunc(self):
-        # Test inspect.getsource with a regular function where
-        # the body is on two lines, following the argument list and
-        # continued on the next line by a \\.
-        self.assertSourceEqual(mod2.twolinefunc, 44, 45)
-
-    def test_lambda_in_list(self):
-        # Test inspect.getsource with a one-line lambda function
-        # defined in a list, indented.
-        self.assertSourceEqual(mod2.a[1], 49, 49)
-
-    def test_anonymous(self):
-        # Test inspect.getsource with a lambda function defined
-        # as argument to another function.
-        self.assertSourceEqual(mod2.anonymous, 55, 55)
-
-class TestBlockComments(GetSourceBase):
-    fodderModule = mod
-
-    def test_toplevel_class(self):
-        self.assertSourceEqual(mod.WhichComments, 96, 114)
-
-    def test_class_method(self):
-        self.assertSourceEqual(mod.WhichComments.f, 99, 104)
-
-    def test_class_async_method(self):
-        self.assertSourceEqual(mod.WhichComments.asyncf, 109, 112)
-
-class TestBuggyCases(GetSourceBase):
-    fodderModule = mod2
-
-    def test_with_comment(self):
-        self.assertSourceEqual(mod2.with_comment, 58, 59)
-
-    def test_multiline_sig(self):
-        self.assertSourceEqual(mod2.multiline_sig[0], 63, 64)
-
-    def test_nested_class(self):
-        self.assertSourceEqual(mod2.func69().func71, 71, 72)
-
-    def test_one_liner_followed_by_non_name(self):
-        self.assertSourceEqual(mod2.func77, 77, 77)
-
-    def test_one_liner_dedent_non_name(self):
-        self.assertSourceEqual(mod2.cls82.func83, 83, 83)
-
-    def test_with_comment_instead_of_docstring(self):
-        self.assertSourceEqual(mod2.func88, 88, 90)
-
-    def test_method_in_dynamic_class(self):
-        self.assertSourceEqual(mod2.method_in_dynamic_class, 95, 97)
-
-    # This should not skip for CPython, but might on a repackaged python where
-    # unicodedata is not an external module, or on pypy.
-    @unittest.skipIf(not hasattr(unicodedata, '__file__') or
-                                 unicodedata.__file__.endswith('.py'),
-                     "unicodedata is not an external binary module")
-    def test_findsource_binary(self):
-        self.assertRaises(OSError, inspect.getsource, unicodedata)
-        self.assertRaises(OSError, inspect.findsource, unicodedata)
-
-    def test_findsource_code_in_linecache(self):
-        lines = ["x=1"]
-        co = compile(lines[0], "_dynamically_created_file", "exec")
-        self.assertRaises(OSError, inspect.findsource, co)
-        self.assertRaises(OSError, inspect.getsource, co)
-        linecache.cache[co.co_filename] = (1, None, lines, co.co_filename)
-        try:
-            self.assertEqual(inspect.findsource(co), (lines,0))
-            self.assertEqual(inspect.getsource(co), lines[0])
-        finally:
-            del linecache.cache[co.co_filename]
-
-    def test_findsource_without_filename(self):
-        for fname in ['', '<string>']:
-            co = compile('x=1', fname, "exec")
-            self.assertRaises(IOError, inspect.findsource, co)
-            self.assertRaises(IOError, inspect.getsource, co)
-
-    def test_findsource_with_out_of_bounds_lineno(self):
-        mod_len = len(inspect.getsource(mod))
-        src = '\n' * 2* mod_len + "def f(): pass"
-        co = compile(src, mod.__file__, "exec")
-        g, l = {}, {}
-        eval(co, g, l)
-        func = l['f']
-        self.assertEqual(func.__code__.co_firstlineno, 1+2*mod_len)
-        with self.assertRaisesRegex(IOError, "lineno is out of bounds"):
-            inspect.findsource(func)
-
-    def test_getsource_on_method(self):
-        self.assertSourceEqual(mod2.ClassWithMethod.method, 118, 119)
-
-    def test_nested_func(self):
-        self.assertSourceEqual(mod2.cls135.func136, 136, 139)
-
-    def test_class_definition_in_multiline_string_definition(self):
-        self.assertSourceEqual(mod2.cls149, 149, 152)
-
-    def test_class_definition_in_multiline_comment(self):
-        self.assertSourceEqual(mod2.cls160, 160, 163)
-
-    def test_nested_class_definition_indented_string(self):
-        self.assertSourceEqual(mod2.cls173.cls175, 175, 176)
-
-    def test_nested_class_definition(self):
-        self.assertSourceEqual(mod2.cls183, 183, 188)
-        self.assertSourceEqual(mod2.cls183.cls185, 185, 188)
-
-    def test_class_decorator(self):
-        self.assertSourceEqual(mod2.cls196, 194, 201)
-        self.assertSourceEqual(mod2.cls196.cls200, 198, 201)
-
-    def test_class_inside_conditional(self):
-        self.assertSourceEqual(mod2.cls238, 238, 240)
-        self.assertSourceEqual(mod2.cls238.cls239, 239, 240)
-
-    def test_multiple_children_classes(self):
-        self.assertSourceEqual(mod2.cls203, 203, 209)
-        self.assertSourceEqual(mod2.cls203.cls204, 204, 206)
-        self.assertSourceEqual(mod2.cls203.cls204.cls205, 205, 206)
-        self.assertSourceEqual(mod2.cls203.cls207, 207, 209)
-        self.assertSourceEqual(mod2.cls203.cls207.cls205, 208, 209)
-
-    def test_nested_class_definition_inside_function(self):
-        self.assertSourceEqual(mod2.func212(), 213, 214)
-        self.assertSourceEqual(mod2.cls213, 218, 222)
-        self.assertSourceEqual(mod2.cls213().func219(), 220, 221)
-
-    @unittest.skipIf(
-        support.is_emscripten or support.is_wasi,
-        "socket.accept is broken"
-    )
-    def test_nested_class_definition_inside_async_function(self):
-        import asyncio
-        self.addCleanup(asyncio.set_event_loop_policy, None)
-        self.assertSourceEqual(asyncio.run(mod2.func225()), 226, 227)
-        self.assertSourceEqual(mod2.cls226, 231, 235)
-        self.assertSourceEqual(asyncio.run(mod2.cls226().func232()), 233, 234)
-
-class TestNoEOL(GetSourceBase):
-    def setUp(self):
-        self.tempdir = TESTFN + '_dir'
-        os.mkdir(self.tempdir)
-        with open(os.path.join(self.tempdir, 'inspect_fodder3%spy' % os.extsep),
-                  'w', encoding='utf-8') as f:
-            f.write("class X:\n    pass # No EOL")
-        with DirsOnSysPath(self.tempdir):
-            import inspect_fodder3 as mod3
-        self.fodderModule = mod3
-        super().setUp()
-
-    def tearDown(self):
-        shutil.rmtree(self.tempdir)
-
-    def test_class(self):
-        self.assertSourceEqual(self.fodderModule.X, 1, 2)
-
-
-class TestComplexDecorator(GetSourceBase):
-    fodderModule = mod2
-
-    def test_parens_in_decorator(self):
-        self.assertSourceEqual(self.fodderModule.complex_decorated, 273, 275)
-
-class _BrokenDataDescriptor(object):
-    """
-    A broken data descriptor. See bug #1785.
-    """
-    def __get__(*args):
-        raise AttributeError("broken data descriptor")
-
-    def __set__(*args):
-        raise RuntimeError
-
-    def __getattr__(*args):
-        raise AttributeError("broken data descriptor")
-
-
-class _BrokenMethodDescriptor(object):
-    """
-    A broken method descriptor. See bug #1785.
-    """
-    def __get__(*args):
-        raise AttributeError("broken method descriptor")
-
-    def __getattr__(*args):
-        raise AttributeError("broken method descriptor")
-
-
-# Helper for testing classify_class_attrs.
-def attrs_wo_objs(cls):
-    return [t[:3] for t in inspect.classify_class_attrs(cls)]
-
-
-class TestClassesAndFunctions(unittest.TestCase):
-    def test_newstyle_mro(self):
-        # The same w/ new-class MRO.
-        class A(object):    pass
-        class B(A): pass
-        class C(A): pass
-        class D(B, C): pass
-
-        expected = (D, B, C, A, object)
-        got = inspect.getmro(D)
-        self.assertEqual(expected, got)
-
-    def assertFullArgSpecEquals(self, routine, args_e, varargs_e=None,
-                                    varkw_e=None, defaults_e=None,
-                                    posonlyargs_e=[], kwonlyargs_e=[],
-                                    kwonlydefaults_e=None,
-                                    ann_e={}):
-        args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = \
-            inspect.getfullargspec(routine)
-        self.assertEqual(args, args_e)
-        self.assertEqual(varargs, varargs_e)
-        self.assertEqual(varkw, varkw_e)
-        self.assertEqual(defaults, defaults_e)
-        self.assertEqual(kwonlyargs, kwonlyargs_e)
-        self.assertEqual(kwonlydefaults, kwonlydefaults_e)
-        self.assertEqual(ann, ann_e)
-
-    def test_getfullargspec(self):
-        self.assertFullArgSpecEquals(mod2.keyworded, [], varargs_e='arg1',
-                                     kwonlyargs_e=['arg2'],
-                                     kwonlydefaults_e={'arg2':1})
-
-        self.assertFullArgSpecEquals(mod2.annotated, ['arg1'],
-                                     ann_e={'arg1' : list})
-        self.assertFullArgSpecEquals(mod2.keyword_only_arg, [],
-                                     kwonlyargs_e=['arg'])
-
-        self.assertFullArgSpecEquals(mod2.all_markers, ['a', 'b', 'c', 'd'],
-                                     kwonlyargs_e=['e', 'f'])
-
-        self.assertFullArgSpecEquals(mod2.all_markers_with_args_and_kwargs,
-                                     ['a', 'b', 'c', 'd'],
-                                     varargs_e='args',
-                                     varkw_e='kwargs',
-                                     kwonlyargs_e=['e', 'f'])
-
-        self.assertFullArgSpecEquals(mod2.all_markers_with_defaults, ['a', 'b', 'c', 'd'],
-                                     defaults_e=(1,2,3),
-                                     kwonlyargs_e=['e', 'f'],
-                                     kwonlydefaults_e={'e': 4, 'f': 5})
-
-    def test_argspec_api_ignores_wrapped(self):
-        # Issue 20684: low level introspection API must ignore __wrapped__
-        @functools.wraps(mod.spam)
-        def ham(x, y):
-            pass
-        # Basic check
-        self.assertFullArgSpecEquals(ham, ['x', 'y'])
-        self.assertFullArgSpecEquals(functools.partial(ham),
-                                     ['x', 'y'])
-
-    def test_getfullargspec_signature_attr(self):
-        def test():
-            pass
-        spam_param = inspect.Parameter('spam', inspect.Parameter.POSITIONAL_ONLY)
-        test.__signature__ = inspect.Signature(parameters=(spam_param,))
-
-        self.assertFullArgSpecEquals(test, ['spam'])
-
-    def test_getfullargspec_signature_annos(self):
-        def test(a:'spam') -> 'ham': pass
-        spec = inspect.getfullargspec(test)
-        self.assertEqual(test.__annotations__, spec.annotations)
-
-        def test(): pass
-        spec = inspect.getfullargspec(test)
-        self.assertEqual(test.__annotations__, spec.annotations)
-
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_getfullargspec_builtin_methods(self):
-        self.assertFullArgSpecEquals(_pickle.Pickler.dump, ['self', 'obj'])
-
-        self.assertFullArgSpecEquals(_pickle.Pickler(io.BytesIO()).dump, ['self', 'obj'])
-
-        self.assertFullArgSpecEquals(
-             os.stat,
-             args_e=['path'],
-             kwonlyargs_e=['dir_fd', 'follow_symlinks'],
-             kwonlydefaults_e={'dir_fd': None, 'follow_symlinks': True})
-
-    @cpython_only
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_getfullargspec_builtin_func(self):
-        import _testcapi
-        builtin = _testcapi.docstring_with_signature_with_defaults
-        spec = inspect.getfullargspec(builtin)
-        self.assertEqual(spec.defaults[0], 'avocado')
-
-    @cpython_only
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_getfullargspec_builtin_func_no_signature(self):
-        import _testcapi
-        builtin = _testcapi.docstring_no_signature
-        with self.assertRaises(TypeError):
-            inspect.getfullargspec(builtin)
-
-    def test_getfullargspec_definition_order_preserved_on_kwonly(self):
-        for fn in signatures_with_lexicographic_keyword_only_parameters():
-            signature = inspect.getfullargspec(fn)
-            l = list(signature.kwonlyargs)
-            sorted_l = sorted(l)
-            self.assertTrue(l)
-            self.assertEqual(l, sorted_l)
-        signature = inspect.getfullargspec(unsorted_keyword_only_parameters_fn)
-        l = list(signature.kwonlyargs)
-        self.assertEqual(l, unsorted_keyword_only_parameters)
-
-    def test_classify_newstyle(self):
-        class A(object):
-
-            def s(): pass
-            s = staticmethod(s)
-
-            def c(cls): pass
-            c = classmethod(c)
-
-            def getp(self): pass
-            p = property(getp)
-
-            def m(self): pass
-
-            def m1(self): pass
-
-            datablob = '1'
-
-            dd = _BrokenDataDescriptor()
-            md = _BrokenMethodDescriptor()
-
-        attrs = attrs_wo_objs(A)
-
-        self.assertIn(('__new__', 'static method', object), attrs,
-                      'missing __new__')
-        self.assertIn(('__init__', 'method', object), attrs, 'missing __init__')
-
-        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
-        self.assertIn(('c', 'class method', A), attrs, 'missing class method')
-        self.assertIn(('p', 'property', A), attrs, 'missing property')
-        self.assertIn(('m', 'method', A), attrs,
-                      'missing plain method: %r' % attrs)
-        self.assertIn(('m1', 'method', A), attrs, 'missing plain method')
-        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
-        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
-        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
-
-        class B(A):
-
-            def m(self): pass
-
-        attrs = attrs_wo_objs(B)
-        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
-        self.assertIn(('c', 'class method', A), attrs, 'missing class method')
-        self.assertIn(('p', 'property', A), attrs, 'missing property')
-        self.assertIn(('m', 'method', B), attrs, 'missing plain method')
-        self.assertIn(('m1', 'method', A), attrs, 'missing plain method')
-        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
-        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
-        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
-
-
-        class C(A):
-
-            def m(self): pass
-            def c(self): pass
-
-        attrs = attrs_wo_objs(C)
-        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
-        self.assertIn(('c', 'method', C), attrs, 'missing plain method')
-        self.assertIn(('p', 'property', A), attrs, 'missing property')
-        self.assertIn(('m', 'method', C), attrs, 'missing plain method')
-        self.assertIn(('m1', 'method', A), attrs, 'missing plain method')
-        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
-        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
-        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
-
-        class D(B, C):
-
-            def m1(self): pass
-
-        attrs = attrs_wo_objs(D)
-        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
-        self.assertIn(('c', 'method', C), attrs, 'missing plain method')
-        self.assertIn(('p', 'property', A), attrs, 'missing property')
-        self.assertIn(('m', 'method', B), attrs, 'missing plain method')
-        self.assertIn(('m1', 'method', D), attrs, 'missing plain method')
-        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
-        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
-        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
-
-    def test_classify_builtin_types(self):
-        # Simple sanity check that all built-in types can have their
-        # attributes classified.
-        for name in dir(__builtins__):
-            builtin = getattr(__builtins__, name)
-            if isinstance(builtin, type):
-                inspect.classify_class_attrs(builtin)
-
-        attrs = attrs_wo_objs(bool)
-        self.assertIn(('__new__', 'static method', bool), attrs,
-                      'missing __new__')
-        self.assertIn(('from_bytes', 'class method', int), attrs,
-                      'missing class method')
-        self.assertIn(('to_bytes', 'method', int), attrs,
-                      'missing plain method')
-        self.assertIn(('__add__', 'method', int), attrs,
-                      'missing plain method')
-        self.assertIn(('__and__', 'method', bool), attrs,
-                      'missing plain method')
-
-    def test_classify_DynamicClassAttribute(self):
-        class Meta(type):
-            def __getattr__(self, name):
-                if name == 'ham':
-                    return 'spam'
-                return super().__getattr__(name)
-        class VA(metaclass=Meta):
-            @types.DynamicClassAttribute
-            def ham(self):
-                return 'eggs'
-        should_find_dca = inspect.Attribute('ham', 'data', VA, VA.__dict__['ham'])
-        self.assertIn(should_find_dca, inspect.classify_class_attrs(VA))
-        should_find_ga = inspect.Attribute('ham', 'data', Meta, 'spam')
-        self.assertIn(should_find_ga, inspect.classify_class_attrs(VA))
-
-    def test_classify_overrides_bool(self):
-        class NoBool(object):
-            def __eq__(self, other):
-                return NoBool()
-
-            def __bool__(self):
-                raise NotImplementedError(
-                    "This object does not specify a boolean value")
-
-        class HasNB(object):
-            dd = NoBool()
-
-        should_find_attr = inspect.Attribute('dd', 'data', HasNB, HasNB.dd)
-        self.assertIn(should_find_attr, inspect.classify_class_attrs(HasNB))
-
-    def test_classify_metaclass_class_attribute(self):
-        class Meta(type):
-            fish = 'slap'
-            def __dir__(self):
-                return ['__class__', '__module__', '__name__', 'fish']
-        class Class(metaclass=Meta):
-            pass
-        should_find = inspect.Attribute('fish', 'data', Meta, 'slap')
-        self.assertIn(should_find, inspect.classify_class_attrs(Class))
-
-    def test_classify_VirtualAttribute(self):
-        class Meta(type):
-            def __dir__(cls):
-                return ['__class__', '__module__', '__name__', 'BOOM']
-            def __getattr__(self, name):
-                if name =='BOOM':
-                    return 42
-                return super().__getattr(name)
-        class Class(metaclass=Meta):
-            pass
-        should_find = inspect.Attribute('BOOM', 'data', Meta, 42)
-        self.assertIn(should_find, inspect.classify_class_attrs(Class))
-
-    def test_classify_VirtualAttribute_multi_classes(self):
-        class Meta1(type):
-            def __dir__(cls):
-                return ['__class__', '__module__', '__name__', 'one']
-            def __getattr__(self, name):
-                if name =='one':
-                    return 1
-                return super().__getattr__(name)
-        class Meta2(type):
-            def __dir__(cls):
-                return ['__class__', '__module__', '__name__', 'two']
-            def __getattr__(self, name):
-                if name =='two':
-                    return 2
-                return super().__getattr__(name)
-        class Meta3(Meta1, Meta2):
-            def __dir__(cls):
-                return list(sorted(set(['__class__', '__module__', '__name__', 'three'] +
-                    Meta1.__dir__(cls) + Meta2.__dir__(cls))))
-            def __getattr__(self, name):
-                if name =='three':
-                    return 3
-                return super().__getattr__(name)
-        class Class1(metaclass=Meta1):
-            pass
-        class Class2(Class1, metaclass=Meta3):
-            pass
-
-        should_find1 = inspect.Attribute('one', 'data', Meta1, 1)
-        should_find2 = inspect.Attribute('two', 'data', Meta2, 2)
-        should_find3 = inspect.Attribute('three', 'data', Meta3, 3)
-        cca = inspect.classify_class_attrs(Class2)
-        for sf in (should_find1, should_find2, should_find3):
-            self.assertIn(sf, cca)
-
-    def test_classify_class_attrs_with_buggy_dir(self):
-        class M(type):
-            def __dir__(cls):
-                return ['__class__', '__name__', 'missing']
-        class C(metaclass=M):
-            pass
-        attrs = [a[0] for a in inspect.classify_class_attrs(C)]
-        self.assertNotIn('missing', attrs)
-
-    def test_getmembers_descriptors(self):
-        class A(object):
-            dd = _BrokenDataDescriptor()
-            md = _BrokenMethodDescriptor()
-
-        def pred_wrapper(pred):
-            # A quick'n'dirty way to discard standard attributes of new-style
-            # classes.
-            class Empty(object):
-                pass
-            def wrapped(x):
-                if '__name__' in dir(x) and hasattr(Empty, x.__name__):
-                    return False
-                return pred(x)
-            return wrapped
-
-        ismethoddescriptor = pred_wrapper(inspect.ismethoddescriptor)
-        isdatadescriptor = pred_wrapper(inspect.isdatadescriptor)
-
-        self.assertEqual(inspect.getmembers(A, ismethoddescriptor),
-            [('md', A.__dict__['md'])])
-        self.assertEqual(inspect.getmembers(A, isdatadescriptor),
-            [('dd', A.__dict__['dd'])])
-
-        class B(A):
-            pass
-
-        self.assertEqual(inspect.getmembers(B, ismethoddescriptor),
-            [('md', A.__dict__['md'])])
-        self.assertEqual(inspect.getmembers(B, isdatadescriptor),
-            [('dd', A.__dict__['dd'])])
-
-    def test_getmembers_method(self):
-        class B:
-            def f(self):
-                pass
-
-        self.assertIn(('f', B.f), inspect.getmembers(B))
-        self.assertNotIn(('f', B.f), inspect.getmembers(B, inspect.ismethod))
-        b = B()
-        self.assertIn(('f', b.f), inspect.getmembers(b))
-        self.assertIn(('f', b.f), inspect.getmembers(b, inspect.ismethod))
-
-    def test_getmembers_VirtualAttribute(self):
-        class M(type):
-            def __getattr__(cls, name):
-                if name == 'eggs':
-                    return 'scrambled'
-                return super().__getattr__(name)
-        class A(metaclass=M):
-            @types.DynamicClassAttribute
-            def eggs(self):
-                return 'spam'
-        class B:
-            def __getattr__(self, attribute):
-                return None
-        self.assertIn(('eggs', 'scrambled'), inspect.getmembers(A))
-        self.assertIn(('eggs', 'spam'), inspect.getmembers(A()))
-        b = B()
-        self.assertIn(('__getattr__', b.__getattr__), inspect.getmembers(b))
-
-    def test_getmembers_static(self):
-        class A:
-            @property
-            def name(self):
-                raise NotImplementedError
-            @types.DynamicClassAttribute
-            def eggs(self):
-                raise NotImplementedError
-
-        a = A()
-        instance_members = inspect.getmembers_static(a)
-        class_members = inspect.getmembers_static(A)
-        self.assertIn(('name', inspect.getattr_static(a, 'name')), instance_members)
-        self.assertIn(('eggs', inspect.getattr_static(a, 'eggs')), instance_members)
-        self.assertIn(('name', inspect.getattr_static(A, 'name')), class_members)
-        self.assertIn(('eggs', inspect.getattr_static(A, 'eggs')), class_members)
-
-    def test_getmembers_with_buggy_dir(self):
-        class M(type):
-            def __dir__(cls):
-                return ['__class__', '__name__', 'missing']
-        class C(metaclass=M):
-            pass
-        attrs = [a[0] for a in inspect.getmembers(C)]
-        self.assertNotIn('missing', attrs)
-
-    def test_get_annotations_with_stock_annotations(self):
-        def foo(a:int, b:str): pass
-        self.assertEqual(inspect.get_annotations(foo), {'a': int, 'b': str})
-
-        foo.__annotations__ = {'a': 'foo', 'b':'str'}
-        self.assertEqual(inspect.get_annotations(foo), {'a': 'foo', 'b': 'str'})
-
-        self.assertEqual(inspect.get_annotations(foo, eval_str=True, locals=locals()), {'a': foo, 'b': str})
-        self.assertEqual(inspect.get_annotations(foo, eval_str=True, globals=locals()), {'a': foo, 'b': str})
-
-        isa = inspect_stock_annotations
-        self.assertEqual(inspect.get_annotations(isa), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.MyClass), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.function), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function2), {'a': int, 'b': 'str', 'c': isa.MyClass, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function3), {'a': 'int', 'b': 'str', 'c': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(inspect), {}) # inspect module has no annotations
-        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass), {})
-        self.assertEqual(inspect.get_annotations(isa.unannotated_function), {})
-
-        self.assertEqual(inspect.get_annotations(isa, eval_str=True), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=True), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.function, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=True), {'a': int, 'b': str, 'c': isa.MyClass, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=True), {'a': int, 'b': str, 'c': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(inspect, eval_str=True), {})
-        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=True), {})
-        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=True), {})
-
-        self.assertEqual(inspect.get_annotations(isa, eval_str=False), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=False), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.function, eval_str=False), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=False), {'a': int, 'b': 'str', 'c': isa.MyClass, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=False), {'a': 'int', 'b': 'str', 'c': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(inspect, eval_str=False), {})
-        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=False), {})
-        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=False), {})
-
-        def times_three(fn):
-            @functools.wraps(fn)
-            def wrapper(a, b):
-                return fn(a*3, b*3)
-            return wrapper
-
-        wrapped = times_three(isa.function)
-        self.assertEqual(wrapped(1, 'x'), isa.MyClass(3, 'xxx'))
-        self.assertIsNot(wrapped.__globals__, isa.function.__globals__)
-        self.assertEqual(inspect.get_annotations(wrapped), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(wrapped, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(wrapped, eval_str=False), {'a': int, 'b': str, 'return': isa.MyClass})
-
-    def test_get_annotations_with_stringized_annotations(self):
-        isa = inspect_stringized_annotations
-        self.assertEqual(inspect.get_annotations(isa), {'a': 'int', 'b': 'str'})
-        self.assertEqual(inspect.get_annotations(isa.MyClass), {'a': 'int', 'b': 'str'})
-        self.assertEqual(inspect.get_annotations(isa.function), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(isa.function2), {'a': 'int', 'b': "'str'", 'c': 'MyClass', 'return': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(isa.function3), {'a': "'int'", 'b': "'str'", 'c': "'MyClass'"})
-        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass), {})
-        self.assertEqual(inspect.get_annotations(isa.unannotated_function), {})
-
-        self.assertEqual(inspect.get_annotations(isa, eval_str=True), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=True), {'a': int, 'b': str})
-        self.assertEqual(inspect.get_annotations(isa.function, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=True), {'a': int, 'b': 'str', 'c': isa.MyClass, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=True), {'a': 'int', 'b': 'str', 'c': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=True), {})
-        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=True), {})
-
-        self.assertEqual(inspect.get_annotations(isa, eval_str=False), {'a': 'int', 'b': 'str'})
-        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=False), {'a': 'int', 'b': 'str'})
-        self.assertEqual(inspect.get_annotations(isa.function, eval_str=False), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=False), {'a': 'int', 'b': "'str'", 'c': 'MyClass', 'return': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=False), {'a': "'int'", 'b': "'str'", 'c': "'MyClass'"})
-        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=False), {})
-        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=False), {})
-
-        isa2 = inspect_stringized_annotations_2
-        self.assertEqual(inspect.get_annotations(isa2), {})
-        self.assertEqual(inspect.get_annotations(isa2, eval_str=True), {})
-        self.assertEqual(inspect.get_annotations(isa2, eval_str=False), {})
-
-        def times_three(fn):
-            @functools.wraps(fn)
-            def wrapper(a, b):
-                return fn(a*3, b*3)
-            return wrapper
-
-        wrapped = times_three(isa.function)
-        self.assertEqual(wrapped(1, 'x'), isa.MyClass(3, 'xxx'))
-        self.assertIsNot(wrapped.__globals__, isa.function.__globals__)
-        self.assertEqual(inspect.get_annotations(wrapped), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
-        self.assertEqual(inspect.get_annotations(wrapped, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
-        self.assertEqual(inspect.get_annotations(wrapped, eval_str=False), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
-
-        # test that local namespace lookups work
-        self.assertEqual(inspect.get_annotations(isa.MyClassWithLocalAnnotations), {'x': 'mytype'})
-        self.assertEqual(inspect.get_annotations(isa.MyClassWithLocalAnnotations, eval_str=True), {'x': int})
-
-
-class TestFormatAnnotation(unittest.TestCase):
-    def test_typing_replacement(self):
-        from test.typinganndata.ann_module9 import ann, ann1
-        self.assertEqual(inspect.formatannotation(ann), 'Union[List[str], int]')
-        self.assertEqual(inspect.formatannotation(ann1), 'Union[List[testModule.typing.A], int]')
-
-
-class TestIsDataDescriptor(unittest.TestCase):
-
-    def test_custom_descriptors(self):
-        class NonDataDescriptor:
-            def __get__(self, value, type=None): pass
-        class DataDescriptor0:
-            def __set__(self, name, value): pass
-        class DataDescriptor1:
-            def __delete__(self, name): pass
-        class DataDescriptor2:
-            __set__ = None
-        self.assertFalse(inspect.isdatadescriptor(NonDataDescriptor()),
-                         'class with only __get__ not a data descriptor')
-        self.assertTrue(inspect.isdatadescriptor(DataDescriptor0()),
-                        'class with __set__ is a data descriptor')
-        self.assertTrue(inspect.isdatadescriptor(DataDescriptor1()),
-                        'class with __delete__ is a data descriptor')
-        self.assertTrue(inspect.isdatadescriptor(DataDescriptor2()),
-                        'class with __set__ = None is a data descriptor')
-
-    def test_slot(self):
-        class Slotted:
-            __slots__ = 'foo',
-        self.assertTrue(inspect.isdatadescriptor(Slotted.foo),
-                        'a slot is a data descriptor')
-
-    def test_property(self):
-        class Propertied:
-            @property
-            def a_property(self):
-                pass
-        self.assertTrue(inspect.isdatadescriptor(Propertied.a_property),
-                        'a property is a data descriptor')
-
-    def test_functions(self):
-        class Test(object):
-            def instance_method(self): pass
-            @classmethod
-            def class_method(cls): pass
-            @staticmethod
-            def static_method(): pass
-        def function():
-            pass
-        a_lambda = lambda: None
-        self.assertFalse(inspect.isdatadescriptor(Test().instance_method),
-                         'a instance method is not a data descriptor')
-        self.assertFalse(inspect.isdatadescriptor(Test().class_method),
-                         'a class method is not a data descriptor')
-        self.assertFalse(inspect.isdatadescriptor(Test().static_method),
-                         'a static method is not a data descriptor')
-        self.assertFalse(inspect.isdatadescriptor(function),
-                         'a function is not a data descriptor')
-        self.assertFalse(inspect.isdatadescriptor(a_lambda),
-                         'a lambda is not a data descriptor')
-
-
-_global_ref = object()
-class TestGetClosureVars(unittest.TestCase):
-
-    def test_name_resolution(self):
-        # Basic test of the 4 different resolution mechanisms
-        def f(nonlocal_ref):
-            def g(local_ref):
-                print(local_ref, nonlocal_ref, _global_ref, unbound_ref)
-            return g
-        _arg = object()
-        nonlocal_vars = {"nonlocal_ref": _arg}
-        global_vars = {"_global_ref": _global_ref}
-        builtin_vars = {"print": print}
-        unbound_names = {"unbound_ref"}
-        expected = inspect.ClosureVars(nonlocal_vars, global_vars,
-                                       builtin_vars, unbound_names)
-        self.assertEqual(inspect.getclosurevars(f(_arg)), expected)
-
-    def test_generator_closure(self):
-        def f(nonlocal_ref):
-            def g(local_ref):
-                print(local_ref, nonlocal_ref, _global_ref, unbound_ref)
-                yield
-            return g
-        _arg = object()
-        nonlocal_vars = {"nonlocal_ref": _arg}
-        global_vars = {"_global_ref": _global_ref}
-        builtin_vars = {"print": print}
-        unbound_names = {"unbound_ref"}
-        expected = inspect.ClosureVars(nonlocal_vars, global_vars,
-                                       builtin_vars, unbound_names)
-        self.assertEqual(inspect.getclosurevars(f(_arg)), expected)
-
-    def test_method_closure(self):
-        class C:
-            def f(self, nonlocal_ref):
-                def g(local_ref):
-                    print(local_ref, nonlocal_ref, _global_ref, unbound_ref)
-                return g
-        _arg = object()
-        nonlocal_vars = {"nonlocal_ref": _arg}
-        global_vars = {"_global_ref": _global_ref}
-        builtin_vars = {"print": print}
-        unbound_names = {"unbound_ref"}
-        expected = inspect.ClosureVars(nonlocal_vars, global_vars,
-                                       builtin_vars, unbound_names)
-        self.assertEqual(inspect.getclosurevars(C().f(_arg)), expected)
-
-    def test_nonlocal_vars(self):
-        # More complex tests of nonlocal resolution
-        def _nonlocal_vars(f):
-            return inspect.getclosurevars(f).nonlocals
-
-        def make_adder(x):
-            def add(y):
-                return x + y
-            return add
-
-        def curry(func, arg1):
-            return lambda arg2: func(arg1, arg2)
-
-        def less_than(a, b):
-            return a < b
-
-        # The infamous Y combinator.
-        def Y(le):
-            def g(f):
-                return le(lambda x: f(f)(x))
-            Y.g_ref = g
-            return g(g)
-
-        def check_y_combinator(func):
-            self.assertEqual(_nonlocal_vars(func), {'f': Y.g_ref})
-
-        inc = make_adder(1)
-        add_two = make_adder(2)
-        greater_than_five = curry(less_than, 5)
-
-        self.assertEqual(_nonlocal_vars(inc), {'x': 1})
-        self.assertEqual(_nonlocal_vars(add_two), {'x': 2})
-        self.assertEqual(_nonlocal_vars(greater_than_five),
-                         {'arg1': 5, 'func': less_than})
-        self.assertEqual(_nonlocal_vars((lambda x: lambda y: x + y)(3)),
-                         {'x': 3})
-        Y(check_y_combinator)
-
-    def test_getclosurevars_empty(self):
-        def foo(): pass
-        _empty = inspect.ClosureVars({}, {}, {}, set())
-        self.assertEqual(inspect.getclosurevars(lambda: True), _empty)
-        self.assertEqual(inspect.getclosurevars(foo), _empty)
-
-    def test_getclosurevars_error(self):
-        class T: pass
-        self.assertRaises(TypeError, inspect.getclosurevars, 1)
-        self.assertRaises(TypeError, inspect.getclosurevars, list)
-        self.assertRaises(TypeError, inspect.getclosurevars, {})
-
-    def _private_globals(self):
-        code = """def f(): print(path)"""
-        ns = {}
-        exec(code, ns)
-        return ns["f"], ns
-
-    def test_builtins_fallback(self):
-        f, ns = self._private_globals()
-        ns.pop("__builtins__", None)
-        expected = inspect.ClosureVars({}, {}, {"print":print}, {"path"})
-        self.assertEqual(inspect.getclosurevars(f), expected)
-
-    def test_builtins_as_dict(self):
-        f, ns = self._private_globals()
-        ns["__builtins__"] = {"path":1}
-        expected = inspect.ClosureVars({}, {}, {"path":1}, {"print"})
-        self.assertEqual(inspect.getclosurevars(f), expected)
-
-    def test_builtins_as_module(self):
-        f, ns = self._private_globals()
-        ns["__builtins__"] = os
-        expected = inspect.ClosureVars({}, {}, {"path":os.path}, {"print"})
-        self.assertEqual(inspect.getclosurevars(f), expected)
-
-
-class TestGetcallargsFunctions(unittest.TestCase):
-
-    def assertEqualCallArgs(self, func, call_params_string, locs=None):
-        locs = dict(locs or {}, func=func)
-        r1 = eval('func(%s)' % call_params_string, None, locs)
-        r2 = eval('inspect.getcallargs(func, %s)' % call_params_string, None,
-                  locs)
-        self.assertEqual(r1, r2)
-
-    def assertEqualException(self, func, call_param_string, locs=None):
-        locs = dict(locs or {}, func=func)
-        try:
-            eval('func(%s)' % call_param_string, None, locs)
-        except Exception as e:
-            ex1 = e
-        else:
-            self.fail('Exception not raised')
-        try:
-            eval('inspect.getcallargs(func, %s)' % call_param_string, None,
-                 locs)
-        except Exception as e:
-            ex2 = e
-        else:
-            self.fail('Exception not raised')
-        self.assertIs(type(ex1), type(ex2))
-        self.assertEqual(str(ex1), str(ex2))
-        del ex1, ex2
-
-    def makeCallable(self, signature):
-        """Create a function that returns its locals()"""
-        code = "lambda %s: locals()"
-        return eval(code % signature)
-
-    def test_plain(self):
-        f = self.makeCallable('a, b=1')
-        self.assertEqualCallArgs(f, '2')
-        self.assertEqualCallArgs(f, '2, 3')
-        self.assertEqualCallArgs(f, 'a=2')
-        self.assertEqualCallArgs(f, 'b=3, a=2')
-        self.assertEqualCallArgs(f, '2, b=3')
-        # expand *iterable / **mapping
-        self.assertEqualCallArgs(f, '*(2,)')
-        self.assertEqualCallArgs(f, '*[2]')
-        self.assertEqualCallArgs(f, '*(2, 3)')
-        self.assertEqualCallArgs(f, '*[2, 3]')
-        self.assertEqualCallArgs(f, '**{"a":2}')
-        self.assertEqualCallArgs(f, 'b=3, **{"a":2}')
-        self.assertEqualCallArgs(f, '2, **{"b":3}')
-        self.assertEqualCallArgs(f, '**{"b":3, "a":2}')
-        # expand UserList / UserDict
-        self.assertEqualCallArgs(f, '*collections.UserList([2])')
-        self.assertEqualCallArgs(f, '*collections.UserList([2, 3])')
-        self.assertEqualCallArgs(f, '**collections.UserDict(a=2)')
-        self.assertEqualCallArgs(f, '2, **collections.UserDict(b=3)')
-        self.assertEqualCallArgs(f, 'b=2, **collections.UserDict(a=3)')
-
-    def test_varargs(self):
-        f = self.makeCallable('a, b=1, *c')
-        self.assertEqualCallArgs(f, '2')
-        self.assertEqualCallArgs(f, '2, 3')
-        self.assertEqualCallArgs(f, '2, 3, 4')
-        self.assertEqualCallArgs(f, '*(2,3,4)')
-        self.assertEqualCallArgs(f, '2, *[3,4]')
-        self.assertEqualCallArgs(f, '2, 3, *collections.UserList([4])')
-
-    def test_varkw(self):
-        f = self.makeCallable('a, b=1, **c')
-        self.assertEqualCallArgs(f, 'a=2')
-        self.assertEqualCallArgs(f, '2, b=3, c=4')
-        self.assertEqualCallArgs(f, 'b=3, a=2, c=4')
-        self.assertEqualCallArgs(f, 'c=4, **{"a":2, "b":3}')
-        self.assertEqualCallArgs(f, '2, c=4, **{"b":3}')
-        self.assertEqualCallArgs(f, 'b=2, **{"a":3, "c":4}')
-        self.assertEqualCallArgs(f, '**collections.UserDict(a=2, b=3, c=4)')
-        self.assertEqualCallArgs(f, '2, c=4, **collections.UserDict(b=3)')
-        self.assertEqualCallArgs(f, 'b=2, **collections.UserDict(a=3, c=4)')
-
-    def test_varkw_only(self):
-        # issue11256:
-        f = self.makeCallable('**c')
-        self.assertEqualCallArgs(f, '')
-        self.assertEqualCallArgs(f, 'a=1')
-        self.assertEqualCallArgs(f, 'a=1, b=2')
-        self.assertEqualCallArgs(f, 'c=3, **{"a": 1, "b": 2}')
-        self.assertEqualCallArgs(f, '**collections.UserDict(a=1, b=2)')
-        self.assertEqualCallArgs(f, 'c=3, **collections.UserDict(a=1, b=2)')
-
-    def test_keyword_only(self):
-        f = self.makeCallable('a=3, *, c, d=2')
-        self.assertEqualCallArgs(f, 'c=3')
-        self.assertEqualCallArgs(f, 'c=3, a=3')
-        self.assertEqualCallArgs(f, 'a=2, c=4')
-        self.assertEqualCallArgs(f, '4, c=4')
-        self.assertEqualException(f, '')
-        self.assertEqualException(f, '3')
-        self.assertEqualException(f, 'a=3')
-        self.assertEqualException(f, 'd=4')
-
-        f = self.makeCallable('*, c, d=2')
-        self.assertEqualCallArgs(f, 'c=3')
-        self.assertEqualCallArgs(f, 'c=3, d=4')
-        self.assertEqualCallArgs(f, 'd=4, c=3')
-
-    def test_multiple_features(self):
-        f = self.makeCallable('a, b=2, *f, **g')
-        self.assertEqualCallArgs(f, '2, 3, 7')
-        self.assertEqualCallArgs(f, '2, 3, x=8')
-        self.assertEqualCallArgs(f, '2, 3, x=8, *[(4,[5,6]), 7]')
-        self.assertEqualCallArgs(f, '2, x=8, *[3, (4,[5,6]), 7], y=9')
-        self.assertEqualCallArgs(f, 'x=8, *[2, 3, (4,[5,6])], y=9')
-        self.assertEqualCallArgs(f, 'x=8, *collections.UserList('
-                                 '[2, 3, (4,[5,6])]), **{"y":9, "z":10}')
-        self.assertEqualCallArgs(f, '2, x=8, *collections.UserList([3, '
-                                 '(4,[5,6])]), **collections.UserDict('
-                                 'y=9, z=10)')
-
-        f = self.makeCallable('a, b=2, *f, x, y=99, **g')
-        self.assertEqualCallArgs(f, '2, 3, x=8')
-        self.assertEqualCallArgs(f, '2, 3, x=8, *[(4,[5,6]), 7]')
-        self.assertEqualCallArgs(f, '2, x=8, *[3, (4,[5,6]), 7], y=9, z=10')
-        self.assertEqualCallArgs(f, 'x=8, *[2, 3, (4,[5,6])], y=9, z=10')
-        self.assertEqualCallArgs(f, 'x=8, *collections.UserList('
-                                 '[2, 3, (4,[5,6])]), q=0, **{"y":9, "z":10}')
-        self.assertEqualCallArgs(f, '2, x=8, *collections.UserList([3, '
-                                 '(4,[5,6])]), q=0, **collections.UserDict('
-                                 'y=9, z=10)')
-
-    def test_errors(self):
-        f0 = self.makeCallable('')
-        f1 = self.makeCallable('a, b')
-        f2 = self.makeCallable('a, b=1')
-        # f0 takes no arguments
-        self.assertEqualException(f0, '1')
-        self.assertEqualException(f0, 'x=1')
-        self.assertEqualException(f0, '1,x=1')
-        # f1 takes exactly 2 arguments
-        self.assertEqualException(f1, '')
-        self.assertEqualException(f1, '1')
-        self.assertEqualException(f1, 'a=2')
-        self.assertEqualException(f1, 'b=3')
-        # f2 takes at least 1 argument
-        self.assertEqualException(f2, '')
-        self.assertEqualException(f2, 'b=3')
-        for f in f1, f2:
-            # f1/f2 takes exactly/at most 2 arguments
-            self.assertEqualException(f, '2, 3, 4')
-            self.assertEqualException(f, '1, 2, 3, a=1')
-            self.assertEqualException(f, '2, 3, 4, c=5')
-            self.assertEqualException(f, '2, 3, 4, a=1, c=5')
-            # f got an unexpected keyword argument
-            self.assertEqualException(f, 'c=2')
-            self.assertEqualException(f, '2, c=3')
-            self.assertEqualException(f, '2, 3, c=4')
-            self.assertEqualException(f, '2, c=4, b=3')
-            self.assertEqualException(f, '**{u"\u03c0\u03b9": 4}')
-            # f got multiple values for keyword argument
-            self.assertEqualException(f, '1, a=2')
-            self.assertEqualException(f, '1, **{"a":2}')
-            self.assertEqualException(f, '1, 2, b=3')
-            self.assertEqualException(f, '1, c=3, a=2')
-        # issue11256:
-        f3 = self.makeCallable('**c')
-        self.assertEqualException(f3, '1, 2')
-        self.assertEqualException(f3, '1, 2, a=1, b=2')
-        f4 = self.makeCallable('*, a, b=0')
-        self.assertEqualException(f4, '1, 2')
-        self.assertEqualException(f4, '1, 2, a=1, b=2')
-        self.assertEqualException(f4, 'a=1, a=3')
-        self.assertEqualException(f4, 'a=1, c=3')
-        self.assertEqualException(f4, 'a=1, a=3, b=4')
-        self.assertEqualException(f4, 'a=1, b=2, a=3, b=4')
-        self.assertEqualException(f4, 'a=1, a=2, a=3, b=4')
-
-        # issue #20816: getcallargs() fails to iterate over non-existent
-        # kwonlydefaults and raises a wrong TypeError
-        def f5(*, a): pass
-        with self.assertRaisesRegex(TypeError,
-                                    'missing 1 required keyword-only'):
-            inspect.getcallargs(f5)
-
-
-        # issue20817:
-        def f6(a, b, c):
-            pass
-        with self.assertRaisesRegex(TypeError, "'a', 'b' and 'c'"):
-            inspect.getcallargs(f6)
-
-        # bpo-33197
-        with self.assertRaisesRegex(ValueError,
-                                    'variadic keyword parameters cannot'
-                                    ' have default values'):
-            inspect.Parameter("foo", kind=inspect.Parameter.VAR_KEYWORD,
-                              default=42)
-        with self.assertRaisesRegex(ValueError,
-                                    "value 5 is not a valid Parameter.kind"):
-            inspect.Parameter("bar", kind=5, default=42)
-
-        with self.assertRaisesRegex(TypeError,
-                                   'name must be a str, not a int'):
-            inspect.Parameter(123, kind=4)
-
-class TestGetcallargsMethods(TestGetcallargsFunctions):
-
-    def setUp(self):
-        class Foo(object):
-            pass
-        self.cls = Foo
-        self.inst = Foo()
-
-    def makeCallable(self, signature):
-        assert 'self' not in signature
-        mk = super(TestGetcallargsMethods, self).makeCallable
-        self.cls.method = mk('self, ' + signature)
-        return self.inst.method
-
-class TestGetcallargsUnboundMethods(TestGetcallargsMethods):
-
-    def makeCallable(self, signature):
-        super(TestGetcallargsUnboundMethods, self).makeCallable(signature)
-        return self.cls.method
-
-    def assertEqualCallArgs(self, func, call_params_string, locs=None):
-        return super(TestGetcallargsUnboundMethods, self).assertEqualCallArgs(
-            *self._getAssertEqualParams(func, call_params_string, locs))
-
-    def assertEqualException(self, func, call_params_string, locs=None):
-        return super(TestGetcallargsUnboundMethods, self).assertEqualException(
-            *self._getAssertEqualParams(func, call_params_string, locs))
-
-    def _getAssertEqualParams(self, func, call_params_string, locs=None):
-        assert 'inst' not in call_params_string
-        locs = dict(locs or {}, inst=self.inst)
-        return (func, 'inst,' + call_params_string, locs)
-
-
-class TestGetattrStatic(unittest.TestCase):
-
-    def test_basic(self):
-        class Thing(object):
-            x = object()
-
-        thing = Thing()
-        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
-        self.assertEqual(inspect.getattr_static(thing, 'x', None), Thing.x)
-        with self.assertRaises(AttributeError):
-            inspect.getattr_static(thing, 'y')
-
-        self.assertEqual(inspect.getattr_static(thing, 'y', 3), 3)
-
-    def test_inherited(self):
-        class Thing(object):
-            x = object()
-        class OtherThing(Thing):
-            pass
-
-        something = OtherThing()
-        self.assertEqual(inspect.getattr_static(something, 'x'), Thing.x)
-
-    def test_instance_attr(self):
-        class Thing(object):
-            x = 2
-            def __init__(self, x):
-                self.x = x
-        thing = Thing(3)
-        self.assertEqual(inspect.getattr_static(thing, 'x'), 3)
-        del thing.x
-        self.assertEqual(inspect.getattr_static(thing, 'x'), 2)
-
-    def test_property(self):
-        class Thing(object):
-            @property
-            def x(self):
-                raise AttributeError("I'm pretending not to exist")
-        thing = Thing()
-        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
-
-    def test_descriptor_raises_AttributeError(self):
-        class descriptor(object):
-            def __get__(*_):
-                raise AttributeError("I'm pretending not to exist")
-        desc = descriptor()
-        class Thing(object):
-            x = desc
-        thing = Thing()
-        self.assertEqual(inspect.getattr_static(thing, 'x'), desc)
-
-    def test_classAttribute(self):
-        class Thing(object):
-            x = object()
-
-        self.assertEqual(inspect.getattr_static(Thing, 'x'), Thing.x)
-
-    def test_classVirtualAttribute(self):
-        class Thing(object):
-            @types.DynamicClassAttribute
-            def x(self):
-                return self._x
-            _x = object()
-
-        self.assertEqual(inspect.getattr_static(Thing, 'x'), Thing.__dict__['x'])
-
-    def test_inherited_classattribute(self):
-        class Thing(object):
-            x = object()
-        class OtherThing(Thing):
-            pass
-
-        self.assertEqual(inspect.getattr_static(OtherThing, 'x'), Thing.x)
-
-    def test_slots(self):
-        class Thing(object):
-            y = 'bar'
-            __slots__ = ['x']
-            def __init__(self):
-                self.x = 'foo'
-        thing = Thing()
-        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
-        self.assertEqual(inspect.getattr_static(thing, 'y'), 'bar')
-
-        del thing.x
-        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
-
-    def test_metaclass(self):
-        class meta(type):
-            attr = 'foo'
-        class Thing(object, metaclass=meta):
-            pass
-        self.assertEqual(inspect.getattr_static(Thing, 'attr'), 'foo')
-
-        class sub(meta):
-            pass
-        class OtherThing(object, metaclass=sub):
-            x = 3
-        self.assertEqual(inspect.getattr_static(OtherThing, 'attr'), 'foo')
-
-        class OtherOtherThing(OtherThing):
-            pass
-        # this test is odd, but it was added as it exposed a bug
-        self.assertEqual(inspect.getattr_static(OtherOtherThing, 'x'), 3)
-
-    def test_no_dict_no_slots(self):
-        self.assertEqual(inspect.getattr_static(1, 'foo', None), None)
-        self.assertNotEqual(inspect.getattr_static('foo', 'lower'), None)
-
-    def test_no_dict_no_slots_instance_member(self):
-        # returns descriptor
-        with open(__file__, encoding='utf-8') as handle:
-            self.assertEqual(inspect.getattr_static(handle, 'name'), type(handle).name)
-
-    def test_inherited_slots(self):
-        # returns descriptor
-        class Thing(object):
-            __slots__ = ['x']
-            def __init__(self):
-                self.x = 'foo'
-
-        class OtherThing(Thing):
-            pass
-        # it would be nice if this worked...
-        # we get the descriptor instead of the instance attribute
-        self.assertEqual(inspect.getattr_static(OtherThing(), 'x'), Thing.x)
-
-    def test_descriptor(self):
-        class descriptor(object):
-            def __get__(self, instance, owner):
-                return 3
-        class Foo(object):
-            d = descriptor()
-
-        foo = Foo()
-
-        # for a non data descriptor we return the instance attribute
-        foo.__dict__['d'] = 1
-        self.assertEqual(inspect.getattr_static(foo, 'd'), 1)
-
-        # if the descriptor is a data-descriptor we should return the
-        # descriptor
-        descriptor.__set__ = lambda s, i, v: None
-        self.assertEqual(inspect.getattr_static(foo, 'd'), Foo.__dict__['d'])
-
-        del descriptor.__set__
-        descriptor.__delete__ = lambda s, i, o: None
-        self.assertEqual(inspect.getattr_static(foo, 'd'), Foo.__dict__['d'])
-
-    def test_metaclass_with_descriptor(self):
-        class descriptor(object):
-            def __get__(self, instance, owner):
-                return 3
-        class meta(type):
-            d = descriptor()
-        class Thing(object, metaclass=meta):
-            pass
-        self.assertEqual(inspect.getattr_static(Thing, 'd'), meta.__dict__['d'])
-
-
-    def test_class_as_property(self):
-        class Base(object):
-            foo = 3
-
-        class Something(Base):
-            executed = False
-            @property
-            def __class__(self):
-                self.executed = True
-                return object
-
-        instance = Something()
-        self.assertEqual(inspect.getattr_static(instance, 'foo'), 3)
-        self.assertFalse(instance.executed)
-        self.assertEqual(inspect.getattr_static(Something, 'foo'), 3)
-
-    def test_mro_as_property(self):
-        class Meta(type):
-            @property
-            def __mro__(self):
-                return (object,)
-
-        class Base(object):
-            foo = 3
-
-        class Something(Base, metaclass=Meta):
-            pass
-
-        self.assertEqual(inspect.getattr_static(Something(), 'foo'), 3)
-        self.assertEqual(inspect.getattr_static(Something, 'foo'), 3)
-
-    def test_dict_as_property(self):
-        test = self
-        test.called = False
-
-        class Foo(dict):
-            a = 3
-            @property
-            def __dict__(self):
-                test.called = True
-                return {}
-
-        foo = Foo()
-        foo.a = 4
-        self.assertEqual(inspect.getattr_static(foo, 'a'), 3)
-        self.assertFalse(test.called)
-
-    def test_mutated_mro(self):
-        test = self
-        test.called = False
-
-        class Foo(dict):
-            a = 3
-            @property
-            def __dict__(self):
-                test.called = True
-                return {}
-
-        class Bar(dict):
-            a = 4
-
-        class Baz(Bar): pass
-
-        baz = Baz()
-        self.assertEqual(inspect.getattr_static(baz, 'a'), 4)
-        Baz.__bases__ = (Foo,)
-        self.assertEqual(inspect.getattr_static(baz, 'a'), 3)
-        self.assertFalse(test.called)
-
-    def test_custom_object_dict(self):
-        test = self
-        test.called = False
-
-        class Custom(dict):
-            def get(self, key, default=None):
-                test.called = True
-                super().get(key, default)
-
-        class Foo(object):
-            a = 3
-        foo = Foo()
-        foo.__dict__ = Custom()
-        self.assertEqual(inspect.getattr_static(foo, 'a'), 3)
-        self.assertFalse(test.called)
-
-    def test_metaclass_dict_as_property(self):
-        class Meta(type):
-            @property
-            def __dict__(self):
-                self.executed = True
-
-        class Thing(metaclass=Meta):
-            executed = False
-
-            def __init__(self):
-                self.spam = 42
-
-        instance = Thing()
-        self.assertEqual(inspect.getattr_static(instance, "spam"), 42)
-        self.assertFalse(Thing.executed)
-
-    def test_module(self):
-        sentinel = object()
-        self.assertIsNot(inspect.getattr_static(sys, "version", sentinel),
-                         sentinel)
-
-    def test_metaclass_with_metaclass_with_dict_as_property(self):
-        class MetaMeta(type):
-            @property
-            def __dict__(self):
-                self.executed = True
-                return dict(spam=42)
-
-        class Meta(type, metaclass=MetaMeta):
-            executed = False
-
-        class Thing(metaclass=Meta):
-            pass
-
-        with self.assertRaises(AttributeError):
-            inspect.getattr_static(Thing, "spam")
-        self.assertFalse(Thing.executed)
-
-    def test_custom___getattr__(self):
-        test = self
-        test.called = False
-
-        class Foo:
-            def __getattr__(self, attr):
-                test.called = True
-                return {}
-
-        with self.assertRaises(AttributeError):
-            inspect.getattr_static(Foo(), 'whatever')
-
-        self.assertFalse(test.called)
-
-    def test_custom___getattribute__(self):
-        test = self
-        test.called = False
-
-        class Foo:
-            def __getattribute__(self, attr):
-                test.called = True
-                return {}
-
-        with self.assertRaises(AttributeError):
-            inspect.getattr_static(Foo(), 'really_could_be_anything')
-
-        self.assertFalse(test.called)
-
-
-class TestGetGeneratorState(unittest.TestCase):
-
-    def setUp(self):
-        def number_generator():
-            for number in range(5):
-                yield number
-        self.generator = number_generator()
-
-    def _generatorstate(self):
-        return inspect.getgeneratorstate(self.generator)
-
-    def test_created(self):
-        self.assertEqual(self._generatorstate(), inspect.GEN_CREATED)
-
-    def test_suspended(self):
-        next(self.generator)
-        self.assertEqual(self._generatorstate(), inspect.GEN_SUSPENDED)
-
-    def test_closed_after_exhaustion(self):
-        for i in self.generator:
-            pass
-        self.assertEqual(self._generatorstate(), inspect.GEN_CLOSED)
-
-    def test_closed_after_immediate_exception(self):
-        with self.assertRaises(RuntimeError):
-            self.generator.throw(RuntimeError)
-        self.assertEqual(self._generatorstate(), inspect.GEN_CLOSED)
-
-    def test_running(self):
-        # As mentioned on issue #10220, checking for the RUNNING state only
-        # makes sense inside the generator itself.
-        # The following generator checks for this by using the closure's
-        # reference to self and the generator state checking helper method
-        def running_check_generator():
-            for number in range(5):
-                self.assertEqual(self._generatorstate(), inspect.GEN_RUNNING)
-                yield number
-                self.assertEqual(self._generatorstate(), inspect.GEN_RUNNING)
-        self.generator = running_check_generator()
-        # Running up to the first yield
-        next(self.generator)
-        # Running after the first yield
-        next(self.generator)
-
-    def test_easy_debugging(self):
-        # repr() and str() of a generator state should contain the state name
-        names = 'GEN_CREATED GEN_RUNNING GEN_SUSPENDED GEN_CLOSED'.split()
-        for name in names:
-            state = getattr(inspect, name)
-            self.assertIn(name, repr(state))
-            self.assertIn(name, str(state))
-
-    def test_getgeneratorlocals(self):
-        def each(lst, a=None):
-            b=(1, 2, 3)
-            for v in lst:
-                if v == 3:
-                    c = 12
-                yield v
-
-        numbers = each([1, 2, 3])
-        self.assertEqual(inspect.getgeneratorlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3]})
-        next(numbers)
-        self.assertEqual(inspect.getgeneratorlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3], 'v': 1,
-                          'b': (1, 2, 3)})
-        next(numbers)
-        self.assertEqual(inspect.getgeneratorlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3], 'v': 2,
-                          'b': (1, 2, 3)})
-        next(numbers)
-        self.assertEqual(inspect.getgeneratorlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3], 'v': 3,
-                          'b': (1, 2, 3), 'c': 12})
-        try:
-            next(numbers)
-        except StopIteration:
-            pass
-        self.assertEqual(inspect.getgeneratorlocals(numbers), {})
-
-    def test_getgeneratorlocals_empty(self):
-        def yield_one():
-            yield 1
-        one = yield_one()
-        self.assertEqual(inspect.getgeneratorlocals(one), {})
-        try:
-            next(one)
-        except StopIteration:
-            pass
-        self.assertEqual(inspect.getgeneratorlocals(one), {})
-
-    def test_getgeneratorlocals_error(self):
-        self.assertRaises(TypeError, inspect.getgeneratorlocals, 1)
-        self.assertRaises(TypeError, inspect.getgeneratorlocals, lambda x: True)
-        self.assertRaises(TypeError, inspect.getgeneratorlocals, set)
-        self.assertRaises(TypeError, inspect.getgeneratorlocals, (2,3))
-
-
-class TestGetCoroutineState(unittest.TestCase):
-
-    def setUp(self):
-        @types.coroutine
-        def number_coroutine():
-            for number in range(5):
-                yield number
-        async def coroutine():
-            await number_coroutine()
-        self.coroutine = coroutine()
-
-    def tearDown(self):
-        self.coroutine.close()
-
-    def _coroutinestate(self):
-        return inspect.getcoroutinestate(self.coroutine)
-
-    def test_created(self):
-        self.assertEqual(self._coroutinestate(), inspect.CORO_CREATED)
-
-    def test_suspended(self):
-        self.coroutine.send(None)
-        self.assertEqual(self._coroutinestate(), inspect.CORO_SUSPENDED)
-
-    def test_closed_after_exhaustion(self):
-        while True:
-            try:
-                self.coroutine.send(None)
-            except StopIteration:
-                break
-
-        self.assertEqual(self._coroutinestate(), inspect.CORO_CLOSED)
-
-    def test_closed_after_immediate_exception(self):
-        with self.assertRaises(RuntimeError):
-            self.coroutine.throw(RuntimeError)
-        self.assertEqual(self._coroutinestate(), inspect.CORO_CLOSED)
-
-    def test_easy_debugging(self):
-        # repr() and str() of a coroutine state should contain the state name
-        names = 'CORO_CREATED CORO_RUNNING CORO_SUSPENDED CORO_CLOSED'.split()
-        for name in names:
-            state = getattr(inspect, name)
-            self.assertIn(name, repr(state))
-            self.assertIn(name, str(state))
-
-    def test_getcoroutinelocals(self):
-        @types.coroutine
-        def gencoro():
-            yield
-
-        gencoro = gencoro()
-        async def func(a=None):
-            b = 'spam'
-            await gencoro
-
-        coro = func()
-        self.assertEqual(inspect.getcoroutinelocals(coro),
-                         {'a': None, 'gencoro': gencoro})
-        coro.send(None)
-        self.assertEqual(inspect.getcoroutinelocals(coro),
-                         {'a': None, 'gencoro': gencoro, 'b': 'spam'})
-
-
-@support.requires_working_socket()
-class TestGetAsyncGenState(unittest.IsolatedAsyncioTestCase):
-
-    def setUp(self):
-        async def number_asyncgen():
-            for number in range(5):
-                yield number
-        self.asyncgen = number_asyncgen()
-
-    async def asyncTearDown(self):
-        await self.asyncgen.aclose()
-
-    def _asyncgenstate(self):
-        return inspect.getasyncgenstate(self.asyncgen)
-
-    def test_created(self):
-        self.assertEqual(self._asyncgenstate(), inspect.AGEN_CREATED)
-
-    async def test_suspended(self):
-        value = await anext(self.asyncgen)
-        self.assertEqual(self._asyncgenstate(), inspect.AGEN_SUSPENDED)
-        self.assertEqual(value, 0)
-
-    async def test_closed_after_exhaustion(self):
-        countdown = 7
-        with self.assertRaises(StopAsyncIteration):
-            while countdown := countdown - 1:
-                await anext(self.asyncgen)
-        self.assertEqual(countdown, 1)
-        self.assertEqual(self._asyncgenstate(), inspect.AGEN_CLOSED)
-
-    async def test_closed_after_immediate_exception(self):
-        with self.assertRaises(RuntimeError):
-            await self.asyncgen.athrow(RuntimeError)
-        self.assertEqual(self._asyncgenstate(), inspect.AGEN_CLOSED)
-
-    async def test_running(self):
-        async def running_check_asyncgen():
-            for number in range(5):
-                self.assertEqual(self._asyncgenstate(), inspect.AGEN_RUNNING)
-                yield number
-                self.assertEqual(self._asyncgenstate(), inspect.AGEN_RUNNING)
-        self.asyncgen = running_check_asyncgen()
-        # Running up to the first yield
-        await anext(self.asyncgen)
-        self.assertEqual(self._asyncgenstate(), inspect.AGEN_SUSPENDED)
-        # Running after the first yield
-        await anext(self.asyncgen)
-        self.assertEqual(self._asyncgenstate(), inspect.AGEN_SUSPENDED)
-
-    def test_easy_debugging(self):
-        # repr() and str() of a asyncgen state should contain the state name
-        names = 'AGEN_CREATED AGEN_RUNNING AGEN_SUSPENDED AGEN_CLOSED'.split()
-        for name in names:
-            state = getattr(inspect, name)
-            self.assertIn(name, repr(state))
-            self.assertIn(name, str(state))
-
-    async def test_getasyncgenlocals(self):
-        async def each(lst, a=None):
-            b=(1, 2, 3)
-            for v in lst:
-                if v == 3:
-                    c = 12
-                yield v
-
-        numbers = each([1, 2, 3])
-        self.assertEqual(inspect.getasyncgenlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3]})
-        await anext(numbers)
-        self.assertEqual(inspect.getasyncgenlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3], 'v': 1,
-                          'b': (1, 2, 3)})
-        await anext(numbers)
-        self.assertEqual(inspect.getasyncgenlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3], 'v': 2,
-                          'b': (1, 2, 3)})
-        await anext(numbers)
-        self.assertEqual(inspect.getasyncgenlocals(numbers),
-                         {'a': None, 'lst': [1, 2, 3], 'v': 3,
-                          'b': (1, 2, 3), 'c': 12})
-        with self.assertRaises(StopAsyncIteration):
-            await anext(numbers)
-        self.assertEqual(inspect.getasyncgenlocals(numbers), {})
-
-    async def test_getasyncgenlocals_empty(self):
-        async def yield_one():
-            yield 1
-        one = yield_one()
-        self.assertEqual(inspect.getasyncgenlocals(one), {})
-        await anext(one)
-        self.assertEqual(inspect.getasyncgenlocals(one), {})
-        with self.assertRaises(StopAsyncIteration):
-            await anext(one)
-        self.assertEqual(inspect.getasyncgenlocals(one), {})
-
-    def test_getasyncgenlocals_error(self):
-        self.assertRaises(TypeError, inspect.getasyncgenlocals, 1)
-        self.assertRaises(TypeError, inspect.getasyncgenlocals, lambda x: True)
-        self.assertRaises(TypeError, inspect.getasyncgenlocals, set)
-        self.assertRaises(TypeError, inspect.getasyncgenlocals, (2,3))
-
-
-class MySignature(inspect.Signature):
-    # Top-level to make it picklable;
-    # used in test_signature_object_pickle
-    pass
-
-class MyParameter(inspect.Parameter):
-    # Top-level to make it picklable;
-    # used in test_signature_object_pickle
-    pass
-
-
-
-class TestSignatureObject(unittest.TestCase):
-    @staticmethod
-    def signature(func, **kw):
-        sig = inspect.signature(func, **kw)
-        return (tuple((param.name,
-                       (... if param.default is param.empty else param.default),
-                       (... if param.annotation is param.empty
-                                                        else param.annotation),
-                       str(param.kind).lower())
-                                    for param in sig.parameters.values()),
-                (... if sig.return_annotation is sig.empty
-                                            else sig.return_annotation))
-
-    def test_signature_object(self):
-        S = inspect.Signature
-        P = inspect.Parameter
-
-        self.assertEqual(str(S()), '()')
-        self.assertEqual(repr(S().parameters), 'mappingproxy(OrderedDict())')
-
-        def test(po, /, pk, pkd=100, *args, ko, kod=10, **kwargs):
-            pass
-
-        sig = inspect.signature(test)
-        self.assertTrue(repr(sig).startswith('<Signature'))
-        self.assertTrue('(po, /, pk' in repr(sig))
-
-        # We need two functions, because it is impossible to represent
-        # all param kinds in a single one.
-        def test2(pod=42, /):
-            pass
-
-        sig2 = inspect.signature(test2)
-        self.assertTrue(repr(sig2).startswith('<Signature'))
-        self.assertTrue('(pod=42, /)' in repr(sig2))
-
-        po = sig.parameters['po']
-        pod = sig2.parameters['pod']
-        pk = sig.parameters['pk']
-        pkd = sig.parameters['pkd']
-        args = sig.parameters['args']
-        ko = sig.parameters['ko']
-        kod = sig.parameters['kod']
-        kwargs = sig.parameters['kwargs']
-
-        S((po, pk, args, ko, kwargs))
-        S((po, pk, ko, kod))
-        S((po, pod, ko))
-        S((po, pod, kod))
-        S((pod, ko, kod))
-        S((pod, kod))
-        S((pod, args, kod, kwargs))
-        # keyword-only parameters without default values
-        # can follow keyword-only parameters with default values:
-        S((kod, ko))
-        S((kod, ko, kwargs))
-        S((args, kod, ko))
-
-        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
-            S((pk, po, args, ko, kwargs))
-
-        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
-            S((po, args, pk, ko, kwargs))
-
-        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
-            S((args, po, pk, ko, kwargs))
-
-        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
-            S((po, pk, args, kwargs, ko))
-
-        kwargs2 = kwargs.replace(name='args')
-        with self.assertRaisesRegex(ValueError, 'duplicate parameter name'):
-            S((po, pk, args, kwargs2, ko))
-
-        with self.assertRaisesRegex(ValueError, 'follows default argument'):
-            S((pod, po))
-
-        with self.assertRaisesRegex(ValueError, 'follows default argument'):
-            S((pod, pk))
-
-        with self.assertRaisesRegex(ValueError, 'follows default argument'):
-            S((po, pod, pk))
-
-        with self.assertRaisesRegex(ValueError, 'follows default argument'):
-            S((po, pkd, pk))
-
-        with self.assertRaisesRegex(ValueError, 'follows default argument'):
-            S((pkd, pk))
-
-    def test_signature_object_pickle(self):
-        def foo(a, b, *, c:1={}, **kw) -> {42:'ham'}: pass
-        foo_partial = functools.partial(foo, a=1)
-
-        sig = inspect.signature(foo_partial)
-
-        for ver in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(pickle_ver=ver, subclass=False):
-                sig_pickled = pickle.loads(pickle.dumps(sig, ver))
-                self.assertEqual(sig, sig_pickled)
-
-        # Test that basic sub-classing works
-        sig = inspect.signature(foo)
-        myparam = MyParameter(name='z', kind=inspect.Parameter.POSITIONAL_ONLY)
-        myparams = collections.OrderedDict(sig.parameters, a=myparam)
-        mysig = MySignature().replace(parameters=myparams.values(),
-                                      return_annotation=sig.return_annotation)
-        self.assertTrue(isinstance(mysig, MySignature))
-        self.assertTrue(isinstance(mysig.parameters['z'], MyParameter))
-
-        for ver in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(pickle_ver=ver, subclass=True):
-                sig_pickled = pickle.loads(pickle.dumps(mysig, ver))
-                self.assertEqual(mysig, sig_pickled)
-                self.assertTrue(isinstance(sig_pickled, MySignature))
-                self.assertTrue(isinstance(sig_pickled.parameters['z'],
-                                           MyParameter))
-
-    def test_signature_immutability(self):
-        def test(a):
-            pass
-        sig = inspect.signature(test)
-
-        with self.assertRaises(AttributeError):
-            sig.foo = 'bar'
-
-        with self.assertRaises(TypeError):
-            sig.parameters['a'] = None
-
-    def test_signature_on_noarg(self):
-        def test():
-            pass
-        self.assertEqual(self.signature(test), ((), ...))
-
-    def test_signature_on_wargs(self):
-        def test(a, b:'foo') -> 123:
-            pass
-        self.assertEqual(self.signature(test),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., 'foo', "positional_or_keyword")),
-                          123))
-
-    def test_signature_on_wkwonly(self):
-        def test(*, a:float, b:str) -> int:
-            pass
-        self.assertEqual(self.signature(test),
-                         ((('a', ..., float, "keyword_only"),
-                           ('b', ..., str, "keyword_only")),
-                           int))
-
-    def test_signature_on_complex_args(self):
-        def test(a, b:'foo'=10, *args:'bar', spam:'baz', ham=123, **kwargs:int):
-            pass
-        self.assertEqual(self.signature(test),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', 10, 'foo', "positional_or_keyword"),
-                           ('args', ..., 'bar', "var_positional"),
-                           ('spam', ..., 'baz', "keyword_only"),
-                           ('ham', 123, ..., "keyword_only"),
-                           ('kwargs', ..., int, "var_keyword")),
-                          ...))
-
-    def test_signature_without_self(self):
-        def test_args_only(*args):  # NOQA
-            pass
-
-        def test_args_kwargs_only(*args, **kwargs):  # NOQA
-            pass
-
-        class A:
-            @classmethod
-            def test_classmethod(*args):  # NOQA
-                pass
-
-            @staticmethod
-            def test_staticmethod(*args):  # NOQA
-                pass
-
-            f1 = functools.partialmethod((test_classmethod), 1)
-            f2 = functools.partialmethod((test_args_only), 1)
-            f3 = functools.partialmethod((test_staticmethod), 1)
-            f4 = functools.partialmethod((test_args_kwargs_only),1)
-
-        self.assertEqual(self.signature(test_args_only),
-                         ((('args', ..., ..., 'var_positional'),), ...))
-        self.assertEqual(self.signature(test_args_kwargs_only),
-                         ((('args', ..., ..., 'var_positional'),
-                           ('kwargs', ..., ..., 'var_keyword')), ...))
-        self.assertEqual(self.signature(A.f1),
-                         ((('args', ..., ..., 'var_positional'),), ...))
-        self.assertEqual(self.signature(A.f2),
-                         ((('args', ..., ..., 'var_positional'),), ...))
-        self.assertEqual(self.signature(A.f3),
-                         ((('args', ..., ..., 'var_positional'),), ...))
-        self.assertEqual(self.signature(A.f4),
-                         ((('args', ..., ..., 'var_positional'),
-                            ('kwargs', ..., ..., 'var_keyword')), ...))
-    @cpython_only
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_signature_on_builtins(self):
-        import _testcapi
-
-        def test_unbound_method(o):
-            """Use this to test unbound methods (things that should have a self)"""
-            signature = inspect.signature(o)
-            self.assertTrue(isinstance(signature, inspect.Signature))
-            self.assertEqual(list(signature.parameters.values())[0].name, 'self')
-            return signature
-
-        def test_callable(o):
-            """Use this to test bound methods or normal callables (things that don't expect self)"""
-            signature = inspect.signature(o)
-            self.assertTrue(isinstance(signature, inspect.Signature))
-            if signature.parameters:
-                self.assertNotEqual(list(signature.parameters.values())[0].name, 'self')
-            return signature
-
-        signature = test_callable(_testcapi.docstring_with_signature_with_defaults)
-        def p(name): return signature.parameters[name].default
-        self.assertEqual(p('s'), 'avocado')
-        self.assertEqual(p('b'), b'bytes')
-        self.assertEqual(p('d'), 3.14)
-        self.assertEqual(p('i'), 35)
-        self.assertEqual(p('n'), None)
-        self.assertEqual(p('t'), True)
-        self.assertEqual(p('f'), False)
-        self.assertEqual(p('local'), 3)
-        self.assertEqual(p('sys'), sys.maxsize)
-        self.assertEqual(p('exp'), sys.maxsize - 1)
-
-        test_callable(object)
-
-        # normal method
-        # (PyMethodDescr_Type, "method_descriptor")
-        test_unbound_method(_pickle.Pickler.dump)
-        d = _pickle.Pickler(io.StringIO())
-        test_callable(d.dump)
-
-        # static method
-        test_callable(bytes.maketrans)
-        test_callable(b'abc'.maketrans)
-
-        # class method
-        test_callable(dict.fromkeys)
-        test_callable({}.fromkeys)
-
-        # wrapper around slot (PyWrapperDescr_Type, "wrapper_descriptor")
-        test_unbound_method(type.__call__)
-        test_unbound_method(int.__add__)
-        test_callable((3).__add__)
-
-        # _PyMethodWrapper_Type
-        # support for 'method-wrapper'
-        test_callable(min.__call__)
-
-        # This doesn't work now.
-        # (We don't have a valid signature for "type" in 3.4)
-        with self.assertRaisesRegex(ValueError, "no signature found"):
-            class ThisWorksNow:
-                __call__ = type
-            test_callable(ThisWorksNow())
-
-        # Regression test for issue #20786
-        test_unbound_method(dict.__delitem__)
-        test_unbound_method(property.__delete__)
-
-        # Regression test for issue #20586
-        test_callable(_testcapi.docstring_with_signature_but_no_doc)
-
-        # Regression test for gh-104955
-        method = bytearray.__release_buffer__
-        sig = test_unbound_method(method)
-        self.assertEqual(list(sig.parameters), ['self', 'buffer'])
-
-    @cpython_only
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_signature_on_decorated_builtins(self):
-        import _testcapi
-        func = _testcapi.docstring_with_signature_with_defaults
-
-        def decorator(func):
-            @functools.wraps(func)
-            def wrapper(*args, **kwargs) -> int:
-                return func(*args, **kwargs)
-            return wrapper
-
-        decorated_func = decorator(func)
-
-        self.assertEqual(inspect.signature(func),
-                         inspect.signature(decorated_func))
-
-        def wrapper_like(*args, **kwargs) -> int: pass
-        self.assertEqual(inspect.signature(decorated_func,
-                                           follow_wrapped=False),
-                         inspect.signature(wrapper_like))
-
-    @cpython_only
-    def test_signature_on_builtins_no_signature(self):
-        import _testcapi
-        with self.assertRaisesRegex(ValueError,
-                                    'no signature found for builtin'):
-            inspect.signature(_testcapi.docstring_no_signature)
-
-        with self.assertRaisesRegex(ValueError,
-                                    'no signature found for builtin'):
-            inspect.signature(str)
-
-    def test_signature_on_non_function(self):
-        with self.assertRaisesRegex(TypeError, 'is not a callable object'):
-            inspect.signature(42)
-
-    def test_signature_from_functionlike_object(self):
-        def func(a,b, *args, kwonly=True, kwonlyreq, **kwargs):
-            pass
-
-        class funclike:
-            # Has to be callable, and have correct
-            # __code__, __annotations__, __defaults__, __name__,
-            # and __kwdefaults__ attributes
-
-            def __init__(self, func):
-                self.__name__ = func.__name__
-                self.__code__ = func.__code__
-                self.__annotations__ = func.__annotations__
-                self.__defaults__ = func.__defaults__
-                self.__kwdefaults__ = func.__kwdefaults__
-                self.func = func
-
-            def __call__(self, *args, **kwargs):
-                return self.func(*args, **kwargs)
-
-        sig_func = inspect.Signature.from_callable(func)
-
-        sig_funclike = inspect.Signature.from_callable(funclike(func))
-        self.assertEqual(sig_funclike, sig_func)
-
-        sig_funclike = inspect.signature(funclike(func))
-        self.assertEqual(sig_funclike, sig_func)
-
-        # If object is not a duck type of function, then
-        # signature will try to get a signature for its '__call__'
-        # method
-        fl = funclike(func)
-        del fl.__defaults__
-        self.assertEqual(self.signature(fl),
-                         ((('args', ..., ..., "var_positional"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                           ...))
-
-        # Test with cython-like builtins:
-        _orig_isdesc = inspect.ismethoddescriptor
-        def _isdesc(obj):
-            if hasattr(obj, '_builtinmock'):
-                return True
-            return _orig_isdesc(obj)
-
-        with unittest.mock.patch('inspect.ismethoddescriptor', _isdesc):
-            builtin_func = funclike(func)
-            # Make sure that our mock setup is working
-            self.assertFalse(inspect.ismethoddescriptor(builtin_func))
-            builtin_func._builtinmock = True
-            self.assertTrue(inspect.ismethoddescriptor(builtin_func))
-            self.assertEqual(inspect.signature(builtin_func), sig_func)
-
-    def test_signature_functionlike_class(self):
-        # We only want to duck type function-like objects,
-        # not classes.
-
-        def func(a,b, *args, kwonly=True, kwonlyreq, **kwargs):
-            pass
-
-        class funclike:
-            def __init__(self, marker):
-                pass
-
-            __name__ = func.__name__
-            __code__ = func.__code__
-            __annotations__ = func.__annotations__
-            __defaults__ = func.__defaults__
-            __kwdefaults__ = func.__kwdefaults__
-
-        self.assertEqual(str(inspect.signature(funclike)), '(marker)')
-
-    def test_signature_on_method(self):
-        class Test:
-            def __init__(*args):
-                pass
-            def m1(self, arg1, arg2=1) -> int:
-                pass
-            def m2(*args):
-                pass
-            def __call__(*, a):
-                pass
-
-        self.assertEqual(self.signature(Test().m1),
-                         ((('arg1', ..., ..., "positional_or_keyword"),
-                           ('arg2', 1, ..., "positional_or_keyword")),
-                          int))
-
-        self.assertEqual(self.signature(Test().m2),
-                         ((('args', ..., ..., "var_positional"),),
-                          ...))
-
-        self.assertEqual(self.signature(Test),
-                         ((('args', ..., ..., "var_positional"),),
-                          ...))
-
-        with self.assertRaisesRegex(ValueError, 'invalid method signature'):
-            self.signature(Test())
-
-    def test_signature_wrapped_bound_method(self):
-        # Issue 24298
-        class Test:
-            def m1(self, arg1, arg2=1) -> int:
-                pass
-        @functools.wraps(Test().m1)
-        def m1d(*args, **kwargs):
-            pass
-        self.assertEqual(self.signature(m1d),
-                         ((('arg1', ..., ..., "positional_or_keyword"),
-                           ('arg2', 1, ..., "positional_or_keyword")),
-                          int))
-
-    def test_signature_on_classmethod(self):
-        class Test:
-            @classmethod
-            def foo(cls, arg1, *, arg2=1):
-                pass
-
-        meth = Test().foo
-        self.assertEqual(self.signature(meth),
-                         ((('arg1', ..., ..., "positional_or_keyword"),
-                           ('arg2', 1, ..., "keyword_only")),
-                          ...))
-
-        meth = Test.foo
-        self.assertEqual(self.signature(meth),
-                         ((('arg1', ..., ..., "positional_or_keyword"),
-                           ('arg2', 1, ..., "keyword_only")),
-                          ...))
-
-    def test_signature_on_staticmethod(self):
-        class Test:
-            @staticmethod
-            def foo(cls, *, arg):
-                pass
-
-        meth = Test().foo
-        self.assertEqual(self.signature(meth),
-                         ((('cls', ..., ..., "positional_or_keyword"),
-                           ('arg', ..., ..., "keyword_only")),
-                          ...))
-
-        meth = Test.foo
-        self.assertEqual(self.signature(meth),
-                         ((('cls', ..., ..., "positional_or_keyword"),
-                           ('arg', ..., ..., "keyword_only")),
-                          ...))
-
-    def test_signature_on_partial(self):
-        from functools import partial
-
-        def test():
-            pass
-
-        self.assertEqual(self.signature(partial(test)), ((), ...))
-
-        with self.assertRaisesRegex(ValueError, "has incorrect arguments"):
-            inspect.signature(partial(test, 1))
-
-        with self.assertRaisesRegex(ValueError, "has incorrect arguments"):
-            inspect.signature(partial(test, a=1))
-
-        def test(a, b, *, c, d):
-            pass
-
-        self.assertEqual(self.signature(partial(test)),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., ..., "positional_or_keyword"),
-                           ('c', ..., ..., "keyword_only"),
-                           ('d', ..., ..., "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, 1)),
-                         ((('b', ..., ..., "positional_or_keyword"),
-                           ('c', ..., ..., "keyword_only"),
-                           ('d', ..., ..., "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, 1, c=2)),
-                         ((('b', ..., ..., "positional_or_keyword"),
-                           ('c', 2, ..., "keyword_only"),
-                           ('d', ..., ..., "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, b=1, c=2)),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', 1, ..., "keyword_only"),
-                           ('c', 2, ..., "keyword_only"),
-                           ('d', ..., ..., "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, 0, b=1, c=2)),
-                         ((('b', 1, ..., "keyword_only"),
-                           ('c', 2, ..., "keyword_only"),
-                           ('d', ..., ..., "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, a=1)),
-                         ((('a', 1, ..., "keyword_only"),
-                           ('b', ..., ..., "keyword_only"),
-                           ('c', ..., ..., "keyword_only"),
-                           ('d', ..., ..., "keyword_only")),
-                          ...))
-
-        def test(a, *args, b, **kwargs):
-            pass
-
-        self.assertEqual(self.signature(partial(test, 1)),
-                         ((('args', ..., ..., "var_positional"),
-                           ('b', ..., ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, a=1)),
-                         ((('a', 1, ..., "keyword_only"),
-                           ('b', ..., ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, 1, 2, 3)),
-                         ((('args', ..., ..., "var_positional"),
-                           ('b', ..., ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, 1, 2, 3, test=True)),
-                         ((('args', ..., ..., "var_positional"),
-                           ('b', ..., ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, 1, 2, 3, test=1, b=0)),
-                         ((('args', ..., ..., "var_positional"),
-                           ('b', 0, ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, b=0)),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('args', ..., ..., "var_positional"),
-                           ('b', 0, ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(partial(test, b=0, test=1)),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('args', ..., ..., "var_positional"),
-                           ('b', 0, ..., "keyword_only"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...))
-
-        def test(a, b, c:int) -> 42:
-            pass
-
-        sig = test.__signature__ = inspect.signature(test)
-
-        self.assertEqual(self.signature(partial(partial(test, 1))),
-                         ((('b', ..., ..., "positional_or_keyword"),
-                           ('c', ..., int, "positional_or_keyword")),
-                          42))
-
-        self.assertEqual(self.signature(partial(partial(test, 1), 2)),
-                         ((('c', ..., int, "positional_or_keyword"),),
-                          42))
-
-        def foo(a):
-            return a
-        _foo = partial(partial(foo, a=10), a=20)
-        self.assertEqual(self.signature(_foo),
-                         ((('a', 20, ..., "keyword_only"),),
-                          ...))
-        # check that we don't have any side-effects in signature(),
-        # and the partial object is still functioning
-        self.assertEqual(_foo(), 20)
-
-        def foo(a, b, c):
-            return a, b, c
-        _foo = partial(partial(foo, 1, b=20), b=30)
-
-        self.assertEqual(self.signature(_foo),
-                         ((('b', 30, ..., "keyword_only"),
-                           ('c', ..., ..., "keyword_only")),
-                          ...))
-        self.assertEqual(_foo(c=10), (1, 30, 10))
-
-        def foo(a, b, c, *, d):
-            return a, b, c, d
-        _foo = partial(partial(foo, d=20, c=20), b=10, d=30)
-        self.assertEqual(self.signature(_foo),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', 10, ..., "keyword_only"),
-                           ('c', 20, ..., "keyword_only"),
-                           ('d', 30, ..., "keyword_only"),
-                           ),
-                          ...))
-        ba = inspect.signature(_foo).bind(a=200, b=11)
-        self.assertEqual(_foo(*ba.args, **ba.kwargs), (200, 11, 20, 30))
-
-        def foo(a=1, b=2, c=3):
-            return a, b, c
-        _foo = partial(foo, c=13) # (a=1, b=2, *, c=13)
-
-        ba = inspect.signature(_foo).bind(a=11)
-        self.assertEqual(_foo(*ba.args, **ba.kwargs), (11, 2, 13))
-
-        ba = inspect.signature(_foo).bind(11, 12)
-        self.assertEqual(_foo(*ba.args, **ba.kwargs), (11, 12, 13))
-
-        ba = inspect.signature(_foo).bind(11, b=12)
-        self.assertEqual(_foo(*ba.args, **ba.kwargs), (11, 12, 13))
-
-        ba = inspect.signature(_foo).bind(b=12)
-        self.assertEqual(_foo(*ba.args, **ba.kwargs), (1, 12, 13))
-
-        _foo = partial(_foo, b=10, c=20)
-        ba = inspect.signature(_foo).bind(12)
-        self.assertEqual(_foo(*ba.args, **ba.kwargs), (12, 10, 20))
-
-
-        def foo(a, b, /, c, d, **kwargs):
-            pass
-        sig = inspect.signature(foo)
-        self.assertEqual(str(sig), '(a, b, /, c, d, **kwargs)')
-
-        self.assertEqual(self.signature(partial(foo, 1)),
-                         ((('b', ..., ..., 'positional_only'),
-                           ('c', ..., ..., 'positional_or_keyword'),
-                           ('d', ..., ..., 'positional_or_keyword'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                         ...))
-
-        self.assertEqual(self.signature(partial(foo, 1, 2)),
-                         ((('c', ..., ..., 'positional_or_keyword'),
-                           ('d', ..., ..., 'positional_or_keyword'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                         ...))
-
-        self.assertEqual(self.signature(partial(foo, 1, 2, 3)),
-                         ((('d', ..., ..., 'positional_or_keyword'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                         ...))
-
-        self.assertEqual(self.signature(partial(foo, 1, 2, c=3)),
-                         ((('c', 3, ..., 'keyword_only'),
-                           ('d', ..., ..., 'keyword_only'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                         ...))
-
-        self.assertEqual(self.signature(partial(foo, 1, c=3)),
-                         ((('b', ..., ..., 'positional_only'),
-                           ('c', 3, ..., 'keyword_only'),
-                           ('d', ..., ..., 'keyword_only'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                         ...))
-
-    def test_signature_on_partialmethod(self):
-        from functools import partialmethod
-
-        class Spam:
-            def test():
-                pass
-            ham = partialmethod(test)
-
-        with self.assertRaisesRegex(ValueError, "has incorrect arguments"):
-            inspect.signature(Spam.ham)
-
-        class Spam:
-            def test(it, a, *, c) -> 'spam':
-                pass
-            ham = partialmethod(test, c=1)
-
-        self.assertEqual(self.signature(Spam.ham, eval_str=False),
-                         ((('it', ..., ..., 'positional_or_keyword'),
-                           ('a', ..., ..., 'positional_or_keyword'),
-                           ('c', 1, ..., 'keyword_only')),
-                          'spam'))
-
-        self.assertEqual(self.signature(Spam().ham, eval_str=False),
-                         ((('a', ..., ..., 'positional_or_keyword'),
-                           ('c', 1, ..., 'keyword_only')),
-                          'spam'))
-
-        class Spam:
-            def test(self: 'anno', x):
-                pass
-
-            g = partialmethod(test, 1)
-
-        self.assertEqual(self.signature(Spam.g, eval_str=False),
-                         ((('self', ..., 'anno', 'positional_or_keyword'),),
-                          ...))
-
-    def test_signature_on_fake_partialmethod(self):
-        def foo(a): pass
-        foo._partialmethod = 'spam'
-        self.assertEqual(str(inspect.signature(foo)), '(a)')
-
-    def test_signature_on_decorated(self):
-        def decorator(func):
-            @functools.wraps(func)
-            def wrapper(*args, **kwargs) -> int:
-                return func(*args, **kwargs)
-            return wrapper
-
-        class Foo:
-            @decorator
-            def bar(self, a, b):
-                pass
-
-        bar = decorator(Foo().bar)
-
-        self.assertEqual(self.signature(Foo.bar),
-                         ((('self', ..., ..., "positional_or_keyword"),
-                           ('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., ..., "positional_or_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(Foo().bar),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., ..., "positional_or_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(Foo.bar, follow_wrapped=False),
-                         ((('args', ..., ..., "var_positional"),
-                           ('kwargs', ..., ..., "var_keyword")),
-                          ...)) # functools.wraps will copy __annotations__
-                                # from "func" to "wrapper", hence no
-                                # return_annotation
-
-        self.assertEqual(self.signature(bar),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., ..., "positional_or_keyword")),
-                          ...))
-
-        # Test that we handle method wrappers correctly
-        def decorator(func):
-            @functools.wraps(func)
-            def wrapper(*args, **kwargs) -> int:
-                return func(42, *args, **kwargs)
-            sig = inspect.signature(func)
-            new_params = tuple(sig.parameters.values())[1:]
-            wrapper.__signature__ = sig.replace(parameters=new_params)
-            return wrapper
-
-        class Foo:
-            @decorator
-            def __call__(self, a, b):
-                pass
-
-        self.assertEqual(self.signature(Foo.__call__),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., ..., "positional_or_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(Foo().__call__),
-                         ((('b', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        # Test we handle __signature__ partway down the wrapper stack
-        def wrapped_foo_call():
-            pass
-        wrapped_foo_call.__wrapped__ = Foo.__call__
-
-        self.assertEqual(self.signature(wrapped_foo_call),
-                         ((('a', ..., ..., "positional_or_keyword"),
-                           ('b', ..., ..., "positional_or_keyword")),
-                          ...))
-
-
-    def test_signature_on_class(self):
-        class C:
-            def __init__(self, a):
-                pass
-
-        self.assertEqual(self.signature(C),
-                         ((('a', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        class CM(type):
-            def __call__(cls, a):
-                pass
-        class C(metaclass=CM):
-            def __init__(self, b):
-                pass
-
-        self.assertEqual(self.signature(C),
-                         ((('a', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        class CM(type):
-            def __new__(mcls, name, bases, dct, *, foo=1):
-                return super().__new__(mcls, name, bases, dct)
-        class C(metaclass=CM):
-            def __init__(self, b):
-                pass
-
-        self.assertEqual(self.signature(C),
-                         ((('b', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        self.assertEqual(self.signature(CM),
-                         ((('name', ..., ..., "positional_or_keyword"),
-                           ('bases', ..., ..., "positional_or_keyword"),
-                           ('dct', ..., ..., "positional_or_keyword"),
-                           ('foo', 1, ..., "keyword_only")),
-                          ...))
-
-        class CMM(type):
-            def __new__(mcls, name, bases, dct, *, foo=1):
-                return super().__new__(mcls, name, bases, dct)
-            def __call__(cls, nm, bs, dt):
-                return type(nm, bs, dt)
-        class CM(type, metaclass=CMM):
-            def __new__(mcls, name, bases, dct, *, bar=2):
-                return super().__new__(mcls, name, bases, dct)
-        class C(metaclass=CM):
-            def __init__(self, b):
-                pass
-
-        self.assertEqual(self.signature(CMM),
-                         ((('name', ..., ..., "positional_or_keyword"),
-                           ('bases', ..., ..., "positional_or_keyword"),
-                           ('dct', ..., ..., "positional_or_keyword"),
-                           ('foo', 1, ..., "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(CM),
-                         ((('nm', ..., ..., "positional_or_keyword"),
-                           ('bs', ..., ..., "positional_or_keyword"),
-                           ('dt', ..., ..., "positional_or_keyword")),
-                          ...))
-
-        self.assertEqual(self.signature(C),
-                         ((('b', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        class CM(type):
-            def __init__(cls, name, bases, dct, *, bar=2):
-                return super().__init__(name, bases, dct)
-        class C(metaclass=CM):
-            def __init__(self, b):
-                pass
-
-        self.assertEqual(self.signature(CM),
-                         ((('name', ..., ..., "positional_or_keyword"),
-                           ('bases', ..., ..., "positional_or_keyword"),
-                           ('dct', ..., ..., "positional_or_keyword"),
-                           ('bar', 2, ..., "keyword_only")),
-                          ...))
-
-    def test_signature_on_subclass(self):
-        class A:
-            def __new__(cls, a=1, *args, **kwargs):
-                return object.__new__(cls)
-        class B(A):
-            def __init__(self, b):
-                pass
-        class C(A):
-            def __new__(cls, a=1, b=2, *args, **kwargs):
-                return object.__new__(cls)
-        class D(A):
-            pass
-
-        self.assertEqual(self.signature(B),
-                         ((('b', ..., ..., "positional_or_keyword"),),
-                          ...))
-        self.assertEqual(self.signature(C),
-                         ((('a', 1, ..., 'positional_or_keyword'),
-                           ('b', 2, ..., 'positional_or_keyword'),
-                           ('args', ..., ..., 'var_positional'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                          ...))
-        self.assertEqual(self.signature(D),
-                         ((('a', 1, ..., 'positional_or_keyword'),
-                           ('args', ..., ..., 'var_positional'),
-                           ('kwargs', ..., ..., 'var_keyword')),
-                          ...))
-
-    def test_signature_on_generic_subclass(self):
-        from typing import Generic, TypeVar
-
-        T = TypeVar('T')
-
-        class A(Generic[T]):
-            def __init__(self, *, a: int) -> None:
-                pass
-
-        self.assertEqual(self.signature(A),
-                         ((('a', ..., int, 'keyword_only'),),
-                          None))
-
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_signature_on_class_without_init(self):
-        # Test classes without user-defined __init__ or __new__
-        class C: pass
-        self.assertEqual(str(inspect.signature(C)), '()')
-        class D(C): pass
-        self.assertEqual(str(inspect.signature(D)), '()')
-
-        # Test meta-classes without user-defined __init__ or __new__
-        class C(type): pass
-        class D(C): pass
-        with self.assertRaisesRegex(ValueError, "callable.*is not supported"):
-            self.assertEqual(inspect.signature(C), None)
-        with self.assertRaisesRegex(ValueError, "callable.*is not supported"):
-            self.assertEqual(inspect.signature(D), None)
-
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_signature_on_builtin_class(self):
-        expected = ('(file, protocol=None, fix_imports=True, '
-                    'buffer_callback=None)')
-        self.assertEqual(str(inspect.signature(_pickle.Pickler)), expected)
-
-        class P(_pickle.Pickler): pass
-        class EmptyTrait: pass
-        class P2(EmptyTrait, P): pass
-        self.assertEqual(str(inspect.signature(P)), expected)
-        self.assertEqual(str(inspect.signature(P2)), expected)
-
-        class P3(P2):
-            def __init__(self, spam):
-                pass
-        self.assertEqual(str(inspect.signature(P3)), '(spam)')
-
-        class MetaP(type):
-            def __call__(cls, foo, bar):
-                pass
-        class P4(P2, metaclass=MetaP):
-            pass
-        self.assertEqual(str(inspect.signature(P4)), '(foo, bar)')
-
-    def test_signature_on_callable_objects(self):
-        class Foo:
-            def __call__(self, a):
-                pass
-
-        self.assertEqual(self.signature(Foo()),
-                         ((('a', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        class Spam:
-            pass
-        with self.assertRaisesRegex(TypeError, "is not a callable object"):
-            inspect.signature(Spam())
-
-        class Bar(Spam, Foo):
-            pass
-
-        self.assertEqual(self.signature(Bar()),
-                         ((('a', ..., ..., "positional_or_keyword"),),
-                          ...))
-
-        class Wrapped:
-            pass
-        Wrapped.__wrapped__ = lambda a: None
-        self.assertEqual(self.signature(Wrapped),
-                         ((('a', ..., ..., "positional_or_keyword"),),
-                          ...))
-        # wrapper loop:
-        Wrapped.__wrapped__ = Wrapped
-        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
-            self.signature(Wrapped)
-
-    def test_signature_on_lambdas(self):
-        self.assertEqual(self.signature((lambda a=10: a)),
-                         ((('a', 10, ..., "positional_or_keyword"),),
-                          ...))
-
-    def test_signature_on_mocks(self):
-        # https://github.com/python/cpython/issues/96127
-        for mock in (
-            unittest.mock.Mock(),
-            unittest.mock.AsyncMock(),
-            unittest.mock.MagicMock(),
-        ):
-            with self.subTest(mock=mock):
-                self.assertEqual(str(inspect.signature(mock)), '(*args, **kwargs)')
-
-    def test_signature_on_noncallable_mocks(self):
-        for mock in (
-            unittest.mock.NonCallableMock(),
-            unittest.mock.NonCallableMagicMock(),
-        ):
-            with self.subTest(mock=mock):
-                with self.assertRaises(TypeError):
-                    inspect.signature(mock)
-
-    def test_signature_equality(self):
-        def foo(a, *, b:int) -> float: pass
-        self.assertFalse(inspect.signature(foo) == 42)
-        self.assertTrue(inspect.signature(foo) != 42)
-        self.assertTrue(inspect.signature(foo) == ALWAYS_EQ)
-        self.assertFalse(inspect.signature(foo) != ALWAYS_EQ)
-
-        def bar(a, *, b:int) -> float: pass
-        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
-        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
-        self.assertEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def bar(a, *, b:int) -> int: pass
-        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def bar(a, *, b:int): pass
-        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def bar(a, *, b:int=42) -> float: pass
-        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def bar(a, *, c) -> float: pass
-        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def bar(a, b:int) -> float: pass
-        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-        def spam(b:int, a) -> float: pass
-        self.assertFalse(inspect.signature(spam) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(spam) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(spam)), hash(inspect.signature(bar)))
-
-        def foo(*, a, b, c): pass
-        def bar(*, c, b, a): pass
-        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
-        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
-        self.assertEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def foo(*, a=1, b, c): pass
-        def bar(*, c, b, a=1): pass
-        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
-        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
-        self.assertEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def foo(pos, *, a=1, b, c): pass
-        def bar(pos, *, c, b, a=1): pass
-        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
-        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
-        self.assertEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def foo(pos, *, a, b, c): pass
-        def bar(pos, *, c, b, a=1): pass
-        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
-        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
-        self.assertNotEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-        def foo(pos, *args, a=42, b, c, **kwargs:int): pass
-        def bar(pos, *args, c, b, a=42, **kwargs:int): pass
-        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
-        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
-        self.assertEqual(
-            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
-
-    def test_signature_hashable(self):
-        S = inspect.Signature
-        P = inspect.Parameter
-
-        def foo(a): pass
-        foo_sig = inspect.signature(foo)
-
-        manual_sig = S(parameters=[P('a', P.POSITIONAL_OR_KEYWORD)])
-
-        self.assertEqual(hash(foo_sig), hash(manual_sig))
-        self.assertNotEqual(hash(foo_sig),
-                            hash(manual_sig.replace(return_annotation='spam')))
-
-        def bar(a) -> 1: pass
-        self.assertNotEqual(hash(foo_sig), hash(inspect.signature(bar)))
-
-        def foo(a={}): pass
-        with self.assertRaisesRegex(TypeError, 'unhashable type'):
-            hash(inspect.signature(foo))
-
-        def foo(a) -> {}: pass
-        with self.assertRaisesRegex(TypeError, 'unhashable type'):
-            hash(inspect.signature(foo))
-
-    def test_signature_str(self):
-        def foo(a:int=1, *, b, c=None, **kwargs) -> 42:
-            pass
-        self.assertEqual(str(inspect.signature(foo)),
-                         '(a: int = 1, *, b, c=None, **kwargs) -> 42')
-
-        def foo(a:int=1, *args, b, c=None, **kwargs) -> 42:
-            pass
-        self.assertEqual(str(inspect.signature(foo)),
-                         '(a: int = 1, *args, b, c=None, **kwargs) -> 42')
-
-        def foo():
-            pass
-        self.assertEqual(str(inspect.signature(foo)), '()')
-
-        def foo(a: list[str]) -> tuple[str, float]:
-            pass
-        self.assertEqual(str(inspect.signature(foo)),
-                         '(a: list[str]) -> tuple[str, float]')
-
-        from typing import Tuple
-        def foo(a: list[str]) -> Tuple[str, float]:
-            pass
-        self.assertEqual(str(inspect.signature(foo)),
-                         '(a: list[str]) -> Tuple[str, float]')
-
-    def test_signature_str_positional_only(self):
-        P = inspect.Parameter
-        S = inspect.Signature
-
-        def test(a_po, /, *, b, **kwargs):
-            return a_po, kwargs
-
-        self.assertEqual(str(inspect.signature(test)),
-                         '(a_po, /, *, b, **kwargs)')
-
-        self.assertEqual(str(S(parameters=[P('foo', P.POSITIONAL_ONLY)])),
-                         '(foo, /)')
-
-        self.assertEqual(str(S(parameters=[
-                                P('foo', P.POSITIONAL_ONLY),
-                                P('bar', P.VAR_KEYWORD)])),
-                         '(foo, /, **bar)')
-
-        self.assertEqual(str(S(parameters=[
-                                P('foo', P.POSITIONAL_ONLY),
-                                P('bar', P.VAR_POSITIONAL)])),
-                         '(foo, /, *bar)')
-
-    def test_signature_replace_anno(self):
-        def test() -> 42:
-            pass
-
-        sig = inspect.signature(test)
-        sig = sig.replace(return_annotation=None)
-        self.assertIs(sig.return_annotation, None)
-        sig = sig.replace(return_annotation=sig.empty)
-        self.assertIs(sig.return_annotation, sig.empty)
-        sig = sig.replace(return_annotation=42)
-        self.assertEqual(sig.return_annotation, 42)
-        self.assertEqual(sig, inspect.signature(test))
-
-    def test_signature_replaced(self):
-        def test():
-            pass
-
-        spam_param = inspect.Parameter('spam', inspect.Parameter.POSITIONAL_ONLY)
-        sig = test.__signature__ = inspect.Signature(parameters=(spam_param,))
-        self.assertEqual(sig, inspect.signature(test))
-
-    def test_signature_on_mangled_parameters(self):
-        class Spam:
-            def foo(self, __p1:1=2, *, __p2:2=3):
-                pass
-        class Ham(Spam):
-            pass
-
-        self.assertEqual(self.signature(Spam.foo),
-                         ((('self', ..., ..., "positional_or_keyword"),
-                           ('_Spam__p1', 2, 1, "positional_or_keyword"),
-                           ('_Spam__p2', 3, 2, "keyword_only")),
-                          ...))
-
-        self.assertEqual(self.signature(Spam.foo),
-                         self.signature(Ham.foo))
-
-    def test_signature_from_callable_python_obj(self):
-        class MySignature(inspect.Signature): pass
-        def foo(a, *, b:1): pass
-        foo_sig = MySignature.from_callable(foo)
-        self.assertIsInstance(foo_sig, MySignature)
-
-    def test_signature_from_callable_class(self):
-        # A regression test for a class inheriting its signature from `object`.
-        class MySignature(inspect.Signature): pass
-        class foo: pass
-        foo_sig = MySignature.from_callable(foo)
-        self.assertIsInstance(foo_sig, MySignature)
-
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_signature_from_callable_builtin_obj(self):
-        class MySignature(inspect.Signature): pass
-        sig = MySignature.from_callable(_pickle.Pickler)
-        self.assertIsInstance(sig, MySignature)
-
-    def test_signature_definition_order_preserved_on_kwonly(self):
-        for fn in signatures_with_lexicographic_keyword_only_parameters():
-            signature = inspect.signature(fn)
-            l = list(signature.parameters)
-            sorted_l = sorted(l)
-            self.assertTrue(l)
-            self.assertEqual(l, sorted_l)
-        signature = inspect.signature(unsorted_keyword_only_parameters_fn)
-        l = list(signature.parameters)
-        self.assertEqual(l, unsorted_keyword_only_parameters)
-
-    def test_signater_parameters_is_ordered(self):
-        p1 = inspect.signature(lambda x, y: None).parameters
-        p2 = inspect.signature(lambda y, x: None).parameters
-        self.assertNotEqual(p1, p2)
-
-    def test_signature_annotations_with_local_namespaces(self):
-        class Foo: ...
-        def func(foo: Foo) -> int: pass
-        def func2(foo: Foo, bar: 'Bar') -> int: pass
-
-        for signature_func in (inspect.signature, inspect.Signature.from_callable):
-            with self.subTest(signature_func = signature_func):
-                sig1 = signature_func(func)
-                self.assertEqual(sig1.return_annotation, int)
-                self.assertEqual(sig1.parameters['foo'].annotation, Foo)
-
-                sig2 = signature_func(func, locals=locals())
-                self.assertEqual(sig2.return_annotation, int)
-                self.assertEqual(sig2.parameters['foo'].annotation, Foo)
-
-                sig3 = signature_func(func2, globals={'Bar': int}, locals=locals())
-                self.assertEqual(sig3.return_annotation, int)
-                self.assertEqual(sig3.parameters['foo'].annotation, Foo)
-                self.assertEqual(sig3.parameters['bar'].annotation, 'Bar')
-
-    def test_signature_eval_str(self):
-        isa = inspect_stringized_annotations
-        sig = inspect.Signature
-        par = inspect.Parameter
-        PORK = inspect.Parameter.POSITIONAL_OR_KEYWORD
-        for signature_func in (inspect.signature, inspect.Signature.from_callable):
-            with self.subTest(signature_func = signature_func):
-                self.assertEqual(
-                    signature_func(isa.MyClass),
-                    sig(
-                        parameters=(
-                            par('a', PORK),
-                            par('b', PORK),
-                        )))
-                self.assertEqual(
-                    signature_func(isa.function),
-                    sig(
-                        return_annotation='MyClass',
-                        parameters=(
-                            par('a', PORK, annotation='int'),
-                            par('b', PORK, annotation='str'),
-                        )))
-                self.assertEqual(
-                    signature_func(isa.function2),
-                    sig(
-                        return_annotation='MyClass',
-                        parameters=(
-                            par('a', PORK, annotation='int'),
-                            par('b', PORK, annotation="'str'"),
-                            par('c', PORK, annotation="MyClass"),
-                        )))
-                self.assertEqual(
-                    signature_func(isa.function3),
-                    sig(
-                        parameters=(
-                            par('a', PORK, annotation="'int'"),
-                            par('b', PORK, annotation="'str'"),
-                            par('c', PORK, annotation="'MyClass'"),
-                        )))
-
-                self.assertEqual(signature_func(isa.UnannotatedClass), sig())
-                self.assertEqual(signature_func(isa.unannotated_function),
-                    sig(
-                        parameters=(
-                            par('a', PORK),
-                            par('b', PORK),
-                            par('c', PORK),
-                        )))
-
-                self.assertEqual(
-                    signature_func(isa.MyClass, eval_str=True),
-                    sig(
-                        parameters=(
-                            par('a', PORK),
-                            par('b', PORK),
-                        )))
-                self.assertEqual(
-                    signature_func(isa.function, eval_str=True),
-                    sig(
-                        return_annotation=isa.MyClass,
-                        parameters=(
-                            par('a', PORK, annotation=int),
-                            par('b', PORK, annotation=str),
-                        )))
-                self.assertEqual(
-                    signature_func(isa.function2, eval_str=True),
-                    sig(
-                        return_annotation=isa.MyClass,
-                        parameters=(
-                            par('a', PORK, annotation=int),
-                            par('b', PORK, annotation='str'),
-                            par('c', PORK, annotation=isa.MyClass),
-                        )))
-                self.assertEqual(
-                    signature_func(isa.function3, eval_str=True),
-                    sig(
-                        parameters=(
-                            par('a', PORK, annotation='int'),
-                            par('b', PORK, annotation='str'),
-                            par('c', PORK, annotation='MyClass'),
-                        )))
-
-                globalns = {'int': float, 'str': complex}
-                localns = {'str': tuple, 'MyClass': dict}
-                with self.assertRaises(NameError):
-                    signature_func(isa.function, eval_str=True, globals=globalns)
-
-                self.assertEqual(
-                    signature_func(isa.function, eval_str=True, locals=localns),
-                    sig(
-                        return_annotation=dict,
-                        parameters=(
-                            par('a', PORK, annotation=int),
-                            par('b', PORK, annotation=tuple),
-                        )))
-
-                self.assertEqual(
-                    signature_func(isa.function, eval_str=True, globals=globalns, locals=localns),
-                    sig(
-                        return_annotation=dict,
-                        parameters=(
-                            par('a', PORK, annotation=float),
-                            par('b', PORK, annotation=tuple),
-                        )))
-
-    def test_signature_none_annotation(self):
-        class funclike:
-            # Has to be callable, and have correct
-            # __code__, __annotations__, __defaults__, __name__,
-            # and __kwdefaults__ attributes
-
-            def __init__(self, func):
-                self.__name__ = func.__name__
-                self.__code__ = func.__code__
-                self.__annotations__ = func.__annotations__
-                self.__defaults__ = func.__defaults__
-                self.__kwdefaults__ = func.__kwdefaults__
-                self.func = func
-
-            def __call__(self, *args, **kwargs):
-                return self.func(*args, **kwargs)
-
-        def foo(): pass
-        foo = funclike(foo)
-        foo.__annotations__ = None
-        for signature_func in (inspect.signature, inspect.Signature.from_callable):
-            with self.subTest(signature_func = signature_func):
-                self.assertEqual(signature_func(foo), inspect.Signature())
-        self.assertEqual(inspect.get_annotations(foo), {})
-
-    def test_signature_as_str(self):
-        self.maxDiff = None
-        class S:
-            __signature__ = '(a, b=2)'
-
-        self.assertEqual(self.signature(S),
-                         ((('a', ..., ..., 'positional_or_keyword'),
-                           ('b', 2, ..., 'positional_or_keyword')),
-                          ...))
-
-    def test_signature_as_callable(self):
-        # __signature__ should be either a staticmethod or a bound classmethod
-        class S:
-            @classmethod
-            def __signature__(cls):
-                return '(a, b=2)'
-
-        self.assertEqual(self.signature(S),
-                         ((('a', ..., ..., 'positional_or_keyword'),
-                           ('b', 2, ..., 'positional_or_keyword')),
-                          ...))
-
-        class S:
-            @staticmethod
-            def __signature__():
-                return '(a, b=2)'
-
-        self.assertEqual(self.signature(S),
-                         ((('a', ..., ..., 'positional_or_keyword'),
-                           ('b', 2, ..., 'positional_or_keyword')),
-                          ...))
-
-    def test_signature_on_derived_classes(self):
-        # gh-105080: Make sure that signatures are consistent on derived classes
-
-        class B:
-            def __new__(self, *args, **kwargs):
-                return super().__new__(self)
-            def __init__(self, value):
-                self.value = value
-
-        class D1(B):
-            def __init__(self, value):
-                super().__init__(value)
-
-        class D2(D1):
-            pass
-
-        self.assertEqual(inspect.signature(D2), inspect.signature(D1))
-
-
-class TestParameterObject(unittest.TestCase):
-    def test_signature_parameter_kinds(self):
-        P = inspect.Parameter
-        self.assertTrue(P.POSITIONAL_ONLY < P.POSITIONAL_OR_KEYWORD < \
-                        P.VAR_POSITIONAL < P.KEYWORD_ONLY < P.VAR_KEYWORD)
-
-        self.assertEqual(str(P.POSITIONAL_ONLY), 'POSITIONAL_ONLY')
-        self.assertTrue('POSITIONAL_ONLY' in repr(P.POSITIONAL_ONLY))
-
-    def test_signature_parameter_object(self):
-        p = inspect.Parameter('foo', default=10,
-                              kind=inspect.Parameter.POSITIONAL_ONLY)
-        self.assertEqual(p.name, 'foo')
-        self.assertEqual(p.default, 10)
-        self.assertIs(p.annotation, p.empty)
-        self.assertEqual(p.kind, inspect.Parameter.POSITIONAL_ONLY)
-
-        with self.assertRaisesRegex(ValueError, "value '123' is "
-                                    "not a valid Parameter.kind"):
-            inspect.Parameter('foo', default=10, kind='123')
-
-        with self.assertRaisesRegex(ValueError, 'not a valid parameter name'):
-            inspect.Parameter('1', kind=inspect.Parameter.VAR_KEYWORD)
-
-        with self.assertRaisesRegex(ValueError, 'not a valid parameter name'):
-            inspect.Parameter('from', kind=inspect.Parameter.VAR_KEYWORD)
-
-        with self.assertRaisesRegex(TypeError, 'name must be a str'):
-            inspect.Parameter(None, kind=inspect.Parameter.VAR_KEYWORD)
-
-        with self.assertRaisesRegex(ValueError,
-                                    'is not a valid parameter name'):
-            inspect.Parameter('$', kind=inspect.Parameter.VAR_KEYWORD)
-
-        with self.assertRaisesRegex(ValueError,
-                                    'is not a valid parameter name'):
-            inspect.Parameter('.a', kind=inspect.Parameter.VAR_KEYWORD)
-
-        with self.assertRaisesRegex(ValueError, 'cannot have default values'):
-            inspect.Parameter('a', default=42,
-                              kind=inspect.Parameter.VAR_KEYWORD)
-
-        with self.assertRaisesRegex(ValueError, 'cannot have default values'):
-            inspect.Parameter('a', default=42,
-                              kind=inspect.Parameter.VAR_POSITIONAL)
-
-        p = inspect.Parameter('a', default=42,
-                              kind=inspect.Parameter.POSITIONAL_OR_KEYWORD)
-        with self.assertRaisesRegex(ValueError, 'cannot have default values'):
-            p.replace(kind=inspect.Parameter.VAR_POSITIONAL)
-
-        self.assertTrue(repr(p).startswith('<Parameter'))
-        self.assertTrue('"a=42"' in repr(p))
-
-    def test_signature_parameter_hashable(self):
-        P = inspect.Parameter
-        foo = P('foo', kind=P.POSITIONAL_ONLY)
-        self.assertEqual(hash(foo), hash(P('foo', kind=P.POSITIONAL_ONLY)))
-        self.assertNotEqual(hash(foo), hash(P('foo', kind=P.POSITIONAL_ONLY,
-                                              default=42)))
-        self.assertNotEqual(hash(foo),
-                            hash(foo.replace(kind=P.VAR_POSITIONAL)))
-
-    def test_signature_parameter_equality(self):
-        P = inspect.Parameter
-        p = P('foo', default=42, kind=inspect.Parameter.KEYWORD_ONLY)
-
-        self.assertTrue(p == p)
-        self.assertFalse(p != p)
-        self.assertFalse(p == 42)
-        self.assertTrue(p != 42)
-        self.assertTrue(p == ALWAYS_EQ)
-        self.assertFalse(p != ALWAYS_EQ)
-
-        self.assertTrue(p == P('foo', default=42,
-                               kind=inspect.Parameter.KEYWORD_ONLY))
-        self.assertFalse(p != P('foo', default=42,
-                                kind=inspect.Parameter.KEYWORD_ONLY))
-
-    def test_signature_parameter_replace(self):
-        p = inspect.Parameter('foo', default=42,
-                              kind=inspect.Parameter.KEYWORD_ONLY)
-
-        self.assertIsNot(p, p.replace())
-        self.assertEqual(p, p.replace())
-
-        p2 = p.replace(annotation=1)
-        self.assertEqual(p2.annotation, 1)
-        p2 = p2.replace(annotation=p2.empty)
-        self.assertEqual(p, p2)
-
-        p2 = p2.replace(name='bar')
-        self.assertEqual(p2.name, 'bar')
-        self.assertNotEqual(p2, p)
-
-        with self.assertRaisesRegex(ValueError,
-                                    'name is a required attribute'):
-            p2 = p2.replace(name=p2.empty)
-
-        p2 = p2.replace(name='foo', default=None)
-        self.assertIs(p2.default, None)
-        self.assertNotEqual(p2, p)
-
-        p2 = p2.replace(name='foo', default=p2.empty)
-        self.assertIs(p2.default, p2.empty)
-
-
-        p2 = p2.replace(default=42, kind=p2.POSITIONAL_OR_KEYWORD)
-        self.assertEqual(p2.kind, p2.POSITIONAL_OR_KEYWORD)
-        self.assertNotEqual(p2, p)
-
-        with self.assertRaisesRegex(ValueError,
-                                    "value <class 'inspect._empty'> "
-                                    "is not a valid Parameter.kind"):
-            p2 = p2.replace(kind=p2.empty)
-
-        p2 = p2.replace(kind=p2.KEYWORD_ONLY)
-        self.assertEqual(p2, p)
-
-    def test_signature_parameter_positional_only(self):
-        with self.assertRaisesRegex(TypeError, 'name must be a str'):
-            inspect.Parameter(None, kind=inspect.Parameter.POSITIONAL_ONLY)
-
-    @cpython_only
-    def test_signature_parameter_implicit(self):
-        with self.assertRaisesRegex(ValueError,
-                                    'implicit arguments must be passed as '
-                                    'positional or keyword arguments, '
-                                    'not positional-only'):
-            inspect.Parameter('.0', kind=inspect.Parameter.POSITIONAL_ONLY)
-
-        param = inspect.Parameter(
-            '.0', kind=inspect.Parameter.POSITIONAL_OR_KEYWORD)
-        self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_ONLY)
-        self.assertEqual(param.name, 'implicit0')
-
-    def test_signature_parameter_immutability(self):
-        p = inspect.Parameter('spam', kind=inspect.Parameter.KEYWORD_ONLY)
-
-        with self.assertRaises(AttributeError):
-            p.foo = 'bar'
-
-        with self.assertRaises(AttributeError):
-            p.kind = 123
-
-
-class TestSignatureBind(unittest.TestCase):
-    @staticmethod
-    def call(func, *args, **kwargs):
-        sig = inspect.signature(func)
-        ba = sig.bind(*args, **kwargs)
-        return func(*ba.args, **ba.kwargs)
-
-    def test_signature_bind_empty(self):
-        def test():
-            return 42
-
-        self.assertEqual(self.call(test), 42)
-        with self.assertRaisesRegex(TypeError, 'too many positional arguments'):
-            self.call(test, 1)
-        with self.assertRaisesRegex(TypeError, 'too many positional arguments'):
-            self.call(test, 1, spam=10)
-        with self.assertRaisesRegex(
-            TypeError, "got an unexpected keyword argument 'spam'"):
-
-            self.call(test, spam=1)
-
-    def test_signature_bind_var(self):
-        def test(*args, **kwargs):
-            return args, kwargs
-
-        self.assertEqual(self.call(test), ((), {}))
-        self.assertEqual(self.call(test, 1), ((1,), {}))
-        self.assertEqual(self.call(test, 1, 2), ((1, 2), {}))
-        self.assertEqual(self.call(test, foo='bar'), ((), {'foo': 'bar'}))
-        self.assertEqual(self.call(test, 1, foo='bar'), ((1,), {'foo': 'bar'}))
-        self.assertEqual(self.call(test, args=10), ((), {'args': 10}))
-        self.assertEqual(self.call(test, 1, 2, foo='bar'),
-                         ((1, 2), {'foo': 'bar'}))
-
-    def test_signature_bind_just_args(self):
-        def test(a, b, c):
-            return a, b, c
-
-        self.assertEqual(self.call(test, 1, 2, 3), (1, 2, 3))
-
-        with self.assertRaisesRegex(TypeError, 'too many positional arguments'):
-            self.call(test, 1, 2, 3, 4)
-
-        with self.assertRaisesRegex(TypeError,
-                                    "missing a required argument: 'b'"):
-            self.call(test, 1)
-
-        with self.assertRaisesRegex(TypeError,
-                                    "missing a required argument: 'a'"):
-            self.call(test)
-
-        def test(a, b, c=10):
-            return a, b, c
-        self.assertEqual(self.call(test, 1, 2, 3), (1, 2, 3))
-        self.assertEqual(self.call(test, 1, 2), (1, 2, 10))
-
-        def test(a=1, b=2, c=3):
-            return a, b, c
-        self.assertEqual(self.call(test, a=10, c=13), (10, 2, 13))
-        self.assertEqual(self.call(test, a=10), (10, 2, 3))
-        self.assertEqual(self.call(test, b=10), (1, 10, 3))
-
-    def test_signature_bind_varargs_order(self):
-        def test(*args):
-            return args
-
-        self.assertEqual(self.call(test), ())
-        self.assertEqual(self.call(test, 1, 2, 3), (1, 2, 3))
-
-    def test_signature_bind_args_and_varargs(self):
-        def test(a, b, c=3, *args):
-            return a, b, c, args
-
-        self.assertEqual(self.call(test, 1, 2, 3, 4, 5), (1, 2, 3, (4, 5)))
-        self.assertEqual(self.call(test, 1, 2), (1, 2, 3, ()))
-        self.assertEqual(self.call(test, b=1, a=2), (2, 1, 3, ()))
-        self.assertEqual(self.call(test, 1, b=2), (1, 2, 3, ()))
-
-        with self.assertRaisesRegex(TypeError,
-                                     "multiple values for argument 'c'"):
-            self.call(test, 1, 2, 3, c=4)
-
-    def test_signature_bind_just_kwargs(self):
-        def test(**kwargs):
-            return kwargs
-
-        self.assertEqual(self.call(test), {})
-        self.assertEqual(self.call(test, foo='bar', spam='ham'),
-                         {'foo': 'bar', 'spam': 'ham'})
-
-    def test_signature_bind_args_and_kwargs(self):
-        def test(a, b, c=3, **kwargs):
-            return a, b, c, kwargs
-
-        self.assertEqual(self.call(test, 1, 2), (1, 2, 3, {}))
-        self.assertEqual(self.call(test, 1, 2, foo='bar', spam='ham'),
-                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
-        self.assertEqual(self.call(test, b=2, a=1, foo='bar', spam='ham'),
-                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
-        self.assertEqual(self.call(test, a=1, b=2, foo='bar', spam='ham'),
-                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
-        self.assertEqual(self.call(test, 1, b=2, foo='bar', spam='ham'),
-                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
-        self.assertEqual(self.call(test, 1, b=2, c=4, foo='bar', spam='ham'),
-                         (1, 2, 4, {'foo': 'bar', 'spam': 'ham'}))
-        self.assertEqual(self.call(test, 1, 2, 4, foo='bar'),
-                         (1, 2, 4, {'foo': 'bar'}))
-        self.assertEqual(self.call(test, c=5, a=4, b=3),
-                         (4, 3, 5, {}))
-
-    def test_signature_bind_kwonly(self):
-        def test(*, foo):
-            return foo
-        with self.assertRaisesRegex(TypeError,
-                                     'too many positional arguments'):
-            self.call(test, 1)
-        self.assertEqual(self.call(test, foo=1), 1)
-
-        def test(a, *, foo=1, bar):
-            return foo
-        with self.assertRaisesRegex(TypeError,
-                                     "missing a required argument: 'bar'"):
-            self.call(test, 1)
-
-        def test(foo, *, bar):
-            return foo, bar
-        self.assertEqual(self.call(test, 1, bar=2), (1, 2))
-        self.assertEqual(self.call(test, bar=2, foo=1), (1, 2))
-
-        with self.assertRaisesRegex(
-            TypeError, "got an unexpected keyword argument 'spam'"):
-
-            self.call(test, bar=2, foo=1, spam=10)
-
-        with self.assertRaisesRegex(TypeError,
-                                     'too many positional arguments'):
-            self.call(test, 1, 2)
-
-        with self.assertRaisesRegex(TypeError,
-                                     'too many positional arguments'):
-            self.call(test, 1, 2, bar=2)
-
-        with self.assertRaisesRegex(
-            TypeError, "got an unexpected keyword argument 'spam'"):
-
-            self.call(test, 1, bar=2, spam='ham')
-
-        with self.assertRaisesRegex(TypeError,
-                                     "missing a required keyword-only "
-                                     "argument: 'bar'"):
-            self.call(test, 1)
-
-        def test(foo, *, bar, **bin):
-            return foo, bar, bin
-        self.assertEqual(self.call(test, 1, bar=2), (1, 2, {}))
-        self.assertEqual(self.call(test, foo=1, bar=2), (1, 2, {}))
-        self.assertEqual(self.call(test, 1, bar=2, spam='ham'),
-                         (1, 2, {'spam': 'ham'}))
-        self.assertEqual(self.call(test, spam='ham', foo=1, bar=2),
-                         (1, 2, {'spam': 'ham'}))
-        with self.assertRaisesRegex(TypeError,
-                                    "missing a required argument: 'foo'"):
-            self.call(test, spam='ham', bar=2)
-        self.assertEqual(self.call(test, 1, bar=2, bin=1, spam=10),
-                         (1, 2, {'bin': 1, 'spam': 10}))
-
-    def test_signature_bind_arguments(self):
-        def test(a, *args, b, z=100, **kwargs):
-            pass
-        sig = inspect.signature(test)
-        ba = sig.bind(10, 20, b=30, c=40, args=50, kwargs=60)
-        # we won't have 'z' argument in the bound arguments object, as we didn't
-        # pass it to the 'bind'
-        self.assertEqual(tuple(ba.arguments.items()),
-                         (('a', 10), ('args', (20,)), ('b', 30),
-                          ('kwargs', {'c': 40, 'args': 50, 'kwargs': 60})))
-        self.assertEqual(ba.kwargs,
-                         {'b': 30, 'c': 40, 'args': 50, 'kwargs': 60})
-        self.assertEqual(ba.args, (10, 20))
-
-    def test_signature_bind_positional_only(self):
-        def test(a_po, b_po, c_po=3, /, foo=42, *, bar=50, **kwargs):
-            return a_po, b_po, c_po, foo, bar, kwargs
-
-        self.assertEqual(self.call(test, 1, 2, 4, 5, bar=6),
-                         (1, 2, 4, 5, 6, {}))
-
-        self.assertEqual(self.call(test, 1, 2),
-                         (1, 2, 3, 42, 50, {}))
-
-        self.assertEqual(self.call(test, 1, 2, foo=4, bar=5),
-                         (1, 2, 3, 4, 5, {}))
-
-        with self.assertRaisesRegex(TypeError, "but was passed as a keyword"):
-            self.call(test, 1, 2, foo=4, bar=5, c_po=10)
-
-        with self.assertRaisesRegex(TypeError, "parameter is positional only"):
-            self.call(test, 1, 2, c_po=4)
-
-        with self.assertRaisesRegex(TypeError, "parameter is positional only"):
-            self.call(test, a_po=1, b_po=2)
-
-    def test_signature_bind_with_self_arg(self):
-        # Issue #17071: one of the parameters is named "self
-        def test(a, self, b):
-            pass
-        sig = inspect.signature(test)
-        ba = sig.bind(1, 2, 3)
-        self.assertEqual(ba.args, (1, 2, 3))
-        ba = sig.bind(1, self=2, b=3)
-        self.assertEqual(ba.args, (1, 2, 3))
-
-    def test_signature_bind_vararg_name(self):
-        def test(a, *args):
-            return a, args
-        sig = inspect.signature(test)
-
-        with self.assertRaisesRegex(
-            TypeError, "got an unexpected keyword argument 'args'"):
-
-            sig.bind(a=0, args=1)
-
-        def test(*args, **kwargs):
-            return args, kwargs
-        self.assertEqual(self.call(test, args=1), ((), {'args': 1}))
-
-        sig = inspect.signature(test)
-        ba = sig.bind(args=1)
-        self.assertEqual(ba.arguments, {'kwargs': {'args': 1}})
-
-    @cpython_only
-    def test_signature_bind_implicit_arg(self):
-        # Issue #19611: getcallargs should work with comprehensions
-        def make_set():
-            return set(z * z for z in range(5))
-        gencomp_code = make_set.__code__.co_consts[1]
-        gencomp_func = types.FunctionType(gencomp_code, {})
-
-        iterator = iter(range(5))
-        self.assertEqual(set(self.call(gencomp_func, iterator)), {0, 1, 4, 9, 16})
-
-    def test_signature_bind_posonly_kwargs(self):
-        def foo(bar, /, **kwargs):
-            return bar, kwargs.get(bar)
-
-        sig = inspect.signature(foo)
-        result = sig.bind("pos-only", bar="keyword")
-
-        self.assertEqual(result.kwargs, {"bar": "keyword"})
-        self.assertIn(("bar", "pos-only"), result.arguments.items())
-
-
-class TestBoundArguments(unittest.TestCase):
-    def test_signature_bound_arguments_unhashable(self):
-        def foo(a): pass
-        ba = inspect.signature(foo).bind(1)
-
-        with self.assertRaisesRegex(TypeError, 'unhashable type'):
-            hash(ba)
-
-    def test_signature_bound_arguments_equality(self):
-        def foo(a): pass
-        ba = inspect.signature(foo).bind(1)
-        self.assertTrue(ba == ba)
-        self.assertFalse(ba != ba)
-        self.assertTrue(ba == ALWAYS_EQ)
-        self.assertFalse(ba != ALWAYS_EQ)
-
-        ba2 = inspect.signature(foo).bind(1)
-        self.assertTrue(ba == ba2)
-        self.assertFalse(ba != ba2)
-
-        ba3 = inspect.signature(foo).bind(2)
-        self.assertFalse(ba == ba3)
-        self.assertTrue(ba != ba3)
-        ba3.arguments['a'] = 1
-        self.assertTrue(ba == ba3)
-        self.assertFalse(ba != ba3)
-
-        def bar(b): pass
-        ba4 = inspect.signature(bar).bind(1)
-        self.assertFalse(ba == ba4)
-        self.assertTrue(ba != ba4)
-
-        def foo(*, a, b): pass
-        sig = inspect.signature(foo)
-        ba1 = sig.bind(a=1, b=2)
-        ba2 = sig.bind(b=2, a=1)
-        self.assertTrue(ba1 == ba2)
-        self.assertFalse(ba1 != ba2)
-
-    def test_signature_bound_arguments_pickle(self):
-        def foo(a, b, *, c:1={}, **kw) -> {42:'ham'}: pass
-        sig = inspect.signature(foo)
-        ba = sig.bind(20, 30, z={})
-
-        for ver in range(pickle.HIGHEST_PROTOCOL + 1):
-            with self.subTest(pickle_ver=ver):
-                ba_pickled = pickle.loads(pickle.dumps(ba, ver))
-                self.assertEqual(ba, ba_pickled)
-
-    def test_signature_bound_arguments_repr(self):
-        def foo(a, b, *, c:1={}, **kw) -> {42:'ham'}: pass
-        sig = inspect.signature(foo)
-        ba = sig.bind(20, 30, z={})
-        self.assertRegex(repr(ba), r'<BoundArguments \(a=20,.*\}\}\)>')
-
-    def test_signature_bound_arguments_apply_defaults(self):
-        def foo(a, b=1, *args, c:1={}, **kw): pass
-        sig = inspect.signature(foo)
-
-        ba = sig.bind(20)
-        ba.apply_defaults()
-        self.assertEqual(
-            list(ba.arguments.items()),
-            [('a', 20), ('b', 1), ('args', ()), ('c', {}), ('kw', {})])
-
-        # Make sure that we preserve the order:
-        # i.e. 'c' should be *before* 'kw'.
-        ba = sig.bind(10, 20, 30, d=1)
-        ba.apply_defaults()
-        self.assertEqual(
-            list(ba.arguments.items()),
-            [('a', 10), ('b', 20), ('args', (30,)), ('c', {}), ('kw', {'d':1})])
-
-        # Make sure that BoundArguments produced by bind_partial()
-        # are supported.
-        def foo(a, b): pass
-        sig = inspect.signature(foo)
-        ba = sig.bind_partial(20)
-        ba.apply_defaults()
-        self.assertEqual(
-            list(ba.arguments.items()),
-            [('a', 20)])
-
-        # Test no args
-        def foo(): pass
-        sig = inspect.signature(foo)
-        ba = sig.bind()
-        ba.apply_defaults()
-        self.assertEqual(list(ba.arguments.items()), [])
-
-        # Make sure a no-args binding still acquires proper defaults.
-        def foo(a='spam'): pass
-        sig = inspect.signature(foo)
-        ba = sig.bind()
-        ba.apply_defaults()
-        self.assertEqual(list(ba.arguments.items()), [('a', 'spam')])
-
-    def test_signature_bound_arguments_arguments_type(self):
-        def foo(a): pass
-        ba = inspect.signature(foo).bind(1)
-        self.assertIs(type(ba.arguments), dict)
-
-class TestSignaturePrivateHelpers(unittest.TestCase):
-    def _strip_non_python_syntax(self, input,
-        clean_signature, self_parameter):
-        computed_clean_signature, \
-            computed_self_parameter = \
-            inspect._signature_strip_non_python_syntax(input)
-        self.assertEqual(computed_clean_signature, clean_signature)
-        self.assertEqual(computed_self_parameter, self_parameter)
-
-    def test_signature_strip_non_python_syntax(self):
-        self._strip_non_python_syntax(
-            "($module, /, path, mode, *, dir_fd=None, " +
-                "effective_ids=False,\n       follow_symlinks=True)",
-            "(module, /, path, mode, *, dir_fd=None, " +
-                "effective_ids=False, follow_symlinks=True)",
-            0)
-
-        self._strip_non_python_syntax(
-            "($module, word, salt, /)",
-            "(module, word, salt, /)",
-            0)
-
-        self._strip_non_python_syntax(
-            "(x, y=None, z=None, /)",
-            "(x, y=None, z=None, /)",
-            None)
-
-        self._strip_non_python_syntax(
-            "(x, y=None, z=None)",
-            "(x, y=None, z=None)",
-            None)
-
-        self._strip_non_python_syntax(
-            "(x,\n    y=None,\n      z = None  )",
-            "(x, y=None, z=None)",
-            None)
-
-        self._strip_non_python_syntax(
-            "",
-            "",
-            None)
-
-        self._strip_non_python_syntax(
-            None,
-            None,
-            None)
-
-class TestSignatureDefinitions(unittest.TestCase):
-    # This test case provides a home for checking that particular APIs
-    # have signatures available for introspection
-
-    @cpython_only
-    @unittest.skipIf(MISSING_C_DOCSTRINGS,
-                     "Signature information for builtins requires docstrings")
-    def test_builtins_have_signatures(self):
-        # This checks all builtin callables in CPython have signatures
-        # A few have signatures Signature can't yet handle, so we skip those
-        # since they will have to wait until PEP 457 adds the required
-        # introspection support to the inspect module
-        # Some others also haven't been converted yet for various other
-        # reasons, so we also skip those for the time being, but design
-        # the test to fail in order to indicate when it needs to be
-        # updated.
-        no_signature = set()
-        # These need PEP 457 groups
-        needs_groups = {"range", "slice", "dir", "getattr",
-                        "next", "iter", "vars"}
-        no_signature |= needs_groups
-        # These have unrepresentable parameter default values of NULL
-        needs_null = {"anext"}
-        no_signature |= needs_null
-        # These need PEP 457 groups or a signature change to accept None
-        needs_semantic_update = {"round"}
-        no_signature |= needs_semantic_update
-        # These need *args support in Argument Clinic
-        needs_varargs = {"breakpoint", "min", "max", "print",
-                         "__build_class__"}
-        no_signature |= needs_varargs
-        # These simply weren't covered in the initial AC conversion
-        # for builtin callables
-        not_converted_yet = {"open", "__import__"}
-        no_signature |= not_converted_yet
-        # These builtin types are expected to provide introspection info
-        types_with_signatures = set()
-        # Check the signatures we expect to be there
-        ns = vars(builtins)
-        for name, obj in sorted(ns.items()):
-            if not callable(obj):
-                continue
-            # The builtin types haven't been converted to AC yet
-            if isinstance(obj, type) and (name not in types_with_signatures):
-                # Note that this also skips all the exception types
-                no_signature.add(name)
-            if (name in no_signature):
-                # Not yet converted
-                continue
-            with self.subTest(builtin=name):
-                self.assertIsNotNone(inspect.signature(obj))
-        # Check callables that haven't been converted don't claim a signature
-        # This ensures this test will start failing as more signatures are
-        # added, so the affected items can be moved into the scope of the
-        # regression test above
-        for name in no_signature:
-            with self.subTest(builtin=name):
-                self.assertIsNone(obj.__text_signature__)
-
-    def test_python_function_override_signature(self):
-        def func(*args, **kwargs):
-            pass
-        func.__text_signature__ = '($self, a, b=1, *args, c, d=2, **kwargs)'
-        sig = inspect.signature(func)
-        self.assertIsNotNone(sig)
-        self.assertEqual(str(sig), '(self, /, a, b=1, *args, c, d=2, **kwargs)')
-
-        func.__text_signature__ = '($self, a, b=1, /, *args, c, d=2, **kwargs)'
-        sig = inspect.signature(func)
-        self.assertEqual(str(sig), '(self, a, b=1, /, *args, c, d=2, **kwargs)')
-
-        func.__text_signature__ = '(self, a=1+2, b=4-3, c=1 | 3 | 16)'
-        sig = inspect.signature(func)
-        self.assertEqual(str(sig), '(self, a=3, b=1, c=19)')
-
-        func.__text_signature__ = '(self, a=1,\nb=2,\n\n\n   c=3)'
-        sig = inspect.signature(func)
-        self.assertEqual(str(sig), '(self, a=1, b=2, c=3)')
-
-        func.__text_signature__ = '(self, x=does_not_exist)'
-        with self.assertRaises(ValueError):
-            inspect.signature(func)
-        func.__text_signature__ = '(self, x=sys, y=inspect)'
-        with self.assertRaises(ValueError):
-            inspect.signature(func)
-        func.__text_signature__ = '(self, 123)'
-        with self.assertRaises(ValueError):
-            inspect.signature(func)
-
-    def test_base_class_have_text_signature(self):
-        # see issue 43118
-        from test.ann_module7 import BufferedReader
-        class MyBufferedReader(BufferedReader):
-            """buffer reader class."""
-
-        text_signature = BufferedReader.__text_signature__
-        self.assertEqual(text_signature, '(raw, buffer_size=DEFAULT_BUFFER_SIZE)')
-        sig = inspect.signature(MyBufferedReader)
-        self.assertEqual(str(sig), '(raw, buffer_size=8192)')
-
-
-class NTimesUnwrappable:
-    def __init__(self, n):
-        self.n = n
-        self._next = None
-
-    @property
-    def __wrapped__(self):
-        if self.n <= 0:
-            raise Exception("Unwrapped too many times")
-        if self._next is None:
-            self._next = NTimesUnwrappable(self.n - 1)
-        return self._next
-
-class TestUnwrap(unittest.TestCase):
-
-    def test_unwrap_one(self):
-        def func(a, b):
-            return a + b
-        wrapper = functools.lru_cache(maxsize=20)(func)
-        self.assertIs(inspect.unwrap(wrapper), func)
-
-    def test_unwrap_several(self):
-        def func(a, b):
-            return a + b
-        wrapper = func
-        for __ in range(10):
-            @functools.wraps(wrapper)
-            def wrapper():
-                pass
-        self.assertIsNot(wrapper.__wrapped__, func)
-        self.assertIs(inspect.unwrap(wrapper), func)
-
-    def test_stop(self):
-        def func1(a, b):
-            return a + b
-        @functools.wraps(func1)
-        def func2():
-            pass
-        @functools.wraps(func2)
-        def wrapper():
-            pass
-        func2.stop_here = 1
-        unwrapped = inspect.unwrap(wrapper,
-                                   stop=(lambda f: hasattr(f, "stop_here")))
-        self.assertIs(unwrapped, func2)
-
-    def test_cycle(self):
-        def func1(): pass
-        func1.__wrapped__ = func1
-        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
-            inspect.unwrap(func1)
-
-        def func2(): pass
-        func2.__wrapped__ = func1
-        func1.__wrapped__ = func2
-        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
-            inspect.unwrap(func1)
-        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
-            inspect.unwrap(func2)
-
-    def test_unhashable(self):
-        def func(): pass
-        func.__wrapped__ = None
-        class C:
-            __hash__ = None
-            __wrapped__ = func
-        self.assertIsNone(inspect.unwrap(C()))
-
-    def test_recursion_limit(self):
-        obj = NTimesUnwrappable(sys.getrecursionlimit() + 1)
-        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
-            inspect.unwrap(obj)
-
-class TestMain(unittest.TestCase):
-    def test_only_source(self):
-        module = importlib.import_module('unittest')
-        rc, out, err = assert_python_ok('-m', 'inspect',
-                                        'unittest')
-        lines = out.decode().splitlines()
-        # ignore the final newline
-        self.assertEqual(lines[:-1], inspect.getsource(module).splitlines())
-        self.assertEqual(err, b'')
-
-    def test_custom_getattr(self):
-        def foo():
-            pass
-        foo.__signature__ = 42
-        with self.assertRaises(TypeError):
-            inspect.signature(foo)
-
-    @unittest.skipIf(ThreadPoolExecutor is None,
-            'threads required to test __qualname__ for source files')
-    def test_qualname_source(self):
-        rc, out, err = assert_python_ok('-m', 'inspect',
-                                     'concurrent.futures:ThreadPoolExecutor')
-        lines = out.decode().splitlines()
-        # ignore the final newline
-        self.assertEqual(lines[:-1],
-                         inspect.getsource(ThreadPoolExecutor).splitlines())
-        self.assertEqual(err, b'')
-
-    def test_builtins(self):
-        _, out, err = assert_python_failure('-m', 'inspect',
-                                            'sys')
-        lines = err.decode().splitlines()
-        self.assertEqual(lines, ["Can't get info for builtin modules."])
-
-    def test_details(self):
-        module = importlib.import_module('unittest')
-        args = support.optim_args_from_interpreter_flags()
-        rc, out, err = assert_python_ok(*args, '-m', 'inspect',
-                                        'unittest', '--details')
-        output = out.decode()
-        # Just a quick sanity check on the output
-        self.assertIn(module.__spec__.name, output)
-        self.assertIn(module.__name__, output)
-        self.assertIn(module.__spec__.origin, output)
-        self.assertIn(module.__file__, output)
-        self.assertIn(module.__spec__.cached, output)
-        self.assertIn(module.__cached__, output)
-        self.assertEqual(err, b'')
-
-
-class TestReload(unittest.TestCase):
-
-    src_before = textwrap.dedent("""\
-def foo():
-    print("Bla")
-    """)
-
-    src_after = textwrap.dedent("""\
-def foo():
-    print("Oh no!")
-    """)
-
-    def assertInspectEqual(self, path, source):
-        inspected_src = inspect.getsource(source)
-        with open(path, encoding='utf-8') as src:
-            self.assertEqual(
-                src.read().splitlines(True),
-                inspected_src.splitlines(True)
-            )
-
-    def test_getsource_reload(self):
-        # see issue 1218234
-        with _ready_to_import('reload_bug', self.src_before) as (name, path):
-            module = importlib.import_module(name)
-            self.assertInspectEqual(path, module)
-            with open(path, 'w', encoding='utf-8') as src:
-                src.write(self.src_after)
-            self.assertInspectEqual(path, module)
-
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_inspect/__init__.py b/Lib/test/test_inspect/__init__.py
new file mode 100644
index 0000000000..f2a39a3fe2
--- /dev/null
+++ b/Lib/test/test_inspect/__init__.py
@@ -0,0 +1,6 @@
+import os
+from test import support
+
+
+def load_tests(*args):
+    return support.load_package_tests(os.path.dirname(__file__), *args)
diff --git a/Lib/test/test_inspect/inspect_fodder.py b/Lib/test/test_inspect/inspect_fodder.py
new file mode 100644
index 0000000000..60ba7aa783
--- /dev/null
+++ b/Lib/test/test_inspect/inspect_fodder.py
@@ -0,0 +1,120 @@
+# line 1
+'A module docstring.'
+
+import inspect
+# line 5
+
+# line 7
+def spam(a, /, b, c, d=3, e=4, f=5, *g, **h):
+    eggs(b + d, c + f)
+
+# line 11
+def eggs(x, y):
+    "A docstring."
+    global fr, st
+    fr = inspect.currentframe()
+    st = inspect.stack()
+    p = x
+    q = y / 0
+
+# line 20
+class StupidGit:
+    """A longer,
+
+    indented
+
+    docstring."""
+# line 27
+
+    def abuse(self, a, b, c):
+        """Another
+
+\tdocstring
+
+        containing
+
+\ttabs
+\t
+        """
+        self.argue(a, b, c)
+# line 40
+    def argue(self, a, b, c):
+        try:
+            spam(a, b, c)
+        except BaseException as e:
+            self.ex = e
+            self.tr = inspect.trace()
+
+    @property
+    def contradiction(self):
+        'The automatic gainsaying.'
+        pass
+
+# line 53
+class MalodorousPervert(StupidGit):
+    def abuse(self, a, b, c):
+        pass
+
+    @property
+    def contradiction(self):
+        pass
+
+Tit = MalodorousPervert
+
+class ParrotDroppings:
+    pass
+
+class FesteringGob(MalodorousPervert, ParrotDroppings):
+    def abuse(self, a, b, c):
+        pass
+
+    @property
+    def contradiction(self):
+        pass
+
+async def lobbest(grenade):
+    pass
+
+currentframe = inspect.currentframe()
+try:
+    raise Exception()
+except BaseException as e:
+    tb = e.__traceback__
+
+class Callable:
+    def __call__(self, *args):
+        return args
+
+    def as_method_of(self, obj):
+        from types import MethodType
+        return MethodType(self, obj)
+
+custom_method = Callable().as_method_of(42)
+del Callable
+
+# line 95
+class WhichComments:
+  # line 97
+    # before f
+    def f(self):
+      # line 100
+        # start f
+        return 1
+        # line 103
+        # end f
+       # line 105
+    # after f
+
+    # before asyncf - line 108
+    async def asyncf(self):
+        # start asyncf
+        return 2
+        # end asyncf
+       # after asyncf - line 113
+    # end of WhichComments - line 114
+  # after WhichComments - line 115
+
+# Test that getsource works on a line that includes
+# a closing parenthesis with the opening paren being in another line
+(
+); after_closing = lambda: 1
diff --git a/Lib/test/test_inspect/inspect_fodder2.py b/Lib/test/test_inspect/inspect_fodder2.py
new file mode 100644
index 0000000000..0346461369
--- /dev/null
+++ b/Lib/test/test_inspect/inspect_fodder2.py
@@ -0,0 +1,292 @@
+# line 1
+def wrap(foo=None):
+    def wrapper(func):
+        return func
+    return wrapper
+
+# line 7
+def replace(func):
+    def insteadfunc():
+        print('hello')
+    return insteadfunc
+
+# line 13
+@wrap()
+@wrap(wrap)
+def wrapped():
+    pass
+
+# line 19
+@replace
+def gone():
+    pass
+
+# line 24
+oll = lambda m: m
+
+# line 27
+tll = lambda g: g and \
+g and \
+g
+
+# line 32
+tlli = lambda d: d and \
+    d
+
+# line 36
+def onelinefunc(): pass
+
+# line 39
+def manyargs(arg1, arg2,
+arg3, arg4): pass
+
+# line 43
+def twolinefunc(m): return m and \
+m
+
+# line 47
+a = [None,
+     lambda x: x,
+     None]
+
+# line 52
+def setfunc(func):
+    globals()["anonymous"] = func
+setfunc(lambda x, y: x*y)
+
+# line 57
+def with_comment():  # hello
+    world
+
+# line 61
+multiline_sig = [
+    lambda x, \
+            y: x+y,
+    None,
+    ]
+
+# line 68
+def func69():
+    class cls70:
+        def func71():
+            pass
+    return cls70
+extra74 = 74
+
+# line 76
+def func77(): pass
+(extra78, stuff78) = 'xy'
+extra79 = 'stop'
+
+# line 81
+class cls82:
+    def func83(): pass
+(extra84, stuff84) = 'xy'
+extra85 = 'stop'
+
+# line 87
+def func88():
+    # comment
+    return 90
+
+# line 92
+def f():
+    class X:
+        def g():
+            "doc"
+            return 42
+    return X
+method_in_dynamic_class = f().g
+
+#line 101
+def keyworded(*arg1, arg2=1):
+    pass
+
+#line 105
+def annotated(arg1: list):
+    pass
+
+#line 109
+def keyword_only_arg(*, arg):
+    pass
+
+@wrap(lambda: None)
+def func114():
+    return 115
+
+class ClassWithMethod:
+    def method(self):
+        pass
+
+from functools import wraps
+
+def decorator(func):
+    @wraps(func)
+    def fake():
+        return 42
+    return fake
+
+#line 129
+@decorator
+def real():
+    return 20
+
+#line 134
+class cls135:
+    def func136():
+        def func137():
+            never_reached1
+            never_reached2
+
+# line 141
+class cls142:
+    a = """
+class cls149:
+    ...
+"""
+
+# line 148
+class cls149:
+
+    def func151(self):
+        pass
+
+'''
+class cls160:
+    pass
+'''
+
+# line 159
+class cls160:
+
+    def func162(self):
+        pass
+
+# line 165
+class cls166:
+    a = '''
+    class cls175:
+        ...
+    '''
+
+# line 172
+class cls173:
+
+    class cls175:
+        pass
+
+# line 178
+class cls179:
+    pass
+
+# line 182
+class cls183:
+
+    class cls185:
+
+        def func186(self):
+            pass
+
+def class_decorator(cls):
+    return cls
+
+# line 193
+@class_decorator
+@class_decorator
+class cls196:
+
+    @class_decorator
+    @class_decorator
+    class cls200:
+        pass
+
+class cls203:
+    class cls204:
+        class cls205:
+            pass
+    class cls207:
+        class cls205:
+            pass
+
+# line 211
+def func212():
+    class cls213:
+        pass
+    return cls213
+
+# line 217
+class cls213:
+    def func219(self):
+        class cls220:
+            pass
+        return cls220
+
+# line 224
+async def func225():
+    class cls226:
+        pass
+    return cls226
+
+# line 230
+class cls226:
+    async def func232(self):
+        class cls233:
+            pass
+        return cls233
+
+if True:
+    class cls238:
+        class cls239:
+            '''if clause cls239'''
+else:
+    class cls238:
+        class cls239:
+            '''else clause 239'''
+            pass
+
+#line 247
+def positional_only_arg(a, /):
+    pass
+
+#line 251
+def all_markers(a, b, /, c, d, *, e, f):
+    pass
+
+# line 255
+def all_markers_with_args_and_kwargs(a, b, /, c, d, *args, e, f, **kwargs):
+    pass
+
+#line 259
+def all_markers_with_defaults(a, b=1, /, c=2, d=3, *, e=4, f=5):
+    pass
+
+# line 263
+def deco_factory(**kwargs):
+    def deco(f):
+        @wraps(f)
+        def wrapper(*a, **kwd):
+            kwd.update(kwargs)
+            return f(*a, **kwd)
+        return wrapper
+    return deco
+
+@deco_factory(foo=(1 + 2), bar=lambda: 1)
+def complex_decorated(foo=0, bar=lambda: 0):
+    return foo + bar()
+
+# line 276
+parenthesized_lambda = (
+    lambda: ())
+parenthesized_lambda2 = [
+    lambda: ()][0]
+parenthesized_lambda3 = {0:
+    lambda: ()}[0]
+
+# line 285
+post_line_parenthesized_lambda1 = (lambda: ()
+)
+
+# line 289
+nested_lambda = (
+    lambda right: [].map(
+        lambda length: ()))
diff --git a/Lib/test/test_inspect/inspect_stock_annotations.py b/Lib/test/test_inspect/inspect_stock_annotations.py
new file mode 100644
index 0000000000..d115a25b65
--- /dev/null
+++ b/Lib/test/test_inspect/inspect_stock_annotations.py
@@ -0,0 +1,28 @@
+a:int=3
+b:str="foo"
+
+class MyClass:
+    a:int=4
+    b:str="bar"
+    def __init__(self, a, b):
+        self.a = a
+        self.b = b
+    def __eq__(self, other):
+        return isinstance(other, MyClass) and self.a == other.a and self.b == other.b
+
+def function(a:int, b:str) -> MyClass:
+    return MyClass(a, b)
+
+
+def function2(a:int, b:"str", c:MyClass) -> MyClass:
+    pass
+
+
+def function3(a:"int", b:"str", c:"MyClass"):
+    pass
+
+
+class UnannotatedClass:
+    pass
+
+def unannotated_function(a, b, c): pass
diff --git a/Lib/test/test_inspect/inspect_stringized_annotations.py b/Lib/test/test_inspect/inspect_stringized_annotations.py
new file mode 100644
index 0000000000..a56fb050ea
--- /dev/null
+++ b/Lib/test/test_inspect/inspect_stringized_annotations.py
@@ -0,0 +1,34 @@
+from __future__ import annotations
+
+a:int=3
+b:str="foo"
+
+class MyClass:
+    a:int=4
+    b:str="bar"
+    def __init__(self, a, b):
+        self.a = a
+        self.b = b
+    def __eq__(self, other):
+        return isinstance(other, MyClass) and self.a == other.a and self.b == other.b
+
+def function(a:int, b:str) -> MyClass:
+    return MyClass(a, b)
+
+
+def function2(a:int, b:"str", c:MyClass) -> MyClass:
+    pass
+
+
+def function3(a:"int", b:"str", c:"MyClass"):
+    pass
+
+
+class UnannotatedClass:
+    pass
+
+def unannotated_function(a, b, c): pass
+
+class MyClassWithLocalAnnotations:
+    mytype = int
+    x: mytype
diff --git a/Lib/test/test_inspect/inspect_stringized_annotations_2.py b/Lib/test/test_inspect/inspect_stringized_annotations_2.py
new file mode 100644
index 0000000000..87206d5a64
--- /dev/null
+++ b/Lib/test/test_inspect/inspect_stringized_annotations_2.py
@@ -0,0 +1,3 @@
+from __future__ import annotations
+
+def foo(a, b, c):  pass
diff --git a/Lib/test/test_inspect/test_inspect.py b/Lib/test/test_inspect/test_inspect.py
new file mode 100644
index 0000000000..4a96502abf
--- /dev/null
+++ b/Lib/test/test_inspect/test_inspect.py
@@ -0,0 +1,4750 @@
+import asyncio
+import builtins
+import collections
+import datetime
+import functools
+import importlib
+import inspect
+import io
+import linecache
+import os
+import dis
+from os.path import normcase
+import _pickle
+import pickle
+import shutil
+import sys
+import types
+import textwrap
+import unicodedata
+import unittest
+import unittest.mock
+import warnings
+
+try:
+    from concurrent.futures import ThreadPoolExecutor
+except ImportError:
+    ThreadPoolExecutor = None
+
+from test.support import cpython_only
+from test.support import MISSING_C_DOCSTRINGS, ALWAYS_EQ
+from test.support.import_helper import DirsOnSysPath, ready_to_import
+from test.support.os_helper import TESTFN
+from test.support.script_helper import assert_python_ok, assert_python_failure
+from test import support
+
+from . import inspect_fodder as mod
+from . import inspect_fodder2 as mod2
+from . import inspect_stock_annotations
+from . import inspect_stringized_annotations
+from . import inspect_stringized_annotations_2
+
+
+# Functions tested in this suite:
+# ismodule, isclass, ismethod, isfunction, istraceback, isframe, iscode,
+# isbuiltin, isroutine, isgenerator, isgeneratorfunction, getmembers,
+# getdoc, getfile, getmodule, getsourcefile, getcomments, getsource,
+# getclasstree, getargvalues, formatargvalues,
+# currentframe, stack, trace, isdatadescriptor,
+# ismethodwrapper
+
+# NOTE: There are some additional tests relating to interaction with
+#       zipimport in the test_zipimport_support test module.
+
+modfile = mod.__file__
+if modfile.endswith(('c', 'o')):
+    modfile = modfile[:-1]
+
+# Normalize file names: on Windows, the case of file names of compiled
+# modules depends on the path used to start the python executable.
+modfile = normcase(modfile)
+
+def revise(filename, *args):
+    return (normcase(filename),) + args
+
+git = mod.StupidGit()
+
+
+def tearDownModule():
+    if support.has_socket_support:
+        asyncio.set_event_loop_policy(None)
+
+
+def signatures_with_lexicographic_keyword_only_parameters():
+    """
+    Yields a whole bunch of functions with only keyword-only parameters,
+    where those parameters are always in lexicographically sorted order.
+    """
+    parameters = ['a', 'bar', 'c', 'delta', 'ephraim', 'magical', 'yoyo', 'z']
+    for i in range(1, 2**len(parameters)):
+        p = []
+        bit = 1
+        for j in range(len(parameters)):
+            if i & (bit << j):
+                p.append(parameters[j])
+        fn_text = "def foo(*, " + ", ".join(p) + "): pass"
+        symbols = {}
+        exec(fn_text, symbols, symbols)
+        yield symbols['foo']
+
+
+def unsorted_keyword_only_parameters_fn(*, throw, out, the, baby, with_,
+                                        the_, bathwater):
+    pass
+
+unsorted_keyword_only_parameters = 'throw out the baby with_ the_ bathwater'.split()
+
+class IsTestBase(unittest.TestCase):
+    predicates = set([inspect.isbuiltin, inspect.isclass, inspect.iscode,
+                      inspect.isframe, inspect.isfunction, inspect.ismethod,
+                      inspect.ismodule, inspect.istraceback,
+                      inspect.isgenerator, inspect.isgeneratorfunction,
+                      inspect.iscoroutine, inspect.iscoroutinefunction,
+                      inspect.isasyncgen, inspect.isasyncgenfunction,
+                      inspect.ismethodwrapper])
+
+    def istest(self, predicate, exp):
+        obj = eval(exp)
+        self.assertTrue(predicate(obj), '%s(%s)' % (predicate.__name__, exp))
+
+        for other in self.predicates - set([predicate]):
+            if (predicate == inspect.isgeneratorfunction or \
+               predicate == inspect.isasyncgenfunction or \
+               predicate == inspect.iscoroutinefunction) and \
+               other == inspect.isfunction:
+                continue
+            self.assertFalse(other(obj), 'not %s(%s)' % (other.__name__, exp))
+
+    def test__all__(self):
+        support.check__all__(self, inspect, not_exported=("modulesbyfile",))
+
+def generator_function_example(self):
+    for i in range(2):
+        yield i
+
+async def async_generator_function_example(self):
+    async for i in range(2):
+        yield i
+
+async def coroutine_function_example(self):
+    return 'spam'
+
+@types.coroutine
+def gen_coroutine_function_example(self):
+    yield
+    return 'spam'
+
+class TestPredicates(IsTestBase):
+
+    def test_excluding_predicates(self):
+        global tb
+        self.istest(inspect.isbuiltin, 'sys.exit')
+        self.istest(inspect.isbuiltin, '[].append')
+        self.istest(inspect.iscode, 'mod.spam.__code__')
+        try:
+            1/0
+        except Exception as e:
+            tb = e.__traceback__
+            self.istest(inspect.isframe, 'tb.tb_frame')
+            self.istest(inspect.istraceback, 'tb')
+            if hasattr(types, 'GetSetDescriptorType'):
+                self.istest(inspect.isgetsetdescriptor,
+                            'type(tb.tb_frame).f_locals')
+            else:
+                self.assertFalse(inspect.isgetsetdescriptor(type(tb.tb_frame).f_locals))
+        finally:
+            # Clear traceback and all the frames and local variables hanging to it.
+            tb = None
+        self.istest(inspect.isfunction, 'mod.spam')
+        self.istest(inspect.isfunction, 'mod.StupidGit.abuse')
+        self.istest(inspect.ismethod, 'git.argue')
+        self.istest(inspect.ismethod, 'mod.custom_method')
+        self.istest(inspect.ismodule, 'mod')
+        self.istest(inspect.isdatadescriptor, 'collections.defaultdict.default_factory')
+        self.istest(inspect.isgenerator, '(x for x in range(2))')
+        self.istest(inspect.isgeneratorfunction, 'generator_function_example')
+        self.istest(inspect.isasyncgen,
+                    'async_generator_function_example(1)')
+        self.istest(inspect.isasyncgenfunction,
+                    'async_generator_function_example')
+
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            self.istest(inspect.iscoroutine, 'coroutine_function_example(1)')
+            self.istest(inspect.iscoroutinefunction, 'coroutine_function_example')
+
+        if hasattr(types, 'MemberDescriptorType'):
+            self.istest(inspect.ismemberdescriptor, 'datetime.timedelta.days')
+        else:
+            self.assertFalse(inspect.ismemberdescriptor(datetime.timedelta.days))
+        self.istest(inspect.ismethodwrapper, "object().__str__")
+        self.istest(inspect.ismethodwrapper, "object().__eq__")
+        self.istest(inspect.ismethodwrapper, "object().__repr__")
+        self.assertFalse(inspect.ismethodwrapper(type))
+        self.assertFalse(inspect.ismethodwrapper(int))
+        self.assertFalse(inspect.ismethodwrapper(type("AnyClass", (), {})))
+
+
+
+    def test_iscoroutine(self):
+        async_gen_coro = async_generator_function_example(1)
+        gen_coro = gen_coroutine_function_example(1)
+        coro = coroutine_function_example(1)
+
+        self.assertFalse(
+            inspect.iscoroutinefunction(gen_coroutine_function_example))
+        self.assertFalse(
+            inspect.iscoroutinefunction(
+                functools.partial(functools.partial(
+                    gen_coroutine_function_example))))
+        self.assertFalse(inspect.iscoroutine(gen_coro))
+
+        self.assertTrue(
+            inspect.isgeneratorfunction(gen_coroutine_function_example))
+        self.assertTrue(
+            inspect.isgeneratorfunction(
+                functools.partial(functools.partial(
+                    gen_coroutine_function_example))))
+        self.assertTrue(inspect.isgenerator(gen_coro))
+
+        async def _fn3():
+            pass
+
+        @inspect.markcoroutinefunction
+        def fn3():
+            return _fn3()
+
+        self.assertTrue(inspect.iscoroutinefunction(fn3))
+        self.assertTrue(
+            inspect.iscoroutinefunction(
+                inspect.markcoroutinefunction(lambda: _fn3())
+            )
+        )
+
+        class Cl:
+            async def __call__(self):
+                pass
+
+        self.assertFalse(inspect.iscoroutinefunction(Cl))
+        # instances with async def __call__ are NOT recognised.
+        self.assertFalse(inspect.iscoroutinefunction(Cl()))
+        # unless explicitly marked.
+        self.assertTrue(inspect.iscoroutinefunction(
+            inspect.markcoroutinefunction(Cl())
+        ))
+
+        class Cl2:
+            @inspect.markcoroutinefunction
+            def __call__(self):
+                pass
+
+        self.assertFalse(inspect.iscoroutinefunction(Cl2))
+        # instances with marked __call__ are NOT recognised.
+        self.assertFalse(inspect.iscoroutinefunction(Cl2()))
+        # unless explicitly marked.
+        self.assertTrue(inspect.iscoroutinefunction(
+            inspect.markcoroutinefunction(Cl2())
+        ))
+
+        class Cl3:
+            @inspect.markcoroutinefunction
+            @classmethod
+            def do_something_classy(cls):
+                pass
+
+            @inspect.markcoroutinefunction
+            @staticmethod
+            def do_something_static():
+                pass
+
+        self.assertTrue(inspect.iscoroutinefunction(Cl3.do_something_classy))
+        self.assertTrue(inspect.iscoroutinefunction(Cl3.do_something_static))
+
+        self.assertFalse(
+            inspect.iscoroutinefunction(unittest.mock.Mock()))
+        self.assertTrue(
+            inspect.iscoroutinefunction(unittest.mock.AsyncMock()))
+        self.assertTrue(
+            inspect.iscoroutinefunction(coroutine_function_example))
+        self.assertTrue(
+            inspect.iscoroutinefunction(
+                functools.partial(functools.partial(
+                    coroutine_function_example))))
+        self.assertTrue(inspect.iscoroutine(coro))
+
+        self.assertFalse(
+            inspect.isgeneratorfunction(unittest.mock.Mock()))
+        self.assertFalse(
+            inspect.isgeneratorfunction(unittest.mock.AsyncMock()))
+        self.assertFalse(
+            inspect.isgeneratorfunction(coroutine_function_example))
+        self.assertFalse(
+            inspect.isgeneratorfunction(
+                functools.partial(functools.partial(
+                    coroutine_function_example))))
+        self.assertFalse(inspect.isgenerator(coro))
+
+        self.assertFalse(
+            inspect.isasyncgenfunction(unittest.mock.Mock()))
+        self.assertFalse(
+            inspect.isasyncgenfunction(unittest.mock.AsyncMock()))
+        self.assertFalse(
+            inspect.isasyncgenfunction(coroutine_function_example))
+        self.assertTrue(
+            inspect.isasyncgenfunction(async_generator_function_example))
+        self.assertTrue(
+            inspect.isasyncgenfunction(
+                functools.partial(functools.partial(
+                    async_generator_function_example))))
+        self.assertTrue(inspect.isasyncgen(async_gen_coro))
+
+        coro.close(); gen_coro.close(); # silence warnings
+
+    def test_isawaitable(self):
+        def gen(): yield
+        self.assertFalse(inspect.isawaitable(gen()))
+
+        coro = coroutine_function_example(1)
+        gen_coro = gen_coroutine_function_example(1)
+
+        self.assertTrue(inspect.isawaitable(coro))
+        self.assertTrue(inspect.isawaitable(gen_coro))
+
+        class Future:
+            def __await__():
+                pass
+        self.assertTrue(inspect.isawaitable(Future()))
+        self.assertFalse(inspect.isawaitable(Future))
+
+        class NotFuture: pass
+        not_fut = NotFuture()
+        not_fut.__await__ = lambda: None
+        self.assertFalse(inspect.isawaitable(not_fut))
+
+        coro.close(); gen_coro.close() # silence warnings
+
+    def test_isroutine(self):
+        # method
+        self.assertTrue(inspect.isroutine(git.argue))
+        self.assertTrue(inspect.isroutine(mod.custom_method))
+        self.assertTrue(inspect.isroutine([].count))
+        # function
+        self.assertTrue(inspect.isroutine(mod.spam))
+        self.assertTrue(inspect.isroutine(mod.StupidGit.abuse))
+        # slot-wrapper
+        self.assertTrue(inspect.isroutine(object.__init__))
+        self.assertTrue(inspect.isroutine(object.__str__))
+        self.assertTrue(inspect.isroutine(object.__lt__))
+        self.assertTrue(inspect.isroutine(int.__lt__))
+        # method-wrapper
+        self.assertTrue(inspect.isroutine(object().__init__))
+        self.assertTrue(inspect.isroutine(object().__str__))
+        self.assertTrue(inspect.isroutine(object().__lt__))
+        self.assertTrue(inspect.isroutine((42).__lt__))
+        # method-descriptor
+        self.assertTrue(inspect.isroutine(str.join))
+        self.assertTrue(inspect.isroutine(list.append))
+        self.assertTrue(inspect.isroutine(''.join))
+        self.assertTrue(inspect.isroutine([].append))
+        # object
+        self.assertFalse(inspect.isroutine(object))
+        self.assertFalse(inspect.isroutine(object()))
+        self.assertFalse(inspect.isroutine(str()))
+        # module
+        self.assertFalse(inspect.isroutine(mod))
+        # type
+        self.assertFalse(inspect.isroutine(type))
+        self.assertFalse(inspect.isroutine(int))
+        self.assertFalse(inspect.isroutine(type('some_class', (), {})))
+
+    def test_isclass(self):
+        self.istest(inspect.isclass, 'mod.StupidGit')
+        self.assertTrue(inspect.isclass(list))
+
+        class CustomGetattr(object):
+            def __getattr__(self, attr):
+                return None
+        self.assertFalse(inspect.isclass(CustomGetattr()))
+
+    def test_get_slot_members(self):
+        class C(object):
+            __slots__ = ("a", "b")
+        x = C()
+        x.a = 42
+        members = dict(inspect.getmembers(x))
+        self.assertIn('a', members)
+        self.assertNotIn('b', members)
+
+    def test_isabstract(self):
+        from abc import ABCMeta, abstractmethod
+
+        class AbstractClassExample(metaclass=ABCMeta):
+
+            @abstractmethod
+            def foo(self):
+                pass
+
+        class ClassExample(AbstractClassExample):
+            def foo(self):
+                pass
+
+        a = ClassExample()
+
+        # Test general behaviour.
+        self.assertTrue(inspect.isabstract(AbstractClassExample))
+        self.assertFalse(inspect.isabstract(ClassExample))
+        self.assertFalse(inspect.isabstract(a))
+        self.assertFalse(inspect.isabstract(int))
+        self.assertFalse(inspect.isabstract(5))
+
+    def test_isabstract_during_init_subclass(self):
+        from abc import ABCMeta, abstractmethod
+        isabstract_checks = []
+        class AbstractChecker(metaclass=ABCMeta):
+            def __init_subclass__(cls):
+                isabstract_checks.append(inspect.isabstract(cls))
+        class AbstractClassExample(AbstractChecker):
+            @abstractmethod
+            def foo(self):
+                pass
+        class ClassExample(AbstractClassExample):
+            def foo(self):
+                pass
+        self.assertEqual(isabstract_checks, [True, False])
+
+        isabstract_checks.clear()
+        class AbstractChild(AbstractClassExample):
+            pass
+        class AbstractGrandchild(AbstractChild):
+            pass
+        class ConcreteGrandchild(ClassExample):
+            pass
+        self.assertEqual(isabstract_checks, [True, True, False])
+
+
+class TestInterpreterStack(IsTestBase):
+    def __init__(self, *args, **kwargs):
+        unittest.TestCase.__init__(self, *args, **kwargs)
+
+        git.abuse(7, 8, 9)
+
+    def test_abuse_done(self):
+        self.istest(inspect.istraceback, 'git.ex.__traceback__')
+        self.istest(inspect.isframe, 'mod.fr')
+
+    def test_stack(self):
+        self.assertTrue(len(mod.st) >= 5)
+        frame1, frame2, frame3, frame4, *_ = mod.st
+        frameinfo = revise(*frame1[1:])
+        self.assertEqual(frameinfo,
+             (modfile, 16, 'eggs', ['    st = inspect.stack()\n'], 0))
+        self.assertEqual(frame1.positions, dis.Positions(16, 16, 9, 24))
+        frameinfo = revise(*frame2[1:])
+        self.assertEqual(frameinfo,
+             (modfile, 9, 'spam', ['    eggs(b + d, c + f)\n'], 0))
+        self.assertEqual(frame2.positions, dis.Positions(9, 9, 4, 22))
+        frameinfo = revise(*frame3[1:])
+        self.assertEqual(frameinfo,
+             (modfile, 43, 'argue', ['            spam(a, b, c)\n'], 0))
+        self.assertEqual(frame3.positions, dis.Positions(43, 43, 12, 25))
+        frameinfo = revise(*frame4[1:])
+        self.assertEqual(frameinfo,
+             (modfile, 39, 'abuse', ['        self.argue(a, b, c)\n'], 0))
+        self.assertEqual(frame4.positions, dis.Positions(39, 39, 8, 27))
+        # Test named tuple fields
+        record = mod.st[0]
+        self.assertIs(record.frame, mod.fr)
+        self.assertEqual(record.lineno, 16)
+        self.assertEqual(record.filename, mod.__file__)
+        self.assertEqual(record.function, 'eggs')
+        self.assertIn('inspect.stack()', record.code_context[0])
+        self.assertEqual(record.index, 0)
+
+    def test_trace(self):
+        self.assertEqual(len(git.tr), 3)
+        frame1, frame2, frame3, = git.tr
+        self.assertEqual(revise(*frame1[1:]),
+             (modfile, 43, 'argue', ['            spam(a, b, c)\n'], 0))
+        self.assertEqual(frame1.positions, dis.Positions(43, 43, 12, 25))
+        self.assertEqual(revise(*frame2[1:]),
+             (modfile, 9, 'spam', ['    eggs(b + d, c + f)\n'], 0))
+        self.assertEqual(frame2.positions, dis.Positions(9, 9, 4, 22))
+        self.assertEqual(revise(*frame3[1:]),
+             (modfile, 18, 'eggs', ['    q = y / 0\n'], 0))
+        self.assertEqual(frame3.positions, dis.Positions(18, 18, 8, 13))
+
+    def test_frame(self):
+        args, varargs, varkw, locals = inspect.getargvalues(mod.fr)
+        self.assertEqual(args, ['x', 'y'])
+        self.assertEqual(varargs, None)
+        self.assertEqual(varkw, None)
+        self.assertEqual(locals, {'x': 11, 'p': 11, 'y': 14})
+        self.assertEqual(inspect.formatargvalues(args, varargs, varkw, locals),
+                         '(x=11, y=14)')
+
+    def test_previous_frame(self):
+        args, varargs, varkw, locals = inspect.getargvalues(mod.fr.f_back)
+        self.assertEqual(args, ['a', 'b', 'c', 'd', 'e', 'f'])
+        self.assertEqual(varargs, 'g')
+        self.assertEqual(varkw, 'h')
+        self.assertEqual(inspect.formatargvalues(args, varargs, varkw, locals),
+             '(a=7, b=8, c=9, d=3, e=4, f=5, *g=(), **h={})')
+
+class GetSourceBase(unittest.TestCase):
+    # Subclasses must override.
+    fodderModule = None
+
+    def setUp(self):
+        with open(inspect.getsourcefile(self.fodderModule), encoding="utf-8") as fp:
+            self.source = fp.read()
+
+    def sourcerange(self, top, bottom):
+        lines = self.source.split("\n")
+        return "\n".join(lines[top-1:bottom]) + ("\n" if bottom else "")
+
+    def assertSourceEqual(self, obj, top, bottom):
+        self.assertEqual(inspect.getsource(obj),
+                         self.sourcerange(top, bottom))
+
+class SlotUser:
+    'Docstrings for __slots__'
+    __slots__ = {'power': 'measured in kilowatts',
+                 'distance': 'measured in kilometers'}
+
+class TestRetrievingSourceCode(GetSourceBase):
+    fodderModule = mod
+
+    def test_getclasses(self):
+        classes = inspect.getmembers(mod, inspect.isclass)
+        self.assertEqual(classes,
+                         [('FesteringGob', mod.FesteringGob),
+                          ('MalodorousPervert', mod.MalodorousPervert),
+                          ('ParrotDroppings', mod.ParrotDroppings),
+                          ('StupidGit', mod.StupidGit),
+                          ('Tit', mod.MalodorousPervert),
+                          ('WhichComments', mod.WhichComments),
+                         ])
+        tree = inspect.getclasstree([cls[1] for cls in classes])
+        self.assertEqual(tree,
+                         [(object, ()),
+                          [(mod.ParrotDroppings, (object,)),
+                           [(mod.FesteringGob, (mod.MalodorousPervert,
+                                                   mod.ParrotDroppings))
+                            ],
+                           (mod.StupidGit, (object,)),
+                           [(mod.MalodorousPervert, (mod.StupidGit,)),
+                            [(mod.FesteringGob, (mod.MalodorousPervert,
+                                                    mod.ParrotDroppings))
+                             ]
+                            ],
+                            (mod.WhichComments, (object,),)
+                           ]
+                          ])
+        tree = inspect.getclasstree([cls[1] for cls in classes], True)
+        self.assertEqual(tree,
+                         [(object, ()),
+                          [(mod.ParrotDroppings, (object,)),
+                           (mod.StupidGit, (object,)),
+                           [(mod.MalodorousPervert, (mod.StupidGit,)),
+                            [(mod.FesteringGob, (mod.MalodorousPervert,
+                                                    mod.ParrotDroppings))
+                             ]
+                            ],
+                            (mod.WhichComments, (object,),)
+                           ]
+                          ])
+
+    def test_getfunctions(self):
+        functions = inspect.getmembers(mod, inspect.isfunction)
+        self.assertEqual(functions, [('after_closing', mod.after_closing),
+                                     ('eggs', mod.eggs),
+                                     ('lobbest', mod.lobbest),
+                                     ('spam', mod.spam)])
+
+    @unittest.skipIf(sys.flags.optimize >= 2,
+                     "Docstrings are omitted with -O2 and above")
+    def test_getdoc(self):
+        self.assertEqual(inspect.getdoc(mod), 'A module docstring.')
+        self.assertEqual(inspect.getdoc(mod.StupidGit),
+                         'A longer,\n\nindented\n\ndocstring.')
+        self.assertEqual(inspect.getdoc(git.abuse),
+                         'Another\n\ndocstring\n\ncontaining\n\ntabs')
+        self.assertEqual(inspect.getdoc(SlotUser.power),
+                         'measured in kilowatts')
+        self.assertEqual(inspect.getdoc(SlotUser.distance),
+                         'measured in kilometers')
+
+    @unittest.skipIf(sys.flags.optimize >= 2,
+                     "Docstrings are omitted with -O2 and above")
+    def test_getdoc_inherited(self):
+        self.assertEqual(inspect.getdoc(mod.FesteringGob),
+                         'A longer,\n\nindented\n\ndocstring.')
+        self.assertEqual(inspect.getdoc(mod.FesteringGob.abuse),
+                         'Another\n\ndocstring\n\ncontaining\n\ntabs')
+        self.assertEqual(inspect.getdoc(mod.FesteringGob().abuse),
+                         'Another\n\ndocstring\n\ncontaining\n\ntabs')
+        self.assertEqual(inspect.getdoc(mod.FesteringGob.contradiction),
+                         'The automatic gainsaying.')
+
+    @unittest.skipIf(MISSING_C_DOCSTRINGS, "test requires docstrings")
+    def test_finddoc(self):
+        finddoc = inspect._finddoc
+        self.assertEqual(finddoc(int), int.__doc__)
+        self.assertEqual(finddoc(int.to_bytes), int.to_bytes.__doc__)
+        self.assertEqual(finddoc(int().to_bytes), int.to_bytes.__doc__)
+        self.assertEqual(finddoc(int.from_bytes), int.from_bytes.__doc__)
+        self.assertEqual(finddoc(int.real), int.real.__doc__)
+
+    def test_cleandoc(self):
+        self.assertEqual(inspect.cleandoc('An\n    indented\n    docstring.'),
+                         'An\nindented\ndocstring.')
+
+    def test_getcomments(self):
+        self.assertEqual(inspect.getcomments(mod), '# line 1\n')
+        self.assertEqual(inspect.getcomments(mod.StupidGit), '# line 20\n')
+        self.assertEqual(inspect.getcomments(mod2.cls160), '# line 159\n')
+        # If the object source file is not available, return None.
+        co = compile('x=1', '_non_existing_filename.py', 'exec')
+        self.assertIsNone(inspect.getcomments(co))
+        # If the object has been defined in C, return None.
+        self.assertIsNone(inspect.getcomments(list))
+
+    def test_getmodule(self):
+        # Check actual module
+        self.assertEqual(inspect.getmodule(mod), mod)
+        # Check class (uses __module__ attribute)
+        self.assertEqual(inspect.getmodule(mod.StupidGit), mod)
+        # Check a method (no __module__ attribute, falls back to filename)
+        self.assertEqual(inspect.getmodule(mod.StupidGit.abuse), mod)
+        # Do it again (check the caching isn't broken)
+        self.assertEqual(inspect.getmodule(mod.StupidGit.abuse), mod)
+        # Check a builtin
+        self.assertEqual(inspect.getmodule(str), sys.modules["builtins"])
+        # Check filename override
+        self.assertEqual(inspect.getmodule(None, modfile), mod)
+
+    def test_getmodule_file_not_found(self):
+        # See bpo-45406
+        def _getabsfile(obj, _filename):
+            raise FileNotFoundError('bad file')
+        with unittest.mock.patch('inspect.getabsfile', _getabsfile):
+            f = inspect.currentframe()
+            self.assertIsNone(inspect.getmodule(f))
+            inspect.getouterframes(f)  # smoke test
+
+    def test_getframeinfo_get_first_line(self):
+        frame_info = inspect.getframeinfo(self.fodderModule.fr, 50)
+        self.assertEqual(frame_info.code_context[0], "# line 1\n")
+        self.assertEqual(frame_info.code_context[1], "'A module docstring.'\n")
+
+    def test_getsource(self):
+        self.assertSourceEqual(git.abuse, 29, 39)
+        self.assertSourceEqual(mod.StupidGit, 21, 51)
+        self.assertSourceEqual(mod.lobbest, 75, 76)
+        self.assertSourceEqual(mod.after_closing, 120, 120)
+
+    def test_getsourcefile(self):
+        self.assertEqual(normcase(inspect.getsourcefile(mod.spam)), modfile)
+        self.assertEqual(normcase(inspect.getsourcefile(git.abuse)), modfile)
+        fn = "_non_existing_filename_used_for_sourcefile_test.py"
+        co = compile("x=1", fn, "exec")
+        self.assertEqual(inspect.getsourcefile(co), None)
+        linecache.cache[co.co_filename] = (1, None, "None", co.co_filename)
+        try:
+            self.assertEqual(normcase(inspect.getsourcefile(co)), fn)
+        finally:
+            del linecache.cache[co.co_filename]
+
+    def test_getfile(self):
+        self.assertEqual(inspect.getfile(mod.StupidGit), mod.__file__)
+
+    def test_getfile_builtin_module(self):
+        with self.assertRaises(TypeError) as e:
+            inspect.getfile(sys)
+        self.assertTrue(str(e.exception).startswith('<module'))
+
+    def test_getfile_builtin_class(self):
+        with self.assertRaises(TypeError) as e:
+            inspect.getfile(int)
+        self.assertTrue(str(e.exception).startswith('<class'))
+
+    def test_getfile_builtin_function_or_method(self):
+        with self.assertRaises(TypeError) as e_abs:
+            inspect.getfile(abs)
+        self.assertIn('expected, got', str(e_abs.exception))
+        with self.assertRaises(TypeError) as e_append:
+            inspect.getfile(list.append)
+        self.assertIn('expected, got', str(e_append.exception))
+
+    def test_getfile_class_without_module(self):
+        class CM(type):
+            @property
+            def __module__(cls):
+                raise AttributeError
+        class C(metaclass=CM):
+            pass
+        with self.assertRaises(TypeError):
+            inspect.getfile(C)
+
+    def test_getfile_broken_repr(self):
+        class ErrorRepr:
+            def __repr__(self):
+                raise Exception('xyz')
+        er = ErrorRepr()
+        with self.assertRaises(TypeError):
+            inspect.getfile(er)
+
+    def test_getmodule_recursion(self):
+        from types import ModuleType
+        name = '__inspect_dummy'
+        m = sys.modules[name] = ModuleType(name)
+        m.__file__ = "<string>" # hopefully not a real filename...
+        m.__loader__ = "dummy"  # pretend the filename is understood by a loader
+        exec("def x(): pass", m.__dict__)
+        self.assertEqual(inspect.getsourcefile(m.x.__code__), '<string>')
+        del sys.modules[name]
+        inspect.getmodule(compile('a=10','','single'))
+
+    def test_proceed_with_fake_filename(self):
+        '''doctest monkeypatches linecache to enable inspection'''
+        fn, source = '<test>', 'def x(): pass\n'
+        getlines = linecache.getlines
+        def monkey(filename, module_globals=None):
+            if filename == fn:
+                return source.splitlines(keepends=True)
+            else:
+                return getlines(filename, module_globals)
+        linecache.getlines = monkey
+        try:
+            ns = {}
+            exec(compile(source, fn, 'single'), ns)
+            inspect.getsource(ns["x"])
+        finally:
+            linecache.getlines = getlines
+
+    def test_getsource_on_code_object(self):
+        self.assertSourceEqual(mod.eggs.__code__, 12, 18)
+
+class TestGetsourceInteractive(unittest.TestCase):
+    def test_getclasses_interactive(self):
+        # bpo-44648: simulate a REPL session;
+        # there is no `__file__` in the __main__ module
+        code = "import sys, inspect; \
+                assert not hasattr(sys.modules['__main__'], '__file__'); \
+                A = type('A', (), {}); \
+                inspect.getsource(A)"
+        _, _, stderr = assert_python_failure("-c", code, __isolated=True)
+        self.assertIn(b'OSError: source code not available', stderr)
+
+class TestGettingSourceOfToplevelFrames(GetSourceBase):
+    fodderModule = mod
+
+    def test_range_toplevel_frame(self):
+        self.maxDiff = None
+        self.assertSourceEqual(mod.currentframe, 1, None)
+
+    def test_range_traceback_toplevel_frame(self):
+        self.assertSourceEqual(mod.tb, 1, None)
+
+class TestDecorators(GetSourceBase):
+    fodderModule = mod2
+
+    def test_wrapped_decorator(self):
+        self.assertSourceEqual(mod2.wrapped, 14, 17)
+
+    def test_replacing_decorator(self):
+        self.assertSourceEqual(mod2.gone, 9, 10)
+
+    def test_getsource_unwrap(self):
+        self.assertSourceEqual(mod2.real, 130, 132)
+
+    def test_decorator_with_lambda(self):
+        self.assertSourceEqual(mod2.func114, 113, 115)
+
+class TestOneliners(GetSourceBase):
+    fodderModule = mod2
+    def test_oneline_lambda(self):
+        # Test inspect.getsource with a one-line lambda function.
+        self.assertSourceEqual(mod2.oll, 25, 25)
+
+    def test_threeline_lambda(self):
+        # Test inspect.getsource with a three-line lambda function,
+        # where the second and third lines are _not_ indented.
+        self.assertSourceEqual(mod2.tll, 28, 30)
+
+    def test_twoline_indented_lambda(self):
+        # Test inspect.getsource with a two-line lambda function,
+        # where the second line _is_ indented.
+        self.assertSourceEqual(mod2.tlli, 33, 34)
+
+    def test_parenthesized_multiline_lambda(self):
+        # Test inspect.getsource with a parenthesized multi-line lambda
+        # function.
+        self.assertSourceEqual(mod2.parenthesized_lambda, 279, 279)
+        self.assertSourceEqual(mod2.parenthesized_lambda2, 281, 281)
+        self.assertSourceEqual(mod2.parenthesized_lambda3, 283, 283)
+
+    def test_post_line_parenthesized_lambda(self):
+        # Test inspect.getsource with a parenthesized multi-line lambda
+        # function.
+        self.assertSourceEqual(mod2.post_line_parenthesized_lambda1, 286, 287)
+
+    def test_nested_lambda(self):
+        # Test inspect.getsource with a nested lambda function.
+        self.assertSourceEqual(mod2.nested_lambda, 291, 292)
+
+    def test_onelinefunc(self):
+        # Test inspect.getsource with a regular one-line function.
+        self.assertSourceEqual(mod2.onelinefunc, 37, 37)
+
+    def test_manyargs(self):
+        # Test inspect.getsource with a regular function where
+        # the arguments are on two lines and _not_ indented and
+        # the body on the second line with the last arguments.
+        self.assertSourceEqual(mod2.manyargs, 40, 41)
+
+    def test_twolinefunc(self):
+        # Test inspect.getsource with a regular function where
+        # the body is on two lines, following the argument list and
+        # continued on the next line by a \\.
+        self.assertSourceEqual(mod2.twolinefunc, 44, 45)
+
+    def test_lambda_in_list(self):
+        # Test inspect.getsource with a one-line lambda function
+        # defined in a list, indented.
+        self.assertSourceEqual(mod2.a[1], 49, 49)
+
+    def test_anonymous(self):
+        # Test inspect.getsource with a lambda function defined
+        # as argument to another function.
+        self.assertSourceEqual(mod2.anonymous, 55, 55)
+
+class TestBlockComments(GetSourceBase):
+    fodderModule = mod
+
+    def test_toplevel_class(self):
+        self.assertSourceEqual(mod.WhichComments, 96, 114)
+
+    def test_class_method(self):
+        self.assertSourceEqual(mod.WhichComments.f, 99, 104)
+
+    def test_class_async_method(self):
+        self.assertSourceEqual(mod.WhichComments.asyncf, 109, 112)
+
+class TestBuggyCases(GetSourceBase):
+    fodderModule = mod2
+
+    def test_with_comment(self):
+        self.assertSourceEqual(mod2.with_comment, 58, 59)
+
+    def test_multiline_sig(self):
+        self.assertSourceEqual(mod2.multiline_sig[0], 63, 64)
+
+    def test_nested_class(self):
+        self.assertSourceEqual(mod2.func69().func71, 71, 72)
+
+    def test_one_liner_followed_by_non_name(self):
+        self.assertSourceEqual(mod2.func77, 77, 77)
+
+    def test_one_liner_dedent_non_name(self):
+        self.assertSourceEqual(mod2.cls82.func83, 83, 83)
+
+    def test_with_comment_instead_of_docstring(self):
+        self.assertSourceEqual(mod2.func88, 88, 90)
+
+    def test_method_in_dynamic_class(self):
+        self.assertSourceEqual(mod2.method_in_dynamic_class, 95, 97)
+
+    # This should not skip for CPython, but might on a repackaged python where
+    # unicodedata is not an external module, or on pypy.
+    @unittest.skipIf(not hasattr(unicodedata, '__file__') or
+                                 unicodedata.__file__.endswith('.py'),
+                     "unicodedata is not an external binary module")
+    def test_findsource_binary(self):
+        self.assertRaises(OSError, inspect.getsource, unicodedata)
+        self.assertRaises(OSError, inspect.findsource, unicodedata)
+
+    def test_findsource_code_in_linecache(self):
+        lines = ["x=1"]
+        co = compile(lines[0], "_dynamically_created_file", "exec")
+        self.assertRaises(OSError, inspect.findsource, co)
+        self.assertRaises(OSError, inspect.getsource, co)
+        linecache.cache[co.co_filename] = (1, None, lines, co.co_filename)
+        try:
+            self.assertEqual(inspect.findsource(co), (lines,0))
+            self.assertEqual(inspect.getsource(co), lines[0])
+        finally:
+            del linecache.cache[co.co_filename]
+
+    def test_findsource_without_filename(self):
+        for fname in ['', '<string>']:
+            co = compile('x=1', fname, "exec")
+            self.assertRaises(IOError, inspect.findsource, co)
+            self.assertRaises(IOError, inspect.getsource, co)
+
+    def test_findsource_with_out_of_bounds_lineno(self):
+        mod_len = len(inspect.getsource(mod))
+        src = '\n' * 2* mod_len + "def f(): pass"
+        co = compile(src, mod.__file__, "exec")
+        g, l = {}, {}
+        eval(co, g, l)
+        func = l['f']
+        self.assertEqual(func.__code__.co_firstlineno, 1+2*mod_len)
+        with self.assertRaisesRegex(IOError, "lineno is out of bounds"):
+            inspect.findsource(func)
+
+    def test_getsource_on_method(self):
+        self.assertSourceEqual(mod2.ClassWithMethod.method, 118, 119)
+
+    def test_nested_func(self):
+        self.assertSourceEqual(mod2.cls135.func136, 136, 139)
+
+    def test_class_definition_in_multiline_string_definition(self):
+        self.assertSourceEqual(mod2.cls149, 149, 152)
+
+    def test_class_definition_in_multiline_comment(self):
+        self.assertSourceEqual(mod2.cls160, 160, 163)
+
+    def test_nested_class_definition_indented_string(self):
+        self.assertSourceEqual(mod2.cls173.cls175, 175, 176)
+
+    def test_nested_class_definition(self):
+        self.assertSourceEqual(mod2.cls183, 183, 188)
+        self.assertSourceEqual(mod2.cls183.cls185, 185, 188)
+
+    def test_class_decorator(self):
+        self.assertSourceEqual(mod2.cls196, 194, 201)
+        self.assertSourceEqual(mod2.cls196.cls200, 198, 201)
+
+    def test_class_inside_conditional(self):
+        self.assertSourceEqual(mod2.cls238, 238, 240)
+        self.assertSourceEqual(mod2.cls238.cls239, 239, 240)
+
+    def test_multiple_children_classes(self):
+        self.assertSourceEqual(mod2.cls203, 203, 209)
+        self.assertSourceEqual(mod2.cls203.cls204, 204, 206)
+        self.assertSourceEqual(mod2.cls203.cls204.cls205, 205, 206)
+        self.assertSourceEqual(mod2.cls203.cls207, 207, 209)
+        self.assertSourceEqual(mod2.cls203.cls207.cls205, 208, 209)
+
+    def test_nested_class_definition_inside_function(self):
+        self.assertSourceEqual(mod2.func212(), 213, 214)
+        self.assertSourceEqual(mod2.cls213, 218, 222)
+        self.assertSourceEqual(mod2.cls213().func219(), 220, 221)
+
+    @unittest.skipIf(
+        support.is_emscripten or support.is_wasi,
+        "socket.accept is broken"
+    )
+    def test_nested_class_definition_inside_async_function(self):
+        import asyncio
+        self.addCleanup(asyncio.set_event_loop_policy, None)
+        self.assertSourceEqual(asyncio.run(mod2.func225()), 226, 227)
+        self.assertSourceEqual(mod2.cls226, 231, 235)
+        self.assertSourceEqual(asyncio.run(mod2.cls226().func232()), 233, 234)
+
+class TestNoEOL(GetSourceBase):
+    def setUp(self):
+        self.tempdir = TESTFN + '_dir'
+        os.mkdir(self.tempdir)
+        with open(os.path.join(self.tempdir, 'inspect_fodder3%spy' % os.extsep),
+                  'w', encoding='utf-8') as f:
+            f.write("class X:\n    pass # No EOL")
+        with DirsOnSysPath(self.tempdir):
+            import inspect_fodder3 as mod3
+        self.fodderModule = mod3
+        super().setUp()
+
+    def tearDown(self):
+        shutil.rmtree(self.tempdir)
+
+    def test_class(self):
+        self.assertSourceEqual(self.fodderModule.X, 1, 2)
+
+
+class TestComplexDecorator(GetSourceBase):
+    fodderModule = mod2
+
+    def test_parens_in_decorator(self):
+        self.assertSourceEqual(self.fodderModule.complex_decorated, 273, 275)
+
+class _BrokenDataDescriptor(object):
+    """
+    A broken data descriptor. See bug #1785.
+    """
+    def __get__(*args):
+        raise AttributeError("broken data descriptor")
+
+    def __set__(*args):
+        raise RuntimeError
+
+    def __getattr__(*args):
+        raise AttributeError("broken data descriptor")
+
+
+class _BrokenMethodDescriptor(object):
+    """
+    A broken method descriptor. See bug #1785.
+    """
+    def __get__(*args):
+        raise AttributeError("broken method descriptor")
+
+    def __getattr__(*args):
+        raise AttributeError("broken method descriptor")
+
+
+# Helper for testing classify_class_attrs.
+def attrs_wo_objs(cls):
+    return [t[:3] for t in inspect.classify_class_attrs(cls)]
+
+
+class TestClassesAndFunctions(unittest.TestCase):
+    def test_newstyle_mro(self):
+        # The same w/ new-class MRO.
+        class A(object):    pass
+        class B(A): pass
+        class C(A): pass
+        class D(B, C): pass
+
+        expected = (D, B, C, A, object)
+        got = inspect.getmro(D)
+        self.assertEqual(expected, got)
+
+    def assertFullArgSpecEquals(self, routine, args_e, varargs_e=None,
+                                    varkw_e=None, defaults_e=None,
+                                    posonlyargs_e=[], kwonlyargs_e=[],
+                                    kwonlydefaults_e=None,
+                                    ann_e={}):
+        args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann = \
+            inspect.getfullargspec(routine)
+        self.assertEqual(args, args_e)
+        self.assertEqual(varargs, varargs_e)
+        self.assertEqual(varkw, varkw_e)
+        self.assertEqual(defaults, defaults_e)
+        self.assertEqual(kwonlyargs, kwonlyargs_e)
+        self.assertEqual(kwonlydefaults, kwonlydefaults_e)
+        self.assertEqual(ann, ann_e)
+
+    def test_getfullargspec(self):
+        self.assertFullArgSpecEquals(mod2.keyworded, [], varargs_e='arg1',
+                                     kwonlyargs_e=['arg2'],
+                                     kwonlydefaults_e={'arg2':1})
+
+        self.assertFullArgSpecEquals(mod2.annotated, ['arg1'],
+                                     ann_e={'arg1' : list})
+        self.assertFullArgSpecEquals(mod2.keyword_only_arg, [],
+                                     kwonlyargs_e=['arg'])
+
+        self.assertFullArgSpecEquals(mod2.all_markers, ['a', 'b', 'c', 'd'],
+                                     kwonlyargs_e=['e', 'f'])
+
+        self.assertFullArgSpecEquals(mod2.all_markers_with_args_and_kwargs,
+                                     ['a', 'b', 'c', 'd'],
+                                     varargs_e='args',
+                                     varkw_e='kwargs',
+                                     kwonlyargs_e=['e', 'f'])
+
+        self.assertFullArgSpecEquals(mod2.all_markers_with_defaults, ['a', 'b', 'c', 'd'],
+                                     defaults_e=(1,2,3),
+                                     kwonlyargs_e=['e', 'f'],
+                                     kwonlydefaults_e={'e': 4, 'f': 5})
+
+    def test_argspec_api_ignores_wrapped(self):
+        # Issue 20684: low level introspection API must ignore __wrapped__
+        @functools.wraps(mod.spam)
+        def ham(x, y):
+            pass
+        # Basic check
+        self.assertFullArgSpecEquals(ham, ['x', 'y'])
+        self.assertFullArgSpecEquals(functools.partial(ham),
+                                     ['x', 'y'])
+
+    def test_getfullargspec_signature_attr(self):
+        def test():
+            pass
+        spam_param = inspect.Parameter('spam', inspect.Parameter.POSITIONAL_ONLY)
+        test.__signature__ = inspect.Signature(parameters=(spam_param,))
+
+        self.assertFullArgSpecEquals(test, ['spam'])
+
+    def test_getfullargspec_signature_annos(self):
+        def test(a:'spam') -> 'ham': pass
+        spec = inspect.getfullargspec(test)
+        self.assertEqual(test.__annotations__, spec.annotations)
+
+        def test(): pass
+        spec = inspect.getfullargspec(test)
+        self.assertEqual(test.__annotations__, spec.annotations)
+
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_getfullargspec_builtin_methods(self):
+        self.assertFullArgSpecEquals(_pickle.Pickler.dump, ['self', 'obj'])
+
+        self.assertFullArgSpecEquals(_pickle.Pickler(io.BytesIO()).dump, ['self', 'obj'])
+
+        self.assertFullArgSpecEquals(
+             os.stat,
+             args_e=['path'],
+             kwonlyargs_e=['dir_fd', 'follow_symlinks'],
+             kwonlydefaults_e={'dir_fd': None, 'follow_symlinks': True})
+
+    @cpython_only
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_getfullargspec_builtin_func(self):
+        import _testcapi
+        builtin = _testcapi.docstring_with_signature_with_defaults
+        spec = inspect.getfullargspec(builtin)
+        self.assertEqual(spec.defaults[0], 'avocado')
+
+    @cpython_only
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_getfullargspec_builtin_func_no_signature(self):
+        import _testcapi
+        builtin = _testcapi.docstring_no_signature
+        with self.assertRaises(TypeError):
+            inspect.getfullargspec(builtin)
+
+    def test_getfullargspec_definition_order_preserved_on_kwonly(self):
+        for fn in signatures_with_lexicographic_keyword_only_parameters():
+            signature = inspect.getfullargspec(fn)
+            l = list(signature.kwonlyargs)
+            sorted_l = sorted(l)
+            self.assertTrue(l)
+            self.assertEqual(l, sorted_l)
+        signature = inspect.getfullargspec(unsorted_keyword_only_parameters_fn)
+        l = list(signature.kwonlyargs)
+        self.assertEqual(l, unsorted_keyword_only_parameters)
+
+    def test_classify_newstyle(self):
+        class A(object):
+
+            def s(): pass
+            s = staticmethod(s)
+
+            def c(cls): pass
+            c = classmethod(c)
+
+            def getp(self): pass
+            p = property(getp)
+
+            def m(self): pass
+
+            def m1(self): pass
+
+            datablob = '1'
+
+            dd = _BrokenDataDescriptor()
+            md = _BrokenMethodDescriptor()
+
+        attrs = attrs_wo_objs(A)
+
+        self.assertIn(('__new__', 'static method', object), attrs,
+                      'missing __new__')
+        self.assertIn(('__init__', 'method', object), attrs, 'missing __init__')
+
+        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
+        self.assertIn(('c', 'class method', A), attrs, 'missing class method')
+        self.assertIn(('p', 'property', A), attrs, 'missing property')
+        self.assertIn(('m', 'method', A), attrs,
+                      'missing plain method: %r' % attrs)
+        self.assertIn(('m1', 'method', A), attrs, 'missing plain method')
+        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
+        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
+        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
+
+        class B(A):
+
+            def m(self): pass
+
+        attrs = attrs_wo_objs(B)
+        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
+        self.assertIn(('c', 'class method', A), attrs, 'missing class method')
+        self.assertIn(('p', 'property', A), attrs, 'missing property')
+        self.assertIn(('m', 'method', B), attrs, 'missing plain method')
+        self.assertIn(('m1', 'method', A), attrs, 'missing plain method')
+        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
+        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
+        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
+
+
+        class C(A):
+
+            def m(self): pass
+            def c(self): pass
+
+        attrs = attrs_wo_objs(C)
+        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
+        self.assertIn(('c', 'method', C), attrs, 'missing plain method')
+        self.assertIn(('p', 'property', A), attrs, 'missing property')
+        self.assertIn(('m', 'method', C), attrs, 'missing plain method')
+        self.assertIn(('m1', 'method', A), attrs, 'missing plain method')
+        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
+        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
+        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
+
+        class D(B, C):
+
+            def m1(self): pass
+
+        attrs = attrs_wo_objs(D)
+        self.assertIn(('s', 'static method', A), attrs, 'missing static method')
+        self.assertIn(('c', 'method', C), attrs, 'missing plain method')
+        self.assertIn(('p', 'property', A), attrs, 'missing property')
+        self.assertIn(('m', 'method', B), attrs, 'missing plain method')
+        self.assertIn(('m1', 'method', D), attrs, 'missing plain method')
+        self.assertIn(('datablob', 'data', A), attrs, 'missing data')
+        self.assertIn(('md', 'method', A), attrs, 'missing method descriptor')
+        self.assertIn(('dd', 'data', A), attrs, 'missing data descriptor')
+
+    def test_classify_builtin_types(self):
+        # Simple sanity check that all built-in types can have their
+        # attributes classified.
+        for name in dir(__builtins__):
+            builtin = getattr(__builtins__, name)
+            if isinstance(builtin, type):
+                inspect.classify_class_attrs(builtin)
+
+        attrs = attrs_wo_objs(bool)
+        self.assertIn(('__new__', 'static method', bool), attrs,
+                      'missing __new__')
+        self.assertIn(('from_bytes', 'class method', int), attrs,
+                      'missing class method')
+        self.assertIn(('to_bytes', 'method', int), attrs,
+                      'missing plain method')
+        self.assertIn(('__add__', 'method', int), attrs,
+                      'missing plain method')
+        self.assertIn(('__and__', 'method', bool), attrs,
+                      'missing plain method')
+
+    def test_classify_DynamicClassAttribute(self):
+        class Meta(type):
+            def __getattr__(self, name):
+                if name == 'ham':
+                    return 'spam'
+                return super().__getattr__(name)
+        class VA(metaclass=Meta):
+            @types.DynamicClassAttribute
+            def ham(self):
+                return 'eggs'
+        should_find_dca = inspect.Attribute('ham', 'data', VA, VA.__dict__['ham'])
+        self.assertIn(should_find_dca, inspect.classify_class_attrs(VA))
+        should_find_ga = inspect.Attribute('ham', 'data', Meta, 'spam')
+        self.assertIn(should_find_ga, inspect.classify_class_attrs(VA))
+
+    def test_classify_overrides_bool(self):
+        class NoBool(object):
+            def __eq__(self, other):
+                return NoBool()
+
+            def __bool__(self):
+                raise NotImplementedError(
+                    "This object does not specify a boolean value")
+
+        class HasNB(object):
+            dd = NoBool()
+
+        should_find_attr = inspect.Attribute('dd', 'data', HasNB, HasNB.dd)
+        self.assertIn(should_find_attr, inspect.classify_class_attrs(HasNB))
+
+    def test_classify_metaclass_class_attribute(self):
+        class Meta(type):
+            fish = 'slap'
+            def __dir__(self):
+                return ['__class__', '__module__', '__name__', 'fish']
+        class Class(metaclass=Meta):
+            pass
+        should_find = inspect.Attribute('fish', 'data', Meta, 'slap')
+        self.assertIn(should_find, inspect.classify_class_attrs(Class))
+
+    def test_classify_VirtualAttribute(self):
+        class Meta(type):
+            def __dir__(cls):
+                return ['__class__', '__module__', '__name__', 'BOOM']
+            def __getattr__(self, name):
+                if name =='BOOM':
+                    return 42
+                return super().__getattr(name)
+        class Class(metaclass=Meta):
+            pass
+        should_find = inspect.Attribute('BOOM', 'data', Meta, 42)
+        self.assertIn(should_find, inspect.classify_class_attrs(Class))
+
+    def test_classify_VirtualAttribute_multi_classes(self):
+        class Meta1(type):
+            def __dir__(cls):
+                return ['__class__', '__module__', '__name__', 'one']
+            def __getattr__(self, name):
+                if name =='one':
+                    return 1
+                return super().__getattr__(name)
+        class Meta2(type):
+            def __dir__(cls):
+                return ['__class__', '__module__', '__name__', 'two']
+            def __getattr__(self, name):
+                if name =='two':
+                    return 2
+                return super().__getattr__(name)
+        class Meta3(Meta1, Meta2):
+            def __dir__(cls):
+                return list(sorted(set(['__class__', '__module__', '__name__', 'three'] +
+                    Meta1.__dir__(cls) + Meta2.__dir__(cls))))
+            def __getattr__(self, name):
+                if name =='three':
+                    return 3
+                return super().__getattr__(name)
+        class Class1(metaclass=Meta1):
+            pass
+        class Class2(Class1, metaclass=Meta3):
+            pass
+
+        should_find1 = inspect.Attribute('one', 'data', Meta1, 1)
+        should_find2 = inspect.Attribute('two', 'data', Meta2, 2)
+        should_find3 = inspect.Attribute('three', 'data', Meta3, 3)
+        cca = inspect.classify_class_attrs(Class2)
+        for sf in (should_find1, should_find2, should_find3):
+            self.assertIn(sf, cca)
+
+    def test_classify_class_attrs_with_buggy_dir(self):
+        class M(type):
+            def __dir__(cls):
+                return ['__class__', '__name__', 'missing']
+        class C(metaclass=M):
+            pass
+        attrs = [a[0] for a in inspect.classify_class_attrs(C)]
+        self.assertNotIn('missing', attrs)
+
+    def test_getmembers_descriptors(self):
+        class A(object):
+            dd = _BrokenDataDescriptor()
+            md = _BrokenMethodDescriptor()
+
+        def pred_wrapper(pred):
+            # A quick'n'dirty way to discard standard attributes of new-style
+            # classes.
+            class Empty(object):
+                pass
+            def wrapped(x):
+                if '__name__' in dir(x) and hasattr(Empty, x.__name__):
+                    return False
+                return pred(x)
+            return wrapped
+
+        ismethoddescriptor = pred_wrapper(inspect.ismethoddescriptor)
+        isdatadescriptor = pred_wrapper(inspect.isdatadescriptor)
+
+        self.assertEqual(inspect.getmembers(A, ismethoddescriptor),
+            [('md', A.__dict__['md'])])
+        self.assertEqual(inspect.getmembers(A, isdatadescriptor),
+            [('dd', A.__dict__['dd'])])
+
+        class B(A):
+            pass
+
+        self.assertEqual(inspect.getmembers(B, ismethoddescriptor),
+            [('md', A.__dict__['md'])])
+        self.assertEqual(inspect.getmembers(B, isdatadescriptor),
+            [('dd', A.__dict__['dd'])])
+
+    def test_getmembers_method(self):
+        class B:
+            def f(self):
+                pass
+
+        self.assertIn(('f', B.f), inspect.getmembers(B))
+        self.assertNotIn(('f', B.f), inspect.getmembers(B, inspect.ismethod))
+        b = B()
+        self.assertIn(('f', b.f), inspect.getmembers(b))
+        self.assertIn(('f', b.f), inspect.getmembers(b, inspect.ismethod))
+
+    def test_getmembers_VirtualAttribute(self):
+        class M(type):
+            def __getattr__(cls, name):
+                if name == 'eggs':
+                    return 'scrambled'
+                return super().__getattr__(name)
+        class A(metaclass=M):
+            @types.DynamicClassAttribute
+            def eggs(self):
+                return 'spam'
+        class B:
+            def __getattr__(self, attribute):
+                return None
+        self.assertIn(('eggs', 'scrambled'), inspect.getmembers(A))
+        self.assertIn(('eggs', 'spam'), inspect.getmembers(A()))
+        b = B()
+        self.assertIn(('__getattr__', b.__getattr__), inspect.getmembers(b))
+
+    def test_getmembers_static(self):
+        class A:
+            @property
+            def name(self):
+                raise NotImplementedError
+            @types.DynamicClassAttribute
+            def eggs(self):
+                raise NotImplementedError
+
+        a = A()
+        instance_members = inspect.getmembers_static(a)
+        class_members = inspect.getmembers_static(A)
+        self.assertIn(('name', inspect.getattr_static(a, 'name')), instance_members)
+        self.assertIn(('eggs', inspect.getattr_static(a, 'eggs')), instance_members)
+        self.assertIn(('name', inspect.getattr_static(A, 'name')), class_members)
+        self.assertIn(('eggs', inspect.getattr_static(A, 'eggs')), class_members)
+
+    def test_getmembers_with_buggy_dir(self):
+        class M(type):
+            def __dir__(cls):
+                return ['__class__', '__name__', 'missing']
+        class C(metaclass=M):
+            pass
+        attrs = [a[0] for a in inspect.getmembers(C)]
+        self.assertNotIn('missing', attrs)
+
+    def test_get_annotations_with_stock_annotations(self):
+        def foo(a:int, b:str): pass
+        self.assertEqual(inspect.get_annotations(foo), {'a': int, 'b': str})
+
+        foo.__annotations__ = {'a': 'foo', 'b':'str'}
+        self.assertEqual(inspect.get_annotations(foo), {'a': 'foo', 'b': 'str'})
+
+        self.assertEqual(inspect.get_annotations(foo, eval_str=True, locals=locals()), {'a': foo, 'b': str})
+        self.assertEqual(inspect.get_annotations(foo, eval_str=True, globals=locals()), {'a': foo, 'b': str})
+
+        isa = inspect_stock_annotations
+        self.assertEqual(inspect.get_annotations(isa), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.MyClass), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.function), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function2), {'a': int, 'b': 'str', 'c': isa.MyClass, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function3), {'a': 'int', 'b': 'str', 'c': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(inspect), {}) # inspect module has no annotations
+        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass), {})
+        self.assertEqual(inspect.get_annotations(isa.unannotated_function), {})
+
+        self.assertEqual(inspect.get_annotations(isa, eval_str=True), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=True), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.function, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=True), {'a': int, 'b': str, 'c': isa.MyClass, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=True), {'a': int, 'b': str, 'c': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(inspect, eval_str=True), {})
+        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=True), {})
+        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=True), {})
+
+        self.assertEqual(inspect.get_annotations(isa, eval_str=False), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=False), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.function, eval_str=False), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=False), {'a': int, 'b': 'str', 'c': isa.MyClass, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=False), {'a': 'int', 'b': 'str', 'c': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(inspect, eval_str=False), {})
+        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=False), {})
+        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=False), {})
+
+        def times_three(fn):
+            @functools.wraps(fn)
+            def wrapper(a, b):
+                return fn(a*3, b*3)
+            return wrapper
+
+        wrapped = times_three(isa.function)
+        self.assertEqual(wrapped(1, 'x'), isa.MyClass(3, 'xxx'))
+        self.assertIsNot(wrapped.__globals__, isa.function.__globals__)
+        self.assertEqual(inspect.get_annotations(wrapped), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(wrapped, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(wrapped, eval_str=False), {'a': int, 'b': str, 'return': isa.MyClass})
+
+    def test_get_annotations_with_stringized_annotations(self):
+        isa = inspect_stringized_annotations
+        self.assertEqual(inspect.get_annotations(isa), {'a': 'int', 'b': 'str'})
+        self.assertEqual(inspect.get_annotations(isa.MyClass), {'a': 'int', 'b': 'str'})
+        self.assertEqual(inspect.get_annotations(isa.function), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(isa.function2), {'a': 'int', 'b': "'str'", 'c': 'MyClass', 'return': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(isa.function3), {'a': "'int'", 'b': "'str'", 'c': "'MyClass'"})
+        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass), {})
+        self.assertEqual(inspect.get_annotations(isa.unannotated_function), {})
+
+        self.assertEqual(inspect.get_annotations(isa, eval_str=True), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=True), {'a': int, 'b': str})
+        self.assertEqual(inspect.get_annotations(isa.function, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=True), {'a': int, 'b': 'str', 'c': isa.MyClass, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=True), {'a': 'int', 'b': 'str', 'c': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=True), {})
+        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=True), {})
+
+        self.assertEqual(inspect.get_annotations(isa, eval_str=False), {'a': 'int', 'b': 'str'})
+        self.assertEqual(inspect.get_annotations(isa.MyClass, eval_str=False), {'a': 'int', 'b': 'str'})
+        self.assertEqual(inspect.get_annotations(isa.function, eval_str=False), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(isa.function2, eval_str=False), {'a': 'int', 'b': "'str'", 'c': 'MyClass', 'return': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(isa.function3, eval_str=False), {'a': "'int'", 'b': "'str'", 'c': "'MyClass'"})
+        self.assertEqual(inspect.get_annotations(isa.UnannotatedClass, eval_str=False), {})
+        self.assertEqual(inspect.get_annotations(isa.unannotated_function, eval_str=False), {})
+
+        isa2 = inspect_stringized_annotations_2
+        self.assertEqual(inspect.get_annotations(isa2), {})
+        self.assertEqual(inspect.get_annotations(isa2, eval_str=True), {})
+        self.assertEqual(inspect.get_annotations(isa2, eval_str=False), {})
+
+        def times_three(fn):
+            @functools.wraps(fn)
+            def wrapper(a, b):
+                return fn(a*3, b*3)
+            return wrapper
+
+        wrapped = times_three(isa.function)
+        self.assertEqual(wrapped(1, 'x'), isa.MyClass(3, 'xxx'))
+        self.assertIsNot(wrapped.__globals__, isa.function.__globals__)
+        self.assertEqual(inspect.get_annotations(wrapped), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
+        self.assertEqual(inspect.get_annotations(wrapped, eval_str=True), {'a': int, 'b': str, 'return': isa.MyClass})
+        self.assertEqual(inspect.get_annotations(wrapped, eval_str=False), {'a': 'int', 'b': 'str', 'return': 'MyClass'})
+
+        # test that local namespace lookups work
+        self.assertEqual(inspect.get_annotations(isa.MyClassWithLocalAnnotations), {'x': 'mytype'})
+        self.assertEqual(inspect.get_annotations(isa.MyClassWithLocalAnnotations, eval_str=True), {'x': int})
+
+
+class TestFormatAnnotation(unittest.TestCase):
+    def test_typing_replacement(self):
+        from test.typinganndata.ann_module9 import ann, ann1
+        self.assertEqual(inspect.formatannotation(ann), 'Union[List[str], int]')
+        self.assertEqual(inspect.formatannotation(ann1), 'Union[List[testModule.typing.A], int]')
+
+
+class TestIsDataDescriptor(unittest.TestCase):
+
+    def test_custom_descriptors(self):
+        class NonDataDescriptor:
+            def __get__(self, value, type=None): pass
+        class DataDescriptor0:
+            def __set__(self, name, value): pass
+        class DataDescriptor1:
+            def __delete__(self, name): pass
+        class DataDescriptor2:
+            __set__ = None
+        self.assertFalse(inspect.isdatadescriptor(NonDataDescriptor()),
+                         'class with only __get__ not a data descriptor')
+        self.assertTrue(inspect.isdatadescriptor(DataDescriptor0()),
+                        'class with __set__ is a data descriptor')
+        self.assertTrue(inspect.isdatadescriptor(DataDescriptor1()),
+                        'class with __delete__ is a data descriptor')
+        self.assertTrue(inspect.isdatadescriptor(DataDescriptor2()),
+                        'class with __set__ = None is a data descriptor')
+
+    def test_slot(self):
+        class Slotted:
+            __slots__ = 'foo',
+        self.assertTrue(inspect.isdatadescriptor(Slotted.foo),
+                        'a slot is a data descriptor')
+
+    def test_property(self):
+        class Propertied:
+            @property
+            def a_property(self):
+                pass
+        self.assertTrue(inspect.isdatadescriptor(Propertied.a_property),
+                        'a property is a data descriptor')
+
+    def test_functions(self):
+        class Test(object):
+            def instance_method(self): pass
+            @classmethod
+            def class_method(cls): pass
+            @staticmethod
+            def static_method(): pass
+        def function():
+            pass
+        a_lambda = lambda: None
+        self.assertFalse(inspect.isdatadescriptor(Test().instance_method),
+                         'a instance method is not a data descriptor')
+        self.assertFalse(inspect.isdatadescriptor(Test().class_method),
+                         'a class method is not a data descriptor')
+        self.assertFalse(inspect.isdatadescriptor(Test().static_method),
+                         'a static method is not a data descriptor')
+        self.assertFalse(inspect.isdatadescriptor(function),
+                         'a function is not a data descriptor')
+        self.assertFalse(inspect.isdatadescriptor(a_lambda),
+                         'a lambda is not a data descriptor')
+
+
+_global_ref = object()
+class TestGetClosureVars(unittest.TestCase):
+
+    def test_name_resolution(self):
+        # Basic test of the 4 different resolution mechanisms
+        def f(nonlocal_ref):
+            def g(local_ref):
+                print(local_ref, nonlocal_ref, _global_ref, unbound_ref)
+            return g
+        _arg = object()
+        nonlocal_vars = {"nonlocal_ref": _arg}
+        global_vars = {"_global_ref": _global_ref}
+        builtin_vars = {"print": print}
+        unbound_names = {"unbound_ref"}
+        expected = inspect.ClosureVars(nonlocal_vars, global_vars,
+                                       builtin_vars, unbound_names)
+        self.assertEqual(inspect.getclosurevars(f(_arg)), expected)
+
+    def test_generator_closure(self):
+        def f(nonlocal_ref):
+            def g(local_ref):
+                print(local_ref, nonlocal_ref, _global_ref, unbound_ref)
+                yield
+            return g
+        _arg = object()
+        nonlocal_vars = {"nonlocal_ref": _arg}
+        global_vars = {"_global_ref": _global_ref}
+        builtin_vars = {"print": print}
+        unbound_names = {"unbound_ref"}
+        expected = inspect.ClosureVars(nonlocal_vars, global_vars,
+                                       builtin_vars, unbound_names)
+        self.assertEqual(inspect.getclosurevars(f(_arg)), expected)
+
+    def test_method_closure(self):
+        class C:
+            def f(self, nonlocal_ref):
+                def g(local_ref):
+                    print(local_ref, nonlocal_ref, _global_ref, unbound_ref)
+                return g
+        _arg = object()
+        nonlocal_vars = {"nonlocal_ref": _arg}
+        global_vars = {"_global_ref": _global_ref}
+        builtin_vars = {"print": print}
+        unbound_names = {"unbound_ref"}
+        expected = inspect.ClosureVars(nonlocal_vars, global_vars,
+                                       builtin_vars, unbound_names)
+        self.assertEqual(inspect.getclosurevars(C().f(_arg)), expected)
+
+    def test_nonlocal_vars(self):
+        # More complex tests of nonlocal resolution
+        def _nonlocal_vars(f):
+            return inspect.getclosurevars(f).nonlocals
+
+        def make_adder(x):
+            def add(y):
+                return x + y
+            return add
+
+        def curry(func, arg1):
+            return lambda arg2: func(arg1, arg2)
+
+        def less_than(a, b):
+            return a < b
+
+        # The infamous Y combinator.
+        def Y(le):
+            def g(f):
+                return le(lambda x: f(f)(x))
+            Y.g_ref = g
+            return g(g)
+
+        def check_y_combinator(func):
+            self.assertEqual(_nonlocal_vars(func), {'f': Y.g_ref})
+
+        inc = make_adder(1)
+        add_two = make_adder(2)
+        greater_than_five = curry(less_than, 5)
+
+        self.assertEqual(_nonlocal_vars(inc), {'x': 1})
+        self.assertEqual(_nonlocal_vars(add_two), {'x': 2})
+        self.assertEqual(_nonlocal_vars(greater_than_five),
+                         {'arg1': 5, 'func': less_than})
+        self.assertEqual(_nonlocal_vars((lambda x: lambda y: x + y)(3)),
+                         {'x': 3})
+        Y(check_y_combinator)
+
+    def test_getclosurevars_empty(self):
+        def foo(): pass
+        _empty = inspect.ClosureVars({}, {}, {}, set())
+        self.assertEqual(inspect.getclosurevars(lambda: True), _empty)
+        self.assertEqual(inspect.getclosurevars(foo), _empty)
+
+    def test_getclosurevars_error(self):
+        class T: pass
+        self.assertRaises(TypeError, inspect.getclosurevars, 1)
+        self.assertRaises(TypeError, inspect.getclosurevars, list)
+        self.assertRaises(TypeError, inspect.getclosurevars, {})
+
+    def _private_globals(self):
+        code = """def f(): print(path)"""
+        ns = {}
+        exec(code, ns)
+        return ns["f"], ns
+
+    def test_builtins_fallback(self):
+        f, ns = self._private_globals()
+        ns.pop("__builtins__", None)
+        expected = inspect.ClosureVars({}, {}, {"print":print}, {"path"})
+        self.assertEqual(inspect.getclosurevars(f), expected)
+
+    def test_builtins_as_dict(self):
+        f, ns = self._private_globals()
+        ns["__builtins__"] = {"path":1}
+        expected = inspect.ClosureVars({}, {}, {"path":1}, {"print"})
+        self.assertEqual(inspect.getclosurevars(f), expected)
+
+    def test_builtins_as_module(self):
+        f, ns = self._private_globals()
+        ns["__builtins__"] = os
+        expected = inspect.ClosureVars({}, {}, {"path":os.path}, {"print"})
+        self.assertEqual(inspect.getclosurevars(f), expected)
+
+
+class TestGetcallargsFunctions(unittest.TestCase):
+
+    def assertEqualCallArgs(self, func, call_params_string, locs=None):
+        locs = dict(locs or {}, func=func)
+        r1 = eval('func(%s)' % call_params_string, None, locs)
+        r2 = eval('inspect.getcallargs(func, %s)' % call_params_string, None,
+                  locs)
+        self.assertEqual(r1, r2)
+
+    def assertEqualException(self, func, call_param_string, locs=None):
+        locs = dict(locs or {}, func=func)
+        try:
+            eval('func(%s)' % call_param_string, None, locs)
+        except Exception as e:
+            ex1 = e
+        else:
+            self.fail('Exception not raised')
+        try:
+            eval('inspect.getcallargs(func, %s)' % call_param_string, None,
+                 locs)
+        except Exception as e:
+            ex2 = e
+        else:
+            self.fail('Exception not raised')
+        self.assertIs(type(ex1), type(ex2))
+        self.assertEqual(str(ex1), str(ex2))
+        del ex1, ex2
+
+    def makeCallable(self, signature):
+        """Create a function that returns its locals()"""
+        code = "lambda %s: locals()"
+        return eval(code % signature)
+
+    def test_plain(self):
+        f = self.makeCallable('a, b=1')
+        self.assertEqualCallArgs(f, '2')
+        self.assertEqualCallArgs(f, '2, 3')
+        self.assertEqualCallArgs(f, 'a=2')
+        self.assertEqualCallArgs(f, 'b=3, a=2')
+        self.assertEqualCallArgs(f, '2, b=3')
+        # expand *iterable / **mapping
+        self.assertEqualCallArgs(f, '*(2,)')
+        self.assertEqualCallArgs(f, '*[2]')
+        self.assertEqualCallArgs(f, '*(2, 3)')
+        self.assertEqualCallArgs(f, '*[2, 3]')
+        self.assertEqualCallArgs(f, '**{"a":2}')
+        self.assertEqualCallArgs(f, 'b=3, **{"a":2}')
+        self.assertEqualCallArgs(f, '2, **{"b":3}')
+        self.assertEqualCallArgs(f, '**{"b":3, "a":2}')
+        # expand UserList / UserDict
+        self.assertEqualCallArgs(f, '*collections.UserList([2])')
+        self.assertEqualCallArgs(f, '*collections.UserList([2, 3])')
+        self.assertEqualCallArgs(f, '**collections.UserDict(a=2)')
+        self.assertEqualCallArgs(f, '2, **collections.UserDict(b=3)')
+        self.assertEqualCallArgs(f, 'b=2, **collections.UserDict(a=3)')
+
+    def test_varargs(self):
+        f = self.makeCallable('a, b=1, *c')
+        self.assertEqualCallArgs(f, '2')
+        self.assertEqualCallArgs(f, '2, 3')
+        self.assertEqualCallArgs(f, '2, 3, 4')
+        self.assertEqualCallArgs(f, '*(2,3,4)')
+        self.assertEqualCallArgs(f, '2, *[3,4]')
+        self.assertEqualCallArgs(f, '2, 3, *collections.UserList([4])')
+
+    def test_varkw(self):
+        f = self.makeCallable('a, b=1, **c')
+        self.assertEqualCallArgs(f, 'a=2')
+        self.assertEqualCallArgs(f, '2, b=3, c=4')
+        self.assertEqualCallArgs(f, 'b=3, a=2, c=4')
+        self.assertEqualCallArgs(f, 'c=4, **{"a":2, "b":3}')
+        self.assertEqualCallArgs(f, '2, c=4, **{"b":3}')
+        self.assertEqualCallArgs(f, 'b=2, **{"a":3, "c":4}')
+        self.assertEqualCallArgs(f, '**collections.UserDict(a=2, b=3, c=4)')
+        self.assertEqualCallArgs(f, '2, c=4, **collections.UserDict(b=3)')
+        self.assertEqualCallArgs(f, 'b=2, **collections.UserDict(a=3, c=4)')
+
+    def test_varkw_only(self):
+        # issue11256:
+        f = self.makeCallable('**c')
+        self.assertEqualCallArgs(f, '')
+        self.assertEqualCallArgs(f, 'a=1')
+        self.assertEqualCallArgs(f, 'a=1, b=2')
+        self.assertEqualCallArgs(f, 'c=3, **{"a": 1, "b": 2}')
+        self.assertEqualCallArgs(f, '**collections.UserDict(a=1, b=2)')
+        self.assertEqualCallArgs(f, 'c=3, **collections.UserDict(a=1, b=2)')
+
+    def test_keyword_only(self):
+        f = self.makeCallable('a=3, *, c, d=2')
+        self.assertEqualCallArgs(f, 'c=3')
+        self.assertEqualCallArgs(f, 'c=3, a=3')
+        self.assertEqualCallArgs(f, 'a=2, c=4')
+        self.assertEqualCallArgs(f, '4, c=4')
+        self.assertEqualException(f, '')
+        self.assertEqualException(f, '3')
+        self.assertEqualException(f, 'a=3')
+        self.assertEqualException(f, 'd=4')
+
+        f = self.makeCallable('*, c, d=2')
+        self.assertEqualCallArgs(f, 'c=3')
+        self.assertEqualCallArgs(f, 'c=3, d=4')
+        self.assertEqualCallArgs(f, 'd=4, c=3')
+
+    def test_multiple_features(self):
+        f = self.makeCallable('a, b=2, *f, **g')
+        self.assertEqualCallArgs(f, '2, 3, 7')
+        self.assertEqualCallArgs(f, '2, 3, x=8')
+        self.assertEqualCallArgs(f, '2, 3, x=8, *[(4,[5,6]), 7]')
+        self.assertEqualCallArgs(f, '2, x=8, *[3, (4,[5,6]), 7], y=9')
+        self.assertEqualCallArgs(f, 'x=8, *[2, 3, (4,[5,6])], y=9')
+        self.assertEqualCallArgs(f, 'x=8, *collections.UserList('
+                                 '[2, 3, (4,[5,6])]), **{"y":9, "z":10}')
+        self.assertEqualCallArgs(f, '2, x=8, *collections.UserList([3, '
+                                 '(4,[5,6])]), **collections.UserDict('
+                                 'y=9, z=10)')
+
+        f = self.makeCallable('a, b=2, *f, x, y=99, **g')
+        self.assertEqualCallArgs(f, '2, 3, x=8')
+        self.assertEqualCallArgs(f, '2, 3, x=8, *[(4,[5,6]), 7]')
+        self.assertEqualCallArgs(f, '2, x=8, *[3, (4,[5,6]), 7], y=9, z=10')
+        self.assertEqualCallArgs(f, 'x=8, *[2, 3, (4,[5,6])], y=9, z=10')
+        self.assertEqualCallArgs(f, 'x=8, *collections.UserList('
+                                 '[2, 3, (4,[5,6])]), q=0, **{"y":9, "z":10}')
+        self.assertEqualCallArgs(f, '2, x=8, *collections.UserList([3, '
+                                 '(4,[5,6])]), q=0, **collections.UserDict('
+                                 'y=9, z=10)')
+
+    def test_errors(self):
+        f0 = self.makeCallable('')
+        f1 = self.makeCallable('a, b')
+        f2 = self.makeCallable('a, b=1')
+        # f0 takes no arguments
+        self.assertEqualException(f0, '1')
+        self.assertEqualException(f0, 'x=1')
+        self.assertEqualException(f0, '1,x=1')
+        # f1 takes exactly 2 arguments
+        self.assertEqualException(f1, '')
+        self.assertEqualException(f1, '1')
+        self.assertEqualException(f1, 'a=2')
+        self.assertEqualException(f1, 'b=3')
+        # f2 takes at least 1 argument
+        self.assertEqualException(f2, '')
+        self.assertEqualException(f2, 'b=3')
+        for f in f1, f2:
+            # f1/f2 takes exactly/at most 2 arguments
+            self.assertEqualException(f, '2, 3, 4')
+            self.assertEqualException(f, '1, 2, 3, a=1')
+            self.assertEqualException(f, '2, 3, 4, c=5')
+            self.assertEqualException(f, '2, 3, 4, a=1, c=5')
+            # f got an unexpected keyword argument
+            self.assertEqualException(f, 'c=2')
+            self.assertEqualException(f, '2, c=3')
+            self.assertEqualException(f, '2, 3, c=4')
+            self.assertEqualException(f, '2, c=4, b=3')
+            self.assertEqualException(f, '**{u"\u03c0\u03b9": 4}')
+            # f got multiple values for keyword argument
+            self.assertEqualException(f, '1, a=2')
+            self.assertEqualException(f, '1, **{"a":2}')
+            self.assertEqualException(f, '1, 2, b=3')
+            self.assertEqualException(f, '1, c=3, a=2')
+        # issue11256:
+        f3 = self.makeCallable('**c')
+        self.assertEqualException(f3, '1, 2')
+        self.assertEqualException(f3, '1, 2, a=1, b=2')
+        f4 = self.makeCallable('*, a, b=0')
+        self.assertEqualException(f4, '1, 2')
+        self.assertEqualException(f4, '1, 2, a=1, b=2')
+        self.assertEqualException(f4, 'a=1, a=3')
+        self.assertEqualException(f4, 'a=1, c=3')
+        self.assertEqualException(f4, 'a=1, a=3, b=4')
+        self.assertEqualException(f4, 'a=1, b=2, a=3, b=4')
+        self.assertEqualException(f4, 'a=1, a=2, a=3, b=4')
+
+        # issue #20816: getcallargs() fails to iterate over non-existent
+        # kwonlydefaults and raises a wrong TypeError
+        def f5(*, a): pass
+        with self.assertRaisesRegex(TypeError,
+                                    'missing 1 required keyword-only'):
+            inspect.getcallargs(f5)
+
+
+        # issue20817:
+        def f6(a, b, c):
+            pass
+        with self.assertRaisesRegex(TypeError, "'a', 'b' and 'c'"):
+            inspect.getcallargs(f6)
+
+        # bpo-33197
+        with self.assertRaisesRegex(ValueError,
+                                    'variadic keyword parameters cannot'
+                                    ' have default values'):
+            inspect.Parameter("foo", kind=inspect.Parameter.VAR_KEYWORD,
+                              default=42)
+        with self.assertRaisesRegex(ValueError,
+                                    "value 5 is not a valid Parameter.kind"):
+            inspect.Parameter("bar", kind=5, default=42)
+
+        with self.assertRaisesRegex(TypeError,
+                                   'name must be a str, not a int'):
+            inspect.Parameter(123, kind=4)
+
+class TestGetcallargsMethods(TestGetcallargsFunctions):
+
+    def setUp(self):
+        class Foo(object):
+            pass
+        self.cls = Foo
+        self.inst = Foo()
+
+    def makeCallable(self, signature):
+        assert 'self' not in signature
+        mk = super(TestGetcallargsMethods, self).makeCallable
+        self.cls.method = mk('self, ' + signature)
+        return self.inst.method
+
+class TestGetcallargsUnboundMethods(TestGetcallargsMethods):
+
+    def makeCallable(self, signature):
+        super(TestGetcallargsUnboundMethods, self).makeCallable(signature)
+        return self.cls.method
+
+    def assertEqualCallArgs(self, func, call_params_string, locs=None):
+        return super(TestGetcallargsUnboundMethods, self).assertEqualCallArgs(
+            *self._getAssertEqualParams(func, call_params_string, locs))
+
+    def assertEqualException(self, func, call_params_string, locs=None):
+        return super(TestGetcallargsUnboundMethods, self).assertEqualException(
+            *self._getAssertEqualParams(func, call_params_string, locs))
+
+    def _getAssertEqualParams(self, func, call_params_string, locs=None):
+        assert 'inst' not in call_params_string
+        locs = dict(locs or {}, inst=self.inst)
+        return (func, 'inst,' + call_params_string, locs)
+
+
+class TestGetattrStatic(unittest.TestCase):
+
+    def test_basic(self):
+        class Thing(object):
+            x = object()
+
+        thing = Thing()
+        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
+        self.assertEqual(inspect.getattr_static(thing, 'x', None), Thing.x)
+        with self.assertRaises(AttributeError):
+            inspect.getattr_static(thing, 'y')
+
+        self.assertEqual(inspect.getattr_static(thing, 'y', 3), 3)
+
+    def test_inherited(self):
+        class Thing(object):
+            x = object()
+        class OtherThing(Thing):
+            pass
+
+        something = OtherThing()
+        self.assertEqual(inspect.getattr_static(something, 'x'), Thing.x)
+
+    def test_instance_attr(self):
+        class Thing(object):
+            x = 2
+            def __init__(self, x):
+                self.x = x
+        thing = Thing(3)
+        self.assertEqual(inspect.getattr_static(thing, 'x'), 3)
+        del thing.x
+        self.assertEqual(inspect.getattr_static(thing, 'x'), 2)
+
+    def test_property(self):
+        class Thing(object):
+            @property
+            def x(self):
+                raise AttributeError("I'm pretending not to exist")
+        thing = Thing()
+        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
+
+    def test_descriptor_raises_AttributeError(self):
+        class descriptor(object):
+            def __get__(*_):
+                raise AttributeError("I'm pretending not to exist")
+        desc = descriptor()
+        class Thing(object):
+            x = desc
+        thing = Thing()
+        self.assertEqual(inspect.getattr_static(thing, 'x'), desc)
+
+    def test_classAttribute(self):
+        class Thing(object):
+            x = object()
+
+        self.assertEqual(inspect.getattr_static(Thing, 'x'), Thing.x)
+
+    def test_classVirtualAttribute(self):
+        class Thing(object):
+            @types.DynamicClassAttribute
+            def x(self):
+                return self._x
+            _x = object()
+
+        self.assertEqual(inspect.getattr_static(Thing, 'x'), Thing.__dict__['x'])
+
+    def test_inherited_classattribute(self):
+        class Thing(object):
+            x = object()
+        class OtherThing(Thing):
+            pass
+
+        self.assertEqual(inspect.getattr_static(OtherThing, 'x'), Thing.x)
+
+    def test_slots(self):
+        class Thing(object):
+            y = 'bar'
+            __slots__ = ['x']
+            def __init__(self):
+                self.x = 'foo'
+        thing = Thing()
+        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
+        self.assertEqual(inspect.getattr_static(thing, 'y'), 'bar')
+
+        del thing.x
+        self.assertEqual(inspect.getattr_static(thing, 'x'), Thing.x)
+
+    def test_metaclass(self):
+        class meta(type):
+            attr = 'foo'
+        class Thing(object, metaclass=meta):
+            pass
+        self.assertEqual(inspect.getattr_static(Thing, 'attr'), 'foo')
+
+        class sub(meta):
+            pass
+        class OtherThing(object, metaclass=sub):
+            x = 3
+        self.assertEqual(inspect.getattr_static(OtherThing, 'attr'), 'foo')
+
+        class OtherOtherThing(OtherThing):
+            pass
+        # this test is odd, but it was added as it exposed a bug
+        self.assertEqual(inspect.getattr_static(OtherOtherThing, 'x'), 3)
+
+    def test_no_dict_no_slots(self):
+        self.assertEqual(inspect.getattr_static(1, 'foo', None), None)
+        self.assertNotEqual(inspect.getattr_static('foo', 'lower'), None)
+
+    def test_no_dict_no_slots_instance_member(self):
+        # returns descriptor
+        with open(__file__, encoding='utf-8') as handle:
+            self.assertEqual(inspect.getattr_static(handle, 'name'), type(handle).name)
+
+    def test_inherited_slots(self):
+        # returns descriptor
+        class Thing(object):
+            __slots__ = ['x']
+            def __init__(self):
+                self.x = 'foo'
+
+        class OtherThing(Thing):
+            pass
+        # it would be nice if this worked...
+        # we get the descriptor instead of the instance attribute
+        self.assertEqual(inspect.getattr_static(OtherThing(), 'x'), Thing.x)
+
+    def test_descriptor(self):
+        class descriptor(object):
+            def __get__(self, instance, owner):
+                return 3
+        class Foo(object):
+            d = descriptor()
+
+        foo = Foo()
+
+        # for a non data descriptor we return the instance attribute
+        foo.__dict__['d'] = 1
+        self.assertEqual(inspect.getattr_static(foo, 'd'), 1)
+
+        # if the descriptor is a data-descriptor we should return the
+        # descriptor
+        descriptor.__set__ = lambda s, i, v: None
+        self.assertEqual(inspect.getattr_static(foo, 'd'), Foo.__dict__['d'])
+
+        del descriptor.__set__
+        descriptor.__delete__ = lambda s, i, o: None
+        self.assertEqual(inspect.getattr_static(foo, 'd'), Foo.__dict__['d'])
+
+    def test_metaclass_with_descriptor(self):
+        class descriptor(object):
+            def __get__(self, instance, owner):
+                return 3
+        class meta(type):
+            d = descriptor()
+        class Thing(object, metaclass=meta):
+            pass
+        self.assertEqual(inspect.getattr_static(Thing, 'd'), meta.__dict__['d'])
+
+
+    def test_class_as_property(self):
+        class Base(object):
+            foo = 3
+
+        class Something(Base):
+            executed = False
+            @property
+            def __class__(self):
+                self.executed = True
+                return object
+
+        instance = Something()
+        self.assertEqual(inspect.getattr_static(instance, 'foo'), 3)
+        self.assertFalse(instance.executed)
+        self.assertEqual(inspect.getattr_static(Something, 'foo'), 3)
+
+    def test_mro_as_property(self):
+        class Meta(type):
+            @property
+            def __mro__(self):
+                return (object,)
+
+        class Base(object):
+            foo = 3
+
+        class Something(Base, metaclass=Meta):
+            pass
+
+        self.assertEqual(inspect.getattr_static(Something(), 'foo'), 3)
+        self.assertEqual(inspect.getattr_static(Something, 'foo'), 3)
+
+    def test_dict_as_property(self):
+        test = self
+        test.called = False
+
+        class Foo(dict):
+            a = 3
+            @property
+            def __dict__(self):
+                test.called = True
+                return {}
+
+        foo = Foo()
+        foo.a = 4
+        self.assertEqual(inspect.getattr_static(foo, 'a'), 3)
+        self.assertFalse(test.called)
+
+    def test_mutated_mro(self):
+        test = self
+        test.called = False
+
+        class Foo(dict):
+            a = 3
+            @property
+            def __dict__(self):
+                test.called = True
+                return {}
+
+        class Bar(dict):
+            a = 4
+
+        class Baz(Bar): pass
+
+        baz = Baz()
+        self.assertEqual(inspect.getattr_static(baz, 'a'), 4)
+        Baz.__bases__ = (Foo,)
+        self.assertEqual(inspect.getattr_static(baz, 'a'), 3)
+        self.assertFalse(test.called)
+
+    def test_custom_object_dict(self):
+        test = self
+        test.called = False
+
+        class Custom(dict):
+            def get(self, key, default=None):
+                test.called = True
+                super().get(key, default)
+
+        class Foo(object):
+            a = 3
+        foo = Foo()
+        foo.__dict__ = Custom()
+        self.assertEqual(inspect.getattr_static(foo, 'a'), 3)
+        self.assertFalse(test.called)
+
+    def test_metaclass_dict_as_property(self):
+        class Meta(type):
+            @property
+            def __dict__(self):
+                self.executed = True
+
+        class Thing(metaclass=Meta):
+            executed = False
+
+            def __init__(self):
+                self.spam = 42
+
+        instance = Thing()
+        self.assertEqual(inspect.getattr_static(instance, "spam"), 42)
+        self.assertFalse(Thing.executed)
+
+    def test_module(self):
+        sentinel = object()
+        self.assertIsNot(inspect.getattr_static(sys, "version", sentinel),
+                         sentinel)
+
+    def test_metaclass_with_metaclass_with_dict_as_property(self):
+        class MetaMeta(type):
+            @property
+            def __dict__(self):
+                self.executed = True
+                return dict(spam=42)
+
+        class Meta(type, metaclass=MetaMeta):
+            executed = False
+
+        class Thing(metaclass=Meta):
+            pass
+
+        with self.assertRaises(AttributeError):
+            inspect.getattr_static(Thing, "spam")
+        self.assertFalse(Thing.executed)
+
+    def test_custom___getattr__(self):
+        test = self
+        test.called = False
+
+        class Foo:
+            def __getattr__(self, attr):
+                test.called = True
+                return {}
+
+        with self.assertRaises(AttributeError):
+            inspect.getattr_static(Foo(), 'whatever')
+
+        self.assertFalse(test.called)
+
+    def test_custom___getattribute__(self):
+        test = self
+        test.called = False
+
+        class Foo:
+            def __getattribute__(self, attr):
+                test.called = True
+                return {}
+
+        with self.assertRaises(AttributeError):
+            inspect.getattr_static(Foo(), 'really_could_be_anything')
+
+        self.assertFalse(test.called)
+
+
+class TestGetGeneratorState(unittest.TestCase):
+
+    def setUp(self):
+        def number_generator():
+            for number in range(5):
+                yield number
+        self.generator = number_generator()
+
+    def _generatorstate(self):
+        return inspect.getgeneratorstate(self.generator)
+
+    def test_created(self):
+        self.assertEqual(self._generatorstate(), inspect.GEN_CREATED)
+
+    def test_suspended(self):
+        next(self.generator)
+        self.assertEqual(self._generatorstate(), inspect.GEN_SUSPENDED)
+
+    def test_closed_after_exhaustion(self):
+        for i in self.generator:
+            pass
+        self.assertEqual(self._generatorstate(), inspect.GEN_CLOSED)
+
+    def test_closed_after_immediate_exception(self):
+        with self.assertRaises(RuntimeError):
+            self.generator.throw(RuntimeError)
+        self.assertEqual(self._generatorstate(), inspect.GEN_CLOSED)
+
+    def test_running(self):
+        # As mentioned on issue #10220, checking for the RUNNING state only
+        # makes sense inside the generator itself.
+        # The following generator checks for this by using the closure's
+        # reference to self and the generator state checking helper method
+        def running_check_generator():
+            for number in range(5):
+                self.assertEqual(self._generatorstate(), inspect.GEN_RUNNING)
+                yield number
+                self.assertEqual(self._generatorstate(), inspect.GEN_RUNNING)
+        self.generator = running_check_generator()
+        # Running up to the first yield
+        next(self.generator)
+        # Running after the first yield
+        next(self.generator)
+
+    def test_easy_debugging(self):
+        # repr() and str() of a generator state should contain the state name
+        names = 'GEN_CREATED GEN_RUNNING GEN_SUSPENDED GEN_CLOSED'.split()
+        for name in names:
+            state = getattr(inspect, name)
+            self.assertIn(name, repr(state))
+            self.assertIn(name, str(state))
+
+    def test_getgeneratorlocals(self):
+        def each(lst, a=None):
+            b=(1, 2, 3)
+            for v in lst:
+                if v == 3:
+                    c = 12
+                yield v
+
+        numbers = each([1, 2, 3])
+        self.assertEqual(inspect.getgeneratorlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3]})
+        next(numbers)
+        self.assertEqual(inspect.getgeneratorlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3], 'v': 1,
+                          'b': (1, 2, 3)})
+        next(numbers)
+        self.assertEqual(inspect.getgeneratorlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3], 'v': 2,
+                          'b': (1, 2, 3)})
+        next(numbers)
+        self.assertEqual(inspect.getgeneratorlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3], 'v': 3,
+                          'b': (1, 2, 3), 'c': 12})
+        try:
+            next(numbers)
+        except StopIteration:
+            pass
+        self.assertEqual(inspect.getgeneratorlocals(numbers), {})
+
+    def test_getgeneratorlocals_empty(self):
+        def yield_one():
+            yield 1
+        one = yield_one()
+        self.assertEqual(inspect.getgeneratorlocals(one), {})
+        try:
+            next(one)
+        except StopIteration:
+            pass
+        self.assertEqual(inspect.getgeneratorlocals(one), {})
+
+    def test_getgeneratorlocals_error(self):
+        self.assertRaises(TypeError, inspect.getgeneratorlocals, 1)
+        self.assertRaises(TypeError, inspect.getgeneratorlocals, lambda x: True)
+        self.assertRaises(TypeError, inspect.getgeneratorlocals, set)
+        self.assertRaises(TypeError, inspect.getgeneratorlocals, (2,3))
+
+
+class TestGetCoroutineState(unittest.TestCase):
+
+    def setUp(self):
+        @types.coroutine
+        def number_coroutine():
+            for number in range(5):
+                yield number
+        async def coroutine():
+            await number_coroutine()
+        self.coroutine = coroutine()
+
+    def tearDown(self):
+        self.coroutine.close()
+
+    def _coroutinestate(self):
+        return inspect.getcoroutinestate(self.coroutine)
+
+    def test_created(self):
+        self.assertEqual(self._coroutinestate(), inspect.CORO_CREATED)
+
+    def test_suspended(self):
+        self.coroutine.send(None)
+        self.assertEqual(self._coroutinestate(), inspect.CORO_SUSPENDED)
+
+    def test_closed_after_exhaustion(self):
+        while True:
+            try:
+                self.coroutine.send(None)
+            except StopIteration:
+                break
+
+        self.assertEqual(self._coroutinestate(), inspect.CORO_CLOSED)
+
+    def test_closed_after_immediate_exception(self):
+        with self.assertRaises(RuntimeError):
+            self.coroutine.throw(RuntimeError)
+        self.assertEqual(self._coroutinestate(), inspect.CORO_CLOSED)
+
+    def test_easy_debugging(self):
+        # repr() and str() of a coroutine state should contain the state name
+        names = 'CORO_CREATED CORO_RUNNING CORO_SUSPENDED CORO_CLOSED'.split()
+        for name in names:
+            state = getattr(inspect, name)
+            self.assertIn(name, repr(state))
+            self.assertIn(name, str(state))
+
+    def test_getcoroutinelocals(self):
+        @types.coroutine
+        def gencoro():
+            yield
+
+        gencoro = gencoro()
+        async def func(a=None):
+            b = 'spam'
+            await gencoro
+
+        coro = func()
+        self.assertEqual(inspect.getcoroutinelocals(coro),
+                         {'a': None, 'gencoro': gencoro})
+        coro.send(None)
+        self.assertEqual(inspect.getcoroutinelocals(coro),
+                         {'a': None, 'gencoro': gencoro, 'b': 'spam'})
+
+
+@support.requires_working_socket()
+class TestGetAsyncGenState(unittest.IsolatedAsyncioTestCase):
+
+    def setUp(self):
+        async def number_asyncgen():
+            for number in range(5):
+                yield number
+        self.asyncgen = number_asyncgen()
+
+    async def asyncTearDown(self):
+        await self.asyncgen.aclose()
+
+    def _asyncgenstate(self):
+        return inspect.getasyncgenstate(self.asyncgen)
+
+    def test_created(self):
+        self.assertEqual(self._asyncgenstate(), inspect.AGEN_CREATED)
+
+    async def test_suspended(self):
+        value = await anext(self.asyncgen)
+        self.assertEqual(self._asyncgenstate(), inspect.AGEN_SUSPENDED)
+        self.assertEqual(value, 0)
+
+    async def test_closed_after_exhaustion(self):
+        countdown = 7
+        with self.assertRaises(StopAsyncIteration):
+            while countdown := countdown - 1:
+                await anext(self.asyncgen)
+        self.assertEqual(countdown, 1)
+        self.assertEqual(self._asyncgenstate(), inspect.AGEN_CLOSED)
+
+    async def test_closed_after_immediate_exception(self):
+        with self.assertRaises(RuntimeError):
+            await self.asyncgen.athrow(RuntimeError)
+        self.assertEqual(self._asyncgenstate(), inspect.AGEN_CLOSED)
+
+    async def test_running(self):
+        async def running_check_asyncgen():
+            for number in range(5):
+                self.assertEqual(self._asyncgenstate(), inspect.AGEN_RUNNING)
+                yield number
+                self.assertEqual(self._asyncgenstate(), inspect.AGEN_RUNNING)
+        self.asyncgen = running_check_asyncgen()
+        # Running up to the first yield
+        await anext(self.asyncgen)
+        self.assertEqual(self._asyncgenstate(), inspect.AGEN_SUSPENDED)
+        # Running after the first yield
+        await anext(self.asyncgen)
+        self.assertEqual(self._asyncgenstate(), inspect.AGEN_SUSPENDED)
+
+    def test_easy_debugging(self):
+        # repr() and str() of a asyncgen state should contain the state name
+        names = 'AGEN_CREATED AGEN_RUNNING AGEN_SUSPENDED AGEN_CLOSED'.split()
+        for name in names:
+            state = getattr(inspect, name)
+            self.assertIn(name, repr(state))
+            self.assertIn(name, str(state))
+
+    async def test_getasyncgenlocals(self):
+        async def each(lst, a=None):
+            b=(1, 2, 3)
+            for v in lst:
+                if v == 3:
+                    c = 12
+                yield v
+
+        numbers = each([1, 2, 3])
+        self.assertEqual(inspect.getasyncgenlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3]})
+        await anext(numbers)
+        self.assertEqual(inspect.getasyncgenlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3], 'v': 1,
+                          'b': (1, 2, 3)})
+        await anext(numbers)
+        self.assertEqual(inspect.getasyncgenlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3], 'v': 2,
+                          'b': (1, 2, 3)})
+        await anext(numbers)
+        self.assertEqual(inspect.getasyncgenlocals(numbers),
+                         {'a': None, 'lst': [1, 2, 3], 'v': 3,
+                          'b': (1, 2, 3), 'c': 12})
+        with self.assertRaises(StopAsyncIteration):
+            await anext(numbers)
+        self.assertEqual(inspect.getasyncgenlocals(numbers), {})
+
+    async def test_getasyncgenlocals_empty(self):
+        async def yield_one():
+            yield 1
+        one = yield_one()
+        self.assertEqual(inspect.getasyncgenlocals(one), {})
+        await anext(one)
+        self.assertEqual(inspect.getasyncgenlocals(one), {})
+        with self.assertRaises(StopAsyncIteration):
+            await anext(one)
+        self.assertEqual(inspect.getasyncgenlocals(one), {})
+
+    def test_getasyncgenlocals_error(self):
+        self.assertRaises(TypeError, inspect.getasyncgenlocals, 1)
+        self.assertRaises(TypeError, inspect.getasyncgenlocals, lambda x: True)
+        self.assertRaises(TypeError, inspect.getasyncgenlocals, set)
+        self.assertRaises(TypeError, inspect.getasyncgenlocals, (2,3))
+
+
+class MySignature(inspect.Signature):
+    # Top-level to make it picklable;
+    # used in test_signature_object_pickle
+    pass
+
+class MyParameter(inspect.Parameter):
+    # Top-level to make it picklable;
+    # used in test_signature_object_pickle
+    pass
+
+
+
+class TestSignatureObject(unittest.TestCase):
+    @staticmethod
+    def signature(func, **kw):
+        sig = inspect.signature(func, **kw)
+        return (tuple((param.name,
+                       (... if param.default is param.empty else param.default),
+                       (... if param.annotation is param.empty
+                                                        else param.annotation),
+                       str(param.kind).lower())
+                                    for param in sig.parameters.values()),
+                (... if sig.return_annotation is sig.empty
+                                            else sig.return_annotation))
+
+    def test_signature_object(self):
+        S = inspect.Signature
+        P = inspect.Parameter
+
+        self.assertEqual(str(S()), '()')
+        self.assertEqual(repr(S().parameters), 'mappingproxy(OrderedDict())')
+
+        def test(po, /, pk, pkd=100, *args, ko, kod=10, **kwargs):
+            pass
+
+        sig = inspect.signature(test)
+        self.assertTrue(repr(sig).startswith('<Signature'))
+        self.assertTrue('(po, /, pk' in repr(sig))
+
+        # We need two functions, because it is impossible to represent
+        # all param kinds in a single one.
+        def test2(pod=42, /):
+            pass
+
+        sig2 = inspect.signature(test2)
+        self.assertTrue(repr(sig2).startswith('<Signature'))
+        self.assertTrue('(pod=42, /)' in repr(sig2))
+
+        po = sig.parameters['po']
+        pod = sig2.parameters['pod']
+        pk = sig.parameters['pk']
+        pkd = sig.parameters['pkd']
+        args = sig.parameters['args']
+        ko = sig.parameters['ko']
+        kod = sig.parameters['kod']
+        kwargs = sig.parameters['kwargs']
+
+        S((po, pk, args, ko, kwargs))
+        S((po, pk, ko, kod))
+        S((po, pod, ko))
+        S((po, pod, kod))
+        S((pod, ko, kod))
+        S((pod, kod))
+        S((pod, args, kod, kwargs))
+        # keyword-only parameters without default values
+        # can follow keyword-only parameters with default values:
+        S((kod, ko))
+        S((kod, ko, kwargs))
+        S((args, kod, ko))
+
+        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
+            S((pk, po, args, ko, kwargs))
+
+        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
+            S((po, args, pk, ko, kwargs))
+
+        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
+            S((args, po, pk, ko, kwargs))
+
+        with self.assertRaisesRegex(ValueError, 'wrong parameter order'):
+            S((po, pk, args, kwargs, ko))
+
+        kwargs2 = kwargs.replace(name='args')
+        with self.assertRaisesRegex(ValueError, 'duplicate parameter name'):
+            S((po, pk, args, kwargs2, ko))
+
+        with self.assertRaisesRegex(ValueError, 'follows default argument'):
+            S((pod, po))
+
+        with self.assertRaisesRegex(ValueError, 'follows default argument'):
+            S((pod, pk))
+
+        with self.assertRaisesRegex(ValueError, 'follows default argument'):
+            S((po, pod, pk))
+
+        with self.assertRaisesRegex(ValueError, 'follows default argument'):
+            S((po, pkd, pk))
+
+        with self.assertRaisesRegex(ValueError, 'follows default argument'):
+            S((pkd, pk))
+
+    def test_signature_object_pickle(self):
+        def foo(a, b, *, c:1={}, **kw) -> {42:'ham'}: pass
+        foo_partial = functools.partial(foo, a=1)
+
+        sig = inspect.signature(foo_partial)
+
+        for ver in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(pickle_ver=ver, subclass=False):
+                sig_pickled = pickle.loads(pickle.dumps(sig, ver))
+                self.assertEqual(sig, sig_pickled)
+
+        # Test that basic sub-classing works
+        sig = inspect.signature(foo)
+        myparam = MyParameter(name='z', kind=inspect.Parameter.POSITIONAL_ONLY)
+        myparams = collections.OrderedDict(sig.parameters, a=myparam)
+        mysig = MySignature().replace(parameters=myparams.values(),
+                                      return_annotation=sig.return_annotation)
+        self.assertTrue(isinstance(mysig, MySignature))
+        self.assertTrue(isinstance(mysig.parameters['z'], MyParameter))
+
+        for ver in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(pickle_ver=ver, subclass=True):
+                sig_pickled = pickle.loads(pickle.dumps(mysig, ver))
+                self.assertEqual(mysig, sig_pickled)
+                self.assertTrue(isinstance(sig_pickled, MySignature))
+                self.assertTrue(isinstance(sig_pickled.parameters['z'],
+                                           MyParameter))
+
+    def test_signature_immutability(self):
+        def test(a):
+            pass
+        sig = inspect.signature(test)
+
+        with self.assertRaises(AttributeError):
+            sig.foo = 'bar'
+
+        with self.assertRaises(TypeError):
+            sig.parameters['a'] = None
+
+    def test_signature_on_noarg(self):
+        def test():
+            pass
+        self.assertEqual(self.signature(test), ((), ...))
+
+    def test_signature_on_wargs(self):
+        def test(a, b:'foo') -> 123:
+            pass
+        self.assertEqual(self.signature(test),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., 'foo', "positional_or_keyword")),
+                          123))
+
+    def test_signature_on_wkwonly(self):
+        def test(*, a:float, b:str) -> int:
+            pass
+        self.assertEqual(self.signature(test),
+                         ((('a', ..., float, "keyword_only"),
+                           ('b', ..., str, "keyword_only")),
+                           int))
+
+    def test_signature_on_complex_args(self):
+        def test(a, b:'foo'=10, *args:'bar', spam:'baz', ham=123, **kwargs:int):
+            pass
+        self.assertEqual(self.signature(test),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', 10, 'foo', "positional_or_keyword"),
+                           ('args', ..., 'bar', "var_positional"),
+                           ('spam', ..., 'baz', "keyword_only"),
+                           ('ham', 123, ..., "keyword_only"),
+                           ('kwargs', ..., int, "var_keyword")),
+                          ...))
+
+    def test_signature_without_self(self):
+        def test_args_only(*args):  # NOQA
+            pass
+
+        def test_args_kwargs_only(*args, **kwargs):  # NOQA
+            pass
+
+        class A:
+            @classmethod
+            def test_classmethod(*args):  # NOQA
+                pass
+
+            @staticmethod
+            def test_staticmethod(*args):  # NOQA
+                pass
+
+            f1 = functools.partialmethod((test_classmethod), 1)
+            f2 = functools.partialmethod((test_args_only), 1)
+            f3 = functools.partialmethod((test_staticmethod), 1)
+            f4 = functools.partialmethod((test_args_kwargs_only),1)
+
+        self.assertEqual(self.signature(test_args_only),
+                         ((('args', ..., ..., 'var_positional'),), ...))
+        self.assertEqual(self.signature(test_args_kwargs_only),
+                         ((('args', ..., ..., 'var_positional'),
+                           ('kwargs', ..., ..., 'var_keyword')), ...))
+        self.assertEqual(self.signature(A.f1),
+                         ((('args', ..., ..., 'var_positional'),), ...))
+        self.assertEqual(self.signature(A.f2),
+                         ((('args', ..., ..., 'var_positional'),), ...))
+        self.assertEqual(self.signature(A.f3),
+                         ((('args', ..., ..., 'var_positional'),), ...))
+        self.assertEqual(self.signature(A.f4),
+                         ((('args', ..., ..., 'var_positional'),
+                            ('kwargs', ..., ..., 'var_keyword')), ...))
+    @cpython_only
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_signature_on_builtins(self):
+        import _testcapi
+
+        def test_unbound_method(o):
+            """Use this to test unbound methods (things that should have a self)"""
+            signature = inspect.signature(o)
+            self.assertTrue(isinstance(signature, inspect.Signature))
+            self.assertEqual(list(signature.parameters.values())[0].name, 'self')
+            return signature
+
+        def test_callable(o):
+            """Use this to test bound methods or normal callables (things that don't expect self)"""
+            signature = inspect.signature(o)
+            self.assertTrue(isinstance(signature, inspect.Signature))
+            if signature.parameters:
+                self.assertNotEqual(list(signature.parameters.values())[0].name, 'self')
+            return signature
+
+        signature = test_callable(_testcapi.docstring_with_signature_with_defaults)
+        def p(name): return signature.parameters[name].default
+        self.assertEqual(p('s'), 'avocado')
+        self.assertEqual(p('b'), b'bytes')
+        self.assertEqual(p('d'), 3.14)
+        self.assertEqual(p('i'), 35)
+        self.assertEqual(p('n'), None)
+        self.assertEqual(p('t'), True)
+        self.assertEqual(p('f'), False)
+        self.assertEqual(p('local'), 3)
+        self.assertEqual(p('sys'), sys.maxsize)
+        self.assertEqual(p('exp'), sys.maxsize - 1)
+
+        test_callable(object)
+
+        # normal method
+        # (PyMethodDescr_Type, "method_descriptor")
+        test_unbound_method(_pickle.Pickler.dump)
+        d = _pickle.Pickler(io.StringIO())
+        test_callable(d.dump)
+
+        # static method
+        test_callable(bytes.maketrans)
+        test_callable(b'abc'.maketrans)
+
+        # class method
+        test_callable(dict.fromkeys)
+        test_callable({}.fromkeys)
+
+        # wrapper around slot (PyWrapperDescr_Type, "wrapper_descriptor")
+        test_unbound_method(type.__call__)
+        test_unbound_method(int.__add__)
+        test_callable((3).__add__)
+
+        # _PyMethodWrapper_Type
+        # support for 'method-wrapper'
+        test_callable(min.__call__)
+
+        # This doesn't work now.
+        # (We don't have a valid signature for "type" in 3.4)
+        with self.assertRaisesRegex(ValueError, "no signature found"):
+            class ThisWorksNow:
+                __call__ = type
+            test_callable(ThisWorksNow())
+
+        # Regression test for issue #20786
+        test_unbound_method(dict.__delitem__)
+        test_unbound_method(property.__delete__)
+
+        # Regression test for issue #20586
+        test_callable(_testcapi.docstring_with_signature_but_no_doc)
+
+        # Regression test for gh-104955
+        method = bytearray.__release_buffer__
+        sig = test_unbound_method(method)
+        self.assertEqual(list(sig.parameters), ['self', 'buffer'])
+
+    @cpython_only
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_signature_on_decorated_builtins(self):
+        import _testcapi
+        func = _testcapi.docstring_with_signature_with_defaults
+
+        def decorator(func):
+            @functools.wraps(func)
+            def wrapper(*args, **kwargs) -> int:
+                return func(*args, **kwargs)
+            return wrapper
+
+        decorated_func = decorator(func)
+
+        self.assertEqual(inspect.signature(func),
+                         inspect.signature(decorated_func))
+
+        def wrapper_like(*args, **kwargs) -> int: pass
+        self.assertEqual(inspect.signature(decorated_func,
+                                           follow_wrapped=False),
+                         inspect.signature(wrapper_like))
+
+    @cpython_only
+    def test_signature_on_builtins_no_signature(self):
+        import _testcapi
+        with self.assertRaisesRegex(ValueError,
+                                    'no signature found for builtin'):
+            inspect.signature(_testcapi.docstring_no_signature)
+
+        with self.assertRaisesRegex(ValueError,
+                                    'no signature found for builtin'):
+            inspect.signature(str)
+
+    def test_signature_on_non_function(self):
+        with self.assertRaisesRegex(TypeError, 'is not a callable object'):
+            inspect.signature(42)
+
+    def test_signature_from_functionlike_object(self):
+        def func(a,b, *args, kwonly=True, kwonlyreq, **kwargs):
+            pass
+
+        class funclike:
+            # Has to be callable, and have correct
+            # __code__, __annotations__, __defaults__, __name__,
+            # and __kwdefaults__ attributes
+
+            def __init__(self, func):
+                self.__name__ = func.__name__
+                self.__code__ = func.__code__
+                self.__annotations__ = func.__annotations__
+                self.__defaults__ = func.__defaults__
+                self.__kwdefaults__ = func.__kwdefaults__
+                self.func = func
+
+            def __call__(self, *args, **kwargs):
+                return self.func(*args, **kwargs)
+
+        sig_func = inspect.Signature.from_callable(func)
+
+        sig_funclike = inspect.Signature.from_callable(funclike(func))
+        self.assertEqual(sig_funclike, sig_func)
+
+        sig_funclike = inspect.signature(funclike(func))
+        self.assertEqual(sig_funclike, sig_func)
+
+        # If object is not a duck type of function, then
+        # signature will try to get a signature for its '__call__'
+        # method
+        fl = funclike(func)
+        del fl.__defaults__
+        self.assertEqual(self.signature(fl),
+                         ((('args', ..., ..., "var_positional"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                           ...))
+
+        # Test with cython-like builtins:
+        _orig_isdesc = inspect.ismethoddescriptor
+        def _isdesc(obj):
+            if hasattr(obj, '_builtinmock'):
+                return True
+            return _orig_isdesc(obj)
+
+        with unittest.mock.patch('inspect.ismethoddescriptor', _isdesc):
+            builtin_func = funclike(func)
+            # Make sure that our mock setup is working
+            self.assertFalse(inspect.ismethoddescriptor(builtin_func))
+            builtin_func._builtinmock = True
+            self.assertTrue(inspect.ismethoddescriptor(builtin_func))
+            self.assertEqual(inspect.signature(builtin_func), sig_func)
+
+    def test_signature_functionlike_class(self):
+        # We only want to duck type function-like objects,
+        # not classes.
+
+        def func(a,b, *args, kwonly=True, kwonlyreq, **kwargs):
+            pass
+
+        class funclike:
+            def __init__(self, marker):
+                pass
+
+            __name__ = func.__name__
+            __code__ = func.__code__
+            __annotations__ = func.__annotations__
+            __defaults__ = func.__defaults__
+            __kwdefaults__ = func.__kwdefaults__
+
+        self.assertEqual(str(inspect.signature(funclike)), '(marker)')
+
+    def test_signature_on_method(self):
+        class Test:
+            def __init__(*args):
+                pass
+            def m1(self, arg1, arg2=1) -> int:
+                pass
+            def m2(*args):
+                pass
+            def __call__(*, a):
+                pass
+
+        self.assertEqual(self.signature(Test().m1),
+                         ((('arg1', ..., ..., "positional_or_keyword"),
+                           ('arg2', 1, ..., "positional_or_keyword")),
+                          int))
+
+        self.assertEqual(self.signature(Test().m2),
+                         ((('args', ..., ..., "var_positional"),),
+                          ...))
+
+        self.assertEqual(self.signature(Test),
+                         ((('args', ..., ..., "var_positional"),),
+                          ...))
+
+        with self.assertRaisesRegex(ValueError, 'invalid method signature'):
+            self.signature(Test())
+
+    def test_signature_wrapped_bound_method(self):
+        # Issue 24298
+        class Test:
+            def m1(self, arg1, arg2=1) -> int:
+                pass
+        @functools.wraps(Test().m1)
+        def m1d(*args, **kwargs):
+            pass
+        self.assertEqual(self.signature(m1d),
+                         ((('arg1', ..., ..., "positional_or_keyword"),
+                           ('arg2', 1, ..., "positional_or_keyword")),
+                          int))
+
+    def test_signature_on_classmethod(self):
+        class Test:
+            @classmethod
+            def foo(cls, arg1, *, arg2=1):
+                pass
+
+        meth = Test().foo
+        self.assertEqual(self.signature(meth),
+                         ((('arg1', ..., ..., "positional_or_keyword"),
+                           ('arg2', 1, ..., "keyword_only")),
+                          ...))
+
+        meth = Test.foo
+        self.assertEqual(self.signature(meth),
+                         ((('arg1', ..., ..., "positional_or_keyword"),
+                           ('arg2', 1, ..., "keyword_only")),
+                          ...))
+
+    def test_signature_on_staticmethod(self):
+        class Test:
+            @staticmethod
+            def foo(cls, *, arg):
+                pass
+
+        meth = Test().foo
+        self.assertEqual(self.signature(meth),
+                         ((('cls', ..., ..., "positional_or_keyword"),
+                           ('arg', ..., ..., "keyword_only")),
+                          ...))
+
+        meth = Test.foo
+        self.assertEqual(self.signature(meth),
+                         ((('cls', ..., ..., "positional_or_keyword"),
+                           ('arg', ..., ..., "keyword_only")),
+                          ...))
+
+    def test_signature_on_partial(self):
+        from functools import partial
+
+        def test():
+            pass
+
+        self.assertEqual(self.signature(partial(test)), ((), ...))
+
+        with self.assertRaisesRegex(ValueError, "has incorrect arguments"):
+            inspect.signature(partial(test, 1))
+
+        with self.assertRaisesRegex(ValueError, "has incorrect arguments"):
+            inspect.signature(partial(test, a=1))
+
+        def test(a, b, *, c, d):
+            pass
+
+        self.assertEqual(self.signature(partial(test)),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., ..., "positional_or_keyword"),
+                           ('c', ..., ..., "keyword_only"),
+                           ('d', ..., ..., "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, 1)),
+                         ((('b', ..., ..., "positional_or_keyword"),
+                           ('c', ..., ..., "keyword_only"),
+                           ('d', ..., ..., "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, 1, c=2)),
+                         ((('b', ..., ..., "positional_or_keyword"),
+                           ('c', 2, ..., "keyword_only"),
+                           ('d', ..., ..., "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, b=1, c=2)),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', 1, ..., "keyword_only"),
+                           ('c', 2, ..., "keyword_only"),
+                           ('d', ..., ..., "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, 0, b=1, c=2)),
+                         ((('b', 1, ..., "keyword_only"),
+                           ('c', 2, ..., "keyword_only"),
+                           ('d', ..., ..., "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, a=1)),
+                         ((('a', 1, ..., "keyword_only"),
+                           ('b', ..., ..., "keyword_only"),
+                           ('c', ..., ..., "keyword_only"),
+                           ('d', ..., ..., "keyword_only")),
+                          ...))
+
+        def test(a, *args, b, **kwargs):
+            pass
+
+        self.assertEqual(self.signature(partial(test, 1)),
+                         ((('args', ..., ..., "var_positional"),
+                           ('b', ..., ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, a=1)),
+                         ((('a', 1, ..., "keyword_only"),
+                           ('b', ..., ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, 1, 2, 3)),
+                         ((('args', ..., ..., "var_positional"),
+                           ('b', ..., ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, 1, 2, 3, test=True)),
+                         ((('args', ..., ..., "var_positional"),
+                           ('b', ..., ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, 1, 2, 3, test=1, b=0)),
+                         ((('args', ..., ..., "var_positional"),
+                           ('b', 0, ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, b=0)),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('args', ..., ..., "var_positional"),
+                           ('b', 0, ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(partial(test, b=0, test=1)),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('args', ..., ..., "var_positional"),
+                           ('b', 0, ..., "keyword_only"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...))
+
+        def test(a, b, c:int) -> 42:
+            pass
+
+        sig = test.__signature__ = inspect.signature(test)
+
+        self.assertEqual(self.signature(partial(partial(test, 1))),
+                         ((('b', ..., ..., "positional_or_keyword"),
+                           ('c', ..., int, "positional_or_keyword")),
+                          42))
+
+        self.assertEqual(self.signature(partial(partial(test, 1), 2)),
+                         ((('c', ..., int, "positional_or_keyword"),),
+                          42))
+
+        def foo(a):
+            return a
+        _foo = partial(partial(foo, a=10), a=20)
+        self.assertEqual(self.signature(_foo),
+                         ((('a', 20, ..., "keyword_only"),),
+                          ...))
+        # check that we don't have any side-effects in signature(),
+        # and the partial object is still functioning
+        self.assertEqual(_foo(), 20)
+
+        def foo(a, b, c):
+            return a, b, c
+        _foo = partial(partial(foo, 1, b=20), b=30)
+
+        self.assertEqual(self.signature(_foo),
+                         ((('b', 30, ..., "keyword_only"),
+                           ('c', ..., ..., "keyword_only")),
+                          ...))
+        self.assertEqual(_foo(c=10), (1, 30, 10))
+
+        def foo(a, b, c, *, d):
+            return a, b, c, d
+        _foo = partial(partial(foo, d=20, c=20), b=10, d=30)
+        self.assertEqual(self.signature(_foo),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', 10, ..., "keyword_only"),
+                           ('c', 20, ..., "keyword_only"),
+                           ('d', 30, ..., "keyword_only"),
+                           ),
+                          ...))
+        ba = inspect.signature(_foo).bind(a=200, b=11)
+        self.assertEqual(_foo(*ba.args, **ba.kwargs), (200, 11, 20, 30))
+
+        def foo(a=1, b=2, c=3):
+            return a, b, c
+        _foo = partial(foo, c=13) # (a=1, b=2, *, c=13)
+
+        ba = inspect.signature(_foo).bind(a=11)
+        self.assertEqual(_foo(*ba.args, **ba.kwargs), (11, 2, 13))
+
+        ba = inspect.signature(_foo).bind(11, 12)
+        self.assertEqual(_foo(*ba.args, **ba.kwargs), (11, 12, 13))
+
+        ba = inspect.signature(_foo).bind(11, b=12)
+        self.assertEqual(_foo(*ba.args, **ba.kwargs), (11, 12, 13))
+
+        ba = inspect.signature(_foo).bind(b=12)
+        self.assertEqual(_foo(*ba.args, **ba.kwargs), (1, 12, 13))
+
+        _foo = partial(_foo, b=10, c=20)
+        ba = inspect.signature(_foo).bind(12)
+        self.assertEqual(_foo(*ba.args, **ba.kwargs), (12, 10, 20))
+
+
+        def foo(a, b, /, c, d, **kwargs):
+            pass
+        sig = inspect.signature(foo)
+        self.assertEqual(str(sig), '(a, b, /, c, d, **kwargs)')
+
+        self.assertEqual(self.signature(partial(foo, 1)),
+                         ((('b', ..., ..., 'positional_only'),
+                           ('c', ..., ..., 'positional_or_keyword'),
+                           ('d', ..., ..., 'positional_or_keyword'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                         ...))
+
+        self.assertEqual(self.signature(partial(foo, 1, 2)),
+                         ((('c', ..., ..., 'positional_or_keyword'),
+                           ('d', ..., ..., 'positional_or_keyword'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                         ...))
+
+        self.assertEqual(self.signature(partial(foo, 1, 2, 3)),
+                         ((('d', ..., ..., 'positional_or_keyword'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                         ...))
+
+        self.assertEqual(self.signature(partial(foo, 1, 2, c=3)),
+                         ((('c', 3, ..., 'keyword_only'),
+                           ('d', ..., ..., 'keyword_only'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                         ...))
+
+        self.assertEqual(self.signature(partial(foo, 1, c=3)),
+                         ((('b', ..., ..., 'positional_only'),
+                           ('c', 3, ..., 'keyword_only'),
+                           ('d', ..., ..., 'keyword_only'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                         ...))
+
+    def test_signature_on_partialmethod(self):
+        from functools import partialmethod
+
+        class Spam:
+            def test():
+                pass
+            ham = partialmethod(test)
+
+        with self.assertRaisesRegex(ValueError, "has incorrect arguments"):
+            inspect.signature(Spam.ham)
+
+        class Spam:
+            def test(it, a, *, c) -> 'spam':
+                pass
+            ham = partialmethod(test, c=1)
+
+        self.assertEqual(self.signature(Spam.ham, eval_str=False),
+                         ((('it', ..., ..., 'positional_or_keyword'),
+                           ('a', ..., ..., 'positional_or_keyword'),
+                           ('c', 1, ..., 'keyword_only')),
+                          'spam'))
+
+        self.assertEqual(self.signature(Spam().ham, eval_str=False),
+                         ((('a', ..., ..., 'positional_or_keyword'),
+                           ('c', 1, ..., 'keyword_only')),
+                          'spam'))
+
+        class Spam:
+            def test(self: 'anno', x):
+                pass
+
+            g = partialmethod(test, 1)
+
+        self.assertEqual(self.signature(Spam.g, eval_str=False),
+                         ((('self', ..., 'anno', 'positional_or_keyword'),),
+                          ...))
+
+    def test_signature_on_fake_partialmethod(self):
+        def foo(a): pass
+        foo._partialmethod = 'spam'
+        self.assertEqual(str(inspect.signature(foo)), '(a)')
+
+    def test_signature_on_decorated(self):
+        def decorator(func):
+            @functools.wraps(func)
+            def wrapper(*args, **kwargs) -> int:
+                return func(*args, **kwargs)
+            return wrapper
+
+        class Foo:
+            @decorator
+            def bar(self, a, b):
+                pass
+
+        bar = decorator(Foo().bar)
+
+        self.assertEqual(self.signature(Foo.bar),
+                         ((('self', ..., ..., "positional_or_keyword"),
+                           ('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., ..., "positional_or_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(Foo().bar),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., ..., "positional_or_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(Foo.bar, follow_wrapped=False),
+                         ((('args', ..., ..., "var_positional"),
+                           ('kwargs', ..., ..., "var_keyword")),
+                          ...)) # functools.wraps will copy __annotations__
+                                # from "func" to "wrapper", hence no
+                                # return_annotation
+
+        self.assertEqual(self.signature(bar),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., ..., "positional_or_keyword")),
+                          ...))
+
+        # Test that we handle method wrappers correctly
+        def decorator(func):
+            @functools.wraps(func)
+            def wrapper(*args, **kwargs) -> int:
+                return func(42, *args, **kwargs)
+            sig = inspect.signature(func)
+            new_params = tuple(sig.parameters.values())[1:]
+            wrapper.__signature__ = sig.replace(parameters=new_params)
+            return wrapper
+
+        class Foo:
+            @decorator
+            def __call__(self, a, b):
+                pass
+
+        self.assertEqual(self.signature(Foo.__call__),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., ..., "positional_or_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(Foo().__call__),
+                         ((('b', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        # Test we handle __signature__ partway down the wrapper stack
+        def wrapped_foo_call():
+            pass
+        wrapped_foo_call.__wrapped__ = Foo.__call__
+
+        self.assertEqual(self.signature(wrapped_foo_call),
+                         ((('a', ..., ..., "positional_or_keyword"),
+                           ('b', ..., ..., "positional_or_keyword")),
+                          ...))
+
+
+    def test_signature_on_class(self):
+        class C:
+            def __init__(self, a):
+                pass
+
+        self.assertEqual(self.signature(C),
+                         ((('a', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        class CM(type):
+            def __call__(cls, a):
+                pass
+        class C(metaclass=CM):
+            def __init__(self, b):
+                pass
+
+        self.assertEqual(self.signature(C),
+                         ((('a', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        class CM(type):
+            def __new__(mcls, name, bases, dct, *, foo=1):
+                return super().__new__(mcls, name, bases, dct)
+        class C(metaclass=CM):
+            def __init__(self, b):
+                pass
+
+        self.assertEqual(self.signature(C),
+                         ((('b', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        self.assertEqual(self.signature(CM),
+                         ((('name', ..., ..., "positional_or_keyword"),
+                           ('bases', ..., ..., "positional_or_keyword"),
+                           ('dct', ..., ..., "positional_or_keyword"),
+                           ('foo', 1, ..., "keyword_only")),
+                          ...))
+
+        class CMM(type):
+            def __new__(mcls, name, bases, dct, *, foo=1):
+                return super().__new__(mcls, name, bases, dct)
+            def __call__(cls, nm, bs, dt):
+                return type(nm, bs, dt)
+        class CM(type, metaclass=CMM):
+            def __new__(mcls, name, bases, dct, *, bar=2):
+                return super().__new__(mcls, name, bases, dct)
+        class C(metaclass=CM):
+            def __init__(self, b):
+                pass
+
+        self.assertEqual(self.signature(CMM),
+                         ((('name', ..., ..., "positional_or_keyword"),
+                           ('bases', ..., ..., "positional_or_keyword"),
+                           ('dct', ..., ..., "positional_or_keyword"),
+                           ('foo', 1, ..., "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(CM),
+                         ((('nm', ..., ..., "positional_or_keyword"),
+                           ('bs', ..., ..., "positional_or_keyword"),
+                           ('dt', ..., ..., "positional_or_keyword")),
+                          ...))
+
+        self.assertEqual(self.signature(C),
+                         ((('b', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        class CM(type):
+            def __init__(cls, name, bases, dct, *, bar=2):
+                return super().__init__(name, bases, dct)
+        class C(metaclass=CM):
+            def __init__(self, b):
+                pass
+
+        self.assertEqual(self.signature(CM),
+                         ((('name', ..., ..., "positional_or_keyword"),
+                           ('bases', ..., ..., "positional_or_keyword"),
+                           ('dct', ..., ..., "positional_or_keyword"),
+                           ('bar', 2, ..., "keyword_only")),
+                          ...))
+
+    def test_signature_on_subclass(self):
+        class A:
+            def __new__(cls, a=1, *args, **kwargs):
+                return object.__new__(cls)
+        class B(A):
+            def __init__(self, b):
+                pass
+        class C(A):
+            def __new__(cls, a=1, b=2, *args, **kwargs):
+                return object.__new__(cls)
+        class D(A):
+            pass
+
+        self.assertEqual(self.signature(B),
+                         ((('b', ..., ..., "positional_or_keyword"),),
+                          ...))
+        self.assertEqual(self.signature(C),
+                         ((('a', 1, ..., 'positional_or_keyword'),
+                           ('b', 2, ..., 'positional_or_keyword'),
+                           ('args', ..., ..., 'var_positional'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                          ...))
+        self.assertEqual(self.signature(D),
+                         ((('a', 1, ..., 'positional_or_keyword'),
+                           ('args', ..., ..., 'var_positional'),
+                           ('kwargs', ..., ..., 'var_keyword')),
+                          ...))
+
+    def test_signature_on_generic_subclass(self):
+        from typing import Generic, TypeVar
+
+        T = TypeVar('T')
+
+        class A(Generic[T]):
+            def __init__(self, *, a: int) -> None:
+                pass
+
+        self.assertEqual(self.signature(A),
+                         ((('a', ..., int, 'keyword_only'),),
+                          None))
+
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_signature_on_class_without_init(self):
+        # Test classes without user-defined __init__ or __new__
+        class C: pass
+        self.assertEqual(str(inspect.signature(C)), '()')
+        class D(C): pass
+        self.assertEqual(str(inspect.signature(D)), '()')
+
+        # Test meta-classes without user-defined __init__ or __new__
+        class C(type): pass
+        class D(C): pass
+        with self.assertRaisesRegex(ValueError, "callable.*is not supported"):
+            self.assertEqual(inspect.signature(C), None)
+        with self.assertRaisesRegex(ValueError, "callable.*is not supported"):
+            self.assertEqual(inspect.signature(D), None)
+
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_signature_on_builtin_class(self):
+        expected = ('(file, protocol=None, fix_imports=True, '
+                    'buffer_callback=None)')
+        self.assertEqual(str(inspect.signature(_pickle.Pickler)), expected)
+
+        class P(_pickle.Pickler): pass
+        class EmptyTrait: pass
+        class P2(EmptyTrait, P): pass
+        self.assertEqual(str(inspect.signature(P)), expected)
+        self.assertEqual(str(inspect.signature(P2)), expected)
+
+        class P3(P2):
+            def __init__(self, spam):
+                pass
+        self.assertEqual(str(inspect.signature(P3)), '(spam)')
+
+        class MetaP(type):
+            def __call__(cls, foo, bar):
+                pass
+        class P4(P2, metaclass=MetaP):
+            pass
+        self.assertEqual(str(inspect.signature(P4)), '(foo, bar)')
+
+    def test_signature_on_callable_objects(self):
+        class Foo:
+            def __call__(self, a):
+                pass
+
+        self.assertEqual(self.signature(Foo()),
+                         ((('a', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        class Spam:
+            pass
+        with self.assertRaisesRegex(TypeError, "is not a callable object"):
+            inspect.signature(Spam())
+
+        class Bar(Spam, Foo):
+            pass
+
+        self.assertEqual(self.signature(Bar()),
+                         ((('a', ..., ..., "positional_or_keyword"),),
+                          ...))
+
+        class Wrapped:
+            pass
+        Wrapped.__wrapped__ = lambda a: None
+        self.assertEqual(self.signature(Wrapped),
+                         ((('a', ..., ..., "positional_or_keyword"),),
+                          ...))
+        # wrapper loop:
+        Wrapped.__wrapped__ = Wrapped
+        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
+            self.signature(Wrapped)
+
+    def test_signature_on_lambdas(self):
+        self.assertEqual(self.signature((lambda a=10: a)),
+                         ((('a', 10, ..., "positional_or_keyword"),),
+                          ...))
+
+    def test_signature_on_mocks(self):
+        # https://github.com/python/cpython/issues/96127
+        for mock in (
+            unittest.mock.Mock(),
+            unittest.mock.AsyncMock(),
+            unittest.mock.MagicMock(),
+        ):
+            with self.subTest(mock=mock):
+                self.assertEqual(str(inspect.signature(mock)), '(*args, **kwargs)')
+
+    def test_signature_on_noncallable_mocks(self):
+        for mock in (
+            unittest.mock.NonCallableMock(),
+            unittest.mock.NonCallableMagicMock(),
+        ):
+            with self.subTest(mock=mock):
+                with self.assertRaises(TypeError):
+                    inspect.signature(mock)
+
+    def test_signature_equality(self):
+        def foo(a, *, b:int) -> float: pass
+        self.assertFalse(inspect.signature(foo) == 42)
+        self.assertTrue(inspect.signature(foo) != 42)
+        self.assertTrue(inspect.signature(foo) == ALWAYS_EQ)
+        self.assertFalse(inspect.signature(foo) != ALWAYS_EQ)
+
+        def bar(a, *, b:int) -> float: pass
+        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
+        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
+        self.assertEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def bar(a, *, b:int) -> int: pass
+        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def bar(a, *, b:int): pass
+        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def bar(a, *, b:int=42) -> float: pass
+        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def bar(a, *, c) -> float: pass
+        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def bar(a, b:int) -> float: pass
+        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+        def spam(b:int, a) -> float: pass
+        self.assertFalse(inspect.signature(spam) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(spam) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(spam)), hash(inspect.signature(bar)))
+
+        def foo(*, a, b, c): pass
+        def bar(*, c, b, a): pass
+        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
+        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
+        self.assertEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def foo(*, a=1, b, c): pass
+        def bar(*, c, b, a=1): pass
+        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
+        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
+        self.assertEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def foo(pos, *, a=1, b, c): pass
+        def bar(pos, *, c, b, a=1): pass
+        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
+        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
+        self.assertEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def foo(pos, *, a, b, c): pass
+        def bar(pos, *, c, b, a=1): pass
+        self.assertFalse(inspect.signature(foo) == inspect.signature(bar))
+        self.assertTrue(inspect.signature(foo) != inspect.signature(bar))
+        self.assertNotEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+        def foo(pos, *args, a=42, b, c, **kwargs:int): pass
+        def bar(pos, *args, c, b, a=42, **kwargs:int): pass
+        self.assertTrue(inspect.signature(foo) == inspect.signature(bar))
+        self.assertFalse(inspect.signature(foo) != inspect.signature(bar))
+        self.assertEqual(
+            hash(inspect.signature(foo)), hash(inspect.signature(bar)))
+
+    def test_signature_hashable(self):
+        S = inspect.Signature
+        P = inspect.Parameter
+
+        def foo(a): pass
+        foo_sig = inspect.signature(foo)
+
+        manual_sig = S(parameters=[P('a', P.POSITIONAL_OR_KEYWORD)])
+
+        self.assertEqual(hash(foo_sig), hash(manual_sig))
+        self.assertNotEqual(hash(foo_sig),
+                            hash(manual_sig.replace(return_annotation='spam')))
+
+        def bar(a) -> 1: pass
+        self.assertNotEqual(hash(foo_sig), hash(inspect.signature(bar)))
+
+        def foo(a={}): pass
+        with self.assertRaisesRegex(TypeError, 'unhashable type'):
+            hash(inspect.signature(foo))
+
+        def foo(a) -> {}: pass
+        with self.assertRaisesRegex(TypeError, 'unhashable type'):
+            hash(inspect.signature(foo))
+
+    def test_signature_str(self):
+        def foo(a:int=1, *, b, c=None, **kwargs) -> 42:
+            pass
+        self.assertEqual(str(inspect.signature(foo)),
+                         '(a: int = 1, *, b, c=None, **kwargs) -> 42')
+
+        def foo(a:int=1, *args, b, c=None, **kwargs) -> 42:
+            pass
+        self.assertEqual(str(inspect.signature(foo)),
+                         '(a: int = 1, *args, b, c=None, **kwargs) -> 42')
+
+        def foo():
+            pass
+        self.assertEqual(str(inspect.signature(foo)), '()')
+
+        def foo(a: list[str]) -> tuple[str, float]:
+            pass
+        self.assertEqual(str(inspect.signature(foo)),
+                         '(a: list[str]) -> tuple[str, float]')
+
+        from typing import Tuple
+        def foo(a: list[str]) -> Tuple[str, float]:
+            pass
+        self.assertEqual(str(inspect.signature(foo)),
+                         '(a: list[str]) -> Tuple[str, float]')
+
+    def test_signature_str_positional_only(self):
+        P = inspect.Parameter
+        S = inspect.Signature
+
+        def test(a_po, /, *, b, **kwargs):
+            return a_po, kwargs
+
+        self.assertEqual(str(inspect.signature(test)),
+                         '(a_po, /, *, b, **kwargs)')
+
+        self.assertEqual(str(S(parameters=[P('foo', P.POSITIONAL_ONLY)])),
+                         '(foo, /)')
+
+        self.assertEqual(str(S(parameters=[
+                                P('foo', P.POSITIONAL_ONLY),
+                                P('bar', P.VAR_KEYWORD)])),
+                         '(foo, /, **bar)')
+
+        self.assertEqual(str(S(parameters=[
+                                P('foo', P.POSITIONAL_ONLY),
+                                P('bar', P.VAR_POSITIONAL)])),
+                         '(foo, /, *bar)')
+
+    def test_signature_replace_anno(self):
+        def test() -> 42:
+            pass
+
+        sig = inspect.signature(test)
+        sig = sig.replace(return_annotation=None)
+        self.assertIs(sig.return_annotation, None)
+        sig = sig.replace(return_annotation=sig.empty)
+        self.assertIs(sig.return_annotation, sig.empty)
+        sig = sig.replace(return_annotation=42)
+        self.assertEqual(sig.return_annotation, 42)
+        self.assertEqual(sig, inspect.signature(test))
+
+    def test_signature_replaced(self):
+        def test():
+            pass
+
+        spam_param = inspect.Parameter('spam', inspect.Parameter.POSITIONAL_ONLY)
+        sig = test.__signature__ = inspect.Signature(parameters=(spam_param,))
+        self.assertEqual(sig, inspect.signature(test))
+
+    def test_signature_on_mangled_parameters(self):
+        class Spam:
+            def foo(self, __p1:1=2, *, __p2:2=3):
+                pass
+        class Ham(Spam):
+            pass
+
+        self.assertEqual(self.signature(Spam.foo),
+                         ((('self', ..., ..., "positional_or_keyword"),
+                           ('_Spam__p1', 2, 1, "positional_or_keyword"),
+                           ('_Spam__p2', 3, 2, "keyword_only")),
+                          ...))
+
+        self.assertEqual(self.signature(Spam.foo),
+                         self.signature(Ham.foo))
+
+    def test_signature_from_callable_python_obj(self):
+        class MySignature(inspect.Signature): pass
+        def foo(a, *, b:1): pass
+        foo_sig = MySignature.from_callable(foo)
+        self.assertIsInstance(foo_sig, MySignature)
+
+    def test_signature_from_callable_class(self):
+        # A regression test for a class inheriting its signature from `object`.
+        class MySignature(inspect.Signature): pass
+        class foo: pass
+        foo_sig = MySignature.from_callable(foo)
+        self.assertIsInstance(foo_sig, MySignature)
+
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_signature_from_callable_builtin_obj(self):
+        class MySignature(inspect.Signature): pass
+        sig = MySignature.from_callable(_pickle.Pickler)
+        self.assertIsInstance(sig, MySignature)
+
+    def test_signature_definition_order_preserved_on_kwonly(self):
+        for fn in signatures_with_lexicographic_keyword_only_parameters():
+            signature = inspect.signature(fn)
+            l = list(signature.parameters)
+            sorted_l = sorted(l)
+            self.assertTrue(l)
+            self.assertEqual(l, sorted_l)
+        signature = inspect.signature(unsorted_keyword_only_parameters_fn)
+        l = list(signature.parameters)
+        self.assertEqual(l, unsorted_keyword_only_parameters)
+
+    def test_signater_parameters_is_ordered(self):
+        p1 = inspect.signature(lambda x, y: None).parameters
+        p2 = inspect.signature(lambda y, x: None).parameters
+        self.assertNotEqual(p1, p2)
+
+    def test_signature_annotations_with_local_namespaces(self):
+        class Foo: ...
+        def func(foo: Foo) -> int: pass
+        def func2(foo: Foo, bar: 'Bar') -> int: pass
+
+        for signature_func in (inspect.signature, inspect.Signature.from_callable):
+            with self.subTest(signature_func = signature_func):
+                sig1 = signature_func(func)
+                self.assertEqual(sig1.return_annotation, int)
+                self.assertEqual(sig1.parameters['foo'].annotation, Foo)
+
+                sig2 = signature_func(func, locals=locals())
+                self.assertEqual(sig2.return_annotation, int)
+                self.assertEqual(sig2.parameters['foo'].annotation, Foo)
+
+                sig3 = signature_func(func2, globals={'Bar': int}, locals=locals())
+                self.assertEqual(sig3.return_annotation, int)
+                self.assertEqual(sig3.parameters['foo'].annotation, Foo)
+                self.assertEqual(sig3.parameters['bar'].annotation, 'Bar')
+
+    def test_signature_eval_str(self):
+        isa = inspect_stringized_annotations
+        sig = inspect.Signature
+        par = inspect.Parameter
+        PORK = inspect.Parameter.POSITIONAL_OR_KEYWORD
+        for signature_func in (inspect.signature, inspect.Signature.from_callable):
+            with self.subTest(signature_func = signature_func):
+                self.assertEqual(
+                    signature_func(isa.MyClass),
+                    sig(
+                        parameters=(
+                            par('a', PORK),
+                            par('b', PORK),
+                        )))
+                self.assertEqual(
+                    signature_func(isa.function),
+                    sig(
+                        return_annotation='MyClass',
+                        parameters=(
+                            par('a', PORK, annotation='int'),
+                            par('b', PORK, annotation='str'),
+                        )))
+                self.assertEqual(
+                    signature_func(isa.function2),
+                    sig(
+                        return_annotation='MyClass',
+                        parameters=(
+                            par('a', PORK, annotation='int'),
+                            par('b', PORK, annotation="'str'"),
+                            par('c', PORK, annotation="MyClass"),
+                        )))
+                self.assertEqual(
+                    signature_func(isa.function3),
+                    sig(
+                        parameters=(
+                            par('a', PORK, annotation="'int'"),
+                            par('b', PORK, annotation="'str'"),
+                            par('c', PORK, annotation="'MyClass'"),
+                        )))
+
+                self.assertEqual(signature_func(isa.UnannotatedClass), sig())
+                self.assertEqual(signature_func(isa.unannotated_function),
+                    sig(
+                        parameters=(
+                            par('a', PORK),
+                            par('b', PORK),
+                            par('c', PORK),
+                        )))
+
+                self.assertEqual(
+                    signature_func(isa.MyClass, eval_str=True),
+                    sig(
+                        parameters=(
+                            par('a', PORK),
+                            par('b', PORK),
+                        )))
+                self.assertEqual(
+                    signature_func(isa.function, eval_str=True),
+                    sig(
+                        return_annotation=isa.MyClass,
+                        parameters=(
+                            par('a', PORK, annotation=int),
+                            par('b', PORK, annotation=str),
+                        )))
+                self.assertEqual(
+                    signature_func(isa.function2, eval_str=True),
+                    sig(
+                        return_annotation=isa.MyClass,
+                        parameters=(
+                            par('a', PORK, annotation=int),
+                            par('b', PORK, annotation='str'),
+                            par('c', PORK, annotation=isa.MyClass),
+                        )))
+                self.assertEqual(
+                    signature_func(isa.function3, eval_str=True),
+                    sig(
+                        parameters=(
+                            par('a', PORK, annotation='int'),
+                            par('b', PORK, annotation='str'),
+                            par('c', PORK, annotation='MyClass'),
+                        )))
+
+                globalns = {'int': float, 'str': complex}
+                localns = {'str': tuple, 'MyClass': dict}
+                with self.assertRaises(NameError):
+                    signature_func(isa.function, eval_str=True, globals=globalns)
+
+                self.assertEqual(
+                    signature_func(isa.function, eval_str=True, locals=localns),
+                    sig(
+                        return_annotation=dict,
+                        parameters=(
+                            par('a', PORK, annotation=int),
+                            par('b', PORK, annotation=tuple),
+                        )))
+
+                self.assertEqual(
+                    signature_func(isa.function, eval_str=True, globals=globalns, locals=localns),
+                    sig(
+                        return_annotation=dict,
+                        parameters=(
+                            par('a', PORK, annotation=float),
+                            par('b', PORK, annotation=tuple),
+                        )))
+
+    def test_signature_none_annotation(self):
+        class funclike:
+            # Has to be callable, and have correct
+            # __code__, __annotations__, __defaults__, __name__,
+            # and __kwdefaults__ attributes
+
+            def __init__(self, func):
+                self.__name__ = func.__name__
+                self.__code__ = func.__code__
+                self.__annotations__ = func.__annotations__
+                self.__defaults__ = func.__defaults__
+                self.__kwdefaults__ = func.__kwdefaults__
+                self.func = func
+
+            def __call__(self, *args, **kwargs):
+                return self.func(*args, **kwargs)
+
+        def foo(): pass
+        foo = funclike(foo)
+        foo.__annotations__ = None
+        for signature_func in (inspect.signature, inspect.Signature.from_callable):
+            with self.subTest(signature_func = signature_func):
+                self.assertEqual(signature_func(foo), inspect.Signature())
+        self.assertEqual(inspect.get_annotations(foo), {})
+
+    def test_signature_as_str(self):
+        self.maxDiff = None
+        class S:
+            __signature__ = '(a, b=2)'
+
+        self.assertEqual(self.signature(S),
+                         ((('a', ..., ..., 'positional_or_keyword'),
+                           ('b', 2, ..., 'positional_or_keyword')),
+                          ...))
+
+    def test_signature_as_callable(self):
+        # __signature__ should be either a staticmethod or a bound classmethod
+        class S:
+            @classmethod
+            def __signature__(cls):
+                return '(a, b=2)'
+
+        self.assertEqual(self.signature(S),
+                         ((('a', ..., ..., 'positional_or_keyword'),
+                           ('b', 2, ..., 'positional_or_keyword')),
+                          ...))
+
+        class S:
+            @staticmethod
+            def __signature__():
+                return '(a, b=2)'
+
+        self.assertEqual(self.signature(S),
+                         ((('a', ..., ..., 'positional_or_keyword'),
+                           ('b', 2, ..., 'positional_or_keyword')),
+                          ...))
+
+    def test_signature_on_derived_classes(self):
+        # gh-105080: Make sure that signatures are consistent on derived classes
+
+        class B:
+            def __new__(self, *args, **kwargs):
+                return super().__new__(self)
+            def __init__(self, value):
+                self.value = value
+
+        class D1(B):
+            def __init__(self, value):
+                super().__init__(value)
+
+        class D2(D1):
+            pass
+
+        self.assertEqual(inspect.signature(D2), inspect.signature(D1))
+
+
+class TestParameterObject(unittest.TestCase):
+    def test_signature_parameter_kinds(self):
+        P = inspect.Parameter
+        self.assertTrue(P.POSITIONAL_ONLY < P.POSITIONAL_OR_KEYWORD < \
+                        P.VAR_POSITIONAL < P.KEYWORD_ONLY < P.VAR_KEYWORD)
+
+        self.assertEqual(str(P.POSITIONAL_ONLY), 'POSITIONAL_ONLY')
+        self.assertTrue('POSITIONAL_ONLY' in repr(P.POSITIONAL_ONLY))
+
+    def test_signature_parameter_object(self):
+        p = inspect.Parameter('foo', default=10,
+                              kind=inspect.Parameter.POSITIONAL_ONLY)
+        self.assertEqual(p.name, 'foo')
+        self.assertEqual(p.default, 10)
+        self.assertIs(p.annotation, p.empty)
+        self.assertEqual(p.kind, inspect.Parameter.POSITIONAL_ONLY)
+
+        with self.assertRaisesRegex(ValueError, "value '123' is "
+                                    "not a valid Parameter.kind"):
+            inspect.Parameter('foo', default=10, kind='123')
+
+        with self.assertRaisesRegex(ValueError, 'not a valid parameter name'):
+            inspect.Parameter('1', kind=inspect.Parameter.VAR_KEYWORD)
+
+        with self.assertRaisesRegex(ValueError, 'not a valid parameter name'):
+            inspect.Parameter('from', kind=inspect.Parameter.VAR_KEYWORD)
+
+        with self.assertRaisesRegex(TypeError, 'name must be a str'):
+            inspect.Parameter(None, kind=inspect.Parameter.VAR_KEYWORD)
+
+        with self.assertRaisesRegex(ValueError,
+                                    'is not a valid parameter name'):
+            inspect.Parameter('$', kind=inspect.Parameter.VAR_KEYWORD)
+
+        with self.assertRaisesRegex(ValueError,
+                                    'is not a valid parameter name'):
+            inspect.Parameter('.a', kind=inspect.Parameter.VAR_KEYWORD)
+
+        with self.assertRaisesRegex(ValueError, 'cannot have default values'):
+            inspect.Parameter('a', default=42,
+                              kind=inspect.Parameter.VAR_KEYWORD)
+
+        with self.assertRaisesRegex(ValueError, 'cannot have default values'):
+            inspect.Parameter('a', default=42,
+                              kind=inspect.Parameter.VAR_POSITIONAL)
+
+        p = inspect.Parameter('a', default=42,
+                              kind=inspect.Parameter.POSITIONAL_OR_KEYWORD)
+        with self.assertRaisesRegex(ValueError, 'cannot have default values'):
+            p.replace(kind=inspect.Parameter.VAR_POSITIONAL)
+
+        self.assertTrue(repr(p).startswith('<Parameter'))
+        self.assertTrue('"a=42"' in repr(p))
+
+    def test_signature_parameter_hashable(self):
+        P = inspect.Parameter
+        foo = P('foo', kind=P.POSITIONAL_ONLY)
+        self.assertEqual(hash(foo), hash(P('foo', kind=P.POSITIONAL_ONLY)))
+        self.assertNotEqual(hash(foo), hash(P('foo', kind=P.POSITIONAL_ONLY,
+                                              default=42)))
+        self.assertNotEqual(hash(foo),
+                            hash(foo.replace(kind=P.VAR_POSITIONAL)))
+
+    def test_signature_parameter_equality(self):
+        P = inspect.Parameter
+        p = P('foo', default=42, kind=inspect.Parameter.KEYWORD_ONLY)
+
+        self.assertTrue(p == p)
+        self.assertFalse(p != p)
+        self.assertFalse(p == 42)
+        self.assertTrue(p != 42)
+        self.assertTrue(p == ALWAYS_EQ)
+        self.assertFalse(p != ALWAYS_EQ)
+
+        self.assertTrue(p == P('foo', default=42,
+                               kind=inspect.Parameter.KEYWORD_ONLY))
+        self.assertFalse(p != P('foo', default=42,
+                                kind=inspect.Parameter.KEYWORD_ONLY))
+
+    def test_signature_parameter_replace(self):
+        p = inspect.Parameter('foo', default=42,
+                              kind=inspect.Parameter.KEYWORD_ONLY)
+
+        self.assertIsNot(p, p.replace())
+        self.assertEqual(p, p.replace())
+
+        p2 = p.replace(annotation=1)
+        self.assertEqual(p2.annotation, 1)
+        p2 = p2.replace(annotation=p2.empty)
+        self.assertEqual(p, p2)
+
+        p2 = p2.replace(name='bar')
+        self.assertEqual(p2.name, 'bar')
+        self.assertNotEqual(p2, p)
+
+        with self.assertRaisesRegex(ValueError,
+                                    'name is a required attribute'):
+            p2 = p2.replace(name=p2.empty)
+
+        p2 = p2.replace(name='foo', default=None)
+        self.assertIs(p2.default, None)
+        self.assertNotEqual(p2, p)
+
+        p2 = p2.replace(name='foo', default=p2.empty)
+        self.assertIs(p2.default, p2.empty)
+
+
+        p2 = p2.replace(default=42, kind=p2.POSITIONAL_OR_KEYWORD)
+        self.assertEqual(p2.kind, p2.POSITIONAL_OR_KEYWORD)
+        self.assertNotEqual(p2, p)
+
+        with self.assertRaisesRegex(ValueError,
+                                    "value <class 'inspect._empty'> "
+                                    "is not a valid Parameter.kind"):
+            p2 = p2.replace(kind=p2.empty)
+
+        p2 = p2.replace(kind=p2.KEYWORD_ONLY)
+        self.assertEqual(p2, p)
+
+    def test_signature_parameter_positional_only(self):
+        with self.assertRaisesRegex(TypeError, 'name must be a str'):
+            inspect.Parameter(None, kind=inspect.Parameter.POSITIONAL_ONLY)
+
+    @cpython_only
+    def test_signature_parameter_implicit(self):
+        with self.assertRaisesRegex(ValueError,
+                                    'implicit arguments must be passed as '
+                                    'positional or keyword arguments, '
+                                    'not positional-only'):
+            inspect.Parameter('.0', kind=inspect.Parameter.POSITIONAL_ONLY)
+
+        param = inspect.Parameter(
+            '.0', kind=inspect.Parameter.POSITIONAL_OR_KEYWORD)
+        self.assertEqual(param.kind, inspect.Parameter.POSITIONAL_ONLY)
+        self.assertEqual(param.name, 'implicit0')
+
+    def test_signature_parameter_immutability(self):
+        p = inspect.Parameter('spam', kind=inspect.Parameter.KEYWORD_ONLY)
+
+        with self.assertRaises(AttributeError):
+            p.foo = 'bar'
+
+        with self.assertRaises(AttributeError):
+            p.kind = 123
+
+
+class TestSignatureBind(unittest.TestCase):
+    @staticmethod
+    def call(func, *args, **kwargs):
+        sig = inspect.signature(func)
+        ba = sig.bind(*args, **kwargs)
+        return func(*ba.args, **ba.kwargs)
+
+    def test_signature_bind_empty(self):
+        def test():
+            return 42
+
+        self.assertEqual(self.call(test), 42)
+        with self.assertRaisesRegex(TypeError, 'too many positional arguments'):
+            self.call(test, 1)
+        with self.assertRaisesRegex(TypeError, 'too many positional arguments'):
+            self.call(test, 1, spam=10)
+        with self.assertRaisesRegex(
+            TypeError, "got an unexpected keyword argument 'spam'"):
+
+            self.call(test, spam=1)
+
+    def test_signature_bind_var(self):
+        def test(*args, **kwargs):
+            return args, kwargs
+
+        self.assertEqual(self.call(test), ((), {}))
+        self.assertEqual(self.call(test, 1), ((1,), {}))
+        self.assertEqual(self.call(test, 1, 2), ((1, 2), {}))
+        self.assertEqual(self.call(test, foo='bar'), ((), {'foo': 'bar'}))
+        self.assertEqual(self.call(test, 1, foo='bar'), ((1,), {'foo': 'bar'}))
+        self.assertEqual(self.call(test, args=10), ((), {'args': 10}))
+        self.assertEqual(self.call(test, 1, 2, foo='bar'),
+                         ((1, 2), {'foo': 'bar'}))
+
+    def test_signature_bind_just_args(self):
+        def test(a, b, c):
+            return a, b, c
+
+        self.assertEqual(self.call(test, 1, 2, 3), (1, 2, 3))
+
+        with self.assertRaisesRegex(TypeError, 'too many positional arguments'):
+            self.call(test, 1, 2, 3, 4)
+
+        with self.assertRaisesRegex(TypeError,
+                                    "missing a required argument: 'b'"):
+            self.call(test, 1)
+
+        with self.assertRaisesRegex(TypeError,
+                                    "missing a required argument: 'a'"):
+            self.call(test)
+
+        def test(a, b, c=10):
+            return a, b, c
+        self.assertEqual(self.call(test, 1, 2, 3), (1, 2, 3))
+        self.assertEqual(self.call(test, 1, 2), (1, 2, 10))
+
+        def test(a=1, b=2, c=3):
+            return a, b, c
+        self.assertEqual(self.call(test, a=10, c=13), (10, 2, 13))
+        self.assertEqual(self.call(test, a=10), (10, 2, 3))
+        self.assertEqual(self.call(test, b=10), (1, 10, 3))
+
+    def test_signature_bind_varargs_order(self):
+        def test(*args):
+            return args
+
+        self.assertEqual(self.call(test), ())
+        self.assertEqual(self.call(test, 1, 2, 3), (1, 2, 3))
+
+    def test_signature_bind_args_and_varargs(self):
+        def test(a, b, c=3, *args):
+            return a, b, c, args
+
+        self.assertEqual(self.call(test, 1, 2, 3, 4, 5), (1, 2, 3, (4, 5)))
+        self.assertEqual(self.call(test, 1, 2), (1, 2, 3, ()))
+        self.assertEqual(self.call(test, b=1, a=2), (2, 1, 3, ()))
+        self.assertEqual(self.call(test, 1, b=2), (1, 2, 3, ()))
+
+        with self.assertRaisesRegex(TypeError,
+                                     "multiple values for argument 'c'"):
+            self.call(test, 1, 2, 3, c=4)
+
+    def test_signature_bind_just_kwargs(self):
+        def test(**kwargs):
+            return kwargs
+
+        self.assertEqual(self.call(test), {})
+        self.assertEqual(self.call(test, foo='bar', spam='ham'),
+                         {'foo': 'bar', 'spam': 'ham'})
+
+    def test_signature_bind_args_and_kwargs(self):
+        def test(a, b, c=3, **kwargs):
+            return a, b, c, kwargs
+
+        self.assertEqual(self.call(test, 1, 2), (1, 2, 3, {}))
+        self.assertEqual(self.call(test, 1, 2, foo='bar', spam='ham'),
+                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
+        self.assertEqual(self.call(test, b=2, a=1, foo='bar', spam='ham'),
+                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
+        self.assertEqual(self.call(test, a=1, b=2, foo='bar', spam='ham'),
+                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
+        self.assertEqual(self.call(test, 1, b=2, foo='bar', spam='ham'),
+                         (1, 2, 3, {'foo': 'bar', 'spam': 'ham'}))
+        self.assertEqual(self.call(test, 1, b=2, c=4, foo='bar', spam='ham'),
+                         (1, 2, 4, {'foo': 'bar', 'spam': 'ham'}))
+        self.assertEqual(self.call(test, 1, 2, 4, foo='bar'),
+                         (1, 2, 4, {'foo': 'bar'}))
+        self.assertEqual(self.call(test, c=5, a=4, b=3),
+                         (4, 3, 5, {}))
+
+    def test_signature_bind_kwonly(self):
+        def test(*, foo):
+            return foo
+        with self.assertRaisesRegex(TypeError,
+                                     'too many positional arguments'):
+            self.call(test, 1)
+        self.assertEqual(self.call(test, foo=1), 1)
+
+        def test(a, *, foo=1, bar):
+            return foo
+        with self.assertRaisesRegex(TypeError,
+                                     "missing a required argument: 'bar'"):
+            self.call(test, 1)
+
+        def test(foo, *, bar):
+            return foo, bar
+        self.assertEqual(self.call(test, 1, bar=2), (1, 2))
+        self.assertEqual(self.call(test, bar=2, foo=1), (1, 2))
+
+        with self.assertRaisesRegex(
+            TypeError, "got an unexpected keyword argument 'spam'"):
+
+            self.call(test, bar=2, foo=1, spam=10)
+
+        with self.assertRaisesRegex(TypeError,
+                                     'too many positional arguments'):
+            self.call(test, 1, 2)
+
+        with self.assertRaisesRegex(TypeError,
+                                     'too many positional arguments'):
+            self.call(test, 1, 2, bar=2)
+
+        with self.assertRaisesRegex(
+            TypeError, "got an unexpected keyword argument 'spam'"):
+
+            self.call(test, 1, bar=2, spam='ham')
+
+        with self.assertRaisesRegex(TypeError,
+                                     "missing a required keyword-only "
+                                     "argument: 'bar'"):
+            self.call(test, 1)
+
+        def test(foo, *, bar, **bin):
+            return foo, bar, bin
+        self.assertEqual(self.call(test, 1, bar=2), (1, 2, {}))
+        self.assertEqual(self.call(test, foo=1, bar=2), (1, 2, {}))
+        self.assertEqual(self.call(test, 1, bar=2, spam='ham'),
+                         (1, 2, {'spam': 'ham'}))
+        self.assertEqual(self.call(test, spam='ham', foo=1, bar=2),
+                         (1, 2, {'spam': 'ham'}))
+        with self.assertRaisesRegex(TypeError,
+                                    "missing a required argument: 'foo'"):
+            self.call(test, spam='ham', bar=2)
+        self.assertEqual(self.call(test, 1, bar=2, bin=1, spam=10),
+                         (1, 2, {'bin': 1, 'spam': 10}))
+
+    def test_signature_bind_arguments(self):
+        def test(a, *args, b, z=100, **kwargs):
+            pass
+        sig = inspect.signature(test)
+        ba = sig.bind(10, 20, b=30, c=40, args=50, kwargs=60)
+        # we won't have 'z' argument in the bound arguments object, as we didn't
+        # pass it to the 'bind'
+        self.assertEqual(tuple(ba.arguments.items()),
+                         (('a', 10), ('args', (20,)), ('b', 30),
+                          ('kwargs', {'c': 40, 'args': 50, 'kwargs': 60})))
+        self.assertEqual(ba.kwargs,
+                         {'b': 30, 'c': 40, 'args': 50, 'kwargs': 60})
+        self.assertEqual(ba.args, (10, 20))
+
+    def test_signature_bind_positional_only(self):
+        def test(a_po, b_po, c_po=3, /, foo=42, *, bar=50, **kwargs):
+            return a_po, b_po, c_po, foo, bar, kwargs
+
+        self.assertEqual(self.call(test, 1, 2, 4, 5, bar=6),
+                         (1, 2, 4, 5, 6, {}))
+
+        self.assertEqual(self.call(test, 1, 2),
+                         (1, 2, 3, 42, 50, {}))
+
+        self.assertEqual(self.call(test, 1, 2, foo=4, bar=5),
+                         (1, 2, 3, 4, 5, {}))
+
+        with self.assertRaisesRegex(TypeError, "but was passed as a keyword"):
+            self.call(test, 1, 2, foo=4, bar=5, c_po=10)
+
+        with self.assertRaisesRegex(TypeError, "parameter is positional only"):
+            self.call(test, 1, 2, c_po=4)
+
+        with self.assertRaisesRegex(TypeError, "parameter is positional only"):
+            self.call(test, a_po=1, b_po=2)
+
+    def test_signature_bind_with_self_arg(self):
+        # Issue #17071: one of the parameters is named "self
+        def test(a, self, b):
+            pass
+        sig = inspect.signature(test)
+        ba = sig.bind(1, 2, 3)
+        self.assertEqual(ba.args, (1, 2, 3))
+        ba = sig.bind(1, self=2, b=3)
+        self.assertEqual(ba.args, (1, 2, 3))
+
+    def test_signature_bind_vararg_name(self):
+        def test(a, *args):
+            return a, args
+        sig = inspect.signature(test)
+
+        with self.assertRaisesRegex(
+            TypeError, "got an unexpected keyword argument 'args'"):
+
+            sig.bind(a=0, args=1)
+
+        def test(*args, **kwargs):
+            return args, kwargs
+        self.assertEqual(self.call(test, args=1), ((), {'args': 1}))
+
+        sig = inspect.signature(test)
+        ba = sig.bind(args=1)
+        self.assertEqual(ba.arguments, {'kwargs': {'args': 1}})
+
+    @cpython_only
+    def test_signature_bind_implicit_arg(self):
+        # Issue #19611: getcallargs should work with comprehensions
+        def make_set():
+            return set(z * z for z in range(5))
+        gencomp_code = make_set.__code__.co_consts[1]
+        gencomp_func = types.FunctionType(gencomp_code, {})
+
+        iterator = iter(range(5))
+        self.assertEqual(set(self.call(gencomp_func, iterator)), {0, 1, 4, 9, 16})
+
+    def test_signature_bind_posonly_kwargs(self):
+        def foo(bar, /, **kwargs):
+            return bar, kwargs.get(bar)
+
+        sig = inspect.signature(foo)
+        result = sig.bind("pos-only", bar="keyword")
+
+        self.assertEqual(result.kwargs, {"bar": "keyword"})
+        self.assertIn(("bar", "pos-only"), result.arguments.items())
+
+
+class TestBoundArguments(unittest.TestCase):
+    def test_signature_bound_arguments_unhashable(self):
+        def foo(a): pass
+        ba = inspect.signature(foo).bind(1)
+
+        with self.assertRaisesRegex(TypeError, 'unhashable type'):
+            hash(ba)
+
+    def test_signature_bound_arguments_equality(self):
+        def foo(a): pass
+        ba = inspect.signature(foo).bind(1)
+        self.assertTrue(ba == ba)
+        self.assertFalse(ba != ba)
+        self.assertTrue(ba == ALWAYS_EQ)
+        self.assertFalse(ba != ALWAYS_EQ)
+
+        ba2 = inspect.signature(foo).bind(1)
+        self.assertTrue(ba == ba2)
+        self.assertFalse(ba != ba2)
+
+        ba3 = inspect.signature(foo).bind(2)
+        self.assertFalse(ba == ba3)
+        self.assertTrue(ba != ba3)
+        ba3.arguments['a'] = 1
+        self.assertTrue(ba == ba3)
+        self.assertFalse(ba != ba3)
+
+        def bar(b): pass
+        ba4 = inspect.signature(bar).bind(1)
+        self.assertFalse(ba == ba4)
+        self.assertTrue(ba != ba4)
+
+        def foo(*, a, b): pass
+        sig = inspect.signature(foo)
+        ba1 = sig.bind(a=1, b=2)
+        ba2 = sig.bind(b=2, a=1)
+        self.assertTrue(ba1 == ba2)
+        self.assertFalse(ba1 != ba2)
+
+    def test_signature_bound_arguments_pickle(self):
+        def foo(a, b, *, c:1={}, **kw) -> {42:'ham'}: pass
+        sig = inspect.signature(foo)
+        ba = sig.bind(20, 30, z={})
+
+        for ver in range(pickle.HIGHEST_PROTOCOL + 1):
+            with self.subTest(pickle_ver=ver):
+                ba_pickled = pickle.loads(pickle.dumps(ba, ver))
+                self.assertEqual(ba, ba_pickled)
+
+    def test_signature_bound_arguments_repr(self):
+        def foo(a, b, *, c:1={}, **kw) -> {42:'ham'}: pass
+        sig = inspect.signature(foo)
+        ba = sig.bind(20, 30, z={})
+        self.assertRegex(repr(ba), r'<BoundArguments \(a=20,.*\}\}\)>')
+
+    def test_signature_bound_arguments_apply_defaults(self):
+        def foo(a, b=1, *args, c:1={}, **kw): pass
+        sig = inspect.signature(foo)
+
+        ba = sig.bind(20)
+        ba.apply_defaults()
+        self.assertEqual(
+            list(ba.arguments.items()),
+            [('a', 20), ('b', 1), ('args', ()), ('c', {}), ('kw', {})])
+
+        # Make sure that we preserve the order:
+        # i.e. 'c' should be *before* 'kw'.
+        ba = sig.bind(10, 20, 30, d=1)
+        ba.apply_defaults()
+        self.assertEqual(
+            list(ba.arguments.items()),
+            [('a', 10), ('b', 20), ('args', (30,)), ('c', {}), ('kw', {'d':1})])
+
+        # Make sure that BoundArguments produced by bind_partial()
+        # are supported.
+        def foo(a, b): pass
+        sig = inspect.signature(foo)
+        ba = sig.bind_partial(20)
+        ba.apply_defaults()
+        self.assertEqual(
+            list(ba.arguments.items()),
+            [('a', 20)])
+
+        # Test no args
+        def foo(): pass
+        sig = inspect.signature(foo)
+        ba = sig.bind()
+        ba.apply_defaults()
+        self.assertEqual(list(ba.arguments.items()), [])
+
+        # Make sure a no-args binding still acquires proper defaults.
+        def foo(a='spam'): pass
+        sig = inspect.signature(foo)
+        ba = sig.bind()
+        ba.apply_defaults()
+        self.assertEqual(list(ba.arguments.items()), [('a', 'spam')])
+
+    def test_signature_bound_arguments_arguments_type(self):
+        def foo(a): pass
+        ba = inspect.signature(foo).bind(1)
+        self.assertIs(type(ba.arguments), dict)
+
+class TestSignaturePrivateHelpers(unittest.TestCase):
+    def _strip_non_python_syntax(self, input,
+        clean_signature, self_parameter):
+        computed_clean_signature, \
+            computed_self_parameter = \
+            inspect._signature_strip_non_python_syntax(input)
+        self.assertEqual(computed_clean_signature, clean_signature)
+        self.assertEqual(computed_self_parameter, self_parameter)
+
+    def test_signature_strip_non_python_syntax(self):
+        self._strip_non_python_syntax(
+            "($module, /, path, mode, *, dir_fd=None, " +
+                "effective_ids=False,\n       follow_symlinks=True)",
+            "(module, /, path, mode, *, dir_fd=None, " +
+                "effective_ids=False, follow_symlinks=True)",
+            0)
+
+        self._strip_non_python_syntax(
+            "($module, word, salt, /)",
+            "(module, word, salt, /)",
+            0)
+
+        self._strip_non_python_syntax(
+            "(x, y=None, z=None, /)",
+            "(x, y=None, z=None, /)",
+            None)
+
+        self._strip_non_python_syntax(
+            "(x, y=None, z=None)",
+            "(x, y=None, z=None)",
+            None)
+
+        self._strip_non_python_syntax(
+            "(x,\n    y=None,\n      z = None  )",
+            "(x, y=None, z=None)",
+            None)
+
+        self._strip_non_python_syntax(
+            "",
+            "",
+            None)
+
+        self._strip_non_python_syntax(
+            None,
+            None,
+            None)
+
+class TestSignatureDefinitions(unittest.TestCase):
+    # This test case provides a home for checking that particular APIs
+    # have signatures available for introspection
+
+    @cpython_only
+    @unittest.skipIf(MISSING_C_DOCSTRINGS,
+                     "Signature information for builtins requires docstrings")
+    def test_builtins_have_signatures(self):
+        # This checks all builtin callables in CPython have signatures
+        # A few have signatures Signature can't yet handle, so we skip those
+        # since they will have to wait until PEP 457 adds the required
+        # introspection support to the inspect module
+        # Some others also haven't been converted yet for various other
+        # reasons, so we also skip those for the time being, but design
+        # the test to fail in order to indicate when it needs to be
+        # updated.
+        no_signature = set()
+        # These need PEP 457 groups
+        needs_groups = {"range", "slice", "dir", "getattr",
+                        "next", "iter", "vars"}
+        no_signature |= needs_groups
+        # These have unrepresentable parameter default values of NULL
+        needs_null = {"anext"}
+        no_signature |= needs_null
+        # These need PEP 457 groups or a signature change to accept None
+        needs_semantic_update = {"round"}
+        no_signature |= needs_semantic_update
+        # These need *args support in Argument Clinic
+        needs_varargs = {"breakpoint", "min", "max", "print",
+                         "__build_class__"}
+        no_signature |= needs_varargs
+        # These simply weren't covered in the initial AC conversion
+        # for builtin callables
+        not_converted_yet = {"open", "__import__"}
+        no_signature |= not_converted_yet
+        # These builtin types are expected to provide introspection info
+        types_with_signatures = set()
+        # Check the signatures we expect to be there
+        ns = vars(builtins)
+        for name, obj in sorted(ns.items()):
+            if not callable(obj):
+                continue
+            # The builtin types haven't been converted to AC yet
+            if isinstance(obj, type) and (name not in types_with_signatures):
+                # Note that this also skips all the exception types
+                no_signature.add(name)
+            if (name in no_signature):
+                # Not yet converted
+                continue
+            with self.subTest(builtin=name):
+                self.assertIsNotNone(inspect.signature(obj))
+        # Check callables that haven't been converted don't claim a signature
+        # This ensures this test will start failing as more signatures are
+        # added, so the affected items can be moved into the scope of the
+        # regression test above
+        for name in no_signature:
+            with self.subTest(builtin=name):
+                self.assertIsNone(obj.__text_signature__)
+
+    def test_python_function_override_signature(self):
+        def func(*args, **kwargs):
+            pass
+        func.__text_signature__ = '($self, a, b=1, *args, c, d=2, **kwargs)'
+        sig = inspect.signature(func)
+        self.assertIsNotNone(sig)
+        self.assertEqual(str(sig), '(self, /, a, b=1, *args, c, d=2, **kwargs)')
+
+        func.__text_signature__ = '($self, a, b=1, /, *args, c, d=2, **kwargs)'
+        sig = inspect.signature(func)
+        self.assertEqual(str(sig), '(self, a, b=1, /, *args, c, d=2, **kwargs)')
+
+        func.__text_signature__ = '(self, a=1+2, b=4-3, c=1 | 3 | 16)'
+        sig = inspect.signature(func)
+        self.assertEqual(str(sig), '(self, a=3, b=1, c=19)')
+
+        func.__text_signature__ = '(self, a=1,\nb=2,\n\n\n   c=3)'
+        sig = inspect.signature(func)
+        self.assertEqual(str(sig), '(self, a=1, b=2, c=3)')
+
+        func.__text_signature__ = '(self, x=does_not_exist)'
+        with self.assertRaises(ValueError):
+            inspect.signature(func)
+        func.__text_signature__ = '(self, x=sys, y=inspect)'
+        with self.assertRaises(ValueError):
+            inspect.signature(func)
+        func.__text_signature__ = '(self, 123)'
+        with self.assertRaises(ValueError):
+            inspect.signature(func)
+
+    def test_base_class_have_text_signature(self):
+        # see issue 43118
+        from test.typinganndata.ann_module7 import BufferedReader
+        class MyBufferedReader(BufferedReader):
+            """buffer reader class."""
+
+        text_signature = BufferedReader.__text_signature__
+        self.assertEqual(text_signature, '(raw, buffer_size=DEFAULT_BUFFER_SIZE)')
+        sig = inspect.signature(MyBufferedReader)
+        self.assertEqual(str(sig), '(raw, buffer_size=8192)')
+
+
+class NTimesUnwrappable:
+    def __init__(self, n):
+        self.n = n
+        self._next = None
+
+    @property
+    def __wrapped__(self):
+        if self.n <= 0:
+            raise Exception("Unwrapped too many times")
+        if self._next is None:
+            self._next = NTimesUnwrappable(self.n - 1)
+        return self._next
+
+class TestUnwrap(unittest.TestCase):
+
+    def test_unwrap_one(self):
+        def func(a, b):
+            return a + b
+        wrapper = functools.lru_cache(maxsize=20)(func)
+        self.assertIs(inspect.unwrap(wrapper), func)
+
+    def test_unwrap_several(self):
+        def func(a, b):
+            return a + b
+        wrapper = func
+        for __ in range(10):
+            @functools.wraps(wrapper)
+            def wrapper():
+                pass
+        self.assertIsNot(wrapper.__wrapped__, func)
+        self.assertIs(inspect.unwrap(wrapper), func)
+
+    def test_stop(self):
+        def func1(a, b):
+            return a + b
+        @functools.wraps(func1)
+        def func2():
+            pass
+        @functools.wraps(func2)
+        def wrapper():
+            pass
+        func2.stop_here = 1
+        unwrapped = inspect.unwrap(wrapper,
+                                   stop=(lambda f: hasattr(f, "stop_here")))
+        self.assertIs(unwrapped, func2)
+
+    def test_cycle(self):
+        def func1(): pass
+        func1.__wrapped__ = func1
+        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
+            inspect.unwrap(func1)
+
+        def func2(): pass
+        func2.__wrapped__ = func1
+        func1.__wrapped__ = func2
+        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
+            inspect.unwrap(func1)
+        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
+            inspect.unwrap(func2)
+
+    def test_unhashable(self):
+        def func(): pass
+        func.__wrapped__ = None
+        class C:
+            __hash__ = None
+            __wrapped__ = func
+        self.assertIsNone(inspect.unwrap(C()))
+
+    def test_recursion_limit(self):
+        obj = NTimesUnwrappable(sys.getrecursionlimit() + 1)
+        with self.assertRaisesRegex(ValueError, 'wrapper loop'):
+            inspect.unwrap(obj)
+
+class TestMain(unittest.TestCase):
+    def test_only_source(self):
+        module = importlib.import_module('unittest')
+        rc, out, err = assert_python_ok('-m', 'inspect',
+                                        'unittest')
+        lines = out.decode().splitlines()
+        # ignore the final newline
+        self.assertEqual(lines[:-1], inspect.getsource(module).splitlines())
+        self.assertEqual(err, b'')
+
+    def test_custom_getattr(self):
+        def foo():
+            pass
+        foo.__signature__ = 42
+        with self.assertRaises(TypeError):
+            inspect.signature(foo)
+
+    @unittest.skipIf(ThreadPoolExecutor is None,
+            'threads required to test __qualname__ for source files')
+    def test_qualname_source(self):
+        rc, out, err = assert_python_ok('-m', 'inspect',
+                                     'concurrent.futures:ThreadPoolExecutor')
+        lines = out.decode().splitlines()
+        # ignore the final newline
+        self.assertEqual(lines[:-1],
+                         inspect.getsource(ThreadPoolExecutor).splitlines())
+        self.assertEqual(err, b'')
+
+    def test_builtins(self):
+        _, out, err = assert_python_failure('-m', 'inspect',
+                                            'sys')
+        lines = err.decode().splitlines()
+        self.assertEqual(lines, ["Can't get info for builtin modules."])
+
+    def test_details(self):
+        module = importlib.import_module('unittest')
+        args = support.optim_args_from_interpreter_flags()
+        rc, out, err = assert_python_ok(*args, '-m', 'inspect',
+                                        'unittest', '--details')
+        output = out.decode()
+        # Just a quick sanity check on the output
+        self.assertIn(module.__spec__.name, output)
+        self.assertIn(module.__name__, output)
+        self.assertIn(module.__spec__.origin, output)
+        self.assertIn(module.__file__, output)
+        self.assertIn(module.__spec__.cached, output)
+        self.assertIn(module.__cached__, output)
+        self.assertEqual(err, b'')
+
+
+class TestReload(unittest.TestCase):
+
+    src_before = textwrap.dedent("""\
+def foo():
+    print("Bla")
+    """)
+
+    src_after = textwrap.dedent("""\
+def foo():
+    print("Oh no!")
+    """)
+
+    def assertInspectEqual(self, path, source):
+        inspected_src = inspect.getsource(source)
+        with open(path, encoding='utf-8') as src:
+            self.assertEqual(
+                src.read().splitlines(True),
+                inspected_src.splitlines(True)
+            )
+
+    def test_getsource_reload(self):
+        # see issue 1218234
+        with ready_to_import('reload_bug', self.src_before) as (name, path):
+            module = importlib.import_module(name)
+            self.assertInspectEqual(path, module)
+            with open(path, 'w', encoding='utf-8') as src:
+                src.write(self.src_after)
+            self.assertInspectEqual(path, module)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_ipaddress.py b/Lib/test/test_ipaddress.py
index a5388b2e5d..fc27628af1 100644
--- a/Lib/test/test_ipaddress.py
+++ b/Lib/test/test_ipaddress.py
@@ -4,6 +4,7 @@
 """Unittest for ipaddress module."""
 
 
+import copy
 import unittest
 import re
 import contextlib
@@ -542,11 +543,17 @@ def assertBadPart(addr, part):
 
     def test_pickle(self):
         self.pickle_test('2001:db8::')
+        self.pickle_test('2001:db8::%scope')
 
     def test_weakref(self):
         weakref.ref(self.factory('2001:db8::'))
         weakref.ref(self.factory('2001:db8::%scope'))
 
+    def test_copy(self):
+        addr = self.factory('2001:db8::%scope')
+        self.assertEqual(addr, copy.copy(addr))
+        self.assertEqual(addr, copy.deepcopy(addr))
+
 
 class NetmaskTestMixin_v4(CommonTestMixin_v4):
     """Input validation on interfaces and networks is very similar"""
diff --git a/Lib/test/test_keywordonlyarg.py b/Lib/test/test_keywordonlyarg.py
index df82f677a0..918f953cae 100644
--- a/Lib/test/test_keywordonlyarg.py
+++ b/Lib/test/test_keywordonlyarg.py
@@ -170,7 +170,7 @@ def f(v=a, x=b, *, y=c, z=d):
                 pass
         self.assertEqual(str(err.exception), "name 'b' is not defined")
         with self.assertRaises(NameError) as err:
-            f = lambda v=a, x=b, *, y=c, z=d: None
+            g = lambda v=a, x=b, *, y=c, z=d: None
         self.assertEqual(str(err.exception), "name 'b' is not defined")
 
 
diff --git a/Lib/test/test_listcomps.py b/Lib/test/test_listcomps.py
index 12f7bbd123..f95a78aff0 100644
--- a/Lib/test/test_listcomps.py
+++ b/Lib/test/test_listcomps.py
@@ -1,5 +1,6 @@
 import doctest
 import textwrap
+import types
 import unittest
 
 
@@ -92,7 +93,8 @@
 
 
 class ListComprehensionTest(unittest.TestCase):
-    def _check_in_scopes(self, code, outputs=None, ns=None, scopes=None, raises=()):
+    def _check_in_scopes(self, code, outputs=None, ns=None, scopes=None, raises=(),
+                         exec_func=exec):
         code = textwrap.dedent(code)
         scopes = scopes or ["module", "class", "function"]
         for scope in scopes:
@@ -119,7 +121,7 @@ def get_output(moddict, name):
                         return moddict[name]
                 newns = ns.copy() if ns else {}
                 try:
-                    exec(newcode, newns)
+                    exec_func(newcode, newns)
                 except raises as e:
                     # We care about e.g. NameError vs UnboundLocalError
                     self.assertIs(type(e), raises)
@@ -613,6 +615,45 @@ def test_frame_locals(self):
         import sys
         self._check_in_scopes(code, {"val": 0}, ns={"sys": sys})
 
+    def _recursive_replace(self, maybe_code):
+        if not isinstance(maybe_code, types.CodeType):
+            return maybe_code
+        return maybe_code.replace(co_consts=tuple(
+            self._recursive_replace(c) for c in maybe_code.co_consts
+        ))
+
+    def _replacing_exec(self, code_string, ns):
+        co = compile(code_string, "<string>", "exec")
+        co = self._recursive_replace(co)
+        exec(co, ns)
+
+    def test_code_replace(self):
+        code = """
+            x = 3
+            [x for x in (1, 2)]
+            dir()
+            y = [x]
+        """
+        self._check_in_scopes(code, {"y": [3], "x": 3})
+        self._check_in_scopes(code, {"y": [3], "x": 3}, exec_func=self._replacing_exec)
+
+    def test_code_replace_extended_arg(self):
+        num_names = 300
+        assignments = "; ".join(f"x{i} = {i}" for i in range(num_names))
+        name_list = ", ".join(f"x{i}" for i in range(num_names))
+        expected = {
+            "y": list(range(num_names)),
+            **{f"x{i}": i for i in range(num_names)}
+        }
+        code = f"""
+            {assignments}
+            [({name_list}) for {name_list} in (range(300),)]
+            dir()
+            y = [{name_list}]
+        """
+        self._check_in_scopes(code, expected)
+        self._check_in_scopes(code, expected, exec_func=self._replacing_exec)
+
 
 __test__ = {'doctests' : doctests}
 
diff --git a/Lib/test/test_logging.py b/Lib/test/test_logging.py
index b7f4c6edf1..a2300daff9 100644
--- a/Lib/test/test_logging.py
+++ b/Lib/test/test_logging.py
@@ -76,6 +76,13 @@
     pass
 
 
+# gh-89363: Skip fork() test if Python is built with Address Sanitizer (ASAN)
+# to work around a libasan race condition, dead lock in pthread_create().
+skip_if_asan_fork = unittest.skipIf(
+    support.HAVE_ASAN_FORK_BUG,
+    "libasan has a pthread_create() dead lock related to thread+fork")
+
+
 class BaseTest(unittest.TestCase):
 
     """Base class for logging tests."""
@@ -730,6 +737,7 @@ def remove_loop(fname, tries):
     # register_at_fork mechanism is also present and used.
     @support.requires_fork()
     @threading_helper.requires_working_threading()
+    @skip_if_asan_fork
     def test_post_fork_child_no_deadlock(self):
         """Ensure child logging locks are not held; bpo-6721 & bpo-36533."""
         class _OurHandler(logging.Handler):
@@ -2170,7 +2178,7 @@ def test_output(self):
                     sslctx = None
                 else:
                     here = os.path.dirname(__file__)
-                    localhost_cert = os.path.join(here, "keycert.pem")
+                    localhost_cert = os.path.join(here, "certdata", "keycert.pem")
                     sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
                     sslctx.load_cert_chain(localhost_cert)
 
diff --git a/Lib/test/test_math.py b/Lib/test/test_math.py
index 2bda610121..faf067235c 100644
--- a/Lib/test/test_math.py
+++ b/Lib/test/test_math.py
@@ -1292,6 +1292,7 @@ def test_sumprod_accuracy(self):
         sumprod = math.sumprod
         self.assertEqual(sumprod([0.1] * 10, [1]*10), 1.0)
         self.assertEqual(sumprod([0.1] * 20, [True, False] * 10), 1.0)
+        self.assertEqual(sumprod([True, False] * 10, [0.1] * 20), 1.0)
         self.assertEqual(sumprod([1.0, 10E100, 1.0, -10E100], [1.0]*4), 2.0)
 
     @support.requires_resource('cpu')
diff --git a/Lib/test/test_memoryio.py b/Lib/test/test_memoryio.py
index cd2faba179..731299294e 100644
--- a/Lib/test/test_memoryio.py
+++ b/Lib/test/test_memoryio.py
@@ -463,6 +463,20 @@ def test_getbuffer(self):
         memio.close()
         self.assertRaises(ValueError, memio.getbuffer)
 
+    def test_getbuffer_empty(self):
+        memio = self.ioclass()
+        buf = memio.getbuffer()
+        self.assertEqual(bytes(buf), b"")
+        # Trying to change the size of the BytesIO while a buffer is exported
+        # raises a BufferError.
+        self.assertRaises(BufferError, memio.write, b'x')
+        buf2 = memio.getbuffer()
+        self.assertRaises(BufferError, memio.write, b'x')
+        buf.release()
+        self.assertRaises(BufferError, memio.write, b'x')
+        buf2.release()
+        memio.write(b'x')
+
     def test_read1(self):
         buf = self.buftype("1234567890")
         self.assertEqual(self.ioclass(buf).read1(), buf)
diff --git a/Lib/test/test_module/__init__.py b/Lib/test/test_module/__init__.py
index cfc4d9ccf1..2524e6c87c 100644
--- a/Lib/test/test_module/__init__.py
+++ b/Lib/test/test_module/__init__.py
@@ -324,7 +324,9 @@ def test_annotations_getset_raises(self):
             del foo.__annotations__
 
     def test_annotations_are_created_correctly(self):
-        ann_module4 = import_helper.import_fresh_module('test.ann_module4')
+        ann_module4 = import_helper.import_fresh_module(
+            'test.typinganndata.ann_module4',
+        )
         self.assertTrue("__annotations__" in ann_module4.__dict__)
         del ann_module4.__annotations__
         self.assertFalse("__annotations__" in ann_module4.__dict__)
diff --git a/Lib/test/test_monitoring.py b/Lib/test/test_monitoring.py
index 8c9755d2a4..8eaf581b8d 100644
--- a/Lib/test/test_monitoring.py
+++ b/Lib/test/test_monitoring.py
@@ -1168,7 +1168,7 @@ def func1():
             ('instruction', 'func1', 14),
             ('line', 'get_events', 11)])
 
-class TestInstallIncrementallly(MonitoringTestBase, unittest.TestCase):
+class TestInstallIncrementally(MonitoringTestBase, unittest.TestCase):
 
     def check_events(self, func, must_include, tool=TEST_TOOL, recorders=(ExceptionRecorder,)):
         try:
@@ -1197,19 +1197,19 @@ def func1():
 
     MUST_INCLUDE_LI = [
             ('instruction', 'func1', 2),
-            ('line', 'func1', 1),
+            ('line', 'func1', 2),
             ('instruction', 'func1', 4),
             ('instruction', 'func1', 6)]
 
     def test_line_then_instruction(self):
         recorders = [ LineRecorder, InstructionRecorder ]
         self.check_events(self.func1,
-                          recorders = recorders, must_include = self.EXPECTED_LI)
+                          recorders = recorders, must_include = self.MUST_INCLUDE_LI)
 
     def test_instruction_then_line(self):
-        recorders = [ InstructionRecorder, LineRecorderLowNoise ]
+        recorders = [ InstructionRecorder, LineRecorder ]
         self.check_events(self.func1,
-                          recorders = recorders, must_include = self.EXPECTED_LI)
+                          recorders = recorders, must_include = self.MUST_INCLUDE_LI)
 
     @staticmethod
     def func2():
@@ -1224,12 +1224,12 @@ def func2():
 
 
 
-    def test_line_then_instruction(self):
+    def test_call_then_instruction(self):
         recorders = [ CallRecorder, InstructionRecorder ]
         self.check_events(self.func2,
                           recorders = recorders, must_include = self.MUST_INCLUDE_CI)
 
-    def test_instruction_then_line(self):
+    def test_instruction_then_call(self):
         recorders = [ InstructionRecorder, CallRecorder ]
         self.check_events(self.func2,
                           recorders = recorders, must_include = self.MUST_INCLUDE_CI)
diff --git a/Lib/test/test_nntplib.py b/Lib/test/test_nntplib.py
index 31a02f86ab..30ae557978 100644
--- a/Lib/test/test_nntplib.py
+++ b/Lib/test/test_nntplib.py
@@ -20,7 +20,7 @@
     ssl = None
 
 
-certfile = os.path.join(os.path.dirname(__file__), 'keycert3.pem')
+certfile = os.path.join(os.path.dirname(__file__), 'certdata', 'keycert3.pem')
 
 if ssl is not None:
     SSLError = ssl.SSLError
diff --git a/Lib/test/test_opcodes.py b/Lib/test/test_opcodes.py
index e880c3f1ac..72488b2bb6 100644
--- a/Lib/test/test_opcodes.py
+++ b/Lib/test/test_opcodes.py
@@ -1,7 +1,8 @@
 # Python test set -- part 2, opcodes
 
 import unittest
-from test import ann_module, support
+from test import support
+from test.typinganndata import ann_module
 
 class OpcodeTest(unittest.TestCase):
 
diff --git a/Lib/test/test_os.py b/Lib/test/test_os.py
index 3cc5a6aaaf..38464c60a8 100644
--- a/Lib/test/test_os.py
+++ b/Lib/test/test_os.py
@@ -2559,30 +2559,34 @@ def _kill_with_event(self, event, name):
         tagname = "test_os_%s" % uuid.uuid1()
         m = mmap.mmap(-1, 1, tagname)
         m[0] = 0
+
         # Run a script which has console control handling enabled.
-        proc = subprocess.Popen([sys.executable,
-                   os.path.join(os.path.dirname(__file__),
-                                "win_console_handler.py"), tagname],
-                   creationflags=subprocess.CREATE_NEW_PROCESS_GROUP)
-        # Let the interpreter startup before we send signals. See #3137.
-        count, max = 0, 100
-        while count < max and proc.poll() is None:
-            if m[0] == 1:
-                break
-            time.sleep(0.1)
-            count += 1
-        else:
-            # Forcefully kill the process if we weren't able to signal it.
-            os.kill(proc.pid, signal.SIGINT)
-            self.fail("Subprocess didn't finish initialization")
-        os.kill(proc.pid, event)
-        # proc.send_signal(event) could also be done here.
-        # Allow time for the signal to be passed and the process to exit.
-        time.sleep(0.5)
-        if not proc.poll():
-            # Forcefully kill the process if we weren't able to signal it.
-            os.kill(proc.pid, signal.SIGINT)
-            self.fail("subprocess did not stop on {}".format(name))
+        script = os.path.join(os.path.dirname(__file__),
+                              "win_console_handler.py")
+        cmd = [sys.executable, script, tagname]
+        proc = subprocess.Popen(cmd,
+                                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP)
+
+        with proc:
+            # Let the interpreter startup before we send signals. See #3137.
+            for _ in support.sleeping_retry(support.SHORT_TIMEOUT):
+                if proc.poll() is None:
+                    break
+            else:
+                # Forcefully kill the process if we weren't able to signal it.
+                proc.kill()
+                self.fail("Subprocess didn't finish initialization")
+
+            os.kill(proc.pid, event)
+
+            try:
+                # proc.send_signal(event) could also be done here.
+                # Allow time for the signal to be passed and the process to exit.
+                proc.wait(timeout=support.SHORT_TIMEOUT)
+            except subprocess.TimeoutExpired:
+                # Forcefully kill the process if we weren't able to signal it.
+                proc.kill()
+                self.fail("subprocess did not stop on {}".format(name))
 
     @unittest.skip("subprocesses aren't inheriting Ctrl+C property")
     @support.requires_subprocess()
diff --git a/Lib/test/test_pathlib.py b/Lib/test/test_pathlib.py
index 012dacf10e..ec105ae1a0 100644
--- a/Lib/test/test_pathlib.py
+++ b/Lib/test/test_pathlib.py
@@ -546,6 +546,7 @@ def test_with_name_common(self):
         self.assertRaises(ValueError, P('.').with_name, 'd.xml')
         self.assertRaises(ValueError, P('/').with_name, 'd.xml')
         self.assertRaises(ValueError, P('a/b').with_name, '')
+        self.assertRaises(ValueError, P('a/b').with_name, '.')
         self.assertRaises(ValueError, P('a/b').with_name, '/c')
         self.assertRaises(ValueError, P('a/b').with_name, 'c/')
         self.assertRaises(ValueError, P('a/b').with_name, 'c/d')
@@ -563,6 +564,7 @@ def test_with_stem_common(self):
         self.assertRaises(ValueError, P('.').with_stem, 'd')
         self.assertRaises(ValueError, P('/').with_stem, 'd')
         self.assertRaises(ValueError, P('a/b').with_stem, '')
+        self.assertRaises(ValueError, P('a/b').with_stem, '.')
         self.assertRaises(ValueError, P('a/b').with_stem, '/c')
         self.assertRaises(ValueError, P('a/b').with_stem, 'c/')
         self.assertRaises(ValueError, P('a/b').with_stem, 'c/d')
@@ -1167,8 +1169,10 @@ def test_with_name(self):
         self.assertRaises(ValueError, P('c:').with_name, 'd.xml')
         self.assertRaises(ValueError, P('c:/').with_name, 'd.xml')
         self.assertRaises(ValueError, P('//My/Share').with_name, 'd.xml')
-        self.assertRaises(ValueError, P('c:a/b').with_name, 'd:')
-        self.assertRaises(ValueError, P('c:a/b').with_name, 'd:e')
+        self.assertEqual(str(P('a').with_name('d:')), '.\\d:')
+        self.assertEqual(str(P('a').with_name('d:e')), '.\\d:e')
+        self.assertEqual(P('c:a/b').with_name('d:'), P('c:a/d:'))
+        self.assertEqual(P('c:a/b').with_name('d:e'), P('c:a/d:e'))
         self.assertRaises(ValueError, P('c:a/b').with_name, 'd:/e')
         self.assertRaises(ValueError, P('c:a/b').with_name, '//My/Share')
 
@@ -1181,8 +1185,10 @@ def test_with_stem(self):
         self.assertRaises(ValueError, P('c:').with_stem, 'd')
         self.assertRaises(ValueError, P('c:/').with_stem, 'd')
         self.assertRaises(ValueError, P('//My/Share').with_stem, 'd')
-        self.assertRaises(ValueError, P('c:a/b').with_stem, 'd:')
-        self.assertRaises(ValueError, P('c:a/b').with_stem, 'd:e')
+        self.assertEqual(str(P('a').with_stem('d:')), '.\\d:')
+        self.assertEqual(str(P('a').with_stem('d:e')), '.\\d:e')
+        self.assertEqual(P('c:a/b').with_stem('d:'), P('c:a/d:'))
+        self.assertEqual(P('c:a/b').with_stem('d:e'), P('c:a/d:e'))
         self.assertRaises(ValueError, P('c:a/b').with_stem, 'd:/e')
         self.assertRaises(ValueError, P('c:a/b').with_stem, '//My/Share')
 
diff --git a/Lib/test/test_pdb.py b/Lib/test/test_pdb.py
index 5793dbfbfd..49a87b1bb4 100644
--- a/Lib/test/test_pdb.py
+++ b/Lib/test/test_pdb.py
@@ -662,8 +662,10 @@ def test_pdb_alias_command():
     ...     o.method()
 
     >>> with PdbTestInput([  # doctest: +ELLIPSIS
+    ...     'alias pi',
     ...     'alias pi for k in %1.__dict__.keys(): print(f"%1.{k} = {%1.__dict__[k]}")',
     ...     'alias ps pi self',
+    ...     'alias ps',
     ...     'pi o',
     ...     's',
     ...     'ps',
@@ -672,8 +674,12 @@ def test_pdb_alias_command():
     ...    test_function()
     > <doctest test.test_pdb.test_pdb_alias_command[1]>(4)test_function()
     -> o.method()
+    (Pdb) alias pi
+    *** Unknown alias 'pi'
     (Pdb) alias pi for k in %1.__dict__.keys(): print(f"%1.{k} = {%1.__dict__[k]}")
     (Pdb) alias ps pi self
+    (Pdb) alias ps
+    ps = pi self
     (Pdb) pi o
     o.attr1 = 10
     o.attr2 = str
@@ -1840,6 +1846,53 @@ def test_pdb_ambiguous_statements():
     (Pdb) continue
     """
 
+def test_pdb_issue_gh_65052():
+    """See GH-65052
+
+    args, retval and display should not crash if the object is not displayable
+    >>> class A:
+    ...     def __new__(cls):
+    ...         import pdb; pdb.Pdb(nosigint=True, readrc=False).set_trace()
+    ...         return object.__new__(cls)
+    ...     def __init__(self):
+    ...         import pdb; pdb.Pdb(nosigint=True, readrc=False).set_trace()
+    ...         self.a = 1
+    ...     def __repr__(self):
+    ...         return self.a
+
+    >>> def test_function():
+    ...     A()
+    >>> with PdbTestInput([  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
+    ...     's',
+    ...     'retval',
+    ...     'continue',
+    ...     'args',
+    ...     'display self',
+    ...     'display',
+    ...     'continue',
+    ... ]):
+    ...    test_function()
+    > <doctest test.test_pdb.test_pdb_issue_gh_65052[0]>(4)__new__()
+    -> return object.__new__(cls)
+    (Pdb) s
+    --Return--
+    > <doctest test.test_pdb.test_pdb_issue_gh_65052[0]>(4)__new__()-><A instance at ...>
+    -> return object.__new__(cls)
+    (Pdb) retval
+    *** repr(retval) failed: AttributeError: 'A' object has no attribute 'a' ***
+    (Pdb) continue
+    > <doctest test.test_pdb.test_pdb_issue_gh_65052[0]>(7)__init__()
+    -> self.a = 1
+    (Pdb) args
+    self = *** repr(self) failed: AttributeError: 'A' object has no attribute 'a' ***
+    (Pdb) display self
+    display self: *** repr(self) failed: AttributeError: 'A' object has no attribute 'a' ***
+    (Pdb) display
+    Currently displaying:
+    self: *** repr(self) failed: AttributeError: 'A' object has no attribute 'a' ***
+    (Pdb) continue
+    """
+
 
 @support.requires_subprocess()
 class PdbTestCase(unittest.TestCase):
@@ -2248,8 +2301,7 @@ def test_module_without_a_main(self):
         stdout, stderr = self._run_pdb(
             ['-m', module_name], "", expected_returncode=1
         )
-        self.assertIn("ImportError: No module named t_main.__main__",
-                      stdout.splitlines())
+        self.assertIn("ImportError: No module named t_main.__main__;", stdout)
 
     def test_package_without_a_main(self):
         pkg_name = 't_pkg'
@@ -2267,6 +2319,22 @@ def test_package_without_a_main(self):
             "'t_pkg.t_main' is a package and cannot be directly executed",
             stdout)
 
+    def test_nonexistent_module(self):
+        assert not os.path.exists(os_helper.TESTFN)
+        stdout, stderr = self._run_pdb(["-m", os_helper.TESTFN], "", expected_returncode=1)
+        self.assertIn(f"ImportError: No module named {os_helper.TESTFN}", stdout)
+
+    def test_dir_as_script(self):
+        with os_helper.temp_dir() as temp_dir:
+            stdout, stderr = self._run_pdb([temp_dir], "", expected_returncode=1)
+            self.assertIn(f"Error: {temp_dir} is a directory", stdout)
+
+    def test_invalid_cmd_line_options(self):
+        stdout, stderr = self._run_pdb(["-c"], "", expected_returncode=1)
+        self.assertIn(f"Error: option -c requires argument", stdout)
+        stdout, stderr = self._run_pdb(["--spam"], "", expected_returncode=1)
+        self.assertIn(f"Error: option --spam not recognized", stdout)
+
     def test_blocks_at_first_code_line(self):
         script = """
                 #This is a comment, on line 2
diff --git a/Lib/test/test_peg_generator/test_pegen.py b/Lib/test/test_peg_generator/test_pegen.py
index d92da7b29b..ec61199d6e 100644
--- a/Lib/test/test_peg_generator/test_pegen.py
+++ b/Lib/test/test_peg_generator/test_pegen.py
@@ -42,6 +42,15 @@ def test_parse_grammar(self) -> None:
         )
         self.assertEqual(repr(rules["term"]), expected_repr)
 
+    def test_repeated_rules(self) -> None:
+        grammar_source = """
+        start: the_rule NEWLINE
+        the_rule: 'b' NEWLINE
+        the_rule: 'a' NEWLINE
+        """
+        with self.assertRaisesRegex(GrammarError, "Repeated rule 'the_rule'"):
+            parse_string(grammar_source, GrammarParser)
+
     def test_long_rule_str(self) -> None:
         grammar_source = """
         start: zero | one | one zero | one one | one zero zero | one zero one | one one zero | one one one
diff --git a/Lib/test/test_perf_profiler.py b/Lib/test/test_perf_profiler.py
index 5418f9f354..fe8707a156 100644
--- a/Lib/test/test_perf_profiler.py
+++ b/Lib/test/test_perf_profiler.py
@@ -17,6 +17,11 @@
 if not support.has_subprocess_support:
     raise unittest.SkipTest("test module requires subprocess")
 
+if support.check_sanitizer(address=True, memory=True, ub=True):
+    # gh-109580: Skip the test because it does crash randomly if Python is
+    # built with ASAN.
+    raise unittest.SkipTest("test crash randomly on ASAN/MSAN/UBSAN build")
+
 
 def supports_trampoline_profiling():
     perf_trampoline = sysconfig.get_config_var("PY_HAVE_PERF_TRAMPOLINE")
@@ -287,7 +292,6 @@ def run_perf(cwd, *args, **env_vars):
 
 @unittest.skipUnless(perf_command_works(), "perf command doesn't work")
 @unittest.skipUnless(is_unwinding_reliable(), "Unwinding is unreliable")
-@support.skip_if_sanitizer(address=True, memory=True, ub=True)
 class TestPerfProfiler(unittest.TestCase):
     def setUp(self):
         super().setUp()
diff --git a/Lib/test/test_poplib.py b/Lib/test/test_poplib.py
index fa41ba0b6e..869f9431b9 100644
--- a/Lib/test/test_poplib.py
+++ b/Lib/test/test_poplib.py
@@ -29,8 +29,8 @@
     import ssl
 
     SUPPORTS_SSL = True
-    CERTFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "keycert3.pem")
-    CAFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "pycacert.pem")
+    CERTFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "certdata", "keycert3.pem")
+    CAFILE = os.path.join(os.path.dirname(__file__) or os.curdir, "certdata", "pycacert.pem")
 
 requires_ssl = skipUnless(SUPPORTS_SSL, 'SSL not supported')
 
diff --git a/Lib/test/test_posix.py b/Lib/test/test_posix.py
index 444f8abe46..9d72dba159 100644
--- a/Lib/test/test_posix.py
+++ b/Lib/test/test_posix.py
@@ -1205,6 +1205,7 @@ def test_sched_getaffinity(self):
     @requires_sched_affinity
     def test_sched_setaffinity(self):
         mask = posix.sched_getaffinity(0)
+        self.addCleanup(posix.sched_setaffinity, 0, list(mask))
         if len(mask) > 1:
             # Empty masks are forbidden
             mask.pop()
diff --git a/Lib/test/test_pty.py b/Lib/test/test_pty.py
index c9c2b42861..f31a68c5d8 100644
--- a/Lib/test/test_pty.py
+++ b/Lib/test/test_pty.py
@@ -76,21 +76,22 @@ def expectedFailureIfStdinIsTTY(fun):
         pass
     return fun
 
+
+def write_all(fd, data):
+    written = os.write(fd, data)
+    if written != len(data):
+        # gh-73256, gh-110673: It should never happen, but check just in case
+        raise Exception(f"short write: os.write({fd}, {len(data)} bytes) "
+                        f"wrote {written} bytes")
+
+
 # Marginal testing of pty suite. Cannot do extensive 'do or fail' testing
 # because pty code is not too portable.
 class PtyTest(unittest.TestCase):
     def setUp(self):
-        old_alarm = signal.signal(signal.SIGALRM, self.handle_sig)
-        self.addCleanup(signal.signal, signal.SIGALRM, old_alarm)
-
         old_sighup = signal.signal(signal.SIGHUP, self.handle_sighup)
         self.addCleanup(signal.signal, signal.SIGHUP, old_sighup)
 
-        # isatty() and close() can hang on some platforms. Set an alarm
-        # before running the test to make sure we don't hang forever.
-        self.addCleanup(signal.alarm, 0)
-        signal.alarm(10)
-
         # Save original stdin window size.
         self.stdin_dim = None
         if _HAVE_WINSZ:
@@ -101,9 +102,6 @@ def setUp(self):
             except tty.error:
                 pass
 
-    def handle_sig(self, sig, frame):
-        self.fail("isatty hung")
-
     @staticmethod
     def handle_sighup(signum, frame):
         pass
@@ -181,14 +179,14 @@ def test_openpty(self):
             os.set_blocking(master_fd, blocking)
 
         debug("Writing to slave_fd")
-        os.write(slave_fd, TEST_STRING_1)
+        write_all(slave_fd, TEST_STRING_1)
         s1 = _readline(master_fd)
         self.assertEqual(b'I wish to buy a fish license.\n',
                          normalize_output(s1))
 
         debug("Writing chunked output")
-        os.write(slave_fd, TEST_STRING_2[:5])
-        os.write(slave_fd, TEST_STRING_2[5:])
+        write_all(slave_fd, TEST_STRING_2[:5])
+        write_all(slave_fd, TEST_STRING_2[5:])
         s2 = _readline(master_fd)
         self.assertEqual(b'For my pet fish, Eric.\n', normalize_output(s2))
 
@@ -371,8 +369,8 @@ def test__copy_to_each(self):
         masters = [s.fileno() for s in socketpair]
 
         # Feed data.  Smaller than PIPEBUF.  These writes will not block.
-        os.write(masters[1], b'from master')
-        os.write(write_to_stdin_fd, b'from stdin')
+        write_all(masters[1], b'from master')
+        write_all(write_to_stdin_fd, b'from stdin')
 
         # Expect three select calls, the last one will cause IndexError
         pty.select = self._mock_select
diff --git a/Lib/test/test_py_compile.py b/Lib/test/test_py_compile.py
index 5e0a44ad96..c4e6551f60 100644
--- a/Lib/test/test_py_compile.py
+++ b/Lib/test/test_py_compile.py
@@ -132,7 +132,9 @@ def test_exceptions_propagate(self):
             os.chmod(self.directory, mode.st_mode)
 
     def test_bad_coding(self):
-        bad_coding = os.path.join(os.path.dirname(__file__), 'bad_coding2.py')
+        bad_coding = os.path.join(os.path.dirname(__file__),
+                                  'tokenizedata',
+                                  'bad_coding2.py')
         with support.captured_stderr():
             self.assertIsNone(py_compile.compile(bad_coding, doraise=False))
         self.assertFalse(os.path.exists(
@@ -195,7 +197,9 @@ def test_invalidation_mode(self):
         self.assertEqual(flags, 0b1)
 
     def test_quiet(self):
-        bad_coding = os.path.join(os.path.dirname(__file__), 'bad_coding2.py')
+        bad_coding = os.path.join(os.path.dirname(__file__),
+                                  'tokenizedata',
+                                  'bad_coding2.py')
         with support.captured_stderr() as stderr:
             self.assertIsNone(py_compile.compile(bad_coding, doraise=False, quiet=2))
             self.assertIsNone(py_compile.compile(bad_coding, doraise=True, quiet=2))
@@ -260,14 +264,18 @@ def test_with_files(self):
         self.assertTrue(os.path.exists(self.cache_path))
 
     def test_bad_syntax(self):
-        bad_syntax = os.path.join(os.path.dirname(__file__), 'badsyntax_3131.py')
+        bad_syntax = os.path.join(os.path.dirname(__file__),
+                                  'tokenizedata',
+                                  'badsyntax_3131.py')
         rc, stdout, stderr = self.pycompilecmd_failure(bad_syntax)
         self.assertEqual(rc, 1)
         self.assertEqual(stdout, b'')
         self.assertIn(b'SyntaxError', stderr)
 
     def test_bad_syntax_with_quiet(self):
-        bad_syntax = os.path.join(os.path.dirname(__file__), 'badsyntax_3131.py')
+        bad_syntax = os.path.join(os.path.dirname(__file__),
+                                  'tokenizedata',
+                                  'badsyntax_3131.py')
         rc, stdout, stderr = self.pycompilecmd_failure('-q', bad_syntax)
         self.assertEqual(rc, 1)
         self.assertEqual(stdout, b'')
diff --git a/Lib/test/test_re.py b/Lib/test/test_re.py
index 5a5de523eb..656429ba85 100644
--- a/Lib/test/test_re.py
+++ b/Lib/test/test_re.py
@@ -1799,6 +1799,29 @@ def test_repeat_minmax_overflow(self):
         self.assertRaises(OverflowError, re.compile, r".{%d,}?" % 2**128)
         self.assertRaises(OverflowError, re.compile, r".{%d,%d}" % (2**129, 2**128))
 
+    def test_look_behind_overflow(self):
+        string = "x" * 2_500_000
+        p1 = r"(?<=((.{%d}){%d}){%d})"
+        p2 = r"(?<!((.{%d}){%d}){%d})"
+        # Test that the templates are valid and look-behind with width 2**21
+        # (larger than sys.maxunicode) are supported.
+        self.assertEqual(re.search(p1 % (2**7, 2**7, 2**7), string).span(),
+                         (2**21, 2**21))
+        self.assertEqual(re.search(p2 % (2**7, 2**7, 2**7), string).span(),
+                         (0, 0))
+        # Test that 2**22 is accepted as a repetition number and look-behind
+        # width.
+        re.compile(p1 % (2**22, 1, 1))
+        re.compile(p1 % (1, 2**22, 1))
+        re.compile(p1 % (1, 1, 2**22))
+        re.compile(p2 % (2**22, 1, 1))
+        re.compile(p2 % (1, 2**22, 1))
+        re.compile(p2 % (1, 1, 2**22))
+        # But 2**66 is too large for look-behind width.
+        errmsg = "looks too much behind"
+        self.assertRaisesRegex(re.error, errmsg, re.compile, p1 % (2**22, 2**22, 2**22))
+        self.assertRaisesRegex(re.error, errmsg, re.compile, p2 % (2**22, 2**22, 2**22))
+
     def test_backref_group_name_in_exception(self):
         # Issue 17341: Poor error message when compiling invalid regex
         self.checkPatternError('(?P=<foo>)',
@@ -2694,6 +2717,9 @@ def test_dealloc(self):
             _sre.compile("abc", 0, [long_overflow], 0, {}, ())
         with self.assertRaises(TypeError):
             _sre.compile({}, 0, [], 0, [], [])
+        # gh-110590: `TypeError` was overwritten with `OverflowError`:
+        with self.assertRaises(TypeError):
+            _sre.compile('', 0, ['abc'], 0, {}, ())
 
     @cpython_only
     def test_repeat_minmax_overflow_maxrepeat(self):
diff --git a/Lib/test/test_regrtest.py b/Lib/test/test_regrtest.py
index a72c052cb8..2f1bb03bc0 100644
--- a/Lib/test/test_regrtest.py
+++ b/Lib/test/test_regrtest.py
@@ -11,18 +11,25 @@
 import locale
 import os.path
 import platform
+import random
 import re
+import shlex
+import signal
 import subprocess
 import sys
 import sysconfig
 import tempfile
 import textwrap
 import unittest
-from test import libregrtest
 from test import support
-from test.support import os_helper, TestStats
-from test.libregrtest import utils, setup
-from test.libregrtest.runtest import normalize_test_name
+from test.support import os_helper
+from test.libregrtest import cmdline
+from test.libregrtest import main
+from test.libregrtest import setup
+from test.libregrtest import utils
+from test.libregrtest.filter import set_match_tests, match_test
+from test.libregrtest.result import TestStats
+from test.libregrtest.utils import normalize_test_name
 
 if not support.has_subprocess_support:
     raise unittest.SkipTest("test module requires subprocess")
@@ -52,9 +59,13 @@ class ParseArgsTestCase(unittest.TestCase):
     Test regrtest's argument parsing, function _parse_args().
     """
 
+    @staticmethod
+    def parse_args(args):
+        return cmdline._parse_args(args)
+
     def checkError(self, args, msg):
         with support.captured_stderr() as err, self.assertRaises(SystemExit):
-            libregrtest._parse_args(args)
+            self.parse_args(args)
         self.assertIn(msg, err.getvalue())
 
     def test_help(self):
@@ -62,83 +73,101 @@ def test_help(self):
             with self.subTest(opt=opt):
                 with support.captured_stdout() as out, \
                      self.assertRaises(SystemExit):
-                    libregrtest._parse_args([opt])
+                    self.parse_args([opt])
                 self.assertIn('Run Python regression tests.', out.getvalue())
 
     def test_timeout(self):
-        ns = libregrtest._parse_args(['--timeout', '4.2'])
+        ns = self.parse_args(['--timeout', '4.2'])
         self.assertEqual(ns.timeout, 4.2)
+
+        # negative, zero and empty string are treated as "no timeout"
+        for value in ('-1', '0', ''):
+            with self.subTest(value=value):
+                ns = self.parse_args([f'--timeout={value}'])
+                self.assertEqual(ns.timeout, None)
+
         self.checkError(['--timeout'], 'expected one argument')
-        self.checkError(['--timeout', 'foo'], 'invalid float value')
+        self.checkError(['--timeout', 'foo'], 'invalid timeout value:')
 
     def test_wait(self):
-        ns = libregrtest._parse_args(['--wait'])
+        ns = self.parse_args(['--wait'])
         self.assertTrue(ns.wait)
 
-    def test_worker_args(self):
-        ns = libregrtest._parse_args(['--worker-args', '[[], {}]'])
-        self.assertEqual(ns.worker_args, '[[], {}]')
-        self.checkError(['--worker-args'], 'expected one argument')
-
     def test_start(self):
         for opt in '-S', '--start':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, 'foo'])
+                ns = self.parse_args([opt, 'foo'])
                 self.assertEqual(ns.start, 'foo')
                 self.checkError([opt], 'expected one argument')
 
     def test_verbose(self):
-        ns = libregrtest._parse_args(['-v'])
+        ns = self.parse_args(['-v'])
         self.assertEqual(ns.verbose, 1)
-        ns = libregrtest._parse_args(['-vvv'])
+        ns = self.parse_args(['-vvv'])
         self.assertEqual(ns.verbose, 3)
-        ns = libregrtest._parse_args(['--verbose'])
+        ns = self.parse_args(['--verbose'])
         self.assertEqual(ns.verbose, 1)
-        ns = libregrtest._parse_args(['--verbose'] * 3)
+        ns = self.parse_args(['--verbose'] * 3)
         self.assertEqual(ns.verbose, 3)
-        ns = libregrtest._parse_args([])
+        ns = self.parse_args([])
         self.assertEqual(ns.verbose, 0)
 
     def test_rerun(self):
         for opt in '-w', '--rerun', '--verbose2':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.rerun)
 
     def test_verbose3(self):
         for opt in '-W', '--verbose3':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.verbose3)
 
     def test_quiet(self):
         for opt in '-q', '--quiet':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.quiet)
                 self.assertEqual(ns.verbose, 0)
 
     def test_slowest(self):
         for opt in '-o', '--slowest':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.print_slow)
 
     def test_header(self):
-        ns = libregrtest._parse_args(['--header'])
+        ns = self.parse_args(['--header'])
         self.assertTrue(ns.header)
 
-        ns = libregrtest._parse_args(['--verbose'])
+        ns = self.parse_args(['--verbose'])
         self.assertTrue(ns.header)
 
     def test_randomize(self):
-        for opt in '-r', '--randomize':
+        for opt in ('-r', '--randomize'):
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.randomize)
 
+        with os_helper.EnvironmentVarGuard() as env:
+            # with SOURCE_DATE_EPOCH
+            env['SOURCE_DATE_EPOCH'] = '1697839080'
+            ns = self.parse_args(['--randomize'])
+            regrtest = main.Regrtest(ns)
+            self.assertFalse(regrtest.randomize)
+            self.assertIsInstance(regrtest.random_seed, str)
+            self.assertEqual(regrtest.random_seed, '1697839080')
+
+            # without SOURCE_DATE_EPOCH
+            del env['SOURCE_DATE_EPOCH']
+            ns = self.parse_args(['--randomize'])
+            regrtest = main.Regrtest(ns)
+            self.assertTrue(regrtest.randomize)
+            self.assertIsInstance(regrtest.random_seed, int)
+
     def test_randseed(self):
-        ns = libregrtest._parse_args(['--randseed', '12345'])
+        ns = self.parse_args(['--randseed', '12345'])
         self.assertEqual(ns.random_seed, 12345)
         self.assertTrue(ns.randomize)
         self.checkError(['--randseed'], 'expected one argument')
@@ -147,7 +176,7 @@ def test_randseed(self):
     def test_fromfile(self):
         for opt in '-f', '--fromfile':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, 'foo'])
+                ns = self.parse_args([opt, 'foo'])
                 self.assertEqual(ns.fromfile, 'foo')
                 self.checkError([opt], 'expected one argument')
                 self.checkError([opt, 'foo', '-s'], "don't go together")
@@ -155,44 +184,37 @@ def test_fromfile(self):
     def test_exclude(self):
         for opt in '-x', '--exclude':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.exclude)
 
     def test_single(self):
         for opt in '-s', '--single':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.single)
                 self.checkError([opt, '-f', 'foo'], "don't go together")
 
-    def test_ignore(self):
-        for opt in '-i', '--ignore':
+    def test_match(self):
+        for opt in '-m', '--match':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, 'pattern'])
-                self.assertEqual(ns.ignore_tests, ['pattern'])
+                ns = self.parse_args([opt, 'pattern'])
+                self.assertEqual(ns.match_tests, [('pattern', True)])
                 self.checkError([opt], 'expected one argument')
 
-        self.addCleanup(os_helper.unlink, os_helper.TESTFN)
-        with open(os_helper.TESTFN, "w") as fp:
-            print('matchfile1', file=fp)
-            print('matchfile2', file=fp)
-
-        filename = os.path.abspath(os_helper.TESTFN)
-        ns = libregrtest._parse_args(['-m', 'match',
-                                      '--ignorefile', filename])
-        self.assertEqual(ns.ignore_tests,
-                         ['matchfile1', 'matchfile2'])
-
-    def test_match(self):
-        for opt in '-m', '--match':
+        for opt in '-i', '--ignore':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, 'pattern'])
-                self.assertEqual(ns.match_tests, ['pattern'])
+                ns = self.parse_args([opt, 'pattern'])
+                self.assertEqual(ns.match_tests, [('pattern', False)])
                 self.checkError([opt], 'expected one argument')
 
-        ns = libregrtest._parse_args(['-m', 'pattern1',
-                                      '-m', 'pattern2'])
-        self.assertEqual(ns.match_tests, ['pattern1', 'pattern2'])
+        ns = self.parse_args(['-m', 'pattern1', '-m', 'pattern2'])
+        self.assertEqual(ns.match_tests, [('pattern1', True), ('pattern2', True)])
+
+        ns = self.parse_args(['-m', 'pattern1', '-i', 'pattern2'])
+        self.assertEqual(ns.match_tests, [('pattern1', True), ('pattern2', False)])
+
+        ns = self.parse_args(['-i', 'pattern1', '-m', 'pattern2'])
+        self.assertEqual(ns.match_tests, [('pattern1', False), ('pattern2', True)])
 
         self.addCleanup(os_helper.unlink, os_helper.TESTFN)
         with open(os_helper.TESTFN, "w") as fp:
@@ -200,73 +222,76 @@ def test_match(self):
             print('matchfile2', file=fp)
 
         filename = os.path.abspath(os_helper.TESTFN)
-        ns = libregrtest._parse_args(['-m', 'match',
-                                      '--matchfile', filename])
+        ns = self.parse_args(['-m', 'match', '--matchfile', filename])
+        self.assertEqual(ns.match_tests,
+                         [('match', True), ('matchfile1', True), ('matchfile2', True)])
+
+        ns = self.parse_args(['-i', 'match', '--ignorefile', filename])
         self.assertEqual(ns.match_tests,
-                         ['match', 'matchfile1', 'matchfile2'])
+                         [('match', False), ('matchfile1', False), ('matchfile2', False)])
 
     def test_failfast(self):
         for opt in '-G', '--failfast':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, '-v'])
+                ns = self.parse_args([opt, '-v'])
                 self.assertTrue(ns.failfast)
-                ns = libregrtest._parse_args([opt, '-W'])
+                ns = self.parse_args([opt, '-W'])
                 self.assertTrue(ns.failfast)
                 self.checkError([opt], '-G/--failfast needs either -v or -W')
 
     def test_use(self):
         for opt in '-u', '--use':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, 'gui,network'])
+                ns = self.parse_args([opt, 'gui,network'])
                 self.assertEqual(ns.use_resources, ['gui', 'network'])
 
-                ns = libregrtest._parse_args([opt, 'gui,none,network'])
+                ns = self.parse_args([opt, 'gui,none,network'])
                 self.assertEqual(ns.use_resources, ['network'])
 
-                expected = list(libregrtest.ALL_RESOURCES)
+                expected = list(cmdline.ALL_RESOURCES)
                 expected.remove('gui')
-                ns = libregrtest._parse_args([opt, 'all,-gui'])
+                ns = self.parse_args([opt, 'all,-gui'])
                 self.assertEqual(ns.use_resources, expected)
                 self.checkError([opt], 'expected one argument')
                 self.checkError([opt, 'foo'], 'invalid resource')
 
                 # all + a resource not part of "all"
-                ns = libregrtest._parse_args([opt, 'all,tzdata'])
+                ns = self.parse_args([opt, 'all,tzdata'])
                 self.assertEqual(ns.use_resources,
-                                 list(libregrtest.ALL_RESOURCES) + ['tzdata'])
+                                 list(cmdline.ALL_RESOURCES) + ['tzdata'])
 
                 # test another resource which is not part of "all"
-                ns = libregrtest._parse_args([opt, 'extralargefile'])
+                ns = self.parse_args([opt, 'extralargefile'])
                 self.assertEqual(ns.use_resources, ['extralargefile'])
 
     def test_memlimit(self):
         for opt in '-M', '--memlimit':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, '4G'])
+                ns = self.parse_args([opt, '4G'])
                 self.assertEqual(ns.memlimit, '4G')
                 self.checkError([opt], 'expected one argument')
 
     def test_testdir(self):
-        ns = libregrtest._parse_args(['--testdir', 'foo'])
+        ns = self.parse_args(['--testdir', 'foo'])
         self.assertEqual(ns.testdir, os.path.join(os_helper.SAVEDCWD, 'foo'))
         self.checkError(['--testdir'], 'expected one argument')
 
     def test_runleaks(self):
         for opt in '-L', '--runleaks':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.runleaks)
 
     def test_huntrleaks(self):
         for opt in '-R', '--huntrleaks':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, ':'])
+                ns = self.parse_args([opt, ':'])
                 self.assertEqual(ns.huntrleaks, (5, 4, 'reflog.txt'))
-                ns = libregrtest._parse_args([opt, '6:'])
+                ns = self.parse_args([opt, '6:'])
                 self.assertEqual(ns.huntrleaks, (6, 4, 'reflog.txt'))
-                ns = libregrtest._parse_args([opt, ':3'])
+                ns = self.parse_args([opt, ':3'])
                 self.assertEqual(ns.huntrleaks, (5, 3, 'reflog.txt'))
-                ns = libregrtest._parse_args([opt, '6:3:leaks.log'])
+                ns = self.parse_args([opt, '6:3:leaks.log'])
                 self.assertEqual(ns.huntrleaks, (6, 3, 'leaks.log'))
                 self.checkError([opt], 'expected one argument')
                 self.checkError([opt, '6'],
@@ -277,7 +302,7 @@ def test_huntrleaks(self):
     def test_multiprocess(self):
         for opt in '-j', '--multiprocess':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, '2'])
+                ns = self.parse_args([opt, '2'])
                 self.assertEqual(ns.use_mp, 2)
                 self.checkError([opt], 'expected one argument')
                 self.checkError([opt, 'foo'], 'invalid int value')
@@ -287,13 +312,13 @@ def test_multiprocess(self):
     def test_coverage(self):
         for opt in '-T', '--coverage':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.trace)
 
     def test_coverdir(self):
         for opt in '-D', '--coverdir':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, 'foo'])
+                ns = self.parse_args([opt, 'foo'])
                 self.assertEqual(ns.coverdir,
                                  os.path.join(os_helper.SAVEDCWD, 'foo'))
                 self.checkError([opt], 'expected one argument')
@@ -301,13 +326,13 @@ def test_coverdir(self):
     def test_nocoverdir(self):
         for opt in '-N', '--nocoverdir':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertIsNone(ns.coverdir)
 
     def test_threshold(self):
         for opt in '-t', '--threshold':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt, '1000'])
+                ns = self.parse_args([opt, '1000'])
                 self.assertEqual(ns.threshold, 1000)
                 self.checkError([opt], 'expected one argument')
                 self.checkError([opt, 'foo'], 'invalid int value')
@@ -316,7 +341,7 @@ def test_nowindows(self):
         for opt in '-n', '--nowindows':
             with self.subTest(opt=opt):
                 with contextlib.redirect_stderr(io.StringIO()) as stderr:
-                    ns = libregrtest._parse_args([opt])
+                    ns = self.parse_args([opt])
                 self.assertTrue(ns.nowindows)
                 err = stderr.getvalue()
                 self.assertIn('the --nowindows (-n) option is deprecated', err)
@@ -324,39 +349,39 @@ def test_nowindows(self):
     def test_forever(self):
         for opt in '-F', '--forever':
             with self.subTest(opt=opt):
-                ns = libregrtest._parse_args([opt])
+                ns = self.parse_args([opt])
                 self.assertTrue(ns.forever)
 
     def test_unrecognized_argument(self):
         self.checkError(['--xxx'], 'usage:')
 
     def test_long_option__partial(self):
-        ns = libregrtest._parse_args(['--qui'])
+        ns = self.parse_args(['--qui'])
         self.assertTrue(ns.quiet)
         self.assertEqual(ns.verbose, 0)
 
     def test_two_options(self):
-        ns = libregrtest._parse_args(['--quiet', '--exclude'])
+        ns = self.parse_args(['--quiet', '--exclude'])
         self.assertTrue(ns.quiet)
         self.assertEqual(ns.verbose, 0)
         self.assertTrue(ns.exclude)
 
     def test_option_with_empty_string_value(self):
-        ns = libregrtest._parse_args(['--start', ''])
+        ns = self.parse_args(['--start', ''])
         self.assertEqual(ns.start, '')
 
     def test_arg(self):
-        ns = libregrtest._parse_args(['foo'])
+        ns = self.parse_args(['foo'])
         self.assertEqual(ns.args, ['foo'])
 
     def test_option_and_arg(self):
-        ns = libregrtest._parse_args(['--quiet', 'foo'])
+        ns = self.parse_args(['--quiet', 'foo'])
         self.assertTrue(ns.quiet)
         self.assertEqual(ns.verbose, 0)
         self.assertEqual(ns.args, ['foo'])
 
     def test_arg_option_arg(self):
-        ns = libregrtest._parse_args(['test_unaryop', '-v', 'test_binop'])
+        ns = self.parse_args(['test_unaryop', '-v', 'test_binop'])
         self.assertEqual(ns.verbose, 1)
         self.assertEqual(ns.args, ['test_unaryop', 'test_binop'])
 
@@ -364,6 +389,63 @@ def test_unknown_option(self):
         self.checkError(['--unknown-option'],
                         'unrecognized arguments: --unknown-option')
 
+    def check_ci_mode(self, args, use_resources, rerun=True):
+        ns = cmdline._parse_args(args)
+
+        # Check Regrtest attributes which are more reliable than Namespace
+        # which has an unclear API
+        with os_helper.EnvironmentVarGuard() as env:
+            # Ignore SOURCE_DATE_EPOCH env var if it's set
+            if 'SOURCE_DATE_EPOCH' in env:
+                del env['SOURCE_DATE_EPOCH']
+
+            regrtest = main.Regrtest(ns)
+
+        self.assertEqual(regrtest.num_workers, -1)
+        self.assertEqual(regrtest.want_rerun, rerun)
+        self.assertTrue(regrtest.randomize)
+        self.assertIsInstance(regrtest.random_seed, int)
+        self.assertTrue(regrtest.fail_env_changed)
+        self.assertTrue(regrtest.fail_rerun)
+        self.assertTrue(regrtest.print_slowest)
+        self.assertTrue(regrtest.output_on_failure)
+        self.assertEqual(sorted(regrtest.use_resources), sorted(use_resources))
+        return regrtest
+
+    def test_fast_ci(self):
+        args = ['--fast-ci']
+        use_resources = sorted(cmdline.ALL_RESOURCES)
+        use_resources.remove('cpu')
+        regrtest = self.check_ci_mode(args, use_resources)
+        self.assertEqual(regrtest.timeout, 10 * 60)
+
+    def test_fast_ci_python_cmd(self):
+        args = ['--fast-ci', '--python', 'python -X dev']
+        use_resources = sorted(cmdline.ALL_RESOURCES)
+        use_resources.remove('cpu')
+        regrtest = self.check_ci_mode(args, use_resources, rerun=False)
+        self.assertEqual(regrtest.timeout, 10 * 60)
+        self.assertEqual(regrtest.python_cmd, ('python', '-X', 'dev'))
+
+    def test_fast_ci_resource(self):
+        # it should be possible to override resources individually
+        args = ['--fast-ci', '-u-network']
+        use_resources = sorted(cmdline.ALL_RESOURCES)
+        use_resources.remove('cpu')
+        use_resources.remove('network')
+        self.check_ci_mode(args, use_resources)
+
+    def test_slow_ci(self):
+        args = ['--slow-ci']
+        use_resources = sorted(cmdline.ALL_RESOURCES)
+        regrtest = self.check_ci_mode(args, use_resources)
+        self.assertEqual(regrtest.timeout, 20 * 60)
+
+    def test_dont_add_python_opts(self):
+        args = ['--dont-add-python-opts']
+        ns = cmdline._parse_args(args)
+        self.assertFalse(ns._add_python_opts)
+
 
 @dataclasses.dataclass(slots=True)
 class Rerun:
@@ -419,10 +501,12 @@ def regex_search(self, regex, output):
             self.fail("%r not found in %r" % (regex, output))
         return match
 
-    def check_line(self, output, regex, full=False):
+    def check_line(self, output, pattern, full=False, regex=True):
+        if not regex:
+            pattern = re.escape(pattern)
         if full:
-            regex += '\n'
-        regex = re.compile(r'^' + regex, re.MULTILINE)
+            pattern += '\n'
+        regex = re.compile(r'^' + pattern, re.MULTILINE)
         self.assertRegex(output, regex)
 
     def parse_executed_tests(self, output):
@@ -431,13 +515,14 @@ def parse_executed_tests(self, output):
         parser = re.finditer(regex, output, re.MULTILINE)
         return list(match.group(1) for match in parser)
 
-    def check_executed_tests(self, output, tests, skipped=(), failed=(),
+    def check_executed_tests(self, output, tests, *, stats,
+                             skipped=(), failed=(),
                              env_changed=(), omitted=(),
                              rerun=None, run_no_tests=(),
                              resource_denied=(),
-                             randomize=False, interrupted=False,
+                             randomize=False, parallel=False, interrupted=False,
                              fail_env_changed=False,
-                             *, stats, forever=False, filtered=False):
+                             forever=False, filtered=False):
         if isinstance(tests, str):
             tests = [tests]
         if isinstance(skipped, str):
@@ -454,9 +539,11 @@ def check_executed_tests(self, output, tests, skipped=(), failed=(),
             run_no_tests = [run_no_tests]
         if isinstance(stats, int):
             stats = TestStats(stats)
+        if parallel:
+            randomize = True
 
         rerun_failed = []
-        if rerun is not None:
+        if rerun is not None and not env_changed:
             failed = [rerun.name]
             if not rerun.success:
                 rerun_failed.append(rerun.name)
@@ -493,7 +580,8 @@ def list_regex(line_format, tests):
             self.check_line(output, regex)
 
         if env_changed:
-            regex = list_regex('%s test%s altered the execution environment',
+            regex = list_regex(r'%s test%s altered the execution environment '
+                               r'\(env changed\)',
                                env_changed)
             self.check_line(output, regex)
 
@@ -504,7 +592,7 @@ def list_regex(line_format, tests):
         if rerun is not None:
             regex = list_regex('%s re-run test%s', [rerun.name])
             self.check_line(output, regex)
-            regex = LOG_PREFIX + fr"Re-running 1 failed tests in verbose mode"
+            regex = LOG_PREFIX + r"Re-running 1 failed tests in verbose mode"
             self.check_line(output, regex)
             regex = fr"Re-running {rerun.name} in verbose mode"
             if rerun.match:
@@ -583,24 +671,29 @@ def list_regex(line_format, tests):
         state = ', '.join(state)
         if rerun is not None:
             new_state = 'SUCCESS' if rerun.success else 'FAILURE'
-            state = 'FAILURE then ' + new_state
+            state = f'{state} then {new_state}'
         self.check_line(output, f'Result: {state}', full=True)
 
-    def parse_random_seed(self, output):
-        match = self.regex_search(r'Using random seed ([0-9]+)', output)
-        randseed = int(match.group(1))
-        self.assertTrue(0 <= randseed <= 10000000, randseed)
-        return randseed
+    def parse_random_seed(self, output: str) -> str:
+        match = self.regex_search(r'Using random seed: (.*)', output)
+        return match.group(1)
 
     def run_command(self, args, input=None, exitcode=0, **kw):
         if not input:
             input = ''
         if 'stderr' not in kw:
             kw['stderr'] = subprocess.STDOUT
+
+        env = kw.pop('env', None)
+        if env is None:
+            env = dict(os.environ)
+            env.pop('SOURCE_DATE_EPOCH', None)
+
         proc = subprocess.run(args,
-                              universal_newlines=True,
+                              text=True,
                               input=input,
                               stdout=subprocess.PIPE,
+                              env=env,
                               **kw)
         if proc.returncode != exitcode:
             msg = ("Command %s failed with exit code %s, but exit code %s expected!\n"
@@ -621,7 +714,11 @@ def run_command(self, args, input=None, exitcode=0, **kw):
         return proc
 
     def run_python(self, args, **kw):
-        args = [sys.executable, '-X', 'faulthandler', '-I', *args]
+        extraargs = []
+        if 'uops' in sys._xoptions:
+            # Pass -X uops along
+            extraargs.extend(['-X', 'uops'])
+        args = [sys.executable, *extraargs, '-X', 'faulthandler', '-I', *args]
         proc = self.run_command(args, **kw)
         return proc.stdout
 
@@ -672,12 +769,14 @@ def setUp(self):
             self.regrtest_args.append('-n')
 
     def check_output(self, output):
-        self.parse_random_seed(output)
+        randseed = self.parse_random_seed(output)
+        self.assertTrue(randseed.isdigit(), randseed)
+
         self.check_executed_tests(output, self.tests,
                                   randomize=True, stats=len(self.tests))
 
-    def run_tests(self, args):
-        output = self.run_python(args)
+    def run_tests(self, args, env=None):
+        output = self.run_python(args, env=env)
         self.check_output(output)
 
     def test_script_regrtest(self):
@@ -718,14 +817,6 @@ def test_script_autotest(self):
         args = [*self.python_args, script, *self.regrtest_args, *self.tests]
         self.run_tests(args)
 
-    @unittest.skipUnless(sysconfig.is_python_build(),
-                         'run_tests.py script is not installed')
-    def test_tools_script_run_tests(self):
-        # Tools/scripts/run_tests.py
-        script = os.path.join(ROOT_DIR, 'Tools', 'scripts', 'run_tests.py')
-        args = [script, *self.regrtest_args, *self.tests]
-        self.run_tests(args)
-
     def run_batch(self, *args):
         proc = self.run_command(args)
         self.check_output(proc.stdout)
@@ -871,7 +962,7 @@ def test_random(self):
         test_random = int(match.group(1))
 
         # try to reproduce with the random seed
-        output = self.run_tests('-r', '--randseed=%s' % randseed, test,
+        output = self.run_tests('-r', f'--randseed={randseed}', test,
                                 exitcode=EXITCODE_NO_TESTS_RAN)
         randseed2 = self.parse_random_seed(output)
         self.assertEqual(randseed2, randseed)
@@ -880,6 +971,35 @@ def test_random(self):
         test_random2 = int(match.group(1))
         self.assertEqual(test_random2, test_random)
 
+        # check that random.seed is used by default
+        output = self.run_tests(test, exitcode=EXITCODE_NO_TESTS_RAN)
+        randseed = self.parse_random_seed(output)
+        self.assertTrue(randseed.isdigit(), randseed)
+
+        # check SOURCE_DATE_EPOCH (integer)
+        timestamp = '1697839080'
+        env = dict(os.environ, SOURCE_DATE_EPOCH=timestamp)
+        output = self.run_tests('-r', test, exitcode=EXITCODE_NO_TESTS_RAN,
+                                env=env)
+        randseed = self.parse_random_seed(output)
+        self.assertEqual(randseed, timestamp)
+        self.check_line(output, 'TESTRANDOM: 520')
+
+        # check SOURCE_DATE_EPOCH (string)
+        env = dict(os.environ, SOURCE_DATE_EPOCH='XYZ')
+        output = self.run_tests('-r', test, exitcode=EXITCODE_NO_TESTS_RAN,
+                                env=env)
+        randseed = self.parse_random_seed(output)
+        self.assertEqual(randseed, 'XYZ')
+        self.check_line(output, 'TESTRANDOM: 22')
+
+        # check SOURCE_DATE_EPOCH (empty string): ignore the env var
+        env = dict(os.environ, SOURCE_DATE_EPOCH='')
+        output = self.run_tests('-r', test, exitcode=EXITCODE_NO_TESTS_RAN,
+                                env=env)
+        randseed = self.parse_random_seed(output)
+        self.assertTrue(randseed.isdigit(), randseed)
+
     def test_fromfile(self):
         # test --fromfile
         tests = [self.create_test() for index in range(5)]
@@ -1014,12 +1134,16 @@ def test_run(self):
                                   stats=TestStats(4, 1),
                                   forever=True)
 
-    def check_leak(self, code, what):
+    def check_leak(self, code, what, *, run_workers=False):
         test = self.create_test('huntrleaks', code=code)
 
         filename = 'reflog.txt'
         self.addCleanup(os_helper.unlink, filename)
-        output = self.run_tests('--huntrleaks', '3:3:', test,
+        cmd = ['--huntrleaks', '3:3:']
+        if run_workers:
+            cmd.append('-j1')
+        cmd.append(test)
+        output = self.run_tests(*cmd,
                                 exitcode=EXITCODE_BAD_TEST,
                                 stderr=subprocess.STDOUT)
         self.check_executed_tests(output, [test], failed=test, stats=1)
@@ -1035,7 +1159,7 @@ def check_leak(self, code, what):
             self.assertIn(line2, reflog)
 
     @unittest.skipUnless(support.Py_DEBUG, 'need a debug build')
-    def test_huntrleaks(self):
+    def check_huntrleaks(self, *, run_workers: bool):
         # test --huntrleaks
         code = textwrap.dedent("""
             import unittest
@@ -1046,7 +1170,13 @@ class RefLeakTest(unittest.TestCase):
                 def test_leak(self):
                     GLOBAL_LIST.append(object())
         """)
-        self.check_leak(code, 'references')
+        self.check_leak(code, 'references', run_workers=run_workers)
+
+    def test_huntrleaks(self):
+        self.check_huntrleaks(run_workers=False)
+
+    def test_huntrleaks_mp(self):
+        self.check_huntrleaks(run_workers=True)
 
     @unittest.skipUnless(support.Py_DEBUG, 'need a debug build')
     def test_huntrleaks_fd_leak(self):
@@ -1104,7 +1234,7 @@ def test_crashed(self):
         tests = [crash_test]
         output = self.run_tests("-j2", *tests, exitcode=EXITCODE_BAD_TEST)
         self.check_executed_tests(output, tests, failed=crash_test,
-                                  randomize=True, stats=0)
+                                  parallel=True, stats=0)
 
     def parse_methods(self, output):
         regex = re.compile("^(test[^ ]+).*ok$", flags=re.MULTILINE)
@@ -1124,8 +1254,6 @@ def test_method3(self):
                 def test_method4(self):
                     pass
         """)
-        all_methods = ['test_method1', 'test_method2',
-                       'test_method3', 'test_method4']
         testname = self.create_test(code=code)
 
         # only run a subset
@@ -1208,6 +1336,15 @@ def test_env_changed(self):
         self.check_executed_tests(output, [testname], env_changed=testname,
                                   fail_env_changed=True, stats=1)
 
+        # rerun
+        output = self.run_tests("--rerun", testname)
+        self.check_executed_tests(output, [testname],
+                                  env_changed=testname,
+                                  rerun=Rerun(testname,
+                                              match=None,
+                                              success=True),
+                                  stats=2)
+
     def test_rerun_fail(self):
         # FAILURE then FAILURE
         code = textwrap.dedent("""
@@ -1730,16 +1867,15 @@ def test_leak_tmp_file(self):
         self.check_executed_tests(output, testnames,
                                   env_changed=testnames,
                                   fail_env_changed=True,
-                                  randomize=True,
+                                  parallel=True,
                                   stats=len(testnames))
         for testname in testnames:
             self.assertIn(f"Warning -- {testname} leaked temporary "
                           f"files (1): mytmpfile",
                           output)
 
-    def test_mp_decode_error(self):
-        # gh-101634: If a worker stdout cannot be decoded, report a failed test
-        # and a non-zero exit code.
+    def test_worker_decode_error(self):
+        # gh-109425: Use "backslashreplace" error handler to decode stdout.
         if sys.platform == 'win32':
             encoding = locale.getencoding()
         else:
@@ -1747,34 +1883,46 @@ def test_mp_decode_error(self):
             if encoding is None:
                 encoding = sys.__stdout__.encoding
                 if encoding is None:
-                    self.skipTest(f"cannot get regrtest worker encoding")
-
-        nonascii = b"byte:\xa0\xa9\xff\n"
+                    self.skipTest("cannot get regrtest worker encoding")
+
+        nonascii = bytes(ch for ch in range(128, 256))
+        corrupted_output = b"nonascii:%s\n" % (nonascii,)
+        # gh-108989: On Windows, assertion errors are written in UTF-16: when
+        # decoded each letter is follow by a NUL character.
+        assertion_failed = 'Assertion failed: tstate_is_alive(tstate)\n'
+        corrupted_output += assertion_failed.encode('utf-16-le')
         try:
-            nonascii.decode(encoding)
+            corrupted_output.decode(encoding)
         except UnicodeDecodeError:
             pass
         else:
-            self.skipTest(f"{encoding} can decode non-ASCII bytes {nonascii!a}")
+            self.skipTest(f"{encoding} can decode non-ASCII bytes")
+
+        expected_line = corrupted_output.decode(encoding, 'backslashreplace')
 
         code = textwrap.dedent(fr"""
             import sys
+            import unittest
+
+            class Tests(unittest.TestCase):
+                def test_pass(self):
+                    pass
+
             # bytes which cannot be decoded from UTF-8
-            nonascii = {nonascii!a}
-            sys.stdout.buffer.write(nonascii)
+            corrupted_output = {corrupted_output!a}
+            sys.stdout.buffer.write(corrupted_output)
             sys.stdout.buffer.flush()
         """)
         testname = self.create_test(code=code)
 
-        output = self.run_tests("--fail-env-changed", "-v", "-j1", testname,
-                                exitcode=EXITCODE_BAD_TEST)
+        output = self.run_tests("--fail-env-changed", "-v", "-j1", testname)
         self.check_executed_tests(output, [testname],
-                                  failed=[testname],
-                                  randomize=True,
-                                  stats=0)
+                                  parallel=True,
+                                  stats=1)
+        self.check_line(output, expected_line, regex=False)
 
     def test_doctest(self):
-        code = textwrap.dedent(fr'''
+        code = textwrap.dedent(r'''
             import doctest
             import sys
             from test import support
@@ -1809,9 +1957,192 @@ def load_tests(loader, tests, pattern):
                                 exitcode=EXITCODE_BAD_TEST)
         self.check_executed_tests(output, [testname],
                                   failed=[testname],
-                                  randomize=True,
+                                  parallel=True,
                                   stats=TestStats(1, 1, 0))
 
+    def _check_random_seed(self, run_workers: bool):
+        # gh-109276: When -r/--randomize is used, random.seed() is called
+        # with the same random seed before running each test file.
+        code = textwrap.dedent(r'''
+            import random
+            import unittest
+
+            class RandomSeedTest(unittest.TestCase):
+                def test_randint(self):
+                    numbers = [random.randint(0, 1000) for _ in range(10)]
+                    print(f"Random numbers: {numbers}")
+        ''')
+        tests = [self.create_test(name=f'test_random{i}', code=code)
+                 for i in range(1, 3+1)]
+
+        random_seed = 856_656_202
+        cmd = ["--randomize", f"--randseed={random_seed}"]
+        if run_workers:
+            # run as many worker processes than the number of tests
+            cmd.append(f'-j{len(tests)}')
+        cmd.extend(tests)
+        output = self.run_tests(*cmd)
+
+        random.seed(random_seed)
+        # Make the assumption that nothing consume entropy between libregrest
+        # setup_tests() which calls random.seed() and RandomSeedTest calling
+        # random.randint().
+        numbers = [random.randint(0, 1000) for _ in range(10)]
+        expected = f"Random numbers: {numbers}"
+
+        regex = r'^Random numbers: .*$'
+        matches = re.findall(regex, output, flags=re.MULTILINE)
+        self.assertEqual(matches, [expected] * len(tests))
+
+    def test_random_seed(self):
+        self._check_random_seed(run_workers=False)
+
+    def test_random_seed_workers(self):
+        self._check_random_seed(run_workers=True)
+
+    def test_python_command(self):
+        code = textwrap.dedent(r"""
+            import sys
+            import unittest
+
+            class WorkerTests(unittest.TestCase):
+                def test_dev_mode(self):
+                    self.assertTrue(sys.flags.dev_mode)
+        """)
+        tests = [self.create_test(code=code) for _ in range(3)]
+
+        # Custom Python command: "python -X dev"
+        python_cmd = [sys.executable, '-X', 'dev']
+        # test.libregrtest.cmdline uses shlex.split() to parse the Python
+        # command line string
+        python_cmd = shlex.join(python_cmd)
+
+        output = self.run_tests("--python", python_cmd, "-j0", *tests)
+        self.check_executed_tests(output, tests,
+                                  stats=len(tests), parallel=True)
+
+    def check_add_python_opts(self, option):
+        # --fast-ci and --slow-ci add "-u -W default -bb -E" options to Python
+        code = textwrap.dedent(r"""
+            import sys
+            import unittest
+            from test import support
+            try:
+                from _testinternalcapi import get_config
+            except ImportError:
+                get_config = None
+
+            # WASI/WASM buildbots don't use -E option
+            use_environment = (support.is_emscripten or support.is_wasi)
+
+            class WorkerTests(unittest.TestCase):
+                @unittest.skipUnless(get_config is None, 'need get_config()')
+                def test_config(self):
+                    config = get_config()['config']
+                    # -u option
+                    self.assertEqual(config['buffered_stdio'], 0)
+                    # -W default option
+                    self.assertTrue(config['warnoptions'], ['default'])
+                    # -bb option
+                    self.assertTrue(config['bytes_warning'], 2)
+                    # -E option
+                    self.assertTrue(config['use_environment'], use_environment)
+
+                def test_python_opts(self):
+                    # -u option
+                    self.assertTrue(sys.__stdout__.write_through)
+                    self.assertTrue(sys.__stderr__.write_through)
+
+                    # -W default option
+                    self.assertTrue(sys.warnoptions, ['default'])
+
+                    # -bb option
+                    self.assertEqual(sys.flags.bytes_warning, 2)
+
+                    # -E option
+                    self.assertEqual(not sys.flags.ignore_environment,
+                                     use_environment)
+        """)
+        testname = self.create_test(code=code)
+
+        # Use directly subprocess to control the exact command line
+        cmd = [sys.executable,
+               "-m", "test", option,
+               f'--testdir={self.tmptestdir}',
+               testname]
+        proc = subprocess.run(cmd,
+                              stdout=subprocess.PIPE,
+                              stderr=subprocess.STDOUT,
+                              text=True)
+        self.assertEqual(proc.returncode, 0, proc)
+
+    def test_add_python_opts(self):
+        for opt in ("--fast-ci", "--slow-ci"):
+            with self.subTest(opt=opt):
+                self.check_add_python_opts(opt)
+
+    # gh-76319: Raising SIGSEGV on Android may not cause a crash.
+    @unittest.skipIf(support.is_android,
+                     'raising SIGSEGV on Android is unreliable')
+    def test_worker_output_on_failure(self):
+        try:
+            from faulthandler import _sigsegv
+        except ImportError:
+            self.skipTest("need faulthandler._sigsegv")
+
+        code = textwrap.dedent(r"""
+            import faulthandler
+            import unittest
+            from test import support
+
+            class CrashTests(unittest.TestCase):
+                def test_crash(self):
+                    print("just before crash!", flush=True)
+
+                    with support.SuppressCrashReport():
+                        faulthandler._sigsegv(True)
+        """)
+        testname = self.create_test(code=code)
+
+        # Sanitizers must not handle SIGSEGV (ex: for test_enable_fd())
+        env = dict(os.environ)
+        option = 'handle_segv=0'
+        support.set_sanitizer_env_var(env, option)
+
+        output = self.run_tests("-j1", testname,
+                                exitcode=EXITCODE_BAD_TEST,
+                                env=env)
+        self.check_executed_tests(output, testname,
+                                  failed=[testname],
+                                  stats=0, parallel=True)
+        if not support.MS_WINDOWS:
+            exitcode = -int(signal.SIGSEGV)
+            self.assertIn(f"Exit code {exitcode} (SIGSEGV)", output)
+        self.check_line(output, "just before crash!", full=True, regex=False)
+
+    def test_verbose3(self):
+        code = textwrap.dedent(r"""
+            import unittest
+            from test import support
+
+            class VerboseTests(unittest.TestCase):
+                def test_pass(self):
+                    print("SPAM SPAM SPAM")
+        """)
+        testname = self.create_test(code=code)
+
+        # Run sequentially
+        output = self.run_tests("--verbose3", testname)
+        self.check_executed_tests(output, testname, stats=1)
+        self.assertNotIn('SPAM SPAM SPAM', output)
+
+        # -R option needs a debug build
+        if support.Py_DEBUG:
+            # Check for reference leaks, run in parallel
+            output = self.run_tests("-R", "3:3", "-j1", "--verbose3", testname)
+            self.check_executed_tests(output, testname, stats=1, parallel=True)
+            self.assertNotIn('SPAM SPAM SPAM', output)
+
 
 class TestUtils(unittest.TestCase):
     def test_format_duration(self):
@@ -1847,6 +2178,149 @@ def test_normalize_test_name(self):
         self.assertIsNone(normalize('setUpModule (test.test_x)', is_error=True))
         self.assertIsNone(normalize('tearDownModule (test.test_module)', is_error=True))
 
+    def test_get_signal_name(self):
+        for exitcode, expected in (
+            (-int(signal.SIGINT), 'SIGINT'),
+            (-int(signal.SIGSEGV), 'SIGSEGV'),
+            (3221225477, "STATUS_ACCESS_VIOLATION"),
+            (0xC00000FD, "STATUS_STACK_OVERFLOW"),
+        ):
+            self.assertEqual(utils.get_signal_name(exitcode), expected, exitcode)
+
+    def test_format_resources(self):
+        format_resources = utils.format_resources
+        ALL_RESOURCES = utils.ALL_RESOURCES
+        self.assertEqual(
+            format_resources(("network",)),
+            'resources (1): network')
+        self.assertEqual(
+            format_resources(("audio", "decimal", "network")),
+            'resources (3): audio,decimal,network')
+        self.assertEqual(
+            format_resources(ALL_RESOURCES),
+            'resources: all')
+        self.assertEqual(
+            format_resources(tuple(name for name in ALL_RESOURCES
+                                   if name != "cpu")),
+            'resources: all,-cpu')
+        self.assertEqual(
+            format_resources((*ALL_RESOURCES, "tzdata")),
+            'resources: all,tzdata')
+
+    def test_match_test(self):
+        class Test:
+            def __init__(self, test_id):
+                self.test_id = test_id
+
+            def id(self):
+                return self.test_id
+
+        test_access = Test('test.test_os.FileTests.test_access')
+        test_chdir = Test('test.test_os.Win32ErrorTests.test_chdir')
+        test_copy = Test('test.test_shutil.TestCopy.test_copy')
+
+        # Test acceptance
+        with support.swap_attr(support, '_test_matchers', ()):
+            # match all
+            set_match_tests([])
+            self.assertTrue(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+
+            # match all using None
+            set_match_tests(None)
+            self.assertTrue(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+
+            # match the full test identifier
+            set_match_tests([(test_access.id(), True)])
+            self.assertTrue(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+
+            # match the module name
+            set_match_tests([('test_os', True)])
+            self.assertTrue(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+            self.assertFalse(match_test(test_copy))
+
+            # Test '*' pattern
+            set_match_tests([('test_*', True)])
+            self.assertTrue(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+
+            # Test case sensitivity
+            set_match_tests([('filetests', True)])
+            self.assertFalse(match_test(test_access))
+            set_match_tests([('FileTests', True)])
+            self.assertTrue(match_test(test_access))
+
+            # Test pattern containing '.' and a '*' metacharacter
+            set_match_tests([('*test_os.*.test_*', True)])
+            self.assertTrue(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+            self.assertFalse(match_test(test_copy))
+
+            # Multiple patterns
+            set_match_tests([(test_access.id(), True), (test_chdir.id(), True)])
+            self.assertTrue(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+            self.assertFalse(match_test(test_copy))
+
+            set_match_tests([('test_access', True), ('DONTMATCH', True)])
+            self.assertTrue(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+
+        # Test rejection
+        with support.swap_attr(support, '_test_matchers', ()):
+            # match the full test identifier
+            set_match_tests([(test_access.id(), False)])
+            self.assertFalse(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+
+            # match the module name
+            set_match_tests([('test_os', False)])
+            self.assertFalse(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+            self.assertTrue(match_test(test_copy))
+
+            # Test '*' pattern
+            set_match_tests([('test_*', False)])
+            self.assertFalse(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+
+            # Test case sensitivity
+            set_match_tests([('filetests', False)])
+            self.assertTrue(match_test(test_access))
+            set_match_tests([('FileTests', False)])
+            self.assertFalse(match_test(test_access))
+
+            # Test pattern containing '.' and a '*' metacharacter
+            set_match_tests([('*test_os.*.test_*', False)])
+            self.assertFalse(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+            self.assertTrue(match_test(test_copy))
+
+            # Multiple patterns
+            set_match_tests([(test_access.id(), False), (test_chdir.id(), False)])
+            self.assertFalse(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+            self.assertTrue(match_test(test_copy))
+
+            set_match_tests([('test_access', False), ('DONTMATCH', False)])
+            self.assertFalse(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+
+        # Test mixed filters
+        with support.swap_attr(support, '_test_matchers', ()):
+            set_match_tests([('*test_os', False), ('test_access', True)])
+            self.assertTrue(match_test(test_access))
+            self.assertFalse(match_test(test_chdir))
+            self.assertTrue(match_test(test_copy))
+
+            set_match_tests([('*test_os', True), ('test_access', False)])
+            self.assertFalse(match_test(test_access))
+            self.assertTrue(match_test(test_chdir))
+            self.assertFalse(match_test(test_copy))
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_reprlib.py b/Lib/test/test_reprlib.py
index e7216d4272..4a896db200 100644
--- a/Lib/test/test_reprlib.py
+++ b/Lib/test/test_reprlib.py
@@ -765,5 +765,16 @@ def test_assigned_attributes(self):
         for name in assigned:
             self.assertIs(getattr(wrapper, name), getattr(wrapped, name))
 
+    def test__type_params__(self):
+        class My:
+            @recursive_repr()
+            def __repr__[T: str](self, default: T = '') -> str:
+                return default
+
+        type_params = My().__repr__.__type_params__
+        self.assertEqual(len(type_params), 1)
+        self.assertEqual(type_params[0].__name__, 'T')
+        self.assertEqual(type_params[0].__bound__, str)
+
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_richcmp.py b/Lib/test/test_richcmp.py
index 58729a9fea..5f449cdc05 100644
--- a/Lib/test/test_richcmp.py
+++ b/Lib/test/test_richcmp.py
@@ -221,6 +221,7 @@ def do(bad):
             self.assertRaises(Exc, func, Bad())
 
     @support.no_tracing
+    @support.infinite_recursion(25)
     def test_recursion(self):
         # Check that comparison for recursive objects fails gracefully
         from collections import UserList
diff --git a/Lib/test/test_selectors.py b/Lib/test/test_selectors.py
index 12ecc50d55..31757205ca 100644
--- a/Lib/test/test_selectors.py
+++ b/Lib/test/test_selectors.py
@@ -279,6 +279,35 @@ def test_select(self):
 
         self.assertEqual([(wr_key, selectors.EVENT_WRITE)], result)
 
+    def test_select_read_write(self):
+        # gh-110038: when a file descriptor is registered for both read and
+        # write, the two events must be seen on a single call to select().
+        s = self.SELECTOR()
+        self.addCleanup(s.close)
+
+        sock1, sock2 = self.make_socketpair()
+        sock2.send(b"foo")
+        my_key = s.register(sock1, selectors.EVENT_READ | selectors.EVENT_WRITE)
+
+        seen_read, seen_write = False, False
+        result = s.select()
+        # We get the read and write either in the same result entry or in two
+        # distinct entries with the same key.
+        self.assertLessEqual(len(result), 2)
+        for key, events in result:
+            self.assertTrue(isinstance(key, selectors.SelectorKey))
+            self.assertEqual(key, my_key)
+            self.assertFalse(events & ~(selectors.EVENT_READ |
+                                        selectors.EVENT_WRITE))
+            if events & selectors.EVENT_READ:
+                self.assertFalse(seen_read)
+                seen_read = True
+            if events & selectors.EVENT_WRITE:
+                self.assertFalse(seen_write)
+                seen_write = True
+        self.assertTrue(seen_read)
+        self.assertTrue(seen_write)
+
     def test_context_manager(self):
         s = self.SELECTOR()
         self.addCleanup(s.close)
diff --git a/Lib/test/test_shutil.py b/Lib/test/test_shutil.py
index cd1c3d8cfb..e96a5313b4 100644
--- a/Lib/test/test_shutil.py
+++ b/Lib/test/test_shutil.py
@@ -2068,6 +2068,14 @@ def setUp(self):
         self.curdir = os.curdir
         self.ext = ".EXE"
 
+    def to_text_type(self, s):
+        '''
+        In this class we're testing with str, so convert s to a str
+        '''
+        if isinstance(s, bytes):
+            return s.decode()
+        return s
+
     def test_basic(self):
         # Given an EXE in a directory, it should be returned.
         rv = shutil.which(self.file, path=self.dir)
@@ -2255,9 +2263,9 @@ def test_empty_path_no_PATH(self):
 
     @unittest.skipUnless(sys.platform == "win32", 'test specific to Windows')
     def test_pathext(self):
-        ext = ".xyz"
+        ext = self.to_text_type(".xyz")
         temp_filexyz = tempfile.NamedTemporaryFile(dir=self.temp_dir,
-                                                   prefix="Tmp2", suffix=ext)
+                                                   prefix=self.to_text_type("Tmp2"), suffix=ext)
         os.chmod(temp_filexyz.name, stat.S_IXUSR)
         self.addCleanup(temp_filexyz.close)
 
@@ -2266,16 +2274,16 @@ def test_pathext(self):
         program = os.path.splitext(program)[0]
 
         with os_helper.EnvironmentVarGuard() as env:
-            env['PATHEXT'] = ext
+            env['PATHEXT'] = ext if isinstance(ext, str) else ext.decode()
             rv = shutil.which(program, path=self.temp_dir)
             self.assertEqual(rv, temp_filexyz.name)
 
     # Issue 40592: See https://bugs.python.org/issue40592
     @unittest.skipUnless(sys.platform == "win32", 'test specific to Windows')
     def test_pathext_with_empty_str(self):
-        ext = ".xyz"
+        ext = self.to_text_type(".xyz")
         temp_filexyz = tempfile.NamedTemporaryFile(dir=self.temp_dir,
-                                                   prefix="Tmp2", suffix=ext)
+                                                   prefix=self.to_text_type("Tmp2"), suffix=ext)
         self.addCleanup(temp_filexyz.close)
 
         # strip path and extension
@@ -2283,7 +2291,7 @@ def test_pathext_with_empty_str(self):
         program = os.path.splitext(program)[0]
 
         with os_helper.EnvironmentVarGuard() as env:
-            env['PATHEXT'] = f"{ext};"  # note the ;
+            env['PATHEXT'] = f"{ext if isinstance(ext, str) else ext.decode()};"  # note the ;
             rv = shutil.which(program, path=self.temp_dir)
             self.assertEqual(rv, temp_filexyz.name)
 
@@ -2291,13 +2299,14 @@ def test_pathext_with_empty_str(self):
     @unittest.skipUnless(sys.platform == "win32", 'test specific to Windows')
     def test_pathext_applied_on_files_in_path(self):
         with os_helper.EnvironmentVarGuard() as env:
-            env["PATH"] = self.temp_dir
+            env["PATH"] = self.temp_dir if isinstance(self.temp_dir, str) else self.temp_dir.decode()
             env["PATHEXT"] = ".test"
 
-            test_path = pathlib.Path(self.temp_dir) / "test_program.test"
-            test_path.touch(mode=0o755)
+            test_path = os.path.join(self.temp_dir, self.to_text_type("test_program.test"))
+            open(test_path, 'w').close()
+            os.chmod(test_path, 0o755)
 
-            self.assertEqual(shutil.which("test_program"), str(test_path))
+            self.assertEqual(shutil.which(self.to_text_type("test_program")), test_path)
 
     # See GH-75586
     @unittest.skipUnless(sys.platform == "win32", 'test specific to Windows')
@@ -2313,6 +2322,50 @@ def test_win_path_needs_curdir(self):
             self.assertFalse(shutil._win_path_needs_curdir('dontcare', os.X_OK))
             need_curdir_mock.assert_called_once_with('dontcare')
 
+    # See GH-109590
+    @unittest.skipUnless(sys.platform == "win32", 'test specific to Windows')
+    def test_pathext_preferred_for_execute(self):
+        with os_helper.EnvironmentVarGuard() as env:
+            env["PATH"] = self.temp_dir if isinstance(self.temp_dir, str) else self.temp_dir.decode()
+            env["PATHEXT"] = ".test"
+
+            exe = os.path.join(self.temp_dir, self.to_text_type("test.exe"))
+            open(exe, 'w').close()
+            os.chmod(exe, 0o755)
+
+            # default behavior allows a direct match if nothing in PATHEXT matches
+            self.assertEqual(shutil.which(self.to_text_type("test.exe")), exe)
+
+            dot_test = os.path.join(self.temp_dir, self.to_text_type("test.exe.test"))
+            open(dot_test, 'w').close()
+            os.chmod(dot_test, 0o755)
+
+            # now we have a PATHEXT match, so it take precedence
+            self.assertEqual(shutil.which(self.to_text_type("test.exe")), dot_test)
+
+            # but if we don't use os.X_OK we don't change the order based off PATHEXT
+            # and therefore get the direct match.
+            self.assertEqual(shutil.which(self.to_text_type("test.exe"), mode=os.F_OK), exe)
+
+    # See GH-109590
+    @unittest.skipUnless(sys.platform == "win32", 'test specific to Windows')
+    def test_pathext_given_extension_preferred(self):
+        with os_helper.EnvironmentVarGuard() as env:
+            env["PATH"] = self.temp_dir if isinstance(self.temp_dir, str) else self.temp_dir.decode()
+            env["PATHEXT"] = ".exe2;.exe"
+
+            exe = os.path.join(self.temp_dir, self.to_text_type("test.exe"))
+            open(exe, 'w').close()
+            os.chmod(exe, 0o755)
+
+            exe2 = os.path.join(self.temp_dir, self.to_text_type("test.exe2"))
+            open(exe2, 'w').close()
+            os.chmod(exe2, 0o755)
+
+            # even though .exe2 is preferred in PATHEXT, we matched directly to test.exe
+            self.assertEqual(shutil.which(self.to_text_type("test.exe")), exe)
+            self.assertEqual(shutil.which(self.to_text_type("test")), exe2)
+
 
 class TestWhichBytes(TestWhich):
     def setUp(self):
@@ -2320,9 +2373,18 @@ def setUp(self):
         self.dir = os.fsencode(self.dir)
         self.file = os.fsencode(self.file)
         self.temp_file.name = os.fsencode(self.temp_file.name)
+        self.temp_dir = os.fsencode(self.temp_dir)
         self.curdir = os.fsencode(self.curdir)
         self.ext = os.fsencode(self.ext)
 
+    def to_text_type(self, s):
+        '''
+        In this class we're testing with bytes, so convert s to a bytes
+        '''
+        if isinstance(s, str):
+            return s.encode()
+        return s
+
 
 class TestMove(BaseTest, unittest.TestCase):
 
diff --git a/Lib/test/test_signal.py b/Lib/test/test_signal.py
index 2a1a1ee22f..f2ae28c38d 100644
--- a/Lib/test/test_signal.py
+++ b/Lib/test/test_signal.py
@@ -1339,7 +1339,7 @@ def set_interrupts():
                 num_sent_signals += 1
 
         def cycle_handlers():
-            while num_sent_signals < 100:
+            while num_sent_signals < 100 or num_received_signals < 1:
                 for i in range(20000):
                     # Cycle between a Python-defined and a non-Python handler
                     for handler in [custom_handler, signal.SIG_IGN]:
@@ -1372,7 +1372,7 @@ def cycle_handlers():
             if not ignored:
                 # Sanity check that some signals were received, but not all
                 self.assertGreater(num_received_signals, 0)
-            self.assertLess(num_received_signals, num_sent_signals)
+            self.assertLessEqual(num_received_signals, num_sent_signals)
         finally:
             do_stop = True
             t.join()
diff --git a/Lib/test/test_socket.py b/Lib/test/test_socket.py
index 99c4c5cbc4..86701caf05 100644
--- a/Lib/test/test_socket.py
+++ b/Lib/test/test_socket.py
@@ -215,24 +215,6 @@ def setUp(self):
         self.serv = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDPLITE)
         self.port = socket_helper.bind_port(self.serv)
 
-class ThreadSafeCleanupTestCase:
-    """Subclass of unittest.TestCase with thread-safe cleanup methods.
-
-    This subclass protects the addCleanup() and doCleanups() methods
-    with a recursive lock.
-    """
-
-    def __init__(self, *args, **kwargs):
-        super().__init__(*args, **kwargs)
-        self._cleanup_lock = threading.RLock()
-
-    def addCleanup(self, *args, **kwargs):
-        with self._cleanup_lock:
-            return super().addCleanup(*args, **kwargs)
-
-    def doCleanups(self, *args, **kwargs):
-        with self._cleanup_lock:
-            return super().doCleanups(*args, **kwargs)
 
 class SocketCANTest(unittest.TestCase):
 
@@ -626,8 +608,7 @@ def setUp(self):
         self.serv.listen()
 
 
-class ThreadedSocketTestMixin(ThreadSafeCleanupTestCase, SocketTestBase,
-                              ThreadableTest):
+class ThreadedSocketTestMixin(SocketTestBase, ThreadableTest):
     """Mixin to add client socket and allow client/server tests.
 
     Client socket is self.cli and its address is self.cli_addr.  See
@@ -2813,7 +2794,7 @@ def _testRecvFromNegative(self):
 # here assumes that datagram delivery on the local machine will be
 # reliable.
 
-class SendrecvmsgBase(ThreadSafeCleanupTestCase):
+class SendrecvmsgBase:
     # Base class for sendmsg()/recvmsg() tests.
 
     # Time in seconds to wait before considering a test failed, or
@@ -4679,7 +4660,6 @@ def testInterruptedRecvmsgIntoTimeout(self):
 @unittest.skipUnless(hasattr(signal, "alarm") or hasattr(signal, "setitimer"),
                      "Don't have signal.alarm or signal.setitimer")
 class InterruptedSendTimeoutTest(InterruptedTimeoutBase,
-                                 ThreadSafeCleanupTestCase,
                                  SocketListeningTestMixin, TCPTestBase):
     # Test interrupting the interruptible send*() methods with signals
     # when a timeout is set.
@@ -5356,6 +5336,7 @@ def test_create_connection_timeout(self):
 
 
 class NetworkConnectionAttributesTest(SocketTCPTest, ThreadableTest):
+    cli = None
 
     def __init__(self, methodName='runTest'):
         SocketTCPTest.__init__(self, methodName=methodName)
@@ -5365,7 +5346,8 @@ def clientSetUp(self):
         self.source_port = socket_helper.find_unused_port()
 
     def clientTearDown(self):
-        self.cli.close()
+        if self.cli is not None:
+            self.cli.close()
         self.cli = None
         ThreadableTest.clientTearDown(self)
 
diff --git a/Lib/test/test_socketserver.py b/Lib/test/test_socketserver.py
index c81d559cde..0f62f9eb20 100644
--- a/Lib/test/test_socketserver.py
+++ b/Lib/test/test_socketserver.py
@@ -32,11 +32,6 @@
 HAVE_FORKING = test.support.has_fork_support
 requires_forking = unittest.skipUnless(HAVE_FORKING, 'requires forking')
 
-def signal_alarm(n):
-    """Call signal.alarm when it exists (i.e. not on Windows)."""
-    if hasattr(signal, 'alarm'):
-        signal.alarm(n)
-
 # Remember real select() to avoid interferences with mocking
 _real_select = select.select
 
@@ -68,12 +63,10 @@ class SocketServerTest(unittest.TestCase):
     """Test all socket servers."""
 
     def setUp(self):
-        signal_alarm(60)  # Kill deadlocks after 60 seconds.
         self.port_seed = 0
         self.test_files = []
 
     def tearDown(self):
-        signal_alarm(0)  # Didn't deadlock.
         reap_children()
 
         for fn in self.test_files:
diff --git a/Lib/test/test_source_encoding.py b/Lib/test/test_source_encoding.py
index 72c2b47779..27871378f1 100644
--- a/Lib/test/test_source_encoding.py
+++ b/Lib/test/test_source_encoding.py
@@ -68,6 +68,7 @@ def test_issue7820(self):
     def test_20731(self):
         sub = subprocess.Popen([sys.executable,
                         os.path.join(os.path.dirname(__file__),
+                                     'tokenizedata',
                                      'coding20731.py')],
                         stderr=subprocess.PIPE)
         err = sub.communicate()[1]
@@ -100,10 +101,10 @@ def test_bad_coding2(self):
         self.verify_bad_module(module_name)
 
     def verify_bad_module(self, module_name):
-        self.assertRaises(SyntaxError, __import__, 'test.' + module_name)
+        self.assertRaises(SyntaxError, __import__, 'test.tokenizedata.' + module_name)
 
         path = os.path.dirname(__file__)
-        filename = os.path.join(path, module_name + '.py')
+        filename = os.path.join(path, 'tokenizedata', module_name + '.py')
         with open(filename, "rb") as fp:
             bytes = fp.read()
         self.assertRaises(SyntaxError, compile, bytes, filename, 'exec')
diff --git a/Lib/test/test_ssl.py b/Lib/test/test_ssl.py
index 2c32fec510..d8ae7b75e1 100644
--- a/Lib/test/test_ssl.py
+++ b/Lib/test/test_ssl.py
@@ -60,10 +60,10 @@
     PROTOCOL_TO_TLS_VERSION[proto] = ver
 
 def data_file(*name):
-    return os.path.join(os.path.dirname(__file__), *name)
+    return os.path.join(os.path.dirname(__file__), "certdata", *name)
 
 # The custom key and certificate files used in test_ssl are generated
-# using Lib/test/make_ssl_certs.py.
+# using Lib/test/certdata/make_ssl_certs.py.
 # Other certificates are simply fetched from the internet servers they
 # are meant to authenticate.
 
@@ -641,7 +641,7 @@ def test_openssl111_deprecations(self):
     def bad_cert_test(self, certfile):
         """Check that trying to use the given client certificate fails"""
         certfile = os.path.join(os.path.dirname(__file__) or os.curdir,
-                                   certfile)
+                                "certdata", certfile)
         sock = socket.socket()
         self.addCleanup(sock.close)
         with self.assertRaises(ssl.SSLError):
@@ -1739,6 +1739,10 @@ def test_buffer_types(self):
         self.assertEqual(bio.read(), b'bar')
         bio.write(memoryview(b'baz'))
         self.assertEqual(bio.read(), b'baz')
+        m = memoryview(bytearray(b'noncontig'))
+        noncontig_writable = m[::-2]
+        with self.assertRaises(BufferError):
+            bio.write(memoryview(noncontig_writable))
 
     def test_error_types(self):
         bio = ssl.MemoryBIO()
@@ -3309,12 +3313,12 @@ def test_socketserver(self):
         # try to connect
         if support.verbose:
             sys.stdout.write('\n')
-        with open(CERTFILE, 'rb') as f:
+        # Get this test file itself:
+        with open(__file__, 'rb') as f:
             d1 = f.read()
         d2 = ''
         # now fetch the same data from the HTTPS server
-        url = 'https://localhost:%d/%s' % (
-            server.port, os.path.split(CERTFILE)[1])
+        url = f'https://localhost:{server.port}/test_ssl.py'
         context = ssl.create_default_context(cafile=SIGNING_CA)
         f = urllib.request.urlopen(url, context=context)
         try:
diff --git a/Lib/test/test_string_literals.py b/Lib/test/test_string_literals.py
index 9b663c0022..371e8193b3 100644
--- a/Lib/test/test_string_literals.py
+++ b/Lib/test/test_string_literals.py
@@ -131,6 +131,18 @@ def test_eval_str_invalid_escape(self):
         self.assertEqual(exc.lineno, 1)
         self.assertEqual(exc.offset, 1)
 
+        # Check that the warning is raised ony once if there are syntax errors
+
+        with warnings.catch_warnings(record=True) as w:
+            warnings.simplefilter('always', category=SyntaxWarning)
+            with self.assertRaises(SyntaxError) as cm:
+                eval("'\\e' $")
+            exc = cm.exception
+        self.assertEqual(len(w), 1)
+        self.assertEqual(w[0].category, SyntaxWarning)
+        self.assertRegex(str(w[0].message), 'invalid escape sequence')
+        self.assertEqual(w[0].filename, '<string>')
+
     def test_eval_str_invalid_octal_escape(self):
         for i in range(0o400, 0o1000):
             with self.assertWarns(SyntaxWarning):
diff --git a/Lib/test/test_structseq.py b/Lib/test/test_structseq.py
index a9fe193028..c6c0afaf07 100644
--- a/Lib/test/test_structseq.py
+++ b/Lib/test/test_structseq.py
@@ -1,4 +1,6 @@
+import copy
 import os
+import pickle
 import time
 import unittest
 
@@ -106,9 +108,78 @@ def __len__(self):
 
         self.assertRaises(Exc, time.struct_time, C())
 
-    def test_reduce(self):
+    def test_pickling(self):
         t = time.gmtime()
-        x = t.__reduce__()
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            p = pickle.dumps(t, proto)
+            t2 = pickle.loads(p)
+            self.assertEqual(t2.__class__, t.__class__)
+            self.assertEqual(t2, t)
+            self.assertEqual(t2.tm_year, t.tm_year)
+            self.assertEqual(t2.tm_zone, t.tm_zone)
+
+    def test_pickling_with_unnamed_fields(self):
+        assert os.stat_result.n_unnamed_fields > 0
+
+        r = os.stat_result(range(os.stat_result.n_sequence_fields),
+                           {'st_atime': 1.0, 'st_atime_ns': 2.0})
+        for proto in range(pickle.HIGHEST_PROTOCOL + 1):
+            p = pickle.dumps(r, proto)
+            r2 = pickle.loads(p)
+            self.assertEqual(r2.__class__, r.__class__)
+            self.assertEqual(r2, r)
+            self.assertEqual(r2.st_mode, r.st_mode)
+            self.assertEqual(r2.st_atime, r.st_atime)
+            self.assertEqual(r2.st_atime_ns, r.st_atime_ns)
+
+    def test_copying(self):
+        n_fields = time.struct_time.n_fields
+        t = time.struct_time([[i] for i in range(n_fields)])
+
+        t2 = copy.copy(t)
+        self.assertEqual(t2.__class__, t.__class__)
+        self.assertEqual(t2, t)
+        self.assertEqual(t2.tm_year, t.tm_year)
+        self.assertEqual(t2.tm_zone, t.tm_zone)
+        self.assertIs(t2[0], t[0])
+        self.assertIs(t2.tm_year, t.tm_year)
+
+        t3 = copy.deepcopy(t)
+        self.assertEqual(t3.__class__, t.__class__)
+        self.assertEqual(t3, t)
+        self.assertEqual(t3.tm_year, t.tm_year)
+        self.assertEqual(t3.tm_zone, t.tm_zone)
+        self.assertIsNot(t3[0], t[0])
+        self.assertIsNot(t3.tm_year, t.tm_year)
+
+    def test_copying_with_unnamed_fields(self):
+        assert os.stat_result.n_unnamed_fields > 0
+
+        n_sequence_fields = os.stat_result.n_sequence_fields
+        r = os.stat_result([[i] for i in range(n_sequence_fields)],
+                           {'st_atime': [1.0], 'st_atime_ns': [2.0]})
+
+        r2 = copy.copy(r)
+        self.assertEqual(r2.__class__, r.__class__)
+        self.assertEqual(r2, r)
+        self.assertEqual(r2.st_mode, r.st_mode)
+        self.assertEqual(r2.st_atime, r.st_atime)
+        self.assertEqual(r2.st_atime_ns, r.st_atime_ns)
+        self.assertIs(r2[0], r[0])
+        self.assertIs(r2.st_mode, r.st_mode)
+        self.assertIs(r2.st_atime, r.st_atime)
+        self.assertIs(r2.st_atime_ns, r.st_atime_ns)
+
+        r3 = copy.deepcopy(r)
+        self.assertEqual(r3.__class__, r.__class__)
+        self.assertEqual(r3, r)
+        self.assertEqual(r3.st_mode, r.st_mode)
+        self.assertEqual(r3.st_atime, r.st_atime)
+        self.assertEqual(r3.st_atime_ns, r.st_atime_ns)
+        self.assertIsNot(r3[0], r[0])
+        self.assertIsNot(r3.st_mode, r.st_mode)
+        self.assertIsNot(r3.st_atime, r.st_atime)
+        self.assertIsNot(r3.st_atime_ns, r.st_atime_ns)
 
     def test_extended_getslice(self):
         # Test extended slicing by comparing with list slicing.
diff --git a/Lib/test/test_subclassinit.py b/Lib/test/test_subclassinit.py
index 310473a4a2..0d32aa509b 100644
--- a/Lib/test/test_subclassinit.py
+++ b/Lib/test/test_subclassinit.py
@@ -230,7 +230,7 @@ def __init__(self, name, bases, namespace, otherarg):
                 super().__init__(name, bases, namespace)
 
         with self.assertRaises(TypeError):
-            class MyClass(metaclass=MyMeta, otherarg=1):
+            class MyClass2(metaclass=MyMeta, otherarg=1):
                 pass
 
         class MyMeta(type):
@@ -241,10 +241,10 @@ def __init__(self, name, bases, namespace, otherarg):
                 super().__init__(name, bases, namespace)
                 self.otherarg = otherarg
 
-        class MyClass(metaclass=MyMeta, otherarg=1):
+        class MyClass3(metaclass=MyMeta, otherarg=1):
             pass
 
-        self.assertEqual(MyClass.otherarg, 1)
+        self.assertEqual(MyClass3.otherarg, 1)
 
     def test_errors_changed_pep487(self):
         # These tests failed before Python 3.6, PEP 487
@@ -263,10 +263,10 @@ def __new__(cls, name, bases, namespace, otherarg):
                 self.otherarg = otherarg
                 return self
 
-        class MyClass(metaclass=MyMeta, otherarg=1):
+        class MyClass2(metaclass=MyMeta, otherarg=1):
             pass
 
-        self.assertEqual(MyClass.otherarg, 1)
+        self.assertEqual(MyClass2.otherarg, 1)
 
     def test_type(self):
         t = type('NewClass', (object,), {})
diff --git a/Lib/test/test_subprocess.py b/Lib/test/test_subprocess.py
index d95ef72b0d..a865df1082 100644
--- a/Lib/test/test_subprocess.py
+++ b/Lib/test/test_subprocess.py
@@ -749,31 +749,36 @@ def test_pipesizes(self):
     @unittest.skipUnless(fcntl and hasattr(fcntl, 'F_GETPIPE_SZ'),
                          'fcntl.F_GETPIPE_SZ required for test.')
     def test_pipesize_default(self):
-        p = subprocess.Popen(
+        proc = subprocess.Popen(
             [sys.executable, "-c",
              'import sys; sys.stdin.read(); sys.stdout.write("out"); '
              'sys.stderr.write("error!")'],
             stdin=subprocess.PIPE, stdout=subprocess.PIPE,
             stderr=subprocess.PIPE, pipesize=-1)
-        try:
-            fp_r, fp_w = os.pipe()
+
+        with proc:
             try:
-                default_pipesize = fcntl.fcntl(fp_w, fcntl.F_GETPIPE_SZ)
-                for fifo in [p.stdin, p.stdout, p.stderr]:
-                    self.assertEqual(
-                        fcntl.fcntl(fifo.fileno(), fcntl.F_GETPIPE_SZ),
-                        default_pipesize)
+                fp_r, fp_w = os.pipe()
+                try:
+                    default_read_pipesize = fcntl.fcntl(fp_r, fcntl.F_GETPIPE_SZ)
+                    default_write_pipesize = fcntl.fcntl(fp_w, fcntl.F_GETPIPE_SZ)
+                finally:
+                    os.close(fp_r)
+                    os.close(fp_w)
+
+                self.assertEqual(
+                    fcntl.fcntl(proc.stdin.fileno(), fcntl.F_GETPIPE_SZ),
+                    default_read_pipesize)
+                self.assertEqual(
+                    fcntl.fcntl(proc.stdout.fileno(), fcntl.F_GETPIPE_SZ),
+                    default_write_pipesize)
+                self.assertEqual(
+                    fcntl.fcntl(proc.stderr.fileno(), fcntl.F_GETPIPE_SZ),
+                    default_write_pipesize)
+                # On other platforms we cannot test the pipe size (yet). But above
+                # code using pipesize=-1 should not crash.
             finally:
-                os.close(fp_r)
-                os.close(fp_w)
-            # On other platforms we cannot test the pipe size (yet). But above
-            # code using pipesize=-1 should not crash.
-            p.stdin.close()
-            p.stdout.close()
-            p.stderr.close()
-        finally:
-            p.kill()
-            p.wait()
+                proc.kill()
 
     def test_env(self):
         newenv = os.environ.copy()
diff --git a/Lib/test/test_support.py b/Lib/test/test_support.py
index 4047e0bd01..1b78d7e84c 100644
--- a/Lib/test/test_support.py
+++ b/Lib/test/test_support.py
@@ -7,6 +7,7 @@
 import stat
 import subprocess
 import sys
+import sysconfig
 import tempfile
 import textwrap
 import unittest
@@ -549,111 +550,6 @@ def test_optim_args_from_interpreter_flags(self):
             with self.subTest(opts=opts):
                 self.check_options(opts, 'optim_args_from_interpreter_flags')
 
-    def test_match_test(self):
-        class Test:
-            def __init__(self, test_id):
-                self.test_id = test_id
-
-            def id(self):
-                return self.test_id
-
-        test_access = Test('test.test_os.FileTests.test_access')
-        test_chdir = Test('test.test_os.Win32ErrorTests.test_chdir')
-
-        # Test acceptance
-        with support.swap_attr(support, '_match_test_func', None):
-            # match all
-            support.set_match_tests([])
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # match all using None
-            support.set_match_tests(None, None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # match the full test identifier
-            support.set_match_tests([test_access.id()], None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertFalse(support.match_test(test_chdir))
-
-            # match the module name
-            support.set_match_tests(['test_os'], None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # Test '*' pattern
-            support.set_match_tests(['test_*'], None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # Test case sensitivity
-            support.set_match_tests(['filetests'], None)
-            self.assertFalse(support.match_test(test_access))
-            support.set_match_tests(['FileTests'], None)
-            self.assertTrue(support.match_test(test_access))
-
-            # Test pattern containing '.' and a '*' metacharacter
-            support.set_match_tests(['*test_os.*.test_*'], None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # Multiple patterns
-            support.set_match_tests([test_access.id(), test_chdir.id()], None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            support.set_match_tests(['test_access', 'DONTMATCH'], None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertFalse(support.match_test(test_chdir))
-
-        # Test rejection
-        with support.swap_attr(support, '_match_test_func', None):
-            # match all
-            support.set_match_tests(ignore_patterns=[])
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # match all using None
-            support.set_match_tests(None, None)
-            self.assertTrue(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # match the full test identifier
-            support.set_match_tests(None, [test_access.id()])
-            self.assertFalse(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
-            # match the module name
-            support.set_match_tests(None, ['test_os'])
-            self.assertFalse(support.match_test(test_access))
-            self.assertFalse(support.match_test(test_chdir))
-
-            # Test '*' pattern
-            support.set_match_tests(None, ['test_*'])
-            self.assertFalse(support.match_test(test_access))
-            self.assertFalse(support.match_test(test_chdir))
-
-            # Test case sensitivity
-            support.set_match_tests(None, ['filetests'])
-            self.assertTrue(support.match_test(test_access))
-            support.set_match_tests(None, ['FileTests'])
-            self.assertFalse(support.match_test(test_access))
-
-            # Test pattern containing '.' and a '*' metacharacter
-            support.set_match_tests(None, ['*test_os.*.test_*'])
-            self.assertFalse(support.match_test(test_access))
-            self.assertFalse(support.match_test(test_chdir))
-
-            # Multiple patterns
-            support.set_match_tests(None, [test_access.id(), test_chdir.id()])
-            self.assertFalse(support.match_test(test_access))
-            self.assertFalse(support.match_test(test_chdir))
-
-            support.set_match_tests(None, ['test_access', 'DONTMATCH'])
-            self.assertFalse(support.match_test(test_access))
-            self.assertTrue(support.match_test(test_chdir))
-
     @unittest.skipIf(support.is_emscripten, "Unstable in Emscripten")
     @unittest.skipIf(support.is_wasi, "Unavailable on WASI")
     def test_fd_count(self):
@@ -763,7 +659,81 @@ def recursive_function(depth):
             else:
                 self.fail("RecursionError was not raised")
 
-        #self.assertEqual(available, 2)
+    def test_parse_memlimit(self):
+        parse = support._parse_memlimit
+        KiB = 1024
+        MiB = KiB * 1024
+        GiB = MiB * 1024
+        TiB = GiB * 1024
+        self.assertEqual(parse('0k'), 0)
+        self.assertEqual(parse('3k'), 3 * KiB)
+        self.assertEqual(parse('2.4m'), int(2.4 * MiB))
+        self.assertEqual(parse('4g'), int(4 * GiB))
+        self.assertEqual(parse('1t'), TiB)
+
+        for limit in ('', '3', '3.5.10k', '10x'):
+            with self.subTest(limit=limit):
+                with self.assertRaises(ValueError):
+                    parse(limit)
+
+    def test_set_memlimit(self):
+        _4GiB = 4 * 1024 ** 3
+        TiB = 1024 ** 4
+        old_max_memuse = support.max_memuse
+        old_real_max_memuse = support.real_max_memuse
+        try:
+            if sys.maxsize > 2**32:
+                support.set_memlimit('4g')
+                self.assertEqual(support.max_memuse, _4GiB)
+                self.assertEqual(support.real_max_memuse, _4GiB)
+
+                big = 2**100 // TiB
+                support.set_memlimit(f'{big}t')
+                self.assertEqual(support.max_memuse, sys.maxsize)
+                self.assertEqual(support.real_max_memuse, big * TiB)
+            else:
+                support.set_memlimit('4g')
+                self.assertEqual(support.max_memuse, sys.maxsize)
+                self.assertEqual(support.real_max_memuse, _4GiB)
+        finally:
+            support.max_memuse = old_max_memuse
+            support.real_max_memuse = old_real_max_memuse
+
+    def test_copy_python_src_ignore(self):
+        # Get source directory
+        src_dir = sysconfig.get_config_var('abs_srcdir')
+        if not src_dir:
+            src_dir = sysconfig.get_config_var('srcdir')
+        src_dir = os.path.abspath(src_dir)
+
+        # Check that the source code is available
+        if not os.path.exists(src_dir):
+            self.skipTest(f"cannot access Python source code directory:"
+                          f" {src_dir!r}")
+        # Check that the landmark copy_python_src_ignore() expects is available
+        # (Previously we looked for 'Lib\os.py', which is always present on Windows.)
+        landmark = os.path.join(src_dir, 'Modules')
+        if not os.path.exists(landmark):
+            self.skipTest(f"cannot access Python source code directory:"
+                          f" {landmark!r} landmark is missing")
+
+        # Test support.copy_python_src_ignore()
+
+        # Source code directory
+        ignored = {'.git', '__pycache__'}
+        names = os.listdir(src_dir)
+        self.assertEqual(support.copy_python_src_ignore(src_dir, names),
+                         ignored | {'build'})
+
+        # Doc/ directory
+        path = os.path.join(src_dir, 'Doc')
+        self.assertEqual(support.copy_python_src_ignore(path, os.listdir(path)),
+                         ignored | {'build', 'venv'})
+
+        # Another directory
+        path = os.path.join(src_dir, 'Objects')
+        self.assertEqual(support.copy_python_src_ignore(path, os.listdir(path)),
+                         ignored)
 
     # XXX -follows a list of untested API
     # make_legacy_pyc
@@ -776,12 +746,10 @@ def recursive_function(depth):
     # EnvironmentVarGuard
     # transient_internet
     # run_with_locale
-    # set_memlimit
     # bigmemtest
     # precisionbigmemtest
     # bigaddrspacetest
     # requires_resource
-    # run_doctest
     # threading_cleanup
     # reap_threads
     # can_symlink
diff --git a/Lib/test/test_symtable.py b/Lib/test/test_symtable.py
index 61fda767e3..82c1d7c856 100644
--- a/Lib/test/test_symtable.py
+++ b/Lib/test/test_symtable.py
@@ -282,6 +282,10 @@ def test_symtable_repr(self):
         self.assertEqual(str(self.top), "<SymbolTable for module ?>")
         self.assertEqual(str(self.spam), "<Function SymbolTable for spam in ?>")
 
+    def test_symtable_entry_repr(self):
+        expected = f"<symtable entry top({self.top.get_id()}), line {self.top.get_lineno()}>"
+        self.assertEqual(repr(self.top._table), expected)
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_syntax.py b/Lib/test/test_syntax.py
index 4c988382f8..00c5f624ce 100644
--- a/Lib/test/test_syntax.py
+++ b/Lib/test/test_syntax.py
@@ -1004,11 +1004,26 @@
    Traceback (most recent call last):
    SyntaxError: expected ':'
 
+   >>> def f[T]()
+   ...     pass
+   Traceback (most recent call last):
+   SyntaxError: expected ':'
+
    >>> class A
    ...     pass
    Traceback (most recent call last):
    SyntaxError: expected ':'
 
+   >>> class A[T]
+   ...     pass
+   Traceback (most recent call last):
+   SyntaxError: expected ':'
+
+   >>> class A[T]()
+   ...     pass
+   Traceback (most recent call last):
+   SyntaxError: expected ':'
+
    >>> class R&D:
    ...     pass
    Traceback (most recent call last):
@@ -1446,11 +1461,21 @@
    Traceback (most recent call last):
    IndentationError: expected an indented block after function definition on line 1
 
+   >>> def foo[T](x, /, y, *, z=2):
+   ... pass
+   Traceback (most recent call last):
+   IndentationError: expected an indented block after function definition on line 1
+
    >>> class Blech(A):
    ... pass
    Traceback (most recent call last):
    IndentationError: expected an indented block after class definition on line 1
 
+   >>> class Blech[T](A):
+   ... pass
+   Traceback (most recent call last):
+   IndentationError: expected an indented block after class definition on line 1
+
    >>> match something:
    ... pass
    Traceback (most recent call last):
@@ -1955,6 +1980,17 @@ def f(x: *b)
       ...
    SyntaxError: yield expression cannot be used within the definition of a generic
 
+    >>> f(**x, *y)
+    Traceback (most recent call last):
+    SyntaxError: iterable argument unpacking follows keyword argument unpacking
+
+    >>> f(**x, *)
+    Traceback (most recent call last):
+    SyntaxError: iterable argument unpacking follows keyword argument unpacking
+
+    >>> f(x, *:)
+    Traceback (most recent call last):
+    SyntaxError: invalid syntax
 """
 
 import re
diff --git a/Lib/test/test_sys.py b/Lib/test/test_sys.py
index c3e9f9c406..0b8529a9b6 100644
--- a/Lib/test/test_sys.py
+++ b/Lib/test/test_sys.py
@@ -4,6 +4,7 @@
 import locale
 import operator
 import os
+import random
 import struct
 import subprocess
 import sys
@@ -19,10 +20,6 @@
 import warnings
 
 
-# count the number of test runs, used to create unique
-# strings to intern in test_intern()
-INTERN_NUMRUNS = 0
-
 DICT_KEY_STRUCT_FORMAT = 'n2BI2n'
 
 class DisplayHookTest(unittest.TestCase):
@@ -685,10 +682,8 @@ def test_43581(self):
         self.assertEqual(sys.__stdout__.encoding, sys.__stderr__.encoding)
 
     def test_intern(self):
-        global INTERN_NUMRUNS
-        INTERN_NUMRUNS += 1
         self.assertRaises(TypeError, sys.intern)
-        s = "never interned before" + str(INTERN_NUMRUNS)
+        s = "never interned before" + str(random.randrange(0, 10**9))
         self.assertTrue(sys.intern(s) is s)
         s2 = s.swapcase().swapcase()
         self.assertTrue(sys.intern(s2) is s)
diff --git a/Lib/test/test_sys_setprofile.py b/Lib/test/test_sys_setprofile.py
index 34c70d6c8d..9e8936630d 100644
--- a/Lib/test/test_sys_setprofile.py
+++ b/Lib/test/test_sys_setprofile.py
@@ -255,6 +255,25 @@ def g(p):
                               (1, 'return', g_ident),
                               ])
 
+    def test_unfinished_generator(self):
+        def f():
+            for i in range(2):
+                yield i
+        def g(p):
+            next(f())
+
+        f_ident = ident(f)
+        g_ident = ident(g)
+        self.check_events(g, [(1, 'call', g_ident),
+                              (2, 'call', f_ident),
+                              (2, 'return', f_ident),
+                              # once more; the generator is being garbage collected
+                              # and it will do a PY_THROW
+                              (2, 'call', f_ident),
+                              (2, 'return', f_ident),
+                              (1, 'return', g_ident),
+                              ])
+
     def test_stop_iteration(self):
         def f():
             for i in range(2):
diff --git a/Lib/test/test_sys_settrace.py b/Lib/test/test_sys_settrace.py
index c29deeba4b..7e16e94aa1 100644
--- a/Lib/test/test_sys_settrace.py
+++ b/Lib/test/test_sys_settrace.py
@@ -9,6 +9,7 @@
 import asyncio
 from test.support import import_helper
 import contextlib
+import warnings
 
 support.requires_working_socket(module=True)
 
@@ -1970,6 +1971,9 @@ def run_test(self, func, jumpFrom, jumpTo, expected, error=None,
                 stack.enter_context(self.assertRaisesRegex(*error))
             if warning is not None:
                 stack.enter_context(self.assertWarnsRegex(*warning))
+            else:
+                stack.enter_context(warnings.catch_warnings())
+                warnings.simplefilter('error')
             func(output)
 
         sys.settrace(None)
@@ -2033,6 +2037,40 @@ def test_jump_simple_backwards(output):
         output.append(1)
         output.append(2)
 
+    @jump_test(1, 4, [5], warning=(RuntimeWarning, unbound_locals))
+    def test_jump_is_none_forwards(output):
+        x = None
+        if x is None:
+            output.append(3)
+        else:
+            output.append(5)
+
+    @jump_test(6, 5, [3, 5, 6])
+    def test_jump_is_none_backwards(output):
+        x = None
+        if x is None:
+            output.append(3)
+        else:
+            output.append(5)
+        output.append(6)
+
+    @jump_test(2, 4, [5])
+    def test_jump_is_not_none_forwards(output):
+        x = None
+        if x is not None:
+            output.append(3)
+        else:
+            output.append(5)
+
+    @jump_test(6, 5, [5, 5, 6])
+    def test_jump_is_not_none_backwards(output):
+        x = None
+        if x is not None:
+            output.append(3)
+        else:
+            output.append(5)
+        output.append(6)
+
     @jump_test(3, 5, [2, 5], warning=(RuntimeWarning, unbound_locals))
     def test_jump_out_of_block_forwards(output):
         for i in 1, 2:
diff --git a/Lib/test/test_tarfile.py b/Lib/test/test_tarfile.py
index 013c62630b..c5fc76dc02 100644
--- a/Lib/test/test_tarfile.py
+++ b/Lib/test/test_tarfile.py
@@ -1,3 +1,4 @@
+import errno
 import sys
 import os
 import io
@@ -2564,16 +2565,17 @@ def tarfilecmd_failure(self, *args):
         return script_helper.assert_python_failure('-m', 'tarfile', *args)
 
     def make_simple_tarfile(self, tar_name):
-        files = [support.findfile('tokenize_tests.txt'),
+        files = [support.findfile('tokenize_tests.txt',
+                                  subdir='tokenizedata'),
                  support.findfile('tokenize_tests-no-coding-cookie-'
-                                  'and-utf8-bom-sig-only.txt')]
+                                  'and-utf8-bom-sig-only.txt',
+                                  subdir='tokenizedata')]
         self.addCleanup(os_helper.unlink, tar_name)
         with tarfile.open(tar_name, 'w') as tf:
             for tardata in files:
                 tf.add(tardata, arcname=os.path.basename(tardata))
 
     def make_evil_tarfile(self, tar_name):
-        files = [support.findfile('tokenize_tests.txt')]
         self.addCleanup(os_helper.unlink, tar_name)
         with tarfile.open(tar_name, 'w') as tf:
             benign = tarfile.TarInfo('benign')
@@ -2654,9 +2656,11 @@ def test_list_command_invalid_file(self):
         self.assertEqual(rc, 1)
 
     def test_create_command(self):
-        files = [support.findfile('tokenize_tests.txt'),
+        files = [support.findfile('tokenize_tests.txt',
+                                  subdir='tokenizedata'),
                  support.findfile('tokenize_tests-no-coding-cookie-'
-                                  'and-utf8-bom-sig-only.txt')]
+                                  'and-utf8-bom-sig-only.txt',
+                                  subdir='tokenizedata')]
         for opt in '-c', '--create':
             try:
                 out = self.tarfilecmd(opt, tmpname, *files)
@@ -2667,9 +2671,11 @@ def test_create_command(self):
                 os_helper.unlink(tmpname)
 
     def test_create_command_verbose(self):
-        files = [support.findfile('tokenize_tests.txt'),
+        files = [support.findfile('tokenize_tests.txt',
+                                  subdir='tokenizedata'),
                  support.findfile('tokenize_tests-no-coding-cookie-'
-                                  'and-utf8-bom-sig-only.txt')]
+                                  'and-utf8-bom-sig-only.txt',
+                                  subdir='tokenizedata')]
         for opt in '-v', '--verbose':
             try:
                 out = self.tarfilecmd(opt, '-c', tmpname, *files,
@@ -2681,7 +2687,7 @@ def test_create_command_verbose(self):
                 os_helper.unlink(tmpname)
 
     def test_create_command_dotless_filename(self):
-        files = [support.findfile('tokenize_tests.txt')]
+        files = [support.findfile('tokenize_tests.txt', subdir='tokenizedata')]
         try:
             out = self.tarfilecmd('-c', dotlessname, *files)
             self.assertEqual(out, b'')
@@ -2692,7 +2698,7 @@ def test_create_command_dotless_filename(self):
 
     def test_create_command_dot_started_filename(self):
         tar_name = os.path.join(TEMPDIR, ".testtar")
-        files = [support.findfile('tokenize_tests.txt')]
+        files = [support.findfile('tokenize_tests.txt', subdir='tokenizedata')]
         try:
             out = self.tarfilecmd('-c', tar_name, *files)
             self.assertEqual(out, b'')
@@ -2702,9 +2708,11 @@ def test_create_command_dot_started_filename(self):
             os_helper.unlink(tar_name)
 
     def test_create_command_compressed(self):
-        files = [support.findfile('tokenize_tests.txt'),
+        files = [support.findfile('tokenize_tests.txt',
+                                  subdir='tokenizedata'),
                  support.findfile('tokenize_tests-no-coding-cookie-'
-                                  'and-utf8-bom-sig-only.txt')]
+                                  'and-utf8-bom-sig-only.txt',
+                                  subdir='tokenizedata')]
         for filetype in (GzipTest, Bz2Test, LzmaTest):
             if not filetype.open:
                 continue
@@ -3791,9 +3799,21 @@ def test_modes(self):
         tmp_filename = os.path.join(TEMPDIR, "tmp.file")
         with open(tmp_filename, 'w'):
             pass
-        os.chmod(tmp_filename, os.stat(tmp_filename).st_mode | stat.S_ISVTX)
-        have_sticky_files = (os.stat(tmp_filename).st_mode & stat.S_ISVTX)
-        os.unlink(tmp_filename)
+        try:
+            try:
+                os.chmod(tmp_filename,
+                         os.stat(tmp_filename).st_mode | stat.S_ISVTX)
+            except OSError as exc:
+                if exc.errno == getattr(errno, "EFTYPE", 0):
+                    # gh-108948: On FreeBSD, regular users cannot set
+                    # the sticky bit.
+                    self.skipTest("chmod() failed with EFTYPE: "
+                                  "regular users cannot set sticky bit")
+                else:
+                    raise
+            have_sticky_files = (os.stat(tmp_filename).st_mode & stat.S_ISVTX)
+        finally:
+            os.unlink(tmp_filename)
 
         os.mkdir(tmp_filename)
         os.chmod(tmp_filename, os.stat(tmp_filename).st_mode | stat.S_ISVTX)
diff --git a/Lib/test/test_termios.py b/Lib/test/test_termios.py
new file mode 100644
index 0000000000..58698ffac2
--- /dev/null
+++ b/Lib/test/test_termios.py
@@ -0,0 +1,220 @@
+import errno
+import os
+import sys
+import tempfile
+import unittest
+from test.support.import_helper import import_module
+
+termios = import_module('termios')
+
+
+@unittest.skipUnless(hasattr(os, 'openpty'), "need os.openpty()")
+class TestFunctions(unittest.TestCase):
+
+    def setUp(self):
+        master_fd, self.fd = os.openpty()
+        self.addCleanup(os.close, master_fd)
+        self.stream = self.enterContext(open(self.fd, 'wb', buffering=0))
+        tmp = self.enterContext(tempfile.TemporaryFile(mode='wb', buffering=0))
+        self.bad_fd = tmp.fileno()
+
+    def assertRaisesTermiosError(self, errno, callable, *args):
+        with self.assertRaises(termios.error) as cm:
+            callable(*args)
+        self.assertEqual(cm.exception.args[0], errno)
+
+    def test_tcgetattr(self):
+        attrs = termios.tcgetattr(self.fd)
+        self.assertIsInstance(attrs, list)
+        self.assertEqual(len(attrs), 7)
+        for i in range(6):
+            self.assertIsInstance(attrs[i], int)
+        iflag, oflag, cflag, lflag, ispeed, ospeed, cc = attrs
+        self.assertIsInstance(cc, list)
+        self.assertEqual(len(cc), termios.NCCS)
+        for i, x in enumerate(cc):
+            if ((lflag & termios.ICANON) == 0 and
+                (i == termios.VMIN or i == termios.VTIME)):
+                self.assertIsInstance(x, int)
+            else:
+                self.assertIsInstance(x, bytes)
+                self.assertEqual(len(x), 1)
+        self.assertEqual(termios.tcgetattr(self.stream), attrs)
+
+    def test_tcgetattr_errors(self):
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcgetattr, self.bad_fd)
+        self.assertRaises(ValueError, termios.tcgetattr, -1)
+        self.assertRaises(OverflowError, termios.tcgetattr, 2**1000)
+        self.assertRaises(TypeError, termios.tcgetattr, object())
+        self.assertRaises(TypeError, termios.tcgetattr)
+
+    def test_tcsetattr(self):
+        attrs = termios.tcgetattr(self.fd)
+        termios.tcsetattr(self.fd, termios.TCSANOW, attrs)
+        termios.tcsetattr(self.fd, termios.TCSADRAIN, attrs)
+        termios.tcsetattr(self.fd, termios.TCSAFLUSH, attrs)
+        termios.tcsetattr(self.stream, termios.TCSANOW, attrs)
+
+    def test_tcsetattr_errors(self):
+        attrs = termios.tcgetattr(self.fd)
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, tuple(attrs))
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs[:-1])
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs + [0])
+        for i in range(6):
+            attrs2 = attrs[:]
+            attrs2[i] = 2**1000
+            self.assertRaises(OverflowError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs2)
+            attrs2[i] = object()
+            self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs2)
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs[:-1] + [attrs[-1][:-1]])
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs[:-1] + [attrs[-1] + [b'\0']])
+        for i in range(len(attrs[-1])):
+            attrs2 = attrs[:]
+            attrs2[-1] = attrs2[-1][:]
+            attrs2[-1][i] = 2**1000
+            self.assertRaises(OverflowError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs2)
+            attrs2[-1][i] = object()
+            self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs2)
+            attrs2[-1][i] = b''
+            self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs2)
+            attrs2[-1][i] = b'\0\0'
+            self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, attrs2)
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW, object())
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW)
+        self.assertRaisesTermiosError(errno.EINVAL, termios.tcsetattr, self.fd, -1, attrs)
+        self.assertRaises(OverflowError, termios.tcsetattr, self.fd, 2**1000, attrs)
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, object(), attrs)
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcsetattr, self.bad_fd, termios.TCSANOW, attrs)
+        self.assertRaises(ValueError, termios.tcsetattr, -1, termios.TCSANOW, attrs)
+        self.assertRaises(OverflowError, termios.tcsetattr, 2**1000, termios.TCSANOW, attrs)
+        self.assertRaises(TypeError, termios.tcsetattr, object(), termios.TCSANOW, attrs)
+        self.assertRaises(TypeError, termios.tcsetattr, self.fd, termios.TCSANOW)
+
+    def test_tcsendbreak(self):
+        try:
+            termios.tcsendbreak(self.fd, 1)
+        except termios.error as exc:
+            if exc.args[0] == errno.ENOTTY and sys.platform.startswith('freebsd'):
+                self.skipTest('termios.tcsendbreak() is not supported '
+                              'with pseudo-terminals (?) on this platform')
+            raise
+        termios.tcsendbreak(self.stream, 1)
+
+    def test_tcsendbreak_errors(self):
+        self.assertRaises(OverflowError, termios.tcsendbreak, self.fd, 2**1000)
+        self.assertRaises(TypeError, termios.tcsendbreak, self.fd, 0.0)
+        self.assertRaises(TypeError, termios.tcsendbreak, self.fd, object())
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcsendbreak, self.bad_fd, 0)
+        self.assertRaises(ValueError, termios.tcsendbreak, -1, 0)
+        self.assertRaises(OverflowError, termios.tcsendbreak, 2**1000, 0)
+        self.assertRaises(TypeError, termios.tcsendbreak, object(), 0)
+        self.assertRaises(TypeError, termios.tcsendbreak, self.fd)
+
+    def test_tcdrain(self):
+        termios.tcdrain(self.fd)
+        termios.tcdrain(self.stream)
+
+    def test_tcdrain_errors(self):
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcdrain, self.bad_fd)
+        self.assertRaises(ValueError, termios.tcdrain, -1)
+        self.assertRaises(OverflowError, termios.tcdrain, 2**1000)
+        self.assertRaises(TypeError, termios.tcdrain, object())
+        self.assertRaises(TypeError, termios.tcdrain)
+
+    def test_tcflush(self):
+        termios.tcflush(self.fd, termios.TCIFLUSH)
+        termios.tcflush(self.fd, termios.TCOFLUSH)
+        termios.tcflush(self.fd, termios.TCIOFLUSH)
+
+    def test_tcflush_errors(self):
+        self.assertRaisesTermiosError(errno.EINVAL, termios.tcflush, self.fd, -1)
+        self.assertRaises(OverflowError, termios.tcflush, self.fd, 2**1000)
+        self.assertRaises(TypeError, termios.tcflush, self.fd, object())
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcflush, self.bad_fd, termios.TCIFLUSH)
+        self.assertRaises(ValueError, termios.tcflush, -1, termios.TCIFLUSH)
+        self.assertRaises(OverflowError, termios.tcflush, 2**1000, termios.TCIFLUSH)
+        self.assertRaises(TypeError, termios.tcflush, object(), termios.TCIFLUSH)
+        self.assertRaises(TypeError, termios.tcflush, self.fd)
+
+    def test_tcflow(self):
+        termios.tcflow(self.fd, termios.TCOOFF)
+        termios.tcflow(self.fd, termios.TCOON)
+        termios.tcflow(self.fd, termios.TCIOFF)
+        termios.tcflow(self.fd, termios.TCION)
+
+    def test_tcflow_errors(self):
+        self.assertRaisesTermiosError(errno.EINVAL, termios.tcflow, self.fd, -1)
+        self.assertRaises(OverflowError, termios.tcflow, self.fd, 2**1000)
+        self.assertRaises(TypeError, termios.tcflow, self.fd, object())
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcflow, self.bad_fd, termios.TCOON)
+        self.assertRaises(ValueError, termios.tcflow, -1, termios.TCOON)
+        self.assertRaises(OverflowError, termios.tcflow, 2**1000, termios.TCOON)
+        self.assertRaises(TypeError, termios.tcflow, object(), termios.TCOON)
+        self.assertRaises(TypeError, termios.tcflow, self.fd)
+
+    def test_tcgetwinsize(self):
+        size = termios.tcgetwinsize(self.fd)
+        self.assertIsInstance(size, tuple)
+        self.assertEqual(len(size), 2)
+        self.assertIsInstance(size[0], int)
+        self.assertIsInstance(size[1], int)
+        self.assertEqual(termios.tcgetwinsize(self.stream), size)
+
+    def test_tcgetwinsize_errors(self):
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcgetwinsize, self.bad_fd)
+        self.assertRaises(ValueError, termios.tcgetwinsize, -1)
+        self.assertRaises(OverflowError, termios.tcgetwinsize, 2**1000)
+        self.assertRaises(TypeError, termios.tcgetwinsize, object())
+        self.assertRaises(TypeError, termios.tcgetwinsize)
+
+    def test_tcsetwinsize(self):
+        size = termios.tcgetwinsize(self.fd)
+        termios.tcsetwinsize(self.fd, size)
+        termios.tcsetwinsize(self.fd, list(size))
+        termios.tcsetwinsize(self.stream, size)
+
+    def test_tcsetwinsize_errors(self):
+        size = termios.tcgetwinsize(self.fd)
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, size[:-1])
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, size + (0,))
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, object())
+        self.assertRaises(OverflowError, termios.tcsetwinsize, self.fd, (size[0], 2**1000))
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, (size[0], float(size[1])))
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, (size[0], object()))
+        self.assertRaises(OverflowError, termios.tcsetwinsize, self.fd, (2**1000, size[1]))
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, (float(size[0]), size[1]))
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd, (object(), size[1]))
+        self.assertRaisesTermiosError(errno.ENOTTY, termios.tcsetwinsize, self.bad_fd, size)
+        self.assertRaises(ValueError, termios.tcsetwinsize, -1, size)
+        self.assertRaises(OverflowError, termios.tcsetwinsize, 2**1000, size)
+        self.assertRaises(TypeError, termios.tcsetwinsize, object(), size)
+        self.assertRaises(TypeError, termios.tcsetwinsize, self.fd)
+
+
+class TestModule(unittest.TestCase):
+    def test_constants(self):
+        self.assertIsInstance(termios.B0, int)
+        self.assertIsInstance(termios.B38400, int)
+        self.assertIsInstance(termios.TCSANOW, int)
+        self.assertIsInstance(termios.TCSADRAIN, int)
+        self.assertIsInstance(termios.TCSAFLUSH, int)
+        self.assertIsInstance(termios.TCIFLUSH, int)
+        self.assertIsInstance(termios.TCOFLUSH, int)
+        self.assertIsInstance(termios.TCIOFLUSH, int)
+        self.assertIsInstance(termios.TCOOFF, int)
+        self.assertIsInstance(termios.TCOON, int)
+        self.assertIsInstance(termios.TCIOFF, int)
+        self.assertIsInstance(termios.TCION, int)
+        self.assertIsInstance(termios.VTIME, int)
+        self.assertIsInstance(termios.VMIN, int)
+        self.assertIsInstance(termios.NCCS, int)
+        self.assertLess(termios.VTIME, termios.NCCS)
+        self.assertLess(termios.VMIN, termios.NCCS)
+
+    def test_exception(self):
+        self.assertTrue(issubclass(termios.error, Exception))
+        self.assertFalse(issubclass(termios.error, OSError))
+
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/Lib/test/test_threading.py b/Lib/test/test_threading.py
index 9e4972ecb6..f63e5c6184 100644
--- a/Lib/test/test_threading.py
+++ b/Lib/test/test_threading.py
@@ -35,6 +35,16 @@
 platforms_to_skip = ('netbsd5', 'hp-ux11')
 
 
+def skip_unless_reliable_fork(test):
+    if not support.has_fork_support:
+        return unittest.skip("requires working os.fork()")(test)
+    if sys.platform in platforms_to_skip:
+        return unittest.skip("due to known OS bug related to thread+fork")(test)
+    if support.HAVE_ASAN_FORK_BUG:
+        return unittest.skip("libasan has a pthread_create() dead lock related to thread+fork")(test)
+    return test
+
+
 def restore_default_excepthook(testcase):
     testcase.addCleanup(setattr, threading, 'excepthook', threading.excepthook)
     threading.excepthook = threading.__excepthook__
@@ -531,7 +541,7 @@ def test_daemon_param(self):
         t = threading.Thread(daemon=True)
         self.assertTrue(t.daemon)
 
-    @support.requires_fork()
+    @skip_unless_reliable_fork
     def test_dummy_thread_after_fork(self):
         # Issue #14308: a dummy thread in the active list doesn't mess up
         # the after-fork mechanism.
@@ -563,7 +573,7 @@ def background_thread(evt):
         self.assertEqual(out, b'')
         self.assertEqual(err, b'')
 
-    @support.requires_fork()
+    @skip_unless_reliable_fork
     def test_is_alive_after_fork(self):
         # Try hard to trigger #18418: is_alive() could sometimes be True on
         # threads that vanished after a fork.
@@ -599,7 +609,7 @@ def f():
         th.start()
         th.join()
 
-    @support.requires_fork()
+    @skip_unless_reliable_fork
     @unittest.skipUnless(hasattr(os, 'waitpid'), "test needs os.waitpid()")
     def test_main_thread_after_fork(self):
         code = """if 1:
@@ -620,8 +630,7 @@ def test_main_thread_after_fork(self):
         self.assertEqual(err, b"")
         self.assertEqual(data, "MainThread\nTrue\nTrue\n")
 
-    @unittest.skipIf(sys.platform in platforms_to_skip, "due to known OS bug")
-    @support.requires_fork()
+    @skip_unless_reliable_fork
     @unittest.skipUnless(hasattr(os, 'waitpid'), "test needs os.waitpid()")
     def test_main_thread_after_fork_from_nonmain_thread(self):
         code = """if 1:
@@ -1068,8 +1077,7 @@ def test_1_join_on_shutdown(self):
             """
         self._run_and_join(script)
 
-    @support.requires_fork()
-    @unittest.skipIf(sys.platform in platforms_to_skip, "due to known OS bug")
+    @skip_unless_reliable_fork
     def test_2_join_in_forked_process(self):
         # Like the test above, but from a forked interpreter
         script = """if 1:
@@ -1089,8 +1097,7 @@ def test_2_join_in_forked_process(self):
             """
         self._run_and_join(script)
 
-    @support.requires_fork()
-    @unittest.skipIf(sys.platform in platforms_to_skip, "due to known OS bug")
+    @skip_unless_reliable_fork
     def test_3_join_in_forked_from_thread(self):
         # Like the test above, but fork() was called from a worker thread
         # In the forked process, the main Thread object must be marked as stopped.
@@ -1160,8 +1167,7 @@ def main():
         rc, out, err = assert_python_ok('-c', script)
         self.assertFalse(err)
 
-    @support.requires_fork()
-    @unittest.skipIf(sys.platform in platforms_to_skip, "due to known OS bug")
+    @skip_unless_reliable_fork
     def test_reinit_tls_after_fork(self):
         # Issue #13817: fork() would deadlock in a multithreaded program with
         # the ad-hoc TLS implementation.
@@ -1187,7 +1193,7 @@ def do_fork_and_wait():
             for t in threads:
                 t.join()
 
-    @support.requires_fork()
+    @skip_unless_reliable_fork
     def test_clear_threads_states_after_fork(self):
         # Issue #17094: check that threads states are cleared after fork()
 
@@ -1747,6 +1753,9 @@ class ConditionAsRLockTests(lock_tests.RLockTests):
     # Condition uses an RLock by default and exports its API.
     locktype = staticmethod(threading.Condition)
 
+    def test_recursion_count(self):
+        self.skipTest("Condition does not expose _recursion_count()")
+
 class ConditionTests(lock_tests.ConditionTests):
     condtype = staticmethod(threading.Condition)
 
diff --git a/Lib/test/test_tkinter/test_images.py b/Lib/test/test_tkinter/test_images.py
index 9f49d6efc7..cc1ed28601 100644
--- a/Lib/test/test_tkinter/test_images.py
+++ b/Lib/test/test_tkinter/test_images.py
@@ -357,13 +357,18 @@ def test_get(self):
         self.assertRaises(tkinter.TclError, image.get, 15, 16)
 
     def test_write(self):
+        filename = os_helper.TESTFN
+        import locale
+        if locale.getlocale()[0] is None:
+            # Tcl uses Latin1 in the C locale
+            filename = os_helper.TESTFN_ASCII
         image = self.create()
-        self.addCleanup(os_helper.unlink, os_helper.TESTFN)
+        self.addCleanup(os_helper.unlink, filename)
 
-        image.write(os_helper.TESTFN)
+        image.write(filename)
         image2 = tkinter.PhotoImage('::img::test2', master=self.root,
                                     format='ppm',
-                                    file=os_helper.TESTFN)
+                                    file=filename)
         self.assertEqual(str(image2), '::img::test2')
         self.assertEqual(image2.type(), 'photo')
         self.assertEqual(image2.width(), 16)
@@ -371,10 +376,10 @@ def test_write(self):
         self.assertEqual(image2.get(0, 0), image.get(0, 0))
         self.assertEqual(image2.get(15, 8), image.get(15, 8))
 
-        image.write(os_helper.TESTFN, format='gif', from_coords=(4, 6, 6, 9))
+        image.write(filename, format='gif', from_coords=(4, 6, 6, 9))
         image3 = tkinter.PhotoImage('::img::test3', master=self.root,
                                     format='gif',
-                                    file=os_helper.TESTFN)
+                                    file=filename)
         self.assertEqual(str(image3), '::img::test3')
         self.assertEqual(image3.type(), 'photo')
         self.assertEqual(image3.width(), 2)
diff --git a/Lib/test/test_tkinter/test_misc.py b/Lib/test/test_tkinter/test_misc.py
index d1aca58d15..bac52ae0c0 100644
--- a/Lib/test/test_tkinter/test_misc.py
+++ b/Lib/test/test_tkinter/test_misc.py
@@ -371,6 +371,309 @@ def test_info_patchlevel(self):
         self.assertTrue(str(vi).startswith(f'{vi.major}.{vi.minor}'))
 
 
+class BindTest(AbstractTkTest, unittest.TestCase):
+
+    def setUp(self):
+        super().setUp()
+        root = self.root
+        self.frame = tkinter.Frame(self.root, class_='Test',
+                                   width=150, height=100)
+        self.frame.pack()
+
+    def assertCommandExist(self, funcid):
+        self.assertEqual(_info_commands(self.root, funcid), (funcid,))
+
+    def assertCommandNotExist(self, funcid):
+        self.assertEqual(_info_commands(self.root, funcid), ())
+
+    def test_bind(self):
+        event = '<Control-Alt-Key-a>'
+        f = self.frame
+        self.assertEqual(f.bind(), ())
+        self.assertEqual(f.bind(event), '')
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = f.bind(event, test1)
+        self.assertEqual(f.bind(), (event,))
+        script = f.bind(event)
+        self.assertIn(funcid, script)
+        self.assertCommandExist(funcid)
+
+        funcid2 = f.bind(event, test2, add=True)
+        script = f.bind(event)
+        self.assertIn(funcid, script)
+        self.assertIn(funcid2, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+    def test_unbind(self):
+        event = '<Control-Alt-Key-b>'
+        f = self.frame
+        self.assertEqual(f.bind(), ())
+        self.assertEqual(f.bind(event), '')
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = f.bind(event, test1)
+        funcid2 = f.bind(event, test2, add=True)
+
+        self.assertRaises(TypeError, f.unbind)
+        f.unbind(event)
+        self.assertEqual(f.bind(event), '')
+        self.assertEqual(f.bind(), ())
+
+    def test_unbind2(self):
+        f = self.frame
+        event = '<Control-Alt-Key-c>'
+        self.assertEqual(f.bind(), ())
+        self.assertEqual(f.bind(event), '')
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = f.bind(event, test1)
+        funcid2 = f.bind(event, test2, add=True)
+
+        f.unbind(event, funcid)
+        script = f.bind(event)
+        self.assertNotIn(funcid, script)
+        self.assertCommandNotExist(funcid)
+        self.assertCommandExist(funcid2)
+
+        f.unbind(event, funcid2)
+        self.assertEqual(f.bind(event), '')
+        self.assertEqual(f.bind(), ())
+        self.assertCommandNotExist(funcid)
+        self.assertCommandNotExist(funcid2)
+
+        # non-idempotent
+        self.assertRaises(tkinter.TclError, f.unbind, event, funcid2)
+
+    def test_bind_rebind(self):
+        event = '<Control-Alt-Key-d>'
+        f = self.frame
+        self.assertEqual(f.bind(), ())
+        self.assertEqual(f.bind(event), '')
+        def test1(e): pass
+        def test2(e): pass
+        def test3(e): pass
+
+        funcid = f.bind(event, test1)
+        funcid2 = f.bind(event, test2, add=True)
+        script = f.bind(event)
+        self.assertIn(funcid2, script)
+        self.assertIn(funcid, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+        funcid3 = f.bind(event, test3)
+        script = f.bind(event)
+        self.assertNotIn(funcid, script)
+        self.assertNotIn(funcid2, script)
+        self.assertIn(funcid3, script)
+        self.assertCommandExist(funcid3)
+
+    def test_bind_class(self):
+        event = '<Control-Alt-Key-e>'
+        bind_class = self.root.bind_class
+        unbind_class = self.root.unbind_class
+        self.assertRaises(TypeError, bind_class)
+        self.assertEqual(bind_class('Test'), ())
+        self.assertEqual(bind_class('Test', event), '')
+        self.addCleanup(unbind_class, 'Test', event)
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = bind_class('Test', event, test1)
+        self.assertEqual(bind_class('Test'), (event,))
+        script = bind_class('Test', event)
+        self.assertIn(funcid, script)
+        self.assertCommandExist(funcid)
+
+        funcid2 = bind_class('Test', event, test2, add=True)
+        script = bind_class('Test', event)
+        self.assertIn(funcid, script)
+        self.assertIn(funcid2, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+    def test_unbind_class(self):
+        event = '<Control-Alt-Key-f>'
+        bind_class = self.root.bind_class
+        unbind_class = self.root.unbind_class
+        self.assertEqual(bind_class('Test'), ())
+        self.assertEqual(bind_class('Test', event), '')
+        self.addCleanup(unbind_class, 'Test', event)
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = bind_class('Test', event, test1)
+        funcid2 = bind_class('Test', event, test2, add=True)
+
+        self.assertRaises(TypeError, unbind_class)
+        self.assertRaises(TypeError, unbind_class, 'Test')
+        unbind_class('Test', event)
+        self.assertEqual(bind_class('Test', event), '')
+        self.assertEqual(bind_class('Test'), ())
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+        unbind_class('Test', event)  # idempotent
+
+    def test_bind_class_rebind(self):
+        event = '<Control-Alt-Key-g>'
+        bind_class = self.root.bind_class
+        unbind_class = self.root.unbind_class
+        self.assertEqual(bind_class('Test'), ())
+        self.assertEqual(bind_class('Test', event), '')
+        self.addCleanup(unbind_class, 'Test', event)
+        def test1(e): pass
+        def test2(e): pass
+        def test3(e): pass
+
+        funcid = bind_class('Test', event, test1)
+        funcid2 = bind_class('Test', event, test2, add=True)
+        script = bind_class('Test', event)
+        self.assertIn(funcid2, script)
+        self.assertIn(funcid, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+        funcid3 = bind_class('Test', event, test3)
+        script = bind_class('Test', event)
+        self.assertNotIn(funcid, script)
+        self.assertNotIn(funcid2, script)
+        self.assertIn(funcid3, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+        self.assertCommandExist(funcid3)
+
+    def test_bind_all(self):
+        event = '<Control-Alt-Key-h>'
+        bind_all = self.root.bind_all
+        unbind_all = self.root.unbind_all
+        self.assertNotIn(event, bind_all())
+        self.assertEqual(bind_all(event), '')
+        self.addCleanup(unbind_all, event)
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = bind_all(event, test1)
+        self.assertIn(event, bind_all())
+        script = bind_all(event)
+        self.assertIn(funcid, script)
+        self.assertCommandExist(funcid)
+
+        funcid2 = bind_all(event, test2, add=True)
+        script = bind_all(event)
+        self.assertIn(funcid, script)
+        self.assertIn(funcid2, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+    def test_unbind_all(self):
+        event = '<Control-Alt-Key-i>'
+        bind_all = self.root.bind_all
+        unbind_all = self.root.unbind_all
+        self.assertNotIn(event, bind_all())
+        self.assertEqual(bind_all(event), '')
+        self.addCleanup(unbind_all, event)
+        def test1(e): pass
+        def test2(e): pass
+
+        funcid = bind_all(event, test1)
+        funcid2 = bind_all(event, test2, add=True)
+
+        unbind_all(event)
+        self.assertEqual(bind_all(event), '')
+        self.assertNotIn(event, bind_all())
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+        unbind_all(event)  # idempotent
+
+    def test_bind_all_rebind(self):
+        event = '<Control-Alt-Key-j>'
+        bind_all = self.root.bind_all
+        unbind_all = self.root.unbind_all
+        self.assertNotIn(event, bind_all())
+        self.assertEqual(bind_all(event), '')
+        self.addCleanup(unbind_all, event)
+        def test1(e): pass
+        def test2(e): pass
+        def test3(e): pass
+
+        funcid = bind_all(event, test1)
+        funcid2 = bind_all(event, test2, add=True)
+        script = bind_all(event)
+        self.assertIn(funcid2, script)
+        self.assertIn(funcid, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+
+        funcid3 = bind_all(event, test3)
+        script = bind_all(event)
+        self.assertNotIn(funcid, script)
+        self.assertNotIn(funcid2, script)
+        self.assertIn(funcid3, script)
+        self.assertCommandExist(funcid)
+        self.assertCommandExist(funcid2)
+        self.assertCommandExist(funcid3)
+
+    def test_bindtags(self):
+        f = self.frame
+        self.assertEqual(self.root.bindtags(), ('.', 'Tk', 'all'))
+        self.assertEqual(f.bindtags(), (str(f), 'Test', '.', 'all'))
+        f.bindtags(('a', 'b c'))
+        self.assertEqual(f.bindtags(), ('a', 'b c'))
+
+    def test_bind_events(self):
+        event = '<Enter>'
+        root = self.root
+        t = tkinter.Toplevel(root)
+        f = tkinter.Frame(t, class_='Test', width=150, height=100)
+        f.pack()
+        root.wait_visibility()  # needed on Windows
+        root.update_idletasks()
+        self.addCleanup(root.unbind_class, 'Test', event)
+        self.addCleanup(root.unbind_class, 'Toplevel', event)
+        self.addCleanup(root.unbind_class, 'tag', event)
+        self.addCleanup(root.unbind_class, 'tag2', event)
+        self.addCleanup(root.unbind_all, event)
+        def test(what):
+            return lambda e: events.append((what, e.widget))
+
+        root.bind_all(event, test('all'))
+        root.bind_class('Test', event, test('frame class'))
+        root.bind_class('Toplevel', event, test('toplevel class'))
+        root.bind_class('tag', event, test('tag'))
+        root.bind_class('tag2', event, test('tag2'))
+        f.bind(event, test('frame'))
+        t.bind(event, test('toplevel'))
+
+        events = []
+        f.event_generate(event)
+        self.assertEqual(events, [
+            ('frame', f),
+            ('frame class', f),
+            ('toplevel', f),
+            ('all', f),
+        ])
+
+        events = []
+        t.event_generate(event)
+        self.assertEqual(events, [
+            ('toplevel', t),
+            ('toplevel class', t),
+            ('all', t),
+        ])
+
+        f.bindtags(('tag', 'tag3'))
+        events = []
+        f.event_generate(event)
+        self.assertEqual(events, [('tag', f)])
+
+
 class DefaultRootTest(AbstractDefaultRootTest, unittest.TestCase):
 
     def test_default_root(self):
@@ -426,5 +729,9 @@ def test_mainloop(self):
         self.assertRaises(RuntimeError, tkinter.mainloop)
 
 
+def _info_commands(widget, pattern=None):
+    return widget.tk.splitlist(widget.tk.call('info', 'commands', pattern))
+
+
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_tokenize.py b/Lib/test/test_tokenize.py
index c320478cf3..bbbc337b18 100644
--- a/Lib/test/test_tokenize.py
+++ b/Lib/test/test_tokenize.py
@@ -571,6 +571,55 @@ def test_string(self):
     OP         '='           (3, 0) (3, 1)
     OP         '}'           (3, 1) (3, 2)
     FSTRING_END "'''"         (3, 2) (3, 5)
+    """)
+        self.check_tokenize("""\
+f'''__{
+    x:a
+}__'''""", """\
+    FSTRING_START "f'''"        (1, 0) (1, 4)
+    FSTRING_MIDDLE '__'          (1, 4) (1, 6)
+    OP         '{'           (1, 6) (1, 7)
+    NL         '\\n'          (1, 7) (1, 8)
+    NAME       'x'           (2, 4) (2, 5)
+    OP         ':'           (2, 5) (2, 6)
+    FSTRING_MIDDLE 'a\\n'         (2, 6) (3, 0)
+    OP         '}'           (3, 0) (3, 1)
+    FSTRING_MIDDLE '__'          (3, 1) (3, 3)
+    FSTRING_END "'''"         (3, 3) (3, 6)
+    """)
+        self.check_tokenize("""\
+f'''__{
+    x:a
+    b
+     c
+      d
+}__'''""", """\
+    FSTRING_START "f'''"        (1, 0) (1, 4)
+    FSTRING_MIDDLE '__'          (1, 4) (1, 6)
+    OP         '{'           (1, 6) (1, 7)
+    NL         '\\n'          (1, 7) (1, 8)
+    NAME       'x'           (2, 4) (2, 5)
+    OP         ':'           (2, 5) (2, 6)
+    FSTRING_MIDDLE 'a\\n    b\\n     c\\n      d\\n' (2, 6) (6, 0)
+    OP         '}'           (6, 0) (6, 1)
+    FSTRING_MIDDLE '__'          (6, 1) (6, 3)
+    FSTRING_END "'''"         (6, 3) (6, 6)
+    """)
+        self.check_tokenize("""\
+f'__{
+    x:d
+}__'""", """\
+    FSTRING_START "f'"          (1, 0) (1, 2)
+    FSTRING_MIDDLE '__'          (1, 2) (1, 4)
+    OP         '{'           (1, 4) (1, 5)
+    NL         '\\n'          (1, 5) (1, 6)
+    NAME       'x'           (2, 4) (2, 5)
+    OP         ':'           (2, 5) (2, 6)
+    FSTRING_MIDDLE 'd'           (2, 6) (2, 7)
+    NL         '\\n'          (2, 7) (2, 8)
+    OP         '}'           (3, 0) (3, 1)
+    FSTRING_MIDDLE '__'          (3, 1) (3, 3)
+    FSTRING_END "'"           (3, 3) (3, 4)
     """)
 
     def test_function(self):
@@ -1198,7 +1247,7 @@ class TestTokenizerAdheresToPep0263(TestCase):
     """
 
     def _testFile(self, filename):
-        path = os.path.join(os.path.dirname(__file__), filename)
+        path = os.path.join(os.path.dirname(__file__), 'tokenizedata', filename)
         with open(path, 'rb') as f:
             TestRoundtrip.check_roundtrip(self, f)
 
@@ -1791,7 +1840,7 @@ def test_roundtrip(self):
 
         self.check_roundtrip("if x == 1 : \n"
                              "  print(x)\n")
-        fn = support.findfile("tokenize_tests.txt")
+        fn = support.findfile("tokenize_tests.txt", subdir="tokenizedata")
         with open(fn, 'rb') as f:
             self.check_roundtrip(f)
         self.check_roundtrip("if x == 1:\n"
@@ -1846,23 +1895,12 @@ def test_random_files(self):
         # pass the '-ucpu' option to process the full directory.
 
         import glob, random
-        fn = support.findfile("tokenize_tests.txt")
-        tempdir = os.path.dirname(fn) or os.curdir
+        tempdir = os.path.dirname(__file__) or os.curdir
         testfiles = glob.glob(os.path.join(glob.escape(tempdir), "test*.py"))
 
-        # Tokenize is broken on test_pep3131.py because regular expressions are
-        # broken on the obscure unicode identifiers in it. *sigh*
-        # With roundtrip extended to test the 5-tuple mode of untokenize,
-        # 7 more testfiles fail.  Remove them also until the failure is diagnosed.
-
-        testfiles.remove(os.path.join(tempdir, "test_unicode_identifiers.py"))
-
         # TODO: Remove this once we can untokenize PEP 701 syntax
         testfiles.remove(os.path.join(tempdir, "test_fstring.py"))
 
-        for f in ('buffer', 'builtin', 'fileio', 'inspect', 'os', 'platform', 'sys'):
-            testfiles.remove(os.path.join(tempdir, "test_%s.py") % f)
-
         if not support.is_resource_enabled("cpu"):
             testfiles = random.sample(testfiles, 10)
 
@@ -2275,6 +2313,54 @@ def test_string(self):
     FSTRING_START \'f"\'          (1, 0) (1, 2)
     FSTRING_MIDDLE 'hola\\\\\\\\\\\\r\\\\ndfgf' (1, 2) (1, 16)
     FSTRING_END \'"\'           (1, 16) (1, 17)
+    """)
+
+        self.check_tokenize("""\
+f'''__{
+    x:a
+}__'''""", """\
+    FSTRING_START "f'''"        (1, 0) (1, 4)
+    FSTRING_MIDDLE '__'          (1, 4) (1, 6)
+    LBRACE     '{'           (1, 6) (1, 7)
+    NAME       'x'           (2, 4) (2, 5)
+    COLON      ':'           (2, 5) (2, 6)
+    FSTRING_MIDDLE 'a\\n'         (2, 6) (3, 0)
+    RBRACE     '}'           (3, 0) (3, 1)
+    FSTRING_MIDDLE '__'          (3, 1) (3, 3)
+    FSTRING_END "'''"         (3, 3) (3, 6)
+    """)
+
+        self.check_tokenize("""\
+f'''__{
+    x:a
+    b
+     c
+      d
+}__'''""", """\
+    FSTRING_START "f'''"        (1, 0) (1, 4)
+    FSTRING_MIDDLE '__'          (1, 4) (1, 6)
+    LBRACE     '{'           (1, 6) (1, 7)
+    NAME       'x'           (2, 4) (2, 5)
+    COLON      ':'           (2, 5) (2, 6)
+    FSTRING_MIDDLE 'a\\n    b\\n     c\\n      d\\n' (2, 6) (6, 0)
+    RBRACE     '}'           (6, 0) (6, 1)
+    FSTRING_MIDDLE '__'          (6, 1) (6, 3)
+    FSTRING_END "'''"         (6, 3) (6, 6)
+    """)
+
+        self.check_tokenize("""\
+f'__{
+    x:d
+}__'""", """\
+    FSTRING_START "f'"          (1, 0) (1, 2)
+    FSTRING_MIDDLE '__'          (1, 2) (1, 4)
+    LBRACE     '{'           (1, 4) (1, 5)
+    NAME       'x'           (2, 4) (2, 5)
+    COLON      ':'           (2, 5) (2, 6)
+    FSTRING_MIDDLE 'd'           (2, 6) (2, 7)
+    RBRACE     '}'           (3, 0) (3, 1)
+    FSTRING_MIDDLE '__'          (3, 1) (3, 3)
+    FSTRING_END "'"           (3, 3) (3, 4)
     """)
 
     def test_function(self):
diff --git a/Lib/test/test_tools/test_freeze.py b/Lib/test/test_tools/test_freeze.py
index 922e74b441..671ec2961e 100644
--- a/Lib/test/test_tools/test_freeze.py
+++ b/Lib/test/test_tools/test_freeze.py
@@ -15,6 +15,10 @@
 @support.requires_zlib()
 @unittest.skipIf(sys.platform.startswith('win'), 'not supported on Windows')
 @support.skip_if_buildbot('not all buildbots have enough space')
+# gh-103053: Skip test if Python is built with Profile Guided Optimization
+# (PGO), since the test is just too slow in this case.
+@unittest.skipIf(support.check_cflags_pgo(),
+                 'test is too slow with PGO')
 class TestFreeze(unittest.TestCase):
 
     @support.requires_resource('cpu') # Building Python is slow
diff --git a/Lib/test/test_tools/test_reindent.py b/Lib/test/test_tools/test_reindent.py
index 3b0c793a38..64e31c2b77 100644
--- a/Lib/test/test_tools/test_reindent.py
+++ b/Lib/test/test_tools/test_reindent.py
@@ -25,7 +25,7 @@ def test_help(self):
         self.assertGreater(err, b'')
 
     def test_reindent_file_with_bad_encoding(self):
-        bad_coding_path = findfile('bad_coding.py')
+        bad_coding_path = findfile('bad_coding.py', subdir='tokenizedata')
         rc, out, err = assert_python_ok(self.script, '-r', bad_coding_path)
         self.assertEqual(out, b'')
         self.assertNotEqual(err, b'')
diff --git a/Lib/test/test_traceback.py b/Lib/test/test_traceback.py
index e84e8fecdf..e0ef9e03f1 100644
--- a/Lib/test/test_traceback.py
+++ b/Lib/test/test_traceback.py
@@ -922,8 +922,63 @@ def f():
             f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
             "    callable()",
             f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 4}, in f",
-            "    print(1, ｗｗｗ(",
-            "             ^^^^",
+            f"    print(1, ｗｗｗ(",
+            f"             ^^^^^^^",
+        ]
+        self.assertEqual(actual, expected)
+
+    def test_byte_offset_with_wide_characters_term_highlight(self):
+        def f():
+            说明说明 = 1
+            şçöğıĤellö = 0 # not wide but still non-ascii
+            return 说明说明 / şçöğıĤellö
+
+        actual = self.get_exception(f)
+        expected = [
+            f"Traceback (most recent call last):",
+            f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
+            f"    callable()",
+            f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 3}, in f",
+            f"    return 说明说明 / şçöğıĤellö",
+            f"           ~~~~~~~~~^~~~~~~~~~~~",
+        ]
+        self.assertEqual(actual, expected)
+
+    def test_byte_offset_with_emojis_term_highlight(self):
+        def f():
+            return "✨🐍" + func_说明说明("📗🚛",
+                "📗🚛") + "🐍"
+
+        actual = self.get_exception(f)
+        expected = [
+            f"Traceback (most recent call last):",
+            f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
+            f"    callable()",
+            f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 1}, in f",
+            f'    return "✨🐍" + func_说明说明("📗🚛",',
+            f"                    ^^^^^^^^^^^^^",
+        ]
+        self.assertEqual(actual, expected)
+
+    def test_byte_offset_wide_chars_subscript(self):
+        def f():
+            my_dct = {
+                "✨🚛✨": {
+                    "说明": {
+                        "🐍🐍🐍": None
+                    }
+                }
+            }
+            return my_dct["✨🚛✨"]["说明"]["🐍"]["说明"]["🐍🐍"]
+
+        actual = self.get_exception(f)
+        expected = [
+            f"Traceback (most recent call last):",
+            f"  File \"{__file__}\", line {self.callable_line}, in get_exception",
+            f"    callable()",
+            f"  File \"{__file__}\", line {f.__code__.co_firstlineno + 8}, in f",
+            f'    return my_dct["✨🚛✨"]["说明"]["🐍"]["说明"]["🐍🐍"]',
+            f"           ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^",
         ]
         self.assertEqual(actual, expected)
 
@@ -1599,27 +1654,28 @@ def __repr__(self):
         err_msg = "b'please do not show me as numbers'"
         self.assertEqual(self.get_report(e), vanilla + err_msg + '\n')
 
-    def test_exception_with_note_with_multiple_notes(self):
-        e = ValueError(42)
-        vanilla = self.get_report(e)
+    def test_exception_with_multiple_notes(self):
+        for e in [ValueError(42), SyntaxError('bad syntax')]:
+            with self.subTest(e=e):
+                vanilla = self.get_report(e)
 
-        e.add_note('Note 1')
-        e.add_note('Note 2')
-        e.add_note('Note 3')
+                e.add_note('Note 1')
+                e.add_note('Note 2')
+                e.add_note('Note 3')
 
-        self.assertEqual(
-            self.get_report(e),
-            vanilla + 'Note 1\n' + 'Note 2\n' + 'Note 3\n')
+                self.assertEqual(
+                    self.get_report(e),
+                    vanilla + 'Note 1\n' + 'Note 2\n' + 'Note 3\n')
 
-        del e.__notes__
-        e.add_note('Note 4')
-        del e.__notes__
-        e.add_note('Note 5')
-        e.add_note('Note 6')
+                del e.__notes__
+                e.add_note('Note 4')
+                del e.__notes__
+                e.add_note('Note 5')
+                e.add_note('Note 6')
 
-        self.assertEqual(
-            self.get_report(e),
-            vanilla + 'Note 5\n' + 'Note 6\n')
+                self.assertEqual(
+                    self.get_report(e),
+                    vanilla + 'Note 5\n' + 'Note 6\n')
 
     def test_exception_qualname(self):
         class A:
diff --git a/Lib/test/test_tty.py b/Lib/test/test_tty.py
new file mode 100644
index 0000000000..af20864aac
--- /dev/null
+++ b/Lib/test/test_tty.py
@@ -0,0 +1,84 @@
+import os
+import unittest
+from test.support.import_helper import import_module
+
+termios = import_module('termios')
+tty = import_module('tty')
+
+
+@unittest.skipUnless(hasattr(os, 'openpty'), "need os.openpty()")
+class TestTty(unittest.TestCase):
+
+    def setUp(self):
+        master_fd, self.fd = os.openpty()
+        self.addCleanup(os.close, master_fd)
+        self.stream = self.enterContext(open(self.fd, 'wb', buffering=0))
+        self.fd = self.stream.fileno()
+        self.mode = termios.tcgetattr(self.fd)
+        self.addCleanup(termios.tcsetattr, self.fd, termios.TCSANOW, self.mode)
+        self.addCleanup(termios.tcsetattr, self.fd, termios.TCSAFLUSH, self.mode)
+
+    def check_cbreak(self, mode):
+        self.assertEqual(mode[0] & termios.ICRNL, 0)
+        self.assertEqual(mode[3] & termios.ECHO, 0)
+        self.assertEqual(mode[3] & termios.ICANON, 0)
+        self.assertEqual(mode[6][termios.VMIN], 1)
+        self.assertEqual(mode[6][termios.VTIME], 0)
+
+    def check_raw(self, mode):
+        self.check_cbreak(mode)
+        self.assertEqual(mode[0] & termios.ISTRIP, 0)
+        self.assertEqual(mode[0] & termios.ICRNL, 0)
+        self.assertEqual(mode[1] & termios.OPOST, 0)
+        self.assertEqual(mode[2] & termios.PARENB, termios.CS8 & termios.PARENB)
+        self.assertEqual(mode[2] & termios.CSIZE, termios.CS8 & termios.CSIZE)
+        self.assertEqual(mode[2] & termios.CS8, termios.CS8)
+        self.assertEqual(mode[3] & termios.ECHO, 0)
+        self.assertEqual(mode[3] & termios.ICANON, 0)
+        self.assertEqual(mode[3] & termios.ISIG, 0)
+        self.assertEqual(mode[6][termios.VMIN], 1)
+        self.assertEqual(mode[6][termios.VTIME], 0)
+
+    def test_cfmakeraw(self):
+        mode = termios.tcgetattr(self.fd)
+        self.assertEqual(mode, self.mode)
+        tty.cfmakeraw(mode)
+        self.check_raw(mode)
+        self.assertEqual(mode[4], self.mode[4])
+        self.assertEqual(mode[5], self.mode[5])
+
+    def test_cfmakecbreak(self):
+        mode = termios.tcgetattr(self.fd)
+        self.assertEqual(mode, self.mode)
+        tty.cfmakecbreak(mode)
+        self.check_cbreak(mode)
+        self.assertEqual(mode[1], self.mode[1])
+        self.assertEqual(mode[2], self.mode[2])
+        self.assertEqual(mode[4], self.mode[4])
+        self.assertEqual(mode[5], self.mode[5])
+
+    def test_setraw(self):
+        mode0 = termios.tcgetattr(self.fd)
+        mode1 = tty.setraw(self.fd)
+        self.assertEqual(mode1, mode0)
+        mode2 = termios.tcgetattr(self.fd)
+        self.check_raw(mode2)
+        mode3 = tty.setraw(self.fd, termios.TCSANOW)
+        self.assertEqual(mode3, mode2)
+        tty.setraw(self.stream)
+        tty.setraw(fd=self.fd, when=termios.TCSANOW)
+
+    def test_setcbreak(self):
+        mode0 = termios.tcgetattr(self.fd)
+        mode1 = tty.setcbreak(self.fd)
+        self.assertEqual(mode1, mode0)
+        mode2 = termios.tcgetattr(self.fd)
+        self.check_cbreak(mode2)
+        mode3 = tty.setcbreak(self.fd, termios.TCSANOW)
+        self.assertEqual(mode3, mode2)
+        tty.setcbreak(self.stream)
+        tty.setcbreak(fd=self.fd, when=termios.TCSANOW)
+
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/Lib/test/test_type_aliases.py b/Lib/test/test_type_aliases.py
index 8f0a998e1f..9c325bc595 100644
--- a/Lib/test/test_type_aliases.py
+++ b/Lib/test/test_type_aliases.py
@@ -2,7 +2,7 @@
 import types
 import unittest
 from test.support import check_syntax_error, run_code
-from test import mod_generics_cache
+from test.typinganndata import mod_generics_cache
 
 from typing import Callable, TypeAliasType, TypeVar, get_args
 
diff --git a/Lib/test/test_typing.py b/Lib/test/test_typing.py
index 6c9f168b63..62fe00b0a0 100644
--- a/Lib/test/test_typing.py
+++ b/Lib/test/test_typing.py
@@ -46,8 +46,7 @@
 import types
 
 from test.support import import_helper, captured_stderr, cpython_only
-from test import mod_generics_cache
-from test import _typed_dict_helper
+from test.typinganndata import mod_generics_cache, _typed_dict_helper
 
 
 CANNOT_SUBCLASS_TYPE = 'Cannot subclass special typing classes'
@@ -185,7 +184,7 @@ def test_cannot_subclass(self):
             class A(self.bottom_type):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class A(type(self.bottom_type)):
+            class B(type(self.bottom_type)):
                 pass
 
     def test_cannot_instantiate(self):
@@ -282,7 +281,7 @@ class C(type(Self)):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.Self'):
-            class C(Self):
+            class D(Self):
                 pass
 
     def test_cannot_init(self):
@@ -339,7 +338,7 @@ class C(type(LiteralString)):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.LiteralString'):
-            class C(LiteralString):
+            class D(LiteralString):
                 pass
 
     def test_cannot_init(self):
@@ -483,7 +482,7 @@ class V(TypeVar): pass
         T = TypeVar("T")
         with self.assertRaisesRegex(TypeError,
                 CANNOT_SUBCLASS_INSTANCE % 'TypeVar'):
-            class V(T): pass
+            class W(T): pass
 
     def test_cannot_instantiate_vars(self):
         with self.assertRaises(TypeError):
@@ -550,10 +549,16 @@ def test_many_weakrefs(self):
             with self.subTest(cls=cls):
                 vals = weakref.WeakValueDictionary()
 
-                for x in range(100000):
+                for x in range(10):
                     vals[x] = cls(str(x))
                 del vals
 
+    def test_constructor(self):
+        T = TypeVar(name="T")
+        self.assertEqual(T.__name__, "T")
+        self.assertEqual(T.__constraints__, ())
+        self.assertIs(T.__bound__, None)
+
 
 def template_replace(templates: list[str], replacements: dict[str, list[str]]) -> list[tuple[str]]:
     """Renders templates with possible combinations of replacements.
@@ -1244,20 +1249,20 @@ class C(TypeVarTuple): pass
         Ts = TypeVarTuple('Ts')
         with self.assertRaisesRegex(TypeError,
                 CANNOT_SUBCLASS_INSTANCE % 'TypeVarTuple'):
-            class C(Ts): pass
+            class D(Ts): pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(Unpack)): pass
+            class E(type(Unpack)): pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(*Ts)): pass
+            class F(type(*Ts)): pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(Unpack[Ts])): pass
+            class G(type(Unpack[Ts])): pass
         with self.assertRaisesRegex(TypeError,
                                     r'Cannot subclass typing\.Unpack'):
-            class C(Unpack): pass
+            class H(Unpack): pass
         with self.assertRaisesRegex(TypeError, r'Cannot subclass typing.Unpack\[Ts\]'):
-            class C(*Ts): pass
+            class I(*Ts): pass
         with self.assertRaisesRegex(TypeError, r'Cannot subclass typing.Unpack\[Ts\]'):
-            class C(Unpack[Ts]): pass
+            class J(Unpack[Ts]): pass
 
     def test_variadic_class_args_are_correct(self):
         T = TypeVar('T')
@@ -1431,12 +1436,12 @@ def test_variadic_class_with_duplicate_typevartuples_fails(self):
         with self.assertRaises(TypeError):
             class C(Generic[*Ts1, *Ts1]): pass
         with self.assertRaises(TypeError):
-            class C(Generic[Unpack[Ts1], Unpack[Ts1]]): pass
+            class D(Generic[Unpack[Ts1], Unpack[Ts1]]): pass
 
         with self.assertRaises(TypeError):
-            class C(Generic[*Ts1, *Ts2, *Ts1]): pass
+            class E(Generic[*Ts1, *Ts2, *Ts1]): pass
         with self.assertRaises(TypeError):
-            class C(Generic[Unpack[Ts1], Unpack[Ts2], Unpack[Ts1]]): pass
+            class F(Generic[Unpack[Ts1], Unpack[Ts2], Unpack[Ts1]]): pass
 
     def test_type_concatenation_in_variadic_class_argument_list_succeeds(self):
         Ts = TypeVarTuple('Ts')
@@ -1804,11 +1809,11 @@ def test_cannot_subclass(self):
             class C(Union):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(Union)):
+            class D(type(Union)):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.Union\[int, str\]'):
-            class C(Union[int, str]):
+            class E(Union[int, str]):
                 pass
 
     def test_cannot_instantiate(self):
@@ -2005,13 +2010,13 @@ def test_callable_instance_type_error(self):
         def f():
             pass
         with self.assertRaises(TypeError):
-            self.assertIsInstance(f, Callable[[], None])
+            isinstance(f, Callable[[], None])
         with self.assertRaises(TypeError):
-            self.assertIsInstance(f, Callable[[], Any])
+            isinstance(f, Callable[[], Any])
         with self.assertRaises(TypeError):
-            self.assertNotIsInstance(None, Callable[[], None])
+            isinstance(None, Callable[[], None])
         with self.assertRaises(TypeError):
-            self.assertNotIsInstance(None, Callable[[], Any])
+            isinstance(None, Callable[[], Any])
 
     def test_repr(self):
         Callable = self.Callable
@@ -2557,10 +2562,10 @@ class BP(Protocol): pass
             class P(C, Protocol):
                 pass
         with self.assertRaises(TypeError):
-            class P(Protocol, C):
+            class Q(Protocol, C):
                 pass
         with self.assertRaises(TypeError):
-            class P(BP, C, Protocol):
+            class R(BP, C, Protocol):
                 pass
 
         class D(BP, C): pass
@@ -2836,7 +2841,7 @@ class NotAProtocolButAnImplicitSubclass3:
             meth: Callable[[], None]
             meth2: Callable[[int, str], bool]
             def meth(self): pass
-            def meth(self, x, y): return True
+            def meth2(self, x, y): return True
 
         self.assertNotIsSubclass(AnnotatedButNotAProtocol, CallableMembersProto)
         self.assertIsSubclass(NotAProtocolButAnImplicitSubclass, CallableMembersProto)
@@ -3646,11 +3651,11 @@ def test_protocols_bad_subscripts(self):
         with self.assertRaises(TypeError):
             class P(Protocol[T, T]): pass
         with self.assertRaises(TypeError):
-            class P(Protocol[int]): pass
+            class Q(Protocol[int]): pass
         with self.assertRaises(TypeError):
-            class P(Protocol[T], Protocol[S]): pass
+            class R(Protocol[T], Protocol[S]): pass
         with self.assertRaises(TypeError):
-            class P(typing.Mapping[T, S], Protocol[T]): pass
+            class S(typing.Mapping[T, S], Protocol[T]): pass
 
     def test_generic_protocols_repr(self):
         T = TypeVar('T')
@@ -4029,12 +4034,12 @@ class NewGeneric(Generic): ...
         with self.assertRaises(TypeError):
             class MyGeneric(Generic[T], Generic[S]): ...
         with self.assertRaises(TypeError):
-            class MyGeneric(List[T], Generic[S]): ...
+            class MyGeneric2(List[T], Generic[S]): ...
         with self.assertRaises(TypeError):
             Generic[()]
-        class C(Generic[T]): pass
+        class D(Generic[T]): pass
         with self.assertRaises(TypeError):
-            C[()]
+            D[()]
 
     def test_init(self):
         T = TypeVar('T')
@@ -4755,7 +4760,7 @@ class Test(Generic[T], Final):
             class Subclass(Test):
                 pass
         with self.assertRaises(FinalException):
-            class Subclass(Test[int]):
+            class Subclass2(Test[int]):
                 pass
 
     def test_nested(self):
@@ -4993,15 +4998,15 @@ def test_cannot_subclass(self):
             class C(type(ClassVar)):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(ClassVar[int])):
+            class D(type(ClassVar[int])):
                 pass
         with self.assertRaisesRegex(TypeError,
                                     r'Cannot subclass typing\.ClassVar'):
-            class C(ClassVar):
+            class E(ClassVar):
                 pass
         with self.assertRaisesRegex(TypeError,
                                     r'Cannot subclass typing\.ClassVar\[int\]'):
-            class C(ClassVar[int]):
+            class F(ClassVar[int]):
                 pass
 
     def test_cannot_init(self):
@@ -5043,15 +5048,15 @@ def test_cannot_subclass(self):
             class C(type(Final)):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(Final[int])):
+            class D(type(Final[int])):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.Final'):
-            class C(Final):
+            class E(Final):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.Final\[int\]'):
-            class C(Final[int]):
+            class F(Final[int]):
                 pass
 
     def test_cannot_init(self):
@@ -5306,7 +5311,7 @@ def test_errors(self):
 
 
 # We need this to make sure that `@no_type_check` respects `__module__` attr:
-from test import ann_module8
+from test.typinganndata import ann_module8
 
 @no_type_check
 class NoTypeCheck_Outer:
@@ -5893,7 +5898,9 @@ def test_overload_registry_repeated(self):
 
 # Definitions needed for features introduced in Python 3.6
 
-from test import ann_module, ann_module2, ann_module3, ann_module5, ann_module6
+from test.typinganndata import (
+    ann_module, ann_module2, ann_module3, ann_module5, ann_module6,
+)
 
 T_a = TypeVar('T_a')
 
@@ -7178,15 +7185,15 @@ class A:
             class X(NamedTuple, A):
                 x: int
         with self.assertRaises(TypeError):
-            class X(NamedTuple, tuple):
+            class Y(NamedTuple, tuple):
                 x: int
         with self.assertRaises(TypeError):
-            class X(NamedTuple, NamedTuple):
+            class Z(NamedTuple, NamedTuple):
                 x: int
-        class A(NamedTuple):
+        class B(NamedTuple):
             x: int
         with self.assertRaises(TypeError):
-            class X(NamedTuple, A):
+            class C(NamedTuple, B):
                 y: str
 
     def test_generic(self):
@@ -7867,15 +7874,15 @@ def test_cannot_subclass(self):
             class C(type(Required)):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(Required[int])):
+            class D(type(Required[int])):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.Required'):
-            class C(Required):
+            class E(Required):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.Required\[int\]'):
-            class C(Required[int]):
+            class F(Required[int]):
                 pass
 
     def test_cannot_init(self):
@@ -7915,15 +7922,15 @@ def test_cannot_subclass(self):
             class C(type(NotRequired)):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(NotRequired[int])):
+            class D(type(NotRequired[int])):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.NotRequired'):
-            class C(NotRequired):
+            class E(NotRequired):
                 pass
         with self.assertRaisesRegex(TypeError,
                 r'Cannot subclass typing\.NotRequired\[int\]'):
-            class C(NotRequired[int]):
+            class F(NotRequired[int]):
                 pass
 
     def test_cannot_init(self):
@@ -8043,7 +8050,7 @@ class A(typing.Match):
             TypeError,
             r"type 're\.Pattern' is not an acceptable base type",
         ):
-            class A(typing.Pattern):
+            class B(typing.Pattern):
                 pass
 
 
@@ -8391,7 +8398,7 @@ class C(TypeAlias):
                 pass
 
         with self.assertRaises(TypeError):
-            class C(type(TypeAlias)):
+            class D(type(TypeAlias)):
                 pass
 
     def test_repr(self):
@@ -8781,19 +8788,19 @@ def test_cannot_subclass(self):
         with self.assertRaisesRegex(TypeError, NOT_A_BASE_TYPE % 'ParamSpec'):
             class C(ParamSpec): pass
         with self.assertRaisesRegex(TypeError, NOT_A_BASE_TYPE % 'ParamSpecArgs'):
-            class C(ParamSpecArgs): pass
+            class D(ParamSpecArgs): pass
         with self.assertRaisesRegex(TypeError, NOT_A_BASE_TYPE % 'ParamSpecKwargs'):
-            class C(ParamSpecKwargs): pass
+            class E(ParamSpecKwargs): pass
         P = ParamSpec('P')
         with self.assertRaisesRegex(TypeError,
                 CANNOT_SUBCLASS_INSTANCE % 'ParamSpec'):
-            class C(P): pass
+            class F(P): pass
         with self.assertRaisesRegex(TypeError,
                 CANNOT_SUBCLASS_INSTANCE % 'ParamSpecArgs'):
-            class C(P.args): pass
+            class G(P.args): pass
         with self.assertRaisesRegex(TypeError,
                 CANNOT_SUBCLASS_INSTANCE % 'ParamSpecKwargs'):
-            class C(P.kwargs): pass
+            class H(P.kwargs): pass
 
 
 class ConcatenateTests(BaseTestCase):
@@ -8874,15 +8881,15 @@ def test_cannot_subclass(self):
             class C(type(TypeGuard)):
                 pass
         with self.assertRaisesRegex(TypeError, CANNOT_SUBCLASS_TYPE):
-            class C(type(TypeGuard[int])):
+            class D(type(TypeGuard[int])):
                 pass
         with self.assertRaisesRegex(TypeError,
                                     r'Cannot subclass typing\.TypeGuard'):
-            class C(TypeGuard):
+            class E(TypeGuard):
                 pass
         with self.assertRaisesRegex(TypeError,
                                     r'Cannot subclass typing\.TypeGuard\[int\]'):
-            class C(TypeGuard[int]):
+            class F(TypeGuard[int]):
                 pass
 
     def test_cannot_init(self):
diff --git a/Lib/test/test_unicode_identifiers.py b/Lib/test/test_unicode_identifiers.py
index 5b9ced5d1c..63c6c05582 100644
--- a/Lib/test/test_unicode_identifiers.py
+++ b/Lib/test/test_unicode_identifiers.py
@@ -19,7 +19,7 @@ def test_non_bmp_normalized(self):
 
     def test_invalid(self):
         try:
-            from test import badsyntax_3131
+            from test.tokenizedata import badsyntax_3131
         except SyntaxError as err:
             self.assertEqual(str(err),
               "invalid character '€' (U+20AC) (badsyntax_3131.py, line 2)")
diff --git a/Lib/test/test_unittest/test_discovery.py b/Lib/test/test_unittest/test_discovery.py
index 004898ed43..dcb72d73ef 100644
--- a/Lib/test/test_unittest/test_discovery.py
+++ b/Lib/test/test_unittest/test_discovery.py
@@ -571,7 +571,7 @@ def _get_module_from_name(name):
         result = unittest.TestResult()
         suite.run(result)
         self.assertEqual(len(result.skipped), 1)
-        self.assertEqual(result.testsRun, 1)
+        self.assertEqual(result.testsRun, 0)
         self.assertEqual(import_calls, ['my_package'])
 
         # Check picklability
diff --git a/Lib/test/test_unittest/test_loader.py b/Lib/test/test_unittest/test_loader.py
index a203145a79..9fc0d95816 100644
--- a/Lib/test/test_unittest/test_loader.py
+++ b/Lib/test/test_unittest/test_loader.py
@@ -82,6 +82,22 @@ def runTest(self):
         self.assertIsInstance(suite, loader.suiteClass)
         self.assertEqual(list(suite), [Foo('runTest')])
 
+    # "Do not load any tests from `TestCase` class itself."
+    def test_loadTestsFromTestCase__from_TestCase(self):
+        loader = unittest.TestLoader()
+
+        suite = loader.loadTestsFromTestCase(unittest.TestCase)
+        self.assertIsInstance(suite, loader.suiteClass)
+        self.assertEqual(list(suite), [])
+
+    # "Do not load any tests from `FunctionTestCase` class."
+    def test_loadTestsFromTestCase__from_FunctionTestCase(self):
+        loader = unittest.TestLoader()
+
+        suite = loader.loadTestsFromTestCase(unittest.FunctionTestCase)
+        self.assertIsInstance(suite, loader.suiteClass)
+        self.assertEqual(list(suite), [])
+
     ################################################################
     ### /Tests for TestLoader.loadTestsFromTestCase
 
@@ -103,6 +119,19 @@ def test(self):
         expected = [loader.suiteClass([MyTestCase('test')])]
         self.assertEqual(list(suite), expected)
 
+    # "This test ensures that internal `TestCase` subclasses are not loaded"
+    def test_loadTestsFromModule__TestCase_subclass_internals(self):
+        # See https://github.com/python/cpython/issues/84867
+        m = types.ModuleType('m')
+        # Simulate imported names:
+        m.TestCase = unittest.TestCase
+        m.FunctionTestCase = unittest.FunctionTestCase
+
+        loader = unittest.TestLoader()
+        suite = loader.loadTestsFromModule(m)
+        self.assertIsInstance(suite, loader.suiteClass)
+        self.assertEqual(list(suite), [])
+
     # "This method searches `module` for classes derived from TestCase"
     #
     # What happens if no tests are found (no TestCase instances)?
diff --git a/Lib/test/test_unittest/test_skipping.py b/Lib/test/test_unittest/test_skipping.py
index f146dcac18..1a6af06d32 100644
--- a/Lib/test/test_unittest/test_skipping.py
+++ b/Lib/test/test_unittest/test_skipping.py
@@ -103,16 +103,16 @@ def test_dont_skip(self): pass
             result = LoggingResult(events)
             self.assertIs(suite.run(result), result)
             self.assertEqual(len(result.skipped), 1)
-            expected = ['startTest', 'addSkip', 'stopTest',
-                        'startTest', 'addSuccess', 'stopTest']
+            expected = ['addSkip', 'stopTest', 'startTest',
+                        'addSuccess', 'stopTest']
             self.assertEqual(events, expected)
-            self.assertEqual(result.testsRun, 2)
+            self.assertEqual(result.testsRun, 1)
             self.assertEqual(result.skipped, [(test_do_skip, "testing")])
             self.assertTrue(result.wasSuccessful())
 
             events = []
             result = test_do_skip.run()
-            self.assertEqual(events, ['startTestRun', 'startTest', 'addSkip',
+            self.assertEqual(events, ['startTestRun', 'addSkip',
                                       'stopTest', 'stopTestRun'])
             self.assertEqual(result.skipped, [(test_do_skip, "testing")])
 
@@ -135,13 +135,13 @@ def test_1(self):
         test = Foo("test_1")
         suite = unittest.TestSuite([test])
         self.assertIs(suite.run(result), result)
-        self.assertEqual(events, ['startTest', 'addSkip', 'stopTest'])
+        self.assertEqual(events, ['addSkip', 'stopTest'])
         self.assertEqual(result.skipped, [(test, "testing")])
         self.assertEqual(record, [])
 
         events = []
         result = test.run()
-        self.assertEqual(events, ['startTestRun', 'startTest', 'addSkip',
+        self.assertEqual(events, ['startTestRun', 'addSkip',
                                   'stopTest', 'stopTestRun'])
         self.assertEqual(result.skipped, [(test, "testing")])
         self.assertEqual(record, [])
diff --git a/Lib/test/test_unittest/testmock/testmock.py b/Lib/test/test_unittest/testmock/testmock.py
index d1cae47a40..34d76ba0ad 100644
--- a/Lib/test/test_unittest/testmock/testmock.py
+++ b/Lib/test/test_unittest/testmock/testmock.py
@@ -1039,7 +1039,7 @@ def test_assert_called_with_failure_message(self):
 
         actual = 'not called.'
         expected = "mock(1, '2', 3, bar='foo')"
-        message = 'expected call not found.\nExpected: %s\nActual: %s'
+        message = 'expected call not found.\nExpected: %s\n  Actual: %s'
         self.assertRaisesWithMsg(
             AssertionError, message % (expected, actual),
             mock.assert_called_with, 1, '2', 3, bar='foo'
@@ -1054,7 +1054,7 @@ def test_assert_called_with_failure_message(self):
         for meth in asserters:
             actual = "foo(1, '2', 3, foo='foo')"
             expected = "foo(1, '2', 3, bar='foo')"
-            message = 'expected call not found.\nExpected: %s\nActual: %s'
+            message = 'expected call not found.\nExpected: %s\n  Actual: %s'
             self.assertRaisesWithMsg(
                 AssertionError, message % (expected, actual),
                 meth, 1, '2', 3, bar='foo'
@@ -1064,7 +1064,7 @@ def test_assert_called_with_failure_message(self):
         for meth in asserters:
             actual = "foo(1, '2', 3, foo='foo')"
             expected = "foo(bar='foo')"
-            message = 'expected call not found.\nExpected: %s\nActual: %s'
+            message = 'expected call not found.\nExpected: %s\n  Actual: %s'
             self.assertRaisesWithMsg(
                 AssertionError, message % (expected, actual),
                 meth, bar='foo'
@@ -1074,7 +1074,7 @@ def test_assert_called_with_failure_message(self):
         for meth in asserters:
             actual = "foo(1, '2', 3, foo='foo')"
             expected = "foo(1, 2, 3)"
-            message = 'expected call not found.\nExpected: %s\nActual: %s'
+            message = 'expected call not found.\nExpected: %s\n  Actual: %s'
             self.assertRaisesWithMsg(
                 AssertionError, message % (expected, actual),
                 meth, 1, 2, 3
@@ -1084,7 +1084,7 @@ def test_assert_called_with_failure_message(self):
         for meth in asserters:
             actual = "foo(1, '2', 3, foo='foo')"
             expected = "foo()"
-            message = 'expected call not found.\nExpected: %s\nActual: %s'
+            message = 'expected call not found.\nExpected: %s\n  Actual: %s'
             self.assertRaisesWithMsg(
                 AssertionError, message % (expected, actual), meth
             )
@@ -1533,7 +1533,7 @@ def f(x=None): pass
                 '^{}$'.format(
                     re.escape('Calls not found.\n'
                               'Expected: [call()]\n'
-                              'Actual: [call(1)]'))) as cm:
+                              '  Actual: [call(1)]'))) as cm:
             mock.assert_has_calls([call()])
         self.assertIsNone(cm.exception.__cause__)
 
@@ -1545,7 +1545,7 @@ def f(x=None): pass
                         'Error processing expected calls.\n'
                         "Errors: [None, TypeError('too many positional arguments')]\n"
                         "Expected: [call(), call(1, 2)]\n"
-                        'Actual: [call(1)]'))) as cm:
+                        '  Actual: [call(1)]'))) as cm:
             mock.assert_has_calls([call(), call(1, 2)])
         self.assertIsInstance(cm.exception.__cause__, TypeError)
 
diff --git a/Lib/test/test_unpack.py b/Lib/test/test_unpack.py
index f5ca1d455b..515ec128a0 100644
--- a/Lib/test/test_unpack.py
+++ b/Lib/test/test_unpack.py
@@ -162,7 +162,7 @@ def test_extended_oparg_not_ignored(self):
         ns = {}
         exec(code, ns)
         unpack_400 = ns["unpack_400"]
-        # Warm up the the function for quickening (PEP 659)
+        # Warm up the function for quickening (PEP 659)
         for _ in range(30):
             y = unpack_400(range(400))
             self.assertEqual(y, 399)
diff --git a/Lib/test/test_unparse.py b/Lib/test/test_unparse.py
index bdf7b0588b..6f698a8d89 100644
--- a/Lib/test/test_unparse.py
+++ b/Lib/test/test_unparse.py
@@ -730,7 +730,8 @@ class DirectoryTestCase(ASTTestCase):
     test_directories = (lib_dir, lib_dir / "test")
     run_always_files = {"test_grammar.py", "test_syntax.py", "test_compile.py",
                         "test_ast.py", "test_asdl_parser.py", "test_fstring.py",
-                        "test_patma.py", "test_type_alias.py", "test_type_params.py"}
+                        "test_patma.py", "test_type_alias.py", "test_type_params.py",
+                        "test_tokenize.py"}
 
     _files_to_test = None
 
diff --git a/Lib/test/test_urllib2_localnet.py b/Lib/test/test_urllib2_localnet.py
index f472935855..96e43970d4 100644
--- a/Lib/test/test_urllib2_localnet.py
+++ b/Lib/test/test_urllib2_localnet.py
@@ -22,9 +22,9 @@
 
 here = os.path.dirname(__file__)
 # Self-signed cert file for 'localhost'
-CERT_localhost = os.path.join(here, 'keycert.pem')
+CERT_localhost = os.path.join(here, 'certdata', 'keycert.pem')
 # Self-signed cert file for 'fakehostname'
-CERT_fakehostname = os.path.join(here, 'keycert2.pem')
+CERT_fakehostname = os.path.join(here, 'certdata', 'keycert2.pem')
 
 
 # Loopback http server infrastructure
diff --git a/Lib/test/test_utf8_mode.py b/Lib/test/test_utf8_mode.py
index ec29ba6d51..f66881044e 100644
--- a/Lib/test/test_utf8_mode.py
+++ b/Lib/test/test_utf8_mode.py
@@ -9,10 +9,9 @@
 import unittest
 from test import support
 from test.support.script_helper import assert_python_ok, assert_python_failure
-from test.support import os_helper
+from test.support import os_helper, MS_WINDOWS
 
 
-MS_WINDOWS = (sys.platform == 'win32')
 POSIX_LOCALES = ('C', 'POSIX')
 VXWORKS = (sys.platform == "vxworks")
 
diff --git a/Lib/test/test_venv.py b/Lib/test/test_venv.py
index aa6a8fbf8c..fea16568af 100644
--- a/Lib/test/test_venv.py
+++ b/Lib/test/test_venv.py
@@ -21,7 +21,7 @@
                           skip_if_broken_multiprocessing_synchronize, verbose,
                           requires_subprocess, is_emscripten, is_wasi,
                           requires_venv_with_pip, TEST_HOME_DIR,
-                          requires_resource)
+                          requires_resource, copy_python_src_ignore)
 from test.support.os_helper import (can_symlink, EnvironmentVarGuard, rmtree)
 import unittest
 import venv
@@ -561,6 +561,7 @@ def test_zippath_from_non_installed_posix(self):
                                     platlibdir,
                                     stdlib_zip)
         additional_pythonpath_for_non_installed = []
+
         # Copy stdlib files to the non-installed python so venv can
         # correctly calculate the prefix.
         for eachpath in sys.path:
@@ -570,14 +571,19 @@ def test_zippath_from_non_installed_posix(self):
                         eachpath,
                         os.path.join(non_installed_dir, platlibdir))
             elif os.path.isfile(os.path.join(eachpath, "os.py")):
-                for name in os.listdir(eachpath):
+                names = os.listdir(eachpath)
+                ignored_names = copy_python_src_ignore(eachpath, names)
+                for name in names:
+                    if name in ignored_names:
+                        continue
                     if name == "site-packages":
                         continue
                     fn = os.path.join(eachpath, name)
                     if os.path.isfile(fn):
                         shutil.copy(fn, libdir)
                     elif os.path.isdir(fn):
-                        shutil.copytree(fn, os.path.join(libdir, name))
+                        shutil.copytree(fn, os.path.join(libdir, name),
+                                        ignore=copy_python_src_ignore)
             else:
                 additional_pythonpath_for_non_installed.append(
                     eachpath)
diff --git a/Lib/test/test_zipfile/test_core.py b/Lib/test/test_zipfile/test_core.py
index 9960259c4c..d8a83d4dbb 100644
--- a/Lib/test/test_zipfile/test_core.py
+++ b/Lib/test/test_zipfile/test_core.py
@@ -1769,13 +1769,9 @@ def test_write_unicode_filenames(self):
             self.assertEqual(zf.filelist[0].filename, "foo.txt")
             self.assertEqual(zf.filelist[1].filename, "\xf6.txt")
 
-    @requires_zlib()
-    def test_read_zipfile_containing_unicode_path_extra_field(self):
+    def create_zipfile_with_extra_data(self, filename, extra_data_name):
         with zipfile.ZipFile(TESTFN, mode='w') as zf:
-            # create a file with a non-ASCII name
-            filename = '이름.txt'
-            filename_encoded = filename.encode('utf-8')
-
+            filename_encoded = filename.encode("utf-8")
             # create a ZipInfo object with Unicode path extra field
             zip_info = zipfile.ZipInfo(filename)
 
@@ -1785,7 +1781,7 @@ def test_read_zipfile_containing_unicode_path_extra_field(self):
             import zlib
             filename_crc = struct.pack('<L', zlib.crc32(filename_encoded))
 
-            extra_data = version_of_unicode_path + filename_crc + filename_encoded
+            extra_data = version_of_unicode_path + filename_crc + extra_data_name
             tsize = len(extra_data).to_bytes(2, 'little')
 
             zip_info.extra = tag_for_unicode_path + tsize + extra_data
@@ -1793,9 +1789,24 @@ def test_read_zipfile_containing_unicode_path_extra_field(self):
             # add the file to the ZIP archive
             zf.writestr(zip_info, b'Hello World!')
 
+    @requires_zlib()
+    def test_read_zipfile_containing_unicode_path_extra_field(self):
+        self.create_zipfile_with_extra_data("이름.txt", "이름.txt".encode("utf-8"))
         with zipfile.ZipFile(TESTFN, "r") as zf:
             self.assertEqual(zf.filelist[0].filename, "이름.txt")
 
+    @requires_zlib()
+    def test_read_zipfile_warning(self):
+        self.create_zipfile_with_extra_data("이름.txt", b"")
+        with self.assertWarns(UserWarning):
+            zipfile.ZipFile(TESTFN, "r").close()
+
+    @requires_zlib()
+    def test_read_zipfile_error(self):
+        self.create_zipfile_with_extra_data("이름.txt", b"\xff")
+        with self.assertRaises(zipfile.BadZipfile):
+            zipfile.ZipFile(TESTFN, "r").close()
+
     def test_read_after_write_unicode_filenames(self):
         with zipfile.ZipFile(TESTFN2, 'w') as zipfp:
             zipfp.writestr('приклад', b'sample')
@@ -2235,6 +2246,22 @@ def test_seek_tell(self):
                 fp.seek(0, os.SEEK_SET)
                 self.assertEqual(fp.tell(), 0)
 
+    def test_read_after_seek(self):
+        # Issue 102956: Make sure seek(x, os.SEEK_CUR) doesn't break read()
+        txt = b"Charge men!"
+        bloc = txt.find(b"men")
+        with zipfile.ZipFile(TESTFN, "w") as zipf:
+            zipf.writestr("foo.txt", txt)
+        with zipfile.ZipFile(TESTFN, mode="r") as zipf:
+            with zipf.open("foo.txt", "r") as fp:
+                fp.seek(bloc, os.SEEK_CUR)
+                self.assertEqual(fp.read(-1), b'men!')
+        with zipfile.ZipFile(TESTFN, mode="r") as zipf:
+            with zipf.open("foo.txt", "r") as fp:
+                fp.read(6)
+                fp.seek(1, os.SEEK_CUR)
+                self.assertEqual(fp.read(-1), b'men!')
+
     @requires_bz2()
     def test_decompress_without_3rd_party_library(self):
         data = b'PK\x05\x06\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
diff --git a/Lib/test/test_zlib.py b/Lib/test/test_zlib.py
index 55306c63cd..cc6446c948 100644
--- a/Lib/test/test_zlib.py
+++ b/Lib/test/test_zlib.py
@@ -513,18 +513,7 @@ def test_odd_flush(self):
 
         # Try 17K of data
         # generate random data stream
-        try:
-            # In 2.3 and later, WichmannHill is the RNG of the bug report
-            gen = random.WichmannHill()
-        except AttributeError:
-            try:
-                # 2.2 called it Random
-                gen = random.Random()
-            except AttributeError:
-                # others might simply have a single RNG
-                gen = random
-        gen.seed(1)
-        data = gen.randbytes(17 * 1024)
+        data = random.randbytes(17 * 1024)
 
         # compress, sync-flush, and decompress
         first = co.compress(data)
diff --git a/Lib/test/test_zoneinfo/test_zoneinfo.py b/Lib/test/test_zoneinfo/test_zoneinfo.py
index ae921f7432..3766ceac83 100644
--- a/Lib/test/test_zoneinfo/test_zoneinfo.py
+++ b/Lib/test/test_zoneinfo/test_zoneinfo.py
@@ -1001,6 +1001,80 @@ def test_tzstr_from_utc(self):
 
                 self.assertEqual(dt_act, dt_utc)
 
+    def test_extreme_tzstr(self):
+        tzstrs = [
+            # Extreme offset hour
+            "AAA24",
+            "AAA+24",
+            "AAA-24",
+            "AAA24BBB,J60/2,J300/2",
+            "AAA+24BBB,J60/2,J300/2",
+            "AAA-24BBB,J60/2,J300/2",
+            "AAA4BBB24,J60/2,J300/2",
+            "AAA4BBB+24,J60/2,J300/2",
+            "AAA4BBB-24,J60/2,J300/2",
+            # Extreme offset minutes
+            "AAA4:00BBB,J60/2,J300/2",
+            "AAA4:59BBB,J60/2,J300/2",
+            "AAA4BBB5:00,J60/2,J300/2",
+            "AAA4BBB5:59,J60/2,J300/2",
+            # Extreme offset seconds
+            "AAA4:00:00BBB,J60/2,J300/2",
+            "AAA4:00:59BBB,J60/2,J300/2",
+            "AAA4BBB5:00:00,J60/2,J300/2",
+            "AAA4BBB5:00:59,J60/2,J300/2",
+            # Extreme total offset
+            "AAA24:59:59BBB5,J60/2,J300/2",
+            "AAA-24:59:59BBB5,J60/2,J300/2",
+            "AAA4BBB24:59:59,J60/2,J300/2",
+            "AAA4BBB-24:59:59,J60/2,J300/2",
+            # Extreme months
+            "AAA4BBB,M12.1.1/2,M1.1.1/2",
+            "AAA4BBB,M1.1.1/2,M12.1.1/2",
+            # Extreme weeks
+            "AAA4BBB,M1.5.1/2,M1.1.1/2",
+            "AAA4BBB,M1.1.1/2,M1.5.1/2",
+            # Extreme weekday
+            "AAA4BBB,M1.1.6/2,M2.1.1/2",
+            "AAA4BBB,M1.1.1/2,M2.1.6/2",
+            # Extreme numeric offset
+            "AAA4BBB,0/2,20/2",
+            "AAA4BBB,0/2,0/14",
+            "AAA4BBB,20/2,365/2",
+            "AAA4BBB,365/2,365/14",
+            # Extreme julian offset
+            "AAA4BBB,J1/2,J20/2",
+            "AAA4BBB,J1/2,J1/14",
+            "AAA4BBB,J20/2,J365/2",
+            "AAA4BBB,J365/2,J365/14",
+            # Extreme transition hour
+            "AAA4BBB,J60/167,J300/2",
+            "AAA4BBB,J60/+167,J300/2",
+            "AAA4BBB,J60/-167,J300/2",
+            "AAA4BBB,J60/2,J300/167",
+            "AAA4BBB,J60/2,J300/+167",
+            "AAA4BBB,J60/2,J300/-167",
+            # Extreme transition minutes
+            "AAA4BBB,J60/2:00,J300/2",
+            "AAA4BBB,J60/2:59,J300/2",
+            "AAA4BBB,J60/2,J300/2:00",
+            "AAA4BBB,J60/2,J300/2:59",
+            # Extreme transition seconds
+            "AAA4BBB,J60/2:00:00,J300/2",
+            "AAA4BBB,J60/2:00:59,J300/2",
+            "AAA4BBB,J60/2,J300/2:00:00",
+            "AAA4BBB,J60/2,J300/2:00:59",
+            # Extreme total transition time
+            "AAA4BBB,J60/167:59:59,J300/2",
+            "AAA4BBB,J60/-167:59:59,J300/2",
+            "AAA4BBB,J60/2,J300/167:59:59",
+            "AAA4BBB,J60/2,J300/-167:59:59",
+        ]
+
+        for tzstr in tzstrs:
+            with self.subTest(tzstr=tzstr):
+                self.zone_from_tzstr(tzstr)
+
     def test_invalid_tzstr(self):
         invalid_tzstrs = [
             "PST8PDT",  # DST but no transition specified
@@ -1008,16 +1082,33 @@ def test_invalid_tzstr(self):
             "GMT,M3.2.0/2,M11.1.0/3",  # Transition rule but no DST
             "GMT0+11,M3.2.0/2,M11.1.0/3",  # Unquoted alphanumeric in DST
             "PST8PDT,M3.2.0/2",  # Only one transition rule
-            # Invalid offsets
-            "STD+25",
-            "STD-25",
-            "STD+374",
-            "STD+374DST,M3.2.0/2,M11.1.0/3",
-            "STD+23DST+25,M3.2.0/2,M11.1.0/3",
-            "STD-23DST-25,M3.2.0/2,M11.1.0/3",
+            # Invalid offset hours
+            "AAA168",
+            "AAA+168",
+            "AAA-168",
+            "AAA168BBB,J60/2,J300/2",
+            "AAA+168BBB,J60/2,J300/2",
+            "AAA-168BBB,J60/2,J300/2",
+            "AAA4BBB168,J60/2,J300/2",
+            "AAA4BBB+168,J60/2,J300/2",
+            "AAA4BBB-168,J60/2,J300/2",
+            # Invalid offset minutes
+            "AAA4:0BBB,J60/2,J300/2",
+            "AAA4:100BBB,J60/2,J300/2",
+            "AAA4BBB5:0,J60/2,J300/2",
+            "AAA4BBB5:100,J60/2,J300/2",
+            # Invalid offset seconds
+            "AAA4:00:0BBB,J60/2,J300/2",
+            "AAA4:00:100BBB,J60/2,J300/2",
+            "AAA4BBB5:00:0,J60/2,J300/2",
+            "AAA4BBB5:00:100,J60/2,J300/2",
             # Completely invalid dates
             "AAA4BBB,M1443339,M11.1.0/3",
             "AAA4BBB,M3.2.0/2,0349309483959c",
+            "AAA4BBB,,J300/2",
+            "AAA4BBB,z,J300/2",
+            "AAA4BBB,J60/2,",
+            "AAA4BBB,J60/2,z",
             # Invalid months
             "AAA4BBB,M13.1.1/2,M1.1.1/2",
             "AAA4BBB,M1.1.1/2,M13.1.1/2",
@@ -1037,6 +1128,26 @@ def test_invalid_tzstr(self):
             # Invalid julian offset
             "AAA4BBB,J0/2,J20/2",
             "AAA4BBB,J20/2,J366/2",
+            # Invalid transition time
+            "AAA4BBB,J60/2/3,J300/2",
+            "AAA4BBB,J60/2,J300/2/3",
+            # Invalid transition hour
+            "AAA4BBB,J60/168,J300/2",
+            "AAA4BBB,J60/+168,J300/2",
+            "AAA4BBB,J60/-168,J300/2",
+            "AAA4BBB,J60/2,J300/168",
+            "AAA4BBB,J60/2,J300/+168",
+            "AAA4BBB,J60/2,J300/-168",
+            # Invalid transition minutes
+            "AAA4BBB,J60/2:0,J300/2",
+            "AAA4BBB,J60/2:100,J300/2",
+            "AAA4BBB,J60/2,J300/2:0",
+            "AAA4BBB,J60/2,J300/2:100",
+            # Invalid transition seconds
+            "AAA4BBB,J60/2:00:0,J300/2",
+            "AAA4BBB,J60/2:00:100,J300/2",
+            "AAA4BBB,J60/2,J300/2:00:0",
+            "AAA4BBB,J60/2,J300/2:00:100",
         ]
 
         for invalid_tzstr in invalid_tzstrs:
diff --git a/Lib/test/tokenize_tests-latin1-coding-cookie-and-utf8-bom-sig.txt b/Lib/test/tokenize_tests-latin1-coding-cookie-and-utf8-bom-sig.txt
deleted file mode 100644
index 1b5335b64e..0000000000
--- a/Lib/test/tokenize_tests-latin1-coding-cookie-and-utf8-bom-sig.txt
+++ /dev/null
@@ -1,13 +0,0 @@
-﻿# -*- coding: latin1 -*-
-# IMPORTANT: this file has the utf-8 BOM signature '\xef\xbb\xbf'
-# at the start of it.  Make sure this is preserved if any changes
-# are made!  Also note that the coding cookie above conflicts with
-# the presence of a utf-8 BOM signature -- this is intended.
-
-# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
-x = 'ЉЊЈЁЂ'
-def y():
-    """
-    And again in a comment.  ЉЊЈЁЂ
-    """
-    pass
diff --git a/Lib/test/tokenize_tests-no-coding-cookie-and-utf8-bom-sig-only.txt b/Lib/test/tokenize_tests-no-coding-cookie-and-utf8-bom-sig-only.txt
deleted file mode 100644
index 23fd2168ae..0000000000
--- a/Lib/test/tokenize_tests-no-coding-cookie-and-utf8-bom-sig-only.txt
+++ /dev/null
@@ -1,11 +0,0 @@
-﻿# IMPORTANT: this file has the utf-8 BOM signature '\xef\xbb\xbf'
-# at the start of it.  Make sure this is preserved if any changes
-# are made!
-
-# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
-x = 'ЉЊЈЁЂ'
-def y():
-    """
-    And again in a comment.  ЉЊЈЁЂ
-    """
-    pass
diff --git a/Lib/test/tokenize_tests-utf8-coding-cookie-and-no-utf8-bom-sig.txt b/Lib/test/tokenize_tests-utf8-coding-cookie-and-no-utf8-bom-sig.txt
deleted file mode 100644
index 04561e4847..0000000000
--- a/Lib/test/tokenize_tests-utf8-coding-cookie-and-no-utf8-bom-sig.txt
+++ /dev/null
@@ -1,13 +0,0 @@
-# -*- coding: utf-8 -*-
-# IMPORTANT: unlike the other test_tokenize-*.txt files, this file
-# does NOT have the utf-8 BOM signature '\xef\xbb\xbf' at the start
-# of it.  Make sure this is not added inadvertently by your editor
-# if any changes are made to this file!
-
-# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
-x = 'ЉЊЈЁЂ'
-def y():
-    """
-    And again in a comment.  ЉЊЈЁЂ
-    """
-    pass
diff --git a/Lib/test/tokenize_tests-utf8-coding-cookie-and-utf8-bom-sig.txt b/Lib/test/tokenize_tests-utf8-coding-cookie-and-utf8-bom-sig.txt
deleted file mode 100644
index 4b20ff6ad6..0000000000
--- a/Lib/test/tokenize_tests-utf8-coding-cookie-and-utf8-bom-sig.txt
+++ /dev/null
@@ -1,12 +0,0 @@
-﻿# -*- coding: utf-8 -*-
-# IMPORTANT: this file has the utf-8 BOM signature '\xef\xbb\xbf'
-# at the start of it.  Make sure this is preserved if any changes
-# are made!
-
-# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
-x = 'ЉЊЈЁЂ'
-def y():
-    """
-    And again in a comment.  ЉЊЈЁЂ
-    """
-    pass
diff --git a/Lib/test/tokenize_tests.txt b/Lib/test/tokenize_tests.txt
deleted file mode 100644
index c4f5a58a94..0000000000
--- a/Lib/test/tokenize_tests.txt
+++ /dev/null
@@ -1,189 +0,0 @@
-# Tests for the 'tokenize' module.
-# Large bits stolen from test_grammar.py.
-
-# Comments
-"#"
-#'
-#"
-#\
-       #
-    # abc
-'''#
-#'''
-
-x = 1  #
-
-# Balancing continuation
-
-a = (3, 4,
-  5, 6)
-y = [3, 4,
-  5]
-z = {'a':5,
-  'b':6}
-x = (len(repr(y)) + 5*x - a[
-   3 ]
-   - x + len({
-   }
-    )
-  )
-
-# Backslash means line continuation:
-x = 1 \
-+ 1
-
-# Backslash does not means continuation in comments :\
-x = 0
-
-# Ordinary integers
-0xff != 255
-0o377 != 255
-2147483647   != 0o17777777777
--2147483647-1 != 0o20000000000
-0o37777777777 != -1
-0xffffffff != -1; 0o37777777777 != -1; -0o1234567 == 0O001234567; 0b10101 == 0B00010101
-
-# Long integers
-x = 0
-x = 0
-x = 0xffffffffffffffff
-x = 0xffffffffffffffff
-x = 0o77777777777777777
-x = 0B11101010111111111
-x = 123456789012345678901234567890
-x = 123456789012345678901234567890
-
-# Floating-point numbers
-x = 3.14
-x = 314.
-x = 0.314
-# XXX x = 000.314
-x = .314
-x = 3e14
-x = 3E14
-x = 3e-14
-x = 3e+14
-x = 3.e14
-x = .3e14
-x = 3.1e4
-
-# String literals
-x = ''; y = "";
-x = '\''; y = "'";
-x = '"'; y = "\"";
-x = "doesn't \"shrink\" does it"
-y = 'doesn\'t "shrink" does it'
-x = "does \"shrink\" doesn't it"
-y = 'does "shrink" doesn\'t it'
-x = """
-The "quick"
-brown fox
-jumps over
-the 'lazy' dog.
-"""
-y = '\nThe "quick"\nbrown fox\njumps over\nthe \'lazy\' dog.\n'
-y = '''
-The "quick"
-brown fox
-jumps over
-the 'lazy' dog.
-''';
-y = "\n\
-The \"quick\"\n\
-brown fox\n\
-jumps over\n\
-the 'lazy' dog.\n\
-";
-y = '\n\
-The \"quick\"\n\
-brown fox\n\
-jumps over\n\
-the \'lazy\' dog.\n\
-';
-x = r'\\' + R'\\'
-x = r'\'' + ''
-y = r'''
-foo bar \\
-baz''' + R'''
-foo'''
-y = r"""foo
-bar \\ baz
-""" + R'''spam
-'''
-x = b'abc' + B'ABC'
-y = b"abc" + B"ABC"
-x = br'abc' + Br'ABC' + bR'ABC' + BR'ABC'
-y = br"abc" + Br"ABC" + bR"ABC" + BR"ABC"
-x = rb'abc' + rB'ABC' + Rb'ABC' + RB'ABC'
-y = rb"abc" + rB"ABC" + Rb"ABC" + RB"ABC"
-x = br'\\' + BR'\\'
-x = rb'\\' + RB'\\'
-x = br'\'' + ''
-x = rb'\'' + ''
-y = br'''
-foo bar \\
-baz''' + BR'''
-foo'''
-y = Br"""foo
-bar \\ baz
-""" + bR'''spam
-'''
-y = rB"""foo
-bar \\ baz
-""" + Rb'''spam
-'''
-
-# Indentation
-if 1:
-    x = 2
-if 1:
-        x = 2
-if 1:
-    while 0:
-     if 0:
-           x = 2
-     x = 2
-if 0:
-  if 2:
-   while 0:
-        if 1:
-          x = 2
-
-# Operators
-
-def d22(a, b, c=1, d=2): pass
-def d01v(a=1, *restt, **restd): pass
-
-(x, y) != ({'a':1}, {'b':2})
-
-# comparison
-if 1 < 1 > 1 == 1 >= 1 <= 1 != 1 != 1 in 1 not in 1 is 1 is not 1: pass
-
-# binary
-x = 1 & 1
-x = 1 ^ 1
-x = 1 | 1
-
-# shift
-x = 1 << 1 >> 1
-
-# additive
-x = 1 - 1 + 1 - 1 + 1
-
-# multiplicative
-x = 1 / 1 * 1 % 1
-
-# unary
-x = ~1 ^ 1 & 1 | 1 & 1 ^ -1
-x = -1*1/1 + 1*1 - ---1*1
-
-# selector
-import sys, time
-x = sys.modules['time'].time()
-
-@staticmethod
-def foo(): pass
-
-@staticmethod
-def foo(x:1)->1: pass
-
diff --git a/Lib/test/tokenizedata/__init__.py b/Lib/test/tokenizedata/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/Lib/test/tokenizedata/bad_coding.py b/Lib/test/tokenizedata/bad_coding.py
new file mode 100644
index 0000000000..971b0a8f3d
--- /dev/null
+++ b/Lib/test/tokenizedata/bad_coding.py
@@ -0,0 +1 @@
+# -*- coding: uft-8 -*-
diff --git a/Lib/test/tokenizedata/bad_coding2.py b/Lib/test/tokenizedata/bad_coding2.py
new file mode 100644
index 0000000000..bb2bb7e1e7
--- /dev/null
+++ b/Lib/test/tokenizedata/bad_coding2.py
@@ -0,0 +1,2 @@
+﻿#coding: utf8
+print('我')
diff --git a/Lib/test/tokenizedata/badsyntax_3131.py b/Lib/test/tokenizedata/badsyntax_3131.py
new file mode 100644
index 0000000000..901d3744ca
--- /dev/null
+++ b/Lib/test/tokenizedata/badsyntax_3131.py
@@ -0,0 +1,2 @@
+# -*- coding: utf-8 -*-
+€ = 2
diff --git a/Lib/test/tokenizedata/coding20731.py b/Lib/test/tokenizedata/coding20731.py
new file mode 100644
index 0000000000..b0e227ad11
--- /dev/null
+++ b/Lib/test/tokenizedata/coding20731.py
@@ -0,0 +1,4 @@
+#coding:latin1
+
+
+
diff --git a/Lib/test/tokenizedata/tokenize_tests-latin1-coding-cookie-and-utf8-bom-sig.txt b/Lib/test/tokenizedata/tokenize_tests-latin1-coding-cookie-and-utf8-bom-sig.txt
new file mode 100644
index 0000000000..1b5335b64e
--- /dev/null
+++ b/Lib/test/tokenizedata/tokenize_tests-latin1-coding-cookie-and-utf8-bom-sig.txt
@@ -0,0 +1,13 @@
+﻿# -*- coding: latin1 -*-
+# IMPORTANT: this file has the utf-8 BOM signature '\xef\xbb\xbf'
+# at the start of it.  Make sure this is preserved if any changes
+# are made!  Also note that the coding cookie above conflicts with
+# the presence of a utf-8 BOM signature -- this is intended.
+
+# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
+x = 'ЉЊЈЁЂ'
+def y():
+    """
+    And again in a comment.  ЉЊЈЁЂ
+    """
+    pass
diff --git a/Lib/test/tokenizedata/tokenize_tests-no-coding-cookie-and-utf8-bom-sig-only.txt b/Lib/test/tokenizedata/tokenize_tests-no-coding-cookie-and-utf8-bom-sig-only.txt
new file mode 100644
index 0000000000..23fd2168ae
--- /dev/null
+++ b/Lib/test/tokenizedata/tokenize_tests-no-coding-cookie-and-utf8-bom-sig-only.txt
@@ -0,0 +1,11 @@
+﻿# IMPORTANT: this file has the utf-8 BOM signature '\xef\xbb\xbf'
+# at the start of it.  Make sure this is preserved if any changes
+# are made!
+
+# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
+x = 'ЉЊЈЁЂ'
+def y():
+    """
+    And again in a comment.  ЉЊЈЁЂ
+    """
+    pass
diff --git a/Lib/test/tokenizedata/tokenize_tests-utf8-coding-cookie-and-no-utf8-bom-sig.txt b/Lib/test/tokenizedata/tokenize_tests-utf8-coding-cookie-and-no-utf8-bom-sig.txt
new file mode 100644
index 0000000000..04561e4847
--- /dev/null
+++ b/Lib/test/tokenizedata/tokenize_tests-utf8-coding-cookie-and-no-utf8-bom-sig.txt
@@ -0,0 +1,13 @@
+# -*- coding: utf-8 -*-
+# IMPORTANT: unlike the other test_tokenize-*.txt files, this file
+# does NOT have the utf-8 BOM signature '\xef\xbb\xbf' at the start
+# of it.  Make sure this is not added inadvertently by your editor
+# if any changes are made to this file!
+
+# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
+x = 'ЉЊЈЁЂ'
+def y():
+    """
+    And again in a comment.  ЉЊЈЁЂ
+    """
+    pass
diff --git a/Lib/test/tokenizedata/tokenize_tests-utf8-coding-cookie-and-utf8-bom-sig.txt b/Lib/test/tokenizedata/tokenize_tests-utf8-coding-cookie-and-utf8-bom-sig.txt
new file mode 100644
index 0000000000..4b20ff6ad6
--- /dev/null
+++ b/Lib/test/tokenizedata/tokenize_tests-utf8-coding-cookie-and-utf8-bom-sig.txt
@@ -0,0 +1,12 @@
+﻿# -*- coding: utf-8 -*-
+# IMPORTANT: this file has the utf-8 BOM signature '\xef\xbb\xbf'
+# at the start of it.  Make sure this is preserved if any changes
+# are made!
+
+# Arbitrary encoded utf-8 text (stolen from test_doctest2.py).
+x = 'ЉЊЈЁЂ'
+def y():
+    """
+    And again in a comment.  ЉЊЈЁЂ
+    """
+    pass
diff --git a/Lib/test/tokenizedata/tokenize_tests.txt b/Lib/test/tokenizedata/tokenize_tests.txt
new file mode 100644
index 0000000000..c4f5a58a94
--- /dev/null
+++ b/Lib/test/tokenizedata/tokenize_tests.txt
@@ -0,0 +1,189 @@
+# Tests for the 'tokenize' module.
+# Large bits stolen from test_grammar.py.
+
+# Comments
+"#"
+#'
+#"
+#\
+       #
+    # abc
+'''#
+#'''
+
+x = 1  #
+
+# Balancing continuation
+
+a = (3, 4,
+  5, 6)
+y = [3, 4,
+  5]
+z = {'a':5,
+  'b':6}
+x = (len(repr(y)) + 5*x - a[
+   3 ]
+   - x + len({
+   }
+    )
+  )
+
+# Backslash means line continuation:
+x = 1 \
++ 1
+
+# Backslash does not means continuation in comments :\
+x = 0
+
+# Ordinary integers
+0xff != 255
+0o377 != 255
+2147483647   != 0o17777777777
+-2147483647-1 != 0o20000000000
+0o37777777777 != -1
+0xffffffff != -1; 0o37777777777 != -1; -0o1234567 == 0O001234567; 0b10101 == 0B00010101
+
+# Long integers
+x = 0
+x = 0
+x = 0xffffffffffffffff
+x = 0xffffffffffffffff
+x = 0o77777777777777777
+x = 0B11101010111111111
+x = 123456789012345678901234567890
+x = 123456789012345678901234567890
+
+# Floating-point numbers
+x = 3.14
+x = 314.
+x = 0.314
+# XXX x = 000.314
+x = .314
+x = 3e14
+x = 3E14
+x = 3e-14
+x = 3e+14
+x = 3.e14
+x = .3e14
+x = 3.1e4
+
+# String literals
+x = ''; y = "";
+x = '\''; y = "'";
+x = '"'; y = "\"";
+x = "doesn't \"shrink\" does it"
+y = 'doesn\'t "shrink" does it'
+x = "does \"shrink\" doesn't it"
+y = 'does "shrink" doesn\'t it'
+x = """
+The "quick"
+brown fox
+jumps over
+the 'lazy' dog.
+"""
+y = '\nThe "quick"\nbrown fox\njumps over\nthe \'lazy\' dog.\n'
+y = '''
+The "quick"
+brown fox
+jumps over
+the 'lazy' dog.
+''';
+y = "\n\
+The \"quick\"\n\
+brown fox\n\
+jumps over\n\
+the 'lazy' dog.\n\
+";
+y = '\n\
+The \"quick\"\n\
+brown fox\n\
+jumps over\n\
+the \'lazy\' dog.\n\
+';
+x = r'\\' + R'\\'
+x = r'\'' + ''
+y = r'''
+foo bar \\
+baz''' + R'''
+foo'''
+y = r"""foo
+bar \\ baz
+""" + R'''spam
+'''
+x = b'abc' + B'ABC'
+y = b"abc" + B"ABC"
+x = br'abc' + Br'ABC' + bR'ABC' + BR'ABC'
+y = br"abc" + Br"ABC" + bR"ABC" + BR"ABC"
+x = rb'abc' + rB'ABC' + Rb'ABC' + RB'ABC'
+y = rb"abc" + rB"ABC" + Rb"ABC" + RB"ABC"
+x = br'\\' + BR'\\'
+x = rb'\\' + RB'\\'
+x = br'\'' + ''
+x = rb'\'' + ''
+y = br'''
+foo bar \\
+baz''' + BR'''
+foo'''
+y = Br"""foo
+bar \\ baz
+""" + bR'''spam
+'''
+y = rB"""foo
+bar \\ baz
+""" + Rb'''spam
+'''
+
+# Indentation
+if 1:
+    x = 2
+if 1:
+        x = 2
+if 1:
+    while 0:
+     if 0:
+           x = 2
+     x = 2
+if 0:
+  if 2:
+   while 0:
+        if 1:
+          x = 2
+
+# Operators
+
+def d22(a, b, c=1, d=2): pass
+def d01v(a=1, *restt, **restd): pass
+
+(x, y) != ({'a':1}, {'b':2})
+
+# comparison
+if 1 < 1 > 1 == 1 >= 1 <= 1 != 1 != 1 in 1 not in 1 is 1 is not 1: pass
+
+# binary
+x = 1 & 1
+x = 1 ^ 1
+x = 1 | 1
+
+# shift
+x = 1 << 1 >> 1
+
+# additive
+x = 1 - 1 + 1 - 1 + 1
+
+# multiplicative
+x = 1 / 1 * 1 % 1
+
+# unary
+x = ~1 ^ 1 & 1 | 1 & 1 ^ -1
+x = -1*1/1 + 1*1 - ---1*1
+
+# selector
+import sys, time
+x = sys.modules['time'].time()
+
+@staticmethod
+def foo(): pass
+
+@staticmethod
+def foo(x:1)->1: pass
+
diff --git a/Lib/test/typinganndata/_typed_dict_helper.py b/Lib/test/typinganndata/_typed_dict_helper.py
new file mode 100644
index 0000000000..9df0ede7d4
--- /dev/null
+++ b/Lib/test/typinganndata/_typed_dict_helper.py
@@ -0,0 +1,30 @@
+"""Used to test `get_type_hints()` on a cross-module inherited `TypedDict` class
+
+This script uses future annotations to postpone a type that won't be available
+on the module inheriting from to `Foo`. The subclass in the other module should
+look something like this:
+
+    class Bar(_typed_dict_helper.Foo, total=False):
+        b: int
+
+In addition, it uses multiple levels of Annotated to test the interaction
+between the __future__ import, Annotated, and Required.
+"""
+
+from __future__ import annotations
+
+from typing import Annotated, Generic, Optional, Required, TypedDict, TypeVar
+
+
+OptionalIntType = Optional[int]
+
+class Foo(TypedDict):
+    a: OptionalIntType
+
+T = TypeVar("T")
+
+class FooGeneric(TypedDict, Generic[T]):
+    a: Optional[T]
+
+class VeryAnnotated(TypedDict, total=False):
+    a: Annotated[Annotated[Annotated[Required[int], "a"], "b"], "c"]
diff --git a/Lib/test/typinganndata/ann_module.py b/Lib/test/typinganndata/ann_module.py
new file mode 100644
index 0000000000..5081e6b583
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module.py
@@ -0,0 +1,62 @@
+
+
+"""
+The module for testing variable annotations.
+Empty lines above are for good reason (testing for correct line numbers)
+"""
+
+from typing import Optional
+from functools import wraps
+
+__annotations__[1] = 2
+
+class C:
+
+    x = 5; y: Optional['C'] = None
+
+from typing import Tuple
+x: int = 5; y: str = x; f: Tuple[int, int]
+
+class M(type):
+
+    __annotations__['123'] = 123
+    o: type = object
+
+(pars): bool = True
+
+class D(C):
+    j: str = 'hi'; k: str= 'bye'
+
+from types import new_class
+h_class = new_class('H', (C,))
+j_class = new_class('J')
+
+class F():
+    z: int = 5
+    def __init__(self, x):
+        pass
+
+class Y(F):
+    def __init__(self):
+        super(F, self).__init__(123)
+
+class Meta(type):
+    def __new__(meta, name, bases, namespace):
+        return super().__new__(meta, name, bases, namespace)
+
+class S(metaclass = Meta):
+    x: str = 'something'
+    y: str = 'something else'
+
+def foo(x: int = 10):
+    def bar(y: List[str]):
+        x: str = 'yes'
+    bar()
+
+def dec(func):
+    @wraps(func)
+    def wrapper(*args, **kwargs):
+        return func(*args, **kwargs)
+    return wrapper
+
+u: int | float
diff --git a/Lib/test/typinganndata/ann_module2.py b/Lib/test/typinganndata/ann_module2.py
new file mode 100644
index 0000000000..76cf5b3ad9
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module2.py
@@ -0,0 +1,36 @@
+"""
+Some correct syntax for variable annotation here.
+More examples are in test_grammar and test_parser.
+"""
+
+from typing import no_type_check, ClassVar
+
+i: int = 1
+j: int
+x: float = i/10
+
+def f():
+    class C: ...
+    return C()
+
+f().new_attr: object = object()
+
+class C:
+    def __init__(self, x: int) -> None:
+        self.x = x
+
+c = C(5)
+c.new_attr: int = 10
+
+__annotations__ = {}
+
+
+@no_type_check
+class NTC:
+    def meth(self, param: complex) -> None:
+        ...
+
+class CV:
+    var: ClassVar['CV']
+
+CV.var = CV()
diff --git a/Lib/test/typinganndata/ann_module3.py b/Lib/test/typinganndata/ann_module3.py
new file mode 100644
index 0000000000..eccd7be22d
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module3.py
@@ -0,0 +1,18 @@
+"""
+Correct syntax for variable annotation that should fail at runtime
+in a certain manner. More examples are in test_grammar and test_parser.
+"""
+
+def f_bad_ann():
+    __annotations__[1] = 2
+
+class C_OK:
+    def __init__(self, x: int) -> None:
+        self.x: no_such_name = x  # This one is OK as proposed by Guido
+
+class D_bad_ann:
+    def __init__(self, x: int) -> None:
+        sfel.y: int = 0
+
+def g_bad_ann():
+    no_such_name.attr: int = 0
diff --git a/Lib/test/typinganndata/ann_module4.py b/Lib/test/typinganndata/ann_module4.py
new file mode 100644
index 0000000000..13e9aee54c
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module4.py
@@ -0,0 +1,5 @@
+# This ann_module isn't for test_typing,
+# it's for test_module
+
+a:int=3
+b:str=4
diff --git a/Lib/test/typinganndata/ann_module5.py b/Lib/test/typinganndata/ann_module5.py
new file mode 100644
index 0000000000..837041e121
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module5.py
@@ -0,0 +1,10 @@
+# Used by test_typing to verify that Final wrapped in ForwardRef works.
+
+from __future__ import annotations
+
+from typing import Final
+
+name: Final[str] = "final"
+
+class MyClass:
+    value: Final = 3000
diff --git a/Lib/test/typinganndata/ann_module6.py b/Lib/test/typinganndata/ann_module6.py
new file mode 100644
index 0000000000..679175669b
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module6.py
@@ -0,0 +1,7 @@
+# Tests that top-level ClassVar is not allowed
+
+from __future__ import annotations
+
+from typing import ClassVar
+
+wrong: ClassVar[int] = 1
diff --git a/Lib/test/typinganndata/ann_module7.py b/Lib/test/typinganndata/ann_module7.py
new file mode 100644
index 0000000000..8f890cd280
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module7.py
@@ -0,0 +1,11 @@
+# Tests class have ``__text_signature__``
+
+from __future__ import annotations
+
+DEFAULT_BUFFER_SIZE = 8192
+
+class BufferedReader(object):
+    """BufferedReader(raw, buffer_size=DEFAULT_BUFFER_SIZE)\n--\n\n
+    Create a new buffered reader using the given readable raw IO object.
+    """
+    pass
diff --git a/Lib/test/typinganndata/ann_module8.py b/Lib/test/typinganndata/ann_module8.py
new file mode 100644
index 0000000000..bd03148137
--- /dev/null
+++ b/Lib/test/typinganndata/ann_module8.py
@@ -0,0 +1,10 @@
+# Test `@no_type_check`,
+# see https://bugs.python.org/issue46571
+
+class NoTypeCheck_Outer:
+    class Inner:
+        x: int
+
+
+def NoTypeCheck_function(arg: int) -> int:
+    ...
diff --git a/Lib/test/typinganndata/mod_generics_cache.py b/Lib/test/typinganndata/mod_generics_cache.py
new file mode 100644
index 0000000000..6c1ee2fec8
--- /dev/null
+++ b/Lib/test/typinganndata/mod_generics_cache.py
@@ -0,0 +1,24 @@
+"""Module for testing the behavior of generics across different modules."""
+
+from typing import TypeVar, Generic, Optional, TypeAliasType
+
+default_a: Optional['A'] = None
+default_b: Optional['B'] = None
+
+T = TypeVar('T')
+
+
+class A(Generic[T]):
+    some_b: 'B'
+
+
+class B(Generic[T]):
+    class A(Generic[T]):
+        pass
+
+    my_inner_a1: 'B.A'
+    my_inner_a2: A
+    my_outer_a: 'A'  # unless somebody calls get_type_hints with localns=B.__dict__
+
+type Alias = int
+OldStyle = TypeAliasType("OldStyle", int)
diff --git a/Lib/test/ziptestdata/README.md b/Lib/test/ziptestdata/README.md
index 6b9147db76..00d96d445b 100644
--- a/Lib/test/ziptestdata/README.md
+++ b/Lib/test/ziptestdata/README.md
@@ -1,7 +1,7 @@
 # Test data for `test_zipfile`
 
 The test executables in this directory are created manually from header.sh and
-the `testdata_module_inside_zip.py` file.  You must have infozip's zip utility
+the `testdata_module_inside_zip.py` file.  You must have Info-ZIP's zip utility
 installed (`apt install zip` on Debian).
 
 ## Purpose
@@ -25,7 +25,7 @@ ### Standard old format (2.0) zip file
 
 ### Modern format (4.5) zip64 file
 
-Redirecting from stdin forces infozip's zip tool to create a zip64.
+Redirecting from stdin forces Info-ZIP's zip tool to create a zip64.
 
 ```
 zip -0 <testdata_module_inside_zip.py >zip64.zip
diff --git a/Lib/threading.py b/Lib/threading.py
index df273870fa..a746dee570 100644
--- a/Lib/threading.py
+++ b/Lib/threading.py
@@ -238,6 +238,13 @@ def _release_save(self):
     def _is_owned(self):
         return self._owner == get_ident()
 
+    # Internal method used for reentrancy checks
+
+    def _recursion_count(self):
+        if self._owner != get_ident():
+            return 0
+        return self._count
+
 _PyRLock = _RLock
 
 
diff --git a/Lib/tkinter/__init__.py b/Lib/tkinter/__init__.py
index c59f8d11e8..cb3e5f1eba 100644
--- a/Lib/tkinter/__init__.py
+++ b/Lib/tkinter/__init__.py
@@ -1459,7 +1459,7 @@ def bind_all(self, sequence=None, func=None, add=None):
         An additional boolean parameter ADD specifies whether FUNC will
         be called additionally to the other bound function or whether
         it will replace the previous function. See bind for the return value."""
-        return self._bind(('bind', 'all'), sequence, func, add, 0)
+        return self._root()._bind(('bind', 'all'), sequence, func, add, True)
 
     def unbind_all(self, sequence):
         """Unbind for all widgets for event SEQUENCE all functions."""
@@ -1473,7 +1473,7 @@ def bind_class(self, className, sequence=None, func=None, add=None):
         whether it will replace the previous function. See bind for
         the return value."""
 
-        return self._bind(('bind', className), sequence, func, add, 0)
+        return self._root()._bind(('bind', className), sequence, func, add, True)
 
     def unbind_class(self, className, sequence):
         """Unbind for all widgets with bindtag CLASSNAME for event SEQUENCE
diff --git a/Lib/traceback.py b/Lib/traceback.py
index 813e13e1e0..f61d5db062 100644
--- a/Lib/traceback.py
+++ b/Lib/traceback.py
@@ -145,14 +145,11 @@ def format_exception_only(exc, /, value=_sentinel):
 
     The return value is a list of strings, each ending in a newline.
 
-    Normally, the list contains a single string; however, for
-    SyntaxError exceptions, it contains several lines that (when
-    printed) display detailed information about where the syntax
-    error occurred.
-
-    The message indicating which exception occurred is always the last
-    string in the list.
-
+    The list contains the exception's message, which is
+    normally a single string; however, for :exc:`SyntaxError` exceptions, it
+    contains several lines that (when printed) display detailed information
+    about where the syntax error occurred. Following the message, the list
+    contains the exception's ``__notes__``.
     """
     if value is _sentinel:
         value = exc
@@ -473,7 +470,8 @@ def format_frame_summary(self, frame_summary):
             stripped_line = frame_summary.line.strip()
             row.append('    {}\n'.format(stripped_line))
 
-            orig_line_len = len(frame_summary._original_line)
+            line = frame_summary._original_line
+            orig_line_len = len(line)
             frame_line_len = len(frame_summary.line.lstrip())
             stripped_characters = orig_line_len - frame_line_len
             if (
@@ -481,31 +479,40 @@ def format_frame_summary(self, frame_summary):
                 and frame_summary.end_colno is not None
             ):
                 start_offset = _byte_offset_to_character_offset(
-                    frame_summary._original_line, frame_summary.colno) + 1
+                    line, frame_summary.colno)
                 end_offset = _byte_offset_to_character_offset(
-                    frame_summary._original_line, frame_summary.end_colno) + 1
+                    line, frame_summary.end_colno)
+                code_segment = line[start_offset:end_offset]
 
                 anchors = None
                 if frame_summary.lineno == frame_summary.end_lineno:
                     with suppress(Exception):
-                        anchors = _extract_caret_anchors_from_line_segment(
-                            frame_summary._original_line[start_offset - 1:end_offset - 1]
-                        )
+                        anchors = _extract_caret_anchors_from_line_segment(code_segment)
                 else:
-                    end_offset = stripped_characters + len(stripped_line)
+                    # Don't count the newline since the anchors only need to
+                    # go up until the last character of the line.
+                    end_offset = len(line.rstrip())
 
                 # show indicators if primary char doesn't span the frame line
                 if end_offset - start_offset < len(stripped_line) or (
                         anchors and anchors.right_start_offset - anchors.left_end_offset > 0):
+                    # When showing this on a terminal, some of the non-ASCII characters
+                    # might be rendered as double-width characters, so we need to take
+                    # that into account when calculating the length of the line.
+                    dp_start_offset = _display_width(line, start_offset) + 1
+                    dp_end_offset = _display_width(line, end_offset) + 1
+
                     row.append('    ')
-                    row.append(' ' * (start_offset - stripped_characters))
+                    row.append(' ' * (dp_start_offset - stripped_characters))
 
                     if anchors:
-                        row.append(anchors.primary_char * (anchors.left_end_offset))
-                        row.append(anchors.secondary_char * (anchors.right_start_offset - anchors.left_end_offset))
-                        row.append(anchors.primary_char * (end_offset - start_offset - anchors.right_start_offset))
+                        dp_left_end_offset = _display_width(code_segment, anchors.left_end_offset)
+                        dp_right_start_offset = _display_width(code_segment, anchors.right_start_offset)
+                        row.append(anchors.primary_char * dp_left_end_offset)
+                        row.append(anchors.secondary_char * (dp_right_start_offset - dp_left_end_offset))
+                        row.append(anchors.primary_char * (dp_end_offset - dp_start_offset - dp_right_start_offset))
                     else:
-                        row.append('^' * (end_offset - start_offset))
+                        row.append('^' * (dp_end_offset - dp_start_offset))
 
                     row.append('\n')
 
@@ -626,6 +633,25 @@ def _extract_caret_anchors_from_line_segment(segment):
 
     return None
 
+_WIDE_CHAR_SPECIFIERS = "WF"
+
+def _display_width(line, offset):
+    """Calculate the extra amount of width space the given source
+    code segment might take if it were to be displayed on a fixed
+    width output device. Supports wide unicode characters and emojis."""
+
+    # Fast track for ASCII-only strings
+    if line.isascii():
+        return offset
+
+    import unicodedata
+
+    return sum(
+        2 if unicodedata.east_asian_width(char) in _WIDE_CHAR_SPECIFIERS else 1
+        for char in line[:offset]
+    )
+
+
 
 class _ExceptionPrintContext:
     def __init__(self):
@@ -841,13 +867,13 @@ def format_exception_only(self):
 
         The return value is a generator of strings, each ending in a newline.
 
-        Normally, the generator emits a single string; however, for
-        SyntaxError exceptions, it emits several lines that (when
-        printed) display detailed information about where the syntax
-        error occurred.
-
-        The message indicating which exception occurred is always the last
-        string in the output.
+        Generator yields the exception message.
+        For :exc:`SyntaxError` exceptions, it
+        also yields (before the exception message)
+        several lines that (when printed)
+        display detailed information about where the syntax error occurred.
+        Following the message, generator also yields
+        all the exception's ``__notes__``.
         """
         if self.exc_type is None:
             yield _format_final_exc_line(None, self._str)
diff --git a/Lib/tty.py b/Lib/tty.py
index 7d916029ff..283e5c334f 100644
--- a/Lib/tty.py
+++ b/Lib/tty.py
@@ -39,6 +39,7 @@ def cfmakeraw(mode):
     # Case B: MIN>0, TIME=0
     # A pending read shall block until MIN (here 1) bytes are received,
     # or a signal is received.
+    mode[CC] = list(mode[CC])
     mode[CC][VMIN] = 1
     mode[CC][VTIME] = 0
 
@@ -54,6 +55,7 @@ def cfmakecbreak(mode):
     # Case B: MIN>0, TIME=0
     # A pending read shall block until MIN (here 1) bytes are received,
     # or a signal is received.
+    mode[CC] = list(mode[CC])
     mode[CC][VMIN] = 1
     mode[CC][VTIME] = 0
 
diff --git a/Lib/turtledemo/__main__.py b/Lib/turtledemo/__main__.py
index f6c9d6aa6f..2ab6c15e2c 100755
--- a/Lib/turtledemo/__main__.py
+++ b/Lib/turtledemo/__main__.py
@@ -161,7 +161,7 @@ def __init__(self, filename=None):
                               label='Help', underline=0)
         root['menu'] = self.mBar
 
-        pane = PanedWindow(orient=HORIZONTAL, sashwidth=5,
+        pane = PanedWindow(root, orient=HORIZONTAL, sashwidth=5,
                            sashrelief=SOLID, bg='#ddd')
         pane.add(self.makeTextFrame(pane))
         pane.add(self.makeGraphFrame(pane))
diff --git a/Lib/unittest/case.py b/Lib/unittest/case.py
index 001b640dc4..811557498b 100644
--- a/Lib/unittest/case.py
+++ b/Lib/unittest/case.py
@@ -606,7 +606,6 @@ def run(self, result=None):
         else:
             stopTestRun = None
 
-        result.startTest(self)
         try:
             testMethod = getattr(self, self._testMethodName)
             if (getattr(self.__class__, "__unittest_skip__", False) or
@@ -617,6 +616,9 @@ def run(self, result=None):
                 _addSkip(result, self, skip_why)
                 return result
 
+            # Increase the number of tests only if it hasn't been skipped
+            result.startTest(self)
+
             expecting_failure = (
                 getattr(self, "__unittest_expecting_failure__", False) or
                 getattr(testMethod, "__unittest_expecting_failure__", False)
diff --git a/Lib/unittest/loader.py b/Lib/unittest/loader.py
index b989284a64..f7c1d61f41 100644
--- a/Lib/unittest/loader.py
+++ b/Lib/unittest/loader.py
@@ -84,9 +84,13 @@ def loadTestsFromTestCase(self, testCaseClass):
             raise TypeError("Test cases should not be derived from "
                             "TestSuite. Maybe you meant to derive from "
                             "TestCase?")
-        testCaseNames = self.getTestCaseNames(testCaseClass)
-        if not testCaseNames and hasattr(testCaseClass, 'runTest'):
-            testCaseNames = ['runTest']
+        if testCaseClass in (case.TestCase, case.FunctionTestCase):
+            # We don't load any tests from base types that should not be loaded.
+            testCaseNames = []
+        else:
+            testCaseNames = self.getTestCaseNames(testCaseClass)
+            if not testCaseNames and hasattr(testCaseClass, 'runTest'):
+                testCaseNames = ['runTest']
         loaded_suite = self.suiteClass(map(testCaseClass, testCaseNames))
         return loaded_suite
 
@@ -95,7 +99,11 @@ def loadTestsFromModule(self, module, *, pattern=None):
         tests = []
         for name in dir(module):
             obj = getattr(module, name)
-            if isinstance(obj, type) and issubclass(obj, case.TestCase):
+            if (
+                isinstance(obj, type)
+                and issubclass(obj, case.TestCase)
+                and obj not in (case.TestCase, case.FunctionTestCase)
+            ):
                 tests.append(self.loadTestsFromTestCase(obj))
 
         load_tests = getattr(module, 'load_tests', None)
@@ -164,7 +172,11 @@ def loadTestsFromName(self, name, module=None):
 
         if isinstance(obj, types.ModuleType):
             return self.loadTestsFromModule(obj)
-        elif isinstance(obj, type) and issubclass(obj, case.TestCase):
+        elif (
+            isinstance(obj, type)
+            and issubclass(obj, case.TestCase)
+            and obj not in (case.TestCase, case.FunctionTestCase)
+        ):
             return self.loadTestsFromTestCase(obj)
         elif (isinstance(obj, types.FunctionType) and
               isinstance(parent, type) and
diff --git a/Lib/unittest/mock.py b/Lib/unittest/mock.py
index 7ca0857606..30e8f1550f 100644
--- a/Lib/unittest/mock.py
+++ b/Lib/unittest/mock.py
@@ -827,7 +827,7 @@ def _format_mock_call_signature(self, args, kwargs):
 
 
     def _format_mock_failure_message(self, args, kwargs, action='call'):
-        message = 'expected %s not found.\nExpected: %s\nActual: %s'
+        message = 'expected %s not found.\nExpected: %s\n  Actual: %s'
         expected_string = self._format_mock_call_signature(args, kwargs)
         call_args = self.call_args
         actual_string = self._format_mock_call_signature(*call_args)
@@ -930,7 +930,7 @@ def assert_called_with(self, /, *args, **kwargs):
         if self.call_args is None:
             expected = self._format_mock_call_signature(args, kwargs)
             actual = 'not called.'
-            error_message = ('expected call not found.\nExpected: %s\nActual: %s'
+            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                     % (expected, actual))
             raise AssertionError(error_message)
 
@@ -981,7 +981,7 @@ def assert_has_calls(self, calls, any_order=False):
                 raise AssertionError(
                     f'{problem}\n'
                     f'Expected: {_CallList(calls)}'
-                    f'{self._calls_repr(prefix="Actual").rstrip(".")}'
+                    f'{self._calls_repr(prefix="  Actual").rstrip(".")}'
                 ) from cause
             return
 
diff --git a/Lib/unittest/result.py b/Lib/unittest/result.py
index 3ace0a5b7b..9e56f65802 100644
--- a/Lib/unittest/result.py
+++ b/Lib/unittest/result.py
@@ -97,10 +97,12 @@ def _restoreStdout(self):
 
             sys.stdout = self._original_stdout
             sys.stderr = self._original_stderr
-            self._stdout_buffer.seek(0)
-            self._stdout_buffer.truncate()
-            self._stderr_buffer.seek(0)
-            self._stderr_buffer.truncate()
+            if self._stdout_buffer is not None:
+                self._stdout_buffer.seek(0)
+                self._stdout_buffer.truncate()
+            if self._stderr_buffer is not None:
+                self._stderr_buffer.seek(0)
+                self._stderr_buffer.truncate()
 
     def stopTestRun(self):
         """Called once after all tests are executed.
diff --git a/Lib/zipfile/__init__.py b/Lib/zipfile/__init__.py
index 9fc1840ba1..59d105580a 100644
--- a/Lib/zipfile/__init__.py
+++ b/Lib/zipfile/__init__.py
@@ -531,6 +531,7 @@ def _decodeExtra(self, filename_crc):
                         if up_unicode_name:
                             self.filename = _sanitize_filename(up_unicode_name)
                         else:
+                            import warnings
                             warnings.warn("Empty unicode path extra field (0x7075)", stacklevel=2)
                 except struct.error as e:
                     raise BadZipFile("Corrupt unicode path extra field (0x7075)") from e
@@ -1121,8 +1122,12 @@ def seek(self, offset, whence=os.SEEK_SET):
         read_offset = new_pos - curr_pos
         buff_offset = read_offset + self._offset
 
+        if buff_offset >= 0 and buff_offset < len(self._readbuffer):
+            # Just move the _offset index if the new position is in the _readbuffer
+            self._offset = buff_offset
+            read_offset = 0
         # Fast seek uncompressed unencrypted file
-        if self._compress_type == ZIP_STORED and self._decrypter is None and read_offset > 0:
+        elif self._compress_type == ZIP_STORED and self._decrypter is None and read_offset > 0:
             # disable CRC checking after first seeking - it would be invalid
             self._expected_crc = None
             # seek actual file taking already buffered data into account
@@ -1133,10 +1138,6 @@ def seek(self, offset, whence=os.SEEK_SET):
             # flush read buffer
             self._readbuffer = b''
             self._offset = 0
-        elif buff_offset >= 0 and buff_offset < len(self._readbuffer):
-            # Just move the _offset index if the new position is in the _readbuffer
-            self._offset = buff_offset
-            read_offset = 0
         elif read_offset < 0:
             # Position is before the current position. Reset the ZipExtFile
             self._fileobj.seek(self._orig_compress_start)
diff --git a/Lib/zoneinfo/_zoneinfo.py b/Lib/zoneinfo/_zoneinfo.py
index eede15b827..b77dc0ed39 100644
--- a/Lib/zoneinfo/_zoneinfo.py
+++ b/Lib/zoneinfo/_zoneinfo.py
@@ -517,8 +517,8 @@ class _DayOffset:
     __slots__ = ["d", "julian", "hour", "minute", "second"]
 
     def __init__(self, d, julian, hour=2, minute=0, second=0):
-        if not (0 + julian) <= d <= 365:
-            min_day = 0 + julian
+        min_day = 0 + julian  # convert bool to int
+        if not min_day <= d <= 365:
             raise ValueError(f"d must be in [{min_day}, 365], not: {d}")
 
         self.d = d
@@ -560,11 +560,11 @@ class _CalendarOffset:
     )
 
     def __init__(self, m, w, d, hour=2, minute=0, second=0):
-        if not 0 < m <= 12:
-            raise ValueError("m must be in (0, 12]")
+        if not 1 <= m <= 12:
+            raise ValueError("m must be in [1, 12]")
 
-        if not 0 < w <= 5:
-            raise ValueError("w must be in (0, 5]")
+        if not 1 <= w <= 5:
+            raise ValueError("w must be in [1, 5]")
 
         if not 0 <= d <= 6:
             raise ValueError("d must be in [0, 6]")
@@ -634,18 +634,21 @@ def _parse_tz_str(tz_str):
 
     offset_str, *start_end_str = tz_str.split(",", 1)
 
-    # fmt: off
     parser_re = re.compile(
-        r"(?P<std>[^<0-9:.+-]+|<[a-zA-Z0-9+\-]+>)" +
-        r"((?P<stdoff>[+-]?\d{1,2}(:\d{2}(:\d{2})?)?)" +
-            r"((?P<dst>[^0-9:.+-]+|<[a-zA-Z0-9+\-]+>)" +
-                r"((?P<dstoff>[+-]?\d{1,2}(:\d{2}(:\d{2})?)?))?" +
-            r")?" + # dst
-        r")?$" # stdoff
+        r"""
+        (?P<std>[^<0-9:.+-]+|<[a-zA-Z0-9+-]+>)
+        (?:
+            (?P<stdoff>[+-]?\d{1,3}(?::\d{2}(?::\d{2})?)?)
+            (?:
+                (?P<dst>[^0-9:.+-]+|<[a-zA-Z0-9+-]+>)
+                (?P<dstoff>[+-]?\d{1,3}(?::\d{2}(?::\d{2})?)?)?
+            )? # dst
+        )? # stdoff
+        """,
+        re.ASCII|re.VERBOSE
     )
-    # fmt: on
 
-    m = parser_re.match(offset_str)
+    m = parser_re.fullmatch(offset_str)
 
     if m is None:
         raise ValueError(f"{tz_str} is not a valid TZ string")
@@ -696,16 +699,17 @@ def _parse_tz_str(tz_str):
 
 
 def _parse_dst_start_end(dststr):
-    date, *time = dststr.split("/")
-    if date[0] == "M":
+    date, *time = dststr.split("/", 1)
+    type = date[:1]
+    if type == "M":
         n_is_julian = False
-        m = re.match(r"M(\d{1,2})\.(\d).(\d)$", date)
+        m = re.fullmatch(r"M(\d{1,2})\.(\d).(\d)", date, re.ASCII)
         if m is None:
             raise ValueError(f"Invalid dst start/end date: {dststr}")
         date_offset = tuple(map(int, m.groups()))
         offset = _CalendarOffset(*date_offset)
     else:
-        if date[0] == "J":
+        if type == "J":
             n_is_julian = True
             date = date[1:]
         else:
@@ -715,38 +719,54 @@ def _parse_dst_start_end(dststr):
         offset = _DayOffset(doy, n_is_julian)
 
     if time:
-        time_components = list(map(int, time[0].split(":")))
-        n_components = len(time_components)
-        if n_components < 3:
-            time_components.extend([0] * (3 - n_components))
-        offset.hour, offset.minute, offset.second = time_components
+        offset.hour, offset.minute, offset.second = _parse_transition_time(time[0])
 
     return offset
 
 
+def _parse_transition_time(time_str):
+    match = re.fullmatch(
+        r"(?P<sign>[+-])?(?P<h>\d{1,3})(:(?P<m>\d{2})(:(?P<s>\d{2}))?)?",
+        time_str,
+        re.ASCII
+    )
+    if match is None:
+        raise ValueError(f"Invalid time: {time_str}")
+
+    h, m, s = (int(v or 0) for v in match.group("h", "m", "s"))
+
+    if h > 167:
+        raise ValueError(
+            f"Hour must be in [0, 167]: {time_str}"
+        )
+
+    if match.group("sign") == "-":
+        h, m, s = -h, -m, -s
+
+    return h, m, s
+
+
 def _parse_tz_delta(tz_delta):
-    match = re.match(
-        r"(?P<sign>[+-])?(?P<h>\d{1,2})(:(?P<m>\d{2})(:(?P<s>\d{2}))?)?",
+    match = re.fullmatch(
+        r"(?P<sign>[+-])?(?P<h>\d{1,3})(:(?P<m>\d{2})(:(?P<s>\d{2}))?)?",
         tz_delta,
+        re.ASCII
     )
     # Anything passed to this function should already have hit an equivalent
     # regular expression to find the section to parse.
     assert match is not None, tz_delta
 
-    h, m, s = (
-        int(v) if v is not None else 0
-        for v in map(match.group, ("h", "m", "s"))
-    )
+    h, m, s = (int(v or 0) for v in match.group("h", "m", "s"))
 
     total = h * 3600 + m * 60 + s
 
-    if not -86400 < total < 86400:
+    if h > 24:
         raise ValueError(
-            f"Offset must be strictly between -24h and +24h: {tz_delta}"
+            f"Offset hours must be in [0, 24]: {tz_delta}"
         )
 
     # Yes, +5 maps to an offset of -5h
     if match.group("sign") != "-":
-        total *= -1
+        total = -total
 
     return total
diff --git a/Mac/BuildScript/build-installer.py b/Mac/BuildScript/build-installer.py
index c54de880c2..a07d38aedc 100755
--- a/Mac/BuildScript/build-installer.py
+++ b/Mac/BuildScript/build-installer.py
@@ -359,9 +359,9 @@ def library_recipes():
                   ),
           ),
           dict(
-              name="SQLite 3.42.0",
-              url="https://sqlite.org/2023/sqlite-autoconf-3420000.tar.gz",
-              checksum="0c5a92bc51cf07cae45b4a1e94653dea",
+              name="SQLite 3.43.1",
+              url="https://sqlite.org/2023/sqlite-autoconf-3430100.tar.gz",
+              checksum="77e61befe9c3298da0504f87772a24b0",
               extra_cflags=('-Os '
                             '-DSQLITE_ENABLE_FTS5 '
                             '-DSQLITE_ENABLE_FTS4 '
diff --git a/Mac/Makefile.in b/Mac/Makefile.in
index 69ab419898..92b3328c07 100644
--- a/Mac/Makefile.in
+++ b/Mac/Makefile.in
@@ -259,6 +259,8 @@ install_IDLE:
 		rm "$(DESTDIR)$(LIBDEST)/idlelib/config-extensions.def~" ; \
 	fi
 	touch "$(DESTDIR)$(PYTHONAPPSDIR)/IDLE.app"
+	chmod -R ugo+rX,go-w "$(DESTDIR)$(PYTHONAPPSDIR)/IDLE.app"
+	chmod ugo+x "$(DESTDIR)$(PYTHONAPPSDIR)/IDLE.app/Contents/MacOS/IDLE"
 
 $(INSTALLED_PYTHONAPP): install_Python
 
diff --git a/Mac/PythonLauncher/Makefile.in b/Mac/PythonLauncher/Makefile.in
index 4c05f26e83..9decadbdc6 100644
--- a/Mac/PythonLauncher/Makefile.in
+++ b/Mac/PythonLauncher/Makefile.in
@@ -27,6 +27,8 @@ install: Python\ Launcher.app
 	-test -d "$(DESTDIR)$(PYTHONAPPSDIR)/Python Launcher.app" && rm -r "$(DESTDIR)$(PYTHONAPPSDIR)/Python Launcher.app"
 	/bin/cp -r "Python Launcher.app" "$(DESTDIR)$(PYTHONAPPSDIR)"
 	touch "$(DESTDIR)$(PYTHONAPPSDIR)/Python Launcher.app"
+	chmod -R ugo+rX,go-w "$(DESTDIR)$(PYTHONAPPSDIR)/Python Launcher.app"
+	chmod ugo+x "$(DESTDIR)$(PYTHONAPPSDIR)/Python Launcher.app/Contents/MacOS/Python Launcher"
 
 clean:
 	rm -f *.o "Python Launcher"
diff --git a/Makefile.pre.in b/Makefile.pre.in
index 09ceccda1d..0cb9db7444 100644
--- a/Makefile.pre.in
+++ b/Makefile.pre.in
@@ -623,7 +623,8 @@ build_wasm: check-clean-src $(BUILDPYTHON) platform sharedmods \
 .PHONY: check-clean-src
 check-clean-src:
 	@if test -n "$(VPATH)" -a \( \
-	    -f "$(srcdir)/Programs/python.o" \
+	    -f "$(srcdir)/$(BUILDPYTHON)" \
+	    -o -f "$(srcdir)/Programs/python.o" \
 	    -o -f "$(srcdir)\Python/frozen_modules/importlib._bootstrap.h" \
 	\); then \
 		echo "Error: The source directory ($(srcdir)) is not clean" ; \
@@ -1396,8 +1397,8 @@ regen-pegen:
 	PYTHONPATH=$(srcdir)/Tools/peg_generator $(PYTHON_FOR_REGEN) -m pegen -q c \
 		$(srcdir)/Grammar/python.gram \
 		$(srcdir)/Grammar/Tokens \
-		-o $(srcdir)/Parser/parser.new.c
-	$(UPDATE_FILE) $(srcdir)/Parser/parser.c $(srcdir)/Parser/parser.new.c
+		-o $(srcdir)/Parser/parser.c.new
+	$(UPDATE_FILE) $(srcdir)/Parser/parser.c $(srcdir)/Parser/parser.c.new
 
 .PHONY: regen-ast
 regen-ast:
@@ -2116,7 +2117,8 @@ LIBSUBDIRS=	asyncio \
 TESTSUBDIRS=	idlelib/idle_test \
 		test \
 		test/audiodata \
-		test/capath \
+		test/certdata \
+		test/certdata/capath \
 		test/cjkencodings \
 		test/crashers \
 		test/data \
@@ -2134,8 +2136,12 @@ TESTSUBDIRS=	idlelib/idle_test \
 		test/test_capi \
 		test/test_cppext \
 		test/test_ctypes \
+		test/test_dataclasses \
 		test/test_email \
 		test/test_email/data \
+		test/test_future_stmt \
+		test/test_gdb \
+		test/test_inspect \
 		test/test_import \
 		test/test_import/data \
 		test/test_import/data/circular_imports \
@@ -2225,6 +2231,7 @@ TESTSUBDIRS=	idlelib/idle_test \
 		test/test_zipfile/_path \
 		test/test_zoneinfo \
 		test/test_zoneinfo/data \
+		test/tokenizedata \
 		test/tracedmodules \
 		test/typinganndata \
 		test/xmltestdata \
diff --git a/Misc/ACKS b/Misc/ACKS
index 7deef8bad1..df377b79c8 100644
--- a/Misc/ACKS
+++ b/Misc/ACKS
@@ -254,6 +254,7 @@ Curtis Bucher
 Colm Buckley
 Erik de Bueger
 Jan-Hein Bührman
+Marc Bürg
 Lars Buitinck
 Artem Bulgakov
 Dick Bulterman
@@ -1341,6 +1342,7 @@ Michele Orrù
 Tomáš Orsava
 Oleg Oshmyan
 Denis Osipov
+Savannah Ostrowski
 Denis S. Otkidach
 Peter Otten
 Michael Otteneder
deleted file mode 100644
index 60e7ed20a3..0000000000
--- a/Misc/requirements-test.txt
+++ /dev/null
@@ -1 +0,0 @@
-tzdata==2020.3
diff --git a/Modules/Setup.stdlib.in b/Modules/Setup.stdlib.in
index 3e01e25056..3360805596 100644
--- a/Modules/Setup.stdlib.in
+++ b/Modules/Setup.stdlib.in
@@ -168,7 +168,7 @@
 @MODULE__XXTESTFUZZ_TRUE@_xxtestfuzz _xxtestfuzz/_xxtestfuzz.c _xxtestfuzz/fuzzer.c
 @MODULE__TESTBUFFER_TRUE@_testbuffer _testbuffer.c
 @MODULE__TESTINTERNALCAPI_TRUE@_testinternalcapi _testinternalcapi.c
-@MODULE__TESTCAPI_TRUE@_testcapi _testcapimodule.c _testcapi/vectorcall.c _testcapi/vectorcall_limited.c _testcapi/heaptype.c _testcapi/abstract.c _testcapi/unicode.c _testcapi/dict.c _testcapi/getargs.c _testcapi/pytime.c _testcapi/datetime.c _testcapi/docstring.c _testcapi/mem.c _testcapi/watchers.c _testcapi/long.c _testcapi/float.c _testcapi/structmember.c _testcapi/exceptions.c _testcapi/code.c _testcapi/buffer.c _testcapi/pyos.c _testcapi/immortal.c _testcapi/heaptype_relative.c _testcapi/gc.c
+@MODULE__TESTCAPI_TRUE@_testcapi _testcapimodule.c _testcapi/vectorcall.c _testcapi/vectorcall_limited.c _testcapi/heaptype.c _testcapi/abstract.c _testcapi/bytearray.c _testcapi/bytes.c _testcapi/unicode.c _testcapi/dict.c _testcapi/set.c _testcapi/list.c _testcapi/tuple.c _testcapi/getargs.c _testcapi/pytime.c _testcapi/datetime.c _testcapi/docstring.c _testcapi/mem.c _testcapi/watchers.c _testcapi/long.c _testcapi/float.c _testcapi/complex.c _testcapi/numbers.c _testcapi/structmember.c _testcapi/exceptions.c _testcapi/code.c _testcapi/buffer.c _testcapi/pyos.c _testcapi/file.c _testcapi/codec.c _testcapi/immortal.c _testcapi/heaptype_relative.c _testcapi/gc.c _testcapi/sys.c
 @MODULE__TESTCLINIC_TRUE@_testclinic _testclinic.c
 
 # Some testing modules MUST be built as shared libraries.
diff --git a/Modules/_io/bytesio.c b/Modules/_io/bytesio.c
index 8077305869..7636394c35 100644
--- a/Modules/_io/bytesio.c
+++ b/Modules/_io/bytesio.c
@@ -124,12 +124,13 @@ unshare_buffer(bytesio *self, size_t size)
 static int
 resize_buffer(bytesio *self, size_t size)
 {
+    assert(self->buf != NULL);
+    assert(self->exports == 0);
+
     /* Here, unsigned types are used to avoid dealing with signed integer
        overflow, which is undefined in C. */
     size_t alloc = PyBytes_GET_SIZE(self->buf);
 
-    assert(self->buf != NULL);
-
     /* For simplicity, stay in the range of the signed type. Anyway, Python
        doesn't allow strings to be longer than this. */
     if (size > PY_SSIZE_T_MAX)
@@ -1072,7 +1073,7 @@ bytesiobuf_getbuffer(bytesiobuf *obj, Py_buffer *view, int flags)
             "bytesiobuf_getbuffer: view==NULL argument is obsolete");
         return -1;
     }
-    if (SHARED_BUF(b)) {
+    if (b->exports == 0 && SHARED_BUF(b)) {
         if (unshare_buffer(b, b->string_size) < 0)
             return -1;
     }
diff --git a/Modules/_io/winconsoleio.c b/Modules/_io/winconsoleio.c
index 7c6f226329..c2c365e080 100644
--- a/Modules/_io/winconsoleio.c
+++ b/Modules/_io/winconsoleio.c
@@ -134,6 +134,23 @@ char _PyIO_get_console_type(PyObject *path_or_fd) {
     return m;
 }
 
+static DWORD
+_find_last_utf8_boundary(const char *buf, DWORD len)
+{
+    /* This function never returns 0, returns the original len instead */
+    DWORD count = 1;
+    if (len == 0 || (buf[len - 1] & 0x80) == 0) {
+        return len;
+    }
+    for (;; count++) {
+        if (count > 3 || count >= len) {
+            return len;
+        }
+        if ((buf[len - count] & 0xc0) != 0x80) {
+            return len - count;
+        }
+    }
+}
 
 /*[clinic input]
 module _io
@@ -975,7 +992,7 @@ _io__WindowsConsoleIO_write_impl(winconsoleio *self, PyTypeObject *cls,
 {
     BOOL res = TRUE;
     wchar_t *wbuf;
-    DWORD len, wlen, orig_len, n = 0;
+    DWORD len, wlen, n = 0;
     HANDLE handle;
 
     if (self->fd == -1)
@@ -1007,21 +1024,8 @@ _io__WindowsConsoleIO_write_impl(winconsoleio *self, PyTypeObject *cls,
        have to reduce and recalculate. */
     while (wlen > 32766 / sizeof(wchar_t)) {
         len /= 2;
-        orig_len = len;
-        /* Reduce the length until we hit the final byte of a UTF-8 sequence
-         * (top bit is unset). Fix for github issue 82052.
-         */
-        while (len > 0 && (((char *)b->buf)[len-1] & 0x80) != 0)
-            --len;
-        /* If we hit a length of 0, something has gone wrong. This shouldn't
-         * be possible, as valid UTF-8 can have at most 3 non-final bytes
-         * before a final one, and our buffer is way longer than that.
-         * But to be on the safe side, if we hit this issue we just restore
-         * the original length and let the console API sort it out.
-         */
-        if (len == 0) {
-            len = orig_len;
-        }
+        /* Fix for github issues gh-110913 and gh-82052. */
+        len = _find_last_utf8_boundary(b->buf, len);
         wlen = MultiByteToWideChar(CP_UTF8, 0, b->buf, len, NULL, 0);
     }
     Py_END_ALLOW_THREADS
diff --git a/Modules/_sre/sre.c b/Modules/_sre/sre.c
index 2f1c7324a0..0547390454 100644
--- a/Modules/_sre/sre.c
+++ b/Modules/_sre/sre.c
@@ -1462,6 +1462,9 @@ _sre_compile_impl(PyObject *module, PyObject *pattern, int flags,
     for (i = 0; i < n; i++) {
         PyObject *o = PyList_GET_ITEM(code, i);
         unsigned long value = PyLong_AsUnsignedLong(o);
+        if (value == (unsigned long)-1 && PyErr_Occurred()) {
+            break;
+        }
         self->code[i] = (SRE_CODE) value;
         if ((unsigned long) self->code[i] != value) {
             PyErr_SetString(PyExc_OverflowError,
@@ -2021,8 +2024,6 @@ _validate_inner(SRE_CODE *code, SRE_CODE *end, Py_ssize_t groups)
             GET_SKIP;
             GET_ARG; /* 0 for lookahead, width for lookbehind */
             code--; /* Back up over arg to simplify math below */
-            if (arg & 0x80000000)
-                FAIL; /* Width too large */
             /* Stop 1 before the end; we check the SUCCESS below */
             if (_validate_inner(code+1, code+skip-2, groups))
                 FAIL;
diff --git a/Modules/_sre/sre.h b/Modules/_sre/sre.h
index d967d9ea04..a0f235606e 100644
--- a/Modules/_sre/sre.h
+++ b/Modules/_sre/sre.h
@@ -94,6 +94,7 @@ typedef struct {
     size_t data_stack_base;
     /* current repeat context */
     SRE_REPEAT *repeat;
+    unsigned int sigcount;
 } SRE_STATE;
 
 typedef struct {
diff --git a/Modules/_sre/sre_lib.h b/Modules/_sre/sre_lib.h
index e83149825e..95c1ada908 100644
--- a/Modules/_sre/sre_lib.h
+++ b/Modules/_sre/sre_lib.h
@@ -563,7 +563,7 @@ SRE(match)(SRE_STATE* state, const SRE_CODE* pattern, int toplevel)
     Py_ssize_t alloc_pos, ctx_pos = -1;
     Py_ssize_t ret = 0;
     int jump;
-    unsigned int sigcount=0;
+    unsigned int sigcount = state->sigcount;
 
     SRE(match_context)* ctx;
     SRE(match_context)* nextctx;
@@ -589,8 +589,8 @@ SRE(match)(SRE_STATE* state, const SRE_CODE* pattern, int toplevel)
         /* optimization info block */
         /* <INFO> <1=skip> <2=flags> <3=min> ... */
         if (pattern[3] && (uintptr_t)(end - ptr) < pattern[3]) {
-            TRACE(("reject (got %zd chars, need %zd)\n",
-                   end - ptr, (Py_ssize_t) pattern[3]));
+            TRACE(("reject (got %tu chars, need %zu)\n",
+                   end - ptr, (size_t) pattern[3]));
             RETURN_FAILURE;
         }
         pattern += pattern[1] + 1;
@@ -1507,7 +1507,7 @@ SRE(match)(SRE_STATE* state, const SRE_CODE* pattern, int toplevel)
             /* <ASSERT> <skip> <back> <pattern> */
             TRACE(("|%p|%p|ASSERT %d\n", pattern,
                    ptr, pattern[1]));
-            if (ptr - (SRE_CHAR *)state->beginning < (Py_ssize_t)pattern[1])
+            if ((uintptr_t)(ptr - (SRE_CHAR *)state->beginning) < pattern[1])
                 RETURN_FAILURE;
             state->ptr = ptr - pattern[1];
             DO_JUMP0(JUMP_ASSERT, jump_assert, pattern+2);
@@ -1520,7 +1520,7 @@ SRE(match)(SRE_STATE* state, const SRE_CODE* pattern, int toplevel)
             /* <ASSERT_NOT> <skip> <back> <pattern> */
             TRACE(("|%p|%p|ASSERT_NOT %d\n", pattern,
                    ptr, pattern[1]));
-            if (ptr - (SRE_CHAR *)state->beginning >= (Py_ssize_t)pattern[1]) {
+            if ((uintptr_t)(ptr - (SRE_CHAR *)state->beginning) >= pattern[1]) {
                 state->ptr = ptr - pattern[1];
                 LASTMARK_SAVE();
                 if (state->repeat)
@@ -1565,8 +1565,10 @@ SRE(match)(SRE_STATE* state, const SRE_CODE* pattern, int toplevel)
     ctx_pos = ctx->last_ctx_pos;
     jump = ctx->jump;
     DATA_POP_DISCARD(ctx);
-    if (ctx_pos == -1)
+    if (ctx_pos == -1) {
+        state->sigcount = sigcount;
         return ret;
+    }
     DATA_LOOKUP_AT(SRE(match_context), ctx, ctx_pos);
 
     switch (jump) {
@@ -1653,9 +1655,9 @@ SRE(search)(SRE_STATE* state, SRE_CODE* pattern)
 
         flags = pattern[2];
 
-        if (pattern[3] && end - ptr < (Py_ssize_t)pattern[3]) {
-            TRACE(("reject (got %u chars, need %u)\n",
-                   (unsigned int)(end - ptr), pattern[3]));
+        if (pattern[3] && (uintptr_t)(end - ptr) < pattern[3]) {
+            TRACE(("reject (got %tu chars, need %zu)\n",
+                   end - ptr, (size_t) pattern[3]));
             return 0;
         }
         if (pattern[3] > 1) {
diff --git a/Modules/_testcapi/abstract.c b/Modules/_testcapi/abstract.c
index 38236aaf4f..1c4c45c6c9 100644
--- a/Modules/_testcapi/abstract.c
+++ b/Modules/_testcapi/abstract.c
@@ -1,5 +1,3 @@
-#include <stddef.h>               // ptrdiff_t
-
 #define PY_SSIZE_T_CLEAN
 #include "parts.h"
 #include "util.h"
diff --git a/Modules/_testcapi/bytearray.c b/Modules/_testcapi/bytearray.c
new file mode 100644
index 0000000000..7ce065aa4f
--- /dev/null
+++ b/Modules/_testcapi/bytearray.c
@@ -0,0 +1,124 @@
+#define PY_SSIZE_T_CLEAN
+#include "parts.h"
+#include "util.h"
+
+
+/* Test PyByteArray_Check() */
+static PyObject *
+bytearray_check(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyByteArray_Check(obj));
+}
+
+/* Test PyByteArray_CheckExact() */
+static PyObject *
+bytearray_checkexact(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyByteArray_CheckExact(obj));
+}
+
+/* Test PyByteArray_FromStringAndSize() */
+static PyObject *
+bytearray_fromstringandsize(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    const char *s;
+    Py_ssize_t bsize;
+    Py_ssize_t size = -100;
+
+    if (!PyArg_ParseTuple(args, "z#|n", &s, &bsize, &size)) {
+        return NULL;
+    }
+
+    if (size == -100) {
+        size = bsize;
+    }
+    return PyByteArray_FromStringAndSize(s, size);
+}
+
+/* Test PyByteArray_FromObject() */
+static PyObject *
+bytearray_fromobject(PyObject *Py_UNUSED(module), PyObject *arg)
+{
+    NULLABLE(arg);
+    return PyByteArray_FromObject(arg);
+}
+
+/* Test PyByteArray_Size() */
+static PyObject *
+bytearray_size(PyObject *Py_UNUSED(module), PyObject *arg)
+{
+    NULLABLE(arg);
+    RETURN_SIZE(PyByteArray_Size(arg));
+}
+
+/* Test PyUnicode_AsString() */
+static PyObject *
+bytearray_asstring(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t buflen;
+    const char *s;
+
+    if (!PyArg_ParseTuple(args, "On", &obj, &buflen))
+        return NULL;
+
+    NULLABLE(obj);
+    s = PyByteArray_AsString(obj);
+    if (s == NULL)
+        return NULL;
+
+    return PyByteArray_FromStringAndSize(s, buflen);
+}
+
+/* Test PyByteArray_Concat() */
+static PyObject *
+bytearray_concat(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *left, *right;
+
+    if (!PyArg_ParseTuple(args, "OO", &left, &right))
+        return NULL;
+
+    NULLABLE(left);
+    NULLABLE(right);
+    return PyByteArray_Concat(left, right);
+}
+
+/* Test PyByteArray_Resize() */
+static PyObject *
+bytearray_resize(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t size;
+
+    if (!PyArg_ParseTuple(args, "On", &obj, &size))
+        return NULL;
+
+    NULLABLE(obj);
+    RETURN_INT(PyByteArray_Resize(obj, size));
+}
+
+
+static PyMethodDef test_methods[] = {
+    {"bytearray_check", bytearray_check, METH_O},
+    {"bytearray_checkexact", bytearray_checkexact, METH_O},
+    {"bytearray_fromstringandsize", bytearray_fromstringandsize, METH_VARARGS},
+    {"bytearray_fromobject", bytearray_fromobject, METH_O},
+    {"bytearray_size", bytearray_size, METH_O},
+    {"bytearray_asstring", bytearray_asstring, METH_VARARGS},
+    {"bytearray_concat", bytearray_concat, METH_VARARGS},
+    {"bytearray_resize", bytearray_resize, METH_VARARGS},
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_ByteArray(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/bytes.c b/Modules/_testcapi/bytes.c
new file mode 100644
index 0000000000..84a6cb88e4
--- /dev/null
+++ b/Modules/_testcapi/bytes.c
@@ -0,0 +1,256 @@
+#define PY_SSIZE_T_CLEAN
+#include "parts.h"
+#include "util.h"
+
+
+/* Test PyBytes_Check() */
+static PyObject *
+bytes_check(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyBytes_Check(obj));
+}
+
+/* Test PyBytes_CheckExact() */
+static PyObject *
+bytes_checkexact(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyBytes_CheckExact(obj));
+}
+
+/* Test PyBytes_FromStringAndSize() */
+static PyObject *
+bytes_fromstringandsize(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    const char *s;
+    Py_ssize_t bsize;
+    Py_ssize_t size = -100;
+
+    if (!PyArg_ParseTuple(args, "z#|n", &s, &bsize, &size)) {
+        return NULL;
+    }
+
+    if (size == -100) {
+        size = bsize;
+    }
+    return PyBytes_FromStringAndSize(s, size);
+}
+
+/* Test PyBytes_FromString() */
+static PyObject *
+bytes_fromstring(PyObject *Py_UNUSED(module), PyObject *arg)
+{
+    const char *s;
+    Py_ssize_t size;
+
+    if (!PyArg_Parse(arg, "z#", &s, &size)) {
+        return NULL;
+    }
+    return PyBytes_FromString(s);
+}
+
+/* Test PyBytes_FromObject() */
+static PyObject *
+bytes_fromobject(PyObject *Py_UNUSED(module), PyObject *arg)
+{
+    NULLABLE(arg);
+    return PyBytes_FromObject(arg);
+}
+
+/* Test PyBytes_Size() */
+static PyObject *
+bytes_size(PyObject *Py_UNUSED(module), PyObject *arg)
+{
+    NULLABLE(arg);
+    RETURN_SIZE(PyBytes_Size(arg));
+}
+
+/* Test PyUnicode_AsString() */
+static PyObject *
+bytes_asstring(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t buflen;
+    const char *s;
+
+    if (!PyArg_ParseTuple(args, "On", &obj, &buflen))
+        return NULL;
+
+    NULLABLE(obj);
+    s = PyBytes_AsString(obj);
+    if (s == NULL)
+        return NULL;
+
+    return PyBytes_FromStringAndSize(s, buflen);
+}
+
+/* Test PyBytes_AsStringAndSize() */
+static PyObject *
+bytes_asstringandsize(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t buflen;
+    char *s = UNINITIALIZED_PTR;
+    Py_ssize_t size = UNINITIALIZED_SIZE;
+
+    if (!PyArg_ParseTuple(args, "On", &obj, &buflen))
+        return NULL;
+
+    NULLABLE(obj);
+    if (PyBytes_AsStringAndSize(obj, &s, &size) < 0) {
+        return NULL;
+    }
+
+    if (s == NULL) {
+        return Py_BuildValue("(On)", Py_None, size);
+    }
+    else {
+        return Py_BuildValue("(y#n)", s, buflen, size);
+    }
+}
+
+static PyObject *
+bytes_asstringandsize_null(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t buflen;
+    char *s = UNINITIALIZED_PTR;
+
+    if (!PyArg_ParseTuple(args, "On", &obj, &buflen))
+        return NULL;
+
+    NULLABLE(obj);
+    if (PyBytes_AsStringAndSize(obj, &s, NULL) < 0) {
+        return NULL;
+    }
+
+    if (s == NULL) {
+        Py_RETURN_NONE;
+    }
+    else {
+        return PyBytes_FromStringAndSize(s, buflen);
+    }
+}
+
+/* Test PyBytes_Repr() */
+static PyObject *
+bytes_repr(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    int smartquotes;
+    if (!PyArg_ParseTuple(args, "Oi", &obj, &smartquotes))
+        return NULL;
+
+    NULLABLE(obj);
+    return PyBytes_Repr(obj, smartquotes);
+}
+
+/* Test PyBytes_Concat() */
+static PyObject *
+bytes_concat(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *left, *right;
+    int new = 0;
+
+    if (!PyArg_ParseTuple(args, "OO|p", &left, &right, &new))
+        return NULL;
+
+    NULLABLE(left);
+    NULLABLE(right);
+    if (new) {
+        assert(left != NULL);
+        assert(PyBytes_CheckExact(left));
+        left = PyBytes_FromStringAndSize(PyBytes_AS_STRING(left),
+                                         PyBytes_GET_SIZE(left));
+        if (left == NULL) {
+            return NULL;
+        }
+    }
+    else {
+        Py_XINCREF(left);
+    }
+    PyBytes_Concat(&left, right);
+    if (left == NULL && !PyErr_Occurred()) {
+        Py_RETURN_NONE;
+    }
+    return left;
+}
+
+/* Test PyBytes_ConcatAndDel() */
+static PyObject *
+bytes_concatanddel(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *left, *right;
+    int new = 0;
+
+    if (!PyArg_ParseTuple(args, "OO|p", &left, &right, &new))
+        return NULL;
+
+    NULLABLE(left);
+    NULLABLE(right);
+    if (new) {
+        assert(left != NULL);
+        assert(PyBytes_CheckExact(left));
+        left = PyBytes_FromStringAndSize(PyBytes_AS_STRING(left),
+                                         PyBytes_GET_SIZE(left));
+        if (left == NULL) {
+            return NULL;
+        }
+    }
+    else {
+        Py_XINCREF(left);
+    }
+    Py_XINCREF(right);
+    PyBytes_ConcatAndDel(&left, right);
+    if (left == NULL && !PyErr_Occurred()) {
+        Py_RETURN_NONE;
+    }
+    return left;
+}
+
+/* Test PyBytes_DecodeEscape() */
+static PyObject *
+bytes_decodeescape(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    const char *s;
+    Py_ssize_t bsize;
+    Py_ssize_t size = -100;
+    const char *errors = NULL;
+
+    if (!PyArg_ParseTuple(args, "z#|zn", &s, &bsize, &errors, &size))
+        return NULL;
+
+    if (size == -100) {
+        size = bsize;
+    }
+    return PyBytes_DecodeEscape(s, size, errors, 0, NULL);
+}
+
+
+static PyMethodDef test_methods[] = {
+    {"bytes_check", bytes_check, METH_O},
+    {"bytes_checkexact", bytes_checkexact, METH_O},
+    {"bytes_fromstringandsize", bytes_fromstringandsize, METH_VARARGS},
+    {"bytes_fromstring", bytes_fromstring, METH_O},
+    {"bytes_fromobject", bytes_fromobject, METH_O},
+    {"bytes_size", bytes_size, METH_O},
+    {"bytes_asstring", bytes_asstring, METH_VARARGS},
+    {"bytes_asstringandsize", bytes_asstringandsize, METH_VARARGS},
+    {"bytes_asstringandsize_null", bytes_asstringandsize_null, METH_VARARGS},
+    {"bytes_repr", bytes_repr, METH_VARARGS},
+    {"bytes_concat", bytes_concat, METH_VARARGS},
+    {"bytes_concatanddel", bytes_concatanddel, METH_VARARGS},
+    {"bytes_decodeescape", bytes_decodeescape, METH_VARARGS},
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Bytes(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/codec.c b/Modules/_testcapi/codec.c
new file mode 100644
index 0000000000..d13f51e203
--- /dev/null
+++ b/Modules/_testcapi/codec.c
@@ -0,0 +1,17 @@
+#include "parts.h"
+#include "util.h"
+
+
+static PyMethodDef test_methods[] = {
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Codec(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0){
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/complex.c b/Modules/_testcapi/complex.c
new file mode 100644
index 0000000000..400f4054c6
--- /dev/null
+++ b/Modules/_testcapi/complex.c
@@ -0,0 +1,108 @@
+#include "parts.h"
+#include "util.h"
+
+
+static PyObject *
+complex_check(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyComplex_Check(obj));
+}
+
+static PyObject *
+complex_checkexact(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyComplex_CheckExact(obj));
+}
+
+static PyObject *
+complex_fromccomplex(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    Py_complex complex;
+
+    if (!PyArg_Parse(obj, "D", &complex)) {
+        return NULL;
+    }
+
+    return PyComplex_FromCComplex(complex);
+}
+
+static PyObject *
+complex_fromdoubles(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    double real, imag;
+
+    if (!PyArg_ParseTuple(args, "dd", &real, &imag)) {
+        return NULL;
+    }
+
+    return PyComplex_FromDoubles(real, imag);
+}
+
+static PyObject *
+complex_realasdouble(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    double real;
+
+    NULLABLE(obj);
+    real = PyComplex_RealAsDouble(obj);
+
+    if (real == -1. && PyErr_Occurred()) {
+        return NULL;
+    }
+
+    return PyFloat_FromDouble(real);
+}
+
+static PyObject *
+complex_imagasdouble(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    double imag;
+
+    NULLABLE(obj);
+    imag = PyComplex_ImagAsDouble(obj);
+
+    if (imag == -1. && PyErr_Occurred()) {
+        return NULL;
+    }
+
+    return PyFloat_FromDouble(imag);
+}
+
+static PyObject *
+complex_asccomplex(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    Py_complex complex;
+
+    NULLABLE(obj);
+    complex = PyComplex_AsCComplex(obj);
+
+    if (complex.real == -1. && PyErr_Occurred()) {
+        return NULL;
+    }
+
+    return PyComplex_FromCComplex(complex);
+}
+
+
+static PyMethodDef test_methods[] = {
+    {"complex_check", complex_check, METH_O},
+    {"complex_checkexact", complex_checkexact, METH_O},
+    {"complex_fromccomplex", complex_fromccomplex, METH_O},
+    {"complex_fromdoubles", complex_fromdoubles, METH_VARARGS},
+    {"complex_realasdouble", complex_realasdouble, METH_O},
+    {"complex_imagasdouble", complex_imagasdouble, METH_O},
+    {"complex_asccomplex", complex_asccomplex, METH_O},
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Complex(PyObject *mod)
+{
+    if (PyModule_AddFunctions(mod, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/dict.c b/Modules/_testcapi/dict.c
index 374464c40d..41c8dfde0d 100644
--- a/Modules/_testcapi/dict.c
+++ b/Modules/_testcapi/dict.c
@@ -1,5 +1,3 @@
-#include <stddef.h>               // ptrdiff_t
-
 #define PY_SSIZE_T_CLEAN
 #include "parts.h"
 #include "util.h"
diff --git a/Modules/_testcapi/exceptions.c b/Modules/_testcapi/exceptions.c
index c511c6d071..4e02f5bec1 100644
--- a/Modules/_testcapi/exceptions.c
+++ b/Modules/_testcapi/exceptions.c
@@ -331,6 +331,22 @@ _testcapi_traceback_print_impl(PyObject *module, PyObject *traceback,
     Py_RETURN_NONE;
 }
 
+static PyObject *
+err_writeunraisable(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *exc, *obj;
+    if (!PyArg_ParseTuple(args, "OO", &exc, &obj)) {
+        return NULL;
+    }
+    NULLABLE(exc);
+    NULLABLE(obj);
+    if (exc) {
+        PyErr_SetRaisedException(Py_NewRef(exc));
+    }
+    PyErr_WriteUnraisable(obj);
+    Py_RETURN_NONE;
+}
+
 /*[clinic input]
 _testcapi.unstable_exc_prep_reraise_star
     orig: object
@@ -375,6 +391,7 @@ static PyTypeObject PyRecursingInfinitelyError_Type = {
 
 static PyMethodDef test_methods[] = {
     {"err_restore",             err_restore,                     METH_VARARGS},
+    {"err_writeunraisable",     err_writeunraisable,             METH_VARARGS},
     _TESTCAPI_ERR_SET_RAISED_METHODDEF
     _TESTCAPI_EXCEPTION_PRINT_METHODDEF
     _TESTCAPI_FATAL_ERROR_METHODDEF
diff --git a/Modules/_testcapi/file.c b/Modules/_testcapi/file.c
new file mode 100644
index 0000000000..634563f6ea
--- /dev/null
+++ b/Modules/_testcapi/file.c
@@ -0,0 +1,17 @@
+#include "parts.h"
+#include "util.h"
+
+
+static PyMethodDef test_methods[] = {
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_File(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0){
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/float.c b/Modules/_testcapi/float.c
index 33cbda83a8..0c26eb9b05 100644
--- a/Modules/_testcapi/float.c
+++ b/Modules/_testcapi/float.c
@@ -1,9 +1,75 @@
 #define PY_SSIZE_T_CLEAN
 
 #include "parts.h"
+#include "util.h"
 #include "clinic/float.c.h"
 
 
+static PyObject *
+float_check(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyFloat_Check(obj));
+}
+
+static PyObject *
+float_checkexact(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyFloat_CheckExact(obj));
+}
+
+static PyObject *
+float_fromstring(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyFloat_FromString(obj);
+}
+
+static PyObject *
+float_fromdouble(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    double d;
+
+    if (!PyArg_Parse(obj, "d", &d)) {
+        return NULL;
+    }
+
+    return PyFloat_FromDouble(d);
+}
+
+static PyObject *
+float_asdouble(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    double d;
+
+    NULLABLE(obj);
+    d = PyFloat_AsDouble(obj);
+    if (d == -1. && PyErr_Occurred()) {
+        return NULL;
+    }
+
+    return PyFloat_FromDouble(d);
+}
+
+static PyObject *
+float_getinfo(PyObject *Py_UNUSED(module), PyObject *Py_UNUSED(arg))
+{
+    return PyFloat_GetInfo();
+}
+
+static PyObject *
+float_getmax(PyObject *Py_UNUSED(module), PyObject *Py_UNUSED(arg))
+{
+    return PyFloat_FromDouble(PyFloat_GetMax());
+}
+
+static PyObject *
+float_getmin(PyObject *Py_UNUSED(module), PyObject *Py_UNUSED(arg))
+{
+    return PyFloat_FromDouble(PyFloat_GetMin());
+}
+
 /*[clinic input]
 module _testcapi
 [clinic start generated code]*/
@@ -98,6 +164,14 @@ _testcapi_float_unpack_impl(PyObject *module, const char *data,
 }
 
 static PyMethodDef test_methods[] = {
+    {"float_check", float_check, METH_O},
+    {"float_checkexact", float_checkexact, METH_O},
+    {"float_fromstring", float_fromstring, METH_O},
+    {"float_fromdouble", float_fromdouble, METH_O},
+    {"float_asdouble", float_asdouble, METH_O},
+    {"float_getinfo", float_getinfo, METH_NOARGS},
+    {"float_getmax", float_getmax, METH_NOARGS},
+    {"float_getmin", float_getmin, METH_NOARGS},
     _TESTCAPI_FLOAT_PACK_METHODDEF
     _TESTCAPI_FLOAT_UNPACK_METHODDEF
     {NULL},
diff --git a/Modules/_testcapi/getargs.c b/Modules/_testcapi/getargs.c
index aa20131995..fbfd6a4669 100644
--- a/Modules/_testcapi/getargs.c
+++ b/Modules/_testcapi/getargs.c
@@ -15,9 +15,9 @@ parse_tuple_and_keywords(PyObject *self, PyObject *args)
     const char *sub_format;
     PyObject *sub_keywords;
 
-    double buffers[8][4]; /* double ensures alignment where necessary */
-    PyObject *converted[8];
-    char *keywords[8 + 1]; /* space for NULL at end */
+#define MAX_PARAMS 8
+    double buffers[MAX_PARAMS][4]; /* double ensures alignment where necessary */
+    char *keywords[MAX_PARAMS + 1]; /* space for NULL at end */
 
     PyObject *return_value = NULL;
 
@@ -37,11 +37,10 @@ parse_tuple_and_keywords(PyObject *self, PyObject *args)
     }
 
     memset(buffers, 0, sizeof(buffers));
-    memset(converted, 0, sizeof(converted));
     memset(keywords, 0, sizeof(keywords));
 
     Py_ssize_t size = PySequence_Fast_GET_SIZE(sub_keywords);
-    if (size > 8) {
+    if (size > MAX_PARAMS) {
         PyErr_SetString(PyExc_ValueError,
             "parse_tuple_and_keywords: too many keywords in sub_keywords");
         goto exit;
@@ -49,29 +48,56 @@ parse_tuple_and_keywords(PyObject *self, PyObject *args)
 
     for (Py_ssize_t i = 0; i < size; i++) {
         PyObject *o = PySequence_Fast_GET_ITEM(sub_keywords, i);
-        if (!PyUnicode_FSConverter(o, (void *)(converted + i))) {
+        if (PyUnicode_Check(o)) {
+            keywords[i] = (char *)PyUnicode_AsUTF8(o);
+            if (keywords[i] == NULL) {
+                goto exit;
+            }
+        }
+        else if (PyBytes_Check(o)) {
+            keywords[i] = PyBytes_AS_STRING(o);
+        }
+        else {
             PyErr_Format(PyExc_ValueError,
                 "parse_tuple_and_keywords: "
-                "could not convert keywords[%zd] to narrow string", i);
+                "keywords must be str or bytes", i);
             goto exit;
         }
-        keywords[i] = PyBytes_AS_STRING(converted[i]);
     }
 
+    assert(MAX_PARAMS == 8);
     int result = PyArg_ParseTupleAndKeywords(sub_args, sub_kwargs,
         sub_format, keywords,
         buffers + 0, buffers + 1, buffers + 2, buffers + 3,
         buffers + 4, buffers + 5, buffers + 6, buffers + 7);
 
     if (result) {
-        return_value = Py_NewRef(Py_None);
+        int objects_only = 1;
+        for (const char *f = sub_format; *f; f++) {
+            if (Py_ISALNUM(*f) && strchr("OSUY", *f) == NULL) {
+                objects_only = 0;
+                break;
+            }
+        }
+        if (objects_only) {
+            return_value = PyTuple_New(size);
+            if (return_value == NULL) {
+                goto exit;
+            }
+            for (Py_ssize_t i = 0; i < size; i++) {
+                PyObject *arg = *(PyObject **)(buffers + i);
+                if (arg == NULL) {
+                    arg = Py_None;
+                }
+                PyTuple_SET_ITEM(return_value, i, Py_NewRef(arg));
+            }
+        }
+        else {
+            return_value = Py_NewRef(Py_None);
+        }
     }
 
 exit:
-    size = sizeof(converted) / sizeof(converted[0]);
-    for (Py_ssize_t i = 0; i < size; i++) {
-        Py_XDECREF(converted[i]);
-    }
     return return_value;
 }
 
@@ -335,68 +361,83 @@ getargs_K(PyObject *self, PyObject *args)
 static PyObject *
 test_k_code(PyObject *self, PyObject *Py_UNUSED(ignored))
 {
-    PyObject *tuple, *num;
-    unsigned long value;
-
-    tuple = PyTuple_New(1);
+    PyObject *tuple = PyTuple_New(1);
     if (tuple == NULL) {
         return NULL;
     }
 
     /* a number larger than ULONG_MAX even on 64-bit platforms */
-    num = PyLong_FromString("FFFFFFFFFFFFFFFFFFFFFFFF", NULL, 16);
+    PyObject *num = PyLong_FromString("FFFFFFFFFFFFFFFFFFFFFFFF", NULL, 16);
     if (num == NULL) {
-        return NULL;
+        goto error;
     }
 
-    value = PyLong_AsUnsignedLongMask(num);
-    if (value != ULONG_MAX) {
+    unsigned long value = PyLong_AsUnsignedLongMask(num);
+    if (value == (unsigned long)-1 && PyErr_Occurred()) {
+        Py_DECREF(num);
+        goto error;
+    }
+    else if (value != ULONG_MAX) {
+        Py_DECREF(num);
         PyErr_SetString(PyExc_AssertionError,
             "test_k_code: "
             "PyLong_AsUnsignedLongMask() returned wrong value for long 0xFFF...FFF");
-        return NULL;
+        goto error;
     }
 
     PyTuple_SET_ITEM(tuple, 0, num);
 
     value = 0;
     if (!PyArg_ParseTuple(tuple, "k:test_k_code", &value)) {
-        return NULL;
+        goto error;
     }
     if (value != ULONG_MAX) {
         PyErr_SetString(PyExc_AssertionError,
             "test_k_code: k code returned wrong value for long 0xFFF...FFF");
-        return NULL;
+        goto error;
     }
 
-    Py_DECREF(num);
+    Py_DECREF(tuple);  // also clears `num`
+    tuple = PyTuple_New(1);
+    if (tuple == NULL) {
+        return NULL;
+    }
     num = PyLong_FromString("-FFFFFFFF000000000000000042", NULL, 16);
     if (num == NULL) {
-        return NULL;
+        goto error;
     }
 
     value = PyLong_AsUnsignedLongMask(num);
-    if (value != (unsigned long)-0x42) {
+    if (value == (unsigned long)-1 && PyErr_Occurred()) {
+        Py_DECREF(num);
+        goto error;
+    }
+    else if (value != (unsigned long)-0x42) {
+        Py_DECREF(num);
         PyErr_SetString(PyExc_AssertionError,
             "test_k_code: "
             "PyLong_AsUnsignedLongMask() returned wrong value for long -0xFFF..000042");
-        return NULL;
+        goto error;
     }
 
     PyTuple_SET_ITEM(tuple, 0, num);
 
     value = 0;
     if (!PyArg_ParseTuple(tuple, "k:test_k_code", &value)) {
-        return NULL;
+        goto error;
     }
     if (value != (unsigned long)-0x42) {
         PyErr_SetString(PyExc_AssertionError,
             "test_k_code: k code returned wrong value for long -0xFFF..000042");
-        return NULL;
+        goto error;
     }
 
     Py_DECREF(tuple);
     Py_RETURN_NONE;
+
+error:
+    Py_DECREF(tuple);
+    return NULL;
 }
 
 static PyObject *
@@ -734,51 +775,56 @@ getargs_et_hash(PyObject *self, PyObject *args)
 static PyObject *
 test_L_code(PyObject *self, PyObject *Py_UNUSED(ignored))
 {
-    PyObject *tuple, *num;
-    long long value;
-
-    tuple = PyTuple_New(1);
+    PyObject *tuple = PyTuple_New(1);
     if (tuple == NULL) {
         return NULL;
     }
 
-    num = PyLong_FromLong(42);
+    PyObject *num = PyLong_FromLong(42);
     if (num == NULL) {
-        return NULL;
+        goto error;
     }
 
     PyTuple_SET_ITEM(tuple, 0, num);
 
-    value = -1;
+    long long value = -1;
     if (!PyArg_ParseTuple(tuple, "L:test_L_code", &value)) {
-        return NULL;
+        goto error;
     }
     if (value != 42) {
         PyErr_SetString(PyExc_AssertionError,
             "test_L_code: L code returned wrong value for long 42");
-        return NULL;
+        goto error;
     }
 
-    Py_DECREF(num);
+    Py_DECREF(tuple);  // also clears `num`
+    tuple = PyTuple_New(1);
+    if (tuple == NULL) {
+        return NULL;
+    }
     num = PyLong_FromLong(42);
     if (num == NULL) {
-        return NULL;
+        goto error;
     }
 
     PyTuple_SET_ITEM(tuple, 0, num);
 
     value = -1;
     if (!PyArg_ParseTuple(tuple, "L:test_L_code", &value)) {
-        return NULL;
+        goto error;
     }
     if (value != 42) {
         PyErr_SetString(PyExc_AssertionError,
             "test_L_code: L code returned wrong value for int 42");
-        return NULL;
+        goto error;
     }
 
     Py_DECREF(tuple);
     Py_RETURN_NONE;
+
+error:
+    Py_DECREF(tuple);
+    return NULL;
 }
 
 /* Test the s and z codes for PyArg_ParseTuple.
@@ -795,7 +841,7 @@ test_s_code(PyObject *self, PyObject *Py_UNUSED(ignored))
     PyObject *obj = PyUnicode_Decode("t\xeate", strlen("t\xeate"),
                                      "latin-1", NULL);
     if (obj == NULL) {
-        return NULL;
+        goto error;
     }
 
     PyTuple_SET_ITEM(tuple, 0, obj);
@@ -805,15 +851,19 @@ test_s_code(PyObject *self, PyObject *Py_UNUSED(ignored))
      */
     char *value;
     if (!PyArg_ParseTuple(tuple, "s:test_s_code1", &value)) {
-        return NULL;
+        goto error;
     }
 
     if (!PyArg_ParseTuple(tuple, "z:test_s_code2", &value)) {
-        return NULL;
+        goto error;
     }
 
     Py_DECREF(tuple);
     Py_RETURN_NONE;
+
+error:
+    Py_DECREF(tuple);
+    return NULL;
 }
 
 #undef PyArg_ParseTupleAndKeywords
diff --git a/Modules/_testcapi/list.c b/Modules/_testcapi/list.c
new file mode 100644
index 0000000000..6ba0e7ab27
--- /dev/null
+++ b/Modules/_testcapi/list.c
@@ -0,0 +1,195 @@
+#include "parts.h"
+#include "util.h"
+
+static PyObject *
+list_check(PyObject* Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyList_Check(obj));
+}
+
+static PyObject *
+list_check_exact(PyObject* Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyList_CheckExact(obj));
+}
+
+static PyObject *
+list_new(PyObject* Py_UNUSED(module), PyObject *obj)
+{
+    return PyList_New(PyLong_AsSsize_t(obj));
+}
+
+static PyObject *
+list_size(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_SIZE(PyList_Size(obj));
+}
+
+static PyObject *
+list_get_size(PyObject *Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_SIZE(PyList_GET_SIZE(obj));
+}
+
+static PyObject *
+list_getitem(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t i;
+    if (!PyArg_ParseTuple(args, "On", &obj, &i)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    return Py_XNewRef(PyList_GetItem(obj, i));
+}
+
+static PyObject *
+list_get_item(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t i;
+    if (!PyArg_ParseTuple(args, "On", &obj, &i)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    return Py_XNewRef(PyList_GET_ITEM(obj, i));
+}
+
+static PyObject *
+list_setitem(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj, *value;
+    Py_ssize_t i;
+    if (!PyArg_ParseTuple(args, "OnO", &obj, &i, &value)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(value);
+    RETURN_INT(PyList_SetItem(obj, i, Py_XNewRef(value)));
+
+}
+
+static PyObject *
+list_set_item(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj, *value;
+    Py_ssize_t i;
+    if (!PyArg_ParseTuple(args, "OnO", &obj, &i, &value)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(value);
+    PyList_SET_ITEM(obj, i, Py_XNewRef(value));
+    Py_RETURN_NONE;
+
+}
+
+static PyObject *
+list_insert(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj, *value;
+    Py_ssize_t where;
+    if (!PyArg_ParseTuple(args, "OnO", &obj, &where, &value)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(value);
+    RETURN_INT(PyList_Insert(obj, where, Py_XNewRef(value)));
+
+}
+
+static PyObject *
+list_append(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj, *value;
+    if (!PyArg_ParseTuple(args, "OO", &obj, &value)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(value);
+    RETURN_INT(PyList_Append(obj, value));
+}
+
+static PyObject *
+list_getslice(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj;
+    Py_ssize_t ilow, ihigh;
+    if (!PyArg_ParseTuple(args, "Onn", &obj, &ilow, &ihigh)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    return PyList_GetSlice(obj, ilow, ihigh);
+
+}
+
+static PyObject *
+list_setslice(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    PyObject *obj, *value;
+    Py_ssize_t ilow, ihigh;
+    if (!PyArg_ParseTuple(args, "OnnO", &obj, &ilow, &ihigh, &value)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(value);
+    RETURN_INT(PyList_SetSlice(obj, ilow, ihigh, value));
+}
+
+static PyObject *
+list_sort(PyObject* Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PyList_Sort(obj));
+}
+
+static PyObject *
+list_reverse(PyObject* Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PyList_Reverse(obj));
+}
+
+static PyObject *
+list_astuple(PyObject* Py_UNUSED(module), PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyList_AsTuple(obj);
+}
+
+
+
+
+static PyMethodDef test_methods[] = {
+    {"list_check", list_check, METH_O},
+    {"list_check_exact", list_check_exact, METH_O},
+    {"list_new", list_new, METH_O},
+    {"list_size", list_size, METH_O},
+    {"list_get_size", list_get_size, METH_O},
+    {"list_getitem", list_getitem, METH_VARARGS},
+    {"list_get_item", list_get_item, METH_VARARGS},
+    {"list_setitem", list_setitem, METH_VARARGS},
+    {"list_set_item", list_set_item, METH_VARARGS},
+    {"list_insert", list_insert, METH_VARARGS},
+    {"list_append", list_append, METH_VARARGS},
+    {"list_getslice", list_getslice, METH_VARARGS},
+    {"list_setslice", list_setslice, METH_VARARGS},
+    {"list_sort", list_sort, METH_O},
+    {"list_reverse", list_reverse, METH_O},
+    {"list_astuple", list_astuple, METH_O},
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_List(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/long.c b/Modules/_testcapi/long.c
index 61dd96596d..213c676e5c 100644
--- a/Modules/_testcapi/long.c
+++ b/Modules/_testcapi/long.c
@@ -1,4 +1,6 @@
+#define PY_SSIZE_T_CLEAN
 #include "parts.h"
+#include "util.h"
 
 
 static PyObject *
@@ -546,6 +548,208 @@ check_long_compact_api(PyObject *self, PyObject *arg)
     return Py_BuildValue("in", is_compact, value);
 }
 
+static PyObject *
+pylong_check(PyObject *module, PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyLong_Check(obj));
+}
+
+static PyObject *
+pylong_checkexact(PyObject *module, PyObject *obj)
+{
+    NULLABLE(obj);
+    return PyLong_FromLong(PyLong_CheckExact(obj));
+}
+
+static PyObject *
+pylong_fromdouble(PyObject *module, PyObject *arg)
+{
+    double value;
+    if (!PyArg_Parse(arg, "d", &value)) {
+        return NULL;
+    }
+    return PyLong_FromDouble(value);
+}
+
+static PyObject *
+pylong_fromstring(PyObject *module, PyObject *args)
+{
+    const char *str;
+    Py_ssize_t len;
+    int base;
+    char *end = UNINITIALIZED_PTR;
+    if (!PyArg_ParseTuple(args, "z#i", &str, &len, &base)) {
+        return NULL;
+    }
+
+    PyObject *result = PyLong_FromString(str, &end, base);
+    if (result == NULL) {
+        // XXX 'end' is not always set.
+        return NULL;
+    }
+    return Py_BuildValue("Nn", result, (Py_ssize_t)(end - str));
+}
+
+static PyObject *
+pylong_fromunicodeobject(PyObject *module, PyObject *args)
+{
+    PyObject *unicode;
+    int base;
+    if (!PyArg_ParseTuple(args, "Oi", &unicode, &base)) {
+        return NULL;
+    }
+
+    NULLABLE(unicode);
+    return PyLong_FromUnicodeObject(unicode, base);
+}
+
+static PyObject *
+pylong_fromvoidptr(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    return PyLong_FromVoidPtr((void *)arg);
+}
+
+static PyObject *
+pylong_aslong(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    long value = PyLong_AsLong(arg);
+    if (value == -1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromLong(value);
+}
+
+static PyObject *
+pylong_aslongandoverflow(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    int overflow = UNINITIALIZED_INT;
+    long value = PyLong_AsLongAndOverflow(arg, &overflow);
+    if (value == -1 && PyErr_Occurred()) {
+        assert(overflow == -1);
+        return NULL;
+    }
+    return Py_BuildValue("li", value, overflow);
+}
+
+static PyObject *
+pylong_asunsignedlong(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    unsigned long value = PyLong_AsUnsignedLong(arg);
+    if (value == (unsigned long)-1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromUnsignedLong(value);
+}
+
+static PyObject *
+pylong_asunsignedlongmask(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    unsigned long value = PyLong_AsUnsignedLongMask(arg);
+    if (value == (unsigned long)-1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromUnsignedLong(value);
+}
+
+static PyObject *
+pylong_aslonglong(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    long long value = PyLong_AsLongLong(arg);
+    if (value == -1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromLongLong(value);
+}
+
+static PyObject *
+pylong_aslonglongandoverflow(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    int overflow = UNINITIALIZED_INT;
+    long long value = PyLong_AsLongLongAndOverflow(arg, &overflow);
+    if (value == -1 && PyErr_Occurred()) {
+        assert(overflow == -1);
+        return NULL;
+    }
+    return Py_BuildValue("Li", value, overflow);
+}
+
+static PyObject *
+pylong_asunsignedlonglong(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    unsigned long long value = PyLong_AsUnsignedLongLong(arg);
+    if (value == (unsigned long long)-1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromUnsignedLongLong(value);
+}
+
+static PyObject *
+pylong_asunsignedlonglongmask(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    unsigned long long value = PyLong_AsUnsignedLongLongMask(arg);
+    if (value == (unsigned long long)-1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromUnsignedLongLong(value);
+}
+
+static PyObject *
+pylong_as_ssize_t(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    Py_ssize_t value = PyLong_AsSsize_t(arg);
+    if (value == -1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromSsize_t(value);
+}
+
+static PyObject *
+pylong_as_size_t(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    size_t value = PyLong_AsSize_t(arg);
+    if (value == (size_t)-1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromSize_t(value);
+}
+
+static PyObject *
+pylong_asdouble(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    double value = PyLong_AsDouble(arg);
+    if (value == -1.0 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyFloat_FromDouble(value);
+}
+
+static PyObject *
+pylong_asvoidptr(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    void *value = PyLong_AsVoidPtr(arg);
+    if (value == NULL) {
+        if (PyErr_Occurred()) {
+            return NULL;
+        }
+        Py_RETURN_NONE;
+    }
+    return Py_NewRef((PyObject *)value);
+}
+
 static PyMethodDef test_methods[] = {
     {"test_long_and_overflow",  test_long_and_overflow,          METH_NOARGS},
     {"test_long_api",           test_long_api,                   METH_NOARGS},
@@ -556,6 +760,24 @@ static PyMethodDef test_methods[] = {
     {"test_long_numbits",       test_long_numbits,               METH_NOARGS},
     {"test_longlong_api",       test_longlong_api,               METH_NOARGS},
     {"call_long_compact_api",   check_long_compact_api,          METH_O},
+    {"pylong_check",                pylong_check,               METH_O},
+    {"pylong_checkexact",           pylong_checkexact,          METH_O},
+    {"pylong_fromdouble",           pylong_fromdouble,          METH_O},
+    {"pylong_fromstring",           pylong_fromstring,          METH_VARARGS},
+    {"pylong_fromunicodeobject",    pylong_fromunicodeobject,   METH_VARARGS},
+    {"pylong_fromvoidptr",          pylong_fromvoidptr,         METH_O},
+    {"pylong_aslong",               pylong_aslong,              METH_O},
+    {"pylong_aslongandoverflow",    pylong_aslongandoverflow,   METH_O},
+    {"pylong_asunsignedlong",       pylong_asunsignedlong,      METH_O},
+    {"pylong_asunsignedlongmask",   pylong_asunsignedlongmask,  METH_O},
+    {"pylong_aslonglong",           pylong_aslonglong,          METH_O},
+    {"pylong_aslonglongandoverflow", pylong_aslonglongandoverflow, METH_O},
+    {"pylong_asunsignedlonglong",   pylong_asunsignedlonglong,  METH_O},
+    {"pylong_asunsignedlonglongmask", pylong_asunsignedlonglongmask, METH_O},
+    {"pylong_as_ssize_t",           pylong_as_ssize_t,          METH_O},
+    {"pylong_as_size_t",            pylong_as_size_t,           METH_O},
+    {"pylong_asdouble",             pylong_asdouble,            METH_O},
+    {"pylong_asvoidptr",            pylong_asvoidptr,           METH_O},
     {NULL},
 };
 
diff --git a/Modules/_testcapi/numbers.c b/Modules/_testcapi/numbers.c
new file mode 100644
index 0000000000..6f7fa3fa7a
--- /dev/null
+++ b/Modules/_testcapi/numbers.c
@@ -0,0 +1,16 @@
+#include "parts.h"
+#include "util.h"
+
+static PyMethodDef test_methods[] = {
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Numbers(PyObject *mod)
+{
+    if (PyModule_AddFunctions(mod, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/parts.h b/Modules/_testcapi/parts.h
index f37be9b67a..1dd0995b87 100644
--- a/Modules/_testcapi/parts.h
+++ b/Modules/_testcapi/parts.h
@@ -27,6 +27,8 @@
 int _PyTestCapi_Init_Vectorcall(PyObject *module);
 int _PyTestCapi_Init_Heaptype(PyObject *module);
 int _PyTestCapi_Init_Abstract(PyObject *module);
+int _PyTestCapi_Init_ByteArray(PyObject *module);
+int _PyTestCapi_Init_Bytes(PyObject *module);
 int _PyTestCapi_Init_Unicode(PyObject *module);
 int _PyTestCapi_Init_GetArgs(PyObject *module);
 int _PyTestCapi_Init_PyTime(PyObject *module);
@@ -36,14 +38,22 @@ int _PyTestCapi_Init_Mem(PyObject *module);
 int _PyTestCapi_Init_Watchers(PyObject *module);
 int _PyTestCapi_Init_Long(PyObject *module);
 int _PyTestCapi_Init_Float(PyObject *module);
+int _PyTestCapi_Init_Complex(PyObject *module);
+int _PyTestCapi_Init_Numbers(PyObject *module);
 int _PyTestCapi_Init_Dict(PyObject *module);
+int _PyTestCapi_Init_Set(PyObject *module);
+int _PyTestCapi_Init_List(PyObject *module);
+int _PyTestCapi_Init_Tuple(PyObject *module);
 int _PyTestCapi_Init_Structmember(PyObject *module);
 int _PyTestCapi_Init_Exceptions(PyObject *module);
 int _PyTestCapi_Init_Code(PyObject *module);
 int _PyTestCapi_Init_Buffer(PyObject *module);
 int _PyTestCapi_Init_PyOS(PyObject *module);
+int _PyTestCapi_Init_File(PyObject *module);
+int _PyTestCapi_Init_Codec(PyObject *module);
 int _PyTestCapi_Init_Immortal(PyObject *module);
-int _PyTestCapi_Init_GC(PyObject *mod);
+int _PyTestCapi_Init_GC(PyObject *module);
+int _PyTestCapi_Init_Sys(PyObject *module);
 
 #ifdef LIMITED_API_AVAILABLE
 int _PyTestCapi_Init_VectorcallLimited(PyObject *module);
diff --git a/Modules/_testcapi/set.c b/Modules/_testcapi/set.c
new file mode 100644
index 0000000000..2fbd0aeffc
--- /dev/null
+++ b/Modules/_testcapi/set.c
@@ -0,0 +1,197 @@
+#include "parts.h"
+#include "util.h"
+
+static PyObject *
+set_check(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PySet_Check(obj));
+}
+
+static PyObject *
+set_checkexact(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PySet_CheckExact(obj));
+}
+
+static PyObject *
+frozenset_check(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PyFrozenSet_Check(obj));
+}
+
+static PyObject *
+frozenset_checkexact(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PyFrozenSet_CheckExact(obj));
+}
+
+static PyObject *
+anyset_check(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PyAnySet_Check(obj));
+}
+
+static PyObject *
+anyset_checkexact(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PyAnySet_CheckExact(obj));
+}
+
+static PyObject *
+set_new(PyObject *self, PyObject *args)
+{
+    PyObject *iterable = NULL;
+    if (!PyArg_ParseTuple(args, "|O", &iterable)) {
+        return NULL;
+    }
+    return PySet_New(iterable);
+}
+
+static PyObject *
+frozenset_new(PyObject *self, PyObject *args)
+{
+    PyObject *iterable = NULL;
+    if (!PyArg_ParseTuple(args, "|O", &iterable)) {
+        return NULL;
+    }
+    return PyFrozenSet_New(iterable);
+}
+
+static PyObject *
+set_size(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_SIZE(PySet_Size(obj));
+}
+
+static PyObject *
+set_get_size(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_SIZE(PySet_GET_SIZE(obj));
+}
+
+static PyObject *
+set_contains(PyObject *self, PyObject *args)
+{
+    PyObject *obj, *item;
+    if (!PyArg_ParseTuple(args, "OO", &obj, &item)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(item);
+    RETURN_INT(PySet_Contains(obj, item));
+}
+
+static PyObject *
+set_add(PyObject *self, PyObject *args)
+{
+    PyObject *obj, *item;
+    if (!PyArg_ParseTuple(args, "OO", &obj, &item)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(item);
+    RETURN_INT(PySet_Add(obj, item));
+}
+
+static PyObject *
+set_discard(PyObject *self, PyObject *args)
+{
+    PyObject *obj, *item;
+    if (!PyArg_ParseTuple(args, "OO", &obj, &item)) {
+        return NULL;
+    }
+    NULLABLE(obj);
+    NULLABLE(item);
+    RETURN_INT(PySet_Discard(obj, item));
+}
+
+static PyObject *
+set_pop(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    return PySet_Pop(obj);
+}
+
+static PyObject *
+set_clear(PyObject *self, PyObject *obj)
+{
+    NULLABLE(obj);
+    RETURN_INT(PySet_Clear(obj));
+}
+
+static PyObject *
+test_frozenset_add_in_capi(PyObject *self, PyObject *Py_UNUSED(obj))
+{
+    // Test that `frozenset` can be used with `PySet_Add`,
+    // when frozenset is just created in CAPI.
+    PyObject *fs = PyFrozenSet_New(NULL);
+    if (fs == NULL) {
+        return NULL;
+    }
+    PyObject *num = PyLong_FromLong(1);
+    if (num == NULL) {
+        goto error;
+    }
+    if (PySet_Add(fs, num) < 0) {
+        goto error;
+    }
+    int contains = PySet_Contains(fs, num);
+    if (contains < 0) {
+        goto error;
+    }
+    else if (contains == 0) {
+        goto unexpected;
+    }
+    Py_DECREF(fs);
+    Py_DECREF(num);
+    Py_RETURN_NONE;
+
+unexpected:
+    PyErr_SetString(PyExc_ValueError, "set does not contain expected value");
+error:
+    Py_DECREF(fs);
+    Py_XDECREF(num);
+    return NULL;
+}
+
+static PyMethodDef test_methods[] = {
+    {"set_check", set_check, METH_O},
+    {"set_checkexact", set_checkexact, METH_O},
+    {"frozenset_check", frozenset_check, METH_O},
+    {"frozenset_checkexact", frozenset_checkexact, METH_O},
+    {"anyset_check", anyset_check, METH_O},
+    {"anyset_checkexact", anyset_checkexact, METH_O},
+
+    {"set_new", set_new, METH_VARARGS},
+    {"frozenset_new", frozenset_new, METH_VARARGS},
+
+    {"set_size", set_size, METH_O},
+    {"set_get_size", set_get_size, METH_O},
+    {"set_contains", set_contains, METH_VARARGS},
+    {"set_add", set_add, METH_VARARGS},
+    {"set_discard", set_discard, METH_VARARGS},
+    {"set_pop", set_pop, METH_O},
+    {"set_clear", set_clear, METH_O},
+
+    {"test_frozenset_add_in_capi", test_frozenset_add_in_capi, METH_NOARGS},
+
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Set(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/sys.c b/Modules/_testcapi/sys.c
new file mode 100644
index 0000000000..53a2ccb2e2
--- /dev/null
+++ b/Modules/_testcapi/sys.c
@@ -0,0 +1,57 @@
+#define PY_SSIZE_T_CLEAN
+#include "parts.h"
+#include "util.h"
+
+
+static PyObject *
+sys_getobject(PyObject *Py_UNUSED(module), PyObject *arg)
+{
+    const char *name;
+    Py_ssize_t size;
+    if (!PyArg_Parse(arg, "z#", &name, &size)) {
+        return NULL;
+    }
+    PyObject *result = PySys_GetObject(name);
+    if (result == NULL) {
+        result = PyExc_AttributeError;
+    }
+    return Py_NewRef(result);
+}
+
+static PyObject *
+sys_setobject(PyObject *Py_UNUSED(module), PyObject *args)
+{
+    const char *name;
+    Py_ssize_t size;
+    PyObject *value;
+    if (!PyArg_ParseTuple(args, "z#O", &name, &size, &value)) {
+        return NULL;
+    }
+    NULLABLE(value);
+    RETURN_INT(PySys_SetObject(name, value));
+}
+
+static PyObject *
+sys_getxoptions(PyObject *Py_UNUSED(module), PyObject *Py_UNUSED(ignored))
+{
+    PyObject *result = PySys_GetXOptions();
+    return Py_XNewRef(result);
+}
+
+
+static PyMethodDef test_methods[] = {
+    {"sys_getobject", sys_getobject, METH_O},
+    {"sys_setobject", sys_setobject, METH_VARARGS},
+    {"sys_getxoptions", sys_getxoptions, METH_NOARGS},
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Sys(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0) {
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/tuple.c b/Modules/_testcapi/tuple.c
new file mode 100644
index 0000000000..95dde8c0ed
--- /dev/null
+++ b/Modules/_testcapi/tuple.c
@@ -0,0 +1,17 @@
+#include "parts.h"
+#include "util.h"
+
+
+static PyMethodDef test_methods[] = {
+    {NULL},
+};
+
+int
+_PyTestCapi_Init_Tuple(PyObject *m)
+{
+    if (PyModule_AddFunctions(m, test_methods) < 0){
+        return -1;
+    }
+
+    return 0;
+}
diff --git a/Modules/_testcapi/util.h b/Modules/_testcapi/util.h
index 4cf7e22638..f26d7656a1 100644
--- a/Modules/_testcapi/util.h
+++ b/Modules/_testcapi/util.h
@@ -25,7 +25,8 @@
     } while (0)
 
 /* Marker to check that pointer value was set. */
-#define UNINITIALIZED_PTR ((void *)"uninitialized")
+static const char uninitialized[] = "uninitialized";
+#define UNINITIALIZED_PTR ((void *)uninitialized)
 /* Marker to check that Py_ssize_t value was set. */
 #define UNINITIALIZED_SIZE ((Py_ssize_t)236892191)
 /* Marker to check that integer value was set. */
diff --git a/Modules/_testcapimodule.c b/Modules/_testcapimodule.c
index c73b297ada..b1cb9350e5 100644
--- a/Modules/_testcapimodule.c
+++ b/Modules/_testcapimodule.c
@@ -423,6 +423,41 @@ raise_error(void *unused)
     return NULL;
 }
 
+static PyObject *
+py_buildvalue(PyObject *self, PyObject *args)
+{
+    const char *fmt;
+    PyObject *objs[10] = {NULL};
+    if (!PyArg_ParseTuple(args, "s|OOOOOOOOOO", &fmt,
+            &objs[0], &objs[1], &objs[2], &objs[3], &objs[4],
+            &objs[5], &objs[6], &objs[7], &objs[8], &objs[9]))
+    {
+        return NULL;
+    }
+    for(int i = 0; i < 10; i++) {
+        NULLABLE(objs[i]);
+    }
+    return Py_BuildValue(fmt,
+            objs[0], objs[1], objs[2], objs[3], objs[4],
+            objs[5], objs[6], objs[7], objs[8], objs[9]);
+}
+
+static PyObject *
+py_buildvalue_ints(PyObject *self, PyObject *args)
+{
+    const char *fmt;
+    unsigned int values[10] = {0};
+    if (!PyArg_ParseTuple(args, "s|IIIIIIIIII", &fmt,
+            &values[0], &values[1], &values[2], &values[3], &values[4],
+            &values[5], &values[6], &values[7], &values[8], &values[9]))
+    {
+        return NULL;
+    }
+    return Py_BuildValue(fmt,
+            values[0], values[1], values[2], values[3], values[4],
+            values[5], values[6], values[7], values[8], values[9]);
+}
+
 static int
 test_buildvalue_N_error(const char *fmt)
 {
@@ -3208,35 +3243,6 @@ test_atexit(PyObject *self, PyObject *Py_UNUSED(args))
 }
 
 
-static PyObject *
-sys_getobject(PyObject *Py_UNUSED(module), PyObject *arg)
-{
-    const char *name;
-    Py_ssize_t size;
-    if (!PyArg_Parse(arg, "z#", &name, &size)) {
-        return NULL;
-    }
-    PyObject *result = PySys_GetObject(name);
-    if (result == NULL) {
-        result = PyExc_AttributeError;
-    }
-    return Py_NewRef(result);
-}
-
-static PyObject *
-sys_setobject(PyObject *Py_UNUSED(module), PyObject *args)
-{
-    const char *name;
-    Py_ssize_t size;
-    PyObject *value;
-    if (!PyArg_ParseTuple(args, "z#O", &name, &size, &value)) {
-        return NULL;
-    }
-    NULLABLE(value);
-    RETURN_INT(PySys_SetObject(name, value));
-}
-
-
 static PyObject *test_buildvalue_issue38913(PyObject *, PyObject *);
 
 static PyMethodDef TestMethods[] = {
@@ -3267,6 +3273,8 @@ static PyMethodDef TestMethods[] = {
 #endif
     {"getbuffer_with_null_view", getbuffer_with_null_view,       METH_O},
     {"PyBuffer_SizeFromFormat",  test_PyBuffer_SizeFromFormat,   METH_VARARGS},
+    {"py_buildvalue",            py_buildvalue,                  METH_VARARGS},
+    {"py_buildvalue_ints",       py_buildvalue_ints,             METH_VARARGS},
     {"test_buildvalue_N",        test_buildvalue_N,              METH_NOARGS},
     {"test_buildvalue_issue38913", test_buildvalue_issue38913,   METH_NOARGS},
     {"test_get_statictype_slots", test_get_statictype_slots,     METH_NOARGS},
@@ -3373,8 +3381,6 @@ static PyMethodDef TestMethods[] = {
     {"function_get_kw_defaults", function_get_kw_defaults, METH_O, NULL},
     {"function_set_kw_defaults", function_set_kw_defaults, METH_VARARGS, NULL},
     {"test_atexit", test_atexit, METH_NOARGS},
-    {"sys_getobject", sys_getobject, METH_O},
-    {"sys_setobject", sys_setobject, METH_VARARGS},
     {NULL, NULL} /* sentinel */
 };
 
@@ -3941,7 +3947,9 @@ PyInit__testcapi(void)
     PyModule_AddObject(m, "ULLONG_MAX", PyLong_FromUnsignedLongLong(ULLONG_MAX));
     PyModule_AddObject(m, "PY_SSIZE_T_MAX", PyLong_FromSsize_t(PY_SSIZE_T_MAX));
     PyModule_AddObject(m, "PY_SSIZE_T_MIN", PyLong_FromSsize_t(PY_SSIZE_T_MIN));
+    PyModule_AddObject(m, "SIZE_MAX", PyLong_FromSize_t(SIZE_MAX));
     PyModule_AddObject(m, "SIZEOF_WCHAR_T", PyLong_FromSsize_t(sizeof(wchar_t)));
+    PyModule_AddObject(m, "SIZEOF_VOID_P", PyLong_FromSsize_t(sizeof(void*)));
     PyModule_AddObject(m, "SIZEOF_TIME_T", PyLong_FromSsize_t(sizeof(time_t)));
     PyModule_AddObject(m, "Py_Version", PyLong_FromUnsignedLong(Py_Version));
     Py_INCREF(&PyInstanceMethod_Type);
@@ -3971,6 +3979,12 @@ PyInit__testcapi(void)
     if (_PyTestCapi_Init_Abstract(m) < 0) {
         return NULL;
     }
+    if (_PyTestCapi_Init_ByteArray(m) < 0) {
+        return NULL;
+    }
+    if (_PyTestCapi_Init_Bytes(m) < 0) {
+        return NULL;
+    }
     if (_PyTestCapi_Init_Unicode(m) < 0) {
         return NULL;
     }
@@ -3998,9 +4012,24 @@ PyInit__testcapi(void)
     if (_PyTestCapi_Init_Float(m) < 0) {
         return NULL;
     }
+    if (_PyTestCapi_Init_Complex(m) < 0) {
+        return NULL;
+    }
+    if (_PyTestCapi_Init_Numbers(m) < 0) {
+        return NULL;
+    }
     if (_PyTestCapi_Init_Dict(m) < 0) {
         return NULL;
     }
+    if (_PyTestCapi_Init_Set(m) < 0) {
+        return NULL;
+    }
+    if (_PyTestCapi_Init_List(m) < 0) {
+        return NULL;
+    }
+    if (_PyTestCapi_Init_Tuple(m) < 0) {
+        return NULL;
+    }
     if (_PyTestCapi_Init_Structmember(m) < 0) {
         return NULL;
     }
@@ -4016,6 +4045,15 @@ PyInit__testcapi(void)
     if (_PyTestCapi_Init_PyOS(m) < 0) {
         return NULL;
     }
+    if (_PyTestCapi_Init_File(m) < 0) {
+        return NULL;
+    }
+    if (_PyTestCapi_Init_Codec(m) < 0) {
+        return NULL;
+    }
+    if (_PyTestCapi_Init_Sys(m) < 0) {
+        return NULL;
+    }
     if (_PyTestCapi_Init_Immortal(m) < 0) {
         return NULL;
     }
diff --git a/Modules/_testinternalcapi.c b/Modules/_testinternalcapi.c
index 4e063a8615..22d156725f 100644
--- a/Modules/_testinternalcapi.c
+++ b/Modules/_testinternalcapi.c
@@ -683,7 +683,11 @@ record_eval(PyThreadState *tstate, struct _PyInterpreterFrame *f, int exc)
         assert(module != NULL);
         module_state *state = get_module_state(module);
         Py_DECREF(module);
-        PyList_Append(state->record_list, ((PyFunctionObject *)f->f_funcobj)->func_name);
+        int res = PyList_Append(state->record_list,
+                                ((PyFunctionObject *)f->f_funcobj)->func_name);
+        if (res < 0) {
+            return NULL;
+        }
     }
     return _PyEval_EvalFrameDefault(tstate, f, exc);
 }
diff --git a/Modules/_threadmodule.c b/Modules/_threadmodule.c
index 04f4400a93..5edb6e9875 100644
--- a/Modules/_threadmodule.c
+++ b/Modules/_threadmodule.c
@@ -486,6 +486,18 @@ PyDoc_STRVAR(rlock_release_save_doc,
 \n\
 For internal use by `threading.Condition`.");
 
+static PyObject *
+rlock_recursion_count(rlockobject *self, PyObject *Py_UNUSED(ignored))
+{
+    unsigned long tid = PyThread_get_thread_ident();
+    return PyLong_FromUnsignedLong(
+        self->rlock_owner == tid ? self->rlock_count : 0UL);
+}
+
+PyDoc_STRVAR(rlock_recursion_count_doc,
+"_recursion_count() -> int\n\
+\n\
+For internal use by reentrancy checks.");
 
 static PyObject *
 rlock_is_owned(rlockobject *self, PyObject *Py_UNUSED(ignored))
@@ -561,6 +573,8 @@ static PyMethodDef rlock_methods[] = {
      METH_VARARGS, rlock_acquire_restore_doc},
     {"_release_save", (PyCFunction)rlock_release_save,
      METH_NOARGS, rlock_release_save_doc},
+    {"_recursion_count", (PyCFunction)rlock_recursion_count,
+     METH_NOARGS, rlock_recursion_count_doc},
     {"__enter__",    _PyCFunction_CAST(rlock_acquire),
      METH_VARARGS | METH_KEYWORDS, rlock_acquire_doc},
     {"__exit__",    (PyCFunction)rlock_release,
@@ -1049,22 +1063,22 @@ _localdummy_destroyed(PyObject *localweakref, PyObject *dummyweakref)
 /* Module functions */
 
 struct bootstate {
-    PyInterpreterState *interp;
+    PyThreadState *tstate;
     PyObject *func;
     PyObject *args;
     PyObject *kwargs;
-    PyThreadState *tstate;
-    _PyRuntimeState *runtime;
 };
 
 
 static void
-thread_bootstate_free(struct bootstate *boot)
+thread_bootstate_free(struct bootstate *boot, int decref)
 {
-    Py_DECREF(boot->func);
-    Py_DECREF(boot->args);
-    Py_XDECREF(boot->kwargs);
-    PyMem_Free(boot);
+    if (decref) {
+        Py_DECREF(boot->func);
+        Py_DECREF(boot->args);
+        Py_XDECREF(boot->kwargs);
+    }
+    PyMem_RawFree(boot);
 }
 
 
@@ -1072,9 +1086,27 @@ static void
 thread_run(void *boot_raw)
 {
     struct bootstate *boot = (struct bootstate *) boot_raw;
-    PyThreadState *tstate;
+    PyThreadState *tstate = boot->tstate;
+
+    // gh-108987: If _thread.start_new_thread() is called before or while
+    // Python is being finalized, thread_run() can called *after*.
+    // _PyRuntimeState_SetFinalizing() is called. At this point, all Python
+    // threads must exit, except of the thread calling Py_Finalize() whch holds
+    // the GIL and must not exit.
+    //
+    // At this stage, tstate can be a dangling pointer (point to freed memory),
+    // it's ok to call _PyThreadState_MustExit() with a dangling pointer.
+    if (_PyThreadState_MustExit(tstate)) {
+        // Don't call PyThreadState_Clear() nor _PyThreadState_DeleteCurrent().
+        // These functions are called on tstate indirectly by Py_Finalize()
+        // which calls _PyInterpreterState_Clear().
+        //
+        // Py_DECREF() cannot be called because the GIL is not held: leak
+        // references on purpose. Python is being finalized anyway.
+        thread_bootstate_free(boot, 0);
+        goto exit;
+    }
 
-    tstate = boot->tstate;
     _PyThreadState_Bind(tstate);
     PyEval_AcquireThread(tstate);
     tstate->interp->threads.count++;
@@ -1092,14 +1124,17 @@ thread_run(void *boot_raw)
         Py_DECREF(res);
     }
 
-    thread_bootstate_free(boot);
+    thread_bootstate_free(boot, 1);
+
     tstate->interp->threads.count--;
     PyThreadState_Clear(tstate);
     _PyThreadState_DeleteCurrent(tstate);
 
+exit:
     // bpo-44434: Don't call explicitly PyThread_exit_thread(). On Linux with
     // the glibc, pthread_exit() can abort the whole process if dlopen() fails
     // to open the libgcc_s.so library (ex: EMFILE error).
+    return;
 }
 
 static PyObject *
@@ -1123,7 +1158,6 @@ and False otherwise.\n");
 static PyObject *
 thread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)
 {
-    _PyRuntimeState *runtime = &_PyRuntime;
     PyObject *func, *args, *kwargs = NULL;
 
     if (!PyArg_UnpackTuple(fargs, "start_new_thread", 2, 3,
@@ -1162,20 +1196,21 @@ thread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)
         return NULL;
     }
 
-    struct bootstate *boot = PyMem_NEW(struct bootstate, 1);
+    // gh-109795: Use PyMem_RawMalloc() instead of PyMem_Malloc(),
+    // because it should be possible to call thread_bootstate_free()
+    // without holding the GIL.
+    struct bootstate *boot = PyMem_RawMalloc(sizeof(struct bootstate));
     if (boot == NULL) {
         return PyErr_NoMemory();
     }
-    boot->interp = _PyInterpreterState_GET();
-    boot->tstate = _PyThreadState_New(boot->interp);
+    boot->tstate = _PyThreadState_New(interp);
     if (boot->tstate == NULL) {
-        PyMem_Free(boot);
+        PyMem_RawFree(boot);
         if (!PyErr_Occurred()) {
             return PyErr_NoMemory();
         }
         return NULL;
     }
-    boot->runtime = runtime;
     boot->func = Py_NewRef(func);
     boot->args = Py_NewRef(args);
     boot->kwargs = Py_XNewRef(kwargs);
@@ -1184,7 +1219,7 @@ thread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)
     if (ident == PYTHREAD_INVALID_THREAD_ID) {
         PyErr_SetString(ThreadError, "can't start new thread");
         PyThreadState_Clear(boot->tstate);
-        thread_bootstate_free(boot);
+        thread_bootstate_free(boot, 1);
         return NULL;
     }
     return PyLong_FromUnsignedLong(ident);
diff --git a/Modules/_xxtestfuzz/fuzzer.c b/Modules/_xxtestfuzz/fuzzer.c
index 37d4028248..cd97206d18 100644
--- a/Modules/_xxtestfuzz/fuzzer.c
+++ b/Modules/_xxtestfuzz/fuzzer.c
@@ -188,37 +188,33 @@ static int fuzz_json_loads(const char* data, size_t size) {
 
 #define MAX_RE_TEST_SIZE 0x10000
 
-PyObject* sre_compile_method = NULL;
-PyObject* sre_error_exception = NULL;
-int SRE_FLAG_DEBUG = 0;
+PyObject* re_compile_method = NULL;
+PyObject* re_error_exception = NULL;
+int RE_FLAG_DEBUG = 0;
 /* Called by LLVMFuzzerTestOneInput for initialization */
 static int init_sre_compile(void) {
     /* Import sre_compile.compile and sre.error */
-    PyObject* sre_compile_module = PyImport_ImportModule("sre_compile");
-    if (sre_compile_module == NULL) {
+    PyObject* re_module = PyImport_ImportModule("re");
+    if (re_module == NULL) {
         return 0;
     }
-    sre_compile_method = PyObject_GetAttrString(sre_compile_module, "compile");
-    if (sre_compile_method == NULL) {
+    re_compile_method = PyObject_GetAttrString(re_module, "compile");
+    if (re_compile_method == NULL) {
         return 0;
     }
 
-    PyObject* sre_constants = PyImport_ImportModule("sre_constants");
-    if (sre_constants == NULL) {
+    re_error_exception = PyObject_GetAttrString(re_module, "error");
+    if (re_error_exception == NULL) {
         return 0;
     }
-    sre_error_exception = PyObject_GetAttrString(sre_constants, "error");
-    if (sre_error_exception == NULL) {
-        return 0;
-    }
-    PyObject* debug_flag = PyObject_GetAttrString(sre_constants, "SRE_FLAG_DEBUG");
+    PyObject* debug_flag = PyObject_GetAttrString(re_module, "DEBUG");
     if (debug_flag == NULL) {
         return 0;
     }
-    SRE_FLAG_DEBUG = PyLong_AsLong(debug_flag);
+    RE_FLAG_DEBUG = PyLong_AsLong(debug_flag);
     return 1;
 }
-/* Fuzz _sre.compile(x) */
+/* Fuzz re.compile(x) */
 static int fuzz_sre_compile(const char* data, size_t size) {
     /* Ignore really long regex patterns that will timeout the fuzzer */
     if (size > MAX_RE_TEST_SIZE) {
@@ -231,7 +227,7 @@ static int fuzz_sre_compile(const char* data, size_t size) {
     uint16_t flags = ((uint16_t*) data)[0];
     /* We remove the SRE_FLAG_DEBUG if present. This is because it
        prints to stdout which greatly decreases fuzzing speed */
-    flags &= ~SRE_FLAG_DEBUG;
+    flags &= ~RE_FLAG_DEBUG;
 
     /* Pull the pattern from the remaining bytes */
     PyObject* pattern_bytes = PyBytes_FromStringAndSize(data + 2, size - 2);
@@ -244,9 +240,9 @@ static int fuzz_sre_compile(const char* data, size_t size) {
         return 0;
     }
 
-    /* compiled = _sre.compile(data[2:], data[0:2] */
+    /* compiled = re.compile(data[2:], data[0:2] */
     PyObject* compiled = PyObject_CallFunctionObjArgs(
-        sre_compile_method, pattern_bytes, flags_obj, NULL);
+        re_compile_method, pattern_bytes, flags_obj, NULL);
     /* Ignore ValueError as the fuzzer will more than likely
        generate some invalid combination of flags */
     if (compiled == NULL && PyErr_ExceptionMatches(PyExc_ValueError)) {
@@ -262,7 +258,7 @@ static int fuzz_sre_compile(const char* data, size_t size) {
         PyErr_Clear();
     }
     /* Ignore re.error */
-    if (compiled == NULL && PyErr_ExceptionMatches(sre_error_exception)) {
+    if (compiled == NULL && PyErr_ExceptionMatches(re_error_exception)) {
         PyErr_Clear();
     }
 
@@ -526,13 +522,8 @@ int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {
 #if !defined(_Py_FUZZ_ONE) || defined(_Py_FUZZ_fuzz_sre_compile)
     static int SRE_COMPILE_INITIALIZED = 0;
     if (!SRE_COMPILE_INITIALIZED && !init_sre_compile()) {
-        if (!PyErr_ExceptionMatches(PyExc_DeprecationWarning)) {
-            PyErr_Print();
-            abort();
-        }
-        else {
-            PyErr_Clear();
-        }
+        PyErr_Print();
+        abort();
     } else {
         SRE_COMPILE_INITIALIZED = 1;
     }
diff --git a/Modules/_zoneinfo.c b/Modules/_zoneinfo.c
index 38b806c244..8fc8616241 100644
--- a/Modules/_zoneinfo.c
+++ b/Modules/_zoneinfo.c
@@ -62,21 +62,21 @@ struct TransitionRuleType {
 
 typedef struct {
     TransitionRuleType base;
-    uint8_t month;
-    uint8_t week;
-    uint8_t day;
-    int8_t hour;
-    int8_t minute;
-    int8_t second;
+    uint8_t month;      /* 1 - 12 */
+    uint8_t week;       /* 1 - 5 */
+    uint8_t day;        /* 0 - 6 */
+    int16_t hour;       /* -167 - 167, RFC 8536 §3.3.1 */
+    int8_t minute;      /* signed 2 digits */
+    int8_t second;      /* signed 2 digits */
 } CalendarRule;
 
 typedef struct {
     TransitionRuleType base;
-    uint8_t julian;
-    unsigned int day;
-    int8_t hour;
-    int8_t minute;
-    int8_t second;
+    uint8_t julian;     /* 0, 1 */
+    uint16_t day;       /* 0 - 365 */
+    int16_t hour;       /* -167 - 167, RFC 8536 §3.3.1 */
+    int8_t minute;      /* signed 2 digits */
+    int8_t second;      /* signed 2 digits */
 } DayRule;
 
 struct StrongCacheNode {
@@ -134,15 +134,14 @@ ts_to_local(size_t *trans_idx, int64_t *trans_utc, long *utcoff,
 static int
 parse_tz_str(zoneinfo_state *state, PyObject *tz_str_obj, _tzrule *out);
 
-static Py_ssize_t
-parse_abbr(const char *const p, PyObject **abbr);
-static Py_ssize_t
-parse_tz_delta(const char *const p, long *total_seconds);
-static Py_ssize_t
-parse_transition_time(const char *const p, int8_t *hour, int8_t *minute,
-                      int8_t *second);
-static Py_ssize_t
-parse_transition_rule(const char *const p, TransitionRuleType **out);
+static int
+parse_abbr(const char **p, PyObject **abbr);
+static int
+parse_tz_delta(const char **p, long *total_seconds);
+static int
+parse_transition_time(const char **p, int *hour, int *minute, int *second);
+static int
+parse_transition_rule(const char **p, TransitionRuleType **out);
 
 static _ttinfo *
 find_tzrule_ttinfo(_tzrule *rule, int64_t ts, unsigned char fold, int year);
@@ -1328,14 +1327,14 @@ calendarrule_year_to_timestamp(TransitionRuleType *base_self, int year)
     }
 
     int64_t ordinal = ymd_to_ord(year, self->month, month_day) - EPOCHORDINAL;
-    return ((ordinal * 86400) + (int64_t)(self->hour * 3600) +
-            (int64_t)(self->minute * 60) + (int64_t)(self->second));
+    return ordinal * 86400 + (int64_t)self->hour * 3600 +
+            (int64_t)self->minute * 60 + self->second;
 }
 
 /* Constructor for CalendarRule. */
 int
-calendarrule_new(uint8_t month, uint8_t week, uint8_t day, int8_t hour,
-                 int8_t minute, int8_t second, CalendarRule *out)
+calendarrule_new(int month, int week, int day, int hour,
+                 int minute, int second, CalendarRule *out)
 {
     // These bounds come from the POSIX standard, which describes an Mm.n.d
     // rule as:
@@ -1344,33 +1343,36 @@ calendarrule_new(uint8_t month, uint8_t week, uint8_t day, int8_t hour,
     //   5, 1 <= m <= 12, where week 5 means "the last d day in month m" which
     //   may occur in either the fourth or the fifth week). Week 1 is the first
     //   week in which the d'th day occurs. Day zero is Sunday.
-    if (month <= 0 || month > 12) {
-        PyErr_Format(PyExc_ValueError, "Month must be in (0, 12]");
+    if (month < 1 || month > 12) {
+        PyErr_Format(PyExc_ValueError, "Month must be in [1, 12]");
         return -1;
     }
 
-    if (week <= 0 || week > 5) {
-        PyErr_Format(PyExc_ValueError, "Week must be in (0, 5]");
+    if (week < 1 || week > 5) {
+        PyErr_Format(PyExc_ValueError, "Week must be in [1, 5]");
         return -1;
     }
 
-    // If the 'day' parameter type is changed to a signed type,
-    // "day < 0" check must be added.
-    if (/* day < 0 || */ day > 6) {
+    if (day < 0 || day > 6) {
         PyErr_Format(PyExc_ValueError, "Day must be in [0, 6]");
         return -1;
     }
 
+    if (hour < -167 || hour > 167) {
+        PyErr_Format(PyExc_ValueError, "Hour must be in [0, 167]");
+        return -1;
+    }
+
     TransitionRuleType base = {&calendarrule_year_to_timestamp};
 
     CalendarRule new_offset = {
         .base = base,
-        .month = month,
-        .week = week,
-        .day = day,
-        .hour = hour,
-        .minute = minute,
-        .second = second,
+        .month = (uint8_t)month,
+        .week = (uint8_t)week,
+        .day = (uint8_t)day,
+        .hour = (int16_t)hour,
+        .minute = (int8_t)minute,
+        .second = (int8_t)second,
     };
 
     *out = new_offset;
@@ -1410,40 +1412,45 @@ dayrule_year_to_timestamp(TransitionRuleType *base_self, int year)
     // always transitions on a given calendar day (other than February 29th),
     // you would use a Julian day, e.g. J91 always refers to April 1st and J365
     // always refers to December 31st.
-    unsigned int day = self->day;
+    uint16_t day = self->day;
     if (self->julian && day >= 59 && is_leap_year(year)) {
         day += 1;
     }
 
-    return ((days_before_year + day) * 86400) + (self->hour * 3600) +
-           (self->minute * 60) + self->second;
+    return (days_before_year + day) * 86400 + (int64_t)self->hour * 3600 +
+           (int64_t)self->minute * 60 + self->second;
 }
 
 /* Constructor for DayRule. */
 static int
-dayrule_new(uint8_t julian, unsigned int day, int8_t hour, int8_t minute,
-            int8_t second, DayRule *out)
+dayrule_new(int julian, int day, int hour, int minute,
+            int second, DayRule *out)
 {
     // The POSIX standard specifies that Julian days must be in the range (1 <=
     // n <= 365) and that non-Julian (they call it "0-based Julian") days must
     // be in the range (0 <= n <= 365).
     if (day < julian || day > 365) {
-        PyErr_Format(PyExc_ValueError, "day must be in [%u, 365], not: %u",
+        PyErr_Format(PyExc_ValueError, "day must be in [%d, 365], not: %d",
                      julian, day);
         return -1;
     }
 
+    if (hour < -167 || hour > 167) {
+        PyErr_Format(PyExc_ValueError, "Hour must be in [0, 167]");
+        return -1;
+    }
+
     TransitionRuleType base = {
         &dayrule_year_to_timestamp,
     };
 
     DayRule tmp = {
         .base = base,
-        .julian = julian,
-        .day = day,
-        .hour = hour,
-        .minute = minute,
-        .second = second,
+        .julian = (uint8_t)julian,
+        .day = (int16_t)day,
+        .hour = (int16_t)hour,
+        .minute = (int8_t)minute,
+        .second = (int8_t)second,
     };
 
     *out = tmp;
@@ -1600,21 +1607,18 @@ parse_tz_str(zoneinfo_state *state, PyObject *tz_str_obj, _tzrule *out)
     const char *p = tz_str;
 
     // Read the `std` abbreviation, which must be at least 3 characters long.
-    Py_ssize_t num_chars = parse_abbr(p, &std_abbr);
-    if (num_chars < 1) {
-        PyErr_Format(PyExc_ValueError, "Invalid STD format in %R", tz_str_obj);
+    if (parse_abbr(&p, &std_abbr)) {
+        if (!PyErr_Occurred()) {
+            PyErr_Format(PyExc_ValueError, "Invalid STD format in %R", tz_str_obj);
+        }
         goto error;
     }
 
-    p += num_chars;
-
     // Now read the STD offset, which is required
-    num_chars = parse_tz_delta(p, &std_offset);
-    if (num_chars < 0) {
+    if (parse_tz_delta(&p, &std_offset)) {
         PyErr_Format(PyExc_ValueError, "Invalid STD offset in %R", tz_str_obj);
         goto error;
     }
-    p += num_chars;
 
     // If the string ends here, there is no DST, otherwise we must parse the
     // DST abbreviation and start and end dates and times.
@@ -1622,12 +1626,12 @@ parse_tz_str(zoneinfo_state *state, PyObject *tz_str_obj, _tzrule *out)
         goto complete;
     }
 
-    num_chars = parse_abbr(p, &dst_abbr);
-    if (num_chars < 1) {
-        PyErr_Format(PyExc_ValueError, "Invalid DST format in %R", tz_str_obj);
+    if (parse_abbr(&p, &dst_abbr)) {
+        if (!PyErr_Occurred()) {
+            PyErr_Format(PyExc_ValueError, "Invalid DST format in %R", tz_str_obj);
+        }
         goto error;
     }
-    p += num_chars;
 
     if (*p == ',') {
         // From the POSIX standard:
@@ -1637,14 +1641,11 @@ parse_tz_str(zoneinfo_state *state, PyObject *tz_str_obj, _tzrule *out)
         dst_offset = std_offset + 3600;
     }
     else {
-        num_chars = parse_tz_delta(p, &dst_offset);
-        if (num_chars < 0) {
+        if (parse_tz_delta(&p, &dst_offset)) {
             PyErr_Format(PyExc_ValueError, "Invalid DST offset in %R",
                          tz_str_obj);
             goto error;
         }
-
-        p += num_chars;
     }
 
     TransitionRuleType **transitions[2] = {&start, &end};
@@ -1657,14 +1658,12 @@ parse_tz_str(zoneinfo_state *state, PyObject *tz_str_obj, _tzrule *out)
         }
         p++;
 
-        num_chars = parse_transition_rule(p, transitions[i]);
-        if (num_chars < 0) {
+        if (parse_transition_rule(&p, transitions[i])) {
             PyErr_Format(PyExc_ValueError,
                          "Malformed transition rule in TZ string: %R",
                          tz_str_obj);
             goto error;
         }
-        p += num_chars;
     }
 
     if (*p != '\0') {
@@ -1699,21 +1698,25 @@ parse_tz_str(zoneinfo_state *state, PyObject *tz_str_obj, _tzrule *out)
 }
 
 static int
-parse_uint(const char *const p, uint8_t *value)
+parse_digits(const char **p, int min, int max, int *value)
 {
-    if (!isdigit(*p)) {
-        return -1;
+    assert(max <= 3);
+    *value = 0;
+    for (int i = 0; i < max; i++, (*p)++) {
+        if (!Py_ISDIGIT(**p)) {
+            return (i < min) ? -1 : 0;
+        }
+        *value *= 10;
+        *value += (**p) - '0';
     }
-
-    *value = (*p) - '0';
     return 0;
 }
 
 /* Parse the STD and DST abbreviations from a TZ string. */
-static Py_ssize_t
-parse_abbr(const char *const p, PyObject **abbr)
+static int
+parse_abbr(const char **p, PyObject **abbr)
 {
-    const char *ptr = p;
+    const char *ptr = *p;
     const char *str_start;
     const char *str_end;
 
@@ -1742,7 +1745,7 @@ parse_abbr(const char *const p, PyObject **abbr)
         ptr++;
     }
     else {
-        str_start = p;
+        str_start = ptr;
         // From the POSIX standard:
         //
         //   In the unquoted form, all characters in these fields shall be
@@ -1752,6 +1755,9 @@ parse_abbr(const char *const p, PyObject **abbr)
             ptr++;
         }
         str_end = ptr;
+        if (str_end == str_start) {
+            return -1;
+        }
     }
 
     *abbr = PyUnicode_FromStringAndSize(str_start, str_end - str_start);
@@ -1759,12 +1765,13 @@ parse_abbr(const char *const p, PyObject **abbr)
         return -1;
     }
 
-    return ptr - p;
+    *p = ptr;
+    return 0;
 }
 
 /* Parse a UTC offset from a TZ str. */
-static Py_ssize_t
-parse_tz_delta(const char *const p, long *total_seconds)
+static int
+parse_tz_delta(const char **p, long *total_seconds)
 {
     // From the POSIX spec:
     //
@@ -1779,75 +1786,30 @@ parse_tz_delta(const char *const p, long *total_seconds)
     // The POSIX spec says that the values for `hour` must be between 0 and 24
     // hours, but RFC 8536 §3.3.1 specifies that the hours part of the
     // transition times may be signed and range from -167 to 167.
-    long sign = -1;
-    long hours = 0;
-    long minutes = 0;
-    long seconds = 0;
-
-    const char *ptr = p;
-    char buff = *ptr;
-    if (buff == '-' || buff == '+') {
-        // Negative numbers correspond to *positive* offsets, from the spec:
-        //
-        //   If preceded by a '-', the timezone shall be east of the Prime
-        //   Meridian; otherwise, it shall be west (which may be indicated by
-        //   an optional preceding '+' ).
-        if (buff == '-') {
-            sign = 1;
-        }
-
-        ptr++;
-    }
-
-    // The hour can be 1 or 2 numeric characters
-    for (size_t i = 0; i < 2; ++i) {
-        buff = *ptr;
-        if (!isdigit(buff)) {
-            if (i == 0) {
-                return -1;
-            }
-            else {
-                break;
-            }
-        }
+    int hours = 0;
+    int minutes = 0;
+    int seconds = 0;
 
-        hours *= 10;
-        hours += buff - '0';
-        ptr++;
-    }
-
-    if (hours > 24 || hours < 0) {
+    if (parse_transition_time(p, &hours, &minutes, &seconds)) {
         return -1;
     }
 
-    // Minutes and seconds always of the format ":dd"
-    long *outputs[2] = {&minutes, &seconds};
-    for (size_t i = 0; i < 2; ++i) {
-        if (*ptr != ':') {
-            goto complete;
-        }
-        ptr++;
-
-        for (size_t j = 0; j < 2; ++j) {
-            buff = *ptr;
-            if (!isdigit(buff)) {
-                return -1;
-            }
-            *(outputs[i]) *= 10;
-            *(outputs[i]) += buff - '0';
-            ptr++;
-        }
+    if (hours > 24 || hours < -24) {
+        return -1;
     }
 
-complete:
-    *total_seconds = sign * ((hours * 3600) + (minutes * 60) + seconds);
-
-    return ptr - p;
+    // Negative numbers correspond to *positive* offsets, from the spec:
+    //
+    //   If preceded by a '-', the timezone shall be east of the Prime
+    //   Meridian; otherwise, it shall be west (which may be indicated by
+    //   an optional preceding '+' ).
+    *total_seconds = -((hours * 3600L) + (minutes * 60) + seconds);
+    return 0;
 }
 
 /* Parse the date portion of a transition rule. */
-static Py_ssize_t
-parse_transition_rule(const char *const p, TransitionRuleType **out)
+static int
+parse_transition_rule(const char **p, TransitionRuleType **out)
 {
     // The full transition rule indicates when to change back and forth between
     // STD and DST, and has the form:
@@ -1859,10 +1821,10 @@ parse_transition_rule(const char *const p, TransitionRuleType **out)
     // does not include the ',' at the end of the first rule.
     //
     // The POSIX spec states that if *time* is not given, the default is 02:00.
-    const char *ptr = p;
-    int8_t hour = 2;
-    int8_t minute = 0;
-    int8_t second = 0;
+    const char *ptr = *p;
+    int hour = 2;
+    int minute = 0;
+    int second = 0;
 
     // Rules come in one of three flavors:
     //
@@ -1871,44 +1833,30 @@ parse_transition_rule(const char *const p, TransitionRuleType **out)
     //   3. Mm.n.d: Specifying by month, week and day-of-week.
 
     if (*ptr == 'M') {
-        uint8_t month, week, day;
+        int month, week, day;
         ptr++;
-        if (parse_uint(ptr, &month)) {
+
+        if (parse_digits(&ptr, 1, 2, &month)) {
             return -1;
         }
-        ptr++;
-        if (*ptr != '.') {
-            uint8_t tmp;
-            if (parse_uint(ptr, &tmp)) {
-                return -1;
-            }
-
-            month *= 10;
-            month += tmp;
-            ptr++;
+        if (*ptr++ != '.') {
+            return -1;
         }
-
-        uint8_t *values[2] = {&week, &day};
-        for (size_t i = 0; i < 2; ++i) {
-            if (*ptr != '.') {
-                return -1;
-            }
-            ptr++;
-
-            if (parse_uint(ptr, values[i])) {
-                return -1;
-            }
-            ptr++;
+        if (parse_digits(&ptr, 1, 1, &week)) {
+            return -1;
+        }
+        if (*ptr++ != '.') {
+            return -1;
+        }
+        if (parse_digits(&ptr, 1, 1, &day)) {
+            return -1;
         }
 
         if (*ptr == '/') {
             ptr++;
-            Py_ssize_t num_chars =
-                parse_transition_time(ptr, &hour, &minute, &second);
-            if (num_chars < 0) {
+            if (parse_transition_time(&ptr, &hour, &minute, &second)) {
                 return -1;
             }
-            ptr += num_chars;
         }
 
         CalendarRule *rv = PyMem_Calloc(1, sizeof(CalendarRule));
@@ -1924,33 +1872,22 @@ parse_transition_rule(const char *const p, TransitionRuleType **out)
         *out = (TransitionRuleType *)rv;
     }
     else {
-        uint8_t julian = 0;
-        unsigned int day = 0;
+        int julian = 0;
+        int day = 0;
         if (*ptr == 'J') {
             julian = 1;
             ptr++;
         }
 
-        for (size_t i = 0; i < 3; ++i) {
-            if (!isdigit(*ptr)) {
-                if (i == 0) {
-                    return -1;
-                }
-                break;
-            }
-            day *= 10;
-            day += (*ptr) - '0';
-            ptr++;
+        if (parse_digits(&ptr, 1, 3, &day)) {
+            return -1;
         }
 
         if (*ptr == '/') {
             ptr++;
-            Py_ssize_t num_chars =
-                parse_transition_time(ptr, &hour, &minute, &second);
-            if (num_chars < 0) {
+            if (parse_transition_time(&ptr, &hour, &minute, &second)) {
                 return -1;
             }
-            ptr += num_chars;
         }
 
         DayRule *rv = PyMem_Calloc(1, sizeof(DayRule));
@@ -1965,13 +1902,13 @@ parse_transition_rule(const char *const p, TransitionRuleType **out)
         *out = (TransitionRuleType *)rv;
     }
 
-    return ptr - p;
+    *p = ptr;
+    return 0;
 }
 
 /* Parse the time portion of a transition rule (e.g. following an /) */
-static Py_ssize_t
-parse_transition_time(const char *const p, int8_t *hour, int8_t *minute,
-                      int8_t *second)
+static int
+parse_transition_time(const char **p, int *hour, int *minute, int *second)
 {
     // From the spec:
     //
@@ -1983,12 +1920,9 @@ parse_transition_time(const char *const p, int8_t *hour, int8_t *minute,
     //   h[h][:mm[:ss]]
     //
     // RFC 8536 also allows transition times to be signed and to range from
-    // -167 to +167, but the current version only supports [0, 99].
-    //
-    // TODO: Support the full range of transition hours.
-    int8_t *components[3] = {hour, minute, second};
-    const char *ptr = p;
-    int8_t sign = 1;
+    // -167 to +167.
+    const char *ptr = *p;
+    int sign = 1;
 
     if (*ptr == '-' || *ptr == '+') {
         if (*ptr == '-') {
@@ -1997,32 +1931,31 @@ parse_transition_time(const char *const p, int8_t *hour, int8_t *minute,
         ptr++;
     }
 
-    for (size_t i = 0; i < 3; ++i) {
-        if (i > 0) {
-            if (*ptr != ':') {
-                break;
-            }
-            ptr++;
+    // The hour can be 1 to 3 numeric characters
+    if (parse_digits(&ptr, 1, 3, hour)) {
+        return -1;
+    }
+    *hour *= sign;
+
+    // Minutes and seconds always of the format ":dd"
+    if (*ptr == ':') {
+        ptr++;
+        if (parse_digits(&ptr, 2, 2, minute)) {
+            return -1;
         }
+        *minute *= sign;
 
-        uint8_t buff = 0;
-        for (size_t j = 0; j < 2; j++) {
-            if (!isdigit(*ptr)) {
-                if (i == 0 && j > 0) {
-                    break;
-                }
+        if (*ptr == ':') {
+            ptr++;
+            if (parse_digits(&ptr, 2, 2, second)) {
                 return -1;
             }
-
-            buff *= 10;
-            buff += (*ptr) - '0';
-            ptr++;
+            *second *= sign;
         }
-
-        *(components[i]) = sign * buff;
     }
 
-    return ptr - p;
+    *p = ptr;
+    return 0;
 }
 
 /* Constructor for a _tzrule.
@@ -2377,8 +2310,8 @@ get_local_timestamp(PyObject *dt, int64_t *local_ts)
         }
     }
 
-    *local_ts = (int64_t)(ord - EPOCHORDINAL) * 86400 +
-                (int64_t)(hour * 3600 + minute * 60 + second);
+    *local_ts = (int64_t)(ord - EPOCHORDINAL) * 86400L +
+                (int64_t)(hour * 3600L + minute * 60 + second);
 
     return 0;
 }
diff --git a/Modules/cjkcodecs/_codecs_iso2022.c b/Modules/cjkcodecs/_codecs_iso2022.c
index 86bb73b982..e8835ad090 100644
--- a/Modules/cjkcodecs/_codecs_iso2022.c
+++ b/Modules/cjkcodecs/_codecs_iso2022.c
@@ -207,8 +207,9 @@ ENCODER(iso2022)
 
         encoded = MAP_UNMAPPABLE;
         for (dsg = CONFIG_DESIGNATIONS; dsg->mark; dsg++) {
+            Py_UCS4 buf[2] = {c, 0};
             Py_ssize_t length = 1;
-            encoded = dsg->encoder(codec, &c, &length);
+            encoded = dsg->encoder(codec, buf, &length);
             if (encoded == MAP_MULTIPLE_AVAIL) {
                 /* this implementation won't work for pair
                  * of non-bmp characters. */
@@ -217,9 +218,11 @@ ENCODER(iso2022)
                         return MBERR_TOOFEW;
                     length = -1;
                 }
-                else
+                else {
+                    buf[1] = INCHAR2;
                     length = 2;
-                encoded = dsg->encoder(codec, &c, &length);
+                }
+                encoded = dsg->encoder(codec, buf, &length);
                 if (encoded != MAP_UNMAPPABLE) {
                     insize = length;
                     break;
diff --git a/Modules/clinic/posixmodule.c.h b/Modules/clinic/posixmodule.c.h
index 5924c4ab03..fb01c8dbc8 100644
--- a/Modules/clinic/posixmodule.c.h
+++ b/Modules/clinic/posixmodule.c.h
@@ -1975,7 +1975,7 @@ exit:
 #if defined(MS_WINDOWS)
 
 PyDoc_STRVAR(os__path_isdir__doc__,
-"_path_isdir($module, /, path)\n"
+"_path_isdir($module, /, s)\n"
 "--\n"
 "\n"
 "Return true if the pathname refers to an existing directory.");
@@ -1984,7 +1984,7 @@ PyDoc_STRVAR(os__path_isdir__doc__,
     {"_path_isdir", _PyCFunction_CAST(os__path_isdir), METH_FASTCALL|METH_KEYWORDS, os__path_isdir__doc__},
 
 static PyObject *
-os__path_isdir_impl(PyObject *module, PyObject *path);
+os__path_isdir_impl(PyObject *module, PyObject *s);
 
 static PyObject *
 os__path_isdir(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyObject *kwnames)
@@ -1999,7 +1999,7 @@ os__path_isdir(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyObje
         PyObject *ob_item[NUM_KEYWORDS];
     } _kwtuple = {
         .ob_base = PyVarObject_HEAD_INIT(&PyTuple_Type, NUM_KEYWORDS)
-        .ob_item = { &_Py_ID(path), },
+        .ob_item = { &_Py_ID(s), },
     };
     #undef NUM_KEYWORDS
     #define KWTUPLE (&_kwtuple.ob_base.ob_base)
@@ -2008,7 +2008,7 @@ os__path_isdir(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyObje
     #  define KWTUPLE NULL
     #endif  // !Py_BUILD_CORE
 
-    static const char * const _keywords[] = {"path", NULL};
+    static const char * const _keywords[] = {"s", NULL};
     static _PyArg_Parser _parser = {
         .keywords = _keywords,
         .fname = "_path_isdir",
@@ -2016,14 +2016,14 @@ os__path_isdir(PyObject *module, PyObject *const *args, Py_ssize_t nargs, PyObje
     };
     #undef KWTUPLE
     PyObject *argsbuf[1];
-    PyObject *path;
+    PyObject *s;
 
     args = _PyArg_UnpackKeywords(args, nargs, NULL, kwnames, &_parser, 1, 1, 0, argsbuf);
     if (!args) {
         goto exit;
     }
-    path = args[0];
-    return_value = os__path_isdir_impl(module, path);
+    s = args[0];
+    return_value = os__path_isdir_impl(module, s);
 
 exit:
     return return_value;
@@ -11999,4 +11999,4 @@ exit:
 #ifndef OS_WAITSTATUS_TO_EXITCODE_METHODDEF
     #define OS_WAITSTATUS_TO_EXITCODE_METHODDEF
 #endif /* !defined(OS_WAITSTATUS_TO_EXITCODE_METHODDEF) */
-/*[clinic end generated code: output=6646be70849f971f input=a9049054013a1b77]*/
+/*[clinic end generated code: output=ce77253f8879f36e input=a9049054013a1b77]*/
diff --git a/Modules/faulthandler.c b/Modules/faulthandler.c
index 3d360cb436..be77bb01f3 100644
--- a/Modules/faulthandler.c
+++ b/Modules/faulthandler.c
@@ -176,7 +176,6 @@ faulthandler_dump_traceback(int fd, int all_threads,
                             PyInterpreterState *interp)
 {
     static volatile int reentrant = 0;
-    PyThreadState *tstate;
 
     if (reentrant)
         return;
@@ -191,7 +190,7 @@ faulthandler_dump_traceback(int fd, int all_threads,
        fault if the thread released the GIL, and so this function cannot be
        used. Read the thread specific storage (TSS) instead: call
        PyGILState_GetThisThreadState(). */
-    tstate = PyGILState_GetThisThreadState();
+    PyThreadState *tstate = PyGILState_GetThisThreadState();
 
     if (all_threads) {
         (void)_Py_DumpTracebackThreads(fd, NULL, tstate);
diff --git a/Modules/mathmodule.c b/Modules/mathmodule.c
index 7b1104ba5a..23fa2b1816 100644
--- a/Modules/mathmodule.c
+++ b/Modules/mathmodule.c
@@ -2831,7 +2831,7 @@ math_sumprod_impl(PyObject *module, PyObject *p, PyObject *q)
                         PyErr_Clear();
                         goto finalize_flt_path;
                     }
-                } else if (q_type_float && (PyLong_CheckExact(p_i) || PyBool_Check(q_i))) {
+                } else if (q_type_float && (PyLong_CheckExact(p_i) || PyBool_Check(p_i))) {
                     flt_q = PyFloat_AS_DOUBLE(q_i);
                     flt_p = PyLong_AsDouble(p_i);
                     if (flt_p == -1.0 && PyErr_Occurred()) {
diff --git a/Modules/posixmodule.c b/Modules/posixmodule.c
index b9ca2865c0..265c817ca6 100644
--- a/Modules/posixmodule.c
+++ b/Modules/posixmodule.c
@@ -2385,21 +2385,26 @@ _posix_free(void *module)
    _posix_clear((PyObject *)module);
 }
 
-static void
+static int
 fill_time(PyObject *module, PyObject *v, int s_index, int f_index, int ns_index, time_t sec, unsigned long nsec)
 {
-    PyObject *s = _PyLong_FromTime_t(sec);
-    PyObject *ns_fractional = PyLong_FromUnsignedLong(nsec);
+    assert(!PyErr_Occurred());
+
+    int res = -1;
     PyObject *s_in_ns = NULL;
     PyObject *ns_total = NULL;
     PyObject *float_s = NULL;
 
-    if (!(s && ns_fractional))
+    PyObject *s = _PyLong_FromTime_t(sec);
+    PyObject *ns_fractional = PyLong_FromUnsignedLong(nsec);
+    if (!(s && ns_fractional)) {
         goto exit;
+    }
 
     s_in_ns = PyNumber_Multiply(s, get_posix_state(module)->billion);
-    if (!s_in_ns)
+    if (!s_in_ns) {
         goto exit;
+    }
 
     ns_total = PyNumber_Add(s_in_ns, ns_fractional);
     if (!ns_total)
@@ -2422,12 +2427,17 @@ fill_time(PyObject *module, PyObject *v, int s_index, int f_index, int ns_index,
         PyStructSequence_SET_ITEM(v, ns_index, ns_total);
         ns_total = NULL;
     }
+
+    assert(!PyErr_Occurred());
+    res = 0;
+
 exit:
     Py_XDECREF(s);
     Py_XDECREF(ns_fractional);
     Py_XDECREF(s_in_ns);
     Py_XDECREF(ns_total);
     Py_XDECREF(float_s);
+    return res;
 }
 
 #ifdef MS_WINDOWS
@@ -2462,34 +2472,47 @@ _pystat_l128_from_l64_l64(uint64_t low, uint64_t high)
 static PyObject*
 _pystat_fromstructstat(PyObject *module, STRUCT_STAT *st)
 {
-    unsigned long ansec, mnsec, cnsec;
+    assert(!PyErr_Occurred());
+
     PyObject *StatResultType = get_posix_state(module)->StatResultType;
     PyObject *v = PyStructSequence_New((PyTypeObject *)StatResultType);
-    if (v == NULL)
+    if (v == NULL) {
         return NULL;
+    }
 
-    PyStructSequence_SET_ITEM(v, 0, PyLong_FromLong((long)st->st_mode));
+#define SET_ITEM(pos, expr) \
+    do { \
+        PyObject *obj = (expr); \
+        if (obj == NULL) { \
+            goto error; \
+        } \
+        PyStructSequence_SET_ITEM(v, (pos), obj); \
+    } while (0)
+
+    SET_ITEM(0, PyLong_FromLong((long)st->st_mode));
 #ifdef MS_WINDOWS
-    PyStructSequence_SET_ITEM(v, 1, _pystat_l128_from_l64_l64(st->st_ino, st->st_ino_high));
-    PyStructSequence_SET_ITEM(v, 2, PyLong_FromUnsignedLongLong(st->st_dev));
+    SET_ITEM(1, _pystat_l128_from_l64_l64(st->st_ino, st->st_ino_high));
+    SET_ITEM(2, PyLong_FromUnsignedLongLong(st->st_dev));
 #else
     static_assert(sizeof(unsigned long long) >= sizeof(st->st_ino),
                   "stat.st_ino is larger than unsigned long long");
-    PyStructSequence_SET_ITEM(v, 1, PyLong_FromUnsignedLongLong(st->st_ino));
-    PyStructSequence_SET_ITEM(v, 2, _PyLong_FromDev(st->st_dev));
+    SET_ITEM(1, PyLong_FromUnsignedLongLong(st->st_ino));
+    SET_ITEM(2, _PyLong_FromDev(st->st_dev));
 #endif
-    PyStructSequence_SET_ITEM(v, 3, PyLong_FromLong((long)st->st_nlink));
+    SET_ITEM(3, PyLong_FromLong((long)st->st_nlink));
 #if defined(MS_WINDOWS)
-    PyStructSequence_SET_ITEM(v, 4, PyLong_FromLong(0));
-    PyStructSequence_SET_ITEM(v, 5, PyLong_FromLong(0));
+    SET_ITEM(4, PyLong_FromLong(0));
+    SET_ITEM(5, PyLong_FromLong(0));
 #else
-    PyStructSequence_SET_ITEM(v, 4, _PyLong_FromUid(st->st_uid));
-    PyStructSequence_SET_ITEM(v, 5, _PyLong_FromGid(st->st_gid));
+    SET_ITEM(4, _PyLong_FromUid(st->st_uid));
+    SET_ITEM(5, _PyLong_FromGid(st->st_gid));
 #endif
     static_assert(sizeof(long long) >= sizeof(st->st_size),
                   "stat.st_size is larger than long long");
-    PyStructSequence_SET_ITEM(v, 6, PyLong_FromLongLong(st->st_size));
+    SET_ITEM(6, PyLong_FromLongLong(st->st_size));
 
+    // Set st_atime, st_mtime and st_ctime
+    unsigned long ansec, mnsec, cnsec;
 #if defined(HAVE_STAT_TV_NSEC)
     ansec = st->st_atim.tv_nsec;
     mnsec = st->st_mtim.tv_nsec;
@@ -2505,67 +2528,67 @@ _pystat_fromstructstat(PyObject *module, STRUCT_STAT *st)
 #else
     ansec = mnsec = cnsec = 0;
 #endif
-    fill_time(module, v, 7, 10, 13, st->st_atime, ansec);
-    fill_time(module, v, 8, 11, 14, st->st_mtime, mnsec);
-    fill_time(module, v, 9, 12, 15, st->st_ctime, cnsec);
+    if (fill_time(module, v, 7, 10, 13, st->st_atime, ansec) < 0) {
+        goto error;
+    }
+    if (fill_time(module, v, 8, 11, 14, st->st_mtime, mnsec) < 0) {
+        goto error;
+    }
+    if (fill_time(module, v, 9, 12, 15, st->st_ctime, cnsec) < 0) {
+        goto error;
+    }
 
 #ifdef HAVE_STRUCT_STAT_ST_BLKSIZE
-    PyStructSequence_SET_ITEM(v, ST_BLKSIZE_IDX,
-                              PyLong_FromLong((long)st->st_blksize));
+    SET_ITEM(ST_BLKSIZE_IDX, PyLong_FromLong((long)st->st_blksize));
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_BLOCKS
-    PyStructSequence_SET_ITEM(v, ST_BLOCKS_IDX,
-                              PyLong_FromLong((long)st->st_blocks));
+    SET_ITEM(ST_BLOCKS_IDX, PyLong_FromLong((long)st->st_blocks));
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_RDEV
-    PyStructSequence_SET_ITEM(v, ST_RDEV_IDX,
-                              PyLong_FromLong((long)st->st_rdev));
+    SET_ITEM(ST_RDEV_IDX, PyLong_FromLong((long)st->st_rdev));
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_GEN
-    PyStructSequence_SET_ITEM(v, ST_GEN_IDX,
-                              PyLong_FromLong((long)st->st_gen));
+    SET_ITEM(ST_GEN_IDX, PyLong_FromLong((long)st->st_gen));
 #endif
 #if defined(HAVE_STRUCT_STAT_ST_BIRTHTIME)
     {
-      PyObject *val;
-      unsigned long bsec,bnsec;
+      unsigned long bsec, bnsec;
       bsec = (long)st->st_birthtime;
 #ifdef HAVE_STAT_TV_NSEC2
       bnsec = st->st_birthtimespec.tv_nsec;
 #else
       bnsec = 0;
 #endif
-      val = PyFloat_FromDouble(bsec + 1e-9*bnsec);
-      PyStructSequence_SET_ITEM(v, ST_BIRTHTIME_IDX,
-                                val);
+      SET_ITEM(ST_BIRTHTIME_IDX, PyFloat_FromDouble(bsec + bnsec * 1e-9));
     }
 #elif defined(MS_WINDOWS)
-    fill_time(module, v, -1, ST_BIRTHTIME_IDX, ST_BIRTHTIME_NS_IDX,
-              st->st_birthtime, st->st_birthtime_nsec);
+    if (fill_time(module, v, -1, ST_BIRTHTIME_IDX, ST_BIRTHTIME_NS_IDX,
+                  st->st_birthtime, st->st_birthtime_nsec) < 0) {
+        goto error;
+    }
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_FLAGS
-    PyStructSequence_SET_ITEM(v, ST_FLAGS_IDX,
-                              PyLong_FromLong((long)st->st_flags));
+    SET_ITEM(ST_FLAGS_IDX, PyLong_FromLong((long)st->st_flags));
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_FILE_ATTRIBUTES
-    PyStructSequence_SET_ITEM(v, ST_FILE_ATTRIBUTES_IDX,
-                              PyLong_FromUnsignedLong(st->st_file_attributes));
+    SET_ITEM(ST_FILE_ATTRIBUTES_IDX,
+             PyLong_FromUnsignedLong(st->st_file_attributes));
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_FSTYPE
-   PyStructSequence_SET_ITEM(v, ST_FSTYPE_IDX,
-                              PyUnicode_FromString(st->st_fstype));
+   SET_ITEM(ST_FSTYPE_IDX, PyUnicode_FromString(st->st_fstype));
 #endif
 #ifdef HAVE_STRUCT_STAT_ST_REPARSE_TAG
-    PyStructSequence_SET_ITEM(v, ST_REPARSE_TAG_IDX,
-                              PyLong_FromUnsignedLong(st->st_reparse_tag));
+    SET_ITEM(ST_REPARSE_TAG_IDX, PyLong_FromUnsignedLong(st->st_reparse_tag));
 #endif
 
-    if (PyErr_Occurred()) {
-        Py_DECREF(v);
-        return NULL;
-    }
-
+    assert(!PyErr_Occurred());
     return v;
+
+error:
+    Py_DECREF(v);
+    return NULL;
+
+#undef SET_ITEM
 }
 
 /* POSIX methods */
@@ -4878,25 +4901,25 @@ os__path_splitroot_impl(PyObject *module, path_t *path)
 /*[clinic input]
 os._path_isdir
 
-    path: 'O'
+    s: 'O'
 
 Return true if the pathname refers to an existing directory.
 
 [clinic start generated code]*/
 
 static PyObject *
-os__path_isdir_impl(PyObject *module, PyObject *path)
-/*[clinic end generated code: output=00faea0af309669d input=b1d2571cf7291aaf]*/
+os__path_isdir_impl(PyObject *module, PyObject *s)
+/*[clinic end generated code: output=9d87ab3c8b8a4e61 input=c17f7ef21d22d64e]*/
 {
     HANDLE hfile;
     BOOL close_file = TRUE;
     FILE_BASIC_INFO info;
-    path_t _path = PATH_T_INITIALIZE("isdir", "path", 0, 1);
+    path_t _path = PATH_T_INITIALIZE("isdir", "s", 0, 1);
     int result;
     BOOL slow_path = TRUE;
     FILE_STAT_BASIC_INFORMATION statInfo;
 
-    if (!path_converter(path, &_path)) {
+    if (!path_converter(s, &_path)) {
         path_cleanup(&_path);
         if (PyErr_ExceptionMatches(PyExc_ValueError)) {
             PyErr_Clear();
@@ -14505,6 +14528,7 @@ typedef struct {
 #ifdef MS_WINDOWS
     struct _Py_stat_struct win32_lstat;
     uint64_t win32_file_index;
+    uint64_t win32_file_index_high;
     int got_file_index;
 #else /* POSIX */
 #ifdef HAVE_DIRENT_D_TYPE
@@ -14836,11 +14860,10 @@ os_DirEntry_inode_impl(DirEntry *self)
         }
 
         self->win32_file_index = stat.st_ino;
+        self->win32_file_index_high = stat.st_ino_high;
         self->got_file_index = 1;
     }
-    static_assert(sizeof(unsigned long long) >= sizeof(self->win32_file_index),
-                  "DirEntry.win32_file_index is larger than unsigned long long");
-    return PyLong_FromUnsignedLongLong(self->win32_file_index);
+    return _pystat_l128_from_l64_l64(self->win32_file_index, self->win32_file_index_high);
 #else /* POSIX */
     static_assert(sizeof(unsigned long long) >= sizeof(self->d_ino),
                   "DirEntry.d_ino is larger than unsigned long long");
diff --git a/Modules/readline.c b/Modules/readline.c
index 2824105a18..9823ebe71d 100644
--- a/Modules/readline.c
+++ b/Modules/readline.c
@@ -442,7 +442,7 @@ readline_set_completion_display_matches_hook_impl(PyObject *module,
        default completion display. */
     rl_completion_display_matches_hook =
         readlinestate_global->completion_display_matches_hook ?
-#if defined(_RL_FUNCTION_TYPEDEF)
+#if defined(HAVE_RL_COMPDISP_FUNC_T)
         (rl_compdisp_func_t *)on_completion_display_matches_hook : 0;
 #else
         (VFunction *)on_completion_display_matches_hook : 0;
diff --git a/Modules/socketmodule.c b/Modules/socketmodule.c
index 4ec68e22a9..de7229d2ce 100644
--- a/Modules/socketmodule.c
+++ b/Modules/socketmodule.c
@@ -5655,8 +5655,9 @@ socket_sethostname(PyObject *self, PyObject *args)
     Py_buffer buf;
     int res, flag = 0;
 
-#ifdef _AIX
-/* issue #18259, not declared in any useful header file */
+#if defined(_AIX) || (defined(__sun) && defined(__SVR4) && Py_SUNOS_VERSION <= 510)
+/* issue #18259, sethostname is not declared in any useful header file on AIX
+ * the same is true for Solaris 10 */
 extern int sethostname(const char *, size_t);
 #endif
 
@@ -7702,10 +7703,10 @@ socket_exec(PyObject *m)
 
 /* FreeBSD divert(4) */
 #ifdef PF_DIVERT
-    PyModule_AddIntMacro(m, PF_DIVERT);
+    ADD_INT_MACRO(m, PF_DIVERT);
 #endif
 #ifdef AF_DIVERT
-    PyModule_AddIntMacro(m, AF_DIVERT);
+    ADD_INT_MACRO(m, AF_DIVERT);
 #endif
 
 #ifdef AF_PACKET
diff --git a/Modules/termios.c b/Modules/termios.c
index 6dc8200572..c3d96cc5b2 100644
--- a/Modules/termios.c
+++ b/Modules/termios.c
@@ -183,17 +183,25 @@ termios_tcsetattr_impl(PyObject *module, int fd, int when, PyObject *term)
         return PyErr_SetFromErrno(state->TermiosError);
     }
 
-    mode.c_iflag = (tcflag_t) PyLong_AsLong(PyList_GetItem(term, 0));
-    mode.c_oflag = (tcflag_t) PyLong_AsLong(PyList_GetItem(term, 1));
-    mode.c_cflag = (tcflag_t) PyLong_AsLong(PyList_GetItem(term, 2));
-    mode.c_lflag = (tcflag_t) PyLong_AsLong(PyList_GetItem(term, 3));
-    speed_t ispeed = (speed_t) PyLong_AsLong(PyList_GetItem(term, 4));
-    speed_t ospeed = (speed_t) PyLong_AsLong(PyList_GetItem(term, 5));
-    PyObject *cc = PyList_GetItem(term, 6);
-    if (PyErr_Occurred()) {
-        return NULL;
-    }
-
+    speed_t ispeed, ospeed;
+#define SET_FROM_LIST(TYPE, VAR, LIST, N) do {  \
+    PyObject *item = PyList_GET_ITEM(LIST, N);  \
+    long num = PyLong_AsLong(item);             \
+    if (num == -1 && PyErr_Occurred()) {        \
+        return NULL;                            \
+    }                                           \
+    VAR = (TYPE)num;                            \
+} while (0)
+
+    SET_FROM_LIST(tcflag_t, mode.c_iflag, term, 0);
+    SET_FROM_LIST(tcflag_t, mode.c_oflag, term, 1);
+    SET_FROM_LIST(tcflag_t, mode.c_cflag, term, 2);
+    SET_FROM_LIST(tcflag_t, mode.c_lflag, term, 3);
+    SET_FROM_LIST(speed_t, ispeed, term, 4);
+    SET_FROM_LIST(speed_t, ospeed, term, 5);
+#undef SET_FROM_LIST
+
+    PyObject *cc = PyList_GET_ITEM(term, 6);
     if (!PyList_Check(cc) || PyList_Size(cc) != NCCS) {
         PyErr_Format(PyExc_TypeError,
             "tcsetattr: attributes[6] must be %d element list",
@@ -208,8 +216,13 @@ termios_tcsetattr_impl(PyObject *module, int fd, int when, PyObject *term)
 
         if (PyBytes_Check(v) && PyBytes_Size(v) == 1)
             mode.c_cc[i] = (cc_t) * PyBytes_AsString(v);
-        else if (PyLong_Check(v))
-            mode.c_cc[i] = (cc_t) PyLong_AsLong(v);
+        else if (PyLong_Check(v)) {
+            long num = PyLong_AsLong(v);
+            if (num == -1 && PyErr_Occurred()) {
+                return NULL;
+            }
+            mode.c_cc[i] = (cc_t)num;
+        }
         else {
             PyErr_SetString(PyExc_TypeError,
      "tcsetattr: elements of attributes must be characters or integers");
diff --git a/Modules/timemodule.c b/Modules/timemodule.c
index f5b0f39e14..3b46deacdf 100644
--- a/Modules/timemodule.c
+++ b/Modules/timemodule.c
@@ -1737,6 +1737,12 @@ get_gmtoff(time_t t, struct tm *p)
 static int
 init_timezone(PyObject *m)
 {
+#define ADD_INT(NAME, VALUE) do {                       \
+    if (PyModule_AddIntConstant(m, NAME, VALUE) < 0) {  \
+        return -1;                                      \
+    }                                                   \
+} while (0)
+
     assert(!PyErr_Occurred());
 
     /* This code moved from PyInit_time wholesale to allow calling it from
@@ -1760,13 +1766,13 @@ init_timezone(PyObject *m)
 #if !defined(MS_WINDOWS) || defined(MS_WINDOWS_DESKTOP) || defined(MS_WINDOWS_SYSTEM)
     tzset();
 #endif
-    PyModule_AddIntConstant(m, "timezone", _Py_timezone);
+    ADD_INT("timezone", _Py_timezone);
 #ifdef HAVE_ALTZONE
-    PyModule_AddIntConstant(m, "altzone", altzone);
+    ADD_INT("altzone", altzone);
 #else
-    PyModule_AddIntConstant(m, "altzone", _Py_timezone-3600);
+    ADD_INT("altzone", _Py_timezone-3600);
 #endif
-    PyModule_AddIntConstant(m, "daylight", _Py_daylight);
+    ADD_INT("daylight", _Py_daylight);
 #ifdef MS_WINDOWS
     TIME_ZONE_INFORMATION tzinfo = {0};
     GetTimeZoneInformation(&tzinfo);
@@ -1825,20 +1831,21 @@ init_timezone(PyObject *m)
     PyObject *tzname_obj;
     if (janzone < julyzone) {
         /* DST is reversed in the southern hemisphere */
-        PyModule_AddIntConstant(m, "timezone", julyzone);
-        PyModule_AddIntConstant(m, "altzone", janzone);
-        PyModule_AddIntConstant(m, "daylight", janzone != julyzone);
+        ADD_INT("timezone", julyzone);
+        ADD_INT("altzone", janzone);
+        ADD_INT("daylight", janzone != julyzone);
         tzname_obj = Py_BuildValue("(zz)", julyname, janname);
     } else {
-        PyModule_AddIntConstant(m, "timezone", janzone);
-        PyModule_AddIntConstant(m, "altzone", julyzone);
-        PyModule_AddIntConstant(m, "daylight", janzone != julyzone);
+        ADD_INT("timezone", janzone);
+        ADD_INT("altzone", julyzone);
+        ADD_INT("daylight", janzone != julyzone);
         tzname_obj = Py_BuildValue("(zz)", janname, julyname);
     }
     if (_PyModule_Add(m, "tzname", tzname_obj) < 0) {
         return -1;
     }
 #endif // !HAVE_DECL_TZNAME
+#undef ADD_INT
 
     if (PyErr_Occurred()) {
         return -1;
diff --git a/Modules/xxlimited.c b/Modules/xxlimited.c
index 3935c00fc2..b9646debba 100644
--- a/Modules/xxlimited.c
+++ b/Modules/xxlimited.c
@@ -62,7 +62,8 @@
           pass
    */
 
-#define Py_LIMITED_API 0x030b0000
+// Need limited C API version 3.12 for Py_MOD_PER_INTERPRETER_GIL_SUPPORTED
+#define Py_LIMITED_API 0x030c0000
 
 #include "Python.h"
 #include <string.h>
diff --git a/Modules/xxlimited_35.c b/Modules/xxlimited_35.c
index 1ff3ef1cb6..361c7e76d7 100644
--- a/Modules/xxlimited_35.c
+++ b/Modules/xxlimited_35.c
@@ -293,7 +293,6 @@ xx_modexec(PyObject *m)
 
 static PyModuleDef_Slot xx_slots[] = {
     {Py_mod_exec, xx_modexec},
-    {Py_mod_multiple_interpreters, Py_MOD_PER_INTERPRETER_GIL_SUPPORTED},
     {0, NULL}
 };
 
diff --git a/Objects/codeobject.c b/Objects/codeobject.c
index aee1213632..cda2d2f544 100644
--- a/Objects/codeobject.c
+++ b/Objects/codeobject.c
@@ -665,6 +665,35 @@ PyUnstable_Code_NewWithPosOnlyArgs(
         _Py_set_localsplus_info(offset, name, CO_FAST_FREE,
                                localsplusnames, localspluskinds);
     }
+
+    // gh-110543: Make sure the CO_FAST_HIDDEN flag is set correctly.
+    if (!(flags & CO_OPTIMIZED)) {
+        Py_ssize_t code_len = PyBytes_GET_SIZE(code);
+        _Py_CODEUNIT *code_data = (_Py_CODEUNIT *)PyBytes_AS_STRING(code);
+        Py_ssize_t num_code_units = code_len / sizeof(_Py_CODEUNIT);
+        int extended_arg = 0;
+        for (int i = 0; i < num_code_units; i += 1 + _PyOpcode_Caches[code_data[i].op.code]) {
+            _Py_CODEUNIT *instr = &code_data[i];
+            uint8_t opcode = instr->op.code;
+            if (opcode == EXTENDED_ARG) {
+                extended_arg = extended_arg << 8 | instr->op.arg;
+                continue;
+            }
+            if (opcode == LOAD_FAST_AND_CLEAR) {
+                int oparg = extended_arg << 8 | instr->op.arg;
+                if (oparg >= nlocalsplus) {
+                    PyErr_Format(PyExc_ValueError,
+                                "code: LOAD_FAST_AND_CLEAR oparg %d out of range",
+                                oparg);
+                    goto error;
+                }
+                _PyLocals_Kind kind = _PyLocals_GetKind(localspluskinds, oparg);
+                _PyLocals_SetKind(localspluskinds, oparg, kind | CO_FAST_HIDDEN);
+            }
+            extended_arg = 0;
+        }
+    }
+
     // If any cells were args then nlocalsplus will have shrunk.
     if (nlocalsplus != PyTuple_GET_SIZE(localsplusnames)) {
         if (_PyTuple_Resize(&localsplusnames, nlocalsplus) < 0
diff --git a/Objects/frameobject.c b/Objects/frameobject.c
index 30c8d3c527..d33c3cde52 100644
--- a/Objects/frameobject.c
+++ b/Objects/frameobject.c
@@ -328,6 +328,8 @@ mark_stacks(PyCodeObject *code_obj, int len)
             switch (opcode) {
                 case POP_JUMP_IF_FALSE:
                 case POP_JUMP_IF_TRUE:
+                case POP_JUMP_IF_NONE:
+                case POP_JUMP_IF_NOT_NONE:
                 {
                     int64_t target_stack;
                     int j = next_i + oparg;
diff --git a/Objects/object_layout.md b/Objects/object_layout.md
index 9380b57938..82483022a0 100644
--- a/Objects/object_layout.md
+++ b/Objects/object_layout.md
@@ -36,7 +36,7 @@ ## 3.11 pre-header
 
 ## 3.12 pre-header
 
-In 3.12 the the pointer to the list of weak references is added to the
+In 3.12 the pointer to the list of weak references is added to the
 pre-header. In order to make space for it, the ``dict`` and ``values``
 pointers are combined into a single tagged pointer:
 
diff --git a/Objects/typevarobject.c b/Objects/typevarobject.c
index 069e1d98ea..db9c2191d6 100644
--- a/Objects/typevarobject.c
+++ b/Objects/typevarobject.c
@@ -364,24 +364,26 @@ typevar_new_impl(PyTypeObject *type, PyObject *name, PyObject *constraints,
         }
     }
 
-    if (!PyTuple_CheckExact(constraints)) {
-        PyErr_SetString(PyExc_TypeError,
-                        "constraints must be a tuple");
-        return NULL;
-    }
-    Py_ssize_t n_constraints = PyTuple_GET_SIZE(constraints);
-    if (n_constraints == 1) {
-        PyErr_SetString(PyExc_TypeError,
-                        "A single constraint is not allowed");
-        Py_XDECREF(bound);
-        return NULL;
-    } else if (n_constraints == 0) {
-        constraints = NULL;
-    } else if (bound != NULL) {
-        PyErr_SetString(PyExc_TypeError,
-                        "Constraints cannot be combined with bound=...");
-        Py_XDECREF(bound);
-        return NULL;
+    if (constraints != NULL) {
+        if (!PyTuple_CheckExact(constraints)) {
+            PyErr_SetString(PyExc_TypeError,
+                            "constraints must be a tuple");
+            return NULL;
+        }
+        Py_ssize_t n_constraints = PyTuple_GET_SIZE(constraints);
+        if (n_constraints == 1) {
+            PyErr_SetString(PyExc_TypeError,
+                            "A single constraint is not allowed");
+            Py_XDECREF(bound);
+            return NULL;
+        } else if (n_constraints == 0) {
+            constraints = NULL;
+        } else if (bound != NULL) {
+            PyErr_SetString(PyExc_TypeError,
+                            "Constraints cannot be combined with bound=...");
+            Py_XDECREF(bound);
+            return NULL;
+        }
     }
     PyObject *module = caller();
     if (module == NULL) {
diff --git a/Parser/parser.c b/Parser/parser.c
index 5d2adf7417..25b4ead781 100644
--- a/Parser/parser.c
+++ b/Parser/parser.c
@@ -82,159 +82,159 @@ static char *soft_keywords[] = {
 #define interactive_type 1001
 #define eval_type 1002
 #define func_type_type 1003
-#define fstring_type 1004
-#define statements_type 1005
-#define statement_type 1006
-#define statement_newline_type 1007
-#define simple_stmts_type 1008
-#define simple_stmt_type 1009
-#define compound_stmt_type 1010
-#define assignment_type 1011
-#define annotated_rhs_type 1012
-#define augassign_type 1013
-#define return_stmt_type 1014
-#define raise_stmt_type 1015
-#define global_stmt_type 1016
-#define nonlocal_stmt_type 1017
-#define del_stmt_type 1018
-#define yield_stmt_type 1019
-#define assert_stmt_type 1020
-#define import_stmt_type 1021
-#define import_name_type 1022
-#define import_from_type 1023
-#define import_from_targets_type 1024
-#define import_from_as_names_type 1025
-#define import_from_as_name_type 1026
-#define dotted_as_names_type 1027
-#define dotted_as_name_type 1028
-#define dotted_name_type 1029  // Left-recursive
-#define block_type 1030
-#define decorators_type 1031
-#define class_def_type 1032
-#define class_def_raw_type 1033
-#define function_def_type 1034
-#define function_def_raw_type 1035
-#define params_type 1036
-#define parameters_type 1037
-#define slash_no_default_type 1038
-#define slash_with_default_type 1039
-#define star_etc_type 1040
-#define kwds_type 1041
-#define param_no_default_type 1042
-#define param_no_default_star_annotation_type 1043
-#define param_with_default_type 1044
-#define param_maybe_default_type 1045
-#define param_type 1046
-#define param_star_annotation_type 1047
-#define annotation_type 1048
-#define star_annotation_type 1049
-#define default_type 1050
-#define if_stmt_type 1051
-#define elif_stmt_type 1052
-#define else_block_type 1053
-#define while_stmt_type 1054
-#define for_stmt_type 1055
-#define with_stmt_type 1056
-#define with_item_type 1057
-#define try_stmt_type 1058
-#define except_block_type 1059
-#define except_star_block_type 1060
-#define finally_block_type 1061
-#define match_stmt_type 1062
-#define subject_expr_type 1063
-#define case_block_type 1064
-#define guard_type 1065
-#define patterns_type 1066
-#define pattern_type 1067
-#define as_pattern_type 1068
-#define or_pattern_type 1069
-#define closed_pattern_type 1070
-#define literal_pattern_type 1071
-#define literal_expr_type 1072
-#define complex_number_type 1073
-#define signed_number_type 1074
-#define signed_real_number_type 1075
-#define real_number_type 1076
-#define imaginary_number_type 1077
-#define capture_pattern_type 1078
-#define pattern_capture_target_type 1079
-#define wildcard_pattern_type 1080
-#define value_pattern_type 1081
-#define attr_type 1082  // Left-recursive
-#define name_or_attr_type 1083  // Left-recursive
-#define group_pattern_type 1084
-#define sequence_pattern_type 1085
-#define open_sequence_pattern_type 1086
-#define maybe_sequence_pattern_type 1087
-#define maybe_star_pattern_type 1088
-#define star_pattern_type 1089
-#define mapping_pattern_type 1090
-#define items_pattern_type 1091
-#define key_value_pattern_type 1092
-#define double_star_pattern_type 1093
-#define class_pattern_type 1094
-#define positional_patterns_type 1095
-#define keyword_patterns_type 1096
-#define keyword_pattern_type 1097
-#define type_alias_type 1098
-#define type_params_type 1099
-#define type_param_seq_type 1100
-#define type_param_type 1101
-#define type_param_bound_type 1102
-#define expressions_type 1103
-#define expression_type 1104
-#define yield_expr_type 1105
-#define star_expressions_type 1106
-#define star_expression_type 1107
-#define star_named_expressions_type 1108
-#define star_named_expression_type 1109
-#define assignment_expression_type 1110
-#define named_expression_type 1111
-#define disjunction_type 1112
-#define conjunction_type 1113
-#define inversion_type 1114
-#define comparison_type 1115
-#define compare_op_bitwise_or_pair_type 1116
-#define eq_bitwise_or_type 1117
-#define noteq_bitwise_or_type 1118
-#define lte_bitwise_or_type 1119
-#define lt_bitwise_or_type 1120
-#define gte_bitwise_or_type 1121
-#define gt_bitwise_or_type 1122
-#define notin_bitwise_or_type 1123
-#define in_bitwise_or_type 1124
-#define isnot_bitwise_or_type 1125
-#define is_bitwise_or_type 1126
-#define bitwise_or_type 1127  // Left-recursive
-#define bitwise_xor_type 1128  // Left-recursive
-#define bitwise_and_type 1129  // Left-recursive
-#define shift_expr_type 1130  // Left-recursive
-#define sum_type 1131  // Left-recursive
-#define term_type 1132  // Left-recursive
-#define factor_type 1133
-#define power_type 1134
-#define await_primary_type 1135
-#define primary_type 1136  // Left-recursive
-#define slices_type 1137
-#define slice_type 1138
-#define atom_type 1139
-#define group_type 1140
-#define lambdef_type 1141
-#define lambda_params_type 1142
-#define lambda_parameters_type 1143
-#define lambda_slash_no_default_type 1144
-#define lambda_slash_with_default_type 1145
-#define lambda_star_etc_type 1146
-#define lambda_kwds_type 1147
-#define lambda_param_no_default_type 1148
-#define lambda_param_with_default_type 1149
-#define lambda_param_maybe_default_type 1150
-#define lambda_param_type 1151
-#define fstring_middle_type 1152
-#define fstring_replacement_field_type 1153
-#define fstring_conversion_type 1154
-#define fstring_full_format_spec_type 1155
-#define fstring_format_spec_type 1156
+#define statements_type 1004
+#define statement_type 1005
+#define statement_newline_type 1006
+#define simple_stmts_type 1007
+#define simple_stmt_type 1008
+#define compound_stmt_type 1009
+#define assignment_type 1010
+#define annotated_rhs_type 1011
+#define augassign_type 1012
+#define return_stmt_type 1013
+#define raise_stmt_type 1014
+#define global_stmt_type 1015
+#define nonlocal_stmt_type 1016
+#define del_stmt_type 1017
+#define yield_stmt_type 1018
+#define assert_stmt_type 1019
+#define import_stmt_type 1020
+#define import_name_type 1021
+#define import_from_type 1022
+#define import_from_targets_type 1023
+#define import_from_as_names_type 1024
+#define import_from_as_name_type 1025
+#define dotted_as_names_type 1026
+#define dotted_as_name_type 1027
+#define dotted_name_type 1028  // Left-recursive
+#define block_type 1029
+#define decorators_type 1030
+#define class_def_type 1031
+#define class_def_raw_type 1032
+#define function_def_type 1033
+#define function_def_raw_type 1034
+#define params_type 1035
+#define parameters_type 1036
+#define slash_no_default_type 1037
+#define slash_with_default_type 1038
+#define star_etc_type 1039
+#define kwds_type 1040
+#define param_no_default_type 1041
+#define param_no_default_star_annotation_type 1042
+#define param_with_default_type 1043
+#define param_maybe_default_type 1044
+#define param_type 1045
+#define param_star_annotation_type 1046
+#define annotation_type 1047
+#define star_annotation_type 1048
+#define default_type 1049
+#define if_stmt_type 1050
+#define elif_stmt_type 1051
+#define else_block_type 1052
+#define while_stmt_type 1053
+#define for_stmt_type 1054
+#define with_stmt_type 1055
+#define with_item_type 1056
+#define try_stmt_type 1057
+#define except_block_type 1058
+#define except_star_block_type 1059
+#define finally_block_type 1060
+#define match_stmt_type 1061
+#define subject_expr_type 1062
+#define case_block_type 1063
+#define guard_type 1064
+#define patterns_type 1065
+#define pattern_type 1066
+#define as_pattern_type 1067
+#define or_pattern_type 1068
+#define closed_pattern_type 1069
+#define literal_pattern_type 1070
+#define literal_expr_type 1071
+#define complex_number_type 1072
+#define signed_number_type 1073
+#define signed_real_number_type 1074
+#define real_number_type 1075
+#define imaginary_number_type 1076
+#define capture_pattern_type 1077
+#define pattern_capture_target_type 1078
+#define wildcard_pattern_type 1079
+#define value_pattern_type 1080
+#define attr_type 1081  // Left-recursive
+#define name_or_attr_type 1082  // Left-recursive
+#define group_pattern_type 1083
+#define sequence_pattern_type 1084
+#define open_sequence_pattern_type 1085
+#define maybe_sequence_pattern_type 1086
+#define maybe_star_pattern_type 1087
+#define star_pattern_type 1088
+#define mapping_pattern_type 1089
+#define items_pattern_type 1090
+#define key_value_pattern_type 1091
+#define double_star_pattern_type 1092
+#define class_pattern_type 1093
+#define positional_patterns_type 1094
+#define keyword_patterns_type 1095
+#define keyword_pattern_type 1096
+#define type_alias_type 1097
+#define type_params_type 1098
+#define type_param_seq_type 1099
+#define type_param_type 1100
+#define type_param_bound_type 1101
+#define expressions_type 1102
+#define expression_type 1103
+#define yield_expr_type 1104
+#define star_expressions_type 1105
+#define star_expression_type 1106
+#define star_named_expressions_type 1107
+#define star_named_expression_type 1108
+#define assignment_expression_type 1109
+#define named_expression_type 1110
+#define disjunction_type 1111
+#define conjunction_type 1112
+#define inversion_type 1113
+#define comparison_type 1114
+#define compare_op_bitwise_or_pair_type 1115
+#define eq_bitwise_or_type 1116
+#define noteq_bitwise_or_type 1117
+#define lte_bitwise_or_type 1118
+#define lt_bitwise_or_type 1119
+#define gte_bitwise_or_type 1120
+#define gt_bitwise_or_type 1121
+#define notin_bitwise_or_type 1122
+#define in_bitwise_or_type 1123
+#define isnot_bitwise_or_type 1124
+#define is_bitwise_or_type 1125
+#define bitwise_or_type 1126  // Left-recursive
+#define bitwise_xor_type 1127  // Left-recursive
+#define bitwise_and_type 1128  // Left-recursive
+#define shift_expr_type 1129  // Left-recursive
+#define sum_type 1130  // Left-recursive
+#define term_type 1131  // Left-recursive
+#define factor_type 1132
+#define power_type 1133
+#define await_primary_type 1134
+#define primary_type 1135  // Left-recursive
+#define slices_type 1136
+#define slice_type 1137
+#define atom_type 1138
+#define group_type 1139
+#define lambdef_type 1140
+#define lambda_params_type 1141
+#define lambda_parameters_type 1142
+#define lambda_slash_no_default_type 1143
+#define lambda_slash_with_default_type 1144
+#define lambda_star_etc_type 1145
+#define lambda_kwds_type 1146
+#define lambda_param_no_default_type 1147
+#define lambda_param_with_default_type 1148
+#define lambda_param_maybe_default_type 1149
+#define lambda_param_type 1150
+#define fstring_middle_type 1151
+#define fstring_replacement_field_type 1152
+#define fstring_conversion_type 1153
+#define fstring_full_format_spec_type 1154
+#define fstring_format_spec_type 1155
+#define fstring_type 1156
 #define string_type 1157
 #define strings_type 1158
 #define list_type 1159
@@ -324,10 +324,10 @@ static char *soft_keywords[] = {
 #define invalid_conversion_character_type 1243
 #define _loop0_1_type 1244
 #define _loop0_2_type 1245
-#define _loop0_3_type 1246
-#define _loop1_4_type 1247
-#define _loop0_6_type 1248
-#define _gather_5_type 1249
+#define _loop1_3_type 1246
+#define _loop0_5_type 1247
+#define _gather_4_type 1248
+#define _tmp_6_type 1249
 #define _tmp_7_type 1250
 #define _tmp_8_type 1251
 #define _tmp_9_type 1252
@@ -335,106 +335,106 @@ static char *soft_keywords[] = {
 #define _tmp_11_type 1254
 #define _tmp_12_type 1255
 #define _tmp_13_type 1256
-#define _tmp_14_type 1257
-#define _loop1_15_type 1258
+#define _loop1_14_type 1257
+#define _tmp_15_type 1258
 #define _tmp_16_type 1259
 #define _tmp_17_type 1260
-#define _tmp_18_type 1261
-#define _loop0_20_type 1262
-#define _gather_19_type 1263
-#define _loop0_22_type 1264
-#define _gather_21_type 1265
+#define _loop0_19_type 1261
+#define _gather_18_type 1262
+#define _loop0_21_type 1263
+#define _gather_20_type 1264
+#define _tmp_22_type 1265
 #define _tmp_23_type 1266
-#define _tmp_24_type 1267
-#define _loop0_25_type 1268
-#define _loop1_26_type 1269
-#define _loop0_28_type 1270
-#define _gather_27_type 1271
-#define _tmp_29_type 1272
-#define _loop0_31_type 1273
-#define _gather_30_type 1274
-#define _tmp_32_type 1275
-#define _loop1_33_type 1276
+#define _loop0_24_type 1267
+#define _loop1_25_type 1268
+#define _loop0_27_type 1269
+#define _gather_26_type 1270
+#define _tmp_28_type 1271
+#define _loop0_30_type 1272
+#define _gather_29_type 1273
+#define _tmp_31_type 1274
+#define _loop1_32_type 1275
+#define _tmp_33_type 1276
 #define _tmp_34_type 1277
 #define _tmp_35_type 1278
-#define _tmp_36_type 1279
+#define _loop0_36_type 1279
 #define _loop0_37_type 1280
 #define _loop0_38_type 1281
-#define _loop0_39_type 1282
-#define _loop1_40_type 1283
-#define _loop0_41_type 1284
+#define _loop1_39_type 1282
+#define _loop0_40_type 1283
+#define _loop1_41_type 1284
 #define _loop1_42_type 1285
 #define _loop1_43_type 1286
-#define _loop1_44_type 1287
-#define _loop0_45_type 1288
-#define _loop1_46_type 1289
-#define _loop0_47_type 1290
-#define _loop1_48_type 1291
+#define _loop0_44_type 1287
+#define _loop1_45_type 1288
+#define _loop0_46_type 1289
+#define _loop1_47_type 1290
+#define _loop0_48_type 1291
 #define _loop0_49_type 1292
-#define _loop0_50_type 1293
-#define _loop1_51_type 1294
-#define _loop0_53_type 1295
-#define _gather_52_type 1296
-#define _loop0_55_type 1297
-#define _gather_54_type 1298
-#define _loop0_57_type 1299
-#define _gather_56_type 1300
-#define _loop0_59_type 1301
-#define _gather_58_type 1302
-#define _tmp_60_type 1303
+#define _loop1_50_type 1293
+#define _loop0_52_type 1294
+#define _gather_51_type 1295
+#define _loop0_54_type 1296
+#define _gather_53_type 1297
+#define _loop0_56_type 1298
+#define _gather_55_type 1299
+#define _loop0_58_type 1300
+#define _gather_57_type 1301
+#define _tmp_59_type 1302
+#define _loop1_60_type 1303
 #define _loop1_61_type 1304
-#define _loop1_62_type 1305
+#define _tmp_62_type 1305
 #define _tmp_63_type 1306
-#define _tmp_64_type 1307
-#define _loop1_65_type 1308
-#define _loop0_67_type 1309
-#define _gather_66_type 1310
+#define _loop1_64_type 1307
+#define _loop0_66_type 1308
+#define _gather_65_type 1309
+#define _tmp_67_type 1310
 #define _tmp_68_type 1311
 #define _tmp_69_type 1312
 #define _tmp_70_type 1313
-#define _tmp_71_type 1314
-#define _loop0_73_type 1315
-#define _gather_72_type 1316
-#define _loop0_75_type 1317
-#define _gather_74_type 1318
-#define _tmp_76_type 1319
-#define _loop0_78_type 1320
-#define _gather_77_type 1321
-#define _loop0_80_type 1322
-#define _gather_79_type 1323
-#define _loop0_82_type 1324
-#define _gather_81_type 1325
+#define _loop0_72_type 1314
+#define _gather_71_type 1315
+#define _loop0_74_type 1316
+#define _gather_73_type 1317
+#define _tmp_75_type 1318
+#define _loop0_77_type 1319
+#define _gather_76_type 1320
+#define _loop0_79_type 1321
+#define _gather_78_type 1322
+#define _loop0_81_type 1323
+#define _gather_80_type 1324
+#define _loop1_82_type 1325
 #define _loop1_83_type 1326
-#define _loop1_84_type 1327
-#define _loop0_86_type 1328
-#define _gather_85_type 1329
+#define _loop0_85_type 1327
+#define _gather_84_type 1328
+#define _loop1_86_type 1329
 #define _loop1_87_type 1330
 #define _loop1_88_type 1331
-#define _loop1_89_type 1332
-#define _tmp_90_type 1333
-#define _loop0_92_type 1334
-#define _gather_91_type 1335
+#define _tmp_89_type 1332
+#define _loop0_91_type 1333
+#define _gather_90_type 1334
+#define _tmp_92_type 1335
 #define _tmp_93_type 1336
 #define _tmp_94_type 1337
 #define _tmp_95_type 1338
 #define _tmp_96_type 1339
 #define _tmp_97_type 1340
-#define _tmp_98_type 1341
+#define _loop0_98_type 1341
 #define _loop0_99_type 1342
 #define _loop0_100_type 1343
-#define _loop0_101_type 1344
-#define _loop1_102_type 1345
-#define _loop0_103_type 1346
+#define _loop1_101_type 1344
+#define _loop0_102_type 1345
+#define _loop1_103_type 1346
 #define _loop1_104_type 1347
 #define _loop1_105_type 1348
-#define _loop1_106_type 1349
-#define _loop0_107_type 1350
-#define _loop1_108_type 1351
-#define _loop0_109_type 1352
-#define _loop1_110_type 1353
-#define _loop0_111_type 1354
-#define _loop1_112_type 1355
-#define _tmp_113_type 1356
+#define _loop0_106_type 1349
+#define _loop1_107_type 1350
+#define _loop0_108_type 1351
+#define _loop1_109_type 1352
+#define _loop0_110_type 1353
+#define _loop1_111_type 1354
+#define _tmp_112_type 1355
+#define _loop0_113_type 1356
 #define _loop0_114_type 1357
 #define _loop1_115_type 1358
 #define _tmp_116_type 1359
@@ -481,65 +481,65 @@ static char *soft_keywords[] = {
 #define _tmp_157_type 1400
 #define _tmp_158_type 1401
 #define _tmp_159_type 1402
-#define _loop0_160_type 1403
+#define _tmp_160_type 1403
 #define _loop0_161_type 1404
 #define _loop0_162_type 1405
-#define _tmp_163_type 1406
+#define _loop0_163_type 1406
 #define _tmp_164_type 1407
 #define _tmp_165_type 1408
 #define _tmp_166_type 1409
 #define _tmp_167_type 1410
-#define _loop0_168_type 1411
+#define _tmp_168_type 1411
 #define _loop0_169_type 1412
 #define _loop0_170_type 1413
-#define _loop1_171_type 1414
-#define _tmp_172_type 1415
-#define _loop0_173_type 1416
-#define _tmp_174_type 1417
-#define _loop0_175_type 1418
-#define _loop1_176_type 1419
-#define _tmp_177_type 1420
+#define _loop0_171_type 1414
+#define _loop1_172_type 1415
+#define _tmp_173_type 1416
+#define _loop0_174_type 1417
+#define _tmp_175_type 1418
+#define _loop0_176_type 1419
+#define _loop1_177_type 1420
 #define _tmp_178_type 1421
 #define _tmp_179_type 1422
-#define _loop0_180_type 1423
-#define _tmp_181_type 1424
+#define _tmp_180_type 1423
+#define _loop0_181_type 1424
 #define _tmp_182_type 1425
-#define _loop1_183_type 1426
-#define _tmp_184_type 1427
-#define _loop0_185_type 1428
+#define _tmp_183_type 1426
+#define _loop1_184_type 1427
+#define _tmp_185_type 1428
 #define _loop0_186_type 1429
 #define _loop0_187_type 1430
-#define _loop0_189_type 1431
-#define _gather_188_type 1432
-#define _tmp_190_type 1433
-#define _loop0_191_type 1434
-#define _tmp_192_type 1435
-#define _loop0_193_type 1436
-#define _loop1_194_type 1437
+#define _loop0_188_type 1431
+#define _loop0_190_type 1432
+#define _gather_189_type 1433
+#define _tmp_191_type 1434
+#define _loop0_192_type 1435
+#define _tmp_193_type 1436
+#define _loop0_194_type 1437
 #define _loop1_195_type 1438
-#define _tmp_196_type 1439
+#define _loop1_196_type 1439
 #define _tmp_197_type 1440
-#define _loop0_198_type 1441
-#define _tmp_199_type 1442
+#define _tmp_198_type 1441
+#define _loop0_199_type 1442
 #define _tmp_200_type 1443
 #define _tmp_201_type 1444
-#define _loop0_203_type 1445
-#define _gather_202_type 1446
-#define _loop0_205_type 1447
-#define _gather_204_type 1448
-#define _loop0_207_type 1449
-#define _gather_206_type 1450
-#define _loop0_209_type 1451
-#define _gather_208_type 1452
-#define _loop0_211_type 1453
-#define _gather_210_type 1454
-#define _tmp_212_type 1455
-#define _loop0_213_type 1456
-#define _loop1_214_type 1457
-#define _tmp_215_type 1458
-#define _loop0_216_type 1459
-#define _loop1_217_type 1460
-#define _tmp_218_type 1461
+#define _tmp_202_type 1445
+#define _loop0_204_type 1446
+#define _gather_203_type 1447
+#define _loop0_206_type 1448
+#define _gather_205_type 1449
+#define _loop0_208_type 1450
+#define _gather_207_type 1451
+#define _loop0_210_type 1452
+#define _gather_209_type 1453
+#define _loop0_212_type 1454
+#define _gather_211_type 1455
+#define _tmp_213_type 1456
+#define _loop0_214_type 1457
+#define _loop1_215_type 1458
+#define _tmp_216_type 1459
+#define _loop0_217_type 1460
+#define _loop1_218_type 1461
 #define _tmp_219_type 1462
 #define _tmp_220_type 1463
 #define _tmp_221_type 1464
@@ -549,9 +549,9 @@ static char *soft_keywords[] = {
 #define _tmp_225_type 1468
 #define _tmp_226_type 1469
 #define _tmp_227_type 1470
-#define _loop0_229_type 1471
-#define _gather_228_type 1472
-#define _tmp_230_type 1473
+#define _tmp_228_type 1471
+#define _loop0_230_type 1472
+#define _gather_229_type 1473
 #define _tmp_231_type 1474
 #define _tmp_232_type 1475
 #define _tmp_233_type 1476
@@ -564,8 +564,8 @@ static char *soft_keywords[] = {
 #define _tmp_240_type 1483
 #define _tmp_241_type 1484
 #define _tmp_242_type 1485
-#define _loop0_243_type 1486
-#define _tmp_244_type 1487
+#define _tmp_243_type 1486
+#define _loop0_244_type 1487
 #define _tmp_245_type 1488
 #define _tmp_246_type 1489
 #define _tmp_247_type 1490
@@ -595,14 +595,19 @@ static char *soft_keywords[] = {
 #define _tmp_271_type 1514
 #define _tmp_272_type 1515
 #define _tmp_273_type 1516
-#define _tmp_274_type 1517
-#define _tmp_275_type 1518
+#define _loop0_275_type 1517
+#define _gather_274_type 1518
+#define _tmp_276_type 1519
+#define _tmp_277_type 1520
+#define _tmp_278_type 1521
+#define _tmp_279_type 1522
+#define _tmp_280_type 1523
+#define _tmp_281_type 1524
 
 static mod_ty file_rule(Parser *p);
 static mod_ty interactive_rule(Parser *p);
 static mod_ty eval_rule(Parser *p);
 static mod_ty func_type_rule(Parser *p);
-static expr_ty fstring_rule(Parser *p);
 static asdl_stmt_seq* statements_rule(Parser *p);
 static asdl_stmt_seq* statement_rule(Parser *p);
 static asdl_stmt_seq* statement_newline_rule(Parser *p);
@@ -755,6 +760,7 @@ static expr_ty fstring_replacement_field_rule(Parser *p);
 static ResultTokenWithMetadata* fstring_conversion_rule(Parser *p);
 static ResultTokenWithMetadata* fstring_full_format_spec_rule(Parser *p);
 static expr_ty fstring_format_spec_rule(Parser *p);
+static expr_ty fstring_rule(Parser *p);
 static expr_ty string_rule(Parser *p);
 static expr_ty strings_rule(Parser *p);
 static expr_ty list_rule(Parser *p);
@@ -844,10 +850,10 @@ static void *invalid_replacement_field_rule(Parser *p);
 static void *invalid_conversion_character_rule(Parser *p);
 static asdl_seq *_loop0_1_rule(Parser *p);
 static asdl_seq *_loop0_2_rule(Parser *p);
-static asdl_seq *_loop0_3_rule(Parser *p);
-static asdl_seq *_loop1_4_rule(Parser *p);
-static asdl_seq *_loop0_6_rule(Parser *p);
-static asdl_seq *_gather_5_rule(Parser *p);
+static asdl_seq *_loop1_3_rule(Parser *p);
+static asdl_seq *_loop0_5_rule(Parser *p);
+static asdl_seq *_gather_4_rule(Parser *p);
+static void *_tmp_6_rule(Parser *p);
 static void *_tmp_7_rule(Parser *p);
 static void *_tmp_8_rule(Parser *p);
 static void *_tmp_9_rule(Parser *p);
@@ -855,106 +861,106 @@ static void *_tmp_10_rule(Parser *p);
 static void *_tmp_11_rule(Parser *p);
 static void *_tmp_12_rule(Parser *p);
 static void *_tmp_13_rule(Parser *p);
-static void *_tmp_14_rule(Parser *p);
-static asdl_seq *_loop1_15_rule(Parser *p);
+static asdl_seq *_loop1_14_rule(Parser *p);
+static void *_tmp_15_rule(Parser *p);
 static void *_tmp_16_rule(Parser *p);
 static void *_tmp_17_rule(Parser *p);
-static void *_tmp_18_rule(Parser *p);
-static asdl_seq *_loop0_20_rule(Parser *p);
-static asdl_seq *_gather_19_rule(Parser *p);
-static asdl_seq *_loop0_22_rule(Parser *p);
-static asdl_seq *_gather_21_rule(Parser *p);
+static asdl_seq *_loop0_19_rule(Parser *p);
+static asdl_seq *_gather_18_rule(Parser *p);
+static asdl_seq *_loop0_21_rule(Parser *p);
+static asdl_seq *_gather_20_rule(Parser *p);
+static void *_tmp_22_rule(Parser *p);
 static void *_tmp_23_rule(Parser *p);
-static void *_tmp_24_rule(Parser *p);
-static asdl_seq *_loop0_25_rule(Parser *p);
-static asdl_seq *_loop1_26_rule(Parser *p);
-static asdl_seq *_loop0_28_rule(Parser *p);
-static asdl_seq *_gather_27_rule(Parser *p);
-static void *_tmp_29_rule(Parser *p);
-static asdl_seq *_loop0_31_rule(Parser *p);
-static asdl_seq *_gather_30_rule(Parser *p);
-static void *_tmp_32_rule(Parser *p);
-static asdl_seq *_loop1_33_rule(Parser *p);
+static asdl_seq *_loop0_24_rule(Parser *p);
+static asdl_seq *_loop1_25_rule(Parser *p);
+static asdl_seq *_loop0_27_rule(Parser *p);
+static asdl_seq *_gather_26_rule(Parser *p);
+static void *_tmp_28_rule(Parser *p);
+static asdl_seq *_loop0_30_rule(Parser *p);
+static asdl_seq *_gather_29_rule(Parser *p);
+static void *_tmp_31_rule(Parser *p);
+static asdl_seq *_loop1_32_rule(Parser *p);
+static void *_tmp_33_rule(Parser *p);
 static void *_tmp_34_rule(Parser *p);
 static void *_tmp_35_rule(Parser *p);
-static void *_tmp_36_rule(Parser *p);
+static asdl_seq *_loop0_36_rule(Parser *p);
 static asdl_seq *_loop0_37_rule(Parser *p);
 static asdl_seq *_loop0_38_rule(Parser *p);
-static asdl_seq *_loop0_39_rule(Parser *p);
-static asdl_seq *_loop1_40_rule(Parser *p);
-static asdl_seq *_loop0_41_rule(Parser *p);
+static asdl_seq *_loop1_39_rule(Parser *p);
+static asdl_seq *_loop0_40_rule(Parser *p);
+static asdl_seq *_loop1_41_rule(Parser *p);
 static asdl_seq *_loop1_42_rule(Parser *p);
 static asdl_seq *_loop1_43_rule(Parser *p);
-static asdl_seq *_loop1_44_rule(Parser *p);
-static asdl_seq *_loop0_45_rule(Parser *p);
-static asdl_seq *_loop1_46_rule(Parser *p);
-static asdl_seq *_loop0_47_rule(Parser *p);
-static asdl_seq *_loop1_48_rule(Parser *p);
+static asdl_seq *_loop0_44_rule(Parser *p);
+static asdl_seq *_loop1_45_rule(Parser *p);
+static asdl_seq *_loop0_46_rule(Parser *p);
+static asdl_seq *_loop1_47_rule(Parser *p);
+static asdl_seq *_loop0_48_rule(Parser *p);
 static asdl_seq *_loop0_49_rule(Parser *p);
-static asdl_seq *_loop0_50_rule(Parser *p);
-static asdl_seq *_loop1_51_rule(Parser *p);
-static asdl_seq *_loop0_53_rule(Parser *p);
-static asdl_seq *_gather_52_rule(Parser *p);
-static asdl_seq *_loop0_55_rule(Parser *p);
-static asdl_seq *_gather_54_rule(Parser *p);
-static asdl_seq *_loop0_57_rule(Parser *p);
-static asdl_seq *_gather_56_rule(Parser *p);
-static asdl_seq *_loop0_59_rule(Parser *p);
-static asdl_seq *_gather_58_rule(Parser *p);
-static void *_tmp_60_rule(Parser *p);
+static asdl_seq *_loop1_50_rule(Parser *p);
+static asdl_seq *_loop0_52_rule(Parser *p);
+static asdl_seq *_gather_51_rule(Parser *p);
+static asdl_seq *_loop0_54_rule(Parser *p);
+static asdl_seq *_gather_53_rule(Parser *p);
+static asdl_seq *_loop0_56_rule(Parser *p);
+static asdl_seq *_gather_55_rule(Parser *p);
+static asdl_seq *_loop0_58_rule(Parser *p);
+static asdl_seq *_gather_57_rule(Parser *p);
+static void *_tmp_59_rule(Parser *p);
+static asdl_seq *_loop1_60_rule(Parser *p);
 static asdl_seq *_loop1_61_rule(Parser *p);
-static asdl_seq *_loop1_62_rule(Parser *p);
+static void *_tmp_62_rule(Parser *p);
 static void *_tmp_63_rule(Parser *p);
-static void *_tmp_64_rule(Parser *p);
-static asdl_seq *_loop1_65_rule(Parser *p);
-static asdl_seq *_loop0_67_rule(Parser *p);
-static asdl_seq *_gather_66_rule(Parser *p);
+static asdl_seq *_loop1_64_rule(Parser *p);
+static asdl_seq *_loop0_66_rule(Parser *p);
+static asdl_seq *_gather_65_rule(Parser *p);
+static void *_tmp_67_rule(Parser *p);
 static void *_tmp_68_rule(Parser *p);
 static void *_tmp_69_rule(Parser *p);
 static void *_tmp_70_rule(Parser *p);
-static void *_tmp_71_rule(Parser *p);
-static asdl_seq *_loop0_73_rule(Parser *p);
-static asdl_seq *_gather_72_rule(Parser *p);
-static asdl_seq *_loop0_75_rule(Parser *p);
-static asdl_seq *_gather_74_rule(Parser *p);
-static void *_tmp_76_rule(Parser *p);
-static asdl_seq *_loop0_78_rule(Parser *p);
-static asdl_seq *_gather_77_rule(Parser *p);
-static asdl_seq *_loop0_80_rule(Parser *p);
-static asdl_seq *_gather_79_rule(Parser *p);
-static asdl_seq *_loop0_82_rule(Parser *p);
-static asdl_seq *_gather_81_rule(Parser *p);
+static asdl_seq *_loop0_72_rule(Parser *p);
+static asdl_seq *_gather_71_rule(Parser *p);
+static asdl_seq *_loop0_74_rule(Parser *p);
+static asdl_seq *_gather_73_rule(Parser *p);
+static void *_tmp_75_rule(Parser *p);
+static asdl_seq *_loop0_77_rule(Parser *p);
+static asdl_seq *_gather_76_rule(Parser *p);
+static asdl_seq *_loop0_79_rule(Parser *p);
+static asdl_seq *_gather_78_rule(Parser *p);
+static asdl_seq *_loop0_81_rule(Parser *p);
+static asdl_seq *_gather_80_rule(Parser *p);
+static asdl_seq *_loop1_82_rule(Parser *p);
 static asdl_seq *_loop1_83_rule(Parser *p);
-static asdl_seq *_loop1_84_rule(Parser *p);
-static asdl_seq *_loop0_86_rule(Parser *p);
-static asdl_seq *_gather_85_rule(Parser *p);
+static asdl_seq *_loop0_85_rule(Parser *p);
+static asdl_seq *_gather_84_rule(Parser *p);
+static asdl_seq *_loop1_86_rule(Parser *p);
 static asdl_seq *_loop1_87_rule(Parser *p);
 static asdl_seq *_loop1_88_rule(Parser *p);
-static asdl_seq *_loop1_89_rule(Parser *p);
-static void *_tmp_90_rule(Parser *p);
-static asdl_seq *_loop0_92_rule(Parser *p);
-static asdl_seq *_gather_91_rule(Parser *p);
+static void *_tmp_89_rule(Parser *p);
+static asdl_seq *_loop0_91_rule(Parser *p);
+static asdl_seq *_gather_90_rule(Parser *p);
+static void *_tmp_92_rule(Parser *p);
 static void *_tmp_93_rule(Parser *p);
 static void *_tmp_94_rule(Parser *p);
 static void *_tmp_95_rule(Parser *p);
 static void *_tmp_96_rule(Parser *p);
 static void *_tmp_97_rule(Parser *p);
-static void *_tmp_98_rule(Parser *p);
+static asdl_seq *_loop0_98_rule(Parser *p);
 static asdl_seq *_loop0_99_rule(Parser *p);
 static asdl_seq *_loop0_100_rule(Parser *p);
-static asdl_seq *_loop0_101_rule(Parser *p);
-static asdl_seq *_loop1_102_rule(Parser *p);
-static asdl_seq *_loop0_103_rule(Parser *p);
+static asdl_seq *_loop1_101_rule(Parser *p);
+static asdl_seq *_loop0_102_rule(Parser *p);
+static asdl_seq *_loop1_103_rule(Parser *p);
 static asdl_seq *_loop1_104_rule(Parser *p);
 static asdl_seq *_loop1_105_rule(Parser *p);
-static asdl_seq *_loop1_106_rule(Parser *p);
-static asdl_seq *_loop0_107_rule(Parser *p);
-static asdl_seq *_loop1_108_rule(Parser *p);
-static asdl_seq *_loop0_109_rule(Parser *p);
-static asdl_seq *_loop1_110_rule(Parser *p);
-static asdl_seq *_loop0_111_rule(Parser *p);
-static asdl_seq *_loop1_112_rule(Parser *p);
-static void *_tmp_113_rule(Parser *p);
+static asdl_seq *_loop0_106_rule(Parser *p);
+static asdl_seq *_loop1_107_rule(Parser *p);
+static asdl_seq *_loop0_108_rule(Parser *p);
+static asdl_seq *_loop1_109_rule(Parser *p);
+static asdl_seq *_loop0_110_rule(Parser *p);
+static asdl_seq *_loop1_111_rule(Parser *p);
+static void *_tmp_112_rule(Parser *p);
+static asdl_seq *_loop0_113_rule(Parser *p);
 static asdl_seq *_loop0_114_rule(Parser *p);
 static asdl_seq *_loop1_115_rule(Parser *p);
 static void *_tmp_116_rule(Parser *p);
@@ -1001,65 +1007,65 @@ static void *_tmp_156_rule(Parser *p);
 static void *_tmp_157_rule(Parser *p);
 static void *_tmp_158_rule(Parser *p);
 static void *_tmp_159_rule(Parser *p);
-static asdl_seq *_loop0_160_rule(Parser *p);
+static void *_tmp_160_rule(Parser *p);
 static asdl_seq *_loop0_161_rule(Parser *p);
 static asdl_seq *_loop0_162_rule(Parser *p);
-static void *_tmp_163_rule(Parser *p);
+static asdl_seq *_loop0_163_rule(Parser *p);
 static void *_tmp_164_rule(Parser *p);
 static void *_tmp_165_rule(Parser *p);
 static void *_tmp_166_rule(Parser *p);
 static void *_tmp_167_rule(Parser *p);
-static asdl_seq *_loop0_168_rule(Parser *p);
+static void *_tmp_168_rule(Parser *p);
 static asdl_seq *_loop0_169_rule(Parser *p);
 static asdl_seq *_loop0_170_rule(Parser *p);
-static asdl_seq *_loop1_171_rule(Parser *p);
-static void *_tmp_172_rule(Parser *p);
-static asdl_seq *_loop0_173_rule(Parser *p);
-static void *_tmp_174_rule(Parser *p);
-static asdl_seq *_loop0_175_rule(Parser *p);
-static asdl_seq *_loop1_176_rule(Parser *p);
-static void *_tmp_177_rule(Parser *p);
+static asdl_seq *_loop0_171_rule(Parser *p);
+static asdl_seq *_loop1_172_rule(Parser *p);
+static void *_tmp_173_rule(Parser *p);
+static asdl_seq *_loop0_174_rule(Parser *p);
+static void *_tmp_175_rule(Parser *p);
+static asdl_seq *_loop0_176_rule(Parser *p);
+static asdl_seq *_loop1_177_rule(Parser *p);
 static void *_tmp_178_rule(Parser *p);
 static void *_tmp_179_rule(Parser *p);
-static asdl_seq *_loop0_180_rule(Parser *p);
-static void *_tmp_181_rule(Parser *p);
+static void *_tmp_180_rule(Parser *p);
+static asdl_seq *_loop0_181_rule(Parser *p);
 static void *_tmp_182_rule(Parser *p);
-static asdl_seq *_loop1_183_rule(Parser *p);
-static void *_tmp_184_rule(Parser *p);
-static asdl_seq *_loop0_185_rule(Parser *p);
+static void *_tmp_183_rule(Parser *p);
+static asdl_seq *_loop1_184_rule(Parser *p);
+static void *_tmp_185_rule(Parser *p);
 static asdl_seq *_loop0_186_rule(Parser *p);
 static asdl_seq *_loop0_187_rule(Parser *p);
-static asdl_seq *_loop0_189_rule(Parser *p);
-static asdl_seq *_gather_188_rule(Parser *p);
-static void *_tmp_190_rule(Parser *p);
-static asdl_seq *_loop0_191_rule(Parser *p);
-static void *_tmp_192_rule(Parser *p);
-static asdl_seq *_loop0_193_rule(Parser *p);
-static asdl_seq *_loop1_194_rule(Parser *p);
+static asdl_seq *_loop0_188_rule(Parser *p);
+static asdl_seq *_loop0_190_rule(Parser *p);
+static asdl_seq *_gather_189_rule(Parser *p);
+static void *_tmp_191_rule(Parser *p);
+static asdl_seq *_loop0_192_rule(Parser *p);
+static void *_tmp_193_rule(Parser *p);
+static asdl_seq *_loop0_194_rule(Parser *p);
 static asdl_seq *_loop1_195_rule(Parser *p);
-static void *_tmp_196_rule(Parser *p);
+static asdl_seq *_loop1_196_rule(Parser *p);
 static void *_tmp_197_rule(Parser *p);
-static asdl_seq *_loop0_198_rule(Parser *p);
-static void *_tmp_199_rule(Parser *p);
+static void *_tmp_198_rule(Parser *p);
+static asdl_seq *_loop0_199_rule(Parser *p);
 static void *_tmp_200_rule(Parser *p);
 static void *_tmp_201_rule(Parser *p);
-static asdl_seq *_loop0_203_rule(Parser *p);
-static asdl_seq *_gather_202_rule(Parser *p);
-static asdl_seq *_loop0_205_rule(Parser *p);
-static asdl_seq *_gather_204_rule(Parser *p);
-static asdl_seq *_loop0_207_rule(Parser *p);
-static asdl_seq *_gather_206_rule(Parser *p);
-static asdl_seq *_loop0_209_rule(Parser *p);
-static asdl_seq *_gather_208_rule(Parser *p);
-static asdl_seq *_loop0_211_rule(Parser *p);
-static asdl_seq *_gather_210_rule(Parser *p);
-static void *_tmp_212_rule(Parser *p);
-static asdl_seq *_loop0_213_rule(Parser *p);
-static asdl_seq *_loop1_214_rule(Parser *p);
-static void *_tmp_215_rule(Parser *p);
-static asdl_seq *_loop0_216_rule(Parser *p);
-static asdl_seq *_loop1_217_rule(Parser *p);
-static void *_tmp_218_rule(Parser *p);
+static void *_tmp_202_rule(Parser *p);
+static asdl_seq *_loop0_204_rule(Parser *p);
+static asdl_seq *_gather_203_rule(Parser *p);
+static asdl_seq *_loop0_206_rule(Parser *p);
+static asdl_seq *_gather_205_rule(Parser *p);
+static asdl_seq *_loop0_208_rule(Parser *p);
+static asdl_seq *_gather_207_rule(Parser *p);
+static asdl_seq *_loop0_210_rule(Parser *p);
+static asdl_seq *_gather_209_rule(Parser *p);
+static asdl_seq *_loop0_212_rule(Parser *p);
+static asdl_seq *_gather_211_rule(Parser *p);
+static void *_tmp_213_rule(Parser *p);
+static asdl_seq *_loop0_214_rule(Parser *p);
+static asdl_seq *_loop1_215_rule(Parser *p);
+static void *_tmp_216_rule(Parser *p);
+static asdl_seq *_loop0_217_rule(Parser *p);
+static asdl_seq *_loop1_218_rule(Parser *p);
 static void *_tmp_219_rule(Parser *p);
 static void *_tmp_220_rule(Parser *p);
 static void *_tmp_221_rule(Parser *p);
@@ -1069,9 +1075,9 @@ static void *_tmp_224_rule(Parser *p);
 static void *_tmp_225_rule(Parser *p);
 static void *_tmp_226_rule(Parser *p);
 static void *_tmp_227_rule(Parser *p);
-static asdl_seq *_loop0_229_rule(Parser *p);
-static asdl_seq *_gather_228_rule(Parser *p);
-static void *_tmp_230_rule(Parser *p);
+static void *_tmp_228_rule(Parser *p);
+static asdl_seq *_loop0_230_rule(Parser *p);
+static asdl_seq *_gather_229_rule(Parser *p);
 static void *_tmp_231_rule(Parser *p);
 static void *_tmp_232_rule(Parser *p);
 static void *_tmp_233_rule(Parser *p);
@@ -1084,8 +1090,8 @@ static void *_tmp_239_rule(Parser *p);
 static void *_tmp_240_rule(Parser *p);
 static void *_tmp_241_rule(Parser *p);
 static void *_tmp_242_rule(Parser *p);
-static asdl_seq *_loop0_243_rule(Parser *p);
-static void *_tmp_244_rule(Parser *p);
+static void *_tmp_243_rule(Parser *p);
+static asdl_seq *_loop0_244_rule(Parser *p);
 static void *_tmp_245_rule(Parser *p);
 static void *_tmp_246_rule(Parser *p);
 static void *_tmp_247_rule(Parser *p);
@@ -1115,8 +1121,14 @@ static void *_tmp_270_rule(Parser *p);
 static void *_tmp_271_rule(Parser *p);
 static void *_tmp_272_rule(Parser *p);
 static void *_tmp_273_rule(Parser *p);
-static void *_tmp_274_rule(Parser *p);
-static void *_tmp_275_rule(Parser *p);
+static asdl_seq *_loop0_275_rule(Parser *p);
+static asdl_seq *_gather_274_rule(Parser *p);
+static void *_tmp_276_rule(Parser *p);
+static void *_tmp_277_rule(Parser *p);
+static void *_tmp_278_rule(Parser *p);
+static void *_tmp_279_rule(Parser *p);
+static void *_tmp_280_rule(Parser *p);
+static void *_tmp_281_rule(Parser *p);
 
 
 // file: statements? $
@@ -1318,55 +1330,6 @@ func_type_rule(Parser *p)
     return _res;
 }
 
-// fstring: FSTRING_START fstring_middle* FSTRING_END
-static expr_ty
-fstring_rule(Parser *p)
-{
-    if (p->level++ == MAXSTACK) {
-        _Pypegen_stack_overflow(p);
-    }
-    if (p->error_indicator) {
-        p->level--;
-        return NULL;
-    }
-    expr_ty _res = NULL;
-    int _mark = p->mark;
-    { // FSTRING_START fstring_middle* FSTRING_END
-        if (p->error_indicator) {
-            p->level--;
-            return NULL;
-        }
-        D(fprintf(stderr, "%*c> fstring[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "FSTRING_START fstring_middle* FSTRING_END"));
-        Token * a;
-        asdl_seq * b;
-        Token * c;
-        if (
-            (a = _PyPegen_expect_token(p, FSTRING_START))  // token='FSTRING_START'
-            &&
-            (b = _loop0_3_rule(p))  // fstring_middle*
-            &&
-            (c = _PyPegen_expect_token(p, FSTRING_END))  // token='FSTRING_END'
-        )
-        {
-            D(fprintf(stderr, "%*c+ fstring[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "FSTRING_START fstring_middle* FSTRING_END"));
-            _res = _PyPegen_joined_str ( p , a , ( asdl_expr_seq* ) b , c );
-            if (_res == NULL && PyErr_Occurred()) {
-                p->error_indicator = 1;
-                p->level--;
-                return NULL;
-            }
-            goto done;
-        }
-        p->mark = _mark;
-        D(fprintf(stderr, "%*c%s fstring[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "FSTRING_START fstring_middle* FSTRING_END"));
-    }
-    _res = NULL;
-  done:
-    p->level--;
-    return _res;
-}
-
 // statements: statement+
 static asdl_stmt_seq*
 statements_rule(Parser *p)
@@ -1388,7 +1351,7 @@ statements_rule(Parser *p)
         D(fprintf(stderr, "%*c> statements[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "statement+"));
         asdl_seq * a;
         if (
-            (a = _loop1_4_rule(p))  // statement+
+            (a = _loop1_3_rule(p))  // statement+
         )
         {
             D(fprintf(stderr, "%*c+ statements[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "statement+"));
@@ -1661,7 +1624,7 @@ simple_stmts_rule(Parser *p)
         asdl_stmt_seq* a;
         Token * newline_var;
         if (
-            (a = (asdl_stmt_seq*)_gather_5_rule(p))  // ';'.simple_stmt+
+            (a = (asdl_stmt_seq*)_gather_4_rule(p))  // ';'.simple_stmt+
             &&
             (_opt_var = _PyPegen_expect_token(p, 13), !p->error_indicator)  // ';'?
             &&
@@ -1829,7 +1792,7 @@ simple_stmt_rule(Parser *p)
         D(fprintf(stderr, "%*c> simple_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&('import' | 'from') import_stmt"));
         stmt_ty import_stmt_var;
         if (
-            _PyPegen_lookahead(1, _tmp_7_rule, p)
+            _PyPegen_lookahead(1, _tmp_6_rule, p)
             &&
             (import_stmt_var = import_stmt_rule(p))  // import_stmt
         )
@@ -2103,7 +2066,7 @@ compound_stmt_rule(Parser *p)
         D(fprintf(stderr, "%*c> compound_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&('def' | '@' | ASYNC) function_def"));
         stmt_ty function_def_var;
         if (
-            _PyPegen_lookahead(1, _tmp_8_rule, p)
+            _PyPegen_lookahead(1, _tmp_7_rule, p)
             &&
             (function_def_var = function_def_rule(p))  // function_def
         )
@@ -2145,7 +2108,7 @@ compound_stmt_rule(Parser *p)
         D(fprintf(stderr, "%*c> compound_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&('class' | '@') class_def"));
         stmt_ty class_def_var;
         if (
-            _PyPegen_lookahead(1, _tmp_9_rule, p)
+            _PyPegen_lookahead(1, _tmp_8_rule, p)
             &&
             (class_def_var = class_def_rule(p))  // class_def
         )
@@ -2166,7 +2129,7 @@ compound_stmt_rule(Parser *p)
         D(fprintf(stderr, "%*c> compound_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&('with' | ASYNC) with_stmt"));
         stmt_ty with_stmt_var;
         if (
-            _PyPegen_lookahead(1, _tmp_10_rule, p)
+            _PyPegen_lookahead(1, _tmp_9_rule, p)
             &&
             (with_stmt_var = with_stmt_rule(p))  // with_stmt
         )
@@ -2187,7 +2150,7 @@ compound_stmt_rule(Parser *p)
         D(fprintf(stderr, "%*c> compound_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&('for' | ASYNC) for_stmt"));
         stmt_ty for_stmt_var;
         if (
-            _PyPegen_lookahead(1, _tmp_11_rule, p)
+            _PyPegen_lookahead(1, _tmp_10_rule, p)
             &&
             (for_stmt_var = for_stmt_rule(p))  // for_stmt
         )
@@ -2311,7 +2274,7 @@ assignment_rule(Parser *p)
             &&
             (b = expression_rule(p))  // expression
             &&
-            (c = _tmp_12_rule(p), !p->error_indicator)  // ['=' annotated_rhs]
+            (c = _tmp_11_rule(p), !p->error_indicator)  // ['=' annotated_rhs]
         )
         {
             D(fprintf(stderr, "%*c+ assignment[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME ':' expression ['=' annotated_rhs]"));
@@ -2347,13 +2310,13 @@ assignment_rule(Parser *p)
         expr_ty b;
         void *c;
         if (
-            (a = _tmp_13_rule(p))  // '(' single_target ')' | single_subscript_attribute_target
+            (a = _tmp_12_rule(p))  // '(' single_target ')' | single_subscript_attribute_target
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
             (b = expression_rule(p))  // expression
             &&
-            (c = _tmp_14_rule(p), !p->error_indicator)  // ['=' annotated_rhs]
+            (c = _tmp_13_rule(p), !p->error_indicator)  // ['=' annotated_rhs]
         )
         {
             D(fprintf(stderr, "%*c+ assignment[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "('(' single_target ')' | single_subscript_attribute_target) ':' expression ['=' annotated_rhs]"));
@@ -2388,9 +2351,9 @@ assignment_rule(Parser *p)
         void *b;
         void *tc;
         if (
-            (a = (asdl_expr_seq*)_loop1_15_rule(p))  // ((star_targets '='))+
+            (a = (asdl_expr_seq*)_loop1_14_rule(p))  // ((star_targets '='))+
             &&
-            (b = _tmp_16_rule(p))  // yield_expr | star_expressions
+            (b = _tmp_15_rule(p))  // yield_expr | star_expressions
             &&
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 22)  // token='='
             &&
@@ -2436,7 +2399,7 @@ assignment_rule(Parser *p)
             &&
             (_cut_var = 1)
             &&
-            (c = _tmp_17_rule(p))  // yield_expr | star_expressions
+            (c = _tmp_16_rule(p))  // yield_expr | star_expressions
         )
         {
             D(fprintf(stderr, "%*c+ assignment[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "single_target augassign ~ (yield_expr | star_expressions)"));
@@ -2991,7 +2954,7 @@ raise_stmt_rule(Parser *p)
             &&
             (a = expression_rule(p))  // expression
             &&
-            (b = _tmp_18_rule(p), !p->error_indicator)  // ['from' expression]
+            (b = _tmp_17_rule(p), !p->error_indicator)  // ['from' expression]
         )
         {
             D(fprintf(stderr, "%*c+ raise_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'raise' expression ['from' expression]"));
@@ -3088,7 +3051,7 @@ global_stmt_rule(Parser *p)
         if (
             (_keyword = _PyPegen_expect_token(p, 523))  // token='global'
             &&
-            (a = (asdl_expr_seq*)_gather_19_rule(p))  // ','.NAME+
+            (a = (asdl_expr_seq*)_gather_18_rule(p))  // ','.NAME+
         )
         {
             D(fprintf(stderr, "%*c+ global_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'global' ','.NAME+"));
@@ -3152,7 +3115,7 @@ nonlocal_stmt_rule(Parser *p)
         if (
             (_keyword = _PyPegen_expect_token(p, 524))  // token='nonlocal'
             &&
-            (a = (asdl_expr_seq*)_gather_21_rule(p))  // ','.NAME+
+            (a = (asdl_expr_seq*)_gather_20_rule(p))  // ','.NAME+
         )
         {
             D(fprintf(stderr, "%*c+ nonlocal_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'nonlocal' ','.NAME+"));
@@ -3218,7 +3181,7 @@ del_stmt_rule(Parser *p)
             &&
             (a = del_targets_rule(p))  // del_targets
             &&
-            _PyPegen_lookahead(1, _tmp_23_rule, p)
+            _PyPegen_lookahead(1, _tmp_22_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ del_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'del' del_targets &(';' | NEWLINE)"));
@@ -3365,7 +3328,7 @@ assert_stmt_rule(Parser *p)
             &&
             (a = expression_rule(p))  // expression
             &&
-            (b = _tmp_24_rule(p), !p->error_indicator)  // [',' expression]
+            (b = _tmp_23_rule(p), !p->error_indicator)  // [',' expression]
         )
         {
             D(fprintf(stderr, "%*c+ assert_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'assert' expression [',' expression]"));
@@ -3574,7 +3537,7 @@ import_from_rule(Parser *p)
         if (
             (_keyword = _PyPegen_expect_token(p, 608))  // token='from'
             &&
-            (a = _loop0_25_rule(p))  // (('.' | '...'))*
+            (a = _loop0_24_rule(p))  // (('.' | '...'))*
             &&
             (b = dotted_name_rule(p))  // dotted_name
             &&
@@ -3618,7 +3581,7 @@ import_from_rule(Parser *p)
         if (
             (_keyword = _PyPegen_expect_token(p, 608))  // token='from'
             &&
-            (a = _loop1_26_rule(p))  // (('.' | '...'))+
+            (a = _loop1_25_rule(p))  // (('.' | '...'))+
             &&
             (_keyword_1 = _PyPegen_expect_token(p, 607))  // token='import'
             &&
@@ -3813,7 +3776,7 @@ import_from_as_names_rule(Parser *p)
         D(fprintf(stderr, "%*c> import_from_as_names[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.import_from_as_name+"));
         asdl_alias_seq* a;
         if (
-            (a = (asdl_alias_seq*)_gather_27_rule(p))  // ','.import_from_as_name+
+            (a = (asdl_alias_seq*)_gather_26_rule(p))  // ','.import_from_as_name+
         )
         {
             D(fprintf(stderr, "%*c+ import_from_as_names[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.import_from_as_name+"));
@@ -3868,7 +3831,7 @@ import_from_as_name_rule(Parser *p)
         if (
             (a = _PyPegen_name_token(p))  // NAME
             &&
-            (b = _tmp_29_rule(p), !p->error_indicator)  // ['as' NAME]
+            (b = _tmp_28_rule(p), !p->error_indicator)  // ['as' NAME]
         )
         {
             D(fprintf(stderr, "%*c+ import_from_as_name[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME ['as' NAME]"));
@@ -3920,7 +3883,7 @@ dotted_as_names_rule(Parser *p)
         D(fprintf(stderr, "%*c> dotted_as_names[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.dotted_as_name+"));
         asdl_alias_seq* a;
         if (
-            (a = (asdl_alias_seq*)_gather_30_rule(p))  // ','.dotted_as_name+
+            (a = (asdl_alias_seq*)_gather_29_rule(p))  // ','.dotted_as_name+
         )
         {
             D(fprintf(stderr, "%*c+ dotted_as_names[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.dotted_as_name+"));
@@ -3975,7 +3938,7 @@ dotted_as_name_rule(Parser *p)
         if (
             (a = dotted_name_rule(p))  // dotted_name
             &&
-            (b = _tmp_32_rule(p), !p->error_indicator)  // ['as' NAME]
+            (b = _tmp_31_rule(p), !p->error_indicator)  // ['as' NAME]
         )
         {
             D(fprintf(stderr, "%*c+ dotted_as_name[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dotted_name ['as' NAME]"));
@@ -4226,7 +4189,7 @@ decorators_rule(Parser *p)
         D(fprintf(stderr, "%*c> decorators[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(('@' named_expression NEWLINE))+"));
         asdl_expr_seq* a;
         if (
-            (a = (asdl_expr_seq*)_loop1_33_rule(p))  // (('@' named_expression NEWLINE))+
+            (a = (asdl_expr_seq*)_loop1_32_rule(p))  // (('@' named_expression NEWLINE))+
         )
         {
             D(fprintf(stderr, "%*c+ decorators[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(('@' named_expression NEWLINE))+"));
@@ -4375,7 +4338,7 @@ class_def_raw_rule(Parser *p)
             &&
             (t = type_params_rule(p), !p->error_indicator)  // type_params?
             &&
-            (b = _tmp_34_rule(p), !p->error_indicator)  // ['(' arguments? ')']
+            (b = _tmp_33_rule(p), !p->error_indicator)  // ['(' arguments? ')']
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -4548,7 +4511,7 @@ function_def_raw_rule(Parser *p)
             &&
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
             &&
-            (a = _tmp_35_rule(p), !p->error_indicator)  // ['->' expression]
+            (a = _tmp_34_rule(p), !p->error_indicator)  // ['->' expression]
             &&
             (_literal_2 = _PyPegen_expect_forced_token(p, 11, ":"))  // forced_token=':'
             &&
@@ -4611,7 +4574,7 @@ function_def_raw_rule(Parser *p)
             &&
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
             &&
-            (a = _tmp_36_rule(p), !p->error_indicator)  // ['->' expression]
+            (a = _tmp_35_rule(p), !p->error_indicator)  // ['->' expression]
             &&
             (_literal_2 = _PyPegen_expect_forced_token(p, 11, ":"))  // forced_token=':'
             &&
@@ -4736,9 +4699,9 @@ parameters_rule(Parser *p)
         if (
             (a = slash_no_default_rule(p))  // slash_no_default
             &&
-            (b = (asdl_arg_seq*)_loop0_37_rule(p))  // param_no_default*
+            (b = (asdl_arg_seq*)_loop0_36_rule(p))  // param_no_default*
             &&
-            (c = _loop0_38_rule(p))  // param_with_default*
+            (c = _loop0_37_rule(p))  // param_with_default*
             &&
             (d = star_etc_rule(p), !p->error_indicator)  // star_etc?
         )
@@ -4768,7 +4731,7 @@ parameters_rule(Parser *p)
         if (
             (a = slash_with_default_rule(p))  // slash_with_default
             &&
-            (b = _loop0_39_rule(p))  // param_with_default*
+            (b = _loop0_38_rule(p))  // param_with_default*
             &&
             (c = star_etc_rule(p), !p->error_indicator)  // star_etc?
         )
@@ -4796,9 +4759,9 @@ parameters_rule(Parser *p)
         asdl_seq * b;
         void *c;
         if (
-            (a = (asdl_arg_seq*)_loop1_40_rule(p))  // param_no_default+
+            (a = (asdl_arg_seq*)_loop1_39_rule(p))  // param_no_default+
             &&
-            (b = _loop0_41_rule(p))  // param_with_default*
+            (b = _loop0_40_rule(p))  // param_with_default*
             &&
             (c = star_etc_rule(p), !p->error_indicator)  // star_etc?
         )
@@ -4825,7 +4788,7 @@ parameters_rule(Parser *p)
         asdl_seq * a;
         void *b;
         if (
-            (a = _loop1_42_rule(p))  // param_with_default+
+            (a = _loop1_41_rule(p))  // param_with_default+
             &&
             (b = star_etc_rule(p), !p->error_indicator)  // star_etc?
         )
@@ -4896,7 +4859,7 @@ slash_no_default_rule(Parser *p)
         Token * _literal_1;
         asdl_arg_seq* a;
         if (
-            (a = (asdl_arg_seq*)_loop1_43_rule(p))  // param_no_default+
+            (a = (asdl_arg_seq*)_loop1_42_rule(p))  // param_no_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -4925,7 +4888,7 @@ slash_no_default_rule(Parser *p)
         Token * _literal;
         asdl_arg_seq* a;
         if (
-            (a = (asdl_arg_seq*)_loop1_44_rule(p))  // param_no_default+
+            (a = (asdl_arg_seq*)_loop1_43_rule(p))  // param_no_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -4977,9 +4940,9 @@ slash_with_default_rule(Parser *p)
         asdl_seq * a;
         asdl_seq * b;
         if (
-            (a = _loop0_45_rule(p))  // param_no_default*
+            (a = _loop0_44_rule(p))  // param_no_default*
             &&
-            (b = _loop1_46_rule(p))  // param_with_default+
+            (b = _loop1_45_rule(p))  // param_with_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -5009,9 +4972,9 @@ slash_with_default_rule(Parser *p)
         asdl_seq * a;
         asdl_seq * b;
         if (
-            (a = _loop0_47_rule(p))  // param_no_default*
+            (a = _loop0_46_rule(p))  // param_no_default*
             &&
-            (b = _loop1_48_rule(p))  // param_with_default+
+            (b = _loop1_47_rule(p))  // param_with_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -5089,7 +5052,7 @@ star_etc_rule(Parser *p)
             &&
             (a = param_no_default_rule(p))  // param_no_default
             &&
-            (b = _loop0_49_rule(p))  // param_maybe_default*
+            (b = _loop0_48_rule(p))  // param_maybe_default*
             &&
             (c = kwds_rule(p), !p->error_indicator)  // kwds?
         )
@@ -5122,7 +5085,7 @@ star_etc_rule(Parser *p)
             &&
             (a = param_no_default_star_annotation_rule(p))  // param_no_default_star_annotation
             &&
-            (b = _loop0_50_rule(p))  // param_maybe_default*
+            (b = _loop0_49_rule(p))  // param_maybe_default*
             &&
             (c = kwds_rule(p), !p->error_indicator)  // kwds?
         )
@@ -5155,7 +5118,7 @@ star_etc_rule(Parser *p)
             &&
             (_literal_1 = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (b = _loop1_51_rule(p))  // param_maybe_default+
+            (b = _loop1_50_rule(p))  // param_maybe_default+
             &&
             (c = kwds_rule(p), !p->error_indicator)  // kwds?
         )
@@ -6582,7 +6545,7 @@ with_stmt_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (a = (asdl_withitem_seq*)_gather_52_rule(p))  // ','.with_item+
+            (a = (asdl_withitem_seq*)_gather_51_rule(p))  // ','.with_item+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
             &&
@@ -6629,7 +6592,7 @@ with_stmt_rule(Parser *p)
         if (
             (_keyword = _PyPegen_expect_token(p, 615))  // token='with'
             &&
-            (a = (asdl_withitem_seq*)_gather_54_rule(p))  // ','.with_item+
+            (a = (asdl_withitem_seq*)_gather_53_rule(p))  // ','.with_item+
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -6682,7 +6645,7 @@ with_stmt_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (a = (asdl_withitem_seq*)_gather_56_rule(p))  // ','.with_item+
+            (a = (asdl_withitem_seq*)_gather_55_rule(p))  // ','.with_item+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
             &&
@@ -6732,7 +6695,7 @@ with_stmt_rule(Parser *p)
             &&
             (_keyword = _PyPegen_expect_token(p, 615))  // token='with'
             &&
-            (a = (asdl_withitem_seq*)_gather_58_rule(p))  // ','.with_item+
+            (a = (asdl_withitem_seq*)_gather_57_rule(p))  // ','.with_item+
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -6820,7 +6783,7 @@ with_item_rule(Parser *p)
             &&
             (t = star_target_rule(p))  // star_target
             &&
-            _PyPegen_lookahead(1, _tmp_60_rule, p)
+            _PyPegen_lookahead(1, _tmp_59_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ with_item[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression 'as' star_target &(',' | ')' | ':')"));
@@ -6991,7 +6954,7 @@ try_stmt_rule(Parser *p)
             &&
             (b = block_rule(p))  // block
             &&
-            (ex = (asdl_excepthandler_seq*)_loop1_61_rule(p))  // except_block+
+            (ex = (asdl_excepthandler_seq*)_loop1_60_rule(p))  // except_block+
             &&
             (el = else_block_rule(p), !p->error_indicator)  // else_block?
             &&
@@ -7039,7 +7002,7 @@ try_stmt_rule(Parser *p)
             &&
             (b = block_rule(p))  // block
             &&
-            (ex = (asdl_excepthandler_seq*)_loop1_62_rule(p))  // except_star_block+
+            (ex = (asdl_excepthandler_seq*)_loop1_61_rule(p))  // except_star_block+
             &&
             (el = else_block_rule(p), !p->error_indicator)  // else_block?
             &&
@@ -7135,7 +7098,7 @@ except_block_rule(Parser *p)
             &&
             (e = expression_rule(p))  // expression
             &&
-            (t = _tmp_63_rule(p), !p->error_indicator)  // ['as' NAME]
+            (t = _tmp_62_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -7291,7 +7254,7 @@ except_star_block_rule(Parser *p)
             &&
             (e = expression_rule(p))  // expression
             &&
-            (t = _tmp_64_rule(p), !p->error_indicator)  // ['as' NAME]
+            (t = _tmp_63_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -7461,7 +7424,7 @@ match_stmt_rule(Parser *p)
             &&
             (indent_var = _PyPegen_expect_token(p, INDENT))  // token='INDENT'
             &&
-            (cases = (asdl_match_case_seq*)_loop1_65_rule(p))  // case_block+
+            (cases = (asdl_match_case_seq*)_loop1_64_rule(p))  // case_block+
             &&
             (dedent_var = _PyPegen_expect_token(p, DEDENT))  // token='DEDENT'
         )
@@ -7972,7 +7935,7 @@ or_pattern_rule(Parser *p)
         D(fprintf(stderr, "%*c> or_pattern[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'|'.closed_pattern+"));
         asdl_pattern_seq* patterns;
         if (
-            (patterns = (asdl_pattern_seq*)_gather_66_rule(p))  // '|'.closed_pattern+
+            (patterns = (asdl_pattern_seq*)_gather_65_rule(p))  // '|'.closed_pattern+
         )
         {
             D(fprintf(stderr, "%*c+ or_pattern[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'|'.closed_pattern+"));
@@ -8225,7 +8188,7 @@ literal_pattern_rule(Parser *p)
         if (
             (value = signed_number_rule(p))  // signed_number
             &&
-            _PyPegen_lookahead(0, _tmp_68_rule, p)
+            _PyPegen_lookahead(0, _tmp_67_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ literal_pattern[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "signed_number !('+' | '-')"));
@@ -8459,7 +8422,7 @@ literal_expr_rule(Parser *p)
         if (
             (signed_number_var = signed_number_rule(p))  // signed_number
             &&
-            _PyPegen_lookahead(0, _tmp_69_rule, p)
+            _PyPegen_lookahead(0, _tmp_68_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ literal_expr[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "signed_number !('+' | '-')"));
@@ -9059,7 +9022,7 @@ pattern_capture_target_rule(Parser *p)
             &&
             (name = _PyPegen_name_token(p))  // NAME
             &&
-            _PyPegen_lookahead(0, _tmp_70_rule, p)
+            _PyPegen_lookahead(0, _tmp_69_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ pattern_capture_target[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "!\"_\" NAME !('.' | '(' | '=')"));
@@ -9174,7 +9137,7 @@ value_pattern_rule(Parser *p)
         if (
             (attr = attr_rule(p))  // attr
             &&
-            _PyPegen_lookahead(0, _tmp_71_rule, p)
+            _PyPegen_lookahead(0, _tmp_70_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ value_pattern[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "attr !('.' | '(' | '=')"));
@@ -9593,7 +9556,7 @@ maybe_sequence_pattern_rule(Parser *p)
         UNUSED(_opt_var); // Silence compiler warnings
         asdl_seq * patterns;
         if (
-            (patterns = _gather_72_rule(p))  // ','.maybe_star_pattern+
+            (patterns = _gather_71_rule(p))  // ','.maybe_star_pattern+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
         )
@@ -10001,13 +9964,13 @@ items_pattern_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> items_pattern[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.key_value_pattern+"));
-        asdl_seq * _gather_74_var;
+        asdl_seq * _gather_73_var;
         if (
-            (_gather_74_var = _gather_74_rule(p))  // ','.key_value_pattern+
+            (_gather_73_var = _gather_73_rule(p))  // ','.key_value_pattern+
         )
         {
             D(fprintf(stderr, "%*c+ items_pattern[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.key_value_pattern+"));
-            _res = _gather_74_var;
+            _res = _gather_73_var;
             goto done;
         }
         p->mark = _mark;
@@ -10043,7 +10006,7 @@ key_value_pattern_rule(Parser *p)
         void *key;
         pattern_ty pattern;
         if (
-            (key = _tmp_76_rule(p))  // literal_expr | attr
+            (key = _tmp_75_rule(p))  // literal_expr | attr
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -10371,7 +10334,7 @@ positional_patterns_rule(Parser *p)
         D(fprintf(stderr, "%*c> positional_patterns[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.pattern+"));
         asdl_pattern_seq* args;
         if (
-            (args = (asdl_pattern_seq*)_gather_77_rule(p))  // ','.pattern+
+            (args = (asdl_pattern_seq*)_gather_76_rule(p))  // ','.pattern+
         )
         {
             D(fprintf(stderr, "%*c+ positional_patterns[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.pattern+"));
@@ -10412,13 +10375,13 @@ keyword_patterns_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> keyword_patterns[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.keyword_pattern+"));
-        asdl_seq * _gather_79_var;
+        asdl_seq * _gather_78_var;
         if (
-            (_gather_79_var = _gather_79_rule(p))  // ','.keyword_pattern+
+            (_gather_78_var = _gather_78_rule(p))  // ','.keyword_pattern+
         )
         {
             D(fprintf(stderr, "%*c+ keyword_patterns[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.keyword_pattern+"));
-            _res = _gather_79_var;
+            _res = _gather_78_var;
             goto done;
         }
         p->mark = _mark;
@@ -10625,7 +10588,7 @@ type_param_seq_rule(Parser *p)
         UNUSED(_opt_var); // Silence compiler warnings
         asdl_type_param_seq* a;
         if (
-            (a = (asdl_type_param_seq*)_gather_81_rule(p))  // ','.type_param+
+            (a = (asdl_type_param_seq*)_gather_80_rule(p))  // ','.type_param+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
         )
@@ -10651,9 +10614,9 @@ type_param_seq_rule(Parser *p)
 
 // type_param:
 //     | NAME type_param_bound?
-//     | '*' NAME ":" expression
+//     | '*' NAME ':' expression
 //     | '*' NAME
-//     | '**' NAME ":" expression
+//     | '**' NAME ':' expression
 //     | '**' NAME
 static type_param_ty
 type_param_rule(Parser *p)
@@ -10716,12 +10679,12 @@ type_param_rule(Parser *p)
         D(fprintf(stderr, "%*c%s type_param[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME type_param_bound?"));
     }
-    { // '*' NAME ":" expression
+    { // '*' NAME ':' expression
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> type_param[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*' NAME \":\" expression"));
+        D(fprintf(stderr, "%*c> type_param[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*' NAME ':' expression"));
         Token * _literal;
         expr_ty a;
         Token * colon;
@@ -10736,7 +10699,7 @@ type_param_rule(Parser *p)
             (e = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ type_param[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*' NAME \":\" expression"));
+            D(fprintf(stderr, "%*c+ type_param[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*' NAME ':' expression"));
             _res = RAISE_SYNTAX_ERROR_STARTING_FROM ( colon , e -> kind == Tuple_kind ? "cannot use constraints with TypeVarTuple" : "cannot use bound with TypeVarTuple" );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -10747,7 +10710,7 @@ type_param_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s type_param[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'*' NAME \":\" expression"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'*' NAME ':' expression"));
     }
     { // '*' NAME
         if (p->error_indicator) {
@@ -10785,12 +10748,12 @@ type_param_rule(Parser *p)
         D(fprintf(stderr, "%*c%s type_param[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'*' NAME"));
     }
-    { // '**' NAME ":" expression
+    { // '**' NAME ':' expression
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> type_param[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**' NAME \":\" expression"));
+        D(fprintf(stderr, "%*c> type_param[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**' NAME ':' expression"));
         Token * _literal;
         expr_ty a;
         Token * colon;
@@ -10805,7 +10768,7 @@ type_param_rule(Parser *p)
             (e = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ type_param[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**' NAME \":\" expression"));
+            D(fprintf(stderr, "%*c+ type_param[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**' NAME ':' expression"));
             _res = RAISE_SYNTAX_ERROR_STARTING_FROM ( colon , e -> kind == Tuple_kind ? "cannot use constraints with ParamSpec" : "cannot use bound with ParamSpec" );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -10816,7 +10779,7 @@ type_param_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s type_param[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'**' NAME \":\" expression"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'**' NAME ':' expression"));
     }
     { // '**' NAME
         if (p->error_indicator) {
@@ -10861,7 +10824,7 @@ type_param_rule(Parser *p)
     return _res;
 }
 
-// type_param_bound: ":" expression
+// type_param_bound: ':' expression
 static expr_ty
 type_param_bound_rule(Parser *p)
 {
@@ -10874,12 +10837,12 @@ type_param_bound_rule(Parser *p)
     }
     expr_ty _res = NULL;
     int _mark = p->mark;
-    { // ":" expression
+    { // ':' expression
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> type_param_bound[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "\":\" expression"));
+        D(fprintf(stderr, "%*c> type_param_bound[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':' expression"));
         Token * _literal;
         expr_ty e;
         if (
@@ -10888,7 +10851,7 @@ type_param_bound_rule(Parser *p)
             (e = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ type_param_bound[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "\":\" expression"));
+            D(fprintf(stderr, "%*c+ type_param_bound[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':' expression"));
             _res = e;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -10899,7 +10862,7 @@ type_param_bound_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s type_param_bound[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "\":\" expression"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':' expression"));
     }
     _res = NULL;
   done:
@@ -10942,7 +10905,7 @@ expressions_rule(Parser *p)
         if (
             (a = expression_rule(p))  // expression
             &&
-            (b = _loop1_83_rule(p))  // ((',' expression))+
+            (b = _loop1_82_rule(p))  // ((',' expression))+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
         )
@@ -11330,7 +11293,7 @@ star_expressions_rule(Parser *p)
         if (
             (a = star_expression_rule(p))  // star_expression
             &&
-            (b = _loop1_84_rule(p))  // ((',' star_expression))+
+            (b = _loop1_83_rule(p))  // ((',' star_expression))+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
         )
@@ -11529,7 +11492,7 @@ star_named_expressions_rule(Parser *p)
         UNUSED(_opt_var); // Silence compiler warnings
         asdl_expr_seq* a;
         if (
-            (a = (asdl_expr_seq*)_gather_85_rule(p))  // ','.star_named_expression+
+            (a = (asdl_expr_seq*)_gather_84_rule(p))  // ','.star_named_expression+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
         )
@@ -11825,7 +11788,7 @@ disjunction_rule(Parser *p)
         if (
             (a = conjunction_rule(p))  // conjunction
             &&
-            (b = _loop1_87_rule(p))  // (('or' conjunction))+
+            (b = _loop1_86_rule(p))  // (('or' conjunction))+
         )
         {
             D(fprintf(stderr, "%*c+ disjunction[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "conjunction (('or' conjunction))+"));
@@ -11913,7 +11876,7 @@ conjunction_rule(Parser *p)
         if (
             (a = inversion_rule(p))  // inversion
             &&
-            (b = _loop1_88_rule(p))  // (('and' inversion))+
+            (b = _loop1_87_rule(p))  // (('and' inversion))+
         )
         {
             D(fprintf(stderr, "%*c+ conjunction[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "inversion (('and' inversion))+"));
@@ -12085,7 +12048,7 @@ comparison_rule(Parser *p)
         if (
             (a = bitwise_or_rule(p))  // bitwise_or
             &&
-            (b = _loop1_89_rule(p))  // compare_op_bitwise_or_pair+
+            (b = _loop1_88_rule(p))  // compare_op_bitwise_or_pair+
         )
         {
             D(fprintf(stderr, "%*c+ comparison[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "bitwise_or compare_op_bitwise_or_pair+"));
@@ -12419,10 +12382,10 @@ noteq_bitwise_or_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> noteq_bitwise_or[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('!=') bitwise_or"));
-        void *_tmp_90_var;
+        void *_tmp_89_var;
         expr_ty a;
         if (
-            (_tmp_90_var = _tmp_90_rule(p))  // '!='
+            (_tmp_89_var = _tmp_89_rule(p))  // '!='
             &&
             (a = bitwise_or_rule(p))  // bitwise_or
         )
@@ -14431,7 +14394,7 @@ slices_rule(Parser *p)
         UNUSED(_opt_var); // Silence compiler warnings
         asdl_expr_seq* a;
         if (
-            (a = (asdl_expr_seq*)_gather_91_rule(p))  // ','.(slice | starred_expression)+
+            (a = (asdl_expr_seq*)_gather_90_rule(p))  // ','.(slice | starred_expression)+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
         )
@@ -14503,7 +14466,7 @@ slice_rule(Parser *p)
             &&
             (b = expression_rule(p), !p->error_indicator)  // expression?
             &&
-            (c = _tmp_93_rule(p), !p->error_indicator)  // [':' expression?]
+            (c = _tmp_92_rule(p), !p->error_indicator)  // [':' expression?]
         )
         {
             D(fprintf(stderr, "%*c+ slice[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression? ':' expression? [':' expression?]"));
@@ -14716,7 +14679,7 @@ atom_rule(Parser *p)
         D(fprintf(stderr, "%*c> atom[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&(STRING | FSTRING_START) strings"));
         expr_ty strings_var;
         if (
-            _PyPegen_lookahead(1, _tmp_94_rule, p)
+            _PyPegen_lookahead(1, _tmp_93_rule, p)
             &&
             (strings_var = strings_rule(p))  // strings
         )
@@ -14754,15 +14717,15 @@ atom_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> atom[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&'(' (tuple | group | genexp)"));
-        void *_tmp_95_var;
+        void *_tmp_94_var;
         if (
             _PyPegen_lookahead_with_int(1, _PyPegen_expect_token, p, 7)  // token='('
             &&
-            (_tmp_95_var = _tmp_95_rule(p))  // tuple | group | genexp
+            (_tmp_94_var = _tmp_94_rule(p))  // tuple | group | genexp
         )
         {
             D(fprintf(stderr, "%*c+ atom[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "&'(' (tuple | group | genexp)"));
-            _res = _tmp_95_var;
+            _res = _tmp_94_var;
             goto done;
         }
         p->mark = _mark;
@@ -14775,15 +14738,15 @@ atom_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> atom[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&'[' (list | listcomp)"));
-        void *_tmp_96_var;
+        void *_tmp_95_var;
         if (
             _PyPegen_lookahead_with_int(1, _PyPegen_expect_token, p, 9)  // token='['
             &&
-            (_tmp_96_var = _tmp_96_rule(p))  // list | listcomp
+            (_tmp_95_var = _tmp_95_rule(p))  // list | listcomp
         )
         {
             D(fprintf(stderr, "%*c+ atom[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "&'[' (list | listcomp)"));
-            _res = _tmp_96_var;
+            _res = _tmp_95_var;
             goto done;
         }
         p->mark = _mark;
@@ -14796,15 +14759,15 @@ atom_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> atom[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "&'{' (dict | set | dictcomp | setcomp)"));
-        void *_tmp_97_var;
+        void *_tmp_96_var;
         if (
             _PyPegen_lookahead_with_int(1, _PyPegen_expect_token, p, 25)  // token='{'
             &&
-            (_tmp_97_var = _tmp_97_rule(p))  // dict | set | dictcomp | setcomp
+            (_tmp_96_var = _tmp_96_rule(p))  // dict | set | dictcomp | setcomp
         )
         {
             D(fprintf(stderr, "%*c+ atom[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "&'{' (dict | set | dictcomp | setcomp)"));
-            _res = _tmp_97_var;
+            _res = _tmp_96_var;
             goto done;
         }
         p->mark = _mark;
@@ -14875,7 +14838,7 @@ group_rule(Parser *p)
         if (
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (a = _tmp_98_rule(p))  // yield_expr | named_expression
+            (a = _tmp_97_rule(p))  // yield_expr | named_expression
             &&
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
         )
@@ -15076,9 +15039,9 @@ lambda_parameters_rule(Parser *p)
         if (
             (a = lambda_slash_no_default_rule(p))  // lambda_slash_no_default
             &&
-            (b = (asdl_arg_seq*)_loop0_99_rule(p))  // lambda_param_no_default*
+            (b = (asdl_arg_seq*)_loop0_98_rule(p))  // lambda_param_no_default*
             &&
-            (c = _loop0_100_rule(p))  // lambda_param_with_default*
+            (c = _loop0_99_rule(p))  // lambda_param_with_default*
             &&
             (d = lambda_star_etc_rule(p), !p->error_indicator)  // lambda_star_etc?
         )
@@ -15108,7 +15071,7 @@ lambda_parameters_rule(Parser *p)
         if (
             (a = lambda_slash_with_default_rule(p))  // lambda_slash_with_default
             &&
-            (b = _loop0_101_rule(p))  // lambda_param_with_default*
+            (b = _loop0_100_rule(p))  // lambda_param_with_default*
             &&
             (c = lambda_star_etc_rule(p), !p->error_indicator)  // lambda_star_etc?
         )
@@ -15136,9 +15099,9 @@ lambda_parameters_rule(Parser *p)
         asdl_seq * b;
         void *c;
         if (
-            (a = (asdl_arg_seq*)_loop1_102_rule(p))  // lambda_param_no_default+
+            (a = (asdl_arg_seq*)_loop1_101_rule(p))  // lambda_param_no_default+
             &&
-            (b = _loop0_103_rule(p))  // lambda_param_with_default*
+            (b = _loop0_102_rule(p))  // lambda_param_with_default*
             &&
             (c = lambda_star_etc_rule(p), !p->error_indicator)  // lambda_star_etc?
         )
@@ -15165,7 +15128,7 @@ lambda_parameters_rule(Parser *p)
         asdl_seq * a;
         void *b;
         if (
-            (a = _loop1_104_rule(p))  // lambda_param_with_default+
+            (a = _loop1_103_rule(p))  // lambda_param_with_default+
             &&
             (b = lambda_star_etc_rule(p), !p->error_indicator)  // lambda_star_etc?
         )
@@ -15238,7 +15201,7 @@ lambda_slash_no_default_rule(Parser *p)
         Token * _literal_1;
         asdl_arg_seq* a;
         if (
-            (a = (asdl_arg_seq*)_loop1_105_rule(p))  // lambda_param_no_default+
+            (a = (asdl_arg_seq*)_loop1_104_rule(p))  // lambda_param_no_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -15267,7 +15230,7 @@ lambda_slash_no_default_rule(Parser *p)
         Token * _literal;
         asdl_arg_seq* a;
         if (
-            (a = (asdl_arg_seq*)_loop1_106_rule(p))  // lambda_param_no_default+
+            (a = (asdl_arg_seq*)_loop1_105_rule(p))  // lambda_param_no_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -15319,9 +15282,9 @@ lambda_slash_with_default_rule(Parser *p)
         asdl_seq * a;
         asdl_seq * b;
         if (
-            (a = _loop0_107_rule(p))  // lambda_param_no_default*
+            (a = _loop0_106_rule(p))  // lambda_param_no_default*
             &&
-            (b = _loop1_108_rule(p))  // lambda_param_with_default+
+            (b = _loop1_107_rule(p))  // lambda_param_with_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -15351,9 +15314,9 @@ lambda_slash_with_default_rule(Parser *p)
         asdl_seq * a;
         asdl_seq * b;
         if (
-            (a = _loop0_109_rule(p))  // lambda_param_no_default*
+            (a = _loop0_108_rule(p))  // lambda_param_no_default*
             &&
-            (b = _loop1_110_rule(p))  // lambda_param_with_default+
+            (b = _loop1_109_rule(p))  // lambda_param_with_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -15430,7 +15393,7 @@ lambda_star_etc_rule(Parser *p)
             &&
             (a = lambda_param_no_default_rule(p))  // lambda_param_no_default
             &&
-            (b = _loop0_111_rule(p))  // lambda_param_maybe_default*
+            (b = _loop0_110_rule(p))  // lambda_param_maybe_default*
             &&
             (c = lambda_kwds_rule(p), !p->error_indicator)  // lambda_kwds?
         )
@@ -15463,7 +15426,7 @@ lambda_star_etc_rule(Parser *p)
             &&
             (_literal_1 = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (b = _loop1_112_rule(p))  // lambda_param_maybe_default+
+            (b = _loop1_111_rule(p))  // lambda_param_maybe_default+
             &&
             (c = lambda_kwds_rule(p), !p->error_indicator)  // lambda_kwds?
         )
@@ -15928,7 +15891,7 @@ fstring_middle_rule(Parser *p)
 }
 
 // fstring_replacement_field:
-//     | '{' (yield_expr | star_expressions) "="? fstring_conversion? fstring_full_format_spec? '}'
+//     | '{' (yield_expr | star_expressions) '='? fstring_conversion? fstring_full_format_spec? '}'
 //     | invalid_replacement_field
 static expr_ty
 fstring_replacement_field_rule(Parser *p)
@@ -15951,12 +15914,12 @@ fstring_replacement_field_rule(Parser *p)
     UNUSED(_start_lineno); // Only used by EXTRA macro
     int _start_col_offset = p->tokens[_mark]->col_offset;
     UNUSED(_start_col_offset); // Only used by EXTRA macro
-    { // '{' (yield_expr | star_expressions) "="? fstring_conversion? fstring_full_format_spec? '}'
+    { // '{' (yield_expr | star_expressions) '='? fstring_conversion? fstring_full_format_spec? '}'
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> fstring_replacement_field[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) \"=\"? fstring_conversion? fstring_full_format_spec? '}'"));
+        D(fprintf(stderr, "%*c> fstring_replacement_field[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '='? fstring_conversion? fstring_full_format_spec? '}'"));
         Token * _literal;
         void *a;
         void *conversion;
@@ -15966,9 +15929,9 @@ fstring_replacement_field_rule(Parser *p)
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (a = _tmp_113_rule(p))  // yield_expr | star_expressions
+            (a = _tmp_112_rule(p))  // yield_expr | star_expressions
             &&
-            (debug_expr = _PyPegen_expect_token(p, 22), !p->error_indicator)  // "="?
+            (debug_expr = _PyPegen_expect_token(p, 22), !p->error_indicator)  // '='?
             &&
             (conversion = fstring_conversion_rule(p), !p->error_indicator)  // fstring_conversion?
             &&
@@ -15977,7 +15940,7 @@ fstring_replacement_field_rule(Parser *p)
             (rbrace = _PyPegen_expect_token(p, 26))  // token='}'
         )
         {
-            D(fprintf(stderr, "%*c+ fstring_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) \"=\"? fstring_conversion? fstring_full_format_spec? '}'"));
+            D(fprintf(stderr, "%*c+ fstring_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '='? fstring_conversion? fstring_full_format_spec? '}'"));
             Token *_token = _PyPegen_get_last_nonnwhitespace_token(p);
             if (_token == NULL) {
                 p->level--;
@@ -15997,7 +15960,7 @@ fstring_replacement_field_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s fstring_replacement_field[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'{' (yield_expr | star_expressions) \"=\"? fstring_conversion? fstring_full_format_spec? '}'"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'{' (yield_expr | star_expressions) '='? fstring_conversion? fstring_full_format_spec? '}'"));
     }
     if (p->call_invalid_rules) { // invalid_replacement_field
         if (p->error_indicator) {
@@ -16103,7 +16066,7 @@ fstring_full_format_spec_rule(Parser *p)
         if (
             (colon = _PyPegen_expect_token(p, 11))  // token=':'
             &&
-            (spec = _loop0_114_rule(p))  // fstring_format_spec*
+            (spec = _loop0_113_rule(p))  // fstring_format_spec*
         )
         {
             D(fprintf(stderr, "%*c+ fstring_full_format_spec[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':' fstring_format_spec*"));
@@ -16196,6 +16159,55 @@ fstring_format_spec_rule(Parser *p)
     return _res;
 }
 
+// fstring: FSTRING_START fstring_middle* FSTRING_END
+static expr_ty
+fstring_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    expr_ty _res = NULL;
+    int _mark = p->mark;
+    { // FSTRING_START fstring_middle* FSTRING_END
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> fstring[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "FSTRING_START fstring_middle* FSTRING_END"));
+        Token * a;
+        asdl_seq * b;
+        Token * c;
+        if (
+            (a = _PyPegen_expect_token(p, FSTRING_START))  // token='FSTRING_START'
+            &&
+            (b = _loop0_114_rule(p))  // fstring_middle*
+            &&
+            (c = _PyPegen_expect_token(p, FSTRING_END))  // token='FSTRING_END'
+        )
+        {
+            D(fprintf(stderr, "%*c+ fstring[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "FSTRING_START fstring_middle* FSTRING_END"));
+            _res = _PyPegen_joined_str ( p , a , ( asdl_expr_seq* ) b , c );
+            if (_res == NULL && PyErr_Occurred()) {
+                p->error_indicator = 1;
+                p->level--;
+                return NULL;
+            }
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s fstring[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "FSTRING_START fstring_middle* FSTRING_END"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
 // string: STRING
 static expr_ty
 string_rule(Parser *p)
@@ -19707,7 +19719,7 @@ func_type_comment_rule(Parser *p)
 }
 
 // invalid_arguments:
-//     | args ',' '*'
+//     | ((','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs) ',' '*'
 //     | expression for_if_clauses ',' [args | expression for_if_clauses]
 //     | NAME '=' expression for_if_clauses
 //     | [(args ',')] NAME '=' &(',' | ')')
@@ -19726,25 +19738,25 @@ invalid_arguments_rule(Parser *p)
     }
     void * _res = NULL;
     int _mark = p->mark;
-    { // args ',' '*'
+    { // ((','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs) ',' '*'
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> invalid_arguments[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "args ',' '*'"));
+        D(fprintf(stderr, "%*c> invalid_arguments[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "((','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs) ',' '*'"));
         Token * _literal;
-        Token * _literal_1;
-        expr_ty a;
+        void *_tmp_150_var;
+        Token * b;
         if (
-            (a = args_rule(p))  // args
+            (_tmp_150_var = _tmp_150_rule(p))  // (','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs
             &&
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (_literal_1 = _PyPegen_expect_token(p, 16))  // token='*'
+            (b = _PyPegen_expect_token(p, 16))  // token='*'
         )
         {
-            D(fprintf(stderr, "%*c+ invalid_arguments[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "args ',' '*'"));
-            _res = RAISE_SYNTAX_ERROR_KNOWN_LOCATION ( a , "iterable argument unpacking follows keyword argument unpacking" );
+            D(fprintf(stderr, "%*c+ invalid_arguments[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "((','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs) ',' '*'"));
+            _res = RAISE_SYNTAX_ERROR_KNOWN_LOCATION ( b , "iterable argument unpacking follows keyword argument unpacking" );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
                 p->level--;
@@ -19754,7 +19766,7 @@ invalid_arguments_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s invalid_arguments[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "args ',' '*'"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "((','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs) | kwargs) ',' '*'"));
     }
     { // expression for_if_clauses ',' [args | expression for_if_clauses]
         if (p->error_indicator) {
@@ -19774,7 +19786,7 @@ invalid_arguments_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (_opt_var = _tmp_150_rule(p), !p->error_indicator)  // [args | expression for_if_clauses]
+            (_opt_var = _tmp_151_rule(p), !p->error_indicator)  // [args | expression for_if_clauses]
         )
         {
             D(fprintf(stderr, "%*c+ invalid_arguments[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression for_if_clauses ',' [args | expression for_if_clauses]"));
@@ -19834,13 +19846,13 @@ invalid_arguments_rule(Parser *p)
         expr_ty a;
         Token * b;
         if (
-            (_opt_var = _tmp_151_rule(p), !p->error_indicator)  // [(args ',')]
+            (_opt_var = _tmp_152_rule(p), !p->error_indicator)  // [(args ',')]
             &&
             (a = _PyPegen_name_token(p))  // NAME
             &&
             (b = _PyPegen_expect_token(p, 22))  // token='='
             &&
-            _PyPegen_lookahead(1, _tmp_152_rule, p)
+            _PyPegen_lookahead(1, _tmp_153_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_arguments[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "[(args ',')] NAME '=' &(',' | ')')"));
@@ -19978,7 +19990,7 @@ invalid_kwarg_rule(Parser *p)
         Token* a;
         Token * b;
         if (
-            (a = (Token*)_tmp_153_rule(p))  // 'True' | 'False' | 'None'
+            (a = (Token*)_tmp_154_rule(p))  // 'True' | 'False' | 'None'
             &&
             (b = _PyPegen_expect_token(p, 22))  // token='='
         )
@@ -20038,7 +20050,7 @@ invalid_kwarg_rule(Parser *p)
         expr_ty a;
         Token * b;
         if (
-            _PyPegen_lookahead(0, _tmp_154_rule, p)
+            _PyPegen_lookahead(0, _tmp_155_rule, p)
             &&
             (a = expression_rule(p))  // expression
             &&
@@ -20294,7 +20306,7 @@ invalid_expression_rule(Parser *p)
         expr_ty a;
         expr_ty b;
         if (
-            _PyPegen_lookahead(0, _tmp_155_rule, p)
+            _PyPegen_lookahead(0, _tmp_156_rule, p)
             &&
             (a = disjunction_rule(p))  // disjunction
             &&
@@ -20330,7 +20342,7 @@ invalid_expression_rule(Parser *p)
             &&
             (b = disjunction_rule(p))  // disjunction
             &&
-            _PyPegen_lookahead(0, _tmp_156_rule, p)
+            _PyPegen_lookahead(0, _tmp_157_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_expression[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "disjunction 'if' disjunction !('else' | ':')"));
@@ -20451,7 +20463,7 @@ invalid_named_expression_rule(Parser *p)
             &&
             (b = bitwise_or_rule(p))  // bitwise_or
             &&
-            _PyPegen_lookahead(0, _tmp_157_rule, p)
+            _PyPegen_lookahead(0, _tmp_158_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_named_expression[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME '=' bitwise_or !('=' | ':=')"));
@@ -20477,7 +20489,7 @@ invalid_named_expression_rule(Parser *p)
         Token * b;
         expr_ty bitwise_or_var;
         if (
-            _PyPegen_lookahead(0, _tmp_158_rule, p)
+            _PyPegen_lookahead(0, _tmp_159_rule, p)
             &&
             (a = bitwise_or_rule(p))  // bitwise_or
             &&
@@ -20485,7 +20497,7 @@ invalid_named_expression_rule(Parser *p)
             &&
             (bitwise_or_var = bitwise_or_rule(p))  // bitwise_or
             &&
-            _PyPegen_lookahead(0, _tmp_159_rule, p)
+            _PyPegen_lookahead(0, _tmp_160_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_named_expression[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "!(list | tuple | genexp | 'True' | 'None' | 'False') bitwise_or '=' bitwise_or !('=' | ':=')"));
@@ -20565,7 +20577,7 @@ invalid_assignment_rule(Parser *p)
         D(fprintf(stderr, "%*c> invalid_assignment[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_named_expression ',' star_named_expressions* ':' expression"));
         Token * _literal;
         Token * _literal_1;
-        asdl_seq * _loop0_160_var;
+        asdl_seq * _loop0_161_var;
         expr_ty a;
         expr_ty expression_var;
         if (
@@ -20573,7 +20585,7 @@ invalid_assignment_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (_loop0_160_var = _loop0_160_rule(p))  // star_named_expressions*
+            (_loop0_161_var = _loop0_161_rule(p))  // star_named_expressions*
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -20630,10 +20642,10 @@ invalid_assignment_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_assignment[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "((star_targets '='))* star_expressions '='"));
         Token * _literal;
-        asdl_seq * _loop0_161_var;
+        asdl_seq * _loop0_162_var;
         expr_ty a;
         if (
-            (_loop0_161_var = _loop0_161_rule(p))  // ((star_targets '='))*
+            (_loop0_162_var = _loop0_162_rule(p))  // ((star_targets '='))*
             &&
             (a = star_expressions_rule(p))  // star_expressions
             &&
@@ -20660,10 +20672,10 @@ invalid_assignment_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_assignment[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "((star_targets '='))* yield_expr '='"));
         Token * _literal;
-        asdl_seq * _loop0_162_var;
+        asdl_seq * _loop0_163_var;
         expr_ty a;
         if (
-            (_loop0_162_var = _loop0_162_rule(p))  // ((star_targets '='))*
+            (_loop0_163_var = _loop0_163_rule(p))  // ((star_targets '='))*
             &&
             (a = yield_expr_rule(p))  // yield_expr
             &&
@@ -20689,7 +20701,7 @@ invalid_assignment_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_assignment[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions augassign (yield_expr | star_expressions)"));
-        void *_tmp_163_var;
+        void *_tmp_164_var;
         expr_ty a;
         AugOperator* augassign_var;
         if (
@@ -20697,7 +20709,7 @@ invalid_assignment_rule(Parser *p)
             &&
             (augassign_var = augassign_rule(p))  // augassign
             &&
-            (_tmp_163_var = _tmp_163_rule(p))  // yield_expr | star_expressions
+            (_tmp_164_var = _tmp_164_rule(p))  // yield_expr | star_expressions
         )
         {
             D(fprintf(stderr, "%*c+ invalid_assignment[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions augassign (yield_expr | star_expressions)"));
@@ -20919,11 +20931,11 @@ invalid_comprehension_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_comprehension[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('[' | '(' | '{') starred_expression for_if_clauses"));
-        void *_tmp_164_var;
+        void *_tmp_165_var;
         expr_ty a;
         asdl_comprehension_seq* for_if_clauses_var;
         if (
-            (_tmp_164_var = _tmp_164_rule(p))  // '[' | '(' | '{'
+            (_tmp_165_var = _tmp_165_rule(p))  // '[' | '(' | '{'
             &&
             (a = starred_expression_rule(p))  // starred_expression
             &&
@@ -20950,12 +20962,12 @@ invalid_comprehension_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_comprehension[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('[' | '{') star_named_expression ',' star_named_expressions for_if_clauses"));
         Token * _literal;
-        void *_tmp_165_var;
+        void *_tmp_166_var;
         expr_ty a;
         asdl_expr_seq* b;
         asdl_comprehension_seq* for_if_clauses_var;
         if (
-            (_tmp_165_var = _tmp_165_rule(p))  // '[' | '{'
+            (_tmp_166_var = _tmp_166_rule(p))  // '[' | '{'
             &&
             (a = star_named_expression_rule(p))  // star_named_expression
             &&
@@ -20985,12 +20997,12 @@ invalid_comprehension_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_comprehension[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('[' | '{') star_named_expression ',' for_if_clauses"));
-        void *_tmp_166_var;
+        void *_tmp_167_var;
         expr_ty a;
         Token * b;
         asdl_comprehension_seq* for_if_clauses_var;
         if (
-            (_tmp_166_var = _tmp_166_rule(p))  // '[' | '{'
+            (_tmp_167_var = _tmp_167_rule(p))  // '[' | '{'
             &&
             (a = star_named_expression_rule(p))  // star_named_expression
             &&
@@ -21125,13 +21137,13 @@ invalid_parameters_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(slash_no_default | slash_with_default) param_maybe_default* '/'"));
-        asdl_seq * _loop0_168_var;
-        void *_tmp_167_var;
+        asdl_seq * _loop0_169_var;
+        void *_tmp_168_var;
         Token * a;
         if (
-            (_tmp_167_var = _tmp_167_rule(p))  // slash_no_default | slash_with_default
+            (_tmp_168_var = _tmp_168_rule(p))  // slash_no_default | slash_with_default
             &&
-            (_loop0_168_var = _loop0_168_rule(p))  // param_maybe_default*
+            (_loop0_169_var = _loop0_169_rule(p))  // param_maybe_default*
             &&
             (a = _PyPegen_expect_token(p, 17))  // token='/'
         )
@@ -21155,7 +21167,7 @@ invalid_parameters_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_no_default? param_no_default* invalid_parameters_helper param_no_default"));
-        asdl_seq * _loop0_169_var;
+        asdl_seq * _loop0_170_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         arg_ty a;
@@ -21163,7 +21175,7 @@ invalid_parameters_rule(Parser *p)
         if (
             (_opt_var = slash_no_default_rule(p), !p->error_indicator)  // slash_no_default?
             &&
-            (_loop0_169_var = _loop0_169_rule(p))  // param_no_default*
+            (_loop0_170_var = _loop0_170_rule(p))  // param_no_default*
             &&
             (invalid_parameters_helper_var = invalid_parameters_helper_rule(p))  // invalid_parameters_helper
             &&
@@ -21189,18 +21201,18 @@ invalid_parameters_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default* '(' param_no_default+ ','? ')'"));
-        asdl_seq * _loop0_170_var;
-        asdl_seq * _loop1_171_var;
+        asdl_seq * _loop0_171_var;
+        asdl_seq * _loop1_172_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         Token * a;
         Token * b;
         if (
-            (_loop0_170_var = _loop0_170_rule(p))  // param_no_default*
+            (_loop0_171_var = _loop0_171_rule(p))  // param_no_default*
             &&
             (a = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (_loop1_171_var = _loop1_171_rule(p))  // param_no_default+
+            (_loop1_172_var = _loop1_172_rule(p))  // param_no_default+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
             &&
@@ -21227,22 +21239,22 @@ invalid_parameters_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "[(slash_no_default | slash_with_default)] param_maybe_default* '*' (',' | param_no_default) param_maybe_default* '/'"));
         Token * _literal;
-        asdl_seq * _loop0_173_var;
-        asdl_seq * _loop0_175_var;
+        asdl_seq * _loop0_174_var;
+        asdl_seq * _loop0_176_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
-        void *_tmp_174_var;
+        void *_tmp_175_var;
         Token * a;
         if (
-            (_opt_var = _tmp_172_rule(p), !p->error_indicator)  // [(slash_no_default | slash_with_default)]
+            (_opt_var = _tmp_173_rule(p), !p->error_indicator)  // [(slash_no_default | slash_with_default)]
             &&
-            (_loop0_173_var = _loop0_173_rule(p))  // param_maybe_default*
+            (_loop0_174_var = _loop0_174_rule(p))  // param_maybe_default*
             &&
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_174_var = _tmp_174_rule(p))  // ',' | param_no_default
+            (_tmp_175_var = _tmp_175_rule(p))  // ',' | param_no_default
             &&
-            (_loop0_175_var = _loop0_175_rule(p))  // param_maybe_default*
+            (_loop0_176_var = _loop0_176_rule(p))  // param_maybe_default*
             &&
             (a = _PyPegen_expect_token(p, 17))  // token='/'
         )
@@ -21267,10 +21279,10 @@ invalid_parameters_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default+ '/' '*'"));
         Token * _literal;
-        asdl_seq * _loop1_176_var;
+        asdl_seq * _loop1_177_var;
         Token * a;
         if (
-            (_loop1_176_var = _loop1_176_rule(p))  // param_maybe_default+
+            (_loop1_177_var = _loop1_177_rule(p))  // param_maybe_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -21319,7 +21331,7 @@ invalid_default_rule(Parser *p)
         if (
             (a = _PyPegen_expect_token(p, 22))  // token='='
             &&
-            _PyPegen_lookahead(1, _tmp_177_rule, p)
+            _PyPegen_lookahead(1, _tmp_178_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_default[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'=' &(')' | ',')"));
@@ -21364,12 +21376,12 @@ invalid_star_etc_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_star_etc[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*' (')' | ',' (')' | '**'))"));
-        void *_tmp_178_var;
+        void *_tmp_179_var;
         Token * a;
         if (
             (a = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_178_var = _tmp_178_rule(p))  // ')' | ',' (')' | '**')
+            (_tmp_179_var = _tmp_179_rule(p))  // ')' | ',' (')' | '**')
         )
         {
             D(fprintf(stderr, "%*c+ invalid_star_etc[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*' (')' | ',' (')' | '**'))"));
@@ -21452,20 +21464,20 @@ invalid_star_etc_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_star_etc[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*' (param_no_default | ',') param_maybe_default* '*' (param_no_default | ',')"));
         Token * _literal;
-        asdl_seq * _loop0_180_var;
-        void *_tmp_179_var;
-        void *_tmp_181_var;
+        asdl_seq * _loop0_181_var;
+        void *_tmp_180_var;
+        void *_tmp_182_var;
         Token * a;
         if (
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_179_var = _tmp_179_rule(p))  // param_no_default | ','
+            (_tmp_180_var = _tmp_180_rule(p))  // param_no_default | ','
             &&
-            (_loop0_180_var = _loop0_180_rule(p))  // param_maybe_default*
+            (_loop0_181_var = _loop0_181_rule(p))  // param_maybe_default*
             &&
             (a = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_181_var = _tmp_181_rule(p))  // param_no_default | ','
+            (_tmp_182_var = _tmp_182_rule(p))  // param_no_default | ','
         )
         {
             D(fprintf(stderr, "%*c+ invalid_star_etc[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*' (param_no_default | ',') param_maybe_default* '*' (param_no_default | ',')"));
@@ -21580,7 +21592,7 @@ invalid_kwds_rule(Parser *p)
             &&
             (_literal_1 = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (a = (Token*)_tmp_182_rule(p))  // '*' | '**' | '/'
+            (a = (Token*)_tmp_183_rule(p))  // '*' | '**' | '/'
         )
         {
             D(fprintf(stderr, "%*c+ invalid_kwds[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**' param ',' ('*' | '**' | '/')"));
@@ -21645,13 +21657,13 @@ invalid_parameters_helper_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_parameters_helper[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default+"));
-        asdl_seq * _loop1_183_var;
+        asdl_seq * _loop1_184_var;
         if (
-            (_loop1_183_var = _loop1_183_rule(p))  // param_with_default+
+            (_loop1_184_var = _loop1_184_rule(p))  // param_with_default+
         )
         {
             D(fprintf(stderr, "%*c+ invalid_parameters_helper[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_with_default+"));
-            _res = _loop1_183_var;
+            _res = _loop1_184_var;
             goto done;
         }
         p->mark = _mark;
@@ -21716,13 +21728,13 @@ invalid_lambda_parameters_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_lambda_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(lambda_slash_no_default | lambda_slash_with_default) lambda_param_maybe_default* '/'"));
-        asdl_seq * _loop0_185_var;
-        void *_tmp_184_var;
+        asdl_seq * _loop0_186_var;
+        void *_tmp_185_var;
         Token * a;
         if (
-            (_tmp_184_var = _tmp_184_rule(p))  // lambda_slash_no_default | lambda_slash_with_default
+            (_tmp_185_var = _tmp_185_rule(p))  // lambda_slash_no_default | lambda_slash_with_default
             &&
-            (_loop0_185_var = _loop0_185_rule(p))  // lambda_param_maybe_default*
+            (_loop0_186_var = _loop0_186_rule(p))  // lambda_param_maybe_default*
             &&
             (a = _PyPegen_expect_token(p, 17))  // token='/'
         )
@@ -21746,7 +21758,7 @@ invalid_lambda_parameters_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_lambda_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default? lambda_param_no_default* invalid_lambda_parameters_helper lambda_param_no_default"));
-        asdl_seq * _loop0_186_var;
+        asdl_seq * _loop0_187_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         arg_ty a;
@@ -21754,7 +21766,7 @@ invalid_lambda_parameters_rule(Parser *p)
         if (
             (_opt_var = lambda_slash_no_default_rule(p), !p->error_indicator)  // lambda_slash_no_default?
             &&
-            (_loop0_186_var = _loop0_186_rule(p))  // lambda_param_no_default*
+            (_loop0_187_var = _loop0_187_rule(p))  // lambda_param_no_default*
             &&
             (invalid_lambda_parameters_helper_var = invalid_lambda_parameters_helper_rule(p))  // invalid_lambda_parameters_helper
             &&
@@ -21780,18 +21792,18 @@ invalid_lambda_parameters_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_lambda_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default* '(' ','.lambda_param+ ','? ')'"));
-        asdl_seq * _gather_188_var;
-        asdl_seq * _loop0_187_var;
+        asdl_seq * _gather_189_var;
+        asdl_seq * _loop0_188_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         Token * a;
         Token * b;
         if (
-            (_loop0_187_var = _loop0_187_rule(p))  // lambda_param_no_default*
+            (_loop0_188_var = _loop0_188_rule(p))  // lambda_param_no_default*
             &&
             (a = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (_gather_188_var = _gather_188_rule(p))  // ','.lambda_param+
+            (_gather_189_var = _gather_189_rule(p))  // ','.lambda_param+
             &&
             (_opt_var = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
             &&
@@ -21818,22 +21830,22 @@ invalid_lambda_parameters_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_lambda_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "[(lambda_slash_no_default | lambda_slash_with_default)] lambda_param_maybe_default* '*' (',' | lambda_param_no_default) lambda_param_maybe_default* '/'"));
         Token * _literal;
-        asdl_seq * _loop0_191_var;
-        asdl_seq * _loop0_193_var;
+        asdl_seq * _loop0_192_var;
+        asdl_seq * _loop0_194_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
-        void *_tmp_192_var;
+        void *_tmp_193_var;
         Token * a;
         if (
-            (_opt_var = _tmp_190_rule(p), !p->error_indicator)  // [(lambda_slash_no_default | lambda_slash_with_default)]
+            (_opt_var = _tmp_191_rule(p), !p->error_indicator)  // [(lambda_slash_no_default | lambda_slash_with_default)]
             &&
-            (_loop0_191_var = _loop0_191_rule(p))  // lambda_param_maybe_default*
+            (_loop0_192_var = _loop0_192_rule(p))  // lambda_param_maybe_default*
             &&
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_192_var = _tmp_192_rule(p))  // ',' | lambda_param_no_default
+            (_tmp_193_var = _tmp_193_rule(p))  // ',' | lambda_param_no_default
             &&
-            (_loop0_193_var = _loop0_193_rule(p))  // lambda_param_maybe_default*
+            (_loop0_194_var = _loop0_194_rule(p))  // lambda_param_maybe_default*
             &&
             (a = _PyPegen_expect_token(p, 17))  // token='/'
         )
@@ -21858,10 +21870,10 @@ invalid_lambda_parameters_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_lambda_parameters[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default+ '/' '*'"));
         Token * _literal;
-        asdl_seq * _loop1_194_var;
+        asdl_seq * _loop1_195_var;
         Token * a;
         if (
-            (_loop1_194_var = _loop1_194_rule(p))  // lambda_param_maybe_default+
+            (_loop1_195_var = _loop1_195_rule(p))  // lambda_param_maybe_default+
             &&
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
             &&
@@ -21932,13 +21944,13 @@ invalid_lambda_parameters_helper_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_lambda_parameters_helper[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default+"));
-        asdl_seq * _loop1_195_var;
+        asdl_seq * _loop1_196_var;
         if (
-            (_loop1_195_var = _loop1_195_rule(p))  // lambda_param_with_default+
+            (_loop1_196_var = _loop1_196_rule(p))  // lambda_param_with_default+
         )
         {
             D(fprintf(stderr, "%*c+ invalid_lambda_parameters_helper[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default+"));
-            _res = _loop1_195_var;
+            _res = _loop1_196_var;
             goto done;
         }
         p->mark = _mark;
@@ -21974,11 +21986,11 @@ invalid_lambda_star_etc_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_lambda_star_etc[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*' (':' | ',' (':' | '**'))"));
         Token * _literal;
-        void *_tmp_196_var;
+        void *_tmp_197_var;
         if (
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_196_var = _tmp_196_rule(p))  // ':' | ',' (':' | '**')
+            (_tmp_197_var = _tmp_197_rule(p))  // ':' | ',' (':' | '**')
         )
         {
             D(fprintf(stderr, "%*c+ invalid_lambda_star_etc[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*' (':' | ',' (':' | '**'))"));
@@ -22031,20 +22043,20 @@ invalid_lambda_star_etc_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_lambda_star_etc[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*' (lambda_param_no_default | ',') lambda_param_maybe_default* '*' (lambda_param_no_default | ',')"));
         Token * _literal;
-        asdl_seq * _loop0_198_var;
-        void *_tmp_197_var;
-        void *_tmp_199_var;
+        asdl_seq * _loop0_199_var;
+        void *_tmp_198_var;
+        void *_tmp_200_var;
         Token * a;
         if (
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_197_var = _tmp_197_rule(p))  // lambda_param_no_default | ','
+            (_tmp_198_var = _tmp_198_rule(p))  // lambda_param_no_default | ','
             &&
-            (_loop0_198_var = _loop0_198_rule(p))  // lambda_param_maybe_default*
+            (_loop0_199_var = _loop0_199_rule(p))  // lambda_param_maybe_default*
             &&
             (a = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_199_var = _tmp_199_rule(p))  // lambda_param_no_default | ','
+            (_tmp_200_var = _tmp_200_rule(p))  // lambda_param_no_default | ','
         )
         {
             D(fprintf(stderr, "%*c+ invalid_lambda_star_etc[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*' (lambda_param_no_default | ',') lambda_param_maybe_default* '*' (lambda_param_no_default | ',')"));
@@ -22162,7 +22174,7 @@ invalid_lambda_kwds_rule(Parser *p)
             &&
             (_literal_1 = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (a = (Token*)_tmp_200_rule(p))  // '*' | '**' | '/'
+            (a = (Token*)_tmp_201_rule(p))  // '*' | '**' | '/'
         )
         {
             D(fprintf(stderr, "%*c+ invalid_lambda_kwds[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**' lambda_param ',' ('*' | '**' | '/')"));
@@ -22268,7 +22280,7 @@ invalid_with_item_rule(Parser *p)
             &&
             (a = expression_rule(p))  // expression
             &&
-            _PyPegen_lookahead(1, _tmp_201_rule, p)
+            _PyPegen_lookahead(1, _tmp_202_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_with_item[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression 'as' expression &(',' | ')' | ':')"));
@@ -22441,14 +22453,14 @@ invalid_import_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_import[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'import' ','.dotted_name+ 'from' dotted_name"));
-        asdl_seq * _gather_202_var;
+        asdl_seq * _gather_203_var;
         Token * _keyword;
         Token * a;
         expr_ty dotted_name_var;
         if (
             (a = _PyPegen_expect_token(p, 607))  // token='import'
             &&
-            (_gather_202_var = _gather_202_rule(p))  // ','.dotted_name+
+            (_gather_203_var = _gather_203_rule(p))  // ','.dotted_name+
             &&
             (_keyword = _PyPegen_expect_token(p, 608))  // token='from'
             &&
@@ -22544,7 +22556,7 @@ invalid_with_stmt_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_with_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC? 'with' ','.(expression ['as' star_target])+ NEWLINE"));
-        asdl_seq * _gather_204_var;
+        asdl_seq * _gather_205_var;
         Token * _keyword;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
@@ -22554,7 +22566,7 @@ invalid_with_stmt_rule(Parser *p)
             &&
             (_keyword = _PyPegen_expect_token(p, 615))  // token='with'
             &&
-            (_gather_204_var = _gather_204_rule(p))  // ','.(expression ['as' star_target])+
+            (_gather_205_var = _gather_205_rule(p))  // ','.(expression ['as' star_target])+
             &&
             (newline_var = _PyPegen_expect_token(p, NEWLINE))  // token='NEWLINE'
         )
@@ -22578,7 +22590,7 @@ invalid_with_stmt_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_with_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC? 'with' '(' ','.(expressions ['as' star_target])+ ','? ')' NEWLINE"));
-        asdl_seq * _gather_206_var;
+        asdl_seq * _gather_207_var;
         Token * _keyword;
         Token * _literal;
         Token * _literal_1;
@@ -22594,7 +22606,7 @@ invalid_with_stmt_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (_gather_206_var = _gather_206_rule(p))  // ','.(expressions ['as' star_target])+
+            (_gather_207_var = _gather_207_rule(p))  // ','.(expressions ['as' star_target])+
             &&
             (_opt_var_1 = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
             &&
@@ -22643,7 +22655,7 @@ invalid_with_stmt_indent_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_with_stmt_indent[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC? 'with' ','.(expression ['as' star_target])+ ':' NEWLINE !INDENT"));
-        asdl_seq * _gather_208_var;
+        asdl_seq * _gather_209_var;
         Token * _literal;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
@@ -22654,7 +22666,7 @@ invalid_with_stmt_indent_rule(Parser *p)
             &&
             (a = _PyPegen_expect_token(p, 615))  // token='with'
             &&
-            (_gather_208_var = _gather_208_rule(p))  // ','.(expression ['as' star_target])+
+            (_gather_209_var = _gather_209_rule(p))  // ','.(expression ['as' star_target])+
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -22682,7 +22694,7 @@ invalid_with_stmt_indent_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_with_stmt_indent[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC? 'with' '(' ','.(expressions ['as' star_target])+ ','? ')' ':' NEWLINE !INDENT"));
-        asdl_seq * _gather_210_var;
+        asdl_seq * _gather_211_var;
         Token * _literal;
         Token * _literal_1;
         Token * _literal_2;
@@ -22699,7 +22711,7 @@ invalid_with_stmt_indent_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (_gather_210_var = _gather_210_rule(p))  // ','.(expressions ['as' star_target])+
+            (_gather_211_var = _gather_211_rule(p))  // ','.(expressions ['as' star_target])+
             &&
             (_opt_var_1 = _PyPegen_expect_token(p, 12), !p->error_indicator)  // ','?
             &&
@@ -22796,7 +22808,7 @@ invalid_try_stmt_rule(Parser *p)
             &&
             (block_var = block_rule(p))  // block
             &&
-            _PyPegen_lookahead(0, _tmp_212_rule, p)
+            _PyPegen_lookahead(0, _tmp_213_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_try_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'try' ':' block !('except' | 'finally')"));
@@ -22821,8 +22833,8 @@ invalid_try_stmt_rule(Parser *p)
         Token * _keyword;
         Token * _literal;
         Token * _literal_1;
-        asdl_seq * _loop0_213_var;
-        asdl_seq * _loop1_214_var;
+        asdl_seq * _loop0_214_var;
+        asdl_seq * _loop1_215_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         Token * a;
@@ -22833,9 +22845,9 @@ invalid_try_stmt_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
-            (_loop0_213_var = _loop0_213_rule(p))  // block*
+            (_loop0_214_var = _loop0_214_rule(p))  // block*
             &&
-            (_loop1_214_var = _loop1_214_rule(p))  // except_block+
+            (_loop1_215_var = _loop1_215_rule(p))  // except_block+
             &&
             (a = _PyPegen_expect_token(p, 637))  // token='except'
             &&
@@ -22843,7 +22855,7 @@ invalid_try_stmt_rule(Parser *p)
             &&
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var = _tmp_215_rule(p), !p->error_indicator)  // ['as' NAME]
+            (_opt_var = _tmp_216_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
         )
@@ -22870,8 +22882,8 @@ invalid_try_stmt_rule(Parser *p)
         Token * _keyword;
         Token * _literal;
         Token * _literal_1;
-        asdl_seq * _loop0_216_var;
-        asdl_seq * _loop1_217_var;
+        asdl_seq * _loop0_217_var;
+        asdl_seq * _loop1_218_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         Token * a;
@@ -22880,13 +22892,13 @@ invalid_try_stmt_rule(Parser *p)
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
-            (_loop0_216_var = _loop0_216_rule(p))  // block*
+            (_loop0_217_var = _loop0_217_rule(p))  // block*
             &&
-            (_loop1_217_var = _loop1_217_rule(p))  // except_star_block+
+            (_loop1_218_var = _loop1_218_rule(p))  // except_star_block+
             &&
             (a = _PyPegen_expect_token(p, 637))  // token='except'
             &&
-            (_opt_var = _tmp_218_rule(p), !p->error_indicator)  // [expression ['as' NAME]]
+            (_opt_var = _tmp_219_rule(p), !p->error_indicator)  // [expression ['as' NAME]]
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
         )
@@ -22953,7 +22965,7 @@ invalid_except_stmt_rule(Parser *p)
             &&
             (expressions_var = expressions_rule(p))  // expressions
             &&
-            (_opt_var_1 = _tmp_219_rule(p), !p->error_indicator)  // ['as' NAME]
+            (_opt_var_1 = _tmp_220_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
         )
@@ -22991,7 +23003,7 @@ invalid_except_stmt_rule(Parser *p)
             &&
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var_1 = _tmp_220_rule(p), !p->error_indicator)  // ['as' NAME]
+            (_opt_var_1 = _tmp_221_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (newline_var = _PyPegen_expect_token(p, NEWLINE))  // token='NEWLINE'
         )
@@ -23043,14 +23055,14 @@ invalid_except_stmt_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_except_stmt[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'except' '*' (NEWLINE | ':')"));
         Token * _literal;
-        void *_tmp_221_var;
+        void *_tmp_222_var;
         Token * a;
         if (
             (a = _PyPegen_expect_token(p, 637))  // token='except'
             &&
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
             &&
-            (_tmp_221_var = _tmp_221_rule(p))  // NEWLINE | ':'
+            (_tmp_222_var = _tmp_222_rule(p))  // NEWLINE | ':'
         )
         {
             D(fprintf(stderr, "%*c+ invalid_except_stmt[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'except' '*' (NEWLINE | ':')"));
@@ -23155,7 +23167,7 @@ invalid_except_stmt_indent_rule(Parser *p)
             &&
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var = _tmp_222_rule(p), !p->error_indicator)  // ['as' NAME]
+            (_opt_var = _tmp_223_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -23249,7 +23261,7 @@ invalid_except_star_stmt_indent_rule(Parser *p)
             &&
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var = _tmp_223_rule(p), !p->error_indicator)  // ['as' NAME]
+            (_opt_var = _tmp_224_rule(p), !p->error_indicator)  // ['as' NAME]
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -23613,7 +23625,7 @@ invalid_class_argument_pattern_rule(Parser *p)
         asdl_pattern_seq* a;
         asdl_seq* keyword_patterns_var;
         if (
-            (_opt_var = _tmp_224_rule(p), !p->error_indicator)  // [positional_patterns ',']
+            (_opt_var = _tmp_225_rule(p), !p->error_indicator)  // [positional_patterns ',']
             &&
             (keyword_patterns_var = keyword_patterns_rule(p))  // keyword_patterns
             &&
@@ -24057,7 +24069,7 @@ invalid_for_stmt_rule(Parser *p)
 }
 
 // invalid_def_raw:
-//     | ASYNC? 'def' NAME '(' params? ')' ['->' expression] ':' NEWLINE !INDENT
+//     | ASYNC? 'def' NAME type_params? '(' params? ')' ['->' expression] ':' NEWLINE !INDENT
 static void *
 invalid_def_raw_rule(Parser *p)
 {
@@ -24070,12 +24082,12 @@ invalid_def_raw_rule(Parser *p)
     }
     void * _res = NULL;
     int _mark = p->mark;
-    { // ASYNC? 'def' NAME '(' params? ')' ['->' expression] ':' NEWLINE !INDENT
+    { // ASYNC? 'def' NAME type_params? '(' params? ')' ['->' expression] ':' NEWLINE !INDENT
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> invalid_def_raw[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC? 'def' NAME '(' params? ')' ['->' expression] ':' NEWLINE !INDENT"));
+        D(fprintf(stderr, "%*c> invalid_def_raw[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC? 'def' NAME type_params? '(' params? ')' ['->' expression] ':' NEWLINE !INDENT"));
         Token * _literal;
         Token * _literal_1;
         Token * _literal_2;
@@ -24085,6 +24097,8 @@ invalid_def_raw_rule(Parser *p)
         UNUSED(_opt_var_1); // Silence compiler warnings
         void *_opt_var_2;
         UNUSED(_opt_var_2); // Silence compiler warnings
+        void *_opt_var_3;
+        UNUSED(_opt_var_3); // Silence compiler warnings
         Token * a;
         expr_ty name_var;
         Token * newline_var;
@@ -24095,13 +24109,15 @@ invalid_def_raw_rule(Parser *p)
             &&
             (name_var = _PyPegen_name_token(p))  // NAME
             &&
+            (_opt_var_1 = type_params_rule(p), !p->error_indicator)  // type_params?
+            &&
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
             &&
-            (_opt_var_1 = params_rule(p), !p->error_indicator)  // params?
+            (_opt_var_2 = params_rule(p), !p->error_indicator)  // params?
             &&
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
             &&
-            (_opt_var_2 = _tmp_225_rule(p), !p->error_indicator)  // ['->' expression]
+            (_opt_var_3 = _tmp_226_rule(p), !p->error_indicator)  // ['->' expression]
             &&
             (_literal_2 = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -24110,7 +24126,7 @@ invalid_def_raw_rule(Parser *p)
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, INDENT)  // token=INDENT
         )
         {
-            D(fprintf(stderr, "%*c+ invalid_def_raw[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC? 'def' NAME '(' params? ')' ['->' expression] ':' NEWLINE !INDENT"));
+            D(fprintf(stderr, "%*c+ invalid_def_raw[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC? 'def' NAME type_params? '(' params? ')' ['->' expression] ':' NEWLINE !INDENT"));
             _res = RAISE_INDENTATION_ERROR ( "expected an indented block after function definition on line %d" , a -> lineno );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -24121,7 +24137,7 @@ invalid_def_raw_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s invalid_def_raw[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "ASYNC? 'def' NAME '(' params? ')' ['->' expression] ':' NEWLINE !INDENT"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "ASYNC? 'def' NAME type_params? '(' params? ')' ['->' expression] ':' NEWLINE !INDENT"));
     }
     _res = NULL;
   done:
@@ -24130,8 +24146,8 @@ invalid_def_raw_rule(Parser *p)
 }
 
 // invalid_class_def_raw:
-//     | 'class' NAME ['(' arguments? ')'] NEWLINE
-//     | 'class' NAME ['(' arguments? ')'] ':' NEWLINE !INDENT
+//     | 'class' NAME type_params? ['(' arguments? ')'] NEWLINE
+//     | 'class' NAME type_params? ['(' arguments? ')'] ':' NEWLINE !INDENT
 static void *
 invalid_class_def_raw_rule(Parser *p)
 {
@@ -24144,15 +24160,17 @@ invalid_class_def_raw_rule(Parser *p)
     }
     void * _res = NULL;
     int _mark = p->mark;
-    { // 'class' NAME ['(' arguments? ')'] NEWLINE
+    { // 'class' NAME type_params? ['(' arguments? ')'] NEWLINE
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> invalid_class_def_raw[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'class' NAME ['(' arguments? ')'] NEWLINE"));
+        D(fprintf(stderr, "%*c> invalid_class_def_raw[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'class' NAME type_params? ['(' arguments? ')'] NEWLINE"));
         Token * _keyword;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
+        void *_opt_var_1;
+        UNUSED(_opt_var_1); // Silence compiler warnings
         expr_ty name_var;
         Token * newline_var;
         if (
@@ -24160,12 +24178,14 @@ invalid_class_def_raw_rule(Parser *p)
             &&
             (name_var = _PyPegen_name_token(p))  // NAME
             &&
-            (_opt_var = _tmp_226_rule(p), !p->error_indicator)  // ['(' arguments? ')']
+            (_opt_var = type_params_rule(p), !p->error_indicator)  // type_params?
+            &&
+            (_opt_var_1 = _tmp_227_rule(p), !p->error_indicator)  // ['(' arguments? ')']
             &&
             (newline_var = _PyPegen_expect_token(p, NEWLINE))  // token='NEWLINE'
         )
         {
-            D(fprintf(stderr, "%*c+ invalid_class_def_raw[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'class' NAME ['(' arguments? ')'] NEWLINE"));
+            D(fprintf(stderr, "%*c+ invalid_class_def_raw[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'class' NAME type_params? ['(' arguments? ')'] NEWLINE"));
             _res = RAISE_SYNTAX_ERROR ( "expected ':'" );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -24176,17 +24196,19 @@ invalid_class_def_raw_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s invalid_class_def_raw[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'class' NAME ['(' arguments? ')'] NEWLINE"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'class' NAME type_params? ['(' arguments? ')'] NEWLINE"));
     }
-    { // 'class' NAME ['(' arguments? ')'] ':' NEWLINE !INDENT
+    { // 'class' NAME type_params? ['(' arguments? ')'] ':' NEWLINE !INDENT
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> invalid_class_def_raw[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'class' NAME ['(' arguments? ')'] ':' NEWLINE !INDENT"));
+        D(fprintf(stderr, "%*c> invalid_class_def_raw[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'class' NAME type_params? ['(' arguments? ')'] ':' NEWLINE !INDENT"));
         Token * _literal;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
+        void *_opt_var_1;
+        UNUSED(_opt_var_1); // Silence compiler warnings
         Token * a;
         expr_ty name_var;
         Token * newline_var;
@@ -24195,7 +24217,9 @@ invalid_class_def_raw_rule(Parser *p)
             &&
             (name_var = _PyPegen_name_token(p))  // NAME
             &&
-            (_opt_var = _tmp_227_rule(p), !p->error_indicator)  // ['(' arguments? ')']
+            (_opt_var = type_params_rule(p), !p->error_indicator)  // type_params?
+            &&
+            (_opt_var_1 = _tmp_228_rule(p), !p->error_indicator)  // ['(' arguments? ')']
             &&
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
             &&
@@ -24204,7 +24228,7 @@ invalid_class_def_raw_rule(Parser *p)
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, INDENT)  // token=INDENT
         )
         {
-            D(fprintf(stderr, "%*c+ invalid_class_def_raw[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'class' NAME ['(' arguments? ')'] ':' NEWLINE !INDENT"));
+            D(fprintf(stderr, "%*c+ invalid_class_def_raw[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'class' NAME type_params? ['(' arguments? ')'] ':' NEWLINE !INDENT"));
             _res = RAISE_INDENTATION_ERROR ( "expected an indented block after class definition on line %d" , a -> lineno );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -24215,7 +24239,7 @@ invalid_class_def_raw_rule(Parser *p)
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s invalid_class_def_raw[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'class' NAME ['(' arguments? ')'] ':' NEWLINE !INDENT"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'class' NAME type_params? ['(' arguments? ')'] ':' NEWLINE !INDENT"));
     }
     _res = NULL;
   done:
@@ -24245,11 +24269,11 @@ invalid_double_starred_kvpairs_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> invalid_double_starred_kvpairs[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.double_starred_kvpair+ ',' invalid_kvpair"));
-        asdl_seq * _gather_228_var;
+        asdl_seq * _gather_229_var;
         Token * _literal;
         void *invalid_kvpair_var;
         if (
-            (_gather_228_var = _gather_228_rule(p))  // ','.double_starred_kvpair+
+            (_gather_229_var = _gather_229_rule(p))  // ','.double_starred_kvpair+
             &&
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
@@ -24257,7 +24281,7 @@ invalid_double_starred_kvpairs_rule(Parser *p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_double_starred_kvpairs[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.double_starred_kvpair+ ',' invalid_kvpair"));
-            _res = _PyPegen_dummy_name(p, _gather_228_var, _literal, invalid_kvpair_var);
+            _res = _PyPegen_dummy_name(p, _gather_229_var, _literal, invalid_kvpair_var);
             goto done;
         }
         p->mark = _mark;
@@ -24310,7 +24334,7 @@ invalid_double_starred_kvpairs_rule(Parser *p)
             &&
             (a = _PyPegen_expect_token(p, 11))  // token=':'
             &&
-            _PyPegen_lookahead(1, _tmp_230_rule, p)
+            _PyPegen_lookahead(1, _tmp_231_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_double_starred_kvpairs[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ':' &('}' | ',')"));
@@ -24420,7 +24444,7 @@ invalid_kvpair_rule(Parser *p)
             &&
             (a = _PyPegen_expect_token(p, 11))  // token=':'
             &&
-            _PyPegen_lookahead(1, _tmp_231_rule, p)
+            _PyPegen_lookahead(1, _tmp_232_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_kvpair[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ':' &('}' | ',')"));
@@ -24636,7 +24660,7 @@ invalid_replacement_field_rule(Parser *p)
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            _PyPegen_lookahead(0, _tmp_232_rule, p)
+            _PyPegen_lookahead(0, _tmp_233_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' !(yield_expr | star_expressions)"));
@@ -24659,13 +24683,13 @@ invalid_replacement_field_rule(Parser *p)
         }
         D(fprintf(stderr, "%*c> invalid_replacement_field[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) !('=' | '!' | ':' | '}')"));
         Token * _literal;
-        void *_tmp_233_var;
+        void *_tmp_234_var;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (_tmp_233_var = _tmp_233_rule(p))  // yield_expr | star_expressions
+            (_tmp_234_var = _tmp_234_rule(p))  // yield_expr | star_expressions
             &&
-            _PyPegen_lookahead(0, _tmp_234_rule, p)
+            _PyPegen_lookahead(0, _tmp_235_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) !('=' | '!' | ':' | '}')"));
@@ -24689,15 +24713,15 @@ invalid_replacement_field_rule(Parser *p)
         D(fprintf(stderr, "%*c> invalid_replacement_field[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '=' !('!' | ':' | '}')"));
         Token * _literal;
         Token * _literal_1;
-        void *_tmp_235_var;
+        void *_tmp_236_var;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (_tmp_235_var = _tmp_235_rule(p))  // yield_expr | star_expressions
+            (_tmp_236_var = _tmp_236_rule(p))  // yield_expr | star_expressions
             &&
             (_literal_1 = _PyPegen_expect_token(p, 22))  // token='='
             &&
-            _PyPegen_lookahead(0, _tmp_236_rule, p)
+            _PyPegen_lookahead(0, _tmp_237_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '=' !('!' | ':' | '}')"));
@@ -24722,12 +24746,12 @@ invalid_replacement_field_rule(Parser *p)
         Token * _literal;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
-        void *_tmp_237_var;
+        void *_tmp_238_var;
         void *invalid_conversion_character_var;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (_tmp_237_var = _tmp_237_rule(p))  // yield_expr | star_expressions
+            (_tmp_238_var = _tmp_238_rule(p))  // yield_expr | star_expressions
             &&
             (_opt_var = _PyPegen_expect_token(p, 22), !p->error_indicator)  // '='?
             &&
@@ -24735,7 +24759,7 @@ invalid_replacement_field_rule(Parser *p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '='? invalid_conversion_character"));
-            _res = _PyPegen_dummy_name(p, _literal, _tmp_237_var, _opt_var, invalid_conversion_character_var);
+            _res = _PyPegen_dummy_name(p, _literal, _tmp_238_var, _opt_var, invalid_conversion_character_var);
             goto done;
         }
         p->mark = _mark;
@@ -24753,17 +24777,17 @@ invalid_replacement_field_rule(Parser *p)
         UNUSED(_opt_var); // Silence compiler warnings
         void *_opt_var_1;
         UNUSED(_opt_var_1); // Silence compiler warnings
-        void *_tmp_238_var;
+        void *_tmp_239_var;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (_tmp_238_var = _tmp_238_rule(p))  // yield_expr | star_expressions
+            (_tmp_239_var = _tmp_239_rule(p))  // yield_expr | star_expressions
             &&
             (_opt_var = _PyPegen_expect_token(p, 22), !p->error_indicator)  // '='?
             &&
-            (_opt_var_1 = _tmp_239_rule(p), !p->error_indicator)  // ['!' NAME]
+            (_opt_var_1 = _tmp_240_rule(p), !p->error_indicator)  // ['!' NAME]
             &&
-            _PyPegen_lookahead(0, _tmp_240_rule, p)
+            _PyPegen_lookahead(0, _tmp_241_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_replacement_field[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '='? ['!' NAME] !(':' | '}')"));
@@ -24787,24 +24811,24 @@ invalid_replacement_field_rule(Parser *p)
         D(fprintf(stderr, "%*c> invalid_replacement_field[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{' (yield_expr | star_expressions) '='? ['!' NAME] ':' fstring_format_spec* !'}'"));
         Token * _literal;
         Token * _literal_1;
-        asdl_seq * _loop0_243_var;
+        asdl_seq * _loop0_244_var;
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         void *_opt_var_1;
         UNUSED(_opt_var_1); // Silence compiler warnings
-        void *_tmp_241_var;
+        void *_tmp_242_var;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (_tmp_241_var = _tmp_241_rule(p))  // yield_expr | star_expressions
+            (_tmp_242_var = _tmp_242_rule(p))  // yield_expr | star_expressions
             &&
             (_opt_var = _PyPegen_expect_token(p, 22), !p->error_indicator)  // '='?
             &&
-            (_opt_var_1 = _tmp_242_rule(p), !p->error_indicator)  // ['!' NAME]
+            (_opt_var_1 = _tmp_243_rule(p), !p->error_indicator)  // ['!' NAME]
             &&
             (_literal_1 = _PyPegen_expect_token(p, 11))  // token=':'
             &&
-            (_loop0_243_var = _loop0_243_rule(p))  // fstring_format_spec*
+            (_loop0_244_var = _loop0_244_rule(p))  // fstring_format_spec*
             &&
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 26)  // token='}'
         )
@@ -24833,15 +24857,15 @@ invalid_replacement_field_rule(Parser *p)
         UNUSED(_opt_var); // Silence compiler warnings
         void *_opt_var_1;
         UNUSED(_opt_var_1); // Silence compiler warnings
-        void *_tmp_244_var;
+        void *_tmp_245_var;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
             &&
-            (_tmp_244_var = _tmp_244_rule(p))  // yield_expr | star_expressions
+            (_tmp_245_var = _tmp_245_rule(p))  // yield_expr | star_expressions
             &&
             (_opt_var = _PyPegen_expect_token(p, 22), !p->error_indicator)  // '='?
             &&
-            (_opt_var_1 = _tmp_245_rule(p), !p->error_indicator)  // ['!' NAME]
+            (_opt_var_1 = _tmp_246_rule(p), !p->error_indicator)  // ['!' NAME]
             &&
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 26)  // token='}'
         )
@@ -24888,7 +24912,7 @@ invalid_conversion_character_rule(Parser *p)
         if (
             (_literal = _PyPegen_expect_token(p, 54))  // token='!'
             &&
-            _PyPegen_lookahead(1, _tmp_246_rule, p)
+            _PyPegen_lookahead(1, _tmp_247_rule, p)
         )
         {
             D(fprintf(stderr, "%*c+ invalid_conversion_character[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' &(':' | '}')"));
@@ -25070,76 +25094,9 @@ _loop0_2_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_3: fstring_middle
-static asdl_seq *
-_loop0_3_rule(Parser *p)
-{
-    if (p->level++ == MAXSTACK) {
-        _Pypegen_stack_overflow(p);
-    }
-    if (p->error_indicator) {
-        p->level--;
-        return NULL;
-    }
-    void *_res = NULL;
-    int _mark = p->mark;
-    void **_children = PyMem_Malloc(sizeof(void *));
-    if (!_children) {
-        p->error_indicator = 1;
-        PyErr_NoMemory();
-        p->level--;
-        return NULL;
-    }
-    Py_ssize_t _children_capacity = 1;
-    Py_ssize_t _n = 0;
-    { // fstring_middle
-        if (p->error_indicator) {
-            p->level--;
-            return NULL;
-        }
-        D(fprintf(stderr, "%*c> _loop0_3[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring_middle"));
-        expr_ty fstring_middle_var;
-        while (
-            (fstring_middle_var = fstring_middle_rule(p))  // fstring_middle
-        )
-        {
-            _res = fstring_middle_var;
-            if (_n == _children_capacity) {
-                _children_capacity *= 2;
-                void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
-                if (!_new_children) {
-                    PyMem_Free(_children);
-                    p->error_indicator = 1;
-                    PyErr_NoMemory();
-                    p->level--;
-                    return NULL;
-                }
-                _children = _new_children;
-            }
-            _children[_n++] = _res;
-            _mark = p->mark;
-        }
-        p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_3[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "fstring_middle"));
-    }
-    asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
-    if (!_seq) {
-        PyMem_Free(_children);
-        p->error_indicator = 1;
-        PyErr_NoMemory();
-        p->level--;
-        return NULL;
-    }
-    for (int i = 0; i < _n; i++) asdl_seq_SET_UNTYPED(_seq, i, _children[i]);
-    PyMem_Free(_children);
-    p->level--;
-    return _seq;
-}
-
-// _loop1_4: statement
+// _loop1_3: statement
 static asdl_seq *
-_loop1_4_rule(Parser *p)
+_loop1_3_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25164,7 +25121,7 @@ _loop1_4_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_4[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "statement"));
+        D(fprintf(stderr, "%*c> _loop1_3[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "statement"));
         asdl_stmt_seq* statement_var;
         while (
             (statement_var = statement_rule(p))  // statement
@@ -25187,7 +25144,7 @@ _loop1_4_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_4[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_3[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "statement"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -25209,9 +25166,9 @@ _loop1_4_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_6: ';' simple_stmt
+// _loop0_5: ';' simple_stmt
 static asdl_seq *
-_loop0_6_rule(Parser *p)
+_loop0_5_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25236,7 +25193,7 @@ _loop0_6_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_6[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "';' simple_stmt"));
+        D(fprintf(stderr, "%*c> _loop0_5[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "';' simple_stmt"));
         Token * _literal;
         stmt_ty elem;
         while (
@@ -25268,7 +25225,7 @@ _loop0_6_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_6[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_5[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "';' simple_stmt"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -25285,9 +25242,9 @@ _loop0_6_rule(Parser *p)
     return _seq;
 }
 
-// _gather_5: simple_stmt _loop0_6
+// _gather_4: simple_stmt _loop0_5
 static asdl_seq *
-_gather_5_rule(Parser *p)
+_gather_4_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25298,27 +25255,27 @@ _gather_5_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // simple_stmt _loop0_6
+    { // simple_stmt _loop0_5
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_5[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "simple_stmt _loop0_6"));
+        D(fprintf(stderr, "%*c> _gather_4[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "simple_stmt _loop0_5"));
         stmt_ty elem;
         asdl_seq * seq;
         if (
             (elem = simple_stmt_rule(p))  // simple_stmt
             &&
-            (seq = _loop0_6_rule(p))  // _loop0_6
+            (seq = _loop0_5_rule(p))  // _loop0_5
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_5[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "simple_stmt _loop0_6"));
+            D(fprintf(stderr, "%*c+ _gather_4[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "simple_stmt _loop0_5"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_5[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "simple_stmt _loop0_6"));
+        D(fprintf(stderr, "%*c%s _gather_4[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "simple_stmt _loop0_5"));
     }
     _res = NULL;
   done:
@@ -25326,9 +25283,9 @@ _gather_5_rule(Parser *p)
     return _res;
 }
 
-// _tmp_7: 'import' | 'from'
+// _tmp_6: 'import' | 'from'
 static void *
-_tmp_7_rule(Parser *p)
+_tmp_6_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25344,18 +25301,18 @@ _tmp_7_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_7[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'import'"));
+        D(fprintf(stderr, "%*c> _tmp_6[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'import'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 607))  // token='import'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_7[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'import'"));
+            D(fprintf(stderr, "%*c+ _tmp_6[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'import'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_7[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_6[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'import'"));
     }
     { // 'from'
@@ -25363,18 +25320,18 @@ _tmp_7_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_7[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'from'"));
+        D(fprintf(stderr, "%*c> _tmp_6[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'from'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 608))  // token='from'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_7[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'from'"));
+            D(fprintf(stderr, "%*c+ _tmp_6[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'from'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_7[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_6[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'from'"));
     }
     _res = NULL;
@@ -25383,9 +25340,9 @@ _tmp_7_rule(Parser *p)
     return _res;
 }
 
-// _tmp_8: 'def' | '@' | ASYNC
+// _tmp_7: 'def' | '@' | ASYNC
 static void *
-_tmp_8_rule(Parser *p)
+_tmp_7_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25401,18 +25358,18 @@ _tmp_8_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_8[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'def'"));
+        D(fprintf(stderr, "%*c> _tmp_7[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'def'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 652))  // token='def'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_8[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'def'"));
+            D(fprintf(stderr, "%*c+ _tmp_7[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'def'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_8[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_7[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'def'"));
     }
     { // '@'
@@ -25420,18 +25377,18 @@ _tmp_8_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_8[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'@'"));
+        D(fprintf(stderr, "%*c> _tmp_7[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'@'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 49))  // token='@'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_8[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'@'"));
+            D(fprintf(stderr, "%*c+ _tmp_7[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'@'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_8[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_7[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'@'"));
     }
     { // ASYNC
@@ -25439,18 +25396,18 @@ _tmp_8_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_8[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC"));
+        D(fprintf(stderr, "%*c> _tmp_7[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC"));
         Token * async_var;
         if (
             (async_var = _PyPegen_expect_token(p, ASYNC))  // token='ASYNC'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_8[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC"));
+            D(fprintf(stderr, "%*c+ _tmp_7[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC"));
             _res = async_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_8[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_7[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "ASYNC"));
     }
     _res = NULL;
@@ -25459,9 +25416,9 @@ _tmp_8_rule(Parser *p)
     return _res;
 }
 
-// _tmp_9: 'class' | '@'
+// _tmp_8: 'class' | '@'
 static void *
-_tmp_9_rule(Parser *p)
+_tmp_8_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25477,18 +25434,18 @@ _tmp_9_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_9[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'class'"));
+        D(fprintf(stderr, "%*c> _tmp_8[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'class'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 654))  // token='class'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_9[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'class'"));
+            D(fprintf(stderr, "%*c+ _tmp_8[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'class'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_9[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_8[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'class'"));
     }
     { // '@'
@@ -25496,18 +25453,18 @@ _tmp_9_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_9[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'@'"));
+        D(fprintf(stderr, "%*c> _tmp_8[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'@'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 49))  // token='@'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_9[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'@'"));
+            D(fprintf(stderr, "%*c+ _tmp_8[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'@'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_9[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_8[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'@'"));
     }
     _res = NULL;
@@ -25516,9 +25473,9 @@ _tmp_9_rule(Parser *p)
     return _res;
 }
 
-// _tmp_10: 'with' | ASYNC
+// _tmp_9: 'with' | ASYNC
 static void *
-_tmp_10_rule(Parser *p)
+_tmp_9_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25534,18 +25491,18 @@ _tmp_10_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_10[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'with'"));
+        D(fprintf(stderr, "%*c> _tmp_9[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'with'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 615))  // token='with'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_10[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'with'"));
+            D(fprintf(stderr, "%*c+ _tmp_9[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'with'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_10[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_9[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'with'"));
     }
     { // ASYNC
@@ -25553,18 +25510,18 @@ _tmp_10_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_10[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC"));
+        D(fprintf(stderr, "%*c> _tmp_9[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC"));
         Token * async_var;
         if (
             (async_var = _PyPegen_expect_token(p, ASYNC))  // token='ASYNC'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_10[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC"));
+            D(fprintf(stderr, "%*c+ _tmp_9[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC"));
             _res = async_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_10[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_9[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "ASYNC"));
     }
     _res = NULL;
@@ -25573,9 +25530,9 @@ _tmp_10_rule(Parser *p)
     return _res;
 }
 
-// _tmp_11: 'for' | ASYNC
+// _tmp_10: 'for' | ASYNC
 static void *
-_tmp_11_rule(Parser *p)
+_tmp_10_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25591,18 +25548,18 @@ _tmp_11_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_11[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'for'"));
+        D(fprintf(stderr, "%*c> _tmp_10[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'for'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 650))  // token='for'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_11[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'for'"));
+            D(fprintf(stderr, "%*c+ _tmp_10[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'for'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_11[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_10[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'for'"));
     }
     { // ASYNC
@@ -25610,18 +25567,18 @@ _tmp_11_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_11[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC"));
+        D(fprintf(stderr, "%*c> _tmp_10[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "ASYNC"));
         Token * async_var;
         if (
             (async_var = _PyPegen_expect_token(p, ASYNC))  // token='ASYNC'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_11[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC"));
+            D(fprintf(stderr, "%*c+ _tmp_10[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "ASYNC"));
             _res = async_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_11[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_10[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "ASYNC"));
     }
     _res = NULL;
@@ -25630,9 +25587,9 @@ _tmp_11_rule(Parser *p)
     return _res;
 }
 
-// _tmp_12: '=' annotated_rhs
+// _tmp_11: '=' annotated_rhs
 static void *
-_tmp_12_rule(Parser *p)
+_tmp_11_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25648,7 +25605,7 @@ _tmp_12_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_12[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
+        D(fprintf(stderr, "%*c> _tmp_11[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
         Token * _literal;
         expr_ty d;
         if (
@@ -25657,7 +25614,7 @@ _tmp_12_rule(Parser *p)
             (d = annotated_rhs_rule(p))  // annotated_rhs
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_12[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
+            D(fprintf(stderr, "%*c+ _tmp_11[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
             _res = d;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -25667,7 +25624,7 @@ _tmp_12_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_12[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_11[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'=' annotated_rhs"));
     }
     _res = NULL;
@@ -25676,9 +25633,9 @@ _tmp_12_rule(Parser *p)
     return _res;
 }
 
-// _tmp_13: '(' single_target ')' | single_subscript_attribute_target
+// _tmp_12: '(' single_target ')' | single_subscript_attribute_target
 static void *
-_tmp_13_rule(Parser *p)
+_tmp_12_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25694,7 +25651,7 @@ _tmp_13_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_13[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' single_target ')'"));
+        D(fprintf(stderr, "%*c> _tmp_12[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' single_target ')'"));
         Token * _literal;
         Token * _literal_1;
         expr_ty b;
@@ -25706,7 +25663,7 @@ _tmp_13_rule(Parser *p)
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_13[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' single_target ')'"));
+            D(fprintf(stderr, "%*c+ _tmp_12[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' single_target ')'"));
             _res = b;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -25716,7 +25673,7 @@ _tmp_13_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_13[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_12[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'(' single_target ')'"));
     }
     { // single_subscript_attribute_target
@@ -25724,18 +25681,18 @@ _tmp_13_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_13[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "single_subscript_attribute_target"));
+        D(fprintf(stderr, "%*c> _tmp_12[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "single_subscript_attribute_target"));
         expr_ty single_subscript_attribute_target_var;
         if (
             (single_subscript_attribute_target_var = single_subscript_attribute_target_rule(p))  // single_subscript_attribute_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_13[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "single_subscript_attribute_target"));
+            D(fprintf(stderr, "%*c+ _tmp_12[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "single_subscript_attribute_target"));
             _res = single_subscript_attribute_target_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_13[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_12[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "single_subscript_attribute_target"));
     }
     _res = NULL;
@@ -25744,9 +25701,9 @@ _tmp_13_rule(Parser *p)
     return _res;
 }
 
-// _tmp_14: '=' annotated_rhs
+// _tmp_13: '=' annotated_rhs
 static void *
-_tmp_14_rule(Parser *p)
+_tmp_13_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25762,7 +25719,7 @@ _tmp_14_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_14[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
+        D(fprintf(stderr, "%*c> _tmp_13[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
         Token * _literal;
         expr_ty d;
         if (
@@ -25771,7 +25728,7 @@ _tmp_14_rule(Parser *p)
             (d = annotated_rhs_rule(p))  // annotated_rhs
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_14[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
+            D(fprintf(stderr, "%*c+ _tmp_13[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'=' annotated_rhs"));
             _res = d;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -25781,7 +25738,7 @@ _tmp_14_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_14[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_13[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'=' annotated_rhs"));
     }
     _res = NULL;
@@ -25790,9 +25747,9 @@ _tmp_14_rule(Parser *p)
     return _res;
 }
 
-// _loop1_15: (star_targets '=')
+// _loop1_14: (star_targets '=')
 static asdl_seq *
-_loop1_15_rule(Parser *p)
+_loop1_14_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25817,13 +25774,13 @@ _loop1_15_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_15[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(star_targets '=')"));
-        void *_tmp_247_var;
+        D(fprintf(stderr, "%*c> _loop1_14[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(star_targets '=')"));
+        void *_tmp_248_var;
         while (
-            (_tmp_247_var = _tmp_247_rule(p))  // star_targets '='
+            (_tmp_248_var = _tmp_248_rule(p))  // star_targets '='
         )
         {
-            _res = _tmp_247_var;
+            _res = _tmp_248_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -25840,7 +25797,7 @@ _loop1_15_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_15[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_14[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(star_targets '=')"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -25862,9 +25819,9 @@ _loop1_15_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_16: yield_expr | star_expressions
+// _tmp_15: yield_expr | star_expressions
 static void *
-_tmp_16_rule(Parser *p)
+_tmp_15_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25880,18 +25837,18 @@ _tmp_16_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_16[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_15[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_16[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_15[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_16[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_15[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -25899,18 +25856,18 @@ _tmp_16_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_16[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_15[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_16[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_15[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_16[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_15[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -25919,9 +25876,9 @@ _tmp_16_rule(Parser *p)
     return _res;
 }
 
-// _tmp_17: yield_expr | star_expressions
+// _tmp_16: yield_expr | star_expressions
 static void *
-_tmp_17_rule(Parser *p)
+_tmp_16_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25937,18 +25894,18 @@ _tmp_17_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_17[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_16[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_17[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_16[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_17[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_16[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -25956,18 +25913,18 @@ _tmp_17_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_17[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_16[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_17[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_16[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_17[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_16[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -25976,9 +25933,9 @@ _tmp_17_rule(Parser *p)
     return _res;
 }
 
-// _tmp_18: 'from' expression
+// _tmp_17: 'from' expression
 static void *
-_tmp_18_rule(Parser *p)
+_tmp_17_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -25994,7 +25951,7 @@ _tmp_18_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_18[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'from' expression"));
+        D(fprintf(stderr, "%*c> _tmp_17[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'from' expression"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -26003,7 +25960,7 @@ _tmp_18_rule(Parser *p)
             (z = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_18[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'from' expression"));
+            D(fprintf(stderr, "%*c+ _tmp_17[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'from' expression"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -26013,7 +25970,7 @@ _tmp_18_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_18[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_17[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'from' expression"));
     }
     _res = NULL;
@@ -26022,9 +25979,9 @@ _tmp_18_rule(Parser *p)
     return _res;
 }
 
-// _loop0_20: ',' NAME
+// _loop0_19: ',' NAME
 static asdl_seq *
-_loop0_20_rule(Parser *p)
+_loop0_19_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26049,7 +26006,7 @@ _loop0_20_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_20[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' NAME"));
+        D(fprintf(stderr, "%*c> _loop0_19[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' NAME"));
         Token * _literal;
         expr_ty elem;
         while (
@@ -26081,7 +26038,7 @@ _loop0_20_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_20[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_19[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' NAME"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -26098,9 +26055,9 @@ _loop0_20_rule(Parser *p)
     return _seq;
 }
 
-// _gather_19: NAME _loop0_20
+// _gather_18: NAME _loop0_19
 static asdl_seq *
-_gather_19_rule(Parser *p)
+_gather_18_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26111,27 +26068,27 @@ _gather_19_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // NAME _loop0_20
+    { // NAME _loop0_19
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_19[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME _loop0_20"));
+        D(fprintf(stderr, "%*c> _gather_18[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME _loop0_19"));
         expr_ty elem;
         asdl_seq * seq;
         if (
             (elem = _PyPegen_name_token(p))  // NAME
             &&
-            (seq = _loop0_20_rule(p))  // _loop0_20
+            (seq = _loop0_19_rule(p))  // _loop0_19
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_19[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME _loop0_20"));
+            D(fprintf(stderr, "%*c+ _gather_18[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME _loop0_19"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_19[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME _loop0_20"));
+        D(fprintf(stderr, "%*c%s _gather_18[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME _loop0_19"));
     }
     _res = NULL;
   done:
@@ -26139,9 +26096,9 @@ _gather_19_rule(Parser *p)
     return _res;
 }
 
-// _loop0_22: ',' NAME
+// _loop0_21: ',' NAME
 static asdl_seq *
-_loop0_22_rule(Parser *p)
+_loop0_21_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26166,7 +26123,7 @@ _loop0_22_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_22[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' NAME"));
+        D(fprintf(stderr, "%*c> _loop0_21[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' NAME"));
         Token * _literal;
         expr_ty elem;
         while (
@@ -26198,7 +26155,7 @@ _loop0_22_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_22[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_21[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' NAME"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -26215,9 +26172,9 @@ _loop0_22_rule(Parser *p)
     return _seq;
 }
 
-// _gather_21: NAME _loop0_22
+// _gather_20: NAME _loop0_21
 static asdl_seq *
-_gather_21_rule(Parser *p)
+_gather_20_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26228,27 +26185,27 @@ _gather_21_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // NAME _loop0_22
+    { // NAME _loop0_21
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_21[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME _loop0_22"));
+        D(fprintf(stderr, "%*c> _gather_20[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME _loop0_21"));
         expr_ty elem;
         asdl_seq * seq;
         if (
             (elem = _PyPegen_name_token(p))  // NAME
             &&
-            (seq = _loop0_22_rule(p))  // _loop0_22
+            (seq = _loop0_21_rule(p))  // _loop0_21
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_21[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME _loop0_22"));
+            D(fprintf(stderr, "%*c+ _gather_20[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME _loop0_21"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_21[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME _loop0_22"));
+        D(fprintf(stderr, "%*c%s _gather_20[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME _loop0_21"));
     }
     _res = NULL;
   done:
@@ -26256,9 +26213,9 @@ _gather_21_rule(Parser *p)
     return _res;
 }
 
-// _tmp_23: ';' | NEWLINE
+// _tmp_22: ';' | NEWLINE
 static void *
-_tmp_23_rule(Parser *p)
+_tmp_22_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26274,18 +26231,18 @@ _tmp_23_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_23[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "';'"));
+        D(fprintf(stderr, "%*c> _tmp_22[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "';'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 13))  // token=';'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_23[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "';'"));
+            D(fprintf(stderr, "%*c+ _tmp_22[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "';'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_23[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_22[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "';'"));
     }
     { // NEWLINE
@@ -26293,18 +26250,18 @@ _tmp_23_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_23[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
+        D(fprintf(stderr, "%*c> _tmp_22[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
         Token * newline_var;
         if (
             (newline_var = _PyPegen_expect_token(p, NEWLINE))  // token='NEWLINE'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_23[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
+            D(fprintf(stderr, "%*c+ _tmp_22[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
             _res = newline_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_23[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_22[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NEWLINE"));
     }
     _res = NULL;
@@ -26313,9 +26270,9 @@ _tmp_23_rule(Parser *p)
     return _res;
 }
 
-// _tmp_24: ',' expression
+// _tmp_23: ',' expression
 static void *
-_tmp_24_rule(Parser *p)
+_tmp_23_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26331,7 +26288,7 @@ _tmp_24_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_24[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' expression"));
+        D(fprintf(stderr, "%*c> _tmp_23[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' expression"));
         Token * _literal;
         expr_ty z;
         if (
@@ -26340,7 +26297,7 @@ _tmp_24_rule(Parser *p)
             (z = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_24[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' expression"));
+            D(fprintf(stderr, "%*c+ _tmp_23[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' expression"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -26350,7 +26307,7 @@ _tmp_24_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_24[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_23[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' expression"));
     }
     _res = NULL;
@@ -26359,9 +26316,9 @@ _tmp_24_rule(Parser *p)
     return _res;
 }
 
-// _loop0_25: ('.' | '...')
+// _loop0_24: ('.' | '...')
 static asdl_seq *
-_loop0_25_rule(Parser *p)
+_loop0_24_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26386,13 +26343,13 @@ _loop0_25_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_25[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('.' | '...')"));
-        void *_tmp_248_var;
+        D(fprintf(stderr, "%*c> _loop0_24[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('.' | '...')"));
+        void *_tmp_249_var;
         while (
-            (_tmp_248_var = _tmp_248_rule(p))  // '.' | '...'
+            (_tmp_249_var = _tmp_249_rule(p))  // '.' | '...'
         )
         {
-            _res = _tmp_248_var;
+            _res = _tmp_249_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -26409,7 +26366,7 @@ _loop0_25_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_25[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_24[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "('.' | '...')"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -26426,9 +26383,9 @@ _loop0_25_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_26: ('.' | '...')
+// _loop1_25: ('.' | '...')
 static asdl_seq *
-_loop1_26_rule(Parser *p)
+_loop1_25_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26453,13 +26410,13 @@ _loop1_26_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_26[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('.' | '...')"));
-        void *_tmp_249_var;
+        D(fprintf(stderr, "%*c> _loop1_25[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('.' | '...')"));
+        void *_tmp_250_var;
         while (
-            (_tmp_249_var = _tmp_249_rule(p))  // '.' | '...'
+            (_tmp_250_var = _tmp_250_rule(p))  // '.' | '...'
         )
         {
-            _res = _tmp_249_var;
+            _res = _tmp_250_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -26476,7 +26433,7 @@ _loop1_26_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_26[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_25[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "('.' | '...')"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -26498,9 +26455,9 @@ _loop1_26_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_28: ',' import_from_as_name
+// _loop0_27: ',' import_from_as_name
 static asdl_seq *
-_loop0_28_rule(Parser *p)
+_loop0_27_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26525,7 +26482,7 @@ _loop0_28_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_28[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' import_from_as_name"));
+        D(fprintf(stderr, "%*c> _loop0_27[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' import_from_as_name"));
         Token * _literal;
         alias_ty elem;
         while (
@@ -26557,7 +26514,7 @@ _loop0_28_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_28[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_27[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' import_from_as_name"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -26574,9 +26531,9 @@ _loop0_28_rule(Parser *p)
     return _seq;
 }
 
-// _gather_27: import_from_as_name _loop0_28
+// _gather_26: import_from_as_name _loop0_27
 static asdl_seq *
-_gather_27_rule(Parser *p)
+_gather_26_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26587,27 +26544,27 @@ _gather_27_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // import_from_as_name _loop0_28
+    { // import_from_as_name _loop0_27
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_27[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "import_from_as_name _loop0_28"));
+        D(fprintf(stderr, "%*c> _gather_26[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "import_from_as_name _loop0_27"));
         alias_ty elem;
         asdl_seq * seq;
         if (
             (elem = import_from_as_name_rule(p))  // import_from_as_name
             &&
-            (seq = _loop0_28_rule(p))  // _loop0_28
+            (seq = _loop0_27_rule(p))  // _loop0_27
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_27[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "import_from_as_name _loop0_28"));
+            D(fprintf(stderr, "%*c+ _gather_26[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "import_from_as_name _loop0_27"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_27[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "import_from_as_name _loop0_28"));
+        D(fprintf(stderr, "%*c%s _gather_26[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "import_from_as_name _loop0_27"));
     }
     _res = NULL;
   done:
@@ -26615,9 +26572,9 @@ _gather_27_rule(Parser *p)
     return _res;
 }
 
-// _tmp_29: 'as' NAME
+// _tmp_28: 'as' NAME
 static void *
-_tmp_29_rule(Parser *p)
+_tmp_28_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26633,7 +26590,7 @@ _tmp_29_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_29[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_28[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -26642,7 +26599,7 @@ _tmp_29_rule(Parser *p)
             (z = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_29[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_28[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -26652,7 +26609,7 @@ _tmp_29_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_29[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_28[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -26661,9 +26618,9 @@ _tmp_29_rule(Parser *p)
     return _res;
 }
 
-// _loop0_31: ',' dotted_as_name
+// _loop0_30: ',' dotted_as_name
 static asdl_seq *
-_loop0_31_rule(Parser *p)
+_loop0_30_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26688,7 +26645,7 @@ _loop0_31_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_31[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' dotted_as_name"));
+        D(fprintf(stderr, "%*c> _loop0_30[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' dotted_as_name"));
         Token * _literal;
         alias_ty elem;
         while (
@@ -26720,7 +26677,7 @@ _loop0_31_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_31[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_30[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' dotted_as_name"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -26737,9 +26694,9 @@ _loop0_31_rule(Parser *p)
     return _seq;
 }
 
-// _gather_30: dotted_as_name _loop0_31
+// _gather_29: dotted_as_name _loop0_30
 static asdl_seq *
-_gather_30_rule(Parser *p)
+_gather_29_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26750,27 +26707,27 @@ _gather_30_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // dotted_as_name _loop0_31
+    { // dotted_as_name _loop0_30
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_30[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dotted_as_name _loop0_31"));
+        D(fprintf(stderr, "%*c> _gather_29[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dotted_as_name _loop0_30"));
         alias_ty elem;
         asdl_seq * seq;
         if (
             (elem = dotted_as_name_rule(p))  // dotted_as_name
             &&
-            (seq = _loop0_31_rule(p))  // _loop0_31
+            (seq = _loop0_30_rule(p))  // _loop0_30
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_30[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dotted_as_name _loop0_31"));
+            D(fprintf(stderr, "%*c+ _gather_29[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dotted_as_name _loop0_30"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_30[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "dotted_as_name _loop0_31"));
+        D(fprintf(stderr, "%*c%s _gather_29[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "dotted_as_name _loop0_30"));
     }
     _res = NULL;
   done:
@@ -26778,9 +26735,9 @@ _gather_30_rule(Parser *p)
     return _res;
 }
 
-// _tmp_32: 'as' NAME
+// _tmp_31: 'as' NAME
 static void *
-_tmp_32_rule(Parser *p)
+_tmp_31_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26796,7 +26753,7 @@ _tmp_32_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_32[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_31[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -26805,7 +26762,7 @@ _tmp_32_rule(Parser *p)
             (z = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_32[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_31[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -26815,7 +26772,7 @@ _tmp_32_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_32[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_31[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -26824,9 +26781,9 @@ _tmp_32_rule(Parser *p)
     return _res;
 }
 
-// _loop1_33: ('@' named_expression NEWLINE)
+// _loop1_32: ('@' named_expression NEWLINE)
 static asdl_seq *
-_loop1_33_rule(Parser *p)
+_loop1_32_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26851,13 +26808,13 @@ _loop1_33_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_33[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('@' named_expression NEWLINE)"));
-        void *_tmp_250_var;
+        D(fprintf(stderr, "%*c> _loop1_32[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('@' named_expression NEWLINE)"));
+        void *_tmp_251_var;
         while (
-            (_tmp_250_var = _tmp_250_rule(p))  // '@' named_expression NEWLINE
+            (_tmp_251_var = _tmp_251_rule(p))  // '@' named_expression NEWLINE
         )
         {
-            _res = _tmp_250_var;
+            _res = _tmp_251_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -26874,7 +26831,7 @@ _loop1_33_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_33[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_32[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "('@' named_expression NEWLINE)"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -26896,9 +26853,9 @@ _loop1_33_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_34: '(' arguments? ')'
+// _tmp_33: '(' arguments? ')'
 static void *
-_tmp_34_rule(Parser *p)
+_tmp_33_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26914,7 +26871,7 @@ _tmp_34_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_34[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
+        D(fprintf(stderr, "%*c> _tmp_33[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
         Token * _literal;
         Token * _literal_1;
         void *z;
@@ -26926,7 +26883,7 @@ _tmp_34_rule(Parser *p)
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_34[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
+            D(fprintf(stderr, "%*c+ _tmp_33[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -26936,7 +26893,7 @@ _tmp_34_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_34[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_33[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'(' arguments? ')'"));
     }
     _res = NULL;
@@ -26945,9 +26902,9 @@ _tmp_34_rule(Parser *p)
     return _res;
 }
 
-// _tmp_35: '->' expression
+// _tmp_34: '->' expression
 static void *
-_tmp_35_rule(Parser *p)
+_tmp_34_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -26963,7 +26920,7 @@ _tmp_35_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_35[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'->' expression"));
+        D(fprintf(stderr, "%*c> _tmp_34[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'->' expression"));
         Token * _literal;
         expr_ty z;
         if (
@@ -26972,7 +26929,7 @@ _tmp_35_rule(Parser *p)
             (z = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_35[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'->' expression"));
+            D(fprintf(stderr, "%*c+ _tmp_34[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'->' expression"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -26982,7 +26939,7 @@ _tmp_35_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_35[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_34[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'->' expression"));
     }
     _res = NULL;
@@ -26991,9 +26948,9 @@ _tmp_35_rule(Parser *p)
     return _res;
 }
 
-// _tmp_36: '->' expression
+// _tmp_35: '->' expression
 static void *
-_tmp_36_rule(Parser *p)
+_tmp_35_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27009,7 +26966,7 @@ _tmp_36_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_36[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'->' expression"));
+        D(fprintf(stderr, "%*c> _tmp_35[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'->' expression"));
         Token * _literal;
         expr_ty z;
         if (
@@ -27018,7 +26975,7 @@ _tmp_36_rule(Parser *p)
             (z = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_36[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'->' expression"));
+            D(fprintf(stderr, "%*c+ _tmp_35[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'->' expression"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -27028,7 +26985,7 @@ _tmp_36_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_36[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_35[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'->' expression"));
     }
     _res = NULL;
@@ -27037,9 +26994,9 @@ _tmp_36_rule(Parser *p)
     return _res;
 }
 
-// _loop0_37: param_no_default
+// _loop0_36: param_no_default
 static asdl_seq *
-_loop0_37_rule(Parser *p)
+_loop0_36_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27064,7 +27021,7 @@ _loop0_37_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_37[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_36[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -27087,7 +27044,7 @@ _loop0_37_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_37[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_36[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27104,9 +27061,9 @@ _loop0_37_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_38: param_with_default
+// _loop0_37: param_with_default
 static asdl_seq *
-_loop0_38_rule(Parser *p)
+_loop0_37_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27131,7 +27088,7 @@ _loop0_38_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_38[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop0_37[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -27154,7 +27111,7 @@ _loop0_38_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_38[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_37[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27171,9 +27128,9 @@ _loop0_38_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_39: param_with_default
+// _loop0_38: param_with_default
 static asdl_seq *
-_loop0_39_rule(Parser *p)
+_loop0_38_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27198,7 +27155,7 @@ _loop0_39_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_39[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop0_38[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -27221,7 +27178,7 @@ _loop0_39_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_39[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_38[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27238,9 +27195,9 @@ _loop0_39_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_40: param_no_default
+// _loop1_39: param_no_default
 static asdl_seq *
-_loop1_40_rule(Parser *p)
+_loop1_39_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27265,7 +27222,7 @@ _loop1_40_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_40[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop1_39[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -27288,7 +27245,7 @@ _loop1_40_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_40[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_39[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -27310,9 +27267,9 @@ _loop1_40_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_41: param_with_default
+// _loop0_40: param_with_default
 static asdl_seq *
-_loop0_41_rule(Parser *p)
+_loop0_40_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27337,7 +27294,7 @@ _loop0_41_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_41[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop0_40[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -27360,7 +27317,7 @@ _loop0_41_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_41[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_40[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27377,9 +27334,9 @@ _loop0_41_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_42: param_with_default
+// _loop1_41: param_with_default
 static asdl_seq *
-_loop1_42_rule(Parser *p)
+_loop1_41_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27404,7 +27361,7 @@ _loop1_42_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_42[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_41[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -27427,7 +27384,7 @@ _loop1_42_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_42[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_41[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -27449,9 +27406,9 @@ _loop1_42_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_43: param_no_default
+// _loop1_42: param_no_default
 static asdl_seq *
-_loop1_43_rule(Parser *p)
+_loop1_42_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27476,7 +27433,7 @@ _loop1_43_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_43[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop1_42[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -27499,7 +27456,7 @@ _loop1_43_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_43[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_42[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -27521,9 +27478,9 @@ _loop1_43_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_44: param_no_default
+// _loop1_43: param_no_default
 static asdl_seq *
-_loop1_44_rule(Parser *p)
+_loop1_43_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27548,7 +27505,7 @@ _loop1_44_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_44[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop1_43[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -27571,7 +27528,7 @@ _loop1_44_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_44[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_43[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -27593,9 +27550,9 @@ _loop1_44_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_45: param_no_default
+// _loop0_44: param_no_default
 static asdl_seq *
-_loop0_45_rule(Parser *p)
+_loop0_44_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27620,7 +27577,7 @@ _loop0_45_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_45[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_44[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -27643,7 +27600,7 @@ _loop0_45_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_45[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_44[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27660,9 +27617,9 @@ _loop0_45_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_46: param_with_default
+// _loop1_45: param_with_default
 static asdl_seq *
-_loop1_46_rule(Parser *p)
+_loop1_45_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27687,7 +27644,7 @@ _loop1_46_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_46[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_45[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -27710,7 +27667,7 @@ _loop1_46_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_46[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_45[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -27732,9 +27689,9 @@ _loop1_46_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_47: param_no_default
+// _loop0_46: param_no_default
 static asdl_seq *
-_loop0_47_rule(Parser *p)
+_loop0_46_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27759,7 +27716,7 @@ _loop0_47_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_47[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_46[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -27782,7 +27739,7 @@ _loop0_47_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_47[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_46[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27799,9 +27756,9 @@ _loop0_47_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_48: param_with_default
+// _loop1_47: param_with_default
 static asdl_seq *
-_loop1_48_rule(Parser *p)
+_loop1_47_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27826,7 +27783,7 @@ _loop1_48_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_48[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_47[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -27849,7 +27806,7 @@ _loop1_48_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_48[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_47[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -27871,9 +27828,9 @@ _loop1_48_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_49: param_maybe_default
+// _loop0_48: param_maybe_default
 static asdl_seq *
-_loop0_49_rule(Parser *p)
+_loop0_48_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27898,7 +27855,7 @@ _loop0_49_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_49[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_48[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -27921,7 +27878,7 @@ _loop0_49_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_49[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_48[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -27938,9 +27895,9 @@ _loop0_49_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_50: param_maybe_default
+// _loop0_49: param_maybe_default
 static asdl_seq *
-_loop0_50_rule(Parser *p)
+_loop0_49_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -27965,7 +27922,7 @@ _loop0_50_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_50[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_49[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -27988,7 +27945,7 @@ _loop0_50_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_50[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_49[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -28005,9 +27962,9 @@ _loop0_50_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_51: param_maybe_default
+// _loop1_50: param_maybe_default
 static asdl_seq *
-_loop1_51_rule(Parser *p)
+_loop1_50_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28032,7 +27989,7 @@ _loop1_51_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_51[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop1_50[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -28055,7 +28012,7 @@ _loop1_51_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_51[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_50[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -28077,9 +28034,9 @@ _loop1_51_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_53: ',' with_item
+// _loop0_52: ',' with_item
 static asdl_seq *
-_loop0_53_rule(Parser *p)
+_loop0_52_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28104,7 +28061,7 @@ _loop0_53_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_53[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
+        D(fprintf(stderr, "%*c> _loop0_52[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
         Token * _literal;
         withitem_ty elem;
         while (
@@ -28136,7 +28093,7 @@ _loop0_53_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_53[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_52[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' with_item"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -28153,9 +28110,9 @@ _loop0_53_rule(Parser *p)
     return _seq;
 }
 
-// _gather_52: with_item _loop0_53
+// _gather_51: with_item _loop0_52
 static asdl_seq *
-_gather_52_rule(Parser *p)
+_gather_51_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28166,27 +28123,27 @@ _gather_52_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // with_item _loop0_53
+    { // with_item _loop0_52
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_52[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_53"));
+        D(fprintf(stderr, "%*c> _gather_51[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_52"));
         withitem_ty elem;
         asdl_seq * seq;
         if (
             (elem = with_item_rule(p))  // with_item
             &&
-            (seq = _loop0_53_rule(p))  // _loop0_53
+            (seq = _loop0_52_rule(p))  // _loop0_52
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_52[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_53"));
+            D(fprintf(stderr, "%*c+ _gather_51[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_52"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_52[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_53"));
+        D(fprintf(stderr, "%*c%s _gather_51[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_52"));
     }
     _res = NULL;
   done:
@@ -28194,9 +28151,9 @@ _gather_52_rule(Parser *p)
     return _res;
 }
 
-// _loop0_55: ',' with_item
+// _loop0_54: ',' with_item
 static asdl_seq *
-_loop0_55_rule(Parser *p)
+_loop0_54_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28221,7 +28178,7 @@ _loop0_55_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_55[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
+        D(fprintf(stderr, "%*c> _loop0_54[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
         Token * _literal;
         withitem_ty elem;
         while (
@@ -28253,7 +28210,7 @@ _loop0_55_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_55[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_54[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' with_item"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -28270,9 +28227,9 @@ _loop0_55_rule(Parser *p)
     return _seq;
 }
 
-// _gather_54: with_item _loop0_55
+// _gather_53: with_item _loop0_54
 static asdl_seq *
-_gather_54_rule(Parser *p)
+_gather_53_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28283,27 +28240,27 @@ _gather_54_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // with_item _loop0_55
+    { // with_item _loop0_54
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_54[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_55"));
+        D(fprintf(stderr, "%*c> _gather_53[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_54"));
         withitem_ty elem;
         asdl_seq * seq;
         if (
             (elem = with_item_rule(p))  // with_item
             &&
-            (seq = _loop0_55_rule(p))  // _loop0_55
+            (seq = _loop0_54_rule(p))  // _loop0_54
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_54[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_55"));
+            D(fprintf(stderr, "%*c+ _gather_53[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_54"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_54[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_55"));
+        D(fprintf(stderr, "%*c%s _gather_53[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_54"));
     }
     _res = NULL;
   done:
@@ -28311,9 +28268,9 @@ _gather_54_rule(Parser *p)
     return _res;
 }
 
-// _loop0_57: ',' with_item
+// _loop0_56: ',' with_item
 static asdl_seq *
-_loop0_57_rule(Parser *p)
+_loop0_56_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28338,7 +28295,7 @@ _loop0_57_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_57[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
+        D(fprintf(stderr, "%*c> _loop0_56[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
         Token * _literal;
         withitem_ty elem;
         while (
@@ -28370,7 +28327,7 @@ _loop0_57_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_57[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_56[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' with_item"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -28387,9 +28344,9 @@ _loop0_57_rule(Parser *p)
     return _seq;
 }
 
-// _gather_56: with_item _loop0_57
+// _gather_55: with_item _loop0_56
 static asdl_seq *
-_gather_56_rule(Parser *p)
+_gather_55_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28400,27 +28357,27 @@ _gather_56_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // with_item _loop0_57
+    { // with_item _loop0_56
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_56[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_57"));
+        D(fprintf(stderr, "%*c> _gather_55[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_56"));
         withitem_ty elem;
         asdl_seq * seq;
         if (
             (elem = with_item_rule(p))  // with_item
             &&
-            (seq = _loop0_57_rule(p))  // _loop0_57
+            (seq = _loop0_56_rule(p))  // _loop0_56
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_56[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_57"));
+            D(fprintf(stderr, "%*c+ _gather_55[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_56"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_56[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_57"));
+        D(fprintf(stderr, "%*c%s _gather_55[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_56"));
     }
     _res = NULL;
   done:
@@ -28428,9 +28385,9 @@ _gather_56_rule(Parser *p)
     return _res;
 }
 
-// _loop0_59: ',' with_item
+// _loop0_58: ',' with_item
 static asdl_seq *
-_loop0_59_rule(Parser *p)
+_loop0_58_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28455,7 +28412,7 @@ _loop0_59_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_59[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
+        D(fprintf(stderr, "%*c> _loop0_58[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' with_item"));
         Token * _literal;
         withitem_ty elem;
         while (
@@ -28487,7 +28444,7 @@ _loop0_59_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_59[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_58[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' with_item"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -28504,9 +28461,9 @@ _loop0_59_rule(Parser *p)
     return _seq;
 }
 
-// _gather_58: with_item _loop0_59
+// _gather_57: with_item _loop0_58
 static asdl_seq *
-_gather_58_rule(Parser *p)
+_gather_57_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28517,27 +28474,27 @@ _gather_58_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // with_item _loop0_59
+    { // with_item _loop0_58
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_58[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_59"));
+        D(fprintf(stderr, "%*c> _gather_57[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "with_item _loop0_58"));
         withitem_ty elem;
         asdl_seq * seq;
         if (
             (elem = with_item_rule(p))  // with_item
             &&
-            (seq = _loop0_59_rule(p))  // _loop0_59
+            (seq = _loop0_58_rule(p))  // _loop0_58
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_58[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_59"));
+            D(fprintf(stderr, "%*c+ _gather_57[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "with_item _loop0_58"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_58[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_59"));
+        D(fprintf(stderr, "%*c%s _gather_57[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "with_item _loop0_58"));
     }
     _res = NULL;
   done:
@@ -28545,9 +28502,9 @@ _gather_58_rule(Parser *p)
     return _res;
 }
 
-// _tmp_60: ',' | ')' | ':'
+// _tmp_59: ',' | ')' | ':'
 static void *
-_tmp_60_rule(Parser *p)
+_tmp_59_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28563,18 +28520,18 @@ _tmp_60_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_60[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_59[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_60[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_59[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_60[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_59[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     { // ')'
@@ -28582,18 +28539,18 @@ _tmp_60_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_60[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
+        D(fprintf(stderr, "%*c> _tmp_59[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_60[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
+            D(fprintf(stderr, "%*c+ _tmp_59[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_60[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_59[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "')'"));
     }
     { // ':'
@@ -28601,18 +28558,18 @@ _tmp_60_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_60[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_59[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_60[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_59[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_60[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_59[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     _res = NULL;
@@ -28621,9 +28578,9 @@ _tmp_60_rule(Parser *p)
     return _res;
 }
 
-// _loop1_61: except_block
+// _loop1_60: except_block
 static asdl_seq *
-_loop1_61_rule(Parser *p)
+_loop1_60_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28648,7 +28605,7 @@ _loop1_61_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_61[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_block"));
+        D(fprintf(stderr, "%*c> _loop1_60[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_block"));
         excepthandler_ty except_block_var;
         while (
             (except_block_var = except_block_rule(p))  // except_block
@@ -28671,7 +28628,7 @@ _loop1_61_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_61[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_60[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "except_block"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -28693,9 +28650,9 @@ _loop1_61_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_62: except_star_block
+// _loop1_61: except_star_block
 static asdl_seq *
-_loop1_62_rule(Parser *p)
+_loop1_61_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28720,7 +28677,7 @@ _loop1_62_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_62[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_star_block"));
+        D(fprintf(stderr, "%*c> _loop1_61[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_star_block"));
         excepthandler_ty except_star_block_var;
         while (
             (except_star_block_var = except_star_block_rule(p))  // except_star_block
@@ -28743,7 +28700,7 @@ _loop1_62_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_62[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_61[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "except_star_block"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -28765,9 +28722,9 @@ _loop1_62_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_63: 'as' NAME
+// _tmp_62: 'as' NAME
 static void *
-_tmp_63_rule(Parser *p)
+_tmp_62_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28783,7 +28740,7 @@ _tmp_63_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_63[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_62[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -28792,7 +28749,7 @@ _tmp_63_rule(Parser *p)
             (z = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_63[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_62[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -28802,7 +28759,7 @@ _tmp_63_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_63[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_62[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -28811,9 +28768,9 @@ _tmp_63_rule(Parser *p)
     return _res;
 }
 
-// _tmp_64: 'as' NAME
+// _tmp_63: 'as' NAME
 static void *
-_tmp_64_rule(Parser *p)
+_tmp_63_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28829,7 +28786,7 @@ _tmp_64_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_64[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_63[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -28838,7 +28795,7 @@ _tmp_64_rule(Parser *p)
             (z = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_64[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_63[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -28848,7 +28805,7 @@ _tmp_64_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_64[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_63[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -28857,9 +28814,9 @@ _tmp_64_rule(Parser *p)
     return _res;
 }
 
-// _loop1_65: case_block
+// _loop1_64: case_block
 static asdl_seq *
-_loop1_65_rule(Parser *p)
+_loop1_64_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28884,7 +28841,7 @@ _loop1_65_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_65[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "case_block"));
+        D(fprintf(stderr, "%*c> _loop1_64[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "case_block"));
         match_case_ty case_block_var;
         while (
             (case_block_var = case_block_rule(p))  // case_block
@@ -28907,7 +28864,7 @@ _loop1_65_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_65[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_64[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "case_block"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -28929,9 +28886,9 @@ _loop1_65_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_67: '|' closed_pattern
+// _loop0_66: '|' closed_pattern
 static asdl_seq *
-_loop0_67_rule(Parser *p)
+_loop0_66_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -28956,7 +28913,7 @@ _loop0_67_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_67[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'|' closed_pattern"));
+        D(fprintf(stderr, "%*c> _loop0_66[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'|' closed_pattern"));
         Token * _literal;
         pattern_ty elem;
         while (
@@ -28988,7 +28945,7 @@ _loop0_67_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_67[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_66[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'|' closed_pattern"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -29005,9 +28962,9 @@ _loop0_67_rule(Parser *p)
     return _seq;
 }
 
-// _gather_66: closed_pattern _loop0_67
+// _gather_65: closed_pattern _loop0_66
 static asdl_seq *
-_gather_66_rule(Parser *p)
+_gather_65_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29018,27 +28975,27 @@ _gather_66_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // closed_pattern _loop0_67
+    { // closed_pattern _loop0_66
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_66[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "closed_pattern _loop0_67"));
+        D(fprintf(stderr, "%*c> _gather_65[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "closed_pattern _loop0_66"));
         pattern_ty elem;
         asdl_seq * seq;
         if (
             (elem = closed_pattern_rule(p))  // closed_pattern
             &&
-            (seq = _loop0_67_rule(p))  // _loop0_67
+            (seq = _loop0_66_rule(p))  // _loop0_66
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_66[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "closed_pattern _loop0_67"));
+            D(fprintf(stderr, "%*c+ _gather_65[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "closed_pattern _loop0_66"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_66[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "closed_pattern _loop0_67"));
+        D(fprintf(stderr, "%*c%s _gather_65[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "closed_pattern _loop0_66"));
     }
     _res = NULL;
   done:
@@ -29046,9 +29003,9 @@ _gather_66_rule(Parser *p)
     return _res;
 }
 
-// _tmp_68: '+' | '-'
+// _tmp_67: '+' | '-'
 static void *
-_tmp_68_rule(Parser *p)
+_tmp_67_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29064,18 +29021,18 @@ _tmp_68_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_68[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'+'"));
+        D(fprintf(stderr, "%*c> _tmp_67[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'+'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 14))  // token='+'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_68[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'+'"));
+            D(fprintf(stderr, "%*c+ _tmp_67[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'+'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_68[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_67[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'+'"));
     }
     { // '-'
@@ -29083,18 +29040,18 @@ _tmp_68_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_68[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'-'"));
+        D(fprintf(stderr, "%*c> _tmp_67[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'-'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 15))  // token='-'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_68[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'-'"));
+            D(fprintf(stderr, "%*c+ _tmp_67[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'-'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_68[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_67[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'-'"));
     }
     _res = NULL;
@@ -29103,9 +29060,9 @@ _tmp_68_rule(Parser *p)
     return _res;
 }
 
-// _tmp_69: '+' | '-'
+// _tmp_68: '+' | '-'
 static void *
-_tmp_69_rule(Parser *p)
+_tmp_68_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29121,18 +29078,18 @@ _tmp_69_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_69[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'+'"));
+        D(fprintf(stderr, "%*c> _tmp_68[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'+'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 14))  // token='+'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_69[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'+'"));
+            D(fprintf(stderr, "%*c+ _tmp_68[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'+'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_69[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_68[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'+'"));
     }
     { // '-'
@@ -29140,18 +29097,18 @@ _tmp_69_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_69[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'-'"));
+        D(fprintf(stderr, "%*c> _tmp_68[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'-'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 15))  // token='-'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_69[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'-'"));
+            D(fprintf(stderr, "%*c+ _tmp_68[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'-'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_69[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_68[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'-'"));
     }
     _res = NULL;
@@ -29160,9 +29117,9 @@ _tmp_69_rule(Parser *p)
     return _res;
 }
 
-// _tmp_70: '.' | '(' | '='
+// _tmp_69: '.' | '(' | '='
 static void *
-_tmp_70_rule(Parser *p)
+_tmp_69_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29178,18 +29135,18 @@ _tmp_70_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_70[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
+        D(fprintf(stderr, "%*c> _tmp_69[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 23))  // token='.'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_70[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
+            D(fprintf(stderr, "%*c+ _tmp_69[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_70[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_69[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'.'"));
     }
     { // '('
@@ -29197,18 +29154,18 @@ _tmp_70_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_70[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'('"));
+        D(fprintf(stderr, "%*c> _tmp_69[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'('"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_70[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'('"));
+            D(fprintf(stderr, "%*c+ _tmp_69[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'('"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_70[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_69[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'('"));
     }
     { // '='
@@ -29216,18 +29173,18 @@ _tmp_70_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_70[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
+        D(fprintf(stderr, "%*c> _tmp_69[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_70[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
+            D(fprintf(stderr, "%*c+ _tmp_69[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_70[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_69[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'='"));
     }
     _res = NULL;
@@ -29236,9 +29193,9 @@ _tmp_70_rule(Parser *p)
     return _res;
 }
 
-// _tmp_71: '.' | '(' | '='
+// _tmp_70: '.' | '(' | '='
 static void *
-_tmp_71_rule(Parser *p)
+_tmp_70_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29254,18 +29211,18 @@ _tmp_71_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_71[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
+        D(fprintf(stderr, "%*c> _tmp_70[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 23))  // token='.'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_71[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
+            D(fprintf(stderr, "%*c+ _tmp_70[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_71[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_70[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'.'"));
     }
     { // '('
@@ -29273,18 +29230,18 @@ _tmp_71_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_71[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'('"));
+        D(fprintf(stderr, "%*c> _tmp_70[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'('"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_71[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'('"));
+            D(fprintf(stderr, "%*c+ _tmp_70[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'('"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_71[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_70[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'('"));
     }
     { // '='
@@ -29292,18 +29249,18 @@ _tmp_71_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_71[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
+        D(fprintf(stderr, "%*c> _tmp_70[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_71[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
+            D(fprintf(stderr, "%*c+ _tmp_70[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_71[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_70[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'='"));
     }
     _res = NULL;
@@ -29312,9 +29269,9 @@ _tmp_71_rule(Parser *p)
     return _res;
 }
 
-// _loop0_73: ',' maybe_star_pattern
+// _loop0_72: ',' maybe_star_pattern
 static asdl_seq *
-_loop0_73_rule(Parser *p)
+_loop0_72_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29339,7 +29296,7 @@ _loop0_73_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_73[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' maybe_star_pattern"));
+        D(fprintf(stderr, "%*c> _loop0_72[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' maybe_star_pattern"));
         Token * _literal;
         pattern_ty elem;
         while (
@@ -29371,7 +29328,7 @@ _loop0_73_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_73[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_72[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' maybe_star_pattern"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -29388,9 +29345,9 @@ _loop0_73_rule(Parser *p)
     return _seq;
 }
 
-// _gather_72: maybe_star_pattern _loop0_73
+// _gather_71: maybe_star_pattern _loop0_72
 static asdl_seq *
-_gather_72_rule(Parser *p)
+_gather_71_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29401,27 +29358,27 @@ _gather_72_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // maybe_star_pattern _loop0_73
+    { // maybe_star_pattern _loop0_72
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_72[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "maybe_star_pattern _loop0_73"));
+        D(fprintf(stderr, "%*c> _gather_71[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "maybe_star_pattern _loop0_72"));
         pattern_ty elem;
         asdl_seq * seq;
         if (
             (elem = maybe_star_pattern_rule(p))  // maybe_star_pattern
             &&
-            (seq = _loop0_73_rule(p))  // _loop0_73
+            (seq = _loop0_72_rule(p))  // _loop0_72
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_72[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "maybe_star_pattern _loop0_73"));
+            D(fprintf(stderr, "%*c+ _gather_71[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "maybe_star_pattern _loop0_72"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_72[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "maybe_star_pattern _loop0_73"));
+        D(fprintf(stderr, "%*c%s _gather_71[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "maybe_star_pattern _loop0_72"));
     }
     _res = NULL;
   done:
@@ -29429,9 +29386,9 @@ _gather_72_rule(Parser *p)
     return _res;
 }
 
-// _loop0_75: ',' key_value_pattern
+// _loop0_74: ',' key_value_pattern
 static asdl_seq *
-_loop0_75_rule(Parser *p)
+_loop0_74_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29456,7 +29413,7 @@ _loop0_75_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_75[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' key_value_pattern"));
+        D(fprintf(stderr, "%*c> _loop0_74[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' key_value_pattern"));
         Token * _literal;
         KeyPatternPair* elem;
         while (
@@ -29488,7 +29445,7 @@ _loop0_75_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_75[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_74[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' key_value_pattern"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -29505,9 +29462,9 @@ _loop0_75_rule(Parser *p)
     return _seq;
 }
 
-// _gather_74: key_value_pattern _loop0_75
+// _gather_73: key_value_pattern _loop0_74
 static asdl_seq *
-_gather_74_rule(Parser *p)
+_gather_73_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29518,27 +29475,27 @@ _gather_74_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // key_value_pattern _loop0_75
+    { // key_value_pattern _loop0_74
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_74[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "key_value_pattern _loop0_75"));
+        D(fprintf(stderr, "%*c> _gather_73[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "key_value_pattern _loop0_74"));
         KeyPatternPair* elem;
         asdl_seq * seq;
         if (
             (elem = key_value_pattern_rule(p))  // key_value_pattern
             &&
-            (seq = _loop0_75_rule(p))  // _loop0_75
+            (seq = _loop0_74_rule(p))  // _loop0_74
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_74[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "key_value_pattern _loop0_75"));
+            D(fprintf(stderr, "%*c+ _gather_73[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "key_value_pattern _loop0_74"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_74[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "key_value_pattern _loop0_75"));
+        D(fprintf(stderr, "%*c%s _gather_73[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "key_value_pattern _loop0_74"));
     }
     _res = NULL;
   done:
@@ -29546,9 +29503,9 @@ _gather_74_rule(Parser *p)
     return _res;
 }
 
-// _tmp_76: literal_expr | attr
+// _tmp_75: literal_expr | attr
 static void *
-_tmp_76_rule(Parser *p)
+_tmp_75_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29564,18 +29521,18 @@ _tmp_76_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_76[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "literal_expr"));
+        D(fprintf(stderr, "%*c> _tmp_75[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "literal_expr"));
         expr_ty literal_expr_var;
         if (
             (literal_expr_var = literal_expr_rule(p))  // literal_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_76[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "literal_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_75[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "literal_expr"));
             _res = literal_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_76[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_75[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "literal_expr"));
     }
     { // attr
@@ -29583,18 +29540,18 @@ _tmp_76_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_76[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "attr"));
+        D(fprintf(stderr, "%*c> _tmp_75[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "attr"));
         expr_ty attr_var;
         if (
             (attr_var = attr_rule(p))  // attr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_76[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "attr"));
+            D(fprintf(stderr, "%*c+ _tmp_75[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "attr"));
             _res = attr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_76[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_75[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "attr"));
     }
     _res = NULL;
@@ -29603,9 +29560,9 @@ _tmp_76_rule(Parser *p)
     return _res;
 }
 
-// _loop0_78: ',' pattern
+// _loop0_77: ',' pattern
 static asdl_seq *
-_loop0_78_rule(Parser *p)
+_loop0_77_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29630,7 +29587,7 @@ _loop0_78_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_78[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' pattern"));
+        D(fprintf(stderr, "%*c> _loop0_77[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' pattern"));
         Token * _literal;
         pattern_ty elem;
         while (
@@ -29662,7 +29619,7 @@ _loop0_78_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_78[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_77[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' pattern"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -29679,9 +29636,9 @@ _loop0_78_rule(Parser *p)
     return _seq;
 }
 
-// _gather_77: pattern _loop0_78
+// _gather_76: pattern _loop0_77
 static asdl_seq *
-_gather_77_rule(Parser *p)
+_gather_76_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29692,27 +29649,27 @@ _gather_77_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // pattern _loop0_78
+    { // pattern _loop0_77
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_77[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "pattern _loop0_78"));
+        D(fprintf(stderr, "%*c> _gather_76[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "pattern _loop0_77"));
         pattern_ty elem;
         asdl_seq * seq;
         if (
             (elem = pattern_rule(p))  // pattern
             &&
-            (seq = _loop0_78_rule(p))  // _loop0_78
+            (seq = _loop0_77_rule(p))  // _loop0_77
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_77[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "pattern _loop0_78"));
+            D(fprintf(stderr, "%*c+ _gather_76[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "pattern _loop0_77"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_77[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "pattern _loop0_78"));
+        D(fprintf(stderr, "%*c%s _gather_76[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "pattern _loop0_77"));
     }
     _res = NULL;
   done:
@@ -29720,9 +29677,9 @@ _gather_77_rule(Parser *p)
     return _res;
 }
 
-// _loop0_80: ',' keyword_pattern
+// _loop0_79: ',' keyword_pattern
 static asdl_seq *
-_loop0_80_rule(Parser *p)
+_loop0_79_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29747,7 +29704,7 @@ _loop0_80_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_80[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' keyword_pattern"));
+        D(fprintf(stderr, "%*c> _loop0_79[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' keyword_pattern"));
         Token * _literal;
         KeyPatternPair* elem;
         while (
@@ -29779,7 +29736,7 @@ _loop0_80_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_80[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_79[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' keyword_pattern"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -29796,9 +29753,9 @@ _loop0_80_rule(Parser *p)
     return _seq;
 }
 
-// _gather_79: keyword_pattern _loop0_80
+// _gather_78: keyword_pattern _loop0_79
 static asdl_seq *
-_gather_79_rule(Parser *p)
+_gather_78_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29809,27 +29766,27 @@ _gather_79_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // keyword_pattern _loop0_80
+    { // keyword_pattern _loop0_79
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_79[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "keyword_pattern _loop0_80"));
+        D(fprintf(stderr, "%*c> _gather_78[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "keyword_pattern _loop0_79"));
         KeyPatternPair* elem;
         asdl_seq * seq;
         if (
             (elem = keyword_pattern_rule(p))  // keyword_pattern
             &&
-            (seq = _loop0_80_rule(p))  // _loop0_80
+            (seq = _loop0_79_rule(p))  // _loop0_79
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_79[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "keyword_pattern _loop0_80"));
+            D(fprintf(stderr, "%*c+ _gather_78[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "keyword_pattern _loop0_79"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_79[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "keyword_pattern _loop0_80"));
+        D(fprintf(stderr, "%*c%s _gather_78[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "keyword_pattern _loop0_79"));
     }
     _res = NULL;
   done:
@@ -29837,9 +29794,9 @@ _gather_79_rule(Parser *p)
     return _res;
 }
 
-// _loop0_82: ',' type_param
+// _loop0_81: ',' type_param
 static asdl_seq *
-_loop0_82_rule(Parser *p)
+_loop0_81_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29864,7 +29821,7 @@ _loop0_82_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_82[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' type_param"));
+        D(fprintf(stderr, "%*c> _loop0_81[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' type_param"));
         Token * _literal;
         type_param_ty elem;
         while (
@@ -29896,7 +29853,7 @@ _loop0_82_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_82[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_81[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' type_param"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -29913,9 +29870,9 @@ _loop0_82_rule(Parser *p)
     return _seq;
 }
 
-// _gather_81: type_param _loop0_82
+// _gather_80: type_param _loop0_81
 static asdl_seq *
-_gather_81_rule(Parser *p)
+_gather_80_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29926,27 +29883,27 @@ _gather_81_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // type_param _loop0_82
+    { // type_param _loop0_81
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_81[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "type_param _loop0_82"));
+        D(fprintf(stderr, "%*c> _gather_80[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "type_param _loop0_81"));
         type_param_ty elem;
         asdl_seq * seq;
         if (
             (elem = type_param_rule(p))  // type_param
             &&
-            (seq = _loop0_82_rule(p))  // _loop0_82
+            (seq = _loop0_81_rule(p))  // _loop0_81
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_81[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "type_param _loop0_82"));
+            D(fprintf(stderr, "%*c+ _gather_80[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "type_param _loop0_81"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_81[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "type_param _loop0_82"));
+        D(fprintf(stderr, "%*c%s _gather_80[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "type_param _loop0_81"));
     }
     _res = NULL;
   done:
@@ -29954,9 +29911,9 @@ _gather_81_rule(Parser *p)
     return _res;
 }
 
-// _loop1_83: (',' expression)
+// _loop1_82: (',' expression)
 static asdl_seq *
-_loop1_83_rule(Parser *p)
+_loop1_82_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -29981,13 +29938,13 @@ _loop1_83_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_83[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(',' expression)"));
-        void *_tmp_251_var;
+        D(fprintf(stderr, "%*c> _loop1_82[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(',' expression)"));
+        void *_tmp_252_var;
         while (
-            (_tmp_251_var = _tmp_251_rule(p))  // ',' expression
+            (_tmp_252_var = _tmp_252_rule(p))  // ',' expression
         )
         {
-            _res = _tmp_251_var;
+            _res = _tmp_252_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -30004,7 +29961,7 @@ _loop1_83_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_83[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_82[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(',' expression)"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -30026,9 +29983,9 @@ _loop1_83_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_84: (',' star_expression)
+// _loop1_83: (',' star_expression)
 static asdl_seq *
-_loop1_84_rule(Parser *p)
+_loop1_83_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30053,13 +30010,13 @@ _loop1_84_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_84[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(',' star_expression)"));
-        void *_tmp_252_var;
+        D(fprintf(stderr, "%*c> _loop1_83[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(',' star_expression)"));
+        void *_tmp_253_var;
         while (
-            (_tmp_252_var = _tmp_252_rule(p))  // ',' star_expression
+            (_tmp_253_var = _tmp_253_rule(p))  // ',' star_expression
         )
         {
-            _res = _tmp_252_var;
+            _res = _tmp_253_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -30076,7 +30033,7 @@ _loop1_84_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_84[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_83[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(',' star_expression)"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -30098,9 +30055,9 @@ _loop1_84_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_86: ',' star_named_expression
+// _loop0_85: ',' star_named_expression
 static asdl_seq *
-_loop0_86_rule(Parser *p)
+_loop0_85_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30125,7 +30082,7 @@ _loop0_86_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_86[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_named_expression"));
+        D(fprintf(stderr, "%*c> _loop0_85[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_named_expression"));
         Token * _literal;
         expr_ty elem;
         while (
@@ -30157,7 +30114,7 @@ _loop0_86_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_86[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_85[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' star_named_expression"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -30174,9 +30131,9 @@ _loop0_86_rule(Parser *p)
     return _seq;
 }
 
-// _gather_85: star_named_expression _loop0_86
+// _gather_84: star_named_expression _loop0_85
 static asdl_seq *
-_gather_85_rule(Parser *p)
+_gather_84_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30187,27 +30144,27 @@ _gather_85_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // star_named_expression _loop0_86
+    { // star_named_expression _loop0_85
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_85[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_named_expression _loop0_86"));
+        D(fprintf(stderr, "%*c> _gather_84[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_named_expression _loop0_85"));
         expr_ty elem;
         asdl_seq * seq;
         if (
             (elem = star_named_expression_rule(p))  // star_named_expression
             &&
-            (seq = _loop0_86_rule(p))  // _loop0_86
+            (seq = _loop0_85_rule(p))  // _loop0_85
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_85[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_named_expression _loop0_86"));
+            D(fprintf(stderr, "%*c+ _gather_84[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_named_expression _loop0_85"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_85[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_named_expression _loop0_86"));
+        D(fprintf(stderr, "%*c%s _gather_84[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_named_expression _loop0_85"));
     }
     _res = NULL;
   done:
@@ -30215,9 +30172,9 @@ _gather_85_rule(Parser *p)
     return _res;
 }
 
-// _loop1_87: ('or' conjunction)
+// _loop1_86: ('or' conjunction)
 static asdl_seq *
-_loop1_87_rule(Parser *p)
+_loop1_86_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30242,13 +30199,13 @@ _loop1_87_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_87[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('or' conjunction)"));
-        void *_tmp_253_var;
+        D(fprintf(stderr, "%*c> _loop1_86[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('or' conjunction)"));
+        void *_tmp_254_var;
         while (
-            (_tmp_253_var = _tmp_253_rule(p))  // 'or' conjunction
+            (_tmp_254_var = _tmp_254_rule(p))  // 'or' conjunction
         )
         {
-            _res = _tmp_253_var;
+            _res = _tmp_254_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -30265,7 +30222,7 @@ _loop1_87_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_87[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_86[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "('or' conjunction)"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -30287,9 +30244,9 @@ _loop1_87_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_88: ('and' inversion)
+// _loop1_87: ('and' inversion)
 static asdl_seq *
-_loop1_88_rule(Parser *p)
+_loop1_87_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30314,13 +30271,13 @@ _loop1_88_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_88[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('and' inversion)"));
-        void *_tmp_254_var;
+        D(fprintf(stderr, "%*c> _loop1_87[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('and' inversion)"));
+        void *_tmp_255_var;
         while (
-            (_tmp_254_var = _tmp_254_rule(p))  // 'and' inversion
+            (_tmp_255_var = _tmp_255_rule(p))  // 'and' inversion
         )
         {
-            _res = _tmp_254_var;
+            _res = _tmp_255_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -30337,7 +30294,7 @@ _loop1_88_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_88[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_87[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "('and' inversion)"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -30359,9 +30316,9 @@ _loop1_88_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_89: compare_op_bitwise_or_pair
+// _loop1_88: compare_op_bitwise_or_pair
 static asdl_seq *
-_loop1_89_rule(Parser *p)
+_loop1_88_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30386,7 +30343,7 @@ _loop1_89_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_89[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "compare_op_bitwise_or_pair"));
+        D(fprintf(stderr, "%*c> _loop1_88[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "compare_op_bitwise_or_pair"));
         CmpopExprPair* compare_op_bitwise_or_pair_var;
         while (
             (compare_op_bitwise_or_pair_var = compare_op_bitwise_or_pair_rule(p))  // compare_op_bitwise_or_pair
@@ -30409,7 +30366,7 @@ _loop1_89_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_89[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_88[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "compare_op_bitwise_or_pair"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -30431,9 +30388,9 @@ _loop1_89_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_90: '!='
+// _tmp_89: '!='
 static void *
-_tmp_90_rule(Parser *p)
+_tmp_89_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30449,13 +30406,13 @@ _tmp_90_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_90[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!='"));
+        D(fprintf(stderr, "%*c> _tmp_89[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!='"));
         Token * tok;
         if (
             (tok = _PyPegen_expect_token(p, 28))  // token='!='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_90[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!='"));
+            D(fprintf(stderr, "%*c+ _tmp_89[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!='"));
             _res = _PyPegen_check_barry_as_flufl ( p , tok ) ? NULL : tok;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -30465,7 +30422,7 @@ _tmp_90_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_90[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_89[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'!='"));
     }
     _res = NULL;
@@ -30474,9 +30431,9 @@ _tmp_90_rule(Parser *p)
     return _res;
 }
 
-// _loop0_92: ',' (slice | starred_expression)
+// _loop0_91: ',' (slice | starred_expression)
 static asdl_seq *
-_loop0_92_rule(Parser *p)
+_loop0_91_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30501,13 +30458,13 @@ _loop0_92_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_92[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (slice | starred_expression)"));
+        D(fprintf(stderr, "%*c> _loop0_91[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (slice | starred_expression)"));
         Token * _literal;
         void *elem;
         while (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (elem = _tmp_255_rule(p))  // slice | starred_expression
+            (elem = _tmp_256_rule(p))  // slice | starred_expression
         )
         {
             _res = elem;
@@ -30533,7 +30490,7 @@ _loop0_92_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_92[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_91[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (slice | starred_expression)"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -30550,9 +30507,9 @@ _loop0_92_rule(Parser *p)
     return _seq;
 }
 
-// _gather_91: (slice | starred_expression) _loop0_92
+// _gather_90: (slice | starred_expression) _loop0_91
 static asdl_seq *
-_gather_91_rule(Parser *p)
+_gather_90_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30563,27 +30520,27 @@ _gather_91_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // (slice | starred_expression) _loop0_92
+    { // (slice | starred_expression) _loop0_91
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_91[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(slice | starred_expression) _loop0_92"));
+        D(fprintf(stderr, "%*c> _gather_90[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(slice | starred_expression) _loop0_91"));
         void *elem;
         asdl_seq * seq;
         if (
-            (elem = _tmp_255_rule(p))  // slice | starred_expression
+            (elem = _tmp_256_rule(p))  // slice | starred_expression
             &&
-            (seq = _loop0_92_rule(p))  // _loop0_92
+            (seq = _loop0_91_rule(p))  // _loop0_91
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_91[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(slice | starred_expression) _loop0_92"));
+            D(fprintf(stderr, "%*c+ _gather_90[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(slice | starred_expression) _loop0_91"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_91[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(slice | starred_expression) _loop0_92"));
+        D(fprintf(stderr, "%*c%s _gather_90[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(slice | starred_expression) _loop0_91"));
     }
     _res = NULL;
   done:
@@ -30591,9 +30548,9 @@ _gather_91_rule(Parser *p)
     return _res;
 }
 
-// _tmp_93: ':' expression?
+// _tmp_92: ':' expression?
 static void *
-_tmp_93_rule(Parser *p)
+_tmp_92_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30609,7 +30566,7 @@ _tmp_93_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_93[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':' expression?"));
+        D(fprintf(stderr, "%*c> _tmp_92[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':' expression?"));
         Token * _literal;
         void *d;
         if (
@@ -30618,7 +30575,7 @@ _tmp_93_rule(Parser *p)
             (d = expression_rule(p), !p->error_indicator)  // expression?
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_93[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':' expression?"));
+            D(fprintf(stderr, "%*c+ _tmp_92[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':' expression?"));
             _res = d;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -30628,7 +30585,7 @@ _tmp_93_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_93[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_92[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':' expression?"));
     }
     _res = NULL;
@@ -30637,9 +30594,9 @@ _tmp_93_rule(Parser *p)
     return _res;
 }
 
-// _tmp_94: STRING | FSTRING_START
+// _tmp_93: STRING | FSTRING_START
 static void *
-_tmp_94_rule(Parser *p)
+_tmp_93_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30655,18 +30612,18 @@ _tmp_94_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_94[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "STRING"));
+        D(fprintf(stderr, "%*c> _tmp_93[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "STRING"));
         expr_ty string_var;
         if (
             (string_var = _PyPegen_string_token(p))  // STRING
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_94[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "STRING"));
+            D(fprintf(stderr, "%*c+ _tmp_93[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "STRING"));
             _res = string_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_94[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_93[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "STRING"));
     }
     { // FSTRING_START
@@ -30674,18 +30631,18 @@ _tmp_94_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_94[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "FSTRING_START"));
+        D(fprintf(stderr, "%*c> _tmp_93[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "FSTRING_START"));
         Token * fstring_start_var;
         if (
             (fstring_start_var = _PyPegen_expect_token(p, FSTRING_START))  // token='FSTRING_START'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_94[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "FSTRING_START"));
+            D(fprintf(stderr, "%*c+ _tmp_93[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "FSTRING_START"));
             _res = fstring_start_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_94[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_93[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "FSTRING_START"));
     }
     _res = NULL;
@@ -30694,9 +30651,9 @@ _tmp_94_rule(Parser *p)
     return _res;
 }
 
-// _tmp_95: tuple | group | genexp
+// _tmp_94: tuple | group | genexp
 static void *
-_tmp_95_rule(Parser *p)
+_tmp_94_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30712,18 +30669,18 @@ _tmp_95_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_95[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "tuple"));
+        D(fprintf(stderr, "%*c> _tmp_94[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "tuple"));
         expr_ty tuple_var;
         if (
             (tuple_var = tuple_rule(p))  // tuple
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_95[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "tuple"));
+            D(fprintf(stderr, "%*c+ _tmp_94[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "tuple"));
             _res = tuple_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_95[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_94[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "tuple"));
     }
     { // group
@@ -30731,18 +30688,18 @@ _tmp_95_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_95[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "group"));
+        D(fprintf(stderr, "%*c> _tmp_94[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "group"));
         expr_ty group_var;
         if (
             (group_var = group_rule(p))  // group
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_95[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "group"));
+            D(fprintf(stderr, "%*c+ _tmp_94[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "group"));
             _res = group_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_95[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_94[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "group"));
     }
     { // genexp
@@ -30750,18 +30707,18 @@ _tmp_95_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_95[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "genexp"));
+        D(fprintf(stderr, "%*c> _tmp_94[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "genexp"));
         expr_ty genexp_var;
         if (
             (genexp_var = genexp_rule(p))  // genexp
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_95[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "genexp"));
+            D(fprintf(stderr, "%*c+ _tmp_94[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "genexp"));
             _res = genexp_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_95[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_94[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "genexp"));
     }
     _res = NULL;
@@ -30770,9 +30727,9 @@ _tmp_95_rule(Parser *p)
     return _res;
 }
 
-// _tmp_96: list | listcomp
+// _tmp_95: list | listcomp
 static void *
-_tmp_96_rule(Parser *p)
+_tmp_95_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30788,18 +30745,18 @@ _tmp_96_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_96[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "list"));
+        D(fprintf(stderr, "%*c> _tmp_95[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "list"));
         expr_ty list_var;
         if (
             (list_var = list_rule(p))  // list
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_96[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "list"));
+            D(fprintf(stderr, "%*c+ _tmp_95[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "list"));
             _res = list_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_96[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_95[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "list"));
     }
     { // listcomp
@@ -30807,18 +30764,18 @@ _tmp_96_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_96[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "listcomp"));
+        D(fprintf(stderr, "%*c> _tmp_95[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "listcomp"));
         expr_ty listcomp_var;
         if (
             (listcomp_var = listcomp_rule(p))  // listcomp
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_96[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "listcomp"));
+            D(fprintf(stderr, "%*c+ _tmp_95[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "listcomp"));
             _res = listcomp_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_96[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_95[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "listcomp"));
     }
     _res = NULL;
@@ -30827,9 +30784,9 @@ _tmp_96_rule(Parser *p)
     return _res;
 }
 
-// _tmp_97: dict | set | dictcomp | setcomp
+// _tmp_96: dict | set | dictcomp | setcomp
 static void *
-_tmp_97_rule(Parser *p)
+_tmp_96_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30845,18 +30802,18 @@ _tmp_97_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_97[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dict"));
+        D(fprintf(stderr, "%*c> _tmp_96[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dict"));
         expr_ty dict_var;
         if (
             (dict_var = dict_rule(p))  // dict
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_97[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dict"));
+            D(fprintf(stderr, "%*c+ _tmp_96[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dict"));
             _res = dict_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_97[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_96[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "dict"));
     }
     { // set
@@ -30864,18 +30821,18 @@ _tmp_97_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_97[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "set"));
+        D(fprintf(stderr, "%*c> _tmp_96[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "set"));
         expr_ty set_var;
         if (
             (set_var = set_rule(p))  // set
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_97[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "set"));
+            D(fprintf(stderr, "%*c+ _tmp_96[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "set"));
             _res = set_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_97[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_96[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "set"));
     }
     { // dictcomp
@@ -30883,18 +30840,18 @@ _tmp_97_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_97[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dictcomp"));
+        D(fprintf(stderr, "%*c> _tmp_96[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dictcomp"));
         expr_ty dictcomp_var;
         if (
             (dictcomp_var = dictcomp_rule(p))  // dictcomp
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_97[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dictcomp"));
+            D(fprintf(stderr, "%*c+ _tmp_96[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dictcomp"));
             _res = dictcomp_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_97[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_96[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "dictcomp"));
     }
     { // setcomp
@@ -30902,18 +30859,18 @@ _tmp_97_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_97[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "setcomp"));
+        D(fprintf(stderr, "%*c> _tmp_96[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "setcomp"));
         expr_ty setcomp_var;
         if (
             (setcomp_var = setcomp_rule(p))  // setcomp
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_97[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "setcomp"));
+            D(fprintf(stderr, "%*c+ _tmp_96[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "setcomp"));
             _res = setcomp_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_97[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_96[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "setcomp"));
     }
     _res = NULL;
@@ -30922,9 +30879,9 @@ _tmp_97_rule(Parser *p)
     return _res;
 }
 
-// _tmp_98: yield_expr | named_expression
+// _tmp_97: yield_expr | named_expression
 static void *
-_tmp_98_rule(Parser *p)
+_tmp_97_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -30940,18 +30897,18 @@ _tmp_98_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_98[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_97[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_98[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_97[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_98[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_97[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // named_expression
@@ -30959,18 +30916,18 @@ _tmp_98_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_98[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "named_expression"));
+        D(fprintf(stderr, "%*c> _tmp_97[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "named_expression"));
         expr_ty named_expression_var;
         if (
             (named_expression_var = named_expression_rule(p))  // named_expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_98[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "named_expression"));
+            D(fprintf(stderr, "%*c+ _tmp_97[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "named_expression"));
             _res = named_expression_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_98[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_97[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "named_expression"));
     }
     _res = NULL;
@@ -30979,9 +30936,9 @@ _tmp_98_rule(Parser *p)
     return _res;
 }
 
-// _loop0_99: lambda_param_no_default
+// _loop0_98: lambda_param_no_default
 static asdl_seq *
-_loop0_99_rule(Parser *p)
+_loop0_98_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31006,7 +30963,7 @@ _loop0_99_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_99[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_98[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -31029,7 +30986,7 @@ _loop0_99_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_99[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_98[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31046,9 +31003,9 @@ _loop0_99_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_100: lambda_param_with_default
+// _loop0_99: lambda_param_with_default
 static asdl_seq *
-_loop0_100_rule(Parser *p)
+_loop0_99_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31073,7 +31030,7 @@ _loop0_100_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_100[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop0_99[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -31096,7 +31053,7 @@ _loop0_100_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_100[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_99[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31113,9 +31070,9 @@ _loop0_100_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_101: lambda_param_with_default
+// _loop0_100: lambda_param_with_default
 static asdl_seq *
-_loop0_101_rule(Parser *p)
+_loop0_100_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31140,7 +31097,7 @@ _loop0_101_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_101[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop0_100[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -31163,7 +31120,7 @@ _loop0_101_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_101[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_100[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31180,9 +31137,9 @@ _loop0_101_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_102: lambda_param_no_default
+// _loop1_101: lambda_param_no_default
 static asdl_seq *
-_loop1_102_rule(Parser *p)
+_loop1_101_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31207,7 +31164,7 @@ _loop1_102_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_102[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop1_101[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -31230,7 +31187,7 @@ _loop1_102_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_102[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_101[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31252,9 +31209,9 @@ _loop1_102_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_103: lambda_param_with_default
+// _loop0_102: lambda_param_with_default
 static asdl_seq *
-_loop0_103_rule(Parser *p)
+_loop0_102_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31279,7 +31236,7 @@ _loop0_103_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_103[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop0_102[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -31302,7 +31259,7 @@ _loop0_103_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_103[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_102[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31319,9 +31276,9 @@ _loop0_103_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_104: lambda_param_with_default
+// _loop1_103: lambda_param_with_default
 static asdl_seq *
-_loop1_104_rule(Parser *p)
+_loop1_103_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31346,7 +31303,7 @@ _loop1_104_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_104[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_103[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -31369,7 +31326,7 @@ _loop1_104_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_104[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_103[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31391,9 +31348,9 @@ _loop1_104_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_105: lambda_param_no_default
+// _loop1_104: lambda_param_no_default
 static asdl_seq *
-_loop1_105_rule(Parser *p)
+_loop1_104_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31418,7 +31375,7 @@ _loop1_105_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_105[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop1_104[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -31441,7 +31398,7 @@ _loop1_105_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_105[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_104[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31463,9 +31420,9 @@ _loop1_105_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_106: lambda_param_no_default
+// _loop1_105: lambda_param_no_default
 static asdl_seq *
-_loop1_106_rule(Parser *p)
+_loop1_105_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31490,7 +31447,7 @@ _loop1_106_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_106[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop1_105[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -31513,7 +31470,7 @@ _loop1_106_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_106[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_105[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31535,9 +31492,9 @@ _loop1_106_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_107: lambda_param_no_default
+// _loop0_106: lambda_param_no_default
 static asdl_seq *
-_loop0_107_rule(Parser *p)
+_loop0_106_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31562,7 +31519,7 @@ _loop0_107_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_107[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_106[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -31585,7 +31542,7 @@ _loop0_107_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_107[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_106[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31602,9 +31559,9 @@ _loop0_107_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_108: lambda_param_with_default
+// _loop1_107: lambda_param_with_default
 static asdl_seq *
-_loop1_108_rule(Parser *p)
+_loop1_107_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31629,7 +31586,7 @@ _loop1_108_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_108[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_107[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -31652,7 +31609,7 @@ _loop1_108_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_108[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_107[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31674,9 +31631,9 @@ _loop1_108_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_109: lambda_param_no_default
+// _loop0_108: lambda_param_no_default
 static asdl_seq *
-_loop0_109_rule(Parser *p)
+_loop0_108_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31701,7 +31658,7 @@ _loop0_109_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_109[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_108[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -31724,7 +31681,7 @@ _loop0_109_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_109[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_108[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31741,9 +31698,9 @@ _loop0_109_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_110: lambda_param_with_default
+// _loop1_109: lambda_param_with_default
 static asdl_seq *
-_loop1_110_rule(Parser *p)
+_loop1_109_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31768,7 +31725,7 @@ _loop1_110_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_110[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_109[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -31791,7 +31748,7 @@ _loop1_110_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_110[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_109[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31813,9 +31770,9 @@ _loop1_110_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_111: lambda_param_maybe_default
+// _loop0_110: lambda_param_maybe_default
 static asdl_seq *
-_loop0_111_rule(Parser *p)
+_loop0_110_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31840,7 +31797,7 @@ _loop0_111_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_111[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_110[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -31863,7 +31820,7 @@ _loop0_111_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_111[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_110[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -31880,9 +31837,9 @@ _loop0_111_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_112: lambda_param_maybe_default
+// _loop1_111: lambda_param_maybe_default
 static asdl_seq *
-_loop1_112_rule(Parser *p)
+_loop1_111_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31907,7 +31864,7 @@ _loop1_112_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_112[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop1_111[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -31930,7 +31887,7 @@ _loop1_112_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_112[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_111[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -31952,9 +31909,9 @@ _loop1_112_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_113: yield_expr | star_expressions
+// _tmp_112: yield_expr | star_expressions
 static void *
-_tmp_113_rule(Parser *p)
+_tmp_112_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -31970,18 +31927,18 @@ _tmp_113_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_113[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_112[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_113[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_112[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_113[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_112[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -31989,18 +31946,18 @@ _tmp_113_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_113[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_112[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_113[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_112[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_113[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_112[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -32009,9 +31966,9 @@ _tmp_113_rule(Parser *p)
     return _res;
 }
 
-// _loop0_114: fstring_format_spec
+// _loop0_113: fstring_format_spec
 static asdl_seq *
-_loop0_114_rule(Parser *p)
+_loop0_113_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -32036,7 +31993,7 @@ _loop0_114_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_114[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring_format_spec"));
+        D(fprintf(stderr, "%*c> _loop0_113[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring_format_spec"));
         expr_ty fstring_format_spec_var;
         while (
             (fstring_format_spec_var = fstring_format_spec_rule(p))  // fstring_format_spec
@@ -32059,7 +32016,7 @@ _loop0_114_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_114[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_113[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "fstring_format_spec"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -32076,6 +32033,73 @@ _loop0_114_rule(Parser *p)
     return _seq;
 }
 
+// _loop0_114: fstring_middle
+static asdl_seq *
+_loop0_114_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void *_res = NULL;
+    int _mark = p->mark;
+    void **_children = PyMem_Malloc(sizeof(void *));
+    if (!_children) {
+        p->error_indicator = 1;
+        PyErr_NoMemory();
+        p->level--;
+        return NULL;
+    }
+    Py_ssize_t _children_capacity = 1;
+    Py_ssize_t _n = 0;
+    { // fstring_middle
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _loop0_114[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring_middle"));
+        expr_ty fstring_middle_var;
+        while (
+            (fstring_middle_var = fstring_middle_rule(p))  // fstring_middle
+        )
+        {
+            _res = fstring_middle_var;
+            if (_n == _children_capacity) {
+                _children_capacity *= 2;
+                void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
+                if (!_new_children) {
+                    PyMem_Free(_children);
+                    p->error_indicator = 1;
+                    PyErr_NoMemory();
+                    p->level--;
+                    return NULL;
+                }
+                _children = _new_children;
+            }
+            _children[_n++] = _res;
+            _mark = p->mark;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _loop0_114[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "fstring_middle"));
+    }
+    asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
+    if (!_seq) {
+        PyMem_Free(_children);
+        p->error_indicator = 1;
+        PyErr_NoMemory();
+        p->level--;
+        return NULL;
+    }
+    for (int i = 0; i < _n; i++) asdl_seq_SET_UNTYPED(_seq, i, _children[i]);
+    PyMem_Free(_children);
+    p->level--;
+    return _seq;
+}
+
 // _loop1_115: (fstring | string)
 static asdl_seq *
 _loop1_115_rule(Parser *p)
@@ -32104,12 +32128,12 @@ _loop1_115_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> _loop1_115[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(fstring | string)"));
-        void *_tmp_256_var;
+        void *_tmp_257_var;
         while (
-            (_tmp_256_var = _tmp_256_rule(p))  // fstring | string
+            (_tmp_257_var = _tmp_257_rule(p))  // fstring | string
         )
         {
-            _res = _tmp_256_var;
+            _res = _tmp_257_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -32414,12 +32438,12 @@ _loop0_120_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> _loop0_120[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('if' disjunction)"));
-        void *_tmp_257_var;
+        void *_tmp_258_var;
         while (
-            (_tmp_257_var = _tmp_257_rule(p))  // 'if' disjunction
+            (_tmp_258_var = _tmp_258_rule(p))  // 'if' disjunction
         )
         {
-            _res = _tmp_257_var;
+            _res = _tmp_258_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -32481,12 +32505,12 @@ _loop0_121_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> _loop0_121[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "('if' disjunction)"));
-        void *_tmp_258_var;
+        void *_tmp_259_var;
         while (
-            (_tmp_258_var = _tmp_258_rule(p))  // 'if' disjunction
+            (_tmp_259_var = _tmp_259_rule(p))  // 'if' disjunction
         )
         {
-            _res = _tmp_258_var;
+            _res = _tmp_259_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -32612,7 +32636,7 @@ _loop0_124_rule(Parser *p)
         while (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (elem = _tmp_259_rule(p))  // starred_expression | (assignment_expression | expression !':=') !'='
+            (elem = _tmp_260_rule(p))  // starred_expression | (assignment_expression | expression !':=') !'='
         )
         {
             _res = elem;
@@ -32678,7 +32702,7 @@ _gather_123_rule(Parser *p)
         void *elem;
         asdl_seq * seq;
         if (
-            (elem = _tmp_259_rule(p))  // starred_expression | (assignment_expression | expression !':=') !'='
+            (elem = _tmp_260_rule(p))  // starred_expression | (assignment_expression | expression !':=') !'='
             &&
             (seq = _loop0_124_rule(p))  // _loop0_124
         )
@@ -33239,12 +33263,12 @@ _loop0_134_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> _loop0_134[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(',' star_target)"));
-        void *_tmp_260_var;
+        void *_tmp_261_var;
         while (
-            (_tmp_260_var = _tmp_260_rule(p))  // ',' star_target
+            (_tmp_261_var = _tmp_261_rule(p))  // ',' star_target
         )
         {
-            _res = _tmp_260_var;
+            _res = _tmp_261_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -33423,12 +33447,12 @@ _loop1_137_rule(Parser *p)
             return NULL;
         }
         D(fprintf(stderr, "%*c> _loop1_137[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(',' star_target)"));
-        void *_tmp_261_var;
+        void *_tmp_262_var;
         while (
-            (_tmp_261_var = _tmp_261_rule(p))  // ',' star_target
+            (_tmp_262_var = _tmp_262_rule(p))  // ',' star_target
         )
         {
-            _res = _tmp_261_var;
+            _res = _tmp_262_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -34133,9 +34157,68 @@ _tmp_149_rule(Parser *p)
     return _res;
 }
 
-// _tmp_150: args | expression for_if_clauses
+// _tmp_150:
+//     | (','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs)
+//     | kwargs
 static void *
 _tmp_150_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void * _res = NULL;
+    int _mark = p->mark;
+    { // (','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs)
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_150[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs)"));
+        void *_tmp_263_var;
+        if (
+            (_tmp_263_var = _tmp_263_rule(p))  // ','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_150[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs)"));
+            _res = _tmp_263_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_150[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs)"));
+    }
+    { // kwargs
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_150[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "kwargs"));
+        asdl_seq* kwargs_var;
+        if (
+            (kwargs_var = kwargs_rule(p))  // kwargs
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_150[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "kwargs"));
+            _res = kwargs_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_150[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "kwargs"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
+// _tmp_151: args | expression for_if_clauses
+static void *
+_tmp_151_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34151,18 +34234,18 @@ _tmp_150_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_150[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "args"));
+        D(fprintf(stderr, "%*c> _tmp_151[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "args"));
         expr_ty args_var;
         if (
             (args_var = args_rule(p))  // args
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_150[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "args"));
+            D(fprintf(stderr, "%*c+ _tmp_151[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "args"));
             _res = args_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_150[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_151[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "args"));
     }
     { // expression for_if_clauses
@@ -34170,7 +34253,7 @@ _tmp_150_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_150[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression for_if_clauses"));
+        D(fprintf(stderr, "%*c> _tmp_151[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression for_if_clauses"));
         expr_ty expression_var;
         asdl_comprehension_seq* for_if_clauses_var;
         if (
@@ -34179,12 +34262,12 @@ _tmp_150_rule(Parser *p)
             (for_if_clauses_var = for_if_clauses_rule(p))  // for_if_clauses
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_150[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression for_if_clauses"));
+            D(fprintf(stderr, "%*c+ _tmp_151[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression for_if_clauses"));
             _res = _PyPegen_dummy_name(p, expression_var, for_if_clauses_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_150[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_151[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expression for_if_clauses"));
     }
     _res = NULL;
@@ -34193,9 +34276,9 @@ _tmp_150_rule(Parser *p)
     return _res;
 }
 
-// _tmp_151: args ','
+// _tmp_152: args ','
 static void *
-_tmp_151_rule(Parser *p)
+_tmp_152_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34211,7 +34294,7 @@ _tmp_151_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_151[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "args ','"));
+        D(fprintf(stderr, "%*c> _tmp_152[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "args ','"));
         Token * _literal;
         expr_ty args_var;
         if (
@@ -34220,12 +34303,12 @@ _tmp_151_rule(Parser *p)
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_151[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "args ','"));
+            D(fprintf(stderr, "%*c+ _tmp_152[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "args ','"));
             _res = _PyPegen_dummy_name(p, args_var, _literal);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_151[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_152[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "args ','"));
     }
     _res = NULL;
@@ -34234,9 +34317,9 @@ _tmp_151_rule(Parser *p)
     return _res;
 }
 
-// _tmp_152: ',' | ')'
+// _tmp_153: ',' | ')'
 static void *
-_tmp_152_rule(Parser *p)
+_tmp_153_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34252,18 +34335,18 @@ _tmp_152_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_152[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_153[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_152[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_153[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_152[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_153[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     { // ')'
@@ -34271,18 +34354,18 @@ _tmp_152_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_152[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
+        D(fprintf(stderr, "%*c> _tmp_153[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_152[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
+            D(fprintf(stderr, "%*c+ _tmp_153[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_152[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_153[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "')'"));
     }
     _res = NULL;
@@ -34291,9 +34374,9 @@ _tmp_152_rule(Parser *p)
     return _res;
 }
 
-// _tmp_153: 'True' | 'False' | 'None'
+// _tmp_154: 'True' | 'False' | 'None'
 static void *
-_tmp_153_rule(Parser *p)
+_tmp_154_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34309,18 +34392,18 @@ _tmp_153_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_153[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'True'"));
+        D(fprintf(stderr, "%*c> _tmp_154[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'True'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 601))  // token='True'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_153[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'True'"));
+            D(fprintf(stderr, "%*c+ _tmp_154[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'True'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_153[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_154[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'True'"));
     }
     { // 'False'
@@ -34328,18 +34411,18 @@ _tmp_153_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_153[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'False'"));
+        D(fprintf(stderr, "%*c> _tmp_154[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'False'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 603))  // token='False'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_153[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'False'"));
+            D(fprintf(stderr, "%*c+ _tmp_154[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'False'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_153[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_154[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'False'"));
     }
     { // 'None'
@@ -34347,18 +34430,18 @@ _tmp_153_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_153[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'None'"));
+        D(fprintf(stderr, "%*c> _tmp_154[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'None'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 602))  // token='None'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_153[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'None'"));
+            D(fprintf(stderr, "%*c+ _tmp_154[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'None'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_153[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_154[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'None'"));
     }
     _res = NULL;
@@ -34367,9 +34450,9 @@ _tmp_153_rule(Parser *p)
     return _res;
 }
 
-// _tmp_154: NAME '='
+// _tmp_155: NAME '='
 static void *
-_tmp_154_rule(Parser *p)
+_tmp_155_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34385,7 +34468,7 @@ _tmp_154_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_154[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME '='"));
+        D(fprintf(stderr, "%*c> _tmp_155[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME '='"));
         Token * _literal;
         expr_ty name_var;
         if (
@@ -34394,12 +34477,12 @@ _tmp_154_rule(Parser *p)
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_154[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME '='"));
+            D(fprintf(stderr, "%*c+ _tmp_155[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME '='"));
             _res = _PyPegen_dummy_name(p, name_var, _literal);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_154[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_155[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME '='"));
     }
     _res = NULL;
@@ -34408,9 +34491,9 @@ _tmp_154_rule(Parser *p)
     return _res;
 }
 
-// _tmp_155: NAME STRING | SOFT_KEYWORD
+// _tmp_156: NAME STRING | SOFT_KEYWORD
 static void *
-_tmp_155_rule(Parser *p)
+_tmp_156_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34426,7 +34509,7 @@ _tmp_155_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_155[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME STRING"));
+        D(fprintf(stderr, "%*c> _tmp_156[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NAME STRING"));
         expr_ty name_var;
         expr_ty string_var;
         if (
@@ -34435,12 +34518,12 @@ _tmp_155_rule(Parser *p)
             (string_var = _PyPegen_string_token(p))  // STRING
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_155[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME STRING"));
+            D(fprintf(stderr, "%*c+ _tmp_156[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NAME STRING"));
             _res = _PyPegen_dummy_name(p, name_var, string_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_155[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_156[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NAME STRING"));
     }
     { // SOFT_KEYWORD
@@ -34448,18 +34531,18 @@ _tmp_155_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_155[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "SOFT_KEYWORD"));
+        D(fprintf(stderr, "%*c> _tmp_156[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "SOFT_KEYWORD"));
         expr_ty soft_keyword_var;
         if (
             (soft_keyword_var = _PyPegen_soft_keyword_token(p))  // SOFT_KEYWORD
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_155[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "SOFT_KEYWORD"));
+            D(fprintf(stderr, "%*c+ _tmp_156[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "SOFT_KEYWORD"));
             _res = soft_keyword_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_155[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_156[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "SOFT_KEYWORD"));
     }
     _res = NULL;
@@ -34468,9 +34551,9 @@ _tmp_155_rule(Parser *p)
     return _res;
 }
 
-// _tmp_156: 'else' | ':'
+// _tmp_157: 'else' | ':'
 static void *
-_tmp_156_rule(Parser *p)
+_tmp_157_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34486,18 +34569,18 @@ _tmp_156_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_156[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'else'"));
+        D(fprintf(stderr, "%*c> _tmp_157[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'else'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 645))  // token='else'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_156[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'else'"));
+            D(fprintf(stderr, "%*c+ _tmp_157[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'else'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_156[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_157[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'else'"));
     }
     { // ':'
@@ -34505,18 +34588,18 @@ _tmp_156_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_156[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_157[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_156[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_157[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_156[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_157[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     _res = NULL;
@@ -34525,9 +34608,9 @@ _tmp_156_rule(Parser *p)
     return _res;
 }
 
-// _tmp_157: '=' | ':='
+// _tmp_158: '=' | ':='
 static void *
-_tmp_157_rule(Parser *p)
+_tmp_158_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34543,18 +34626,18 @@ _tmp_157_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_157[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
+        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_157[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
+            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_157[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'='"));
     }
     { // ':='
@@ -34562,18 +34645,18 @@ _tmp_157_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_157[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':='"));
+        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 53))  // token=':='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_157[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':='"));
+            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_157[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':='"));
     }
     _res = NULL;
@@ -34582,9 +34665,9 @@ _tmp_157_rule(Parser *p)
     return _res;
 }
 
-// _tmp_158: list | tuple | genexp | 'True' | 'None' | 'False'
+// _tmp_159: list | tuple | genexp | 'True' | 'None' | 'False'
 static void *
-_tmp_158_rule(Parser *p)
+_tmp_159_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34600,18 +34683,18 @@ _tmp_158_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "list"));
+        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "list"));
         expr_ty list_var;
         if (
             (list_var = list_rule(p))  // list
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "list"));
+            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "list"));
             _res = list_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "list"));
     }
     { // tuple
@@ -34619,18 +34702,18 @@ _tmp_158_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "tuple"));
+        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "tuple"));
         expr_ty tuple_var;
         if (
             (tuple_var = tuple_rule(p))  // tuple
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "tuple"));
+            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "tuple"));
             _res = tuple_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "tuple"));
     }
     { // genexp
@@ -34638,18 +34721,18 @@ _tmp_158_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "genexp"));
+        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "genexp"));
         expr_ty genexp_var;
         if (
             (genexp_var = genexp_rule(p))  // genexp
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "genexp"));
+            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "genexp"));
             _res = genexp_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "genexp"));
     }
     { // 'True'
@@ -34657,18 +34740,18 @@ _tmp_158_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'True'"));
+        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'True'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 601))  // token='True'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'True'"));
+            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'True'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'True'"));
     }
     { // 'None'
@@ -34676,18 +34759,18 @@ _tmp_158_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'None'"));
+        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'None'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 602))  // token='None'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'None'"));
+            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'None'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'None'"));
     }
     { // 'False'
@@ -34695,18 +34778,18 @@ _tmp_158_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_158[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'False'"));
+        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'False'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 603))  // token='False'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_158[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'False'"));
+            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'False'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_158[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'False'"));
     }
     _res = NULL;
@@ -34715,9 +34798,9 @@ _tmp_158_rule(Parser *p)
     return _res;
 }
 
-// _tmp_159: '=' | ':='
+// _tmp_160: '=' | ':='
 static void *
-_tmp_159_rule(Parser *p)
+_tmp_160_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34733,18 +34816,18 @@ _tmp_159_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
+        D(fprintf(stderr, "%*c> _tmp_160[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
+            D(fprintf(stderr, "%*c+ _tmp_160[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_160[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'='"));
     }
     { // ':='
@@ -34752,18 +34835,18 @@ _tmp_159_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_159[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':='"));
+        D(fprintf(stderr, "%*c> _tmp_160[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 53))  // token=':='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_159[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':='"));
+            D(fprintf(stderr, "%*c+ _tmp_160[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_159[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_160[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':='"));
     }
     _res = NULL;
@@ -34772,9 +34855,9 @@ _tmp_159_rule(Parser *p)
     return _res;
 }
 
-// _loop0_160: star_named_expressions
+// _loop0_161: star_named_expressions
 static asdl_seq *
-_loop0_160_rule(Parser *p)
+_loop0_161_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34799,7 +34882,7 @@ _loop0_160_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_160[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_named_expressions"));
+        D(fprintf(stderr, "%*c> _loop0_161[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_named_expressions"));
         asdl_expr_seq* star_named_expressions_var;
         while (
             (star_named_expressions_var = star_named_expressions_rule(p))  // star_named_expressions
@@ -34822,7 +34905,7 @@ _loop0_160_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_160[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_161[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_named_expressions"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -34839,9 +34922,9 @@ _loop0_160_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_161: (star_targets '=')
+// _loop0_162: (star_targets '=')
 static asdl_seq *
-_loop0_161_rule(Parser *p)
+_loop0_162_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34866,13 +34949,13 @@ _loop0_161_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_161[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(star_targets '=')"));
-        void *_tmp_262_var;
+        D(fprintf(stderr, "%*c> _loop0_162[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(star_targets '=')"));
+        void *_tmp_264_var;
         while (
-            (_tmp_262_var = _tmp_262_rule(p))  // star_targets '='
+            (_tmp_264_var = _tmp_264_rule(p))  // star_targets '='
         )
         {
-            _res = _tmp_262_var;
+            _res = _tmp_264_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -34889,7 +34972,7 @@ _loop0_161_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_161[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_162[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(star_targets '=')"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -34906,9 +34989,9 @@ _loop0_161_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_162: (star_targets '=')
+// _loop0_163: (star_targets '=')
 static asdl_seq *
-_loop0_162_rule(Parser *p)
+_loop0_163_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34933,13 +35016,13 @@ _loop0_162_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_162[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(star_targets '=')"));
-        void *_tmp_263_var;
+        D(fprintf(stderr, "%*c> _loop0_163[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(star_targets '=')"));
+        void *_tmp_265_var;
         while (
-            (_tmp_263_var = _tmp_263_rule(p))  // star_targets '='
+            (_tmp_265_var = _tmp_265_rule(p))  // star_targets '='
         )
         {
-            _res = _tmp_263_var;
+            _res = _tmp_265_var;
             if (_n == _children_capacity) {
                 _children_capacity *= 2;
                 void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
@@ -34956,7 +35039,7 @@ _loop0_162_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_162[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_163[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(star_targets '=')"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -34973,9 +35056,9 @@ _loop0_162_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_163: yield_expr | star_expressions
+// _tmp_164: yield_expr | star_expressions
 static void *
-_tmp_163_rule(Parser *p)
+_tmp_164_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -34991,18 +35074,18 @@ _tmp_163_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_163[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_164[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_163[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_164[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_163[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_164[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -35010,18 +35093,18 @@ _tmp_163_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_163[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_164[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_163[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_164[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_163[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_164[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -35030,9 +35113,9 @@ _tmp_163_rule(Parser *p)
     return _res;
 }
 
-// _tmp_164: '[' | '(' | '{'
+// _tmp_165: '[' | '(' | '{'
 static void *
-_tmp_164_rule(Parser *p)
+_tmp_165_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35048,18 +35131,18 @@ _tmp_164_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_164[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'['"));
+        D(fprintf(stderr, "%*c> _tmp_165[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'['"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 9))  // token='['
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_164[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'['"));
+            D(fprintf(stderr, "%*c+ _tmp_165[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'['"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_164[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_165[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'['"));
     }
     { // '('
@@ -35067,18 +35150,18 @@ _tmp_164_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_164[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'('"));
+        D(fprintf(stderr, "%*c> _tmp_165[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'('"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 7))  // token='('
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_164[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'('"));
+            D(fprintf(stderr, "%*c+ _tmp_165[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'('"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_164[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_165[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'('"));
     }
     { // '{'
@@ -35086,18 +35169,18 @@ _tmp_164_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_164[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{'"));
+        D(fprintf(stderr, "%*c> _tmp_165[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_164[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{'"));
+            D(fprintf(stderr, "%*c+ _tmp_165[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_164[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_165[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'{'"));
     }
     _res = NULL;
@@ -35106,9 +35189,9 @@ _tmp_164_rule(Parser *p)
     return _res;
 }
 
-// _tmp_165: '[' | '{'
+// _tmp_166: '[' | '{'
 static void *
-_tmp_165_rule(Parser *p)
+_tmp_166_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35124,18 +35207,18 @@ _tmp_165_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_165[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'['"));
+        D(fprintf(stderr, "%*c> _tmp_166[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'['"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 9))  // token='['
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_165[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'['"));
+            D(fprintf(stderr, "%*c+ _tmp_166[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'['"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_165[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_166[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'['"));
     }
     { // '{'
@@ -35143,18 +35226,18 @@ _tmp_165_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_165[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{'"));
+        D(fprintf(stderr, "%*c> _tmp_166[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_165[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{'"));
+            D(fprintf(stderr, "%*c+ _tmp_166[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_165[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_166[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'{'"));
     }
     _res = NULL;
@@ -35163,9 +35246,9 @@ _tmp_165_rule(Parser *p)
     return _res;
 }
 
-// _tmp_166: '[' | '{'
+// _tmp_167: '[' | '{'
 static void *
-_tmp_166_rule(Parser *p)
+_tmp_167_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35181,18 +35264,18 @@ _tmp_166_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_166[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'['"));
+        D(fprintf(stderr, "%*c> _tmp_167[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'['"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 9))  // token='['
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_166[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'['"));
+            D(fprintf(stderr, "%*c+ _tmp_167[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'['"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_166[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_167[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'['"));
     }
     { // '{'
@@ -35200,18 +35283,18 @@ _tmp_166_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_166[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{'"));
+        D(fprintf(stderr, "%*c> _tmp_167[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'{'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 25))  // token='{'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_166[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{'"));
+            D(fprintf(stderr, "%*c+ _tmp_167[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'{'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_166[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_167[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'{'"));
     }
     _res = NULL;
@@ -35220,9 +35303,9 @@ _tmp_166_rule(Parser *p)
     return _res;
 }
 
-// _tmp_167: slash_no_default | slash_with_default
+// _tmp_168: slash_no_default | slash_with_default
 static void *
-_tmp_167_rule(Parser *p)
+_tmp_168_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35238,18 +35321,18 @@ _tmp_167_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_167[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_168[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
         asdl_arg_seq* slash_no_default_var;
         if (
             (slash_no_default_var = slash_no_default_rule(p))  // slash_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_167[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_168[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
             _res = slash_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_167[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_168[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "slash_no_default"));
     }
     { // slash_with_default
@@ -35257,18 +35340,18 @@ _tmp_167_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_167[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
+        D(fprintf(stderr, "%*c> _tmp_168[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
         SlashWithDefault* slash_with_default_var;
         if (
             (slash_with_default_var = slash_with_default_rule(p))  // slash_with_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_167[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
+            D(fprintf(stderr, "%*c+ _tmp_168[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
             _res = slash_with_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_167[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_168[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "slash_with_default"));
     }
     _res = NULL;
@@ -35277,9 +35360,9 @@ _tmp_167_rule(Parser *p)
     return _res;
 }
 
-// _loop0_168: param_maybe_default
+// _loop0_169: param_maybe_default
 static asdl_seq *
-_loop0_168_rule(Parser *p)
+_loop0_169_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35304,7 +35387,7 @@ _loop0_168_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_168[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_169[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -35327,75 +35410,8 @@ _loop0_168_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_168[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
-    }
-    asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
-    if (!_seq) {
-        PyMem_Free(_children);
-        p->error_indicator = 1;
-        PyErr_NoMemory();
-        p->level--;
-        return NULL;
-    }
-    for (int i = 0; i < _n; i++) asdl_seq_SET_UNTYPED(_seq, i, _children[i]);
-    PyMem_Free(_children);
-    p->level--;
-    return _seq;
-}
-
-// _loop0_169: param_no_default
-static asdl_seq *
-_loop0_169_rule(Parser *p)
-{
-    if (p->level++ == MAXSTACK) {
-        _Pypegen_stack_overflow(p);
-    }
-    if (p->error_indicator) {
-        p->level--;
-        return NULL;
-    }
-    void *_res = NULL;
-    int _mark = p->mark;
-    void **_children = PyMem_Malloc(sizeof(void *));
-    if (!_children) {
-        p->error_indicator = 1;
-        PyErr_NoMemory();
-        p->level--;
-        return NULL;
-    }
-    Py_ssize_t _children_capacity = 1;
-    Py_ssize_t _n = 0;
-    { // param_no_default
-        if (p->error_indicator) {
-            p->level--;
-            return NULL;
-        }
-        D(fprintf(stderr, "%*c> _loop0_169[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
-        arg_ty param_no_default_var;
-        while (
-            (param_no_default_var = param_no_default_rule(p))  // param_no_default
-        )
-        {
-            _res = param_no_default_var;
-            if (_n == _children_capacity) {
-                _children_capacity *= 2;
-                void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
-                if (!_new_children) {
-                    PyMem_Free(_children);
-                    p->error_indicator = 1;
-                    PyErr_NoMemory();
-                    p->level--;
-                    return NULL;
-                }
-                _children = _new_children;
-            }
-            _children[_n++] = _res;
-            _mark = p->mark;
-        }
-        p->mark = _mark;
         D(fprintf(stderr, "%*c%s _loop0_169[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
     if (!_seq) {
@@ -35478,9 +35494,9 @@ _loop0_170_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_171: param_no_default
+// _loop0_171: param_no_default
 static asdl_seq *
-_loop1_171_rule(Parser *p)
+_loop0_171_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35505,7 +35521,7 @@ _loop1_171_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_171[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_171[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         while (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
@@ -35528,7 +35544,74 @@ _loop1_171_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_171[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_171[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
+    }
+    asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
+    if (!_seq) {
+        PyMem_Free(_children);
+        p->error_indicator = 1;
+        PyErr_NoMemory();
+        p->level--;
+        return NULL;
+    }
+    for (int i = 0; i < _n; i++) asdl_seq_SET_UNTYPED(_seq, i, _children[i]);
+    PyMem_Free(_children);
+    p->level--;
+    return _seq;
+}
+
+// _loop1_172: param_no_default
+static asdl_seq *
+_loop1_172_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void *_res = NULL;
+    int _mark = p->mark;
+    void **_children = PyMem_Malloc(sizeof(void *));
+    if (!_children) {
+        p->error_indicator = 1;
+        PyErr_NoMemory();
+        p->level--;
+        return NULL;
+    }
+    Py_ssize_t _children_capacity = 1;
+    Py_ssize_t _n = 0;
+    { // param_no_default
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _loop1_172[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        arg_ty param_no_default_var;
+        while (
+            (param_no_default_var = param_no_default_rule(p))  // param_no_default
+        )
+        {
+            _res = param_no_default_var;
+            if (_n == _children_capacity) {
+                _children_capacity *= 2;
+                void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
+                if (!_new_children) {
+                    PyMem_Free(_children);
+                    p->error_indicator = 1;
+                    PyErr_NoMemory();
+                    p->level--;
+                    return NULL;
+                }
+                _children = _new_children;
+            }
+            _children[_n++] = _res;
+            _mark = p->mark;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _loop1_172[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -35550,9 +35633,9 @@ _loop1_171_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_172: slash_no_default | slash_with_default
+// _tmp_173: slash_no_default | slash_with_default
 static void *
-_tmp_172_rule(Parser *p)
+_tmp_173_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35568,18 +35651,18 @@ _tmp_172_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_172[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_173[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
         asdl_arg_seq* slash_no_default_var;
         if (
             (slash_no_default_var = slash_no_default_rule(p))  // slash_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_172[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_173[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_no_default"));
             _res = slash_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_172[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_173[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "slash_no_default"));
     }
     { // slash_with_default
@@ -35587,18 +35670,18 @@ _tmp_172_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_172[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
+        D(fprintf(stderr, "%*c> _tmp_173[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
         SlashWithDefault* slash_with_default_var;
         if (
             (slash_with_default_var = slash_with_default_rule(p))  // slash_with_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_172[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
+            D(fprintf(stderr, "%*c+ _tmp_173[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slash_with_default"));
             _res = slash_with_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_172[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_173[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "slash_with_default"));
     }
     _res = NULL;
@@ -35607,9 +35690,9 @@ _tmp_172_rule(Parser *p)
     return _res;
 }
 
-// _loop0_173: param_maybe_default
+// _loop0_174: param_maybe_default
 static asdl_seq *
-_loop0_173_rule(Parser *p)
+_loop0_174_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35634,7 +35717,7 @@ _loop0_173_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_173[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_174[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -35657,7 +35740,7 @@ _loop0_173_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_173[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_174[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -35674,9 +35757,9 @@ _loop0_173_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_174: ',' | param_no_default
+// _tmp_175: ',' | param_no_default
 static void *
-_tmp_174_rule(Parser *p)
+_tmp_175_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35692,18 +35775,18 @@ _tmp_174_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_174[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_175[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_174[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_175[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_174[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_175[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     { // param_no_default
@@ -35711,18 +35794,18 @@ _tmp_174_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_174[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_175[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         if (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_174[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_175[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_no_default"));
             _res = param_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_174[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_175[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     _res = NULL;
@@ -35731,9 +35814,9 @@ _tmp_174_rule(Parser *p)
     return _res;
 }
 
-// _loop0_175: param_maybe_default
+// _loop0_176: param_maybe_default
 static asdl_seq *
-_loop0_175_rule(Parser *p)
+_loop0_176_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35758,7 +35841,7 @@ _loop0_175_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_175[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_176[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -35781,7 +35864,7 @@ _loop0_175_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_175[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_176[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -35798,9 +35881,9 @@ _loop0_175_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_176: param_maybe_default
+// _loop1_177: param_maybe_default
 static asdl_seq *
-_loop1_176_rule(Parser *p)
+_loop1_177_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35825,7 +35908,7 @@ _loop1_176_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_176[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop1_177[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -35848,7 +35931,7 @@ _loop1_176_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_176[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_177[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -35870,9 +35953,9 @@ _loop1_176_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_177: ')' | ','
+// _tmp_178: ')' | ','
 static void *
-_tmp_177_rule(Parser *p)
+_tmp_178_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35888,18 +35971,18 @@ _tmp_177_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_177[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
+        D(fprintf(stderr, "%*c> _tmp_178[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_177[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
+            D(fprintf(stderr, "%*c+ _tmp_178[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_177[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_178[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "')'"));
     }
     { // ','
@@ -35907,18 +35990,18 @@ _tmp_177_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_177[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_178[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_177[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_178[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_177[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_178[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     _res = NULL;
@@ -35927,9 +36010,9 @@ _tmp_177_rule(Parser *p)
     return _res;
 }
 
-// _tmp_178: ')' | ',' (')' | '**')
+// _tmp_179: ')' | ',' (')' | '**')
 static void *
-_tmp_178_rule(Parser *p)
+_tmp_179_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -35945,18 +36028,18 @@ _tmp_178_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_178[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
+        D(fprintf(stderr, "%*c> _tmp_179[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_178[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
+            D(fprintf(stderr, "%*c+ _tmp_179[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_178[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_179[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "')'"));
     }
     { // ',' (')' | '**')
@@ -35964,21 +36047,21 @@ _tmp_178_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_178[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (')' | '**')"));
+        D(fprintf(stderr, "%*c> _tmp_179[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (')' | '**')"));
         Token * _literal;
-        void *_tmp_264_var;
+        void *_tmp_266_var;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (_tmp_264_var = _tmp_264_rule(p))  // ')' | '**'
+            (_tmp_266_var = _tmp_266_rule(p))  // ')' | '**'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_178[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' (')' | '**')"));
-            _res = _PyPegen_dummy_name(p, _literal, _tmp_264_var);
+            D(fprintf(stderr, "%*c+ _tmp_179[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' (')' | '**')"));
+            _res = _PyPegen_dummy_name(p, _literal, _tmp_266_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_178[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_179[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (')' | '**')"));
     }
     _res = NULL;
@@ -35987,9 +36070,9 @@ _tmp_178_rule(Parser *p)
     return _res;
 }
 
-// _tmp_179: param_no_default | ','
+// _tmp_180: param_no_default | ','
 static void *
-_tmp_179_rule(Parser *p)
+_tmp_180_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36005,18 +36088,18 @@ _tmp_179_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_179[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_180[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         if (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_179[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_180[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_no_default"));
             _res = param_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_179[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_180[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     { // ','
@@ -36024,18 +36107,18 @@ _tmp_179_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_179[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_180[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_179[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_180[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_179[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_180[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     _res = NULL;
@@ -36044,9 +36127,9 @@ _tmp_179_rule(Parser *p)
     return _res;
 }
 
-// _loop0_180: param_maybe_default
+// _loop0_181: param_maybe_default
 static asdl_seq *
-_loop0_180_rule(Parser *p)
+_loop0_181_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36071,7 +36154,7 @@ _loop0_180_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_180[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_181[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_maybe_default"));
         NameDefaultPair* param_maybe_default_var;
         while (
             (param_maybe_default_var = param_maybe_default_rule(p))  // param_maybe_default
@@ -36094,7 +36177,7 @@ _loop0_180_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_180[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_181[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36111,9 +36194,9 @@ _loop0_180_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_181: param_no_default | ','
+// _tmp_182: param_no_default | ','
 static void *
-_tmp_181_rule(Parser *p)
+_tmp_182_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36129,18 +36212,18 @@ _tmp_181_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_181[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_182[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_no_default"));
         arg_ty param_no_default_var;
         if (
             (param_no_default_var = param_no_default_rule(p))  // param_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_181[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_182[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "param_no_default"));
             _res = param_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_181[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_182[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_no_default"));
     }
     { // ','
@@ -36148,18 +36231,18 @@ _tmp_181_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_181[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_182[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_181[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_182[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_181[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_182[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     _res = NULL;
@@ -36168,9 +36251,9 @@ _tmp_181_rule(Parser *p)
     return _res;
 }
 
-// _tmp_182: '*' | '**' | '/'
+// _tmp_183: '*' | '**' | '/'
 static void *
-_tmp_182_rule(Parser *p)
+_tmp_183_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36186,18 +36269,18 @@ _tmp_182_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_182[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*'"));
+        D(fprintf(stderr, "%*c> _tmp_183[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_182[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*'"));
+            D(fprintf(stderr, "%*c+ _tmp_183[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_182[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_183[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'*'"));
     }
     { // '**'
@@ -36205,18 +36288,18 @@ _tmp_182_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_182[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
+        D(fprintf(stderr, "%*c> _tmp_183[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 35))  // token='**'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_182[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
+            D(fprintf(stderr, "%*c+ _tmp_183[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_182[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_183[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'**'"));
     }
     { // '/'
@@ -36224,18 +36307,18 @@ _tmp_182_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_182[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'/'"));
+        D(fprintf(stderr, "%*c> _tmp_183[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'/'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_182[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'/'"));
+            D(fprintf(stderr, "%*c+ _tmp_183[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'/'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_182[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_183[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'/'"));
     }
     _res = NULL;
@@ -36244,9 +36327,9 @@ _tmp_182_rule(Parser *p)
     return _res;
 }
 
-// _loop1_183: param_with_default
+// _loop1_184: param_with_default
 static asdl_seq *
-_loop1_183_rule(Parser *p)
+_loop1_184_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36271,7 +36354,7 @@ _loop1_183_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_183[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_184[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "param_with_default"));
         NameDefaultPair* param_with_default_var;
         while (
             (param_with_default_var = param_with_default_rule(p))  // param_with_default
@@ -36294,7 +36377,7 @@ _loop1_183_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_183[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_184[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -36316,9 +36399,9 @@ _loop1_183_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_184: lambda_slash_no_default | lambda_slash_with_default
+// _tmp_185: lambda_slash_no_default | lambda_slash_with_default
 static void *
-_tmp_184_rule(Parser *p)
+_tmp_185_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36334,18 +36417,18 @@ _tmp_184_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_184[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_185[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
         asdl_arg_seq* lambda_slash_no_default_var;
         if (
             (lambda_slash_no_default_var = lambda_slash_no_default_rule(p))  // lambda_slash_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_184[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_185[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
             _res = lambda_slash_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_184[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_185[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_slash_no_default"));
     }
     { // lambda_slash_with_default
@@ -36353,18 +36436,18 @@ _tmp_184_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_184[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
+        D(fprintf(stderr, "%*c> _tmp_185[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
         SlashWithDefault* lambda_slash_with_default_var;
         if (
             (lambda_slash_with_default_var = lambda_slash_with_default_rule(p))  // lambda_slash_with_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_184[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
+            D(fprintf(stderr, "%*c+ _tmp_185[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
             _res = lambda_slash_with_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_184[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_185[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_slash_with_default"));
     }
     _res = NULL;
@@ -36373,9 +36456,9 @@ _tmp_184_rule(Parser *p)
     return _res;
 }
 
-// _loop0_185: lambda_param_maybe_default
+// _loop0_186: lambda_param_maybe_default
 static asdl_seq *
-_loop0_185_rule(Parser *p)
+_loop0_186_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36400,7 +36483,7 @@ _loop0_185_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_185[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_186[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -36423,7 +36506,7 @@ _loop0_185_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_185[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_186[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36440,9 +36523,9 @@ _loop0_185_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_186: lambda_param_no_default
+// _loop0_187: lambda_param_no_default
 static asdl_seq *
-_loop0_186_rule(Parser *p)
+_loop0_187_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36467,7 +36550,7 @@ _loop0_186_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_186[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_187[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -36490,7 +36573,7 @@ _loop0_186_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_186[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_187[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36507,9 +36590,9 @@ _loop0_186_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_187: lambda_param_no_default
+// _loop0_188: lambda_param_no_default
 static asdl_seq *
-_loop0_187_rule(Parser *p)
+_loop0_188_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36534,7 +36617,7 @@ _loop0_187_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_187[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _loop0_188[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         while (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
@@ -36557,7 +36640,7 @@ _loop0_187_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_187[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_188[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36574,9 +36657,9 @@ _loop0_187_rule(Parser *p)
     return _seq;
 }
 
-// _loop0_189: ',' lambda_param
+// _loop0_190: ',' lambda_param
 static asdl_seq *
-_loop0_189_rule(Parser *p)
+_loop0_190_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36601,7 +36684,7 @@ _loop0_189_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_189[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' lambda_param"));
+        D(fprintf(stderr, "%*c> _loop0_190[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' lambda_param"));
         Token * _literal;
         arg_ty elem;
         while (
@@ -36633,7 +36716,7 @@ _loop0_189_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_189[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_190[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' lambda_param"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36650,9 +36733,9 @@ _loop0_189_rule(Parser *p)
     return _seq;
 }
 
-// _gather_188: lambda_param _loop0_189
+// _gather_189: lambda_param _loop0_190
 static asdl_seq *
-_gather_188_rule(Parser *p)
+_gather_189_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36663,27 +36746,27 @@ _gather_188_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // lambda_param _loop0_189
+    { // lambda_param _loop0_190
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_188[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param _loop0_189"));
+        D(fprintf(stderr, "%*c> _gather_189[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param _loop0_190"));
         arg_ty elem;
         asdl_seq * seq;
         if (
             (elem = lambda_param_rule(p))  // lambda_param
             &&
-            (seq = _loop0_189_rule(p))  // _loop0_189
+            (seq = _loop0_190_rule(p))  // _loop0_190
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_188[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param _loop0_189"));
+            D(fprintf(stderr, "%*c+ _gather_189[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param _loop0_190"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_188[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param _loop0_189"));
+        D(fprintf(stderr, "%*c%s _gather_189[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param _loop0_190"));
     }
     _res = NULL;
   done:
@@ -36691,9 +36774,9 @@ _gather_188_rule(Parser *p)
     return _res;
 }
 
-// _tmp_190: lambda_slash_no_default | lambda_slash_with_default
+// _tmp_191: lambda_slash_no_default | lambda_slash_with_default
 static void *
-_tmp_190_rule(Parser *p)
+_tmp_191_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36709,18 +36792,18 @@ _tmp_190_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_190[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_191[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
         asdl_arg_seq* lambda_slash_no_default_var;
         if (
             (lambda_slash_no_default_var = lambda_slash_no_default_rule(p))  // lambda_slash_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_190[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_191[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_no_default"));
             _res = lambda_slash_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_190[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_191[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_slash_no_default"));
     }
     { // lambda_slash_with_default
@@ -36728,18 +36811,18 @@ _tmp_190_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_190[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
+        D(fprintf(stderr, "%*c> _tmp_191[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
         SlashWithDefault* lambda_slash_with_default_var;
         if (
             (lambda_slash_with_default_var = lambda_slash_with_default_rule(p))  // lambda_slash_with_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_190[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
+            D(fprintf(stderr, "%*c+ _tmp_191[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_slash_with_default"));
             _res = lambda_slash_with_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_190[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_191[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_slash_with_default"));
     }
     _res = NULL;
@@ -36748,9 +36831,9 @@ _tmp_190_rule(Parser *p)
     return _res;
 }
 
-// _loop0_191: lambda_param_maybe_default
+// _loop0_192: lambda_param_maybe_default
 static asdl_seq *
-_loop0_191_rule(Parser *p)
+_loop0_192_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36775,7 +36858,7 @@ _loop0_191_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_191[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_192[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -36798,7 +36881,7 @@ _loop0_191_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_191[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_192[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36815,9 +36898,9 @@ _loop0_191_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_192: ',' | lambda_param_no_default
+// _tmp_193: ',' | lambda_param_no_default
 static void *
-_tmp_192_rule(Parser *p)
+_tmp_193_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36833,18 +36916,18 @@ _tmp_192_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_192[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_193[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_192[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_193[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_192[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_193[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     { // lambda_param_no_default
@@ -36852,18 +36935,18 @@ _tmp_192_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_192[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_193[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         if (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_192[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_193[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
             _res = lambda_param_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_192[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_193[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     _res = NULL;
@@ -36872,9 +36955,9 @@ _tmp_192_rule(Parser *p)
     return _res;
 }
 
-// _loop0_193: lambda_param_maybe_default
+// _loop0_194: lambda_param_maybe_default
 static asdl_seq *
-_loop0_193_rule(Parser *p)
+_loop0_194_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36899,7 +36982,7 @@ _loop0_193_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_193[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_194[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -36922,7 +37005,7 @@ _loop0_193_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_193[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_194[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -36939,9 +37022,9 @@ _loop0_193_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_194: lambda_param_maybe_default
+// _loop1_195: lambda_param_maybe_default
 static asdl_seq *
-_loop1_194_rule(Parser *p)
+_loop1_195_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -36966,7 +37049,7 @@ _loop1_194_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_194[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop1_195[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -36989,7 +37072,7 @@ _loop1_194_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_194[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_195[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -37011,9 +37094,9 @@ _loop1_194_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_195: lambda_param_with_default
+// _loop1_196: lambda_param_with_default
 static asdl_seq *
-_loop1_195_rule(Parser *p)
+_loop1_196_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37038,7 +37121,7 @@ _loop1_195_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_195[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
+        D(fprintf(stderr, "%*c> _loop1_196[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_with_default"));
         NameDefaultPair* lambda_param_with_default_var;
         while (
             (lambda_param_with_default_var = lambda_param_with_default_rule(p))  // lambda_param_with_default
@@ -37061,7 +37144,7 @@ _loop1_195_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_195[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_196[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_with_default"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -37083,9 +37166,9 @@ _loop1_195_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_196: ':' | ',' (':' | '**')
+// _tmp_197: ':' | ',' (':' | '**')
 static void *
-_tmp_196_rule(Parser *p)
+_tmp_197_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37101,18 +37184,18 @@ _tmp_196_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_196[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_197[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_196[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_197[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_196[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_197[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     { // ',' (':' | '**')
@@ -37120,21 +37203,21 @@ _tmp_196_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_196[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (':' | '**')"));
+        D(fprintf(stderr, "%*c> _tmp_197[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (':' | '**')"));
         Token * _literal;
-        void *_tmp_265_var;
+        void *_tmp_267_var;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (_tmp_265_var = _tmp_265_rule(p))  // ':' | '**'
+            (_tmp_267_var = _tmp_267_rule(p))  // ':' | '**'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_196[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' (':' | '**')"));
-            _res = _PyPegen_dummy_name(p, _literal, _tmp_265_var);
+            D(fprintf(stderr, "%*c+ _tmp_197[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' (':' | '**')"));
+            _res = _PyPegen_dummy_name(p, _literal, _tmp_267_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_196[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_197[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (':' | '**')"));
     }
     _res = NULL;
@@ -37143,9 +37226,9 @@ _tmp_196_rule(Parser *p)
     return _res;
 }
 
-// _tmp_197: lambda_param_no_default | ','
+// _tmp_198: lambda_param_no_default | ','
 static void *
-_tmp_197_rule(Parser *p)
+_tmp_198_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37161,18 +37244,18 @@ _tmp_197_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_197[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_198[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         if (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_197[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_198[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
             _res = lambda_param_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_197[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_198[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     { // ','
@@ -37180,18 +37263,18 @@ _tmp_197_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_197[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_198[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_197[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_198[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_197[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_198[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     _res = NULL;
@@ -37200,9 +37283,9 @@ _tmp_197_rule(Parser *p)
     return _res;
 }
 
-// _loop0_198: lambda_param_maybe_default
+// _loop0_199: lambda_param_maybe_default
 static asdl_seq *
-_loop0_198_rule(Parser *p)
+_loop0_199_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37227,7 +37310,7 @@ _loop0_198_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_198[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
+        D(fprintf(stderr, "%*c> _loop0_199[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_maybe_default"));
         NameDefaultPair* lambda_param_maybe_default_var;
         while (
             (lambda_param_maybe_default_var = lambda_param_maybe_default_rule(p))  // lambda_param_maybe_default
@@ -37250,7 +37333,7 @@ _loop0_198_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_198[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_199[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_maybe_default"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -37267,9 +37350,9 @@ _loop0_198_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_199: lambda_param_no_default | ','
+// _tmp_200: lambda_param_no_default | ','
 static void *
-_tmp_199_rule(Parser *p)
+_tmp_200_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37285,18 +37368,18 @@ _tmp_199_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_199[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+        D(fprintf(stderr, "%*c> _tmp_200[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
         arg_ty lambda_param_no_default_var;
         if (
             (lambda_param_no_default_var = lambda_param_no_default_rule(p))  // lambda_param_no_default
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_199[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
+            D(fprintf(stderr, "%*c+ _tmp_200[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "lambda_param_no_default"));
             _res = lambda_param_no_default_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_199[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_200[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "lambda_param_no_default"));
     }
     { // ','
@@ -37304,18 +37387,18 @@ _tmp_199_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_199[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_200[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_199[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_200[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_199[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_200[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     _res = NULL;
@@ -37324,9 +37407,9 @@ _tmp_199_rule(Parser *p)
     return _res;
 }
 
-// _tmp_200: '*' | '**' | '/'
+// _tmp_201: '*' | '**' | '/'
 static void *
-_tmp_200_rule(Parser *p)
+_tmp_201_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37342,18 +37425,18 @@ _tmp_200_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_200[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*'"));
+        D(fprintf(stderr, "%*c> _tmp_201[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'*'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 16))  // token='*'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_200[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*'"));
+            D(fprintf(stderr, "%*c+ _tmp_201[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'*'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_200[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_201[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'*'"));
     }
     { // '**'
@@ -37361,18 +37444,18 @@ _tmp_200_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_200[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
+        D(fprintf(stderr, "%*c> _tmp_201[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 35))  // token='**'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_200[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
+            D(fprintf(stderr, "%*c+ _tmp_201[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_200[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_201[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'**'"));
     }
     { // '/'
@@ -37380,18 +37463,18 @@ _tmp_200_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_200[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'/'"));
+        D(fprintf(stderr, "%*c> _tmp_201[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'/'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 17))  // token='/'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_200[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'/'"));
+            D(fprintf(stderr, "%*c+ _tmp_201[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'/'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_200[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_201[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'/'"));
     }
     _res = NULL;
@@ -37400,9 +37483,9 @@ _tmp_200_rule(Parser *p)
     return _res;
 }
 
-// _tmp_201: ',' | ')' | ':'
+// _tmp_202: ',' | ')' | ':'
 static void *
-_tmp_201_rule(Parser *p)
+_tmp_202_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37418,18 +37501,18 @@ _tmp_201_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_201[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c> _tmp_202[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_201[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            D(fprintf(stderr, "%*c+ _tmp_202[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_201[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_202[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     { // ')'
@@ -37437,18 +37520,18 @@ _tmp_201_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_201[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
+        D(fprintf(stderr, "%*c> _tmp_202[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_201[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
+            D(fprintf(stderr, "%*c+ _tmp_202[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_201[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_202[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "')'"));
     }
     { // ':'
@@ -37456,18 +37539,18 @@ _tmp_201_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_201[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_202[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_201[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_202[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_201[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_202[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     _res = NULL;
@@ -37476,9 +37559,9 @@ _tmp_201_rule(Parser *p)
     return _res;
 }
 
-// _loop0_203: ',' dotted_name
+// _loop0_204: ',' dotted_name
 static asdl_seq *
-_loop0_203_rule(Parser *p)
+_loop0_204_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37503,7 +37586,7 @@ _loop0_203_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_203[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' dotted_name"));
+        D(fprintf(stderr, "%*c> _loop0_204[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' dotted_name"));
         Token * _literal;
         expr_ty elem;
         while (
@@ -37535,7 +37618,7 @@ _loop0_203_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_203[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_204[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' dotted_name"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -37552,9 +37635,9 @@ _loop0_203_rule(Parser *p)
     return _seq;
 }
 
-// _gather_202: dotted_name _loop0_203
+// _gather_203: dotted_name _loop0_204
 static asdl_seq *
-_gather_202_rule(Parser *p)
+_gather_203_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37565,27 +37648,27 @@ _gather_202_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // dotted_name _loop0_203
+    { // dotted_name _loop0_204
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_202[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dotted_name _loop0_203"));
+        D(fprintf(stderr, "%*c> _gather_203[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "dotted_name _loop0_204"));
         expr_ty elem;
         asdl_seq * seq;
         if (
             (elem = dotted_name_rule(p))  // dotted_name
             &&
-            (seq = _loop0_203_rule(p))  // _loop0_203
+            (seq = _loop0_204_rule(p))  // _loop0_204
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_202[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dotted_name _loop0_203"));
+            D(fprintf(stderr, "%*c+ _gather_203[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "dotted_name _loop0_204"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_202[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "dotted_name _loop0_203"));
+        D(fprintf(stderr, "%*c%s _gather_203[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "dotted_name _loop0_204"));
     }
     _res = NULL;
   done:
@@ -37593,9 +37676,9 @@ _gather_202_rule(Parser *p)
     return _res;
 }
 
-// _loop0_205: ',' (expression ['as' star_target])
+// _loop0_206: ',' (expression ['as' star_target])
 static asdl_seq *
-_loop0_205_rule(Parser *p)
+_loop0_206_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37620,13 +37703,13 @@ _loop0_205_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_205[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expression ['as' star_target])"));
+        D(fprintf(stderr, "%*c> _loop0_206[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expression ['as' star_target])"));
         Token * _literal;
         void *elem;
         while (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (elem = _tmp_266_rule(p))  // expression ['as' star_target]
+            (elem = _tmp_268_rule(p))  // expression ['as' star_target]
         )
         {
             _res = elem;
@@ -37652,7 +37735,7 @@ _loop0_205_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_205[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_206[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (expression ['as' star_target])"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -37669,9 +37752,9 @@ _loop0_205_rule(Parser *p)
     return _seq;
 }
 
-// _gather_204: (expression ['as' star_target]) _loop0_205
+// _gather_205: (expression ['as' star_target]) _loop0_206
 static asdl_seq *
-_gather_204_rule(Parser *p)
+_gather_205_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37682,27 +37765,27 @@ _gather_204_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // (expression ['as' star_target]) _loop0_205
+    { // (expression ['as' star_target]) _loop0_206
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_204[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_205"));
+        D(fprintf(stderr, "%*c> _gather_205[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_206"));
         void *elem;
         asdl_seq * seq;
         if (
-            (elem = _tmp_266_rule(p))  // expression ['as' star_target]
+            (elem = _tmp_268_rule(p))  // expression ['as' star_target]
             &&
-            (seq = _loop0_205_rule(p))  // _loop0_205
+            (seq = _loop0_206_rule(p))  // _loop0_206
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_204[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_205"));
+            D(fprintf(stderr, "%*c+ _gather_205[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_206"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_204[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expression ['as' star_target]) _loop0_205"));
+        D(fprintf(stderr, "%*c%s _gather_205[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expression ['as' star_target]) _loop0_206"));
     }
     _res = NULL;
   done:
@@ -37710,9 +37793,9 @@ _gather_204_rule(Parser *p)
     return _res;
 }
 
-// _loop0_207: ',' (expressions ['as' star_target])
+// _loop0_208: ',' (expressions ['as' star_target])
 static asdl_seq *
-_loop0_207_rule(Parser *p)
+_loop0_208_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37737,13 +37820,13 @@ _loop0_207_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_207[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expressions ['as' star_target])"));
+        D(fprintf(stderr, "%*c> _loop0_208[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expressions ['as' star_target])"));
         Token * _literal;
         void *elem;
         while (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (elem = _tmp_267_rule(p))  // expressions ['as' star_target]
+            (elem = _tmp_269_rule(p))  // expressions ['as' star_target]
         )
         {
             _res = elem;
@@ -37769,7 +37852,7 @@ _loop0_207_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_207[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_208[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (expressions ['as' star_target])"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -37786,9 +37869,9 @@ _loop0_207_rule(Parser *p)
     return _seq;
 }
 
-// _gather_206: (expressions ['as' star_target]) _loop0_207
+// _gather_207: (expressions ['as' star_target]) _loop0_208
 static asdl_seq *
-_gather_206_rule(Parser *p)
+_gather_207_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37799,27 +37882,27 @@ _gather_206_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // (expressions ['as' star_target]) _loop0_207
+    { // (expressions ['as' star_target]) _loop0_208
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_206[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_207"));
+        D(fprintf(stderr, "%*c> _gather_207[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_208"));
         void *elem;
         asdl_seq * seq;
         if (
-            (elem = _tmp_267_rule(p))  // expressions ['as' star_target]
+            (elem = _tmp_269_rule(p))  // expressions ['as' star_target]
             &&
-            (seq = _loop0_207_rule(p))  // _loop0_207
+            (seq = _loop0_208_rule(p))  // _loop0_208
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_206[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_207"));
+            D(fprintf(stderr, "%*c+ _gather_207[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_208"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_206[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expressions ['as' star_target]) _loop0_207"));
+        D(fprintf(stderr, "%*c%s _gather_207[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expressions ['as' star_target]) _loop0_208"));
     }
     _res = NULL;
   done:
@@ -37827,9 +37910,9 @@ _gather_206_rule(Parser *p)
     return _res;
 }
 
-// _loop0_209: ',' (expression ['as' star_target])
+// _loop0_210: ',' (expression ['as' star_target])
 static asdl_seq *
-_loop0_209_rule(Parser *p)
+_loop0_210_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37854,13 +37937,13 @@ _loop0_209_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_209[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expression ['as' star_target])"));
+        D(fprintf(stderr, "%*c> _loop0_210[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expression ['as' star_target])"));
         Token * _literal;
         void *elem;
         while (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (elem = _tmp_268_rule(p))  // expression ['as' star_target]
+            (elem = _tmp_270_rule(p))  // expression ['as' star_target]
         )
         {
             _res = elem;
@@ -37886,7 +37969,7 @@ _loop0_209_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_209[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_210[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (expression ['as' star_target])"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -37903,9 +37986,9 @@ _loop0_209_rule(Parser *p)
     return _seq;
 }
 
-// _gather_208: (expression ['as' star_target]) _loop0_209
+// _gather_209: (expression ['as' star_target]) _loop0_210
 static asdl_seq *
-_gather_208_rule(Parser *p)
+_gather_209_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37916,27 +37999,27 @@ _gather_208_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // (expression ['as' star_target]) _loop0_209
+    { // (expression ['as' star_target]) _loop0_210
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_208[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_209"));
+        D(fprintf(stderr, "%*c> _gather_209[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_210"));
         void *elem;
         asdl_seq * seq;
         if (
-            (elem = _tmp_268_rule(p))  // expression ['as' star_target]
+            (elem = _tmp_270_rule(p))  // expression ['as' star_target]
             &&
-            (seq = _loop0_209_rule(p))  // _loop0_209
+            (seq = _loop0_210_rule(p))  // _loop0_210
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_208[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_209"));
+            D(fprintf(stderr, "%*c+ _gather_209[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expression ['as' star_target]) _loop0_210"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_208[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expression ['as' star_target]) _loop0_209"));
+        D(fprintf(stderr, "%*c%s _gather_209[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expression ['as' star_target]) _loop0_210"));
     }
     _res = NULL;
   done:
@@ -37944,9 +38027,9 @@ _gather_208_rule(Parser *p)
     return _res;
 }
 
-// _loop0_211: ',' (expressions ['as' star_target])
+// _loop0_212: ',' (expressions ['as' star_target])
 static asdl_seq *
-_loop0_211_rule(Parser *p)
+_loop0_212_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -37971,13 +38054,13 @@ _loop0_211_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_211[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expressions ['as' star_target])"));
+        D(fprintf(stderr, "%*c> _loop0_212[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (expressions ['as' star_target])"));
         Token * _literal;
         void *elem;
         while (
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
             &&
-            (elem = _tmp_269_rule(p))  // expressions ['as' star_target]
+            (elem = _tmp_271_rule(p))  // expressions ['as' star_target]
         )
         {
             _res = elem;
@@ -38003,7 +38086,7 @@ _loop0_211_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_211[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_212[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (expressions ['as' star_target])"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -38020,9 +38103,9 @@ _loop0_211_rule(Parser *p)
     return _seq;
 }
 
-// _gather_210: (expressions ['as' star_target]) _loop0_211
+// _gather_211: (expressions ['as' star_target]) _loop0_212
 static asdl_seq *
-_gather_210_rule(Parser *p)
+_gather_211_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38033,27 +38116,27 @@ _gather_210_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // (expressions ['as' star_target]) _loop0_211
+    { // (expressions ['as' star_target]) _loop0_212
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_210[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_211"));
+        D(fprintf(stderr, "%*c> _gather_211[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_212"));
         void *elem;
         asdl_seq * seq;
         if (
-            (elem = _tmp_269_rule(p))  // expressions ['as' star_target]
+            (elem = _tmp_271_rule(p))  // expressions ['as' star_target]
             &&
-            (seq = _loop0_211_rule(p))  // _loop0_211
+            (seq = _loop0_212_rule(p))  // _loop0_212
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_210[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_211"));
+            D(fprintf(stderr, "%*c+ _gather_211[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(expressions ['as' star_target]) _loop0_212"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_210[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expressions ['as' star_target]) _loop0_211"));
+        D(fprintf(stderr, "%*c%s _gather_211[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(expressions ['as' star_target]) _loop0_212"));
     }
     _res = NULL;
   done:
@@ -38061,9 +38144,9 @@ _gather_210_rule(Parser *p)
     return _res;
 }
 
-// _tmp_212: 'except' | 'finally'
+// _tmp_213: 'except' | 'finally'
 static void *
-_tmp_212_rule(Parser *p)
+_tmp_213_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38079,18 +38162,18 @@ _tmp_212_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_212[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'except'"));
+        D(fprintf(stderr, "%*c> _tmp_213[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'except'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 637))  // token='except'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_212[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'except'"));
+            D(fprintf(stderr, "%*c+ _tmp_213[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'except'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_212[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_213[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'except'"));
     }
     { // 'finally'
@@ -38098,18 +38181,18 @@ _tmp_212_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_212[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'finally'"));
+        D(fprintf(stderr, "%*c> _tmp_213[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'finally'"));
         Token * _keyword;
         if (
             (_keyword = _PyPegen_expect_token(p, 633))  // token='finally'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_212[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'finally'"));
+            D(fprintf(stderr, "%*c+ _tmp_213[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'finally'"));
             _res = _keyword;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_212[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_213[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'finally'"));
     }
     _res = NULL;
@@ -38118,9 +38201,9 @@ _tmp_212_rule(Parser *p)
     return _res;
 }
 
-// _loop0_213: block
+// _loop0_214: block
 static asdl_seq *
-_loop0_213_rule(Parser *p)
+_loop0_214_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38145,7 +38228,7 @@ _loop0_213_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_213[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "block"));
+        D(fprintf(stderr, "%*c> _loop0_214[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "block"));
         asdl_stmt_seq* block_var;
         while (
             (block_var = block_rule(p))  // block
@@ -38168,7 +38251,7 @@ _loop0_213_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_213[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_214[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "block"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -38185,9 +38268,9 @@ _loop0_213_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_214: except_block
+// _loop1_215: except_block
 static asdl_seq *
-_loop1_214_rule(Parser *p)
+_loop1_215_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38212,7 +38295,7 @@ _loop1_214_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_214[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_block"));
+        D(fprintf(stderr, "%*c> _loop1_215[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_block"));
         excepthandler_ty except_block_var;
         while (
             (except_block_var = except_block_rule(p))  // except_block
@@ -38235,7 +38318,7 @@ _loop1_214_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_214[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_215[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "except_block"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -38257,9 +38340,9 @@ _loop1_214_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_215: 'as' NAME
+// _tmp_216: 'as' NAME
 static void *
-_tmp_215_rule(Parser *p)
+_tmp_216_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38275,7 +38358,7 @@ _tmp_215_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_215[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_216[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty name_var;
         if (
@@ -38284,12 +38367,12 @@ _tmp_215_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_215[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_216[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = _PyPegen_dummy_name(p, _keyword, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_215[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_216[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -38298,9 +38381,9 @@ _tmp_215_rule(Parser *p)
     return _res;
 }
 
-// _loop0_216: block
+// _loop0_217: block
 static asdl_seq *
-_loop0_216_rule(Parser *p)
+_loop0_217_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38325,7 +38408,7 @@ _loop0_216_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_216[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "block"));
+        D(fprintf(stderr, "%*c> _loop0_217[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "block"));
         asdl_stmt_seq* block_var;
         while (
             (block_var = block_rule(p))  // block
@@ -38348,7 +38431,7 @@ _loop0_216_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_216[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_217[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "block"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -38365,9 +38448,9 @@ _loop0_216_rule(Parser *p)
     return _seq;
 }
 
-// _loop1_217: except_star_block
+// _loop1_218: except_star_block
 static asdl_seq *
-_loop1_217_rule(Parser *p)
+_loop1_218_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38392,7 +38475,7 @@ _loop1_217_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop1_217[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_star_block"));
+        D(fprintf(stderr, "%*c> _loop1_218[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "except_star_block"));
         excepthandler_ty except_star_block_var;
         while (
             (except_star_block_var = except_star_block_rule(p))  // except_star_block
@@ -38415,7 +38498,7 @@ _loop1_217_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop1_217[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop1_218[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "except_star_block"));
     }
     if (_n == 0 || p->error_indicator) {
@@ -38437,9 +38520,9 @@ _loop1_217_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_218: expression ['as' NAME]
+// _tmp_219: expression ['as' NAME]
 static void *
-_tmp_218_rule(Parser *p)
+_tmp_219_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38455,22 +38538,22 @@ _tmp_218_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_218[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression ['as' NAME]"));
+        D(fprintf(stderr, "%*c> _tmp_219[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression ['as' NAME]"));
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         expr_ty expression_var;
         if (
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var = _tmp_270_rule(p), !p->error_indicator)  // ['as' NAME]
+            (_opt_var = _tmp_272_rule(p), !p->error_indicator)  // ['as' NAME]
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_218[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ['as' NAME]"));
+            D(fprintf(stderr, "%*c+ _tmp_219[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ['as' NAME]"));
             _res = _PyPegen_dummy_name(p, expression_var, _opt_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_218[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_219[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expression ['as' NAME]"));
     }
     _res = NULL;
@@ -38479,9 +38562,9 @@ _tmp_218_rule(Parser *p)
     return _res;
 }
 
-// _tmp_219: 'as' NAME
+// _tmp_220: 'as' NAME
 static void *
-_tmp_219_rule(Parser *p)
+_tmp_220_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38497,7 +38580,7 @@ _tmp_219_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_219[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_220[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty name_var;
         if (
@@ -38506,12 +38589,12 @@ _tmp_219_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_219[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_220[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = _PyPegen_dummy_name(p, _keyword, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_219[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_220[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -38520,9 +38603,9 @@ _tmp_219_rule(Parser *p)
     return _res;
 }
 
-// _tmp_220: 'as' NAME
+// _tmp_221: 'as' NAME
 static void *
-_tmp_220_rule(Parser *p)
+_tmp_221_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38538,7 +38621,7 @@ _tmp_220_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_220[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_221[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty name_var;
         if (
@@ -38547,12 +38630,12 @@ _tmp_220_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_220[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_221[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = _PyPegen_dummy_name(p, _keyword, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_220[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_221[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -38561,9 +38644,9 @@ _tmp_220_rule(Parser *p)
     return _res;
 }
 
-// _tmp_221: NEWLINE | ':'
+// _tmp_222: NEWLINE | ':'
 static void *
-_tmp_221_rule(Parser *p)
+_tmp_222_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38579,18 +38662,18 @@ _tmp_221_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_221[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
+        D(fprintf(stderr, "%*c> _tmp_222[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
         Token * newline_var;
         if (
             (newline_var = _PyPegen_expect_token(p, NEWLINE))  // token='NEWLINE'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_221[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
+            D(fprintf(stderr, "%*c+ _tmp_222[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "NEWLINE"));
             _res = newline_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_221[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_222[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "NEWLINE"));
     }
     { // ':'
@@ -38598,18 +38681,18 @@ _tmp_221_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_221[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_222[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_221[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_222[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_221[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_222[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     _res = NULL;
@@ -38618,9 +38701,9 @@ _tmp_221_rule(Parser *p)
     return _res;
 }
 
-// _tmp_222: 'as' NAME
+// _tmp_223: 'as' NAME
 static void *
-_tmp_222_rule(Parser *p)
+_tmp_223_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38636,7 +38719,7 @@ _tmp_222_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_222[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_223[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty name_var;
         if (
@@ -38645,12 +38728,12 @@ _tmp_222_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_222[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_223[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = _PyPegen_dummy_name(p, _keyword, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_222[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_223[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -38659,9 +38742,9 @@ _tmp_222_rule(Parser *p)
     return _res;
 }
 
-// _tmp_223: 'as' NAME
+// _tmp_224: 'as' NAME
 static void *
-_tmp_223_rule(Parser *p)
+_tmp_224_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38677,7 +38760,7 @@ _tmp_223_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_223[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_224[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty name_var;
         if (
@@ -38686,12 +38769,12 @@ _tmp_223_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_223[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_224[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = _PyPegen_dummy_name(p, _keyword, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_223[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_224[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -38700,9 +38783,9 @@ _tmp_223_rule(Parser *p)
     return _res;
 }
 
-// _tmp_224: positional_patterns ','
+// _tmp_225: positional_patterns ','
 static void *
-_tmp_224_rule(Parser *p)
+_tmp_225_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38718,7 +38801,7 @@ _tmp_224_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_224[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "positional_patterns ','"));
+        D(fprintf(stderr, "%*c> _tmp_225[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "positional_patterns ','"));
         Token * _literal;
         asdl_pattern_seq* positional_patterns_var;
         if (
@@ -38727,12 +38810,12 @@ _tmp_224_rule(Parser *p)
             (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_224[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "positional_patterns ','"));
+            D(fprintf(stderr, "%*c+ _tmp_225[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "positional_patterns ','"));
             _res = _PyPegen_dummy_name(p, positional_patterns_var, _literal);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_224[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_225[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "positional_patterns ','"));
     }
     _res = NULL;
@@ -38741,9 +38824,9 @@ _tmp_224_rule(Parser *p)
     return _res;
 }
 
-// _tmp_225: '->' expression
+// _tmp_226: '->' expression
 static void *
-_tmp_225_rule(Parser *p)
+_tmp_226_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38759,7 +38842,7 @@ _tmp_225_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_225[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'->' expression"));
+        D(fprintf(stderr, "%*c> _tmp_226[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'->' expression"));
         Token * _literal;
         expr_ty expression_var;
         if (
@@ -38768,12 +38851,12 @@ _tmp_225_rule(Parser *p)
             (expression_var = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_225[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'->' expression"));
+            D(fprintf(stderr, "%*c+ _tmp_226[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'->' expression"));
             _res = _PyPegen_dummy_name(p, _literal, expression_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_225[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_226[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'->' expression"));
     }
     _res = NULL;
@@ -38782,9 +38865,9 @@ _tmp_225_rule(Parser *p)
     return _res;
 }
 
-// _tmp_226: '(' arguments? ')'
+// _tmp_227: '(' arguments? ')'
 static void *
-_tmp_226_rule(Parser *p)
+_tmp_227_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38800,7 +38883,7 @@ _tmp_226_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_226[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
+        D(fprintf(stderr, "%*c> _tmp_227[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
         Token * _literal;
         Token * _literal_1;
         void *_opt_var;
@@ -38813,12 +38896,12 @@ _tmp_226_rule(Parser *p)
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_226[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
+            D(fprintf(stderr, "%*c+ _tmp_227[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
             _res = _PyPegen_dummy_name(p, _literal, _opt_var, _literal_1);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_226[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_227[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'(' arguments? ')'"));
     }
     _res = NULL;
@@ -38827,9 +38910,9 @@ _tmp_226_rule(Parser *p)
     return _res;
 }
 
-// _tmp_227: '(' arguments? ')'
+// _tmp_228: '(' arguments? ')'
 static void *
-_tmp_227_rule(Parser *p)
+_tmp_228_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38845,7 +38928,7 @@ _tmp_227_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_227[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
+        D(fprintf(stderr, "%*c> _tmp_228[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
         Token * _literal;
         Token * _literal_1;
         void *_opt_var;
@@ -38858,12 +38941,12 @@ _tmp_227_rule(Parser *p)
             (_literal_1 = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_227[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
+            D(fprintf(stderr, "%*c+ _tmp_228[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'(' arguments? ')'"));
             _res = _PyPegen_dummy_name(p, _literal, _opt_var, _literal_1);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_227[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_228[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'(' arguments? ')'"));
     }
     _res = NULL;
@@ -38872,9 +38955,9 @@ _tmp_227_rule(Parser *p)
     return _res;
 }
 
-// _loop0_229: ',' double_starred_kvpair
+// _loop0_230: ',' double_starred_kvpair
 static asdl_seq *
-_loop0_229_rule(Parser *p)
+_loop0_230_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38899,7 +38982,7 @@ _loop0_229_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_229[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' double_starred_kvpair"));
+        D(fprintf(stderr, "%*c> _loop0_230[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' double_starred_kvpair"));
         Token * _literal;
         KeyValuePair* elem;
         while (
@@ -38931,7 +39014,7 @@ _loop0_229_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_229[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_230[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' double_starred_kvpair"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -38948,9 +39031,9 @@ _loop0_229_rule(Parser *p)
     return _seq;
 }
 
-// _gather_228: double_starred_kvpair _loop0_229
+// _gather_229: double_starred_kvpair _loop0_230
 static asdl_seq *
-_gather_228_rule(Parser *p)
+_gather_229_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -38961,84 +39044,27 @@ _gather_228_rule(Parser *p)
     }
     asdl_seq * _res = NULL;
     int _mark = p->mark;
-    { // double_starred_kvpair _loop0_229
+    { // double_starred_kvpair _loop0_230
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _gather_228[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "double_starred_kvpair _loop0_229"));
+        D(fprintf(stderr, "%*c> _gather_229[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "double_starred_kvpair _loop0_230"));
         KeyValuePair* elem;
         asdl_seq * seq;
         if (
             (elem = double_starred_kvpair_rule(p))  // double_starred_kvpair
             &&
-            (seq = _loop0_229_rule(p))  // _loop0_229
+            (seq = _loop0_230_rule(p))  // _loop0_230
         )
         {
-            D(fprintf(stderr, "%*c+ _gather_228[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "double_starred_kvpair _loop0_229"));
+            D(fprintf(stderr, "%*c+ _gather_229[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "double_starred_kvpair _loop0_230"));
             _res = _PyPegen_seq_insert_in_front(p, elem, seq);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _gather_228[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "double_starred_kvpair _loop0_229"));
-    }
-    _res = NULL;
-  done:
-    p->level--;
-    return _res;
-}
-
-// _tmp_230: '}' | ','
-static void *
-_tmp_230_rule(Parser *p)
-{
-    if (p->level++ == MAXSTACK) {
-        _Pypegen_stack_overflow(p);
-    }
-    if (p->error_indicator) {
-        p->level--;
-        return NULL;
-    }
-    void * _res = NULL;
-    int _mark = p->mark;
-    { // '}'
-        if (p->error_indicator) {
-            p->level--;
-            return NULL;
-        }
-        D(fprintf(stderr, "%*c> _tmp_230[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
-        Token * _literal;
-        if (
-            (_literal = _PyPegen_expect_token(p, 26))  // token='}'
-        )
-        {
-            D(fprintf(stderr, "%*c+ _tmp_230[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
-            _res = _literal;
-            goto done;
-        }
-        p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_230[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'}'"));
-    }
-    { // ','
-        if (p->error_indicator) {
-            p->level--;
-            return NULL;
-        }
-        D(fprintf(stderr, "%*c> _tmp_230[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
-        Token * _literal;
-        if (
-            (_literal = _PyPegen_expect_token(p, 12))  // token=','
-        )
-        {
-            D(fprintf(stderr, "%*c+ _tmp_230[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
-            _res = _literal;
-            goto done;
-        }
-        p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_230[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
+        D(fprintf(stderr, "%*c%s _gather_229[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "double_starred_kvpair _loop0_230"));
     }
     _res = NULL;
   done:
@@ -39103,7 +39129,7 @@ _tmp_231_rule(Parser *p)
     return _res;
 }
 
-// _tmp_232: yield_expr | star_expressions
+// _tmp_232: '}' | ','
 static void *
 _tmp_232_rule(Parser *p)
 {
@@ -39116,43 +39142,43 @@ _tmp_232_rule(Parser *p)
     }
     void * _res = NULL;
     int _mark = p->mark;
-    { // yield_expr
+    { // '}'
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_232[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
-        expr_ty yield_expr_var;
+        D(fprintf(stderr, "%*c> _tmp_232[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
+        Token * _literal;
         if (
-            (yield_expr_var = yield_expr_rule(p))  // yield_expr
+            (_literal = _PyPegen_expect_token(p, 26))  // token='}'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_232[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
-            _res = yield_expr_var;
+            D(fprintf(stderr, "%*c+ _tmp_232[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
+            _res = _literal;
             goto done;
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s _tmp_232[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'}'"));
     }
-    { // star_expressions
+    { // ','
         if (p->error_indicator) {
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_232[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
-        expr_ty star_expressions_var;
+        D(fprintf(stderr, "%*c> _tmp_232[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','"));
+        Token * _literal;
         if (
-            (star_expressions_var = star_expressions_rule(p))  // star_expressions
+            (_literal = _PyPegen_expect_token(p, 12))  // token=','
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_232[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
-            _res = star_expressions_var;
+            D(fprintf(stderr, "%*c+ _tmp_232[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','"));
+            _res = _literal;
             goto done;
         }
         p->mark = _mark;
         D(fprintf(stderr, "%*c%s _tmp_232[%d-%d]: %s failed!\n", p->level, ' ',
-                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','"));
     }
     _res = NULL;
   done:
@@ -39217,9 +39243,66 @@ _tmp_233_rule(Parser *p)
     return _res;
 }
 
-// _tmp_234: '=' | '!' | ':' | '}'
+// _tmp_234: yield_expr | star_expressions
 static void *
 _tmp_234_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void * _res = NULL;
+    int _mark = p->mark;
+    { // yield_expr
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_234[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        expr_ty yield_expr_var;
+        if (
+            (yield_expr_var = yield_expr_rule(p))  // yield_expr
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_234[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            _res = yield_expr_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_234[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
+    }
+    { // star_expressions
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_234[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        expr_ty star_expressions_var;
+        if (
+            (star_expressions_var = star_expressions_rule(p))  // star_expressions
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_234[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            _res = star_expressions_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_234[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
+// _tmp_235: '=' | '!' | ':' | '}'
+static void *
+_tmp_235_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39235,18 +39318,18 @@ _tmp_234_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_234[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
+        D(fprintf(stderr, "%*c> _tmp_235[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'='"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_234[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
+            D(fprintf(stderr, "%*c+ _tmp_235[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'='"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_234[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_235[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'='"));
     }
     { // '!'
@@ -39254,18 +39337,18 @@ _tmp_234_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_234[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!'"));
+        D(fprintf(stderr, "%*c> _tmp_235[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 54))  // token='!'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_234[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!'"));
+            D(fprintf(stderr, "%*c+ _tmp_235[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_234[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_235[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'!'"));
     }
     { // ':'
@@ -39273,18 +39356,18 @@ _tmp_234_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_234[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_235[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_234[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_235[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_234[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_235[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     { // '}'
@@ -39292,18 +39375,18 @@ _tmp_234_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_234[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
+        D(fprintf(stderr, "%*c> _tmp_235[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 26))  // token='}'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_234[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
+            D(fprintf(stderr, "%*c+ _tmp_235[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_234[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_235[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'}'"));
     }
     _res = NULL;
@@ -39312,9 +39395,9 @@ _tmp_234_rule(Parser *p)
     return _res;
 }
 
-// _tmp_235: yield_expr | star_expressions
+// _tmp_236: yield_expr | star_expressions
 static void *
-_tmp_235_rule(Parser *p)
+_tmp_236_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39330,18 +39413,18 @@ _tmp_235_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_235[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_236[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_235[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_236[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_235[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_236[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -39349,18 +39432,18 @@ _tmp_235_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_235[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_236[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_235[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_236[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_235[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_236[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -39369,9 +39452,9 @@ _tmp_235_rule(Parser *p)
     return _res;
 }
 
-// _tmp_236: '!' | ':' | '}'
+// _tmp_237: '!' | ':' | '}'
 static void *
-_tmp_236_rule(Parser *p)
+_tmp_237_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39387,18 +39470,18 @@ _tmp_236_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_236[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!'"));
+        D(fprintf(stderr, "%*c> _tmp_237[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 54))  // token='!'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_236[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!'"));
+            D(fprintf(stderr, "%*c+ _tmp_237[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_236[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_237[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'!'"));
     }
     { // ':'
@@ -39406,18 +39489,18 @@ _tmp_236_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_236[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_237[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_236[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_237[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_236[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_237[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     { // '}'
@@ -39425,18 +39508,18 @@ _tmp_236_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_236[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
+        D(fprintf(stderr, "%*c> _tmp_237[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 26))  // token='}'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_236[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
+            D(fprintf(stderr, "%*c+ _tmp_237[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_236[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_237[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'}'"));
     }
     _res = NULL;
@@ -39445,9 +39528,9 @@ _tmp_236_rule(Parser *p)
     return _res;
 }
 
-// _tmp_237: yield_expr | star_expressions
+// _tmp_238: yield_expr | star_expressions
 static void *
-_tmp_237_rule(Parser *p)
+_tmp_238_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39463,18 +39546,18 @@ _tmp_237_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_237[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_238[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_237[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_238[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_237[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_238[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -39482,18 +39565,18 @@ _tmp_237_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_237[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_238[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_237[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_238[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_237[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_238[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -39502,9 +39585,9 @@ _tmp_237_rule(Parser *p)
     return _res;
 }
 
-// _tmp_238: yield_expr | star_expressions
+// _tmp_239: yield_expr | star_expressions
 static void *
-_tmp_238_rule(Parser *p)
+_tmp_239_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39520,18 +39603,18 @@ _tmp_238_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_238[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_239[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_238[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_239[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_238[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_239[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -39539,18 +39622,18 @@ _tmp_238_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_238[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_239[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_238[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_239[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_238[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_239[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -39559,9 +39642,9 @@ _tmp_238_rule(Parser *p)
     return _res;
 }
 
-// _tmp_239: '!' NAME
+// _tmp_240: '!' NAME
 static void *
-_tmp_239_rule(Parser *p)
+_tmp_240_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39577,7 +39660,7 @@ _tmp_239_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_239[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_240[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
         Token * _literal;
         expr_ty name_var;
         if (
@@ -39586,12 +39669,12 @@ _tmp_239_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_239[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_240[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
             _res = _PyPegen_dummy_name(p, _literal, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_239[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_240[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'!' NAME"));
     }
     _res = NULL;
@@ -39600,9 +39683,9 @@ _tmp_239_rule(Parser *p)
     return _res;
 }
 
-// _tmp_240: ':' | '}'
+// _tmp_241: ':' | '}'
 static void *
-_tmp_240_rule(Parser *p)
+_tmp_241_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39618,18 +39701,18 @@ _tmp_240_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_240[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_241[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_240[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_241[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_240[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_241[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     { // '}'
@@ -39637,18 +39720,18 @@ _tmp_240_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_240[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
+        D(fprintf(stderr, "%*c> _tmp_241[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 26))  // token='}'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_240[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
+            D(fprintf(stderr, "%*c+ _tmp_241[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_240[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_241[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'}'"));
     }
     _res = NULL;
@@ -39657,9 +39740,9 @@ _tmp_240_rule(Parser *p)
     return _res;
 }
 
-// _tmp_241: yield_expr | star_expressions
+// _tmp_242: yield_expr | star_expressions
 static void *
-_tmp_241_rule(Parser *p)
+_tmp_242_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39675,18 +39758,18 @@ _tmp_241_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_241[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_242[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_241[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_242[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_241[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_242[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -39694,18 +39777,18 @@ _tmp_241_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_241[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_242[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_241[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_242[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_241[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_242[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -39714,9 +39797,9 @@ _tmp_241_rule(Parser *p)
     return _res;
 }
 
-// _tmp_242: '!' NAME
+// _tmp_243: '!' NAME
 static void *
-_tmp_242_rule(Parser *p)
+_tmp_243_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39732,7 +39815,7 @@ _tmp_242_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_242[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_243[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
         Token * _literal;
         expr_ty name_var;
         if (
@@ -39741,12 +39824,12 @@ _tmp_242_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_242[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_243[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
             _res = _PyPegen_dummy_name(p, _literal, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_242[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_243[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'!' NAME"));
     }
     _res = NULL;
@@ -39755,9 +39838,9 @@ _tmp_242_rule(Parser *p)
     return _res;
 }
 
-// _loop0_243: fstring_format_spec
+// _loop0_244: fstring_format_spec
 static asdl_seq *
-_loop0_243_rule(Parser *p)
+_loop0_244_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39782,7 +39865,7 @@ _loop0_243_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _loop0_243[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring_format_spec"));
+        D(fprintf(stderr, "%*c> _loop0_244[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring_format_spec"));
         expr_ty fstring_format_spec_var;
         while (
             (fstring_format_spec_var = fstring_format_spec_rule(p))  // fstring_format_spec
@@ -39805,7 +39888,7 @@ _loop0_243_rule(Parser *p)
             _mark = p->mark;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _loop0_243[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _loop0_244[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "fstring_format_spec"));
     }
     asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
@@ -39822,9 +39905,9 @@ _loop0_243_rule(Parser *p)
     return _seq;
 }
 
-// _tmp_244: yield_expr | star_expressions
+// _tmp_245: yield_expr | star_expressions
 static void *
-_tmp_244_rule(Parser *p)
+_tmp_245_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39840,18 +39923,18 @@ _tmp_244_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_244[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+        D(fprintf(stderr, "%*c> _tmp_245[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "yield_expr"));
         expr_ty yield_expr_var;
         if (
             (yield_expr_var = yield_expr_rule(p))  // yield_expr
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_244[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
+            D(fprintf(stderr, "%*c+ _tmp_245[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "yield_expr"));
             _res = yield_expr_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_244[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_245[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "yield_expr"));
     }
     { // star_expressions
@@ -39859,18 +39942,18 @@ _tmp_244_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_244[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+        D(fprintf(stderr, "%*c> _tmp_245[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_expressions"));
         expr_ty star_expressions_var;
         if (
             (star_expressions_var = star_expressions_rule(p))  // star_expressions
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_244[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
+            D(fprintf(stderr, "%*c+ _tmp_245[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_expressions"));
             _res = star_expressions_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_244[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_245[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_expressions"));
     }
     _res = NULL;
@@ -39879,9 +39962,9 @@ _tmp_244_rule(Parser *p)
     return _res;
 }
 
-// _tmp_245: '!' NAME
+// _tmp_246: '!' NAME
 static void *
-_tmp_245_rule(Parser *p)
+_tmp_246_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39897,7 +39980,7 @@ _tmp_245_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_245[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_246[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
         Token * _literal;
         expr_ty name_var;
         if (
@@ -39906,12 +39989,12 @@ _tmp_245_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_245[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_246[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'!' NAME"));
             _res = _PyPegen_dummy_name(p, _literal, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_245[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_246[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'!' NAME"));
     }
     _res = NULL;
@@ -39920,9 +40003,9 @@ _tmp_245_rule(Parser *p)
     return _res;
 }
 
-// _tmp_246: ':' | '}'
+// _tmp_247: ':' | '}'
 static void *
-_tmp_246_rule(Parser *p)
+_tmp_247_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39938,18 +40021,18 @@ _tmp_246_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_246[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_247[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_246[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_247[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_246[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_247[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     { // '}'
@@ -39957,18 +40040,18 @@ _tmp_246_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_246[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
+        D(fprintf(stderr, "%*c> _tmp_247[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'}'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 26))  // token='}'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_246[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
+            D(fprintf(stderr, "%*c+ _tmp_247[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'}'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_246[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_247[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'}'"));
     }
     _res = NULL;
@@ -39977,9 +40060,9 @@ _tmp_246_rule(Parser *p)
     return _res;
 }
 
-// _tmp_247: star_targets '='
+// _tmp_248: star_targets '='
 static void *
-_tmp_247_rule(Parser *p)
+_tmp_248_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -39995,7 +40078,7 @@ _tmp_247_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_247[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
+        D(fprintf(stderr, "%*c> _tmp_248[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
         Token * _literal;
         expr_ty z;
         if (
@@ -40004,7 +40087,7 @@ _tmp_247_rule(Parser *p)
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_247[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
+            D(fprintf(stderr, "%*c+ _tmp_248[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40014,7 +40097,7 @@ _tmp_247_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_247[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_248[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_targets '='"));
     }
     _res = NULL;
@@ -40023,9 +40106,9 @@ _tmp_247_rule(Parser *p)
     return _res;
 }
 
-// _tmp_248: '.' | '...'
+// _tmp_249: '.' | '...'
 static void *
-_tmp_248_rule(Parser *p)
+_tmp_249_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40041,18 +40124,18 @@ _tmp_248_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_248[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
+        D(fprintf(stderr, "%*c> _tmp_249[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 23))  // token='.'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_248[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
+            D(fprintf(stderr, "%*c+ _tmp_249[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_248[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_249[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'.'"));
     }
     { // '...'
@@ -40060,18 +40143,18 @@ _tmp_248_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_248[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'...'"));
+        D(fprintf(stderr, "%*c> _tmp_249[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'...'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 52))  // token='...'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_248[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'...'"));
+            D(fprintf(stderr, "%*c+ _tmp_249[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'...'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_248[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_249[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'...'"));
     }
     _res = NULL;
@@ -40080,9 +40163,9 @@ _tmp_248_rule(Parser *p)
     return _res;
 }
 
-// _tmp_249: '.' | '...'
+// _tmp_250: '.' | '...'
 static void *
-_tmp_249_rule(Parser *p)
+_tmp_250_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40098,18 +40181,18 @@ _tmp_249_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_249[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
+        D(fprintf(stderr, "%*c> _tmp_250[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'.'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 23))  // token='.'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_249[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
+            D(fprintf(stderr, "%*c+ _tmp_250[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'.'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_249[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_250[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'.'"));
     }
     { // '...'
@@ -40117,18 +40200,18 @@ _tmp_249_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_249[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'...'"));
+        D(fprintf(stderr, "%*c> _tmp_250[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'...'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 52))  // token='...'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_249[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'...'"));
+            D(fprintf(stderr, "%*c+ _tmp_250[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'...'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_249[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_250[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'...'"));
     }
     _res = NULL;
@@ -40137,9 +40220,9 @@ _tmp_249_rule(Parser *p)
     return _res;
 }
 
-// _tmp_250: '@' named_expression NEWLINE
+// _tmp_251: '@' named_expression NEWLINE
 static void *
-_tmp_250_rule(Parser *p)
+_tmp_251_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40155,7 +40238,7 @@ _tmp_250_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_250[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'@' named_expression NEWLINE"));
+        D(fprintf(stderr, "%*c> _tmp_251[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'@' named_expression NEWLINE"));
         Token * _literal;
         expr_ty f;
         Token * newline_var;
@@ -40167,7 +40250,7 @@ _tmp_250_rule(Parser *p)
             (newline_var = _PyPegen_expect_token(p, NEWLINE))  // token='NEWLINE'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_250[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'@' named_expression NEWLINE"));
+            D(fprintf(stderr, "%*c+ _tmp_251[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'@' named_expression NEWLINE"));
             _res = f;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40177,7 +40260,7 @@ _tmp_250_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_250[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_251[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'@' named_expression NEWLINE"));
     }
     _res = NULL;
@@ -40186,9 +40269,9 @@ _tmp_250_rule(Parser *p)
     return _res;
 }
 
-// _tmp_251: ',' expression
+// _tmp_252: ',' expression
 static void *
-_tmp_251_rule(Parser *p)
+_tmp_252_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40204,7 +40287,7 @@ _tmp_251_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_251[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' expression"));
+        D(fprintf(stderr, "%*c> _tmp_252[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' expression"));
         Token * _literal;
         expr_ty c;
         if (
@@ -40213,7 +40296,7 @@ _tmp_251_rule(Parser *p)
             (c = expression_rule(p))  // expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_251[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' expression"));
+            D(fprintf(stderr, "%*c+ _tmp_252[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' expression"));
             _res = c;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40223,7 +40306,7 @@ _tmp_251_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_251[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_252[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' expression"));
     }
     _res = NULL;
@@ -40232,9 +40315,9 @@ _tmp_251_rule(Parser *p)
     return _res;
 }
 
-// _tmp_252: ',' star_expression
+// _tmp_253: ',' star_expression
 static void *
-_tmp_252_rule(Parser *p)
+_tmp_253_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40250,7 +40333,7 @@ _tmp_252_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_252[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_expression"));
+        D(fprintf(stderr, "%*c> _tmp_253[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_expression"));
         Token * _literal;
         expr_ty c;
         if (
@@ -40259,7 +40342,7 @@ _tmp_252_rule(Parser *p)
             (c = star_expression_rule(p))  // star_expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_252[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' star_expression"));
+            D(fprintf(stderr, "%*c+ _tmp_253[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' star_expression"));
             _res = c;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40269,7 +40352,7 @@ _tmp_252_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_252[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_253[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' star_expression"));
     }
     _res = NULL;
@@ -40278,9 +40361,9 @@ _tmp_252_rule(Parser *p)
     return _res;
 }
 
-// _tmp_253: 'or' conjunction
+// _tmp_254: 'or' conjunction
 static void *
-_tmp_253_rule(Parser *p)
+_tmp_254_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40296,7 +40379,7 @@ _tmp_253_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_253[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'or' conjunction"));
+        D(fprintf(stderr, "%*c> _tmp_254[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'or' conjunction"));
         Token * _keyword;
         expr_ty c;
         if (
@@ -40305,7 +40388,7 @@ _tmp_253_rule(Parser *p)
             (c = conjunction_rule(p))  // conjunction
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_253[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'or' conjunction"));
+            D(fprintf(stderr, "%*c+ _tmp_254[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'or' conjunction"));
             _res = c;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40315,7 +40398,7 @@ _tmp_253_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_253[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_254[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'or' conjunction"));
     }
     _res = NULL;
@@ -40324,9 +40407,9 @@ _tmp_253_rule(Parser *p)
     return _res;
 }
 
-// _tmp_254: 'and' inversion
+// _tmp_255: 'and' inversion
 static void *
-_tmp_254_rule(Parser *p)
+_tmp_255_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40342,7 +40425,7 @@ _tmp_254_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_254[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'and' inversion"));
+        D(fprintf(stderr, "%*c> _tmp_255[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'and' inversion"));
         Token * _keyword;
         expr_ty c;
         if (
@@ -40351,7 +40434,7 @@ _tmp_254_rule(Parser *p)
             (c = inversion_rule(p))  // inversion
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_254[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'and' inversion"));
+            D(fprintf(stderr, "%*c+ _tmp_255[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'and' inversion"));
             _res = c;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40361,7 +40444,7 @@ _tmp_254_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_254[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_255[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'and' inversion"));
     }
     _res = NULL;
@@ -40370,9 +40453,9 @@ _tmp_254_rule(Parser *p)
     return _res;
 }
 
-// _tmp_255: slice | starred_expression
+// _tmp_256: slice | starred_expression
 static void *
-_tmp_255_rule(Parser *p)
+_tmp_256_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40388,18 +40471,18 @@ _tmp_255_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_255[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slice"));
+        D(fprintf(stderr, "%*c> _tmp_256[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "slice"));
         expr_ty slice_var;
         if (
             (slice_var = slice_rule(p))  // slice
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_255[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slice"));
+            D(fprintf(stderr, "%*c+ _tmp_256[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "slice"));
             _res = slice_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_255[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_256[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "slice"));
     }
     { // starred_expression
@@ -40407,18 +40490,18 @@ _tmp_255_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_255[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "starred_expression"));
+        D(fprintf(stderr, "%*c> _tmp_256[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "starred_expression"));
         expr_ty starred_expression_var;
         if (
             (starred_expression_var = starred_expression_rule(p))  // starred_expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_255[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "starred_expression"));
+            D(fprintf(stderr, "%*c+ _tmp_256[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "starred_expression"));
             _res = starred_expression_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_255[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_256[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "starred_expression"));
     }
     _res = NULL;
@@ -40427,9 +40510,9 @@ _tmp_255_rule(Parser *p)
     return _res;
 }
 
-// _tmp_256: fstring | string
+// _tmp_257: fstring | string
 static void *
-_tmp_256_rule(Parser *p)
+_tmp_257_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40445,18 +40528,18 @@ _tmp_256_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_256[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring"));
+        D(fprintf(stderr, "%*c> _tmp_257[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "fstring"));
         expr_ty fstring_var;
         if (
             (fstring_var = fstring_rule(p))  // fstring
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_256[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "fstring"));
+            D(fprintf(stderr, "%*c+ _tmp_257[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "fstring"));
             _res = fstring_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_256[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_257[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "fstring"));
     }
     { // string
@@ -40464,18 +40547,18 @@ _tmp_256_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_256[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "string"));
+        D(fprintf(stderr, "%*c> _tmp_257[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "string"));
         expr_ty string_var;
         if (
             (string_var = string_rule(p))  // string
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_256[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "string"));
+            D(fprintf(stderr, "%*c+ _tmp_257[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "string"));
             _res = string_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_256[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_257[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "string"));
     }
     _res = NULL;
@@ -40484,9 +40567,9 @@ _tmp_256_rule(Parser *p)
     return _res;
 }
 
-// _tmp_257: 'if' disjunction
+// _tmp_258: 'if' disjunction
 static void *
-_tmp_257_rule(Parser *p)
+_tmp_258_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40502,7 +40585,7 @@ _tmp_257_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_257[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
+        D(fprintf(stderr, "%*c> _tmp_258[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -40511,7 +40594,7 @@ _tmp_257_rule(Parser *p)
             (z = disjunction_rule(p))  // disjunction
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_257[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
+            D(fprintf(stderr, "%*c+ _tmp_258[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40521,7 +40604,7 @@ _tmp_257_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_257[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_258[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'if' disjunction"));
     }
     _res = NULL;
@@ -40530,9 +40613,9 @@ _tmp_257_rule(Parser *p)
     return _res;
 }
 
-// _tmp_258: 'if' disjunction
+// _tmp_259: 'if' disjunction
 static void *
-_tmp_258_rule(Parser *p)
+_tmp_259_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40548,7 +40631,7 @@ _tmp_258_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_258[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
+        D(fprintf(stderr, "%*c> _tmp_259[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
         Token * _keyword;
         expr_ty z;
         if (
@@ -40557,7 +40640,7 @@ _tmp_258_rule(Parser *p)
             (z = disjunction_rule(p))  // disjunction
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_258[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
+            D(fprintf(stderr, "%*c+ _tmp_259[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'if' disjunction"));
             _res = z;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40567,7 +40650,7 @@ _tmp_258_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_258[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_259[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'if' disjunction"));
     }
     _res = NULL;
@@ -40576,9 +40659,9 @@ _tmp_258_rule(Parser *p)
     return _res;
 }
 
-// _tmp_259: starred_expression | (assignment_expression | expression !':=') !'='
+// _tmp_260: starred_expression | (assignment_expression | expression !':=') !'='
 static void *
-_tmp_259_rule(Parser *p)
+_tmp_260_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40594,18 +40677,18 @@ _tmp_259_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_259[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "starred_expression"));
+        D(fprintf(stderr, "%*c> _tmp_260[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "starred_expression"));
         expr_ty starred_expression_var;
         if (
             (starred_expression_var = starred_expression_rule(p))  // starred_expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_259[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "starred_expression"));
+            D(fprintf(stderr, "%*c+ _tmp_260[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "starred_expression"));
             _res = starred_expression_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_259[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_260[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "starred_expression"));
     }
     { // (assignment_expression | expression !':=') !'='
@@ -40613,20 +40696,20 @@ _tmp_259_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_259[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
-        void *_tmp_271_var;
+        D(fprintf(stderr, "%*c> _tmp_260[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
+        void *_tmp_273_var;
         if (
-            (_tmp_271_var = _tmp_271_rule(p))  // assignment_expression | expression !':='
+            (_tmp_273_var = _tmp_273_rule(p))  // assignment_expression | expression !':='
             &&
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 22)  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_259[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
-            _res = _tmp_271_var;
+            D(fprintf(stderr, "%*c+ _tmp_260[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
+            _res = _tmp_273_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_259[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_260[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
     }
     _res = NULL;
@@ -40635,9 +40718,9 @@ _tmp_259_rule(Parser *p)
     return _res;
 }
 
-// _tmp_260: ',' star_target
+// _tmp_261: ',' star_target
 static void *
-_tmp_260_rule(Parser *p)
+_tmp_261_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40653,7 +40736,7 @@ _tmp_260_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_260[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_target"));
+        D(fprintf(stderr, "%*c> _tmp_261[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_target"));
         Token * _literal;
         expr_ty c;
         if (
@@ -40662,7 +40745,7 @@ _tmp_260_rule(Parser *p)
             (c = star_target_rule(p))  // star_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_260[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' star_target"));
+            D(fprintf(stderr, "%*c+ _tmp_261[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' star_target"));
             _res = c;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40672,7 +40755,7 @@ _tmp_260_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_260[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_261[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' star_target"));
     }
     _res = NULL;
@@ -40681,9 +40764,9 @@ _tmp_260_rule(Parser *p)
     return _res;
 }
 
-// _tmp_261: ',' star_target
+// _tmp_262: ',' star_target
 static void *
-_tmp_261_rule(Parser *p)
+_tmp_262_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40699,7 +40782,7 @@ _tmp_261_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_261[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_target"));
+        D(fprintf(stderr, "%*c> _tmp_262[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' star_target"));
         Token * _literal;
         expr_ty c;
         if (
@@ -40708,7 +40791,7 @@ _tmp_261_rule(Parser *p)
             (c = star_target_rule(p))  // star_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_261[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' star_target"));
+            D(fprintf(stderr, "%*c+ _tmp_262[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "',' star_target"));
             _res = c;
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
@@ -40718,7 +40801,7 @@ _tmp_261_rule(Parser *p)
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_261[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_262[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' star_target"));
     }
     _res = NULL;
@@ -40727,9 +40810,54 @@ _tmp_261_rule(Parser *p)
     return _res;
 }
 
-// _tmp_262: star_targets '='
+// _tmp_263:
+//     | ','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs
 static void *
-_tmp_262_rule(Parser *p)
+_tmp_263_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void * _res = NULL;
+    int _mark = p->mark;
+    { // ','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_263[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs"));
+        asdl_seq * _gather_274_var;
+        Token * _literal;
+        asdl_seq* kwargs_var;
+        if (
+            (_gather_274_var = _gather_274_rule(p))  // ','.(starred_expression | (assignment_expression | expression !':=') !'=')+
+            &&
+            (_literal = _PyPegen_expect_token(p, 12))  // token=','
+            &&
+            (kwargs_var = kwargs_rule(p))  // kwargs
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_263[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs"));
+            _res = _PyPegen_dummy_name(p, _gather_274_var, _literal, kwargs_var);
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_263[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "','.(starred_expression | (assignment_expression | expression !':=') !'=')+ ',' kwargs"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
+// _tmp_264: star_targets '='
+static void *
+_tmp_264_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40745,7 +40873,7 @@ _tmp_262_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_262[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
+        D(fprintf(stderr, "%*c> _tmp_264[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
         Token * _literal;
         expr_ty star_targets_var;
         if (
@@ -40754,12 +40882,12 @@ _tmp_262_rule(Parser *p)
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_262[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
+            D(fprintf(stderr, "%*c+ _tmp_264[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
             _res = _PyPegen_dummy_name(p, star_targets_var, _literal);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_262[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_264[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_targets '='"));
     }
     _res = NULL;
@@ -40768,9 +40896,9 @@ _tmp_262_rule(Parser *p)
     return _res;
 }
 
-// _tmp_263: star_targets '='
+// _tmp_265: star_targets '='
 static void *
-_tmp_263_rule(Parser *p)
+_tmp_265_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40786,7 +40914,7 @@ _tmp_263_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_263[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
+        D(fprintf(stderr, "%*c> _tmp_265[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
         Token * _literal;
         expr_ty star_targets_var;
         if (
@@ -40795,12 +40923,12 @@ _tmp_263_rule(Parser *p)
             (_literal = _PyPegen_expect_token(p, 22))  // token='='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_263[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
+            D(fprintf(stderr, "%*c+ _tmp_265[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "star_targets '='"));
             _res = _PyPegen_dummy_name(p, star_targets_var, _literal);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_263[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_265[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "star_targets '='"));
     }
     _res = NULL;
@@ -40809,9 +40937,9 @@ _tmp_263_rule(Parser *p)
     return _res;
 }
 
-// _tmp_264: ')' | '**'
+// _tmp_266: ')' | '**'
 static void *
-_tmp_264_rule(Parser *p)
+_tmp_266_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40827,18 +40955,18 @@ _tmp_264_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_264[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
+        D(fprintf(stderr, "%*c> _tmp_266[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "')'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 8))  // token=')'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_264[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
+            D(fprintf(stderr, "%*c+ _tmp_266[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "')'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_264[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_266[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "')'"));
     }
     { // '**'
@@ -40846,18 +40974,18 @@ _tmp_264_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_264[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
+        D(fprintf(stderr, "%*c> _tmp_266[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 35))  // token='**'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_264[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
+            D(fprintf(stderr, "%*c+ _tmp_266[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_264[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_266[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'**'"));
     }
     _res = NULL;
@@ -40866,9 +40994,9 @@ _tmp_264_rule(Parser *p)
     return _res;
 }
 
-// _tmp_265: ':' | '**'
+// _tmp_267: ':' | '**'
 static void *
-_tmp_265_rule(Parser *p)
+_tmp_267_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40884,18 +41012,18 @@ _tmp_265_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_265[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
+        D(fprintf(stderr, "%*c> _tmp_267[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "':'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 11))  // token=':'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_265[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
+            D(fprintf(stderr, "%*c+ _tmp_267[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "':'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_265[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_267[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "':'"));
     }
     { // '**'
@@ -40903,18 +41031,18 @@ _tmp_265_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_265[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
+        D(fprintf(stderr, "%*c> _tmp_267[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'**'"));
         Token * _literal;
         if (
             (_literal = _PyPegen_expect_token(p, 35))  // token='**'
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_265[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
+            D(fprintf(stderr, "%*c+ _tmp_267[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'**'"));
             _res = _literal;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_265[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_267[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'**'"));
     }
     _res = NULL;
@@ -40923,9 +41051,9 @@ _tmp_265_rule(Parser *p)
     return _res;
 }
 
-// _tmp_266: expression ['as' star_target]
+// _tmp_268: expression ['as' star_target]
 static void *
-_tmp_266_rule(Parser *p)
+_tmp_268_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40941,22 +41069,22 @@ _tmp_266_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_266[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
+        D(fprintf(stderr, "%*c> _tmp_268[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         expr_ty expression_var;
         if (
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var = _tmp_272_rule(p), !p->error_indicator)  // ['as' star_target]
+            (_opt_var = _tmp_276_rule(p), !p->error_indicator)  // ['as' star_target]
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_266[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
+            D(fprintf(stderr, "%*c+ _tmp_268[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
             _res = _PyPegen_dummy_name(p, expression_var, _opt_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_266[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_268[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expression ['as' star_target]"));
     }
     _res = NULL;
@@ -40965,9 +41093,9 @@ _tmp_266_rule(Parser *p)
     return _res;
 }
 
-// _tmp_267: expressions ['as' star_target]
+// _tmp_269: expressions ['as' star_target]
 static void *
-_tmp_267_rule(Parser *p)
+_tmp_269_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -40983,22 +41111,22 @@ _tmp_267_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_267[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
+        D(fprintf(stderr, "%*c> _tmp_269[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         expr_ty expressions_var;
         if (
             (expressions_var = expressions_rule(p))  // expressions
             &&
-            (_opt_var = _tmp_273_rule(p), !p->error_indicator)  // ['as' star_target]
+            (_opt_var = _tmp_277_rule(p), !p->error_indicator)  // ['as' star_target]
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_267[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
+            D(fprintf(stderr, "%*c+ _tmp_269[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
             _res = _PyPegen_dummy_name(p, expressions_var, _opt_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_267[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_269[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expressions ['as' star_target]"));
     }
     _res = NULL;
@@ -41007,9 +41135,9 @@ _tmp_267_rule(Parser *p)
     return _res;
 }
 
-// _tmp_268: expression ['as' star_target]
+// _tmp_270: expression ['as' star_target]
 static void *
-_tmp_268_rule(Parser *p)
+_tmp_270_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41025,22 +41153,22 @@ _tmp_268_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_268[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
+        D(fprintf(stderr, "%*c> _tmp_270[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         expr_ty expression_var;
         if (
             (expression_var = expression_rule(p))  // expression
             &&
-            (_opt_var = _tmp_274_rule(p), !p->error_indicator)  // ['as' star_target]
+            (_opt_var = _tmp_278_rule(p), !p->error_indicator)  // ['as' star_target]
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_268[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
+            D(fprintf(stderr, "%*c+ _tmp_270[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression ['as' star_target]"));
             _res = _PyPegen_dummy_name(p, expression_var, _opt_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_268[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_270[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expression ['as' star_target]"));
     }
     _res = NULL;
@@ -41049,9 +41177,9 @@ _tmp_268_rule(Parser *p)
     return _res;
 }
 
-// _tmp_269: expressions ['as' star_target]
+// _tmp_271: expressions ['as' star_target]
 static void *
-_tmp_269_rule(Parser *p)
+_tmp_271_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41067,22 +41195,22 @@ _tmp_269_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_269[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
+        D(fprintf(stderr, "%*c> _tmp_271[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
         void *_opt_var;
         UNUSED(_opt_var); // Silence compiler warnings
         expr_ty expressions_var;
         if (
             (expressions_var = expressions_rule(p))  // expressions
             &&
-            (_opt_var = _tmp_275_rule(p), !p->error_indicator)  // ['as' star_target]
+            (_opt_var = _tmp_279_rule(p), !p->error_indicator)  // ['as' star_target]
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_269[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
+            D(fprintf(stderr, "%*c+ _tmp_271[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expressions ['as' star_target]"));
             _res = _PyPegen_dummy_name(p, expressions_var, _opt_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_269[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_271[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expressions ['as' star_target]"));
     }
     _res = NULL;
@@ -41091,9 +41219,9 @@ _tmp_269_rule(Parser *p)
     return _res;
 }
 
-// _tmp_270: 'as' NAME
+// _tmp_272: 'as' NAME
 static void *
-_tmp_270_rule(Parser *p)
+_tmp_272_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41109,7 +41237,7 @@ _tmp_270_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_270[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+        D(fprintf(stderr, "%*c> _tmp_272[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
         Token * _keyword;
         expr_ty name_var;
         if (
@@ -41118,12 +41246,12 @@ _tmp_270_rule(Parser *p)
             (name_var = _PyPegen_name_token(p))  // NAME
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_270[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
+            D(fprintf(stderr, "%*c+ _tmp_272[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' NAME"));
             _res = _PyPegen_dummy_name(p, _keyword, name_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_270[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_272[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' NAME"));
     }
     _res = NULL;
@@ -41132,9 +41260,9 @@ _tmp_270_rule(Parser *p)
     return _res;
 }
 
-// _tmp_271: assignment_expression | expression !':='
+// _tmp_273: assignment_expression | expression !':='
 static void *
-_tmp_271_rule(Parser *p)
+_tmp_273_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41150,18 +41278,18 @@ _tmp_271_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_271[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "assignment_expression"));
+        D(fprintf(stderr, "%*c> _tmp_273[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "assignment_expression"));
         expr_ty assignment_expression_var;
         if (
             (assignment_expression_var = assignment_expression_rule(p))  // assignment_expression
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_271[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "assignment_expression"));
+            D(fprintf(stderr, "%*c+ _tmp_273[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "assignment_expression"));
             _res = assignment_expression_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_271[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_273[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "assignment_expression"));
     }
     { // expression !':='
@@ -41169,7 +41297,7 @@ _tmp_271_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_271[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression !':='"));
+        D(fprintf(stderr, "%*c> _tmp_273[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression !':='"));
         expr_ty expression_var;
         if (
             (expression_var = expression_rule(p))  // expression
@@ -41177,12 +41305,12 @@ _tmp_271_rule(Parser *p)
             _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 53)  // token=':='
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_271[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression !':='"));
+            D(fprintf(stderr, "%*c+ _tmp_273[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression !':='"));
             _res = expression_var;
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_271[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_273[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expression !':='"));
     }
     _res = NULL;
@@ -41191,9 +41319,127 @@ _tmp_271_rule(Parser *p)
     return _res;
 }
 
-// _tmp_272: 'as' star_target
+// _loop0_275: ',' (starred_expression | (assignment_expression | expression !':=') !'=')
+static asdl_seq *
+_loop0_275_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void *_res = NULL;
+    int _mark = p->mark;
+    void **_children = PyMem_Malloc(sizeof(void *));
+    if (!_children) {
+        p->error_indicator = 1;
+        PyErr_NoMemory();
+        p->level--;
+        return NULL;
+    }
+    Py_ssize_t _children_capacity = 1;
+    Py_ssize_t _n = 0;
+    { // ',' (starred_expression | (assignment_expression | expression !':=') !'=')
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _loop0_275[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "',' (starred_expression | (assignment_expression | expression !':=') !'=')"));
+        Token * _literal;
+        void *elem;
+        while (
+            (_literal = _PyPegen_expect_token(p, 12))  // token=','
+            &&
+            (elem = _tmp_280_rule(p))  // starred_expression | (assignment_expression | expression !':=') !'='
+        )
+        {
+            _res = elem;
+            if (_res == NULL && PyErr_Occurred()) {
+                p->error_indicator = 1;
+                PyMem_Free(_children);
+                p->level--;
+                return NULL;
+            }
+            if (_n == _children_capacity) {
+                _children_capacity *= 2;
+                void **_new_children = PyMem_Realloc(_children, _children_capacity*sizeof(void *));
+                if (!_new_children) {
+                    PyMem_Free(_children);
+                    p->error_indicator = 1;
+                    PyErr_NoMemory();
+                    p->level--;
+                    return NULL;
+                }
+                _children = _new_children;
+            }
+            _children[_n++] = _res;
+            _mark = p->mark;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _loop0_275[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "',' (starred_expression | (assignment_expression | expression !':=') !'=')"));
+    }
+    asdl_seq *_seq = (asdl_seq*)_Py_asdl_generic_seq_new(_n, p->arena);
+    if (!_seq) {
+        PyMem_Free(_children);
+        p->error_indicator = 1;
+        PyErr_NoMemory();
+        p->level--;
+        return NULL;
+    }
+    for (int i = 0; i < _n; i++) asdl_seq_SET_UNTYPED(_seq, i, _children[i]);
+    PyMem_Free(_children);
+    p->level--;
+    return _seq;
+}
+
+// _gather_274:
+//     | (starred_expression | (assignment_expression | expression !':=') !'=') _loop0_275
+static asdl_seq *
+_gather_274_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    asdl_seq * _res = NULL;
+    int _mark = p->mark;
+    { // (starred_expression | (assignment_expression | expression !':=') !'=') _loop0_275
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _gather_274[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(starred_expression | (assignment_expression | expression !':=') !'=') _loop0_275"));
+        void *elem;
+        asdl_seq * seq;
+        if (
+            (elem = _tmp_280_rule(p))  // starred_expression | (assignment_expression | expression !':=') !'='
+            &&
+            (seq = _loop0_275_rule(p))  // _loop0_275
+        )
+        {
+            D(fprintf(stderr, "%*c+ _gather_274[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(starred_expression | (assignment_expression | expression !':=') !'=') _loop0_275"));
+            _res = _PyPegen_seq_insert_in_front(p, elem, seq);
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _gather_274[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(starred_expression | (assignment_expression | expression !':=') !'=') _loop0_275"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
+// _tmp_276: 'as' star_target
 static void *
-_tmp_272_rule(Parser *p)
+_tmp_276_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41209,7 +41455,7 @@ _tmp_272_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_272[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+        D(fprintf(stderr, "%*c> _tmp_276[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
         Token * _keyword;
         expr_ty star_target_var;
         if (
@@ -41218,12 +41464,12 @@ _tmp_272_rule(Parser *p)
             (star_target_var = star_target_rule(p))  // star_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_272[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+            D(fprintf(stderr, "%*c+ _tmp_276[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
             _res = _PyPegen_dummy_name(p, _keyword, star_target_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_272[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_276[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' star_target"));
     }
     _res = NULL;
@@ -41232,9 +41478,9 @@ _tmp_272_rule(Parser *p)
     return _res;
 }
 
-// _tmp_273: 'as' star_target
+// _tmp_277: 'as' star_target
 static void *
-_tmp_273_rule(Parser *p)
+_tmp_277_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41250,7 +41496,7 @@ _tmp_273_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_273[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+        D(fprintf(stderr, "%*c> _tmp_277[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
         Token * _keyword;
         expr_ty star_target_var;
         if (
@@ -41259,12 +41505,12 @@ _tmp_273_rule(Parser *p)
             (star_target_var = star_target_rule(p))  // star_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_273[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+            D(fprintf(stderr, "%*c+ _tmp_277[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
             _res = _PyPegen_dummy_name(p, _keyword, star_target_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_273[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_277[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' star_target"));
     }
     _res = NULL;
@@ -41273,9 +41519,9 @@ _tmp_273_rule(Parser *p)
     return _res;
 }
 
-// _tmp_274: 'as' star_target
+// _tmp_278: 'as' star_target
 static void *
-_tmp_274_rule(Parser *p)
+_tmp_278_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41291,7 +41537,7 @@ _tmp_274_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_274[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+        D(fprintf(stderr, "%*c> _tmp_278[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
         Token * _keyword;
         expr_ty star_target_var;
         if (
@@ -41300,12 +41546,12 @@ _tmp_274_rule(Parser *p)
             (star_target_var = star_target_rule(p))  // star_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_274[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+            D(fprintf(stderr, "%*c+ _tmp_278[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
             _res = _PyPegen_dummy_name(p, _keyword, star_target_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_274[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_278[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' star_target"));
     }
     _res = NULL;
@@ -41314,9 +41560,9 @@ _tmp_274_rule(Parser *p)
     return _res;
 }
 
-// _tmp_275: 'as' star_target
+// _tmp_279: 'as' star_target
 static void *
-_tmp_275_rule(Parser *p)
+_tmp_279_rule(Parser *p)
 {
     if (p->level++ == MAXSTACK) {
         _Pypegen_stack_overflow(p);
@@ -41332,7 +41578,7 @@ _tmp_275_rule(Parser *p)
             p->level--;
             return NULL;
         }
-        D(fprintf(stderr, "%*c> _tmp_275[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+        D(fprintf(stderr, "%*c> _tmp_279[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
         Token * _keyword;
         expr_ty star_target_var;
         if (
@@ -41341,12 +41587,12 @@ _tmp_275_rule(Parser *p)
             (star_target_var = star_target_rule(p))  // star_target
         )
         {
-            D(fprintf(stderr, "%*c+ _tmp_275[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
+            D(fprintf(stderr, "%*c+ _tmp_279[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "'as' star_target"));
             _res = _PyPegen_dummy_name(p, _keyword, star_target_var);
             goto done;
         }
         p->mark = _mark;
-        D(fprintf(stderr, "%*c%s _tmp_275[%d-%d]: %s failed!\n", p->level, ' ',
+        D(fprintf(stderr, "%*c%s _tmp_279[%d-%d]: %s failed!\n", p->level, ' ',
                   p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "'as' star_target"));
     }
     _res = NULL;
@@ -41355,6 +41601,124 @@ _tmp_275_rule(Parser *p)
     return _res;
 }
 
+// _tmp_280: starred_expression | (assignment_expression | expression !':=') !'='
+static void *
+_tmp_280_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void * _res = NULL;
+    int _mark = p->mark;
+    { // starred_expression
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_280[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "starred_expression"));
+        expr_ty starred_expression_var;
+        if (
+            (starred_expression_var = starred_expression_rule(p))  // starred_expression
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_280[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "starred_expression"));
+            _res = starred_expression_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_280[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "starred_expression"));
+    }
+    { // (assignment_expression | expression !':=') !'='
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_280[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
+        void *_tmp_281_var;
+        if (
+            (_tmp_281_var = _tmp_281_rule(p))  // assignment_expression | expression !':='
+            &&
+            _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 22)  // token='='
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_280[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
+            _res = _tmp_281_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_280[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "(assignment_expression | expression !':=') !'='"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
+// _tmp_281: assignment_expression | expression !':='
+static void *
+_tmp_281_rule(Parser *p)
+{
+    if (p->level++ == MAXSTACK) {
+        _Pypegen_stack_overflow(p);
+    }
+    if (p->error_indicator) {
+        p->level--;
+        return NULL;
+    }
+    void * _res = NULL;
+    int _mark = p->mark;
+    { // assignment_expression
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_281[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "assignment_expression"));
+        expr_ty assignment_expression_var;
+        if (
+            (assignment_expression_var = assignment_expression_rule(p))  // assignment_expression
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_281[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "assignment_expression"));
+            _res = assignment_expression_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_281[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "assignment_expression"));
+    }
+    { // expression !':='
+        if (p->error_indicator) {
+            p->level--;
+            return NULL;
+        }
+        D(fprintf(stderr, "%*c> _tmp_281[%d-%d]: %s\n", p->level, ' ', _mark, p->mark, "expression !':='"));
+        expr_ty expression_var;
+        if (
+            (expression_var = expression_rule(p))  // expression
+            &&
+            _PyPegen_lookahead_with_int(0, _PyPegen_expect_token, p, 53)  // token=':='
+        )
+        {
+            D(fprintf(stderr, "%*c+ _tmp_281[%d-%d]: %s succeeded!\n", p->level, ' ', _mark, p->mark, "expression !':='"));
+            _res = expression_var;
+            goto done;
+        }
+        p->mark = _mark;
+        D(fprintf(stderr, "%*c%s _tmp_281[%d-%d]: %s failed!\n", p->level, ' ',
+                  p->error_indicator ? "ERROR!" : "-", _mark, p->mark, "expression !':='"));
+    }
+    _res = NULL;
+  done:
+    p->level--;
+    return _res;
+}
+
 void *
 _PyPegen_parse(Parser *p)
 {
@@ -41373,8 +41737,6 @@ _PyPegen_parse(Parser *p)
         result = eval_rule(p);
     } else if (p->start_rule == Py_func_type_input) {
         result = func_type_rule(p);
-    } else if (p->start_rule == Py_fstring_input) {
-        result = fstring_rule(p);
     }
 
     return result;
diff --git a/Parser/pegen.c b/Parser/pegen.c
index b9894dd0ac..ff02e88cee 100644
--- a/Parser/pegen.c
+++ b/Parser/pegen.c
@@ -38,6 +38,61 @@ _PyPegen_byte_offset_to_character_offset(PyObject *line, Py_ssize_t col_offset)
     return size;
 }
 
+// Calculate the extra amount of width space the given source
+// code segment might take if it were to be displayed on a fixed
+// width output device. Supports wide unicode characters and emojis.
+Py_ssize_t
+_PyPegen_calculate_display_width(PyObject *line, Py_ssize_t character_offset)
+{
+    PyObject *segment = PyUnicode_Substring(line, 0, character_offset);
+    if (!segment) {
+        return -1;
+    }
+
+    // Fast track for ascii strings
+    if (PyUnicode_IS_ASCII(segment)) {
+        Py_DECREF(segment);
+        return character_offset;
+    }
+
+    PyObject *width_fn = _PyImport_GetModuleAttrString("unicodedata", "east_asian_width");
+    if (!width_fn) {
+        return -1;
+    }
+
+    Py_ssize_t width = 0;
+    Py_ssize_t len = PyUnicode_GET_LENGTH(segment);
+    for (Py_ssize_t i = 0; i < len; i++) {
+        PyObject *chr = PyUnicode_Substring(segment, i, i + 1);
+        if (!chr) {
+            Py_DECREF(segment);
+            Py_DECREF(width_fn);
+            return -1;
+        }
+
+        PyObject *width_specifier = PyObject_CallOneArg(width_fn, chr);
+        Py_DECREF(chr);
+        if (!width_specifier) {
+            Py_DECREF(segment);
+            Py_DECREF(width_fn);
+            return -1;
+        }
+
+        if (_PyUnicode_EqualToASCIIString(width_specifier, "W") ||
+            _PyUnicode_EqualToASCIIString(width_specifier, "F")) {
+            width += 2;
+        }
+        else {
+            width += 1;
+        }
+        Py_DECREF(width_specifier);
+    }
+
+    Py_DECREF(segment);
+    Py_DECREF(width_fn);
+    return width;
+}
+
 // Here, mark is the start of the node, while p->mark is the end.
 // If node==NULL, they should be the same.
 int
diff --git a/Parser/pegen.h b/Parser/pegen.h
index a8bfa786b9..268f380262 100644
--- a/Parser/pegen.h
+++ b/Parser/pegen.h
@@ -151,6 +151,7 @@ expr_ty _PyPegen_name_token(Parser *p);
 expr_ty _PyPegen_number_token(Parser *p);
 void *_PyPegen_string_token(Parser *p);
 Py_ssize_t _PyPegen_byte_offset_to_character_offset(PyObject *line, Py_ssize_t col_offset);
+Py_ssize_t _PyPegen_calculate_display_width(PyObject *segment, Py_ssize_t character_offset);
 
 // Error handling functions and APIs
 typedef enum {
diff --git a/Parser/pegen_errors.c b/Parser/pegen_errors.c
index b2fca019f6..6390a66719 100644
--- a/Parser/pegen_errors.c
+++ b/Parser/pegen_errors.c
@@ -66,6 +66,7 @@ _Pypegen_tokenizer_error(Parser *p)
     const char *msg = NULL;
     PyObject* errtype = PyExc_SyntaxError;
     Py_ssize_t col_offset = -1;
+    p->error_indicator = 1;
     switch (p->tok->done) {
         case E_TOKEN:
             msg = "invalid token";
@@ -101,6 +102,10 @@ _Pypegen_tokenizer_error(Parser *p)
             msg = "unexpected character after line continuation character";
             break;
         }
+        case E_COLUMNOVERFLOW:
+            PyErr_SetString(PyExc_OverflowError,
+                    "Parser column offset overflow - source line is too big");
+            return -1;
         default:
             msg = "unknown parsing error";
     }
@@ -309,21 +314,6 @@ _PyPegen_raise_error_known_location(Parser *p, PyObject *errtype,
         end_col_offset = p->tok->cur - p->tok->line_start;
     }
 
-    if (p->start_rule == Py_fstring_input) {
-        const char *fstring_msg = "f-string: ";
-        Py_ssize_t len = strlen(fstring_msg) + strlen(errmsg);
-
-        char *new_errmsg = PyMem_Malloc(len + 1); // Lengths of both strings plus NULL character
-        if (!new_errmsg) {
-            return (void *) PyErr_NoMemory();
-        }
-
-        // Copy both strings into new buffer
-        memcpy(new_errmsg, fstring_msg, strlen(fstring_msg));
-        memcpy(new_errmsg + strlen(fstring_msg), errmsg, strlen(errmsg));
-        new_errmsg[len] = 0;
-        errmsg = new_errmsg;
-    }
     errstr = PyUnicode_FromFormatV(errmsg, va);
     if (!errstr) {
         goto error;
@@ -362,11 +352,6 @@ _PyPegen_raise_error_known_location(Parser *p, PyObject *errtype,
         }
     }
 
-    if (p->start_rule == Py_fstring_input) {
-        col_offset -= p->starting_col_offset;
-        end_col_offset -= p->starting_col_offset;
-    }
-
     Py_ssize_t col_number = col_offset;
     Py_ssize_t end_col_number = end_col_offset;
 
@@ -397,17 +382,11 @@ _PyPegen_raise_error_known_location(Parser *p, PyObject *errtype,
 
     Py_DECREF(errstr);
     Py_DECREF(value);
-    if (p->start_rule == Py_fstring_input) {
-        PyMem_Free((void *)errmsg);
-    }
     return NULL;
 
 error:
     Py_XDECREF(errstr);
     Py_XDECREF(error_line);
-    if (p->start_rule == Py_fstring_input) {
-        PyMem_Free((void *)errmsg);
-    }
     return NULL;
 }
 
diff --git a/Parser/string_parser.c b/Parser/string_parser.c
index 20459e8946..65c320c217 100644
--- a/Parser/string_parser.c
+++ b/Parser/string_parser.c
@@ -11,6 +11,11 @@
 static int
 warn_invalid_escape_sequence(Parser *p, const char *first_invalid_escape, Token *t)
 {
+    if (p->call_invalid_rules) {
+        // Do not report warnings if we are in the second pass of the parser
+        // to avoid showing the warning twice.
+        return 0;
+    }
     unsigned char c = *first_invalid_escape;
     if ((t->type == FSTRING_MIDDLE || t->type == FSTRING_END) && (c == '{' || c == '}')) {  // in this case the tokenizer has already emitted a warning,
                                                                                             // see tokenizer.c:warn_invalid_escape_sequence
diff --git a/Parser/tokenizer.c b/Parser/tokenizer.c
index c4c345e4c3..a59b728e60 100644
--- a/Parser/tokenizer.c
+++ b/Parser/tokenizer.c
@@ -1366,6 +1366,10 @@ tok_nextc(struct tok_state *tok)
     int rc;
     for (;;) {
         if (tok->cur != tok->inp) {
+            if ((unsigned int) tok->col_offset >= (unsigned int) INT_MAX) {
+                tok->done = E_COLUMNOVERFLOW;
+                return EOF;
+            }
             tok->col_offset++;
             return Py_CHARMASK(*tok->cur++); /* Fast path */
         }
@@ -1648,7 +1652,7 @@ verify_end_of_number(struct tok_state *tok, int c, const char *kind) {
         tok_nextc(tok);
     }
     else /* In future releases, only error will remain. */
-    if (is_potential_identifier_char(c)) {
+    if (c < 128 && is_potential_identifier_char(c)) {
         tok_backup(tok, c);
         syntaxerror(tok, "invalid %s literal", kind);
         return 0;
@@ -2768,11 +2772,28 @@ tok_get_fstring_mode(struct tok_state *tok, tokenizer_mode* current_tok, struct
         if (tok->done == E_ERROR) {
             return MAKE_TOKEN(ERRORTOKEN);
         }
-        if (c == EOF || (current_tok->f_string_quote_size == 1 && c == '\n')) {
+        int in_format_spec = (
+                current_tok->last_expr_end != -1
+                &&
+                INSIDE_FSTRING_EXPR(current_tok)
+        );
+
+       if (c == EOF || (current_tok->f_string_quote_size == 1 && c == '\n')) {
             if (tok->decoding_erred) {
                 return MAKE_TOKEN(ERRORTOKEN);
             }
 
+            // If we are in a format spec and we found a newline,
+            // it means that the format spec ends here and we should
+            // return to the regular mode.
+            if (in_format_spec && c == '\n') {
+                tok_backup(tok, c);
+                TOK_GET_MODE(tok)->kind = TOK_REGULAR_MODE;
+                p_start = tok->start;
+                p_end = tok->cur;
+                return MAKE_TOKEN(FSTRING_MIDDLE);
+            }
+
             assert(tok->multi_line_start != NULL);
             // shift the tok_state's location into
             // the start of string, and report the error
@@ -2804,11 +2825,6 @@ tok_get_fstring_mode(struct tok_state *tok, tokenizer_mode* current_tok, struct
             end_quote_size = 0;
         }
 
-        int in_format_spec = (
-                current_tok->last_expr_end != -1
-                &&
-                INSIDE_FSTRING_EXPR(current_tok)
-        );
         if (c == '{') {
             int peek = tok_nextc(tok);
             if (peek != '{' || in_format_spec) {
diff --git a/Python/ast.c b/Python/ast.c
index a3acf78ac9..82d7beec0e 100644
--- a/Python/ast.c
+++ b/Python/ast.c
@@ -381,6 +381,11 @@ validate_expr(struct validator *state, expr_ty exp, expr_context_ty ctx)
         ret = validate_exprs(state, exp->v.Tuple.elts, ctx, 0);
         break;
     case NamedExpr_kind:
+        if (exp->v.NamedExpr.target->kind != Name_kind) {
+            PyErr_SetString(PyExc_TypeError,
+                            "NamedExpr target must be a Name");
+            return 0;
+        }
         ret = validate_expr(state, exp->v.NamedExpr.value, Load);
         break;
     /* This last case doesn't have any checking. */
diff --git a/Python/bytecodes.c b/Python/bytecodes.c
index dfebaaa300..b957d8895b 100644
--- a/Python/bytecodes.c
+++ b/Python/bytecodes.c
@@ -1425,7 +1425,6 @@ dummy_func(
                     Py_INCREF(value);
                 }
                 else if (_PyErr_Occurred(tstate)) {
-                    Py_DECREF(class_dict);
                     goto error;
                 }
             }
@@ -1433,13 +1432,11 @@ dummy_func(
                 value = PyObject_GetItem(class_dict, name);
                 if (value == NULL) {
                     if (!_PyErr_ExceptionMatches(tstate, PyExc_KeyError)) {
-                        Py_DECREF(class_dict);
                         goto error;
                     }
                     _PyErr_Clear(tstate);
                 }
             }
-            Py_DECREF(class_dict);
             if (!value) {
                 PyObject *cell = GETLOCAL(oparg);
                 value = PyCell_GET(cell);
@@ -1449,6 +1446,7 @@ dummy_func(
                 }
                 Py_INCREF(value);
             }
+            Py_DECREF(class_dict);
         }
 
         inst(LOAD_DEREF, ( -- value)) {
@@ -1543,9 +1541,6 @@ dummy_func(
                     values, 2,
                     values+1, 2,
                     oparg);
-            if (map == NULL)
-                goto error;
-
             DECREF_INPUTS();
             ERROR_IF(map == NULL, error);
         }
diff --git a/Python/ceval.c b/Python/ceval.c
index fdb5b72e6c..4845ec04f0 100644
--- a/Python/ceval.c
+++ b/Python/ceval.c
@@ -489,7 +489,9 @@ match_class(PyThreadState *tstate, PyObject *subject, PyObject *type,
         }
         if (match_self) {
             // Easy. Copy the subject itself, and move on to kwargs.
-            PyList_Append(attrs, subject);
+            if (PyList_Append(attrs, subject) < 0) {
+                goto fail;
+            }
         }
         else {
             for (Py_ssize_t i = 0; i < nargs; i++) {
@@ -505,7 +507,10 @@ match_class(PyThreadState *tstate, PyObject *subject, PyObject *type,
                 if (attr == NULL) {
                     goto fail;
                 }
-                PyList_Append(attrs, attr);
+                if (PyList_Append(attrs, attr) < 0) {
+                    Py_DECREF(attr);
+                    goto fail;
+                }
                 Py_DECREF(attr);
             }
         }
@@ -518,7 +523,10 @@ match_class(PyThreadState *tstate, PyObject *subject, PyObject *type,
         if (attr == NULL) {
             goto fail;
         }
-        PyList_Append(attrs, attr);
+        if (PyList_Append(attrs, attr) < 0) {
+            Py_DECREF(attr);
+            goto fail;
+        }
         Py_DECREF(attr);
     }
     Py_SETREF(attrs, PyList_AsTuple(attrs));
diff --git a/Python/ceval_gil.c b/Python/ceval_gil.c
index aacf2b5c2e..c1ab588356 100644
--- a/Python/ceval_gil.c
+++ b/Python/ceval_gil.c
@@ -162,16 +162,6 @@ UNSIGNAL_ASYNC_EXC(PyInterpreterState *interp)
     COMPUTE_EVAL_BREAKER(interp, ceval, ceval2);
 }
 
-#ifndef NDEBUG
-/* Ensure that tstate is valid */
-static int
-is_tstate_valid(PyThreadState *tstate)
-{
-    assert(!_PyMem_IsPtrFreed(tstate));
-    assert(!_PyMem_IsPtrFreed(tstate->interp));
-    return 1;
-}
-#endif
 
 /*
  * Implementation of the Global Interpreter Lock (GIL).
@@ -324,7 +314,7 @@ drop_gil(struct _ceval_state *ceval, PyThreadState *tstate)
         /* Not switched yet => wait */
         if (((PyThreadState*)_Py_atomic_load_relaxed(&gil->last_holder)) == tstate)
         {
-            assert(is_tstate_valid(tstate));
+            assert(_PyThreadState_CheckConsistency(tstate));
             RESET_GIL_DROP_REQUEST(tstate->interp);
             /* NOTE: if COND_WAIT does not atomically start waiting when
                releasing the mutex, another thread can run through, take
@@ -338,28 +328,6 @@ drop_gil(struct _ceval_state *ceval, PyThreadState *tstate)
 }
 
 
-/* Check if a Python thread must exit immediately, rather than taking the GIL
-   if Py_Finalize() has been called.
-
-   When this function is called by a daemon thread after Py_Finalize() has been
-   called, the GIL does no longer exist.
-
-   tstate must be non-NULL. */
-static inline int
-tstate_must_exit(PyThreadState *tstate)
-{
-    /* bpo-39877: Access _PyRuntime directly rather than using
-       tstate->interp->runtime to support calls from Python daemon threads.
-       After Py_Finalize() has been called, tstate can be a dangling pointer:
-       point to PyThreadState freed memory. */
-    PyThreadState *finalizing = _PyRuntimeState_GetFinalizing(&_PyRuntime);
-    if (finalizing == NULL) {
-        finalizing = _PyInterpreterState_GetFinalizing(tstate->interp);
-    }
-    return (finalizing != NULL && finalizing != tstate);
-}
-
-
 /* Take the GIL.
 
    The function saves errno at entry and restores its value at exit.
@@ -375,7 +343,7 @@ take_gil(PyThreadState *tstate)
     // XXX It may be more correct to check tstate->_status.finalizing.
     // XXX assert(!tstate->_status.cleared);
 
-    if (tstate_must_exit(tstate)) {
+    if (_PyThreadState_MustExit(tstate)) {
         /* bpo-39877: If Py_Finalize() has been called and tstate is not the
            thread which called Py_Finalize(), exit immediately the thread.
 
@@ -385,7 +353,7 @@ take_gil(PyThreadState *tstate)
         PyThread_exit_thread();
     }
 
-    assert(is_tstate_valid(tstate));
+    assert(_PyThreadState_CheckConsistency(tstate));
     PyInterpreterState *interp = tstate->interp;
     struct _ceval_state *ceval = &interp->ceval;
     struct _gil_runtime_state *gil = ceval->gil;
@@ -413,7 +381,7 @@ take_gil(PyThreadState *tstate)
             _Py_atomic_load_relaxed(&gil->locked) &&
             gil->switch_number == saved_switchnum)
         {
-            if (tstate_must_exit(tstate)) {
+            if (_PyThreadState_MustExit(tstate)) {
                 MUTEX_UNLOCK(gil->mutex);
                 // gh-96387: If the loop requested a drop request in a previous
                 // iteration, reset the request. Otherwise, drop_gil() can
@@ -426,7 +394,7 @@ take_gil(PyThreadState *tstate)
                 }
                 PyThread_exit_thread();
             }
-            assert(is_tstate_valid(tstate));
+            assert(_PyThreadState_CheckConsistency(tstate));
 
             SET_GIL_DROP_REQUEST(interp);
             drop_requested = 1;
@@ -453,7 +421,7 @@ take_gil(PyThreadState *tstate)
     MUTEX_UNLOCK(gil->switch_mutex);
 #endif
 
-    if (tstate_must_exit(tstate)) {
+    if (_PyThreadState_MustExit(tstate)) {
         /* bpo-36475: If Py_Finalize() has been called and tstate is not
            the thread which called Py_Finalize(), exit immediately the
            thread.
@@ -465,7 +433,7 @@ take_gil(PyThreadState *tstate)
         drop_gil(ceval, tstate);
         PyThread_exit_thread();
     }
-    assert(is_tstate_valid(tstate));
+    assert(_PyThreadState_CheckConsistency(tstate));
 
     if (_Py_atomic_load_relaxed(&ceval->gil_drop_request)) {
         RESET_GIL_DROP_REQUEST(interp);
@@ -673,7 +641,7 @@ PyEval_AcquireThread(PyThreadState *tstate)
 void
 PyEval_ReleaseThread(PyThreadState *tstate)
 {
-    assert(is_tstate_valid(tstate));
+    assert(_PyThreadState_CheckConsistency(tstate));
 
     PyThreadState *new_tstate = _PyThreadState_SwapNoGIL(NULL);
     if (new_tstate != tstate) {
@@ -871,7 +839,7 @@ Py_AddPendingCall(int (*func)(void *), void *arg)
 static int
 handle_signals(PyThreadState *tstate)
 {
-    assert(is_tstate_valid(tstate));
+    assert(_PyThreadState_CheckConsistency(tstate));
     if (!_Py_ThreadCanHandleSignals(tstate->interp)) {
         return 0;
     }
@@ -977,7 +945,7 @@ void
 _Py_FinishPendingCalls(PyThreadState *tstate)
 {
     assert(PyGILState_Check());
-    assert(is_tstate_valid(tstate));
+    assert(_PyThreadState_CheckConsistency(tstate));
 
     if (make_pending_calls(tstate->interp) < 0) {
         PyObject *exc = _PyErr_GetRaisedException(tstate);
@@ -1018,7 +986,7 @@ Py_MakePendingCalls(void)
     assert(PyGILState_Check());
 
     PyThreadState *tstate = _PyThreadState_GET();
-    assert(is_tstate_valid(tstate));
+    assert(_PyThreadState_CheckConsistency(tstate));
 
     /* Only execute pending calls on the main thread. */
     if (!_Py_IsMainThread() || !_Py_IsMainInterpreter(tstate->interp)) {
diff --git a/Python/flowgraph.c b/Python/flowgraph.c
index f860631a6c..afcae31740 100644
--- a/Python/flowgraph.c
+++ b/Python/flowgraph.c
@@ -981,7 +981,17 @@ remove_redundant_nops(basicblock *bb) {
                 }
                 /* or if last instruction in BB and next BB has same line number */
                 if (next) {
-                    if (lineno == next->b_instr[0].i_loc.lineno) {
+                    location next_loc = NO_LOCATION;
+                    for (int next_i=0; next_i < next->b_iused; next_i++) {
+                        cfg_instr *instr = &next->b_instr[next_i];
+                        if (instr->i_opcode == NOP && instr->i_loc.lineno == NO_LOCATION.lineno) {
+                            /* Skip over NOPs without location, they will be removed */
+                            continue;
+                        }
+                        next_loc = instr->i_loc;
+                        break;
+                    }
+                    if (lineno == next_loc.lineno) {
                         continue;
                     }
                 }
diff --git a/Python/generated_cases.c.h b/Python/generated_cases.c.h
index e4cff7bdc3..ea17c0410b 100644
--- a/Python/generated_cases.c.h
+++ b/Python/generated_cases.c.h
@@ -1939,7 +1939,6 @@
                     Py_INCREF(value);
                 }
                 else if (_PyErr_Occurred(tstate)) {
-                    Py_DECREF(class_dict);
                     goto error;
                 }
             }
@@ -1947,13 +1946,11 @@
                 value = PyObject_GetItem(class_dict, name);
                 if (value == NULL) {
                     if (!_PyErr_ExceptionMatches(tstate, PyExc_KeyError)) {
-                        Py_DECREF(class_dict);
                         goto error;
                     }
                     _PyErr_Clear(tstate);
                 }
             }
-            Py_DECREF(class_dict);
             if (!value) {
                 PyObject *cell = GETLOCAL(oparg);
                 value = PyCell_GET(cell);
@@ -1963,14 +1960,15 @@
                 }
                 Py_INCREF(value);
             }
-            #line 1967 "Python/generated_cases.c.h"
+            Py_DECREF(class_dict);
+            #line 1965 "Python/generated_cases.c.h"
             stack_pointer[-1] = value;
             DISPATCH();
         }
 
         TARGET(LOAD_DEREF) {
             PyObject *value;
-            #line 1455 "Python/bytecodes.c"
+            #line 1453 "Python/bytecodes.c"
             PyObject *cell = GETLOCAL(oparg);
             value = PyCell_GET(cell);
             if (value == NULL) {
@@ -1978,7 +1976,7 @@
                 if (true) goto error;
             }
             Py_INCREF(value);
-            #line 1982 "Python/generated_cases.c.h"
+            #line 1980 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = value;
             DISPATCH();
@@ -1986,18 +1984,18 @@
 
         TARGET(STORE_DEREF) {
             PyObject *v = stack_pointer[-1];
-            #line 1465 "Python/bytecodes.c"
+            #line 1463 "Python/bytecodes.c"
             PyObject *cell = GETLOCAL(oparg);
             PyObject *oldobj = PyCell_GET(cell);
             PyCell_SET(cell, v);
             Py_XDECREF(oldobj);
-            #line 1995 "Python/generated_cases.c.h"
+            #line 1993 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             DISPATCH();
         }
 
         TARGET(COPY_FREE_VARS) {
-            #line 1472 "Python/bytecodes.c"
+            #line 1470 "Python/bytecodes.c"
             /* Copy closure variables to free variables */
             PyCodeObject *co = frame->f_code;
             assert(PyFunction_Check(frame->f_funcobj));
@@ -2008,22 +2006,22 @@
                 PyObject *o = PyTuple_GET_ITEM(closure, i);
                 frame->localsplus[offset + i] = Py_NewRef(o);
             }
-            #line 2012 "Python/generated_cases.c.h"
+            #line 2010 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(BUILD_STRING) {
             PyObject **pieces = (stack_pointer - oparg);
             PyObject *str;
-            #line 1485 "Python/bytecodes.c"
+            #line 1483 "Python/bytecodes.c"
             str = _PyUnicode_JoinArray(&_Py_STR(empty), pieces, oparg);
-            #line 2021 "Python/generated_cases.c.h"
+            #line 2019 "Python/generated_cases.c.h"
             for (int _i = oparg; --_i >= 0;) {
                 Py_DECREF(pieces[_i]);
             }
-            #line 1487 "Python/bytecodes.c"
+            #line 1485 "Python/bytecodes.c"
             if (str == NULL) { STACK_SHRINK(oparg); goto error; }
-            #line 2027 "Python/generated_cases.c.h"
+            #line 2025 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_GROW(1);
             stack_pointer[-1] = str;
@@ -2033,10 +2031,10 @@
         TARGET(BUILD_TUPLE) {
             PyObject **values = (stack_pointer - oparg);
             PyObject *tup;
-            #line 1491 "Python/bytecodes.c"
+            #line 1489 "Python/bytecodes.c"
             tup = _PyTuple_FromArraySteal(values, oparg);
             if (tup == NULL) { STACK_SHRINK(oparg); goto error; }
-            #line 2040 "Python/generated_cases.c.h"
+            #line 2038 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_GROW(1);
             stack_pointer[-1] = tup;
@@ -2046,10 +2044,10 @@
         TARGET(BUILD_LIST) {
             PyObject **values = (stack_pointer - oparg);
             PyObject *list;
-            #line 1496 "Python/bytecodes.c"
+            #line 1494 "Python/bytecodes.c"
             list = _PyList_FromArraySteal(values, oparg);
             if (list == NULL) { STACK_SHRINK(oparg); goto error; }
-            #line 2053 "Python/generated_cases.c.h"
+            #line 2051 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_GROW(1);
             stack_pointer[-1] = list;
@@ -2059,7 +2057,7 @@
         TARGET(LIST_EXTEND) {
             PyObject *iterable = stack_pointer[-1];
             PyObject *list = stack_pointer[-(2 + (oparg-1))];
-            #line 1501 "Python/bytecodes.c"
+            #line 1499 "Python/bytecodes.c"
             PyObject *none_val = _PyList_Extend((PyListObject *)list, iterable);
             if (none_val == NULL) {
                 if (_PyErr_ExceptionMatches(tstate, PyExc_TypeError) &&
@@ -2070,13 +2068,13 @@
                           "Value after * must be an iterable, not %.200s",
                           Py_TYPE(iterable)->tp_name);
                 }
-            #line 2074 "Python/generated_cases.c.h"
+            #line 2072 "Python/generated_cases.c.h"
                 Py_DECREF(iterable);
-            #line 1512 "Python/bytecodes.c"
+            #line 1510 "Python/bytecodes.c"
                 if (true) goto pop_1_error;
             }
             assert(Py_IsNone(none_val));
-            #line 2080 "Python/generated_cases.c.h"
+            #line 2078 "Python/generated_cases.c.h"
             Py_DECREF(iterable);
             STACK_SHRINK(1);
             DISPATCH();
@@ -2085,13 +2083,13 @@
         TARGET(SET_UPDATE) {
             PyObject *iterable = stack_pointer[-1];
             PyObject *set = stack_pointer[-(2 + (oparg-1))];
-            #line 1519 "Python/bytecodes.c"
+            #line 1517 "Python/bytecodes.c"
             int err = _PySet_Update(set, iterable);
-            #line 2091 "Python/generated_cases.c.h"
+            #line 2089 "Python/generated_cases.c.h"
             Py_DECREF(iterable);
-            #line 1521 "Python/bytecodes.c"
+            #line 1519 "Python/bytecodes.c"
             if (err < 0) goto pop_1_error;
-            #line 2095 "Python/generated_cases.c.h"
+            #line 2093 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             DISPATCH();
         }
@@ -2099,7 +2097,7 @@
         TARGET(BUILD_SET) {
             PyObject **values = (stack_pointer - oparg);
             PyObject *set;
-            #line 1525 "Python/bytecodes.c"
+            #line 1523 "Python/bytecodes.c"
             set = PySet_New(NULL);
             if (set == NULL)
                 goto error;
@@ -2114,7 +2112,7 @@
                 Py_DECREF(set);
                 if (true) { STACK_SHRINK(oparg); goto error; }
             }
-            #line 2118 "Python/generated_cases.c.h"
+            #line 2116 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_GROW(1);
             stack_pointer[-1] = set;
@@ -2124,21 +2122,18 @@
         TARGET(BUILD_MAP) {
             PyObject **values = (stack_pointer - oparg*2);
             PyObject *map;
-            #line 1542 "Python/bytecodes.c"
+            #line 1540 "Python/bytecodes.c"
             map = _PyDict_FromItems(
                     values, 2,
                     values+1, 2,
                     oparg);
-            if (map == NULL)
-                goto error;
-
-            #line 2136 "Python/generated_cases.c.h"
+            #line 2131 "Python/generated_cases.c.h"
             for (int _i = oparg*2; --_i >= 0;) {
                 Py_DECREF(values[_i]);
             }
-            #line 1550 "Python/bytecodes.c"
+            #line 1545 "Python/bytecodes.c"
             if (map == NULL) { STACK_SHRINK(oparg*2); goto error; }
-            #line 2142 "Python/generated_cases.c.h"
+            #line 2137 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg*2);
             STACK_GROW(1);
             stack_pointer[-1] = map;
@@ -2146,7 +2141,7 @@
         }
 
         TARGET(SETUP_ANNOTATIONS) {
-            #line 1554 "Python/bytecodes.c"
+            #line 1549 "Python/bytecodes.c"
             int err;
             PyObject *ann_dict;
             if (LOCALS() == NULL) {
@@ -2186,7 +2181,7 @@
                     Py_DECREF(ann_dict);
                 }
             }
-            #line 2190 "Python/generated_cases.c.h"
+            #line 2185 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
@@ -2194,7 +2189,7 @@
             PyObject *keys = stack_pointer[-1];
             PyObject **values = (stack_pointer - (1 + oparg));
             PyObject *map;
-            #line 1596 "Python/bytecodes.c"
+            #line 1591 "Python/bytecodes.c"
             if (!PyTuple_CheckExact(keys) ||
                 PyTuple_GET_SIZE(keys) != (Py_ssize_t)oparg) {
                 _PyErr_SetString(tstate, PyExc_SystemError,
@@ -2204,14 +2199,14 @@
             map = _PyDict_FromItems(
                     &PyTuple_GET_ITEM(keys, 0), 1,
                     values, 1, oparg);
-            #line 2208 "Python/generated_cases.c.h"
+            #line 2203 "Python/generated_cases.c.h"
             for (int _i = oparg; --_i >= 0;) {
                 Py_DECREF(values[_i]);
             }
             Py_DECREF(keys);
-            #line 1606 "Python/bytecodes.c"
+            #line 1601 "Python/bytecodes.c"
             if (map == NULL) { STACK_SHRINK(oparg); goto pop_1_error; }
-            #line 2215 "Python/generated_cases.c.h"
+            #line 2210 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             stack_pointer[-1] = map;
             DISPATCH();
@@ -2219,7 +2214,7 @@
 
         TARGET(DICT_UPDATE) {
             PyObject *update = stack_pointer[-1];
-            #line 1610 "Python/bytecodes.c"
+            #line 1605 "Python/bytecodes.c"
             PyObject *dict = PEEK(oparg + 1);  // update is still on the stack
             if (PyDict_Update(dict, update) < 0) {
                 if (_PyErr_ExceptionMatches(tstate, PyExc_AttributeError)) {
@@ -2227,12 +2222,12 @@
                                     "'%.200s' object is not a mapping",
                                     Py_TYPE(update)->tp_name);
                 }
-            #line 2231 "Python/generated_cases.c.h"
+            #line 2226 "Python/generated_cases.c.h"
                 Py_DECREF(update);
-            #line 1618 "Python/bytecodes.c"
+            #line 1613 "Python/bytecodes.c"
                 if (true) goto pop_1_error;
             }
-            #line 2236 "Python/generated_cases.c.h"
+            #line 2231 "Python/generated_cases.c.h"
             Py_DECREF(update);
             STACK_SHRINK(1);
             DISPATCH();
@@ -2240,17 +2235,17 @@
 
         TARGET(DICT_MERGE) {
             PyObject *update = stack_pointer[-1];
-            #line 1624 "Python/bytecodes.c"
+            #line 1619 "Python/bytecodes.c"
             PyObject *dict = PEEK(oparg + 1);  // update is still on the stack
 
             if (_PyDict_MergeEx(dict, update, 2) < 0) {
                 format_kwargs_error(tstate, PEEK(3 + oparg), update);
-            #line 2249 "Python/generated_cases.c.h"
+            #line 2244 "Python/generated_cases.c.h"
                 Py_DECREF(update);
-            #line 1629 "Python/bytecodes.c"
+            #line 1624 "Python/bytecodes.c"
                 if (true) goto pop_1_error;
             }
-            #line 2254 "Python/generated_cases.c.h"
+            #line 2249 "Python/generated_cases.c.h"
             Py_DECREF(update);
             STACK_SHRINK(1);
             PREDICT(CALL_FUNCTION_EX);
@@ -2260,26 +2255,26 @@
         TARGET(MAP_ADD) {
             PyObject *value = stack_pointer[-1];
             PyObject *key = stack_pointer[-2];
-            #line 1636 "Python/bytecodes.c"
+            #line 1631 "Python/bytecodes.c"
             PyObject *dict = PEEK(oparg + 2);  // key, value are still on the stack
             assert(PyDict_CheckExact(dict));
             /* dict[key] = value */
             // Do not DECREF INPUTS because the function steals the references
             if (_PyDict_SetItem_Take2((PyDictObject *)dict, key, value) != 0) goto pop_2_error;
-            #line 2270 "Python/generated_cases.c.h"
+            #line 2265 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             PREDICT(JUMP_BACKWARD);
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_LOAD_SUPER_ATTR) {
-            #line 1645 "Python/bytecodes.c"
+            #line 1640 "Python/bytecodes.c"
             _PySuperAttrCache *cache = (_PySuperAttrCache *)next_instr;
             // cancel out the decrement that will happen in LOAD_SUPER_ATTR; we
             // don't want to specialize instrumented instructions
             INCREMENT_ADAPTIVE_COUNTER(cache->counter);
             GO_TO_INSTRUCTION(LOAD_SUPER_ATTR);
-            #line 2283 "Python/generated_cases.c.h"
+            #line 2278 "Python/generated_cases.c.h"
         }
 
         TARGET(LOAD_SUPER_ATTR) {
@@ -2290,7 +2285,7 @@
             PyObject *global_super = stack_pointer[-3];
             PyObject *res2 = NULL;
             PyObject *res;
-            #line 1659 "Python/bytecodes.c"
+            #line 1654 "Python/bytecodes.c"
             PyObject *name = GETITEM(frame->f_code->co_names, oparg >> 2);
             int load_method = oparg & 1;
             #if ENABLE_SPECIALIZATION
@@ -2332,16 +2327,16 @@
                     }
                 }
             }
-            #line 2336 "Python/generated_cases.c.h"
+            #line 2331 "Python/generated_cases.c.h"
             Py_DECREF(global_super);
             Py_DECREF(class);
             Py_DECREF(self);
-            #line 1701 "Python/bytecodes.c"
+            #line 1696 "Python/bytecodes.c"
             if (super == NULL) goto pop_3_error;
             res = PyObject_GetAttr(super, name);
             Py_DECREF(super);
             if (res == NULL) goto pop_3_error;
-            #line 2345 "Python/generated_cases.c.h"
+            #line 2340 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2356,20 +2351,20 @@
             PyObject *global_super = stack_pointer[-3];
             PyObject *res2 = NULL;
             PyObject *res;
-            #line 1708 "Python/bytecodes.c"
+            #line 1703 "Python/bytecodes.c"
             assert(!(oparg & 1));
             DEOPT_IF(global_super != (PyObject *)&PySuper_Type, LOAD_SUPER_ATTR);
             DEOPT_IF(!PyType_Check(class), LOAD_SUPER_ATTR);
             STAT_INC(LOAD_SUPER_ATTR, hit);
             PyObject *name = GETITEM(frame->f_code->co_names, oparg >> 2);
             res = _PySuper_Lookup((PyTypeObject *)class, self, name, NULL);
-            #line 2367 "Python/generated_cases.c.h"
+            #line 2362 "Python/generated_cases.c.h"
             Py_DECREF(global_super);
             Py_DECREF(class);
             Py_DECREF(self);
-            #line 1715 "Python/bytecodes.c"
+            #line 1710 "Python/bytecodes.c"
             if (res == NULL) goto pop_3_error;
-            #line 2373 "Python/generated_cases.c.h"
+            #line 2368 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2384,7 +2379,7 @@
             PyObject *global_super = stack_pointer[-3];
             PyObject *res2;
             PyObject *res;
-            #line 1719 "Python/bytecodes.c"
+            #line 1714 "Python/bytecodes.c"
             assert(oparg & 1);
             DEOPT_IF(global_super != (PyObject *)&PySuper_Type, LOAD_SUPER_ATTR);
             DEOPT_IF(!PyType_Check(class), LOAD_SUPER_ATTR);
@@ -2407,7 +2402,7 @@
                 res = res2;
                 res2 = NULL;
             }
-            #line 2411 "Python/generated_cases.c.h"
+            #line 2406 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             stack_pointer[-2] = res2;
@@ -2421,7 +2416,7 @@
             PyObject *owner = stack_pointer[-1];
             PyObject *res2 = NULL;
             PyObject *res;
-            #line 1758 "Python/bytecodes.c"
+            #line 1753 "Python/bytecodes.c"
             #if ENABLE_SPECIALIZATION
             _PyAttrCache *cache = (_PyAttrCache *)next_instr;
             if (ADAPTIVE_COUNTER_IS_ZERO(cache->counter)) {
@@ -2455,9 +2450,9 @@
 
                        NULL | meth | arg1 | ... | argN
                     */
-            #line 2459 "Python/generated_cases.c.h"
+            #line 2454 "Python/generated_cases.c.h"
                     Py_DECREF(owner);
-            #line 1792 "Python/bytecodes.c"
+            #line 1787 "Python/bytecodes.c"
                     if (meth == NULL) goto pop_1_error;
                     res2 = NULL;
                     res = meth;
@@ -2466,12 +2461,12 @@
             else {
                 /* Classic, pushes one value. */
                 res = PyObject_GetAttr(owner, name);
-            #line 2470 "Python/generated_cases.c.h"
+            #line 2465 "Python/generated_cases.c.h"
                 Py_DECREF(owner);
-            #line 1801 "Python/bytecodes.c"
+            #line 1796 "Python/bytecodes.c"
                 if (res == NULL) goto pop_1_error;
             }
-            #line 2475 "Python/generated_cases.c.h"
+            #line 2470 "Python/generated_cases.c.h"
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
             if (oparg & 1) { stack_pointer[-(1 + ((oparg & 1) ? 1 : 0))] = res2; }
@@ -2485,7 +2480,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t index = read_u16(&next_instr[3].cache);
-            #line 1806 "Python/bytecodes.c"
+            #line 1801 "Python/bytecodes.c"
             PyTypeObject *tp = Py_TYPE(owner);
             assert(type_version != 0);
             DEOPT_IF(tp->tp_version_tag != type_version, LOAD_ATTR);
@@ -2498,7 +2493,7 @@
             STAT_INC(LOAD_ATTR, hit);
             Py_INCREF(res);
             res2 = NULL;
-            #line 2502 "Python/generated_cases.c.h"
+            #line 2497 "Python/generated_cases.c.h"
             Py_DECREF(owner);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2513,7 +2508,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t index = read_u16(&next_instr[3].cache);
-            #line 1822 "Python/bytecodes.c"
+            #line 1817 "Python/bytecodes.c"
             DEOPT_IF(!PyModule_CheckExact(owner), LOAD_ATTR);
             PyDictObject *dict = (PyDictObject *)((PyModuleObject *)owner)->md_dict;
             assert(dict != NULL);
@@ -2526,7 +2521,7 @@
             STAT_INC(LOAD_ATTR, hit);
             Py_INCREF(res);
             res2 = NULL;
-            #line 2530 "Python/generated_cases.c.h"
+            #line 2525 "Python/generated_cases.c.h"
             Py_DECREF(owner);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2541,7 +2536,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t index = read_u16(&next_instr[3].cache);
-            #line 1838 "Python/bytecodes.c"
+            #line 1833 "Python/bytecodes.c"
             PyTypeObject *tp = Py_TYPE(owner);
             assert(type_version != 0);
             DEOPT_IF(tp->tp_version_tag != type_version, LOAD_ATTR);
@@ -2568,7 +2563,7 @@
             STAT_INC(LOAD_ATTR, hit);
             Py_INCREF(res);
             res2 = NULL;
-            #line 2572 "Python/generated_cases.c.h"
+            #line 2567 "Python/generated_cases.c.h"
             Py_DECREF(owner);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2583,7 +2578,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t index = read_u16(&next_instr[3].cache);
-            #line 1868 "Python/bytecodes.c"
+            #line 1863 "Python/bytecodes.c"
             PyTypeObject *tp = Py_TYPE(owner);
             assert(type_version != 0);
             DEOPT_IF(tp->tp_version_tag != type_version, LOAD_ATTR);
@@ -2593,7 +2588,7 @@
             STAT_INC(LOAD_ATTR, hit);
             Py_INCREF(res);
             res2 = NULL;
-            #line 2597 "Python/generated_cases.c.h"
+            #line 2592 "Python/generated_cases.c.h"
             Py_DECREF(owner);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2608,7 +2603,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             PyObject *descr = read_obj(&next_instr[5].cache);
-            #line 1881 "Python/bytecodes.c"
+            #line 1876 "Python/bytecodes.c"
 
             DEOPT_IF(!PyType_Check(cls), LOAD_ATTR);
             DEOPT_IF(((PyTypeObject *)cls)->tp_version_tag != type_version,
@@ -2620,7 +2615,7 @@
             res = descr;
             assert(res != NULL);
             Py_INCREF(res);
-            #line 2624 "Python/generated_cases.c.h"
+            #line 2619 "Python/generated_cases.c.h"
             Py_DECREF(cls);
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
@@ -2634,7 +2629,7 @@
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint32_t func_version = read_u32(&next_instr[3].cache);
             PyObject *fget = read_obj(&next_instr[5].cache);
-            #line 1896 "Python/bytecodes.c"
+            #line 1891 "Python/bytecodes.c"
             DEOPT_IF(tstate->interp->eval_frame, LOAD_ATTR);
 
             PyTypeObject *cls = Py_TYPE(owner);
@@ -2658,7 +2653,7 @@
             JUMPBY(INLINE_CACHE_ENTRIES_LOAD_ATTR);
             frame->return_offset = 0;
             DISPATCH_INLINED(new_frame);
-            #line 2662 "Python/generated_cases.c.h"
+            #line 2657 "Python/generated_cases.c.h"
         }
 
         TARGET(LOAD_ATTR_GETATTRIBUTE_OVERRIDDEN) {
@@ -2666,7 +2661,7 @@
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint32_t func_version = read_u32(&next_instr[3].cache);
             PyObject *getattribute = read_obj(&next_instr[5].cache);
-            #line 1922 "Python/bytecodes.c"
+            #line 1917 "Python/bytecodes.c"
             DEOPT_IF(tstate->interp->eval_frame, LOAD_ATTR);
             PyTypeObject *cls = Py_TYPE(owner);
             DEOPT_IF(cls->tp_version_tag != type_version, LOAD_ATTR);
@@ -2692,7 +2687,7 @@
             JUMPBY(INLINE_CACHE_ENTRIES_LOAD_ATTR);
             frame->return_offset = 0;
             DISPATCH_INLINED(new_frame);
-            #line 2696 "Python/generated_cases.c.h"
+            #line 2691 "Python/generated_cases.c.h"
         }
 
         TARGET(STORE_ATTR_INSTANCE_VALUE) {
@@ -2700,7 +2695,7 @@
             PyObject *value = stack_pointer[-2];
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t index = read_u16(&next_instr[3].cache);
-            #line 1950 "Python/bytecodes.c"
+            #line 1945 "Python/bytecodes.c"
             PyTypeObject *tp = Py_TYPE(owner);
             assert(type_version != 0);
             DEOPT_IF(tp->tp_version_tag != type_version, STORE_ATTR);
@@ -2718,7 +2713,7 @@
                 Py_DECREF(old_value);
             }
             Py_DECREF(owner);
-            #line 2722 "Python/generated_cases.c.h"
+            #line 2717 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             next_instr += 4;
             DISPATCH();
@@ -2729,7 +2724,7 @@
             PyObject *value = stack_pointer[-2];
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t hint = read_u16(&next_instr[3].cache);
-            #line 1970 "Python/bytecodes.c"
+            #line 1965 "Python/bytecodes.c"
             PyTypeObject *tp = Py_TYPE(owner);
             assert(type_version != 0);
             DEOPT_IF(tp->tp_version_tag != type_version, STORE_ATTR);
@@ -2768,7 +2763,7 @@
             /* PEP 509 */
             dict->ma_version_tag = new_version;
             Py_DECREF(owner);
-            #line 2772 "Python/generated_cases.c.h"
+            #line 2767 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             next_instr += 4;
             DISPATCH();
@@ -2779,7 +2774,7 @@
             PyObject *value = stack_pointer[-2];
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint16_t index = read_u16(&next_instr[3].cache);
-            #line 2011 "Python/bytecodes.c"
+            #line 2006 "Python/bytecodes.c"
             PyTypeObject *tp = Py_TYPE(owner);
             assert(type_version != 0);
             DEOPT_IF(tp->tp_version_tag != type_version, STORE_ATTR);
@@ -2789,7 +2784,7 @@
             *(PyObject **)addr = value;
             Py_XDECREF(old_value);
             Py_DECREF(owner);
-            #line 2793 "Python/generated_cases.c.h"
+            #line 2788 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             next_instr += 4;
             DISPATCH();
@@ -2801,7 +2796,7 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *res;
-            #line 2030 "Python/bytecodes.c"
+            #line 2025 "Python/bytecodes.c"
             #if ENABLE_SPECIALIZATION
             _PyCompareOpCache *cache = (_PyCompareOpCache *)next_instr;
             if (ADAPTIVE_COUNTER_IS_ZERO(cache->counter)) {
@@ -2814,12 +2809,12 @@
             #endif  /* ENABLE_SPECIALIZATION */
             assert((oparg >> 4) <= Py_GE);
             res = PyObject_RichCompare(left, right, oparg>>4);
-            #line 2818 "Python/generated_cases.c.h"
+            #line 2813 "Python/generated_cases.c.h"
             Py_DECREF(left);
             Py_DECREF(right);
-            #line 2043 "Python/bytecodes.c"
+            #line 2038 "Python/bytecodes.c"
             if (res == NULL) goto pop_2_error;
-            #line 2823 "Python/generated_cases.c.h"
+            #line 2818 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             next_instr += 1;
@@ -2830,7 +2825,7 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *res;
-            #line 2047 "Python/bytecodes.c"
+            #line 2042 "Python/bytecodes.c"
             DEOPT_IF(!PyFloat_CheckExact(left), COMPARE_OP);
             DEOPT_IF(!PyFloat_CheckExact(right), COMPARE_OP);
             STAT_INC(COMPARE_OP, hit);
@@ -2841,7 +2836,7 @@
             _Py_DECREF_SPECIALIZED(left, _PyFloat_ExactDealloc);
             _Py_DECREF_SPECIALIZED(right, _PyFloat_ExactDealloc);
             res = (sign_ish & oparg) ? Py_True : Py_False;
-            #line 2845 "Python/generated_cases.c.h"
+            #line 2840 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             next_instr += 1;
@@ -2852,7 +2847,7 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *res;
-            #line 2061 "Python/bytecodes.c"
+            #line 2056 "Python/bytecodes.c"
             DEOPT_IF(!PyLong_CheckExact(left), COMPARE_OP);
             DEOPT_IF(!PyLong_CheckExact(right), COMPARE_OP);
             DEOPT_IF(!_PyLong_IsCompact((PyLongObject *)left), COMPARE_OP);
@@ -2867,7 +2862,7 @@
             _Py_DECREF_SPECIALIZED(left, (destructor)PyObject_Free);
             _Py_DECREF_SPECIALIZED(right, (destructor)PyObject_Free);
             res = (sign_ish & oparg) ? Py_True : Py_False;
-            #line 2871 "Python/generated_cases.c.h"
+            #line 2866 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             next_instr += 1;
@@ -2878,7 +2873,7 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *res;
-            #line 2079 "Python/bytecodes.c"
+            #line 2074 "Python/bytecodes.c"
             DEOPT_IF(!PyUnicode_CheckExact(left), COMPARE_OP);
             DEOPT_IF(!PyUnicode_CheckExact(right), COMPARE_OP);
             STAT_INC(COMPARE_OP, hit);
@@ -2890,7 +2885,7 @@
             assert((oparg & 0xf) == COMPARISON_NOT_EQUALS || (oparg & 0xf) == COMPARISON_EQUALS);
             assert(COMPARISON_NOT_EQUALS + 1 == COMPARISON_EQUALS);
             res = ((COMPARISON_NOT_EQUALS + eq) & oparg) ? Py_True : Py_False;
-            #line 2894 "Python/generated_cases.c.h"
+            #line 2889 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             next_instr += 1;
@@ -2901,14 +2896,14 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *b;
-            #line 2093 "Python/bytecodes.c"
+            #line 2088 "Python/bytecodes.c"
             int res = Py_Is(left, right) ^ oparg;
-            #line 2907 "Python/generated_cases.c.h"
+            #line 2902 "Python/generated_cases.c.h"
             Py_DECREF(left);
             Py_DECREF(right);
-            #line 2095 "Python/bytecodes.c"
+            #line 2090 "Python/bytecodes.c"
             b = res ? Py_True : Py_False;
-            #line 2912 "Python/generated_cases.c.h"
+            #line 2907 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = b;
             DISPATCH();
@@ -2918,15 +2913,15 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *b;
-            #line 2099 "Python/bytecodes.c"
+            #line 2094 "Python/bytecodes.c"
             int res = PySequence_Contains(right, left);
-            #line 2924 "Python/generated_cases.c.h"
+            #line 2919 "Python/generated_cases.c.h"
             Py_DECREF(left);
             Py_DECREF(right);
-            #line 2101 "Python/bytecodes.c"
+            #line 2096 "Python/bytecodes.c"
             if (res < 0) goto pop_2_error;
             b = (res ^ oparg) ? Py_True : Py_False;
-            #line 2930 "Python/generated_cases.c.h"
+            #line 2925 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = b;
             DISPATCH();
@@ -2937,12 +2932,12 @@
             PyObject *exc_value = stack_pointer[-2];
             PyObject *rest;
             PyObject *match;
-            #line 2106 "Python/bytecodes.c"
+            #line 2101 "Python/bytecodes.c"
             if (check_except_star_type_valid(tstate, match_type) < 0) {
-            #line 2943 "Python/generated_cases.c.h"
+            #line 2938 "Python/generated_cases.c.h"
                 Py_DECREF(exc_value);
                 Py_DECREF(match_type);
-            #line 2108 "Python/bytecodes.c"
+            #line 2103 "Python/bytecodes.c"
                 if (true) goto pop_2_error;
             }
 
@@ -2950,10 +2945,10 @@
             rest = NULL;
             int res = exception_group_match(exc_value, match_type,
                                             &match, &rest);
-            #line 2954 "Python/generated_cases.c.h"
+            #line 2949 "Python/generated_cases.c.h"
             Py_DECREF(exc_value);
             Py_DECREF(match_type);
-            #line 2116 "Python/bytecodes.c"
+            #line 2111 "Python/bytecodes.c"
             if (res < 0) goto pop_2_error;
 
             assert((match == NULL) == (rest == NULL));
@@ -2962,7 +2957,7 @@
             if (!Py_IsNone(match)) {
                 PyErr_SetHandledException(match);
             }
-            #line 2966 "Python/generated_cases.c.h"
+            #line 2961 "Python/generated_cases.c.h"
             stack_pointer[-1] = match;
             stack_pointer[-2] = rest;
             DISPATCH();
@@ -2972,21 +2967,21 @@
             PyObject *right = stack_pointer[-1];
             PyObject *left = stack_pointer[-2];
             PyObject *b;
-            #line 2127 "Python/bytecodes.c"
+            #line 2122 "Python/bytecodes.c"
             assert(PyExceptionInstance_Check(left));
             if (check_except_type_valid(tstate, right) < 0) {
-            #line 2979 "Python/generated_cases.c.h"
+            #line 2974 "Python/generated_cases.c.h"
                  Py_DECREF(right);
-            #line 2130 "Python/bytecodes.c"
+            #line 2125 "Python/bytecodes.c"
                  if (true) goto pop_1_error;
             }
 
             int res = PyErr_GivenExceptionMatches(left, right);
-            #line 2986 "Python/generated_cases.c.h"
+            #line 2981 "Python/generated_cases.c.h"
             Py_DECREF(right);
-            #line 2135 "Python/bytecodes.c"
+            #line 2130 "Python/bytecodes.c"
             b = res ? Py_True : Py_False;
-            #line 2990 "Python/generated_cases.c.h"
+            #line 2985 "Python/generated_cases.c.h"
             stack_pointer[-1] = b;
             DISPATCH();
         }
@@ -2995,15 +2990,15 @@
             PyObject *fromlist = stack_pointer[-1];
             PyObject *level = stack_pointer[-2];
             PyObject *res;
-            #line 2139 "Python/bytecodes.c"
+            #line 2134 "Python/bytecodes.c"
             PyObject *name = GETITEM(frame->f_code->co_names, oparg);
             res = import_name(tstate, frame, name, fromlist, level);
-            #line 3002 "Python/generated_cases.c.h"
+            #line 2997 "Python/generated_cases.c.h"
             Py_DECREF(level);
             Py_DECREF(fromlist);
-            #line 2142 "Python/bytecodes.c"
+            #line 2137 "Python/bytecodes.c"
             if (res == NULL) goto pop_2_error;
-            #line 3007 "Python/generated_cases.c.h"
+            #line 3002 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             DISPATCH();
@@ -3012,29 +3007,29 @@
         TARGET(IMPORT_FROM) {
             PyObject *from = stack_pointer[-1];
             PyObject *res;
-            #line 2146 "Python/bytecodes.c"
+            #line 2141 "Python/bytecodes.c"
             PyObject *name = GETITEM(frame->f_code->co_names, oparg);
             res = import_from(tstate, from, name);
             if (res == NULL) goto error;
-            #line 3020 "Python/generated_cases.c.h"
+            #line 3015 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = res;
             DISPATCH();
         }
 
         TARGET(JUMP_FORWARD) {
-            #line 2152 "Python/bytecodes.c"
+            #line 2147 "Python/bytecodes.c"
             JUMPBY(oparg);
-            #line 3029 "Python/generated_cases.c.h"
+            #line 3024 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(JUMP_BACKWARD) {
             PREDICTED(JUMP_BACKWARD);
-            #line 2156 "Python/bytecodes.c"
+            #line 2151 "Python/bytecodes.c"
             assert(oparg < INSTR_OFFSET());
             JUMPBY(-oparg);
-            #line 3038 "Python/generated_cases.c.h"
+            #line 3033 "Python/generated_cases.c.h"
             CHECK_EVAL_BREAKER();
             DISPATCH();
         }
@@ -3042,15 +3037,15 @@
         TARGET(POP_JUMP_IF_FALSE) {
             PREDICTED(POP_JUMP_IF_FALSE);
             PyObject *cond = stack_pointer[-1];
-            #line 2162 "Python/bytecodes.c"
+            #line 2157 "Python/bytecodes.c"
             if (Py_IsFalse(cond)) {
                 JUMPBY(oparg);
             }
             else if (!Py_IsTrue(cond)) {
                 int err = PyObject_IsTrue(cond);
-            #line 3052 "Python/generated_cases.c.h"
+            #line 3047 "Python/generated_cases.c.h"
                 Py_DECREF(cond);
-            #line 2168 "Python/bytecodes.c"
+            #line 2163 "Python/bytecodes.c"
                 if (err == 0) {
                     JUMPBY(oparg);
                 }
@@ -3058,22 +3053,22 @@
                     if (err < 0) goto pop_1_error;
                 }
             }
-            #line 3062 "Python/generated_cases.c.h"
+            #line 3057 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             DISPATCH();
         }
 
         TARGET(POP_JUMP_IF_TRUE) {
             PyObject *cond = stack_pointer[-1];
-            #line 2178 "Python/bytecodes.c"
+            #line 2173 "Python/bytecodes.c"
             if (Py_IsTrue(cond)) {
                 JUMPBY(oparg);
             }
             else if (!Py_IsFalse(cond)) {
                 int err = PyObject_IsTrue(cond);
-            #line 3075 "Python/generated_cases.c.h"
+            #line 3070 "Python/generated_cases.c.h"
                 Py_DECREF(cond);
-            #line 2184 "Python/bytecodes.c"
+            #line 2179 "Python/bytecodes.c"
                 if (err > 0) {
                     JUMPBY(oparg);
                 }
@@ -3081,63 +3076,63 @@
                     if (err < 0) goto pop_1_error;
                 }
             }
-            #line 3085 "Python/generated_cases.c.h"
+            #line 3080 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             DISPATCH();
         }
 
         TARGET(POP_JUMP_IF_NOT_NONE) {
             PyObject *value = stack_pointer[-1];
-            #line 2194 "Python/bytecodes.c"
+            #line 2189 "Python/bytecodes.c"
             if (!Py_IsNone(value)) {
-            #line 3094 "Python/generated_cases.c.h"
+            #line 3089 "Python/generated_cases.c.h"
                 Py_DECREF(value);
-            #line 2196 "Python/bytecodes.c"
+            #line 2191 "Python/bytecodes.c"
                 JUMPBY(oparg);
             }
-            #line 3099 "Python/generated_cases.c.h"
+            #line 3094 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             DISPATCH();
         }
 
         TARGET(POP_JUMP_IF_NONE) {
             PyObject *value = stack_pointer[-1];
-            #line 2201 "Python/bytecodes.c"
+            #line 2196 "Python/bytecodes.c"
             if (Py_IsNone(value)) {
                 JUMPBY(oparg);
             }
             else {
-            #line 3111 "Python/generated_cases.c.h"
+            #line 3106 "Python/generated_cases.c.h"
                 Py_DECREF(value);
-            #line 2206 "Python/bytecodes.c"
+            #line 2201 "Python/bytecodes.c"
             }
-            #line 3115 "Python/generated_cases.c.h"
+            #line 3110 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             DISPATCH();
         }
 
         TARGET(JUMP_BACKWARD_NO_INTERRUPT) {
-            #line 2210 "Python/bytecodes.c"
+            #line 2205 "Python/bytecodes.c"
             /* This bytecode is used in the `yield from` or `await` loop.
              * If there is an interrupt, we want it handled in the innermost
              * generator or coroutine, so we deliberately do not check it here.
              * (see bpo-30039).
              */
             JUMPBY(-oparg);
-            #line 3128 "Python/generated_cases.c.h"
+            #line 3123 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(GET_LEN) {
             PyObject *obj = stack_pointer[-1];
             PyObject *len_o;
-            #line 2219 "Python/bytecodes.c"
+            #line 2214 "Python/bytecodes.c"
             // PUSH(len(TOS))
             Py_ssize_t len_i = PyObject_Length(obj);
             if (len_i < 0) goto error;
             len_o = PyLong_FromSsize_t(len_i);
             if (len_o == NULL) goto error;
-            #line 3141 "Python/generated_cases.c.h"
+            #line 3136 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = len_o;
             DISPATCH();
@@ -3148,16 +3143,16 @@
             PyObject *type = stack_pointer[-2];
             PyObject *subject = stack_pointer[-3];
             PyObject *attrs;
-            #line 2227 "Python/bytecodes.c"
+            #line 2222 "Python/bytecodes.c"
             // Pop TOS and TOS1. Set TOS to a tuple of attributes on success, or
             // None on failure.
             assert(PyTuple_CheckExact(names));
             attrs = match_class(tstate, subject, type, oparg, names);
-            #line 3157 "Python/generated_cases.c.h"
+            #line 3152 "Python/generated_cases.c.h"
             Py_DECREF(subject);
             Py_DECREF(type);
             Py_DECREF(names);
-            #line 2232 "Python/bytecodes.c"
+            #line 2227 "Python/bytecodes.c"
             if (attrs) {
                 assert(PyTuple_CheckExact(attrs));  // Success!
             }
@@ -3165,7 +3160,7 @@
                 if (_PyErr_Occurred(tstate)) goto pop_3_error;
                 attrs = Py_None;  // Failure!
             }
-            #line 3169 "Python/generated_cases.c.h"
+            #line 3164 "Python/generated_cases.c.h"
             STACK_SHRINK(2);
             stack_pointer[-1] = attrs;
             DISPATCH();
@@ -3174,10 +3169,10 @@
         TARGET(MATCH_MAPPING) {
             PyObject *subject = stack_pointer[-1];
             PyObject *res;
-            #line 2242 "Python/bytecodes.c"
+            #line 2237 "Python/bytecodes.c"
             int match = Py_TYPE(subject)->tp_flags & Py_TPFLAGS_MAPPING;
             res = match ? Py_True : Py_False;
-            #line 3181 "Python/generated_cases.c.h"
+            #line 3176 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = res;
             PREDICT(POP_JUMP_IF_FALSE);
@@ -3187,10 +3182,10 @@
         TARGET(MATCH_SEQUENCE) {
             PyObject *subject = stack_pointer[-1];
             PyObject *res;
-            #line 2248 "Python/bytecodes.c"
+            #line 2243 "Python/bytecodes.c"
             int match = Py_TYPE(subject)->tp_flags & Py_TPFLAGS_SEQUENCE;
             res = match ? Py_True : Py_False;
-            #line 3194 "Python/generated_cases.c.h"
+            #line 3189 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = res;
             PREDICT(POP_JUMP_IF_FALSE);
@@ -3201,11 +3196,11 @@
             PyObject *keys = stack_pointer[-1];
             PyObject *subject = stack_pointer[-2];
             PyObject *values_or_none;
-            #line 2254 "Python/bytecodes.c"
+            #line 2249 "Python/bytecodes.c"
             // On successful match, PUSH(values). Otherwise, PUSH(None).
             values_or_none = match_keys(tstate, subject, keys);
             if (values_or_none == NULL) goto error;
-            #line 3209 "Python/generated_cases.c.h"
+            #line 3204 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = values_or_none;
             DISPATCH();
@@ -3214,14 +3209,14 @@
         TARGET(GET_ITER) {
             PyObject *iterable = stack_pointer[-1];
             PyObject *iter;
-            #line 2260 "Python/bytecodes.c"
+            #line 2255 "Python/bytecodes.c"
             /* before: [obj]; after [getiter(obj)] */
             iter = PyObject_GetIter(iterable);
-            #line 3221 "Python/generated_cases.c.h"
+            #line 3216 "Python/generated_cases.c.h"
             Py_DECREF(iterable);
-            #line 2263 "Python/bytecodes.c"
+            #line 2258 "Python/bytecodes.c"
             if (iter == NULL) goto pop_1_error;
-            #line 3225 "Python/generated_cases.c.h"
+            #line 3220 "Python/generated_cases.c.h"
             stack_pointer[-1] = iter;
             DISPATCH();
         }
@@ -3229,7 +3224,7 @@
         TARGET(GET_YIELD_FROM_ITER) {
             PyObject *iterable = stack_pointer[-1];
             PyObject *iter;
-            #line 2267 "Python/bytecodes.c"
+            #line 2262 "Python/bytecodes.c"
             /* before: [obj]; after [getiter(obj)] */
             if (PyCoro_CheckExact(iterable)) {
                 /* `iterable` is a coroutine */
@@ -3252,11 +3247,11 @@
                 if (iter == NULL) {
                     goto error;
                 }
-            #line 3256 "Python/generated_cases.c.h"
+            #line 3251 "Python/generated_cases.c.h"
                 Py_DECREF(iterable);
-            #line 2290 "Python/bytecodes.c"
+            #line 2285 "Python/bytecodes.c"
             }
-            #line 3260 "Python/generated_cases.c.h"
+            #line 3255 "Python/generated_cases.c.h"
             stack_pointer[-1] = iter;
             PREDICT(LOAD_CONST);
             DISPATCH();
@@ -3267,7 +3262,7 @@
             static_assert(INLINE_CACHE_ENTRIES_FOR_ITER == 1, "incorrect cache size");
             PyObject *iter = stack_pointer[-1];
             PyObject *next;
-            #line 2309 "Python/bytecodes.c"
+            #line 2304 "Python/bytecodes.c"
             #if ENABLE_SPECIALIZATION
             _PyForIterCache *cache = (_PyForIterCache *)next_instr;
             if (ADAPTIVE_COUNTER_IS_ZERO(cache->counter)) {
@@ -3298,7 +3293,7 @@
                 DISPATCH();
             }
             // Common case: no jump, leave it to the code generator
-            #line 3302 "Python/generated_cases.c.h"
+            #line 3297 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = next;
             next_instr += 1;
@@ -3306,7 +3301,7 @@
         }
 
         TARGET(INSTRUMENTED_FOR_ITER) {
-            #line 2342 "Python/bytecodes.c"
+            #line 2337 "Python/bytecodes.c"
             _Py_CODEUNIT *here = next_instr-1;
             _Py_CODEUNIT *target;
             PyObject *iter = TOP();
@@ -3332,14 +3327,14 @@
                 target = next_instr + INLINE_CACHE_ENTRIES_FOR_ITER + oparg + 1;
             }
             INSTRUMENTED_JUMP(here, target, PY_MONITORING_EVENT_BRANCH);
-            #line 3336 "Python/generated_cases.c.h"
+            #line 3331 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(FOR_ITER_LIST) {
             PyObject *iter = stack_pointer[-1];
             PyObject *next;
-            #line 2370 "Python/bytecodes.c"
+            #line 2365 "Python/bytecodes.c"
             DEOPT_IF(Py_TYPE(iter) != &PyListIter_Type, FOR_ITER);
             _PyListIterObject *it = (_PyListIterObject *)iter;
             STAT_INC(FOR_ITER, hit);
@@ -3359,7 +3354,7 @@
             DISPATCH();
         end_for_iter_list:
             // Common case: no jump, leave it to the code generator
-            #line 3363 "Python/generated_cases.c.h"
+            #line 3358 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = next;
             next_instr += 1;
@@ -3369,7 +3364,7 @@
         TARGET(FOR_ITER_TUPLE) {
             PyObject *iter = stack_pointer[-1];
             PyObject *next;
-            #line 2392 "Python/bytecodes.c"
+            #line 2387 "Python/bytecodes.c"
             _PyTupleIterObject *it = (_PyTupleIterObject *)iter;
             DEOPT_IF(Py_TYPE(it) != &PyTupleIter_Type, FOR_ITER);
             STAT_INC(FOR_ITER, hit);
@@ -3389,7 +3384,7 @@
             DISPATCH();
         end_for_iter_tuple:
             // Common case: no jump, leave it to the code generator
-            #line 3393 "Python/generated_cases.c.h"
+            #line 3388 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = next;
             next_instr += 1;
@@ -3399,7 +3394,7 @@
         TARGET(FOR_ITER_RANGE) {
             PyObject *iter = stack_pointer[-1];
             PyObject *next;
-            #line 2414 "Python/bytecodes.c"
+            #line 2409 "Python/bytecodes.c"
             _PyRangeIterObject *r = (_PyRangeIterObject *)iter;
             DEOPT_IF(Py_TYPE(r) != &PyRangeIter_Type, FOR_ITER);
             STAT_INC(FOR_ITER, hit);
@@ -3417,7 +3412,7 @@
             if (next == NULL) {
                 goto error;
             }
-            #line 3421 "Python/generated_cases.c.h"
+            #line 3416 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = next;
             next_instr += 1;
@@ -3426,7 +3421,7 @@
 
         TARGET(FOR_ITER_GEN) {
             PyObject *iter = stack_pointer[-1];
-            #line 2434 "Python/bytecodes.c"
+            #line 2429 "Python/bytecodes.c"
             DEOPT_IF(tstate->interp->eval_frame, FOR_ITER);
             PyGenObject *gen = (PyGenObject *)iter;
             DEOPT_IF(Py_TYPE(gen) != &PyGen_Type, FOR_ITER);
@@ -3442,14 +3437,14 @@
             assert(next_instr[oparg].op.code == END_FOR ||
                    next_instr[oparg].op.code == INSTRUMENTED_END_FOR);
             DISPATCH_INLINED(gen_frame);
-            #line 3446 "Python/generated_cases.c.h"
+            #line 3441 "Python/generated_cases.c.h"
         }
 
         TARGET(BEFORE_ASYNC_WITH) {
             PyObject *mgr = stack_pointer[-1];
             PyObject *exit;
             PyObject *res;
-            #line 2452 "Python/bytecodes.c"
+            #line 2447 "Python/bytecodes.c"
             PyObject *enter = _PyObject_LookupSpecial(mgr, &_Py_ID(__aenter__));
             if (enter == NULL) {
                 if (!_PyErr_Occurred(tstate)) {
@@ -3472,16 +3467,16 @@
                 Py_DECREF(enter);
                 goto error;
             }
-            #line 3476 "Python/generated_cases.c.h"
+            #line 3471 "Python/generated_cases.c.h"
             Py_DECREF(mgr);
-            #line 2475 "Python/bytecodes.c"
+            #line 2470 "Python/bytecodes.c"
             res = _PyObject_CallNoArgs(enter);
             Py_DECREF(enter);
             if (res == NULL) {
                 Py_DECREF(exit);
                 if (true) goto pop_1_error;
             }
-            #line 3485 "Python/generated_cases.c.h"
+            #line 3480 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = res;
             stack_pointer[-2] = exit;
@@ -3493,7 +3488,7 @@
             PyObject *mgr = stack_pointer[-1];
             PyObject *exit;
             PyObject *res;
-            #line 2485 "Python/bytecodes.c"
+            #line 2480 "Python/bytecodes.c"
             /* pop the context manager, push its __exit__ and the
              * value returned from calling its __enter__
              */
@@ -3519,16 +3514,16 @@
                 Py_DECREF(enter);
                 goto error;
             }
-            #line 3523 "Python/generated_cases.c.h"
+            #line 3518 "Python/generated_cases.c.h"
             Py_DECREF(mgr);
-            #line 2511 "Python/bytecodes.c"
+            #line 2506 "Python/bytecodes.c"
             res = _PyObject_CallNoArgs(enter);
             Py_DECREF(enter);
             if (res == NULL) {
                 Py_DECREF(exit);
                 if (true) goto pop_1_error;
             }
-            #line 3532 "Python/generated_cases.c.h"
+            #line 3527 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = res;
             stack_pointer[-2] = exit;
@@ -3540,7 +3535,7 @@
             PyObject *lasti = stack_pointer[-3];
             PyObject *exit_func = stack_pointer[-4];
             PyObject *res;
-            #line 2520 "Python/bytecodes.c"
+            #line 2515 "Python/bytecodes.c"
             /* At the top of the stack are 4 values:
                - val: TOP = exc_info()
                - unused: SECOND = previous exception
@@ -3566,7 +3561,7 @@
             res = PyObject_Vectorcall(exit_func, stack + 1,
                     3 | PY_VECTORCALL_ARGUMENTS_OFFSET, NULL);
             if (res == NULL) goto error;
-            #line 3570 "Python/generated_cases.c.h"
+            #line 3565 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = res;
             DISPATCH();
@@ -3575,7 +3570,7 @@
         TARGET(PUSH_EXC_INFO) {
             PyObject *new_exc = stack_pointer[-1];
             PyObject *prev_exc;
-            #line 2548 "Python/bytecodes.c"
+            #line 2543 "Python/bytecodes.c"
             _PyErr_StackItem *exc_info = tstate->exc_info;
             if (exc_info->exc_value != NULL) {
                 prev_exc = exc_info->exc_value;
@@ -3585,7 +3580,7 @@
             }
             assert(PyExceptionInstance_Check(new_exc));
             exc_info->exc_value = Py_NewRef(new_exc);
-            #line 3589 "Python/generated_cases.c.h"
+            #line 3584 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = new_exc;
             stack_pointer[-2] = prev_exc;
@@ -3599,7 +3594,7 @@
             uint32_t type_version = read_u32(&next_instr[1].cache);
             uint32_t keys_version = read_u32(&next_instr[3].cache);
             PyObject *descr = read_obj(&next_instr[5].cache);
-            #line 2560 "Python/bytecodes.c"
+            #line 2555 "Python/bytecodes.c"
             /* Cached method object */
             PyTypeObject *self_cls = Py_TYPE(self);
             assert(type_version != 0);
@@ -3616,7 +3611,7 @@
             assert(_PyType_HasFeature(Py_TYPE(res2), Py_TPFLAGS_METHOD_DESCRIPTOR));
             res = self;
             assert(oparg & 1);
-            #line 3620 "Python/generated_cases.c.h"
+            #line 3615 "Python/generated_cases.c.h"
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
             if (oparg & 1) { stack_pointer[-(1 + ((oparg & 1) ? 1 : 0))] = res2; }
@@ -3630,7 +3625,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             PyObject *descr = read_obj(&next_instr[5].cache);
-            #line 2579 "Python/bytecodes.c"
+            #line 2574 "Python/bytecodes.c"
             PyTypeObject *self_cls = Py_TYPE(self);
             DEOPT_IF(self_cls->tp_version_tag != type_version, LOAD_ATTR);
             assert(self_cls->tp_dictoffset == 0);
@@ -3640,7 +3635,7 @@
             res2 = Py_NewRef(descr);
             res = self;
             assert(oparg & 1);
-            #line 3644 "Python/generated_cases.c.h"
+            #line 3639 "Python/generated_cases.c.h"
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
             if (oparg & 1) { stack_pointer[-(1 + ((oparg & 1) ? 1 : 0))] = res2; }
@@ -3654,7 +3649,7 @@
             PyObject *res;
             uint32_t type_version = read_u32(&next_instr[1].cache);
             PyObject *descr = read_obj(&next_instr[5].cache);
-            #line 2591 "Python/bytecodes.c"
+            #line 2586 "Python/bytecodes.c"
             PyTypeObject *self_cls = Py_TYPE(self);
             DEOPT_IF(self_cls->tp_version_tag != type_version, LOAD_ATTR);
             Py_ssize_t dictoffset = self_cls->tp_dictoffset;
@@ -3668,7 +3663,7 @@
             res2 = Py_NewRef(descr);
             res = self;
             assert(oparg & 1);
-            #line 3672 "Python/generated_cases.c.h"
+            #line 3667 "Python/generated_cases.c.h"
             STACK_GROW(((oparg & 1) ? 1 : 0));
             stack_pointer[-1] = res;
             if (oparg & 1) { stack_pointer[-(1 + ((oparg & 1) ? 1 : 0))] = res2; }
@@ -3677,16 +3672,16 @@
         }
 
         TARGET(KW_NAMES) {
-            #line 2607 "Python/bytecodes.c"
+            #line 2602 "Python/bytecodes.c"
             assert(kwnames == NULL);
             assert(oparg < PyTuple_GET_SIZE(frame->f_code->co_consts));
             kwnames = GETITEM(frame->f_code->co_consts, oparg);
-            #line 3685 "Python/generated_cases.c.h"
+            #line 3680 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_CALL) {
-            #line 2613 "Python/bytecodes.c"
+            #line 2608 "Python/bytecodes.c"
             int is_meth = PEEK(oparg+2) != NULL;
             int total_args = oparg + is_meth;
             PyObject *function = PEEK(total_args + 1);
@@ -3699,7 +3694,7 @@
             _PyCallCache *cache = (_PyCallCache *)next_instr;
             INCREMENT_ADAPTIVE_COUNTER(cache->counter);
             GO_TO_INSTRUCTION(CALL);
-            #line 3703 "Python/generated_cases.c.h"
+            #line 3698 "Python/generated_cases.c.h"
         }
 
         TARGET(CALL) {
@@ -3709,7 +3704,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2658 "Python/bytecodes.c"
+            #line 2653 "Python/bytecodes.c"
             int is_meth = method != NULL;
             int total_args = oparg;
             if (is_meth) {
@@ -3791,7 +3786,7 @@
                 Py_DECREF(args[i]);
             }
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 3795 "Python/generated_cases.c.h"
+            #line 3790 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -3803,7 +3798,7 @@
         TARGET(CALL_BOUND_METHOD_EXACT_ARGS) {
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
-            #line 2746 "Python/bytecodes.c"
+            #line 2741 "Python/bytecodes.c"
             DEOPT_IF(method != NULL, CALL);
             DEOPT_IF(Py_TYPE(callable) != &PyMethod_Type, CALL);
             STAT_INC(CALL, hit);
@@ -3813,7 +3808,7 @@
             PEEK(oparg + 2) = Py_NewRef(meth);  // method
             Py_DECREF(callable);
             GO_TO_INSTRUCTION(CALL_PY_EXACT_ARGS);
-            #line 3817 "Python/generated_cases.c.h"
+            #line 3812 "Python/generated_cases.c.h"
         }
 
         TARGET(CALL_PY_EXACT_ARGS) {
@@ -3822,7 +3817,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             uint32_t func_version = read_u32(&next_instr[1].cache);
-            #line 2758 "Python/bytecodes.c"
+            #line 2753 "Python/bytecodes.c"
             assert(kwnames == NULL);
             DEOPT_IF(tstate->interp->eval_frame, CALL);
             int is_meth = method != NULL;
@@ -3848,7 +3843,7 @@
             JUMPBY(INLINE_CACHE_ENTRIES_CALL);
             frame->return_offset = 0;
             DISPATCH_INLINED(new_frame);
-            #line 3852 "Python/generated_cases.c.h"
+            #line 3847 "Python/generated_cases.c.h"
         }
 
         TARGET(CALL_PY_WITH_DEFAULTS) {
@@ -3856,7 +3851,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             uint32_t func_version = read_u32(&next_instr[1].cache);
-            #line 2786 "Python/bytecodes.c"
+            #line 2781 "Python/bytecodes.c"
             assert(kwnames == NULL);
             DEOPT_IF(tstate->interp->eval_frame, CALL);
             int is_meth = method != NULL;
@@ -3892,7 +3887,7 @@
             JUMPBY(INLINE_CACHE_ENTRIES_CALL);
             frame->return_offset = 0;
             DISPATCH_INLINED(new_frame);
-            #line 3896 "Python/generated_cases.c.h"
+            #line 3891 "Python/generated_cases.c.h"
         }
 
         TARGET(CALL_NO_KW_TYPE_1) {
@@ -3900,7 +3895,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *null = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2824 "Python/bytecodes.c"
+            #line 2819 "Python/bytecodes.c"
             assert(kwnames == NULL);
             assert(oparg == 1);
             DEOPT_IF(null != NULL, CALL);
@@ -3910,7 +3905,7 @@
             res = Py_NewRef(Py_TYPE(obj));
             Py_DECREF(obj);
             Py_DECREF(&PyType_Type);  // I.e., callable
-            #line 3914 "Python/generated_cases.c.h"
+            #line 3909 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -3923,7 +3918,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *null = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2836 "Python/bytecodes.c"
+            #line 2831 "Python/bytecodes.c"
             assert(kwnames == NULL);
             assert(oparg == 1);
             DEOPT_IF(null != NULL, CALL);
@@ -3934,7 +3929,7 @@
             Py_DECREF(arg);
             Py_DECREF(&PyUnicode_Type);  // I.e., callable
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 3938 "Python/generated_cases.c.h"
+            #line 3933 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -3948,7 +3943,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *null = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2850 "Python/bytecodes.c"
+            #line 2845 "Python/bytecodes.c"
             assert(kwnames == NULL);
             assert(oparg == 1);
             DEOPT_IF(null != NULL, CALL);
@@ -3959,7 +3954,7 @@
             Py_DECREF(arg);
             Py_DECREF(&PyTuple_Type);  // I.e., tuple
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 3963 "Python/generated_cases.c.h"
+            #line 3958 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -3973,7 +3968,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2864 "Python/bytecodes.c"
+            #line 2859 "Python/bytecodes.c"
             int is_meth = method != NULL;
             int total_args = oparg;
             if (is_meth) {
@@ -3995,7 +3990,7 @@
             }
             Py_DECREF(tp);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 3999 "Python/generated_cases.c.h"
+            #line 3994 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4009,7 +4004,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2889 "Python/bytecodes.c"
+            #line 2884 "Python/bytecodes.c"
             /* Builtin METH_O functions */
             assert(kwnames == NULL);
             int is_meth = method != NULL;
@@ -4037,7 +4032,7 @@
             Py_DECREF(arg);
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4041 "Python/generated_cases.c.h"
+            #line 4036 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4051,7 +4046,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2920 "Python/bytecodes.c"
+            #line 2915 "Python/bytecodes.c"
             /* Builtin METH_FASTCALL functions, without keywords */
             assert(kwnames == NULL);
             int is_meth = method != NULL;
@@ -4083,7 +4078,7 @@
                    'invalid'). In those cases an exception is set, so we must
                    handle it.
                 */
-            #line 4087 "Python/generated_cases.c.h"
+            #line 4082 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4097,7 +4092,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2955 "Python/bytecodes.c"
+            #line 2950 "Python/bytecodes.c"
             /* Builtin METH_FASTCALL | METH_KEYWORDS functions */
             int is_meth = method != NULL;
             int total_args = oparg;
@@ -4129,7 +4124,7 @@
             }
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4133 "Python/generated_cases.c.h"
+            #line 4128 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4143,7 +4138,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 2990 "Python/bytecodes.c"
+            #line 2985 "Python/bytecodes.c"
             assert(kwnames == NULL);
             /* len(o) */
             int is_meth = method != NULL;
@@ -4168,7 +4163,7 @@
             Py_DECREF(callable);
             Py_DECREF(arg);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4172 "Python/generated_cases.c.h"
+            #line 4167 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4181,7 +4176,7 @@
             PyObject *callable = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 3017 "Python/bytecodes.c"
+            #line 3012 "Python/bytecodes.c"
             assert(kwnames == NULL);
             /* isinstance(o, o2) */
             int is_meth = method != NULL;
@@ -4208,7 +4203,7 @@
             Py_DECREF(cls);
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4212 "Python/generated_cases.c.h"
+            #line 4207 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4220,7 +4215,7 @@
             PyObject **args = (stack_pointer - oparg);
             PyObject *self = stack_pointer[-(1 + oparg)];
             PyObject *method = stack_pointer[-(2 + oparg)];
-            #line 3047 "Python/bytecodes.c"
+            #line 3042 "Python/bytecodes.c"
             assert(kwnames == NULL);
             assert(oparg == 1);
             PyInterpreterState *interp = _PyInterpreterState_GET();
@@ -4238,14 +4233,14 @@
             JUMPBY(INLINE_CACHE_ENTRIES_CALL + 1);
             assert(next_instr[-1].op.code == POP_TOP);
             DISPATCH();
-            #line 4242 "Python/generated_cases.c.h"
+            #line 4237 "Python/generated_cases.c.h"
         }
 
         TARGET(CALL_NO_KW_METHOD_DESCRIPTOR_O) {
             PyObject **args = (stack_pointer - oparg);
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 3067 "Python/bytecodes.c"
+            #line 3062 "Python/bytecodes.c"
             assert(kwnames == NULL);
             int is_meth = method != NULL;
             int total_args = oparg;
@@ -4276,7 +4271,7 @@
             Py_DECREF(arg);
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4280 "Python/generated_cases.c.h"
+            #line 4275 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4289,7 +4284,7 @@
             PyObject **args = (stack_pointer - oparg);
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 3101 "Python/bytecodes.c"
+            #line 3096 "Python/bytecodes.c"
             int is_meth = method != NULL;
             int total_args = oparg;
             if (is_meth) {
@@ -4318,7 +4313,7 @@
             }
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4322 "Python/generated_cases.c.h"
+            #line 4317 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4331,7 +4326,7 @@
             PyObject **args = (stack_pointer - oparg);
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 3133 "Python/bytecodes.c"
+            #line 3128 "Python/bytecodes.c"
             assert(kwnames == NULL);
             assert(oparg == 0 || oparg == 1);
             int is_meth = method != NULL;
@@ -4360,7 +4355,7 @@
             Py_DECREF(self);
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4364 "Python/generated_cases.c.h"
+            #line 4359 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4373,7 +4368,7 @@
             PyObject **args = (stack_pointer - oparg);
             PyObject *method = stack_pointer[-(2 + oparg)];
             PyObject *res;
-            #line 3165 "Python/bytecodes.c"
+            #line 3160 "Python/bytecodes.c"
             assert(kwnames == NULL);
             int is_meth = method != NULL;
             int total_args = oparg;
@@ -4401,7 +4396,7 @@
             }
             Py_DECREF(callable);
             if (res == NULL) { STACK_SHRINK(oparg); goto pop_2_error; }
-            #line 4405 "Python/generated_cases.c.h"
+            #line 4400 "Python/generated_cases.c.h"
             STACK_SHRINK(oparg);
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
@@ -4411,9 +4406,9 @@
         }
 
         TARGET(INSTRUMENTED_CALL_FUNCTION_EX) {
-            #line 3196 "Python/bytecodes.c"
+            #line 3191 "Python/bytecodes.c"
             GO_TO_INSTRUCTION(CALL_FUNCTION_EX);
-            #line 4417 "Python/generated_cases.c.h"
+            #line 4412 "Python/generated_cases.c.h"
         }
 
         TARGET(CALL_FUNCTION_EX) {
@@ -4422,7 +4417,7 @@
             PyObject *callargs = stack_pointer[-(1 + ((oparg & 1) ? 1 : 0))];
             PyObject *func = stack_pointer[-(2 + ((oparg & 1) ? 1 : 0))];
             PyObject *result;
-            #line 3200 "Python/bytecodes.c"
+            #line 3195 "Python/bytecodes.c"
             // DICT_MERGE is called before this opcode if there are kwargs.
             // It converts all dict subtypes in kwargs into regular dicts.
             assert(kwargs == NULL || PyDict_CheckExact(kwargs));
@@ -4484,14 +4479,14 @@
                 }
                 result = PyObject_Call(func, callargs, kwargs);
             }
-            #line 4488 "Python/generated_cases.c.h"
+            #line 4483 "Python/generated_cases.c.h"
             Py_DECREF(func);
             Py_DECREF(callargs);
             Py_XDECREF(kwargs);
-            #line 3262 "Python/bytecodes.c"
+            #line 3257 "Python/bytecodes.c"
             assert(PEEK(3 + (oparg & 1)) == NULL);
             if (result == NULL) { STACK_SHRINK(((oparg & 1) ? 1 : 0)); goto pop_3_error; }
-            #line 4495 "Python/generated_cases.c.h"
+            #line 4490 "Python/generated_cases.c.h"
             STACK_SHRINK(((oparg & 1) ? 1 : 0));
             STACK_SHRINK(2);
             stack_pointer[-1] = result;
@@ -4506,7 +4501,7 @@
             PyObject *kwdefaults = (oparg & 0x02) ? stack_pointer[-(1 + ((oparg & 0x08) ? 1 : 0) + ((oparg & 0x04) ? 1 : 0) + ((oparg & 0x02) ? 1 : 0))] : NULL;
             PyObject *defaults = (oparg & 0x01) ? stack_pointer[-(1 + ((oparg & 0x08) ? 1 : 0) + ((oparg & 0x04) ? 1 : 0) + ((oparg & 0x02) ? 1 : 0) + ((oparg & 0x01) ? 1 : 0))] : NULL;
             PyObject *func;
-            #line 3272 "Python/bytecodes.c"
+            #line 3267 "Python/bytecodes.c"
 
             PyFunctionObject *func_obj = (PyFunctionObject *)
                 PyFunction_New(codeobj, GLOBALS());
@@ -4535,14 +4530,14 @@
 
             func_obj->func_version = ((PyCodeObject *)codeobj)->co_version;
             func = (PyObject *)func_obj;
-            #line 4539 "Python/generated_cases.c.h"
+            #line 4534 "Python/generated_cases.c.h"
             STACK_SHRINK(((oparg & 0x01) ? 1 : 0) + ((oparg & 0x02) ? 1 : 0) + ((oparg & 0x04) ? 1 : 0) + ((oparg & 0x08) ? 1 : 0));
             stack_pointer[-1] = func;
             DISPATCH();
         }
 
         TARGET(RETURN_GENERATOR) {
-            #line 3303 "Python/bytecodes.c"
+            #line 3298 "Python/bytecodes.c"
             assert(PyFunction_Check(frame->f_funcobj));
             PyFunctionObject *func = (PyFunctionObject *)frame->f_funcobj;
             PyGenObject *gen = (PyGenObject *)_Py_MakeCoro(func);
@@ -4563,7 +4558,7 @@
             frame = cframe.current_frame = prev;
             _PyFrame_StackPush(frame, (PyObject *)gen);
             goto resume_frame;
-            #line 4567 "Python/generated_cases.c.h"
+            #line 4562 "Python/generated_cases.c.h"
         }
 
         TARGET(BUILD_SLICE) {
@@ -4571,15 +4566,15 @@
             PyObject *stop = stack_pointer[-(1 + ((oparg == 3) ? 1 : 0))];
             PyObject *start = stack_pointer[-(2 + ((oparg == 3) ? 1 : 0))];
             PyObject *slice;
-            #line 3326 "Python/bytecodes.c"
+            #line 3321 "Python/bytecodes.c"
             slice = PySlice_New(start, stop, step);
-            #line 4577 "Python/generated_cases.c.h"
+            #line 4572 "Python/generated_cases.c.h"
             Py_DECREF(start);
             Py_DECREF(stop);
             Py_XDECREF(step);
-            #line 3328 "Python/bytecodes.c"
+            #line 3323 "Python/bytecodes.c"
             if (slice == NULL) { STACK_SHRINK(((oparg == 3) ? 1 : 0)); goto pop_2_error; }
-            #line 4583 "Python/generated_cases.c.h"
+            #line 4578 "Python/generated_cases.c.h"
             STACK_SHRINK(((oparg == 3) ? 1 : 0));
             STACK_SHRINK(1);
             stack_pointer[-1] = slice;
@@ -4590,7 +4585,7 @@
             PyObject *fmt_spec = ((oparg & FVS_MASK) == FVS_HAVE_SPEC) ? stack_pointer[-((((oparg & FVS_MASK) == FVS_HAVE_SPEC) ? 1 : 0))] : NULL;
             PyObject *value = stack_pointer[-(1 + (((oparg & FVS_MASK) == FVS_HAVE_SPEC) ? 1 : 0))];
             PyObject *result;
-            #line 3332 "Python/bytecodes.c"
+            #line 3327 "Python/bytecodes.c"
             /* Handles f-string value formatting. */
             PyObject *(*conv_fn)(PyObject *);
             int which_conversion = oparg & FVC_MASK;
@@ -4625,7 +4620,7 @@
             Py_DECREF(value);
             Py_XDECREF(fmt_spec);
             if (result == NULL) { STACK_SHRINK((((oparg & FVS_MASK) == FVS_HAVE_SPEC) ? 1 : 0)); goto pop_1_error; }
-            #line 4629 "Python/generated_cases.c.h"
+            #line 4624 "Python/generated_cases.c.h"
             STACK_SHRINK((((oparg & FVS_MASK) == FVS_HAVE_SPEC) ? 1 : 0));
             stack_pointer[-1] = result;
             DISPATCH();
@@ -4634,10 +4629,10 @@
         TARGET(COPY) {
             PyObject *bottom = stack_pointer[-(1 + (oparg-1))];
             PyObject *top;
-            #line 3369 "Python/bytecodes.c"
+            #line 3364 "Python/bytecodes.c"
             assert(oparg > 0);
             top = Py_NewRef(bottom);
-            #line 4641 "Python/generated_cases.c.h"
+            #line 4636 "Python/generated_cases.c.h"
             STACK_GROW(1);
             stack_pointer[-1] = top;
             DISPATCH();
@@ -4649,7 +4644,7 @@
             PyObject *rhs = stack_pointer[-1];
             PyObject *lhs = stack_pointer[-2];
             PyObject *res;
-            #line 3374 "Python/bytecodes.c"
+            #line 3369 "Python/bytecodes.c"
             #if ENABLE_SPECIALIZATION
             _PyBinaryOpCache *cache = (_PyBinaryOpCache *)next_instr;
             if (ADAPTIVE_COUNTER_IS_ZERO(cache->counter)) {
@@ -4664,12 +4659,12 @@
             assert((unsigned)oparg < Py_ARRAY_LENGTH(binary_ops));
             assert(binary_ops[oparg]);
             res = binary_ops[oparg](lhs, rhs);
-            #line 4668 "Python/generated_cases.c.h"
+            #line 4663 "Python/generated_cases.c.h"
             Py_DECREF(lhs);
             Py_DECREF(rhs);
-            #line 3389 "Python/bytecodes.c"
+            #line 3384 "Python/bytecodes.c"
             if (res == NULL) goto pop_2_error;
-            #line 4673 "Python/generated_cases.c.h"
+            #line 4668 "Python/generated_cases.c.h"
             STACK_SHRINK(1);
             stack_pointer[-1] = res;
             next_instr += 1;
@@ -4679,16 +4674,16 @@
         TARGET(SWAP) {
             PyObject *top = stack_pointer[-1];
             PyObject *bottom = stack_pointer[-(2 + (oparg-2))];
-            #line 3394 "Python/bytecodes.c"
+            #line 3389 "Python/bytecodes.c"
             assert(oparg >= 2);
-            #line 4685 "Python/generated_cases.c.h"
+            #line 4680 "Python/generated_cases.c.h"
             stack_pointer[-1] = bottom;
             stack_pointer[-(2 + (oparg-2))] = top;
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_INSTRUCTION) {
-            #line 3398 "Python/bytecodes.c"
+            #line 3393 "Python/bytecodes.c"
             int next_opcode = _Py_call_instrumentation_instruction(
                 tstate, frame, next_instr-1);
             if (next_opcode < 0) goto error;
@@ -4700,26 +4695,26 @@
             assert(next_opcode > 0 && next_opcode < 256);
             opcode = next_opcode;
             DISPATCH_GOTO();
-            #line 4704 "Python/generated_cases.c.h"
+            #line 4699 "Python/generated_cases.c.h"
         }
 
         TARGET(INSTRUMENTED_JUMP_FORWARD) {
-            #line 3412 "Python/bytecodes.c"
+            #line 3407 "Python/bytecodes.c"
             INSTRUMENTED_JUMP(next_instr-1, next_instr+oparg, PY_MONITORING_EVENT_JUMP);
-            #line 4710 "Python/generated_cases.c.h"
+            #line 4705 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_JUMP_BACKWARD) {
-            #line 3416 "Python/bytecodes.c"
+            #line 3411 "Python/bytecodes.c"
             INSTRUMENTED_JUMP(next_instr-1, next_instr-oparg, PY_MONITORING_EVENT_JUMP);
-            #line 4717 "Python/generated_cases.c.h"
+            #line 4712 "Python/generated_cases.c.h"
             CHECK_EVAL_BREAKER();
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_POP_JUMP_IF_TRUE) {
-            #line 3421 "Python/bytecodes.c"
+            #line 3416 "Python/bytecodes.c"
             PyObject *cond = POP();
             int err = PyObject_IsTrue(cond);
             Py_DECREF(cond);
@@ -4728,12 +4723,12 @@
             assert(err == 0 || err == 1);
             int offset = err*oparg;
             INSTRUMENTED_JUMP(here, next_instr + offset, PY_MONITORING_EVENT_BRANCH);
-            #line 4732 "Python/generated_cases.c.h"
+            #line 4727 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_POP_JUMP_IF_FALSE) {
-            #line 3432 "Python/bytecodes.c"
+            #line 3427 "Python/bytecodes.c"
             PyObject *cond = POP();
             int err = PyObject_IsTrue(cond);
             Py_DECREF(cond);
@@ -4742,12 +4737,12 @@
             assert(err == 0 || err == 1);
             int offset = (1-err)*oparg;
             INSTRUMENTED_JUMP(here, next_instr + offset, PY_MONITORING_EVENT_BRANCH);
-            #line 4746 "Python/generated_cases.c.h"
+            #line 4741 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_POP_JUMP_IF_NONE) {
-            #line 3443 "Python/bytecodes.c"
+            #line 3438 "Python/bytecodes.c"
             PyObject *value = POP();
             _Py_CODEUNIT *here = next_instr-1;
             int offset;
@@ -4759,12 +4754,12 @@
                 offset = 0;
             }
             INSTRUMENTED_JUMP(here, next_instr + offset, PY_MONITORING_EVENT_BRANCH);
-            #line 4763 "Python/generated_cases.c.h"
+            #line 4758 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(INSTRUMENTED_POP_JUMP_IF_NOT_NONE) {
-            #line 3457 "Python/bytecodes.c"
+            #line 3452 "Python/bytecodes.c"
             PyObject *value = POP();
             _Py_CODEUNIT *here = next_instr-1;
             int offset;
@@ -4776,30 +4771,30 @@
                  offset = oparg;
             }
             INSTRUMENTED_JUMP(here, next_instr + offset, PY_MONITORING_EVENT_BRANCH);
-            #line 4780 "Python/generated_cases.c.h"
+            #line 4775 "Python/generated_cases.c.h"
             DISPATCH();
         }
 
         TARGET(EXTENDED_ARG) {
-            #line 3471 "Python/bytecodes.c"
+            #line 3466 "Python/bytecodes.c"
             assert(oparg);
             opcode = next_instr->op.code;
             oparg = oparg << 8 | next_instr->op.arg;
             PRE_DISPATCH_GOTO();
             DISPATCH_GOTO();
-            #line 4791 "Python/generated_cases.c.h"
+            #line 4786 "Python/generated_cases.c.h"
         }
 
         TARGET(CACHE) {
-            #line 3479 "Python/bytecodes.c"
+            #line 3474 "Python/bytecodes.c"
             assert(0 && "Executing a cache.");
             Py_UNREACHABLE();
-            #line 4798 "Python/generated_cases.c.h"
+            #line 4793 "Python/generated_cases.c.h"
         }
 
         TARGET(RESERVED) {
-            #line 3484 "Python/bytecodes.c"
+            #line 3479 "Python/bytecodes.c"
             assert(0 && "Executing RESERVED instruction.");
             Py_UNREACHABLE();
-            #line 4805 "Python/generated_cases.c.h"
+            #line 4800 "Python/generated_cases.c.h"
         }
diff --git a/Python/import.c b/Python/import.c
index 3f3f2a2b68..54232a1300 100644
--- a/Python/import.c
+++ b/Python/import.c
@@ -2380,9 +2380,14 @@ get_path_importer(PyThreadState *tstate, PyObject *path_importer_cache,
     PyObject *importer;
     Py_ssize_t j, nhooks;
 
-    /* These conditions are the caller's responsibility: */
-    assert(PyList_Check(path_hooks));
-    assert(PyDict_Check(path_importer_cache));
+    if (!PyList_Check(path_hooks)) {
+        PyErr_SetString(PyExc_RuntimeError, "sys.path_hooks is not a list");
+        return NULL;
+    }
+    if (!PyDict_Check(path_importer_cache)) {
+        PyErr_SetString(PyExc_RuntimeError, "sys.path_importer_cache is not a dict");
+        return NULL;
+    }
 
     nhooks = PyList_Size(path_hooks);
     if (nhooks < 0)
@@ -2425,11 +2430,22 @@ PyImport_GetImporter(PyObject *path)
 {
     PyThreadState *tstate = _PyThreadState_GET();
     PyObject *path_importer_cache = PySys_GetObject("path_importer_cache");
+    if (path_importer_cache == NULL) {
+        PyErr_SetString(PyExc_RuntimeError, "lost sys.path_importer_cache");
+        return NULL;
+    }
+    Py_INCREF(path_importer_cache);
     PyObject *path_hooks = PySys_GetObject("path_hooks");
-    if (path_importer_cache == NULL || path_hooks == NULL) {
+    if (path_hooks == NULL) {
+        PyErr_SetString(PyExc_RuntimeError, "lost sys.path_hooks");
+        Py_DECREF(path_importer_cache);
         return NULL;
     }
-    return get_path_importer(tstate, path_importer_cache, path_hooks, path);
+    Py_INCREF(path_hooks);
+    PyObject *importer = get_path_importer(tstate, path_importer_cache, path_hooks, path);
+    Py_DECREF(path_hooks);
+    Py_DECREF(path_importer_cache);
+    return importer;
 }
 
 
diff --git a/Python/legacy_tracing.c b/Python/legacy_tracing.c
index b0136d2ebc..43fa5910ef 100644
--- a/Python/legacy_tracing.c
+++ b/Python/legacy_tracing.c
@@ -377,6 +377,11 @@ _PyEval_SetProfile(PyThreadState *tstate, Py_tracefunc func, PyObject *arg)
                         PY_MONITORING_EVENT_PY_START, PY_MONITORING_EVENT_PY_RESUME)) {
             return -1;
         }
+        if (set_callbacks(PY_MONITORING_SYS_PROFILE_ID,
+            (vectorcallfunc)sys_profile_func3, PyTrace_CALL,
+                        PY_MONITORING_EVENT_PY_THROW, -1)) {
+            return -1;
+        }
         if (set_callbacks(PY_MONITORING_SYS_PROFILE_ID,
             (vectorcallfunc)sys_profile_func3, PyTrace_RETURN,
                         PY_MONITORING_EVENT_PY_RETURN, PY_MONITORING_EVENT_PY_YIELD)) {
@@ -417,7 +422,8 @@ _PyEval_SetProfile(PyThreadState *tstate, Py_tracefunc func, PyObject *arg)
         events =
             (1 << PY_MONITORING_EVENT_PY_START) | (1 << PY_MONITORING_EVENT_PY_RESUME) |
             (1 << PY_MONITORING_EVENT_PY_RETURN) | (1 << PY_MONITORING_EVENT_PY_YIELD) |
-            (1 << PY_MONITORING_EVENT_CALL) | (1 << PY_MONITORING_EVENT_PY_UNWIND);
+            (1 << PY_MONITORING_EVENT_CALL) | (1 << PY_MONITORING_EVENT_PY_UNWIND) |
+            (1 << PY_MONITORING_EVENT_PY_THROW);
     }
     return _PyMonitoring_SetEvents(PY_MONITORING_SYS_PROFILE_ID, events);
 }
diff --git a/Python/pystate.c b/Python/pystate.c
index 2ee16e3de2..6f60c3dccc 100644
--- a/Python/pystate.c
+++ b/Python/pystate.c
@@ -264,10 +264,10 @@ static void
 unbind_tstate(PyThreadState *tstate)
 {
     assert(tstate != NULL);
-    // XXX assert(tstate_is_alive(tstate));
     assert(tstate_is_bound(tstate));
-    // XXX assert(!tstate->_status.active);
+#ifndef HAVE_PTHREAD_STUBS
     assert(tstate->thread_id > 0);
+#endif
 #ifdef PY_HAVE_THREAD_NATIVE_ID
     assert(tstate->native_thread_id > 0);
 #endif
@@ -1867,6 +1867,10 @@ PyThreadState_Swap(PyThreadState *newts)
 void
 _PyThreadState_Bind(PyThreadState *tstate)
 {
+    // gh-104690: If Python is being finalized and PyInterpreterState_Delete()
+    // was called, tstate becomes a dangling pointer.
+    assert(_PyThreadState_CheckConsistency(tstate));
+
     bind_tstate(tstate);
     // This makes sure there's a gilstate tstate bound
     // as soon as possible.
@@ -2848,6 +2852,49 @@ _PyThreadState_PopFrame(PyThreadState *tstate, _PyInterpreterFrame * frame)
 }
 
 
+#ifndef NDEBUG
+// Check that a Python thread state valid. In practice, this function is used
+// on a Python debug build to check if 'tstate' is a dangling pointer, if the
+// PyThreadState memory has been freed.
+//
+// Usage:
+//
+//     assert(_PyThreadState_CheckConsistency(tstate));
+int
+_PyThreadState_CheckConsistency(PyThreadState *tstate)
+{
+    assert(!_PyMem_IsPtrFreed(tstate));
+    assert(!_PyMem_IsPtrFreed(tstate->interp));
+    return 1;
+}
+#endif
+
+
+// Check if a Python thread must exit immediately, rather than taking the GIL
+// if Py_Finalize() has been called.
+//
+// When this function is called by a daemon thread after Py_Finalize() has been
+// called, the GIL does no longer exist.
+//
+// tstate can be a dangling pointer (point to freed memory): only tstate value
+// is used, the pointer is not deferenced.
+//
+// tstate must be non-NULL.
+int
+_PyThreadState_MustExit(PyThreadState *tstate)
+{
+    /* bpo-39877: Access _PyRuntime directly rather than using
+       tstate->interp->runtime to support calls from Python daemon threads.
+       After Py_Finalize() has been called, tstate can be a dangling pointer:
+       point to PyThreadState freed memory. */
+    PyThreadState *finalizing = _PyRuntimeState_GetFinalizing(&_PyRuntime);
+    if (finalizing == NULL) {
+        finalizing = _PyInterpreterState_GetFinalizing(tstate->interp);
+    }
+    return (finalizing != NULL && finalizing != tstate);
+}
+
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/Python/pythonrun.c b/Python/pythonrun.c
index 99e2eec453..f4c5d39c59 100644
--- a/Python/pythonrun.c
+++ b/Python/pythonrun.c
@@ -1092,21 +1092,16 @@ print_exception_suggestions(struct exception_print_context *ctx,
 }
 
 static int
-print_exception_notes(struct exception_print_context *ctx, PyObject *value)
+print_exception_notes(struct exception_print_context *ctx, PyObject *notes)
 {
     PyObject *f = ctx->file;
 
-    if (!PyExceptionInstance_Check(value)) {
+    if (notes == NULL) {
         return 0;
     }
 
-    PyObject *notes;
-    int res = _PyObject_LookupAttr(value, &_Py_ID(__notes__), &notes);
-    if (res <= 0) {
-        return res;
-    }
     if (!PySequence_Check(notes) || PyUnicode_Check(notes) || PyBytes_Check(notes)) {
-        res = 0;
+        int res = 0;
         if (write_indented_margin(ctx, f) < 0) {
             res = -1;
         }
@@ -1119,7 +1114,6 @@ print_exception_notes(struct exception_print_context *ctx, PyObject *value)
             res = PyFile_WriteObject(s, f, Py_PRINT_RAW);
             Py_DECREF(s);
         }
-        Py_DECREF(notes);
         if (PyFile_WriteString("\n", f) < 0) {
             res = -1;
         }
@@ -1164,17 +1158,16 @@ print_exception_notes(struct exception_print_context *ctx, PyObject *value)
         }
     }
 
-    Py_DECREF(notes);
     return 0;
 error:
     Py_XDECREF(lines);
-    Py_DECREF(notes);
     return -1;
 }
 
 static int
 print_exception(struct exception_print_context *ctx, PyObject *value)
 {
+    PyObject *notes = NULL;
     PyObject *f = ctx->file;
 
     if (!PyExceptionInstance_Check(value)) {
@@ -1188,8 +1181,11 @@ print_exception(struct exception_print_context *ctx, PyObject *value)
         goto error;
     }
 
-    /* grab the type now because value can change below */
+    /* grab the type and notes now because value can change below */
     PyObject *type = (PyObject *) Py_TYPE(value);
+    if (_PyObject_LookupAttr(value, &_Py_ID(__notes__), &notes) < 0) {
+        goto error;
+    }
 
     if (print_exception_file_and_line(ctx, &value) < 0) {
         goto error;
@@ -1203,14 +1199,16 @@ print_exception(struct exception_print_context *ctx, PyObject *value)
     if (PyFile_WriteString("\n", f) < 0) {
         goto error;
     }
-    if (print_exception_notes(ctx, value) < 0) {
+    if (print_exception_notes(ctx, notes) < 0) {
         goto error;
     }
 
+    Py_XDECREF(notes);
     Py_DECREF(value);
     assert(!PyErr_Occurred());
     return 0;
 error:
+    Py_XDECREF(notes);
     Py_DECREF(value);
     return -1;
 }
diff --git a/Python/symtable.c b/Python/symtable.c
index 4989e03d4b..70b6eacd4a 100644
--- a/Python/symtable.c
+++ b/Python/symtable.c
@@ -150,9 +150,8 @@ ste_new(struct symtable *st, identifier name, _Py_block_ty block,
 static PyObject *
 ste_repr(PySTEntryObject *ste)
 {
-    return PyUnicode_FromFormat("<symtable entry %U(%ld), line %d>",
-                                ste->ste_name,
-                                PyLong_AS_LONG(ste->ste_id), ste->ste_lineno);
+    return PyUnicode_FromFormat("<symtable entry %U(%R), line %d>",
+                                ste->ste_name, ste->ste_id, ste->ste_lineno);
 }
 
 static void
@@ -523,6 +522,7 @@ analyze_name(PySTEntryObject *ste, PyObject *scopes, PyObject *name, long flags,
              PyObject *bound, PyObject *local, PyObject *free,
              PyObject *global, PyObject *type_params, PySTEntryObject *class_entry)
 {
+    int contains;
     if (flags & DEF_GLOBAL) {
         if (flags & DEF_NONLOCAL) {
             PyErr_Format(PyExc_SyntaxError,
@@ -543,14 +543,22 @@ analyze_name(PySTEntryObject *ste, PyObject *scopes, PyObject *name, long flags,
                          "nonlocal declaration not allowed at module level");
             return error_at_directive(ste, name);
         }
-        if (!PySet_Contains(bound, name)) {
+        contains = PySet_Contains(bound, name);
+        if (contains < 0) {
+            return 0;
+        }
+        if (!contains) {
             PyErr_Format(PyExc_SyntaxError,
                          "no binding for nonlocal '%U' found",
                          name);
 
             return error_at_directive(ste, name);
         }
-        if (PySet_Contains(type_params, name)) {
+        contains = PySet_Contains(type_params, name);
+        if (contains < 0) {
+            return 0;
+        }
+        if (contains) {
             PyErr_Format(PyExc_SyntaxError,
                          "nonlocal binding not allowed for type parameter '%U'",
                          name);
@@ -599,17 +607,29 @@ analyze_name(PySTEntryObject *ste, PyObject *scopes, PyObject *name, long flags,
        Note that having a non-NULL bound implies that the block
        is nested.
     */
-    if (bound && PySet_Contains(bound, name)) {
-        SET_SCOPE(scopes, name, FREE);
-        ste->ste_free = 1;
-        return PySet_Add(free, name) >= 0;
+    if (bound) {
+        contains = PySet_Contains(bound, name);
+        if (contains < 0) {
+            return 0;
+        }
+        if (contains) {
+            SET_SCOPE(scopes, name, FREE);
+            ste->ste_free = 1;
+            return PySet_Add(free, name) >= 0;
+        }
     }
     /* If a parent has a global statement, then call it global
        explicit?  It could also be global implicit.
      */
-    if (global && PySet_Contains(global, name)) {
-        SET_SCOPE(scopes, name, GLOBAL_IMPLICIT);
-        return 1;
+    if (global) {
+        contains = PySet_Contains(global, name);
+        if (contains < 0) {
+            return 0;
+        }
+        if (contains) {
+            SET_SCOPE(scopes, name, GLOBAL_IMPLICIT);
+            return 1;
+        }
     }
     if (ste->ste_nested)
         ste->ste_free = 1;
@@ -712,8 +732,19 @@ analyze_cells(PyObject *scopes, PyObject *free, PyObject *inlined_cells)
         scope = PyLong_AS_LONG(v);
         if (scope != LOCAL)
             continue;
-        if (!PySet_Contains(free, name) && !PySet_Contains(inlined_cells, name))
-            continue;
+        int contains = PySet_Contains(free, name);
+        if (contains < 0) {
+            goto error;
+        }
+        if (!contains) {
+            contains = PySet_Contains(inlined_cells, name);
+            if (contains < 0) {
+                goto error;
+            }
+            if (!contains) {
+                continue;
+            }
+        }
         /* Replace LOCAL with CELL for this name, and remove
            from free. It is safe to replace the value of name
            in the dict, because it will not cause a resize.
@@ -764,7 +795,11 @@ update_symbols(PyObject *symbols, PyObject *scopes,
         long scope, flags;
         assert(PyLong_Check(v));
         flags = PyLong_AS_LONG(v);
-        if (PySet_Contains(inlined_cells, name)) {
+        int contains = PySet_Contains(inlined_cells, name);
+        if (contains < 0) {
+            return 0;
+        }
+        if (contains) {
             flags |= DEF_COMP_CELL;
         }
         v_scope = PyDict_GetItemWithError(scopes, name);
@@ -821,9 +856,15 @@ update_symbols(PyObject *symbols, PyObject *scopes,
             goto error;
         }
         /* Handle global symbol */
-        if (bound && !PySet_Contains(bound, name)) {
-            Py_DECREF(name);
-            continue;       /* it's a global */
+        if (bound) {
+            int contains = PySet_Contains(bound, name);
+            if (contains < 0) {
+                goto error;
+            }
+            if (!contains) {
+                Py_DECREF(name);
+                continue;       /* it's a global */
+            }
         }
         /* Propagate new free symbol up the lexical stack */
         if (PyDict_SetItem(symbols, name, v_free) < 0) {
diff --git a/Python/sysmodule.c b/Python/sysmodule.c
index 4bd38b4b26..14f4447425 100644
--- a/Python/sysmodule.c
+++ b/Python/sysmodule.c
@@ -3466,7 +3466,9 @@ _PySys_UpdateConfig(PyThreadState *tstate)
     if (config->pycache_prefix != NULL) {
         SET_SYS_FROM_WSTR("pycache_prefix", config->pycache_prefix);
     } else {
-        PyDict_SetItemString(sysdict, "pycache_prefix", Py_None);
+        if (PyDict_SetItemString(sysdict, "pycache_prefix", Py_None) < 0) {
+            return -1;
+        }
     }
 
     COPY_LIST("argv", config->argv);
@@ -3480,7 +3482,9 @@ _PySys_UpdateConfig(PyThreadState *tstate)
         SET_SYS_FROM_WSTR("_stdlib_dir", stdlibdir);
     }
     else {
-        PyDict_SetItemString(sysdict, "_stdlib_dir", Py_None);
+        if (PyDict_SetItemString(sysdict, "_stdlib_dir", Py_None) < 0) {
+            return -1;
+        }
     }
 
 #undef SET_SYS_FROM_WSTR
@@ -3490,6 +3494,9 @@ _PySys_UpdateConfig(PyThreadState *tstate)
     // sys.flags
     PyObject *flags = _PySys_GetObject(interp, "flags"); // borrowed ref
     if (flags == NULL) {
+        if (!_PyErr_Occurred(tstate)) {
+            _PyErr_SetString(tstate, PyExc_RuntimeError, "lost sys.flags");
+        }
         return -1;
     }
     if (set_flags_from_config(interp, flags) < 0) {
diff --git a/Python/traceback.c b/Python/traceback.c
index dc258703a8..b627b06df7 100644
--- a/Python/traceback.c
+++ b/Python/traceback.c
@@ -107,6 +107,26 @@ tb_next_get(PyTracebackObject *self, void *Py_UNUSED(_))
     return Py_NewRef(ret);
 }
 
+static int
+tb_get_lineno(PyTracebackObject* tb) {
+    PyFrameObject* frame = tb->tb_frame;
+    assert(frame != NULL);
+    return PyCode_Addr2Line(PyFrame_GetCode(frame), tb->tb_lasti);
+}
+
+static PyObject *
+tb_lineno_get(PyTracebackObject *self, void *Py_UNUSED(_))
+{
+    int lineno = self->tb_lineno;
+    if (lineno == -1) {
+        lineno = tb_get_lineno(self);
+        if (lineno < 0) {
+            Py_RETURN_NONE;
+        }
+    }
+    return PyLong_FromLong(lineno);
+}
+
 static int
 tb_next_set(PyTracebackObject *self, PyObject *new_next, void *Py_UNUSED(_))
 {
@@ -150,12 +170,12 @@ static PyMethodDef tb_methods[] = {
 static PyMemberDef tb_memberlist[] = {
     {"tb_frame",        T_OBJECT,       OFF(tb_frame),  READONLY|PY_AUDIT_READ},
     {"tb_lasti",        T_INT,          OFF(tb_lasti),  READONLY},
-    {"tb_lineno",       T_INT,          OFF(tb_lineno), READONLY},
     {NULL}      /* Sentinel */
 };
 
 static PyGetSetDef tb_getsetters[] = {
     {"tb_next", (getter)tb_next_get, (setter)tb_next_set, NULL, NULL},
+    {"tb_lineno", (getter)tb_lineno_get, NULL, NULL, NULL},
     {NULL}      /* Sentinel */
 };
 
@@ -234,8 +254,7 @@ _PyTraceBack_FromFrame(PyObject *tb_next, PyFrameObject *frame)
     assert(tb_next == NULL || PyTraceBack_Check(tb_next));
     assert(frame != NULL);
     int addr = _PyInterpreterFrame_LASTI(frame->f_frame) * sizeof(_Py_CODEUNIT);
-    return tb_create_raw((PyTracebackObject *)tb_next, frame, addr,
-                         PyFrame_GetLineNumber(frame));
+    return tb_create_raw((PyTracebackObject *)tb_next, frame, addr, -1);
 }
 
 
@@ -900,8 +919,39 @@ tb_displayline(PyTracebackObject* tb, PyObject *f, PyObject *filename, int linen
         goto done;
     }
 
-    if (print_error_location_carets(f, truncation, start_offset, end_offset,
-                                    right_start_offset, left_end_offset,
+    // Convert all offsets to display offsets (e.g. the space they would take up if printed
+    // on the screen).
+    Py_ssize_t dp_start = _PyPegen_calculate_display_width(source_line, start_offset);
+    if (dp_start < 0) {
+        err = ignore_source_errors() < 0;
+        goto done;
+    }
+
+    Py_ssize_t dp_end = _PyPegen_calculate_display_width(source_line, end_offset);
+    if (dp_end < 0) {
+        err = ignore_source_errors() < 0;
+        goto done;
+    }
+
+    Py_ssize_t dp_left_end = -1;
+    Py_ssize_t dp_right_start = -1;
+    if (has_secondary_ranges) {
+        dp_left_end = _PyPegen_calculate_display_width(source_line, left_end_offset);
+        if (dp_left_end < 0) {
+            err = ignore_source_errors() < 0;
+            goto done;
+        }
+
+        dp_right_start = _PyPegen_calculate_display_width(source_line, right_start_offset);
+        if (dp_right_start < 0) {
+            err = ignore_source_errors() < 0;
+            goto done;
+        }
+    }
+
+
+    if (print_error_location_carets(f, truncation, dp_start, dp_end,
+                                    dp_right_start, dp_left_end,
                                     primary_error_char, secondary_error_char) < 0) {
         err = -1;
         goto done;
@@ -952,9 +1002,13 @@ tb_printinternal(PyTracebackObject *tb, PyObject *f, long limit,
     }
     while (tb != NULL) {
         code = PyFrame_GetCode(tb->tb_frame);
+        int tb_lineno = tb->tb_lineno;
+        if (tb_lineno == -1) {
+            tb_lineno = tb_get_lineno(tb);
+        }
         if (last_file == NULL ||
             code->co_filename != last_file ||
-            last_line == -1 || tb->tb_lineno != last_line ||
+            last_line == -1 || tb_lineno != last_line ||
             last_name == NULL || code->co_name != last_name) {
             if (cnt > TB_RECURSIVE_CUTOFF) {
                 if (tb_print_line_repeated(f, cnt) < 0) {
@@ -962,13 +1016,13 @@ tb_printinternal(PyTracebackObject *tb, PyObject *f, long limit,
                 }
             }
             last_file = code->co_filename;
-            last_line = tb->tb_lineno;
+            last_line = tb_lineno;
             last_name = code->co_name;
             cnt = 0;
         }
         cnt++;
         if (cnt <= TB_RECURSIVE_CUTOFF) {
-            if (tb_displayline(tb, f, code->co_filename, tb->tb_lineno,
+            if (tb_displayline(tb, f, code->co_filename, tb_lineno,
                                tb->tb_frame, code->co_name, indent, margin) < 0) {
                 goto error;
             }
@@ -1218,23 +1272,45 @@ dump_frame(int fd, _PyInterpreterFrame *frame)
     PUTS(fd, "\n");
 }
 
+static int
+tstate_is_freed(PyThreadState *tstate)
+{
+    if (_PyMem_IsPtrFreed(tstate)) {
+        return 1;
+    }
+    if (_PyMem_IsPtrFreed(tstate->interp)) {
+        return 1;
+    }
+    return 0;
+}
+
+
+static int
+interp_is_freed(PyInterpreterState *interp)
+{
+    return _PyMem_IsPtrFreed(interp);
+}
+
+
 static void
 dump_traceback(int fd, PyThreadState *tstate, int write_header)
 {
-    _PyInterpreterFrame *frame;
-    unsigned int depth;
-
     if (write_header) {
         PUTS(fd, "Stack (most recent call first):\n");
     }
 
-    frame = tstate->cframe->current_frame;
+    if (tstate_is_freed(tstate)) {
+        PUTS(fd, "  <tstate is freed>\n");
+        return;
+    }
+
+    _PyInterpreterFrame *frame = tstate->cframe->current_frame;
     if (frame == NULL) {
         PUTS(fd, "  <no Python frame>\n");
         return;
     }
 
-    depth = 0;
+    unsigned int depth = 0;
     while (1) {
         if (MAX_FRAME_DEPTH <= depth) {
             PUTS(fd, "  ...\n");
@@ -1298,9 +1374,6 @@ const char*
 _Py_DumpTracebackThreads(int fd, PyInterpreterState *interp,
                          PyThreadState *current_tstate)
 {
-    PyThreadState *tstate;
-    unsigned int nthreads;
-
     if (current_tstate == NULL) {
         /* _Py_DumpTracebackThreads() is called from signal handlers by
            faulthandler.
@@ -1316,6 +1389,10 @@ _Py_DumpTracebackThreads(int fd, PyInterpreterState *interp,
         current_tstate = PyGILState_GetThisThreadState();
     }
 
+    if (current_tstate != NULL && tstate_is_freed(current_tstate)) {
+        return "tstate is freed";
+    }
+
     if (interp == NULL) {
         if (current_tstate == NULL) {
             interp = _PyGILState_GetInterpreterStateUnsafe();
@@ -1330,14 +1407,18 @@ _Py_DumpTracebackThreads(int fd, PyInterpreterState *interp,
     }
     assert(interp != NULL);
 
+    if (interp_is_freed(interp)) {
+        return "interp is freed";
+    }
+
     /* Get the current interpreter from the current thread */
-    tstate = PyInterpreterState_ThreadHead(interp);
+    PyThreadState *tstate = PyInterpreterState_ThreadHead(interp);
     if (tstate == NULL)
         return "unable to get the thread head state";
 
     /* Dump the traceback of each thread */
     tstate = PyInterpreterState_ThreadHead(interp);
-    nthreads = 0;
+    unsigned int nthreads = 0;
     _Py_BEGIN_SUPPRESS_IPH
     do
     {
diff --git a/Tools/c-analyzer/cpython/ignored.tsv b/Tools/c-analyzer/cpython/ignored.tsv
index 6a7c14ebb2..629a9a10ae 100644
--- a/Tools/c-analyzer/cpython/ignored.tsv
+++ b/Tools/c-analyzer/cpython/ignored.tsv
@@ -572,15 +572,15 @@ Modules/_testmultiphase.c	-	uninitialized_def	-
 Modules/_testsinglephase.c	-	global_state	-
 Modules/_xxtestfuzz/_xxtestfuzz.c	-	_fuzzmodule	-
 Modules/_xxtestfuzz/_xxtestfuzz.c	-	module_methods	-
-Modules/_xxtestfuzz/fuzzer.c	-	SRE_FLAG_DEBUG	-
+Modules/_xxtestfuzz/fuzzer.c	-	RE_FLAG_DEBUG	-
 Modules/_xxtestfuzz/fuzzer.c	-	ast_literal_eval_method	-
 Modules/_xxtestfuzz/fuzzer.c	-	compiled_patterns	-
 Modules/_xxtestfuzz/fuzzer.c	-	csv_error	-
 Modules/_xxtestfuzz/fuzzer.c	-	csv_module	-
 Modules/_xxtestfuzz/fuzzer.c	-	json_loads_method	-
 Modules/_xxtestfuzz/fuzzer.c	-	regex_patterns	-
-Modules/_xxtestfuzz/fuzzer.c	-	sre_compile_method	-
-Modules/_xxtestfuzz/fuzzer.c	-	sre_error_exception	-
+Modules/_xxtestfuzz/fuzzer.c	-	re_compile_method	-
+Modules/_xxtestfuzz/fuzzer.c	-	re_error_exception	-
 Modules/_xxtestfuzz/fuzzer.c	-	struct_error	-
 Modules/_xxtestfuzz/fuzzer.c	-	struct_unpack_method	-
 Modules/_xxtestfuzz/fuzzer.c	LLVMFuzzerTestOneInput	CSV_READER_INITIALIZED	-
diff --git a/Tools/clinic/.ruff.toml b/Tools/clinic/.ruff.toml
new file mode 100644
index 0000000000..cbb3a9a8f3
--- /dev/null
+++ b/Tools/clinic/.ruff.toml
@@ -0,0 +1,29 @@
+target-version = "py310"
+fix = true
+select = [
+    "F",  # Enable all pyflakes rules
+    "UP",  # Enable all pyupgrade rules by default
+    "RUF100",  # Ban unused `# noqa` comments
+    "PGH004",  # Ban blanket `# noqa` comments (only ignore specific error codes)
+]
+ignore = [
+    # Unnecessary parentheses to functools.lru_cache: just leads to unnecessary churn.
+    # https://github.com/python/cpython/pull/104684#discussion_r1199653347.
+    "UP011",
+    # Use format specifiers instead of %-style formatting.
+    # Doesn't always make code more readable.
+    "UP031",
+    # Use f-strings instead of format specifiers.
+    # Doesn't always make code more readable.
+    "UP032",
+    # Use PEP-604 unions rather than tuples for isinstance() checks.
+    # Makes code slower and more verbose. https://github.com/astral-sh/ruff/issues/7871.
+    "UP038",
+]
+unfixable = [
+    # The autofixes sometimes do the wrong things for these;
+    # it's better to have to manually look at the code and see how it needs fixing
+    "F841",  # Detects unused variables
+    "F601",  # Detects dictionaries that have duplicate keys
+    "F602",  # Also detects dictionaries that have duplicate keys
+]
diff --git a/Tools/clinic/clinic.py b/Tools/clinic/clinic.py
index fd394c92ca..921b77bad5 100755
--- a/Tools/clinic/clinic.py
+++ b/Tools/clinic/clinic.py
@@ -1968,7 +1968,7 @@ def dump(self):
 
 def write_file(filename: str, new_contents: str) -> None:
     try:
-        with open(filename, 'r', encoding="utf-8") as fp:
+        with open(filename, encoding="utf-8") as fp:
             old_contents = fp.read()
 
         if old_contents == new_contents:
diff --git a/Tools/clinic/requirements-dev.txt b/Tools/clinic/requirements-dev.txt
deleted file mode 100644
index 154934003c..0000000000
--- a/Tools/clinic/requirements-dev.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-# Requirements file for external linters and checks we run on Tools/clinic/ in CI
-mypy==1.3.0
diff --git a/Tools/freeze/test/freeze.py b/Tools/freeze/test/freeze.py
index 92e97cb261..d5f4d3d24c 100644
--- a/Tools/freeze/test/freeze.py
+++ b/Tools/freeze/test/freeze.py
@@ -1,14 +1,22 @@
 import os
 import os.path
-import re
 import shlex
 import shutil
 import subprocess
+import sysconfig
+from test import support
+
+
+def get_python_source_dir():
+    src_dir = sysconfig.get_config_var('abs_srcdir')
+    if not src_dir:
+        src_dir = sysconfig.get_config_var('srcdir')
+    return os.path.abspath(src_dir)
 
 
 TESTS_DIR = os.path.dirname(__file__)
 TOOL_ROOT = os.path.dirname(TESTS_DIR)
-SRCDIR = os.path.dirname(os.path.dirname(TOOL_ROOT))
+SRCDIR = get_python_source_dir()
 
 MAKE = shutil.which('make')
 FREEZE = os.path.join(TOOL_ROOT, 'freeze.py')
@@ -19,8 +27,10 @@ class UnsupportedError(Exception):
     """The operation isn't supported."""
 
 
-def _run_quiet(cmd, cwd=None):
-    #print(f'# {" ".join(shlex.quote(a) for a in cmd)}')
+def _run_quiet(cmd, *, cwd=None):
+    if cwd:
+        print('+', 'cd', cwd, flush=True)
+    print('+', shlex.join(cmd), flush=True)
     try:
         return subprocess.run(
             cmd,
@@ -40,8 +50,8 @@ def _run_quiet(cmd, cwd=None):
         raise
 
 
-def _run_stdout(cmd, cwd=None):
-    proc = _run_quiet(cmd, cwd)
+def _run_stdout(cmd):
+    proc = _run_quiet(cmd)
     return proc.stdout.strip()
 
 
@@ -75,60 +85,26 @@ def ensure_opt(args, name, value):
 
 
 def copy_source_tree(newroot, oldroot):
-    print(f'copying the source tree into {newroot}...')
+    print(f'copying the source tree from {oldroot} to {newroot}...')
     if os.path.exists(newroot):
         if newroot == SRCDIR:
             raise Exception('this probably isn\'t what you wanted')
         shutil.rmtree(newroot)
 
-    def ignore_non_src(src, names):
-        """Turns what could be a 1000M copy into a 100M copy."""
-        # Don't copy the ~600M+ of needless git repo metadata.
-        # source only, ignore cached .pyc files.
-        subdirs_to_skip = {'.git', '__pycache__'}
-        if os.path.basename(src) == 'Doc':
-            # Another potential ~250M+ of non test related data.
-            subdirs_to_skip.add('build')
-            subdirs_to_skip.add('venv')
-        return subdirs_to_skip
-
-    shutil.copytree(oldroot, newroot, ignore=ignore_non_src)
+    shutil.copytree(oldroot, newroot, ignore=support.copy_python_src_ignore)
     if os.path.exists(os.path.join(newroot, 'Makefile')):
-        _run_quiet([MAKE, 'clean'], newroot)
-
-
-def get_makefile_var(builddir, name):
-    regex = re.compile(rf'^{name} *=\s*(.*?)\s*$')
-    filename = os.path.join(builddir, 'Makefile')
-    try:
-        infile = open(filename, encoding='utf-8')
-    except FileNotFoundError:
-        return None
-    with infile:
-        for line in infile:
-            m = regex.match(line)
-            if m:
-                value, = m.groups()
-                return value or ''
-    return None
-
-
-def get_config_var(builddir, name):
-    python = os.path.join(builddir, 'python')
-    if os.path.isfile(python):
-        cmd = [python, '-c',
-               f'import sysconfig; print(sysconfig.get_config_var("{name}"))']
-        try:
-            return _run_stdout(cmd)
-        except subprocess.CalledProcessError:
-            pass
-    return get_makefile_var(builddir, name)
+        # Out-of-tree builds require a clean srcdir. "make clean" keeps
+        # the "python" program, so use "make distclean" instead.
+        _run_quiet([MAKE, 'distclean'], cwd=newroot)
 
 
 ##################################
 # freezing
 
 def prepare(script=None, outdir=None):
+    print()
+    print("cwd:", os.getcwd())
+
     if not outdir:
         outdir = OUTDIR
     os.makedirs(outdir, exist_ok=True)
@@ -151,14 +127,12 @@ def prepare(script=None, outdir=None):
 
     # Run configure.
     print(f'configuring python in {builddir}...')
-    cmd = [
-        os.path.join(srcdir, 'configure'),
-        *shlex.split(get_config_var(SRCDIR, 'CONFIG_ARGS') or ''),
-    ]
+    config_args = shlex.split(sysconfig.get_config_var('CONFIG_ARGS') or '')
+    cmd = [os.path.join(srcdir, 'configure'), *config_args]
     ensure_opt(cmd, 'cache-file', os.path.join(outdir, 'python-config.cache'))
     prefix = os.path.join(outdir, 'python-installation')
     ensure_opt(cmd, 'prefix', prefix)
-    _run_quiet(cmd, builddir)
+    _run_quiet(cmd, cwd=builddir)
 
     if not MAKE:
         raise UnsupportedError('make')
@@ -168,20 +142,18 @@ def prepare(script=None, outdir=None):
         # this test is most often run as part of the whole suite with a lot
         # of other tests running in parallel, from 1-2 vCPU systems up to
         # people's NNN core beasts. Don't attempt to use it all.
-        parallel = f'-j{cores*2//3}'
+        jobs = cores * 2 // 3
+        parallel = f'-j{jobs}'
     else:
         parallel = '-j2'
 
     # Build python.
     print(f'building python {parallel=} in {builddir}...')
-    if os.path.exists(os.path.join(srcdir, 'Makefile')):
-        # Out-of-tree builds require a clean srcdir.
-        _run_quiet([MAKE, '-C', srcdir, 'clean'])
-    _run_quiet([MAKE, '-C', builddir, parallel])
+    _run_quiet([MAKE, parallel], cwd=builddir)
 
     # Install the build.
     print(f'installing python into {prefix}...')
-    _run_quiet([MAKE, '-C', builddir, 'install'])
+    _run_quiet([MAKE, 'install'], cwd=builddir)
     python = os.path.join(prefix, 'bin', 'python3')
 
     return outdir, scriptfile, python
@@ -194,8 +166,8 @@ def freeze(python, scriptfile, outdir):
     print(f'freezing {scriptfile}...')
     os.makedirs(outdir, exist_ok=True)
     # Use -E to ignore PYTHONSAFEPATH
-    _run_quiet([python, '-E', FREEZE, '-o', outdir, scriptfile], outdir)
-    _run_quiet([MAKE, '-C', os.path.dirname(scriptfile)])
+    _run_quiet([python, '-E', FREEZE, '-o', outdir, scriptfile], cwd=outdir)
+    _run_quiet([MAKE], cwd=os.path.dirname(scriptfile))
 
     name = os.path.basename(scriptfile).rpartition('.')[0]
     executable = os.path.join(outdir, name)
diff --git a/Tools/patchcheck/patchcheck.py b/Tools/patchcheck/patchcheck.py
index fa3a43af6e..af1f0584bb 100755
--- a/Tools/patchcheck/patchcheck.py
+++ b/Tools/patchcheck/patchcheck.py
@@ -11,6 +11,13 @@
 import untabify
 
 
+def get_python_source_dir():
+    src_dir = sysconfig.get_config_var('abs_srcdir')
+    if not src_dir:
+        src_dir = sysconfig.get_config_var('srcdir')
+    return os.path.abspath(src_dir)
+
+
 # Excluded directories which are copies of external libraries:
 # don't check their coding style
 EXCLUDE_DIRS = [
@@ -18,12 +25,13 @@
     os.path.join('Modules', 'expat'),
     os.path.join('Modules', 'zlib'),
     ]
-SRCDIR = sysconfig.get_config_var('srcdir')
+SRCDIR = get_python_source_dir()
 
 
 def n_files_str(count):
     """Return 'N file(s)' with the proper plurality on 'file'."""
-    return "{} file{}".format(count, "s" if count != 1 else "")
+    s = "s" if count != 1 else ""
+    return f"{count} file{s}"
 
 
 def status(message, modal=False, info=None):
@@ -77,7 +85,7 @@ def get_git_remote_default_branch(remote_name):
 
     It is typically called 'main', but may differ
     """
-    cmd = "git remote show {}".format(remote_name).split()
+    cmd = f"git remote show {remote_name}".split()
     env = os.environ.copy()
     env['LANG'] = 'C'
     try:
@@ -164,9 +172,9 @@ def report_modified_files(file_paths):
     if count == 0:
         return n_files_str(count)
     else:
-        lines = ["{}:".format(n_files_str(count))]
+        lines = [f"{n_files_str(count)}:"]
         for path in file_paths:
-            lines.append("  {}".format(path))
+            lines.append(f"  {path}")
         return "\n".join(lines)
 
 
@@ -205,27 +213,6 @@ def normalize_c_whitespace(file_paths):
     return fixed
 
 
-ws_re = re.compile(br'\s+(\r?\n)$')
-
-@status("Fixing docs whitespace", info=report_modified_files)
-def normalize_docs_whitespace(file_paths):
-    fixed = []
-    for path in file_paths:
-        abspath = os.path.join(SRCDIR, path)
-        try:
-            with open(abspath, 'rb') as f:
-                lines = f.readlines()
-            new_lines = [ws_re.sub(br'\1', line) for line in lines]
-            if new_lines != lines:
-                shutil.copyfile(abspath, abspath + '.bak')
-                with open(abspath, 'wb') as f:
-                    f.writelines(new_lines)
-                fixed.append(path)
-        except Exception as err:
-            print('Cannot fix %s: %s' % (path, err))
-    return fixed
-
-
 @status("Docs modified", modal=True)
 def docs_modified(file_paths):
     """Report if any file in the Doc directory has been changed."""
@@ -244,6 +231,7 @@ def reported_news(file_paths):
     return any(p.startswith(os.path.join('Misc', 'NEWS.d', 'next'))
                for p in file_paths)
 
+
 @status("configure regenerated", modal=True, info=str)
 def regenerated_configure(file_paths):
     """Check if configure has been regenerated."""
@@ -252,6 +240,7 @@ def regenerated_configure(file_paths):
     else:
         return "not needed"
 
+
 @status("pyconfig.h.in regenerated", modal=True, info=str)
 def regenerated_pyconfig_h_in(file_paths):
     """Check if pyconfig.h.in has been regenerated."""
@@ -260,6 +249,7 @@ def regenerated_pyconfig_h_in(file_paths):
     else:
         return "not needed"
 
+
 def ci(pull_request):
     if pull_request == 'false':
         print('Not a pull request; skipping')
@@ -268,19 +258,18 @@ def ci(pull_request):
     file_paths = changed_files(base_branch)
     python_files = [fn for fn in file_paths if fn.endswith('.py')]
     c_files = [fn for fn in file_paths if fn.endswith(('.c', '.h'))]
-    doc_files = [fn for fn in file_paths if fn.startswith('Doc') and
-                 fn.endswith(('.rst', '.inc'))]
     fixed = []
     fixed.extend(normalize_whitespace(python_files))
     fixed.extend(normalize_c_whitespace(c_files))
-    fixed.extend(normalize_docs_whitespace(doc_files))
     if not fixed:
         print('No whitespace issues found')
     else:
-        print(f'Please fix the {len(fixed)} file(s) with whitespace issues')
-        print('(on UNIX you can run `make patchcheck` to make the fixes)')
+        count = len(fixed)
+        print(f'Please fix the {n_files_str(count)} with whitespace issues')
+        print('(on Unix you can run `make patchcheck` to make the fixes)')
         sys.exit(1)
 
+
 def main():
     base_branch = get_base_branch()
     file_paths = changed_files(base_branch)
@@ -293,8 +282,6 @@ def main():
     normalize_whitespace(python_files)
     # C rules enforcement.
     normalize_c_whitespace(c_files)
-    # Doc whitespace enforcement.
-    normalize_docs_whitespace(doc_files)
     # Docs updated.
     docs_modified(doc_files)
     # Misc/ACKS changed.
diff --git a/Tools/patchcheck/untabify.py b/Tools/patchcheck/untabify.py
index 861c83ced9..5c9d120854 100755
--- a/Tools/patchcheck/untabify.py
+++ b/Tools/patchcheck/untabify.py
@@ -21,8 +21,7 @@ def main():
         if optname == '-t':
             tabsize = int(optvalue)
 
-    for filename in args:
-        process(filename, tabsize)
+    return max(process(filename, tabsize) for filename in args)
 
 
 def process(filename, tabsize, verbose=True):
@@ -32,10 +31,10 @@ def process(filename, tabsize, verbose=True):
             encoding = f.encoding
     except IOError as msg:
         print("%r: I/O error: %s" % (filename, msg))
-        return
+        return 2
     newtext = text.expandtabs(tabsize)
     if newtext == text:
-        return
+        return 0
     backup = filename + "~"
     try:
         os.unlink(backup)
@@ -49,7 +48,8 @@ def process(filename, tabsize, verbose=True):
         f.write(newtext)
     if verbose:
         print(filename)
+    return 1
 
 
 if __name__ == '__main__':
-    main()
+    raise SystemExit(main())
diff --git a/Tools/peg_generator/pegen/grammar.py b/Tools/peg_generator/pegen/grammar.py
index 03d60d0102..a6c19bc7b8 100644
--- a/Tools/peg_generator/pegen/grammar.py
+++ b/Tools/peg_generator/pegen/grammar.py
@@ -35,7 +35,13 @@ def generic_visit(self, node: Iterable[Any], *args: Any, **kwargs: Any) -> Any:
 
 class Grammar:
     def __init__(self, rules: Iterable[Rule], metas: Iterable[Tuple[str, Optional[str]]]):
-        self.rules = {rule.name: rule for rule in rules}
+        # Check if there are repeated rules in "rules"
+        all_rules = {}
+        for rule in rules:
+            if rule.name in all_rules:
+                raise GrammarError(f"Repeated rule {rule.name!r}")
+            all_rules[rule.name] = rule
+        self.rules = all_rules
         self.metas = dict(metas)
 
     def __str__(self) -> str:
diff --git a/Tools/requirements-dev.txt b/Tools/requirements-dev.txt
new file mode 100644
index 0000000000..79ef43a402
--- /dev/null
+++ b/Tools/requirements-dev.txt
@@ -0,0 +1,2 @@
+# Requirements file for external linters and checks we run on Tools/clinic/ in CI
+mypy==1.6.1
diff --git a/Tools/unicode/genmap_japanese.py b/Tools/unicode/genmap_japanese.py
index 21de37b62b..838317fa54 100644
--- a/Tools/unicode/genmap_japanese.py
+++ b/Tools/unicode/genmap_japanese.py
@@ -2,7 +2,7 @@
 # genmap_ja_codecs.py: Japanese Codecs Map Generator
 #
 # Original Author:  Hye-Shik Chang <perky@FreeBSD.org>
-# Modified Author:  Dong-hee Na <donghee.na92@gmail.com>
+# Modified Author:  Donghee Na <donghee.na92@gmail.com>
 #
 import os
 
diff --git a/Tools/unicode/genmap_korean.py b/Tools/unicode/genmap_korean.py
index 4b94a6c43e..4432a3601b 100644
--- a/Tools/unicode/genmap_korean.py
+++ b/Tools/unicode/genmap_korean.py
@@ -2,7 +2,7 @@
 # genmap_korean.py: Korean Codecs Map Generator
 #
 # Original Author:  Hye-Shik Chang <perky@FreeBSD.org>
-# Modified Author:  Dong-hee Na <donghee.na92@gmail.com>
+# Modified Author:  Donghee Na <donghee.na92@gmail.com>
 #
 import os
 
diff --git a/Tools/unicode/genmap_schinese.py b/Tools/unicode/genmap_schinese.py
index 647c0333ed..862f1def71 100644
--- a/Tools/unicode/genmap_schinese.py
+++ b/Tools/unicode/genmap_schinese.py
@@ -2,7 +2,7 @@
 # genmap_schinese.py: Simplified Chinese Codecs Map Generator
 #
 # Original Author:  Hye-Shik Chang <perky@FreeBSD.org>
-# Modified Author:  Dong-hee Na <donghee.na92@gmail.com>
+# Modified Author:  Donghee Na <donghee.na92@gmail.com>
 #
 import os
 import re
diff --git a/Tools/unicode/genmap_support.py b/Tools/unicode/genmap_support.py
index 5e1d9ee77b..4649bc3b71 100644
--- a/Tools/unicode/genmap_support.py
+++ b/Tools/unicode/genmap_support.py
@@ -2,7 +2,7 @@
 # genmap_support.py: Multibyte Codec Map Generator
 #
 # Original Author:  Hye-Shik Chang <perky@FreeBSD.org>
-# Modified Author:  Dong-hee Na <donghee.na92@gmail.com>
+# Modified Author:  Donghee Na <donghee.na92@gmail.com>
 #
 
 
diff --git a/configure.ac b/configure.ac
index ba768aea93..3afa9aca8b 100644
--- a/configure.ac
+++ b/configure.ac
@@ -590,6 +590,14 @@ then
 	darwin*) MACHDEP="darwin";;
 	'')	MACHDEP="unknown";;
     esac
+
+    if test "$ac_sys_system" = "SunOS"; then
+	# For Solaris, there isn't an OS version specific macro defined
+	# in most compilers, so we define one here.
+	SUNOS_VERSION=`echo $ac_sys_release | sed -e 's!\.\([0-9]\)$!.0\1!g' | tr -d '.'`
+	AC_DEFINE_UNQUOTED([Py_SUNOS_VERSION], [$SUNOS_VERSION],
+	                   [The version of SunOS/Solaris as reported by `uname -r' without the dot.])
+    fi
 fi
 AC_MSG_RESULT(["$MACHDEP"])
 
@@ -2318,10 +2326,15 @@ AS_CASE([$ac_sys_system],
       # without this, configure fails to find pthread_create, sem_init,
       # etc because they are only available in the sysroot for
       # wasm32-wasi-threads.
+      # Note: wasi-threads requires --import-memory.
+      # Note: wasi requires --export-memory.
+      # Note: --export-memory is implicit unless --import-memory is given
+      # Note: this requires LLVM >= 16.
       AS_VAR_APPEND([CFLAGS], [" -target wasm32-wasi-threads -pthread"])
       AS_VAR_APPEND([CFLAGS_NODIST], [" -target wasm32-wasi-threads -pthread"])
       AS_VAR_APPEND([LDFLAGS_NODIST], [" -target wasm32-wasi-threads -pthread"])
       AS_VAR_APPEND([LDFLAGS_NODIST], [" -Wl,--import-memory"])
+      AS_VAR_APPEND([LDFLAGS_NODIST], [" -Wl,--export-memory"])
       AS_VAR_APPEND([LDFLAGS_NODIST], [" -Wl,--max-memory=10485760"])
     ])
 
@@ -6213,6 +6226,13 @@ AS_VAR_IF([with_readline], [no], [
       AC_DEFINE([HAVE_RL_APPEND_HISTORY], [1], [Define if readline supports append_history])
     ])
 
+    # in readline as well as newer editline (April 2023)
+    AC_CHECK_TYPE([rl_compdisp_func_t],
+                  [AC_DEFINE([HAVE_RL_COMPDISP_FUNC_T], [1],
+                             [Define if readline supports rl_compdisp_func_t])],
+                  [],
+                  [readline_includes])
+
     m4_undefine([readline_includes])
   ])dnl WITH_SAVE_ENV()
 ])
diff --git a/pyconfig.h.in b/pyconfig.h.in
index ada9dccfef..6d370f6664 100644
--- a/pyconfig.h.in
+++ b/pyconfig.h.in
@@ -989,6 +989,9 @@
 /* Define if you can turn off readline's signal handling. */
 #undef HAVE_RL_CATCH_SIGNAL
 
+/* Define if readline supports rl_compdisp_func_t */
+#undef HAVE_RL_COMPDISP_FUNC_T
+
 /* Define if you have readline 2.2 */
 #undef HAVE_RL_COMPLETION_APPEND_CHARACTER
 
@@ -1618,6 +1621,9 @@
 /* Define if you want to enable internal statistics gathering. */
 #undef Py_STATS
 
+/* The version of SunOS/Solaris as reported by `uname -r' without the dot. */
+#undef Py_SUNOS_VERSION
+
 /* Define if you want to enable tracing references for debugging purpose */
 #undef Py_TRACE_REFS
 
