Description: Updates from the 3.12 branch (until 2024-04-02).
 We pick the latest updates from the maintainance branch, and carry them in a
 patch, rather than creating and uploading uploading a new .orig tarball.

# git diff --no-renames 6abddd9f6afdddc09031989e0deb25e301ecf315 52f1fb6f7dba31ccbe28f555f199c7d29f137581 | filterdiff -x ?/.hgignore -x ?/.hgeol -x ?/.hgtags -x ?/.hgtouch -x ?/.gitignore -x ?/.gitattributes -x '?/.github/*' -x '?/.git*' -x ?/.codecov.yml -x ?/.travis.yml -x ?/configure --remove-timestamps

diff --git a/Doc/Makefile b/Doc/Makefile
index 38fd60f2ae..dd068c520a 100644
--- a/Doc/Makefile
+++ b/Doc/Makefile
@@ -163,6 +163,7 @@ venv:
 		echo "venv already exists."; \
 		echo "To recreate it, remove it first with \`make clean-venv'."; \
 	else \
+		echo "Creating venv in $(VENVDIR)"; \
 		$(PYTHON) -m venv $(VENVDIR); \
 		$(VENVDIR)/bin/python3 -m pip install --upgrade pip; \
 		$(VENVDIR)/bin/python3 -m pip install -r $(REQUIREMENTS); \
diff --git a/Doc/c-api/buffer.rst b/Doc/c-api/buffer.rst
index e572815ffd..1e1cabdf24 100644
--- a/Doc/c-api/buffer.rst
+++ b/Doc/c-api/buffer.rst
@@ -29,7 +29,7 @@ without intermediate copying.
 Python provides such a facility at the C level in the form of the :ref:`buffer
 protocol <bufferobjects>`.  This protocol has two sides:
 
-.. index:: single: PyBufferProcs
+.. index:: single: PyBufferProcs (C type)
 
 - on the producer side, a type can export a "buffer interface" which allows
   objects of that type to expose information about their underlying buffer.
diff --git a/Doc/c-api/code.rst b/Doc/c-api/code.rst
index 5082b0cb6a..f6fdd75743 100644
--- a/Doc/c-api/code.rst
+++ b/Doc/c-api/code.rst
@@ -22,16 +22,21 @@ bound into a function.
 .. c:var:: PyTypeObject PyCode_Type
 
    This is an instance of :c:type:`PyTypeObject` representing the Python
-   :class:`code` type.
+   :ref:`code object <code-objects>`.
 
 
 .. c:function:: int PyCode_Check(PyObject *co)
 
-   Return true if *co* is a :class:`code` object.  This function always succeeds.
+   Return true if *co* is a :ref:`code object <code-objects>`.
+   This function always succeeds.
 
-.. c:function:: int PyCode_GetNumFree(PyCodeObject *co)
+.. c:function:: Py_ssize_t PyCode_GetNumFree(PyCodeObject *co)
 
-   Return the number of free variables in *co*.
+   Return the number of free variables in a code object.
+
+.. c:function:: int PyCode_GetFirstFree(PyCodeObject *co)
+
+   Return the position of the first free variable in a code object.
 
 .. c:function:: PyCodeObject* PyUnstable_Code_New(int argcount, int kwonlyargcount, int nlocals, int stacksize, int flags, PyObject *code, PyObject *consts, PyObject *names, PyObject *varnames, PyObject *freevars, PyObject *cellvars, PyObject *filename, PyObject *name, PyObject *qualname, int firstlineno, PyObject *linetable, PyObject *exceptiontable)
 
@@ -48,7 +53,7 @@ bound into a function.
    .. versionchanged:: 3.11
       Added ``qualname`` and ``exceptiontable`` parameters.
 
-   .. index:: single: PyCode_New
+   .. index:: single: PyCode_New (C function)
 
    .. versionchanged:: 3.12
 
@@ -61,7 +66,7 @@ bound into a function.
    Similar to :c:func:`PyUnstable_Code_New`, but with an extra "posonlyargcount" for positional-only arguments.
    The same caveats that apply to ``PyUnstable_Code_New`` also apply to this function.
 
-   .. index:: single: PyCode_NewWithPosOnlyArgs
+   .. index:: single: PyCode_NewWithPosOnlyArgs (C function)
 
    .. versionadded:: 3.8 as ``PyCode_NewWithPosOnlyArgs``
 
@@ -220,7 +225,7 @@ may change without deprecation warnings.
    *free* will be called on non-``NULL`` data stored under the new index.
    Use :c:func:`Py_DecRef` when storing :c:type:`PyObject`.
 
-   .. index:: single: _PyEval_RequestCodeExtraIndex
+   .. index:: single: _PyEval_RequestCodeExtraIndex (C function)
 
    .. versionadded:: 3.6 as ``_PyEval_RequestCodeExtraIndex``
 
@@ -238,7 +243,7 @@ may change without deprecation warnings.
    If no data was set under the index, set *extra* to ``NULL`` and return
    0 without setting an exception.
 
-   .. index:: single: _PyCode_GetExtra
+   .. index:: single: _PyCode_GetExtra (C function)
 
    .. versionadded:: 3.6 as ``_PyCode_GetExtra``
 
@@ -253,7 +258,7 @@ may change without deprecation warnings.
    Set the extra data stored under the given index to *extra*.
    Return 0 on success. Set an exception and return -1 on failure.
 
-   .. index:: single: _PyCode_SetExtra
+   .. index:: single: _PyCode_SetExtra (C function)
 
    .. versionadded:: 3.6 as ``_PyCode_SetExtra``
 
diff --git a/Doc/c-api/contextvars.rst b/Doc/c-api/contextvars.rst
index d970f5443b..fe7b8f93f2 100644
--- a/Doc/c-api/contextvars.rst
+++ b/Doc/c-api/contextvars.rst
@@ -6,6 +6,8 @@ Context Variables Objects
 -------------------------
 
 .. _contextvarsobjects_pointertype_change:
+.. versionadded:: 3.7
+
 .. versionchanged:: 3.7.1
 
    .. note::
@@ -24,8 +26,6 @@ Context Variables Objects
       See :issue:`34762` for more details.
 
 
-.. versionadded:: 3.7
-
 This section details the public C API for the :mod:`contextvars` module.
 
 .. c:type:: PyContext
diff --git a/Doc/c-api/exceptions.rst b/Doc/c-api/exceptions.rst
index 39408641c8..dd49d2d219 100644
--- a/Doc/c-api/exceptions.rst
+++ b/Doc/c-api/exceptions.rst
@@ -167,7 +167,7 @@ For convenience, some of these functions will always return a
 
 .. c:function:: PyObject* PyErr_SetFromErrno(PyObject *type)
 
-   .. index:: single: strerror()
+   .. index:: single: strerror (C function)
 
    This is a convenience function to raise an exception when a C library function
    has returned an error and set the C variable :c:data:`errno`.  It constructs a
@@ -383,7 +383,7 @@ an error value).
 .. c:function:: int PyErr_ResourceWarning(PyObject *source, Py_ssize_t stack_level, const char *format, ...)
 
    Function similar to :c:func:`PyErr_WarnFormat`, but *category* is
-   :exc:`ResourceWarning` and it passes *source* to :func:`warnings.WarningMessage`.
+   :exc:`ResourceWarning` and it passes *source* to :class:`!warnings.WarningMessage`.
 
    .. versionadded:: 3.6
 
@@ -622,7 +622,7 @@ Signal Handling
 
    .. index::
       pair: module; signal
-      single: SIGINT
+      single: SIGINT (C macro)
       single: KeyboardInterrupt (built-in exception)
 
    This function interacts with Python's signal handling.
@@ -653,7 +653,7 @@ Signal Handling
 
    .. index::
       pair: module; signal
-      single: SIGINT
+      single: SIGINT (C macro)
       single: KeyboardInterrupt (built-in exception)
 
    Simulate the effect of a :c:macro:`!SIGINT` signal arriving.
@@ -719,7 +719,7 @@ Exception Classes
    This creates a class object derived from :exc:`Exception` (accessible in C as
    :c:data:`PyExc_Exception`).
 
-   The :attr:`__module__` attribute of the new class is set to the first part (up
+   The :attr:`!__module__` attribute of the new class is set to the first part (up
    to the last dot) of the *name* argument, and the class name is set to the last
    part (after the last dot).  The *base* argument can be used to specify alternate
    base classes; it can either be only one class or a tuple of classes. The *dict*
@@ -891,8 +891,8 @@ because the :ref:`call protocol <call>` takes care of recursion handling.
 
    Marks a point where a recursive C-level call is about to be performed.
 
-   If :c:macro:`USE_STACKCHECK` is defined, this function checks if the OS
-   stack overflowed using :c:func:`PyOS_CheckStack`.  In this is the case, it
+   If :c:macro:`!USE_STACKCHECK` is defined, this function checks if the OS
+   stack overflowed using :c:func:`PyOS_CheckStack`.  If this is the case, it
    sets a :exc:`MemoryError` and returns a nonzero value.
 
    The function then checks if the recursion limit is reached.  If this is the
@@ -955,59 +955,59 @@ All standard Python exceptions are available as global variables whose names are
 the variables:
 
 .. index::
-   single: PyExc_BaseException
-   single: PyExc_Exception
-   single: PyExc_ArithmeticError
-   single: PyExc_AssertionError
-   single: PyExc_AttributeError
-   single: PyExc_BlockingIOError
-   single: PyExc_BrokenPipeError
-   single: PyExc_BufferError
-   single: PyExc_ChildProcessError
-   single: PyExc_ConnectionAbortedError
-   single: PyExc_ConnectionError
-   single: PyExc_ConnectionRefusedError
-   single: PyExc_ConnectionResetError
-   single: PyExc_EOFError
-   single: PyExc_FileExistsError
-   single: PyExc_FileNotFoundError
-   single: PyExc_FloatingPointError
-   single: PyExc_GeneratorExit
-   single: PyExc_ImportError
-   single: PyExc_IndentationError
-   single: PyExc_IndexError
-   single: PyExc_InterruptedError
-   single: PyExc_IsADirectoryError
-   single: PyExc_KeyError
-   single: PyExc_KeyboardInterrupt
-   single: PyExc_LookupError
-   single: PyExc_MemoryError
-   single: PyExc_ModuleNotFoundError
-   single: PyExc_NameError
-   single: PyExc_NotADirectoryError
-   single: PyExc_NotImplementedError
-   single: PyExc_OSError
-   single: PyExc_OverflowError
-   single: PyExc_PermissionError
-   single: PyExc_ProcessLookupError
-   single: PyExc_RecursionError
-   single: PyExc_ReferenceError
-   single: PyExc_RuntimeError
-   single: PyExc_StopAsyncIteration
-   single: PyExc_StopIteration
-   single: PyExc_SyntaxError
-   single: PyExc_SystemError
-   single: PyExc_SystemExit
-   single: PyExc_TabError
-   single: PyExc_TimeoutError
-   single: PyExc_TypeError
-   single: PyExc_UnboundLocalError
-   single: PyExc_UnicodeDecodeError
-   single: PyExc_UnicodeEncodeError
-   single: PyExc_UnicodeError
-   single: PyExc_UnicodeTranslateError
-   single: PyExc_ValueError
-   single: PyExc_ZeroDivisionError
+   single: PyExc_BaseException (C var)
+   single: PyExc_Exception (C var)
+   single: PyExc_ArithmeticError (C var)
+   single: PyExc_AssertionError (C var)
+   single: PyExc_AttributeError (C var)
+   single: PyExc_BlockingIOError (C var)
+   single: PyExc_BrokenPipeError (C var)
+   single: PyExc_BufferError (C var)
+   single: PyExc_ChildProcessError (C var)
+   single: PyExc_ConnectionAbortedError (C var)
+   single: PyExc_ConnectionError (C var)
+   single: PyExc_ConnectionRefusedError (C var)
+   single: PyExc_ConnectionResetError (C var)
+   single: PyExc_EOFError (C var)
+   single: PyExc_FileExistsError (C var)
+   single: PyExc_FileNotFoundError (C var)
+   single: PyExc_FloatingPointError (C var)
+   single: PyExc_GeneratorExit (C var)
+   single: PyExc_ImportError (C var)
+   single: PyExc_IndentationError (C var)
+   single: PyExc_IndexError (C var)
+   single: PyExc_InterruptedError (C var)
+   single: PyExc_IsADirectoryError (C var)
+   single: PyExc_KeyError (C var)
+   single: PyExc_KeyboardInterrupt (C var)
+   single: PyExc_LookupError (C var)
+   single: PyExc_MemoryError (C var)
+   single: PyExc_ModuleNotFoundError (C var)
+   single: PyExc_NameError (C var)
+   single: PyExc_NotADirectoryError (C var)
+   single: PyExc_NotImplementedError (C var)
+   single: PyExc_OSError (C var)
+   single: PyExc_OverflowError (C var)
+   single: PyExc_PermissionError (C var)
+   single: PyExc_ProcessLookupError (C var)
+   single: PyExc_RecursionError (C var)
+   single: PyExc_ReferenceError (C var)
+   single: PyExc_RuntimeError (C var)
+   single: PyExc_StopAsyncIteration (C var)
+   single: PyExc_StopIteration (C var)
+   single: PyExc_SyntaxError (C var)
+   single: PyExc_SystemError (C var)
+   single: PyExc_SystemExit (C var)
+   single: PyExc_TabError (C var)
+   single: PyExc_TimeoutError (C var)
+   single: PyExc_TypeError (C var)
+   single: PyExc_UnboundLocalError (C var)
+   single: PyExc_UnicodeDecodeError (C var)
+   single: PyExc_UnicodeEncodeError (C var)
+   single: PyExc_UnicodeError (C var)
+   single: PyExc_UnicodeTranslateError (C var)
+   single: PyExc_ValueError (C var)
+   single: PyExc_ZeroDivisionError (C var)
 
 +-----------------------------------------+---------------------------------+----------+
 | C Name                                  | Python Name                     | Notes    |
@@ -1138,18 +1138,18 @@ the variables:
 These are compatibility aliases to :c:data:`PyExc_OSError`:
 
 .. index::
-   single: PyExc_EnvironmentError
-   single: PyExc_IOError
-   single: PyExc_WindowsError
+   single: PyExc_EnvironmentError (C var)
+   single: PyExc_IOError (C var)
+   single: PyExc_WindowsError (C var)
 
 +-------------------------------------+----------+
 | C Name                              | Notes    |
 +=====================================+==========+
-| :c:data:`PyExc_EnvironmentError`    |          |
+| :c:data:`!PyExc_EnvironmentError`   |          |
 +-------------------------------------+----------+
-| :c:data:`PyExc_IOError`             |          |
+| :c:data:`!PyExc_IOError`            |          |
 +-------------------------------------+----------+
-| :c:data:`PyExc_WindowsError`        | [2]_     |
+| :c:data:`!PyExc_WindowsError`       | [2]_     |
 +-------------------------------------+----------+
 
 .. versionchanged:: 3.3
@@ -1175,17 +1175,17 @@ names are ``PyExc_`` followed by the Python exception name. These have the type
 the variables:
 
 .. index::
-   single: PyExc_Warning
-   single: PyExc_BytesWarning
-   single: PyExc_DeprecationWarning
-   single: PyExc_FutureWarning
-   single: PyExc_ImportWarning
-   single: PyExc_PendingDeprecationWarning
-   single: PyExc_ResourceWarning
-   single: PyExc_RuntimeWarning
-   single: PyExc_SyntaxWarning
-   single: PyExc_UnicodeWarning
-   single: PyExc_UserWarning
+   single: PyExc_Warning (C var)
+   single: PyExc_BytesWarning (C var)
+   single: PyExc_DeprecationWarning (C var)
+   single: PyExc_FutureWarning (C var)
+   single: PyExc_ImportWarning (C var)
+   single: PyExc_PendingDeprecationWarning (C var)
+   single: PyExc_ResourceWarning (C var)
+   single: PyExc_RuntimeWarning (C var)
+   single: PyExc_SyntaxWarning (C var)
+   single: PyExc_UnicodeWarning (C var)
+   single: PyExc_UserWarning (C var)
 
 +------------------------------------------+---------------------------------+----------+
 | C Name                                   | Python Name                     | Notes    |
diff --git a/Doc/c-api/file.rst b/Doc/c-api/file.rst
index 0a03841e46..c4f535920a 100644
--- a/Doc/c-api/file.rst
+++ b/Doc/c-api/file.rst
@@ -95,7 +95,7 @@ the :mod:`io` APIs instead.
 
 .. c:function:: int PyFile_WriteObject(PyObject *obj, PyObject *p, int flags)
 
-   .. index:: single: Py_PRINT_RAW
+   .. index:: single: Py_PRINT_RAW (C macro)
 
    Write object *obj* to file object *p*.  The only supported flag for *flags* is
    :c:macro:`Py_PRINT_RAW`; if given, the :func:`str` of the object is written
diff --git a/Doc/c-api/gcsupport.rst b/Doc/c-api/gcsupport.rst
index 6b2494ee4f..621da3eb06 100644
--- a/Doc/c-api/gcsupport.rst
+++ b/Doc/c-api/gcsupport.rst
@@ -83,10 +83,15 @@ rules:
    .. versionadded:: 3.12
 
 
-.. c:function:: TYPE* PyObject_GC_Resize(TYPE, PyVarObject *op, Py_ssize_t newsize)
+.. c:macro:: PyObject_GC_Resize(TYPE, op, newsize)
 
-   Resize an object allocated by :c:macro:`PyObject_NewVar`.  Returns the
-   resized object or ``NULL`` on failure.  *op* must not be tracked by the collector yet.
+   Resize an object allocated by :c:macro:`PyObject_NewVar`.
+   Returns the resized object of type ``TYPE*`` (refers to any C type)
+   or ``NULL`` on failure.
+
+   *op* must be of type :c:expr:`PyVarObject *`
+   and must not be tracked by the collector yet.
+   *newsize* must be of type :c:type:`Py_ssize_t`.
 
 
 .. c:function:: void PyObject_GC_Track(PyObject *op)
diff --git a/Doc/c-api/hash.rst b/Doc/c-api/hash.rst
new file mode 100644
index 0000000000..3bfaf8b9f5
--- /dev/null
+++ b/Doc/c-api/hash.rst
@@ -0,0 +1,51 @@
+.. highlight:: c
+
+PyHash API
+----------
+
+See also the :c:member:`PyTypeObject.tp_hash` member.
+
+.. c:type:: Py_hash_t
+
+   Hash value type: signed integer.
+
+   .. versionadded:: 3.2
+
+.. c:type:: Py_uhash_t
+
+   Hash value type: unsigned integer.
+
+   .. versionadded:: 3.2
+
+
+.. c:type:: PyHash_FuncDef
+
+   Hash function definition used by :c:func:`PyHash_GetFuncDef`.
+
+   .. c::member:: Py_hash_t (*const hash)(const void *, Py_ssize_t)
+
+      Hash function.
+
+   .. c:member:: const char *name
+
+      Hash function name (UTF-8 encoded string).
+
+   .. c:member:: const int hash_bits
+
+      Internal size of the hash value in bits.
+
+   .. c:member:: const int seed_bits
+
+      Size of seed input in bits.
+
+   .. versionadded:: 3.4
+
+
+.. c:function:: PyHash_FuncDef* PyHash_GetFuncDef(void)
+
+   Get the hash function definition.
+
+   .. seealso::
+      :pep:`456` "Secure and interchangeable hash algorithm".
+
+   .. versionadded:: 3.4
diff --git a/Doc/c-api/import.rst b/Doc/c-api/import.rst
index 5b24ba1dbb..380465b817 100644
--- a/Doc/c-api/import.rst
+++ b/Doc/c-api/import.rst
@@ -292,7 +292,7 @@ Importing Modules
 
       The module name, as an ASCII encoded string.
 
-   .. c: member:: PyObject* (*initfunc)(void)
+   .. c:member:: PyObject* (*initfunc)(void)
 
       Initialization function for a module built into the interpreter.
 
diff --git a/Doc/c-api/init.rst b/Doc/c-api/init.rst
index 5c553d1dfb..db1f41ee12 100644
--- a/Doc/c-api/init.rst
+++ b/Doc/c-api/init.rst
@@ -340,9 +340,9 @@ Initializing and finalizing the interpreter
       pair: module; __main__
       pair: module; sys
       triple: module; search; path
-      single: PySys_SetArgv()
-      single: PySys_SetArgvEx()
-      single: Py_FinalizeEx()
+      single: PySys_SetArgv (C function)
+      single: PySys_SetArgvEx (C function)
+      single: Py_FinalizeEx (C function)
 
    Initialize the Python interpreter.  In an application embedding  Python,
    this should be called before using any other Python/C API functions; see
@@ -849,7 +849,7 @@ operations could cause problems in a multi-threaded program: for example, when
 two threads simultaneously increment the reference count of the same object, the
 reference count could end up being incremented only once instead of twice.
 
-.. index:: single: setswitchinterval() (in module sys)
+.. index:: single: setswitchinterval (in module sys)
 
 Therefore, the rule exists that only the thread that has acquired the
 :term:`GIL` may operate on Python objects or call Python/C API functions.
@@ -859,8 +859,7 @@ released around potentially blocking I/O operations like reading or writing
 a file, so that other Python threads can run in the meantime.
 
 .. index::
-   single: PyThreadState
-   single: PyThreadState
+   single: PyThreadState (C type)
 
 The Python interpreter keeps some thread-specific bookkeeping information
 inside a data structure called :c:type:`PyThreadState`.  There's also one
@@ -886,8 +885,8 @@ This is so common that a pair of macros exists to simplify it::
    Py_END_ALLOW_THREADS
 
 .. index::
-   single: Py_BEGIN_ALLOW_THREADS
-   single: Py_END_ALLOW_THREADS
+   single: Py_BEGIN_ALLOW_THREADS (C macro)
+   single: Py_END_ALLOW_THREADS (C macro)
 
 The :c:macro:`Py_BEGIN_ALLOW_THREADS` macro opens a new block and declares a
 hidden local variable; the :c:macro:`Py_END_ALLOW_THREADS` macro closes the
@@ -902,8 +901,8 @@ The block above expands to the following code::
    PyEval_RestoreThread(_save);
 
 .. index::
-   single: PyEval_RestoreThread()
-   single: PyEval_SaveThread()
+   single: PyEval_RestoreThread (C function)
+   single: PyEval_SaveThread (C function)
 
 Here is how these functions work: the global interpreter lock is used to protect the pointer to the
 current thread state.  When releasing the lock and saving the thread state,
@@ -1646,8 +1645,8 @@ function. You can create and destroy them using the following functions:
    may be stored internally on the :c:type:`PyInterpreterState`.
 
    .. index::
-      single: Py_FinalizeEx()
-      single: Py_Initialize()
+      single: Py_FinalizeEx (C function)
+      single: Py_Initialize (C function)
 
    Extension modules are shared between (sub-)interpreters as follows:
 
@@ -1675,7 +1674,7 @@ function. You can create and destroy them using the following functions:
       As with multi-phase initialization, this means that only C-level static
       and global variables are shared between these modules.
 
-   .. index:: single: close() (in module os)
+   .. index:: single: close (in module os)
 
 
 .. c:function:: PyThreadState* Py_NewInterpreter(void)
@@ -1698,7 +1697,7 @@ function. You can create and destroy them using the following functions:
 
 .. c:function:: void Py_EndInterpreter(PyThreadState *tstate)
 
-   .. index:: single: Py_FinalizeEx()
+   .. index:: single: Py_FinalizeEx (C function)
 
    Destroy the (sub-)interpreter represented by the given thread state.
    The given thread state must be the current thread state.  See the
@@ -1790,8 +1789,6 @@ pointer and a void pointer argument.
 
 .. c:function:: int Py_AddPendingCall(int (*func)(void *), void *arg)
 
-   .. index:: single: Py_AddPendingCall()
-
    Schedule a function to be called from the main interpreter thread.  On
    success, ``0`` is returned and *func* is queued for being called in the
    main thread.  On failure, ``-1`` is returned without setting any exception.
@@ -1825,14 +1822,14 @@ pointer and a void pointer argument.
       function is generally **not** suitable for calling Python code from
       arbitrary C threads.  Instead, use the :ref:`PyGILState API<gilstate>`.
 
+   .. versionadded:: 3.1
+
    .. versionchanged:: 3.9
       If this function is called in a subinterpreter, the function *func* is
       now scheduled to be called from the subinterpreter, rather than being
       called from the main interpreter. Each subinterpreter now has its own
       list of scheduled calls.
 
-   .. versionadded:: 3.1
-
 .. _profiling:
 
 Profiling and Tracing
diff --git a/Doc/c-api/intro.rst b/Doc/c-api/intro.rst
index 26c0168dbb..c8709e1153 100644
--- a/Doc/c-api/intro.rst
+++ b/Doc/c-api/intro.rst
@@ -148,7 +148,7 @@ complete listing.
    worse performances (due to increased code size for example). The compiler is
    usually smarter than the developer for the cost/benefit analysis.
 
-   If Python is :ref:`built in debug mode <debug-build>` (if the ``Py_DEBUG``
+   If Python is :ref:`built in debug mode <debug-build>` (if the :c:macro:`Py_DEBUG`
    macro is defined), the :c:macro:`Py_ALWAYS_INLINE` macro does nothing.
 
    It must be specified before the function return type. Usage::
@@ -325,8 +325,8 @@ objects that reference each other here; for now, the solution
 is "don't do that.")
 
 .. index::
-   single: Py_INCREF()
-   single: Py_DECREF()
+   single: Py_INCREF (C function)
+   single: Py_DECREF (C function)
 
 Reference counts are always manipulated explicitly.  The normal way is
 to use the macro :c:func:`Py_INCREF` to take a new reference to an
@@ -401,8 +401,8 @@ function, that function assumes that it now owns that reference, and you are not
 responsible for it any longer.
 
 .. index::
-   single: PyList_SetItem()
-   single: PyTuple_SetItem()
+   single: PyList_SetItem (C function)
+   single: PyTuple_SetItem (C function)
 
 Few functions steal references; the two notable exceptions are
 :c:func:`PyList_SetItem` and :c:func:`PyTuple_SetItem`, which  steal a reference
@@ -491,8 +491,8 @@ using :c:func:`PySequence_GetItem` (which happens to take exactly the same
 arguments), you do own a reference to the returned object.
 
 .. index::
-   single: PyList_GetItem()
-   single: PySequence_GetItem()
+   single: PyList_GetItem (C function)
+   single: PySequence_GetItem (C function)
 
 Here is an example of how you could write a function that computes the sum of
 the items in a list of integers; once using  :c:func:`PyList_GetItem`, and once
@@ -587,7 +587,7 @@ caller, then to the caller's caller, and so on, until they reach the top-level
 interpreter, where they are reported to the  user accompanied by a stack
 traceback.
 
-.. index:: single: PyErr_Occurred()
+.. index:: single: PyErr_Occurred (C function)
 
 For C programmers, however, error checking always has to be explicit.  All
 functions in the Python/C API can raise exceptions, unless an explicit claim is
@@ -601,8 +601,8 @@ ambiguous return value, and require explicit testing for errors with
 :c:func:`PyErr_Occurred`.  These exceptions are always explicitly documented.
 
 .. index::
-   single: PyErr_SetString()
-   single: PyErr_Clear()
+   single: PyErr_SetString (C function)
+   single: PyErr_Clear (C function)
 
 Exception state is maintained in per-thread storage (this is  equivalent to
 using global storage in an unthreaded application).  A  thread can be in one of
@@ -624,7 +624,7 @@ an exception is being passed on between C functions until it reaches the Python
 bytecode interpreter's  main loop, which takes care of transferring it to
 ``sys.exc_info()`` and friends.
 
-.. index:: single: exc_info() (in module sys)
+.. index:: single: exc_info (in module sys)
 
 Note that starting with Python 1.5, the preferred, thread-safe way to access the
 exception state from Python code is to call the function :func:`sys.exc_info`,
@@ -709,9 +709,9 @@ Here is the corresponding C code, in all its glory::
 .. index:: single: incr_item()
 
 .. index::
-   single: PyErr_ExceptionMatches()
-   single: PyErr_Clear()
-   single: Py_XDECREF()
+   single: PyErr_ExceptionMatches (C function)
+   single: PyErr_Clear (C function)
+   single: Py_XDECREF (C function)
 
 This example represents an endorsed use of the ``goto`` statement  in C!
 It illustrates the use of :c:func:`PyErr_ExceptionMatches` and
@@ -735,7 +735,7 @@ the finalization, of the Python interpreter.  Most functionality of the
 interpreter can only be used after the interpreter has been initialized.
 
 .. index::
-   single: Py_Initialize()
+   single: Py_Initialize (C function)
    pair: module; builtins
    pair: module; __main__
    pair: module; sys
@@ -770,11 +770,11 @@ environment variable :envvar:`PYTHONHOME`, or insert additional directories in
 front of the standard path by setting :envvar:`PYTHONPATH`.
 
 .. index::
-   single: Py_SetProgramName()
-   single: Py_GetPath()
-   single: Py_GetPrefix()
-   single: Py_GetExecPrefix()
-   single: Py_GetProgramFullPath()
+   single: Py_SetProgramName (C function)
+   single: Py_GetPath (C function)
+   single: Py_GetPrefix (C function)
+   single: Py_GetExecPrefix (C function)
+   single: Py_GetProgramFullPath (C function)
 
 The embedding application can steer the search by calling
 ``Py_SetProgramName(file)`` *before* calling  :c:func:`Py_Initialize`.  Note that
@@ -784,7 +784,7 @@ control has to provide its own implementation of :c:func:`Py_GetPath`,
 :c:func:`Py_GetPrefix`, :c:func:`Py_GetExecPrefix`, and
 :c:func:`Py_GetProgramFullPath` (all defined in :file:`Modules/getpath.c`).
 
-.. index:: single: Py_IsInitialized()
+.. index:: single: Py_IsInitialized (C function)
 
 Sometimes, it is desirable to "uninitialize" Python.  For instance,  the
 application may want to start over (make another call to
@@ -812,12 +812,14 @@ available that support tracing of reference counts, debugging the memory
 allocator, or low-level profiling of the main interpreter loop.  Only the most
 frequently used builds will be described in the remainder of this section.
 
-Compiling the interpreter with the :c:macro:`Py_DEBUG` macro defined produces
+.. c:macro:: Py_DEBUG
+
+Compiling the interpreter with the :c:macro:`!Py_DEBUG` macro defined produces
 what is generally meant by :ref:`a debug build of Python <debug-build>`.
-:c:macro:`Py_DEBUG` is enabled in the Unix build by adding
+:c:macro:`!Py_DEBUG` is enabled in the Unix build by adding
 :option:`--with-pydebug` to the :file:`./configure` command.
 It is also implied by the presence of the
-not-Python-specific :c:macro:`_DEBUG` macro.  When :c:macro:`Py_DEBUG` is enabled
+not-Python-specific :c:macro:`!_DEBUG` macro.  When :c:macro:`!Py_DEBUG` is enabled
 in the Unix build, compiler optimization is disabled.
 
 In addition to the reference count debugging described below, extra checks are
@@ -832,4 +834,3 @@ after every statement run by the interpreter.)
 
 Please refer to :file:`Misc/SpecialBuilds.txt` in the Python source distribution
 for more detailed information.
-
diff --git a/Doc/c-api/long.rst b/Doc/c-api/long.rst
index f1354a34f2..76ac80322f 100644
--- a/Doc/c-api/long.rst
+++ b/Doc/c-api/long.rst
@@ -117,7 +117,7 @@ distinguished from a number.  Use :c:func:`PyErr_Occurred` to disambiguate.
 .. c:function:: long PyLong_AsLong(PyObject *obj)
 
    .. index::
-      single: LONG_MAX
+      single: LONG_MAX (C macro)
       single: OverflowError (built-in exception)
 
    Return a C :c:expr:`long` representation of *obj*.  If *obj* is not an
@@ -202,7 +202,7 @@ distinguished from a number.  Use :c:func:`PyErr_Occurred` to disambiguate.
 .. c:function:: Py_ssize_t PyLong_AsSsize_t(PyObject *pylong)
 
    .. index::
-      single: PY_SSIZE_T_MAX
+      single: PY_SSIZE_T_MAX (C macro)
       single: OverflowError (built-in exception)
 
    Return a C :c:type:`Py_ssize_t` representation of *pylong*.  *pylong* must
@@ -217,7 +217,7 @@ distinguished from a number.  Use :c:func:`PyErr_Occurred` to disambiguate.
 .. c:function:: unsigned long PyLong_AsUnsignedLong(PyObject *pylong)
 
    .. index::
-      single: ULONG_MAX
+      single: ULONG_MAX (C macro)
       single: OverflowError (built-in exception)
 
    Return a C :c:expr:`unsigned long` representation of *pylong*.  *pylong*
@@ -233,7 +233,7 @@ distinguished from a number.  Use :c:func:`PyErr_Occurred` to disambiguate.
 .. c:function:: size_t PyLong_AsSize_t(PyObject *pylong)
 
    .. index::
-      single: SIZE_MAX
+      single: SIZE_MAX (C macro)
       single: OverflowError (built-in exception)
 
    Return a C :c:type:`size_t` representation of *pylong*.  *pylong* must be
diff --git a/Doc/c-api/memory.rst b/Doc/c-api/memory.rst
index ec8b828ecb..cac6347d92 100644
--- a/Doc/c-api/memory.rst
+++ b/Doc/c-api/memory.rst
@@ -41,10 +41,10 @@ buffers is performed on demand by the Python memory manager through the Python/C
 API functions listed in this document.
 
 .. index::
-   single: malloc()
-   single: calloc()
-   single: realloc()
-   single: free()
+   single: malloc (C function)
+   single: calloc (C function)
+   single: realloc (C function)
+   single: free (C function)
 
 To avoid memory corruption, extension writers should never try to operate on
 Python objects with the functions exported by the C library: :c:func:`malloc`,
diff --git a/Doc/c-api/refcounting.rst b/Doc/c-api/refcounting.rst
index 4ea0378d02..a484fa4469 100644
--- a/Doc/c-api/refcounting.rst
+++ b/Doc/c-api/refcounting.rst
@@ -23,12 +23,12 @@ of Python objects.
 
    Use the :c:func:`Py_SET_REFCNT()` function to set an object reference count.
 
-   .. versionchanged:: 3.11
-      The parameter type is no longer :c:expr:`const PyObject*`.
-
    .. versionchanged:: 3.10
       :c:func:`Py_REFCNT()` is changed to the inline static function.
 
+   .. versionchanged:: 3.11
+      The parameter type is no longer :c:expr:`const PyObject*`.
+
 
 .. c:function:: void Py_SET_REFCNT(PyObject *o, Py_ssize_t refcnt)
 
diff --git a/Doc/c-api/structures.rst b/Doc/c-api/structures.rst
index 0032da9659..36a0abced0 100644
--- a/Doc/c-api/structures.rst
+++ b/Doc/c-api/structures.rst
@@ -561,9 +561,9 @@ The following flags can be used with :c:member:`PyMemberDef.flags`:
    :c:member:`PyMemberDef.offset` to the offset from the ``PyObject`` struct.
 
 .. index::
-   single: READ_RESTRICTED
-   single: WRITE_RESTRICTED
-   single: RESTRICTED
+   single: READ_RESTRICTED (C macro)
+   single: WRITE_RESTRICTED (C macro)
+   single: RESTRICTED (C macro)
 
 .. versionchanged:: 3.10
 
@@ -574,7 +574,7 @@ The following flags can be used with :c:member:`PyMemberDef.flags`:
    :c:macro:`Py_AUDIT_READ`; :c:macro:`!WRITE_RESTRICTED` does nothing.
 
 .. index::
-   single: READONLY
+   single: READONLY (C macro)
 
 .. versionchanged:: 3.12
 
@@ -637,24 +637,24 @@ Macro name                       C type                        Python type
    Reading a ``NULL`` pointer raises :py:exc:`AttributeError`.
 
 .. index::
-   single: T_BYTE
-   single: T_SHORT
-   single: T_INT
-   single: T_LONG
-   single: T_LONGLONG
-   single: T_UBYTE
-   single: T_USHORT
-   single: T_UINT
-   single: T_ULONG
-   single: T_ULONGULONG
-   single: T_PYSSIZET
-   single: T_FLOAT
-   single: T_DOUBLE
-   single: T_BOOL
-   single: T_CHAR
-   single: T_STRING
-   single: T_STRING_INPLACE
-   single: T_OBJECT_EX
+   single: T_BYTE (C macro)
+   single: T_SHORT (C macro)
+   single: T_INT (C macro)
+   single: T_LONG (C macro)
+   single: T_LONGLONG (C macro)
+   single: T_UBYTE (C macro)
+   single: T_USHORT (C macro)
+   single: T_UINT (C macro)
+   single: T_ULONG (C macro)
+   single: T_ULONGULONG (C macro)
+   single: T_PYSSIZET (C macro)
+   single: T_FLOAT (C macro)
+   single: T_DOUBLE (C macro)
+   single: T_BOOL (C macro)
+   single: T_CHAR (C macro)
+   single: T_STRING (C macro)
+   single: T_STRING_INPLACE (C macro)
+   single: T_OBJECT_EX (C macro)
    single: structmember.h
 
 .. versionadded:: 3.12
@@ -702,12 +702,12 @@ Defining Getters and Setters
 
    .. c:member:: void* closure
 
-      Optional function pointer, providing additional data for getter and setter.
+      Optional user data pointer, providing additional data for getter and setter.
 
 .. c:type:: PyObject *(*getter)(PyObject *, void *)
 
    The ``get`` function takes one :c:expr:`PyObject*` parameter (the
-   instance) and a function pointer (the associated ``closure``):
+   instance) and a user data pointer (the associated ``closure``):
 
    It should return a new reference on success or ``NULL`` with a set exception
    on failure.
@@ -715,7 +715,7 @@ Defining Getters and Setters
 .. c:type:: int (*setter)(PyObject *, PyObject *, void *)
 
    ``set`` functions take two :c:expr:`PyObject*` parameters (the instance and
-   the value to be set) and a function pointer (the associated ``closure``):
+   the value to be set) and a user data pointer (the associated ``closure``):
 
    In case the attribute should be deleted the second parameter is ``NULL``.
    Should return ``0`` on success or ``-1`` with a set exception on failure.
diff --git a/Doc/c-api/sys.rst b/Doc/c-api/sys.rst
index a8a284e6e1..68055317c0 100644
--- a/Doc/c-api/sys.rst
+++ b/Doc/c-api/sys.rst
@@ -5,6 +5,7 @@
 Operating System Utilities
 ==========================
 
+
 .. c:function:: PyObject* PyOS_FSPath(PyObject *path)
 
    Return the file system representation for *path*. If the object is a
@@ -97,27 +98,30 @@ Operating System Utilities
 
 .. c:function:: int PyOS_CheckStack()
 
+   .. index:: single: USE_STACKCHECK (C macro)
+
    Return true when the interpreter runs out of stack space.  This is a reliable
-   check, but is only available when :c:macro:`USE_STACKCHECK` is defined (currently
+   check, but is only available when :c:macro:`!USE_STACKCHECK` is defined (currently
    on certain versions of Windows using the Microsoft Visual C++ compiler).
-   :c:macro:`USE_STACKCHECK` will be defined automatically; you should never
+   :c:macro:`!USE_STACKCHECK` will be defined automatically; you should never
    change the definition in your own code.
 
 
+.. c:type::  void (*PyOS_sighandler_t)(int)
+
+
 .. c:function:: PyOS_sighandler_t PyOS_getsig(int i)
 
    Return the current signal handler for signal *i*.  This is a thin wrapper around
    either :c:func:`!sigaction` or :c:func:`!signal`.  Do not call those functions
-   directly! :c:type:`PyOS_sighandler_t` is a typedef alias for :c:expr:`void
-   (\*)(int)`.
+   directly!
 
 
 .. c:function:: PyOS_sighandler_t PyOS_setsig(int i, PyOS_sighandler_t h)
 
    Set the signal handler for signal *i* to be *h*; return the old signal handler.
    This is a thin wrapper around either :c:func:`!sigaction` or :c:func:`!signal`.  Do
-   not call those functions directly!  :c:type:`PyOS_sighandler_t` is a typedef
-   alias for :c:expr:`void (\*)(int)`.
+   not call those functions directly!
 
 .. c:function:: wchar_t* Py_DecodeLocale(const char* arg, size_t *size)
 
@@ -380,10 +384,8 @@ accessible to C code.  They all work with the current interpreter thread's
    silently abort the operation by raising an error subclassed from
    :class:`Exception` (other errors will not be silenced).
 
-   The hook function is of type :c:expr:`int (*)(const char *event, PyObject
-   *args, void *userData)`, where *args* is guaranteed to be a
-   :c:type:`PyTupleObject`. The hook function is always called with the GIL
-   held by the Python interpreter that raised the event.
+   The hook function is always called with the GIL held by the Python
+   interpreter that raised the event.
 
    See :pep:`578` for a detailed description of auditing.  Functions in the
    runtime and standard library that raise events are listed in the
@@ -392,12 +394,20 @@ accessible to C code.  They all work with the current interpreter thread's
 
    .. audit-event:: sys.addaudithook "" c.PySys_AddAuditHook
 
-      If the interpreter is initialized, this function raises a auditing event
+      If the interpreter is initialized, this function raises an auditing event
       ``sys.addaudithook`` with no arguments. If any existing hooks raise an
       exception derived from :class:`Exception`, the new hook will not be
       added and the exception is cleared. As a result, callers cannot assume
       that their hook has been added unless they control all existing hooks.
 
+   .. c:namespace:: NULL
+   .. c:type:: int (*Py_AuditHookFunction) (const char *event, PyObject *args, void *userData)
+
+      The type of the hook function.
+      *event* is the C string event argument passed to :c:func:`PySys_Audit`.
+      *args* is guaranteed to be a :c:type:`PyTupleObject`.
+      *userData* is the argument passed to PySys_AddAuditHook().
+
    .. versionadded:: 3.8
 
 
@@ -409,7 +419,7 @@ Process Control
 
 .. c:function:: void Py_FatalError(const char *message)
 
-   .. index:: single: abort()
+   .. index:: single: abort (C function)
 
    Print a fatal error message and kill the process.  No cleanup is performed.
    This function should only be invoked when a condition is detected that would
@@ -429,8 +439,8 @@ Process Control
 .. c:function:: void Py_Exit(int status)
 
    .. index::
-      single: Py_FinalizeEx()
-      single: exit()
+      single: Py_FinalizeEx (C function)
+      single: exit (C function)
 
    Exit the current process.  This calls :c:func:`Py_FinalizeEx` and then calls the
    standard C library function ``exit(status)``.  If :c:func:`Py_FinalizeEx`
@@ -443,7 +453,7 @@ Process Control
 .. c:function:: int Py_AtExit(void (*func) ())
 
    .. index::
-      single: Py_FinalizeEx()
+      single: Py_FinalizeEx (C function)
       single: cleanup functions
 
    Register a cleanup function to be called by :c:func:`Py_FinalizeEx`.  The cleanup
diff --git a/Doc/c-api/unicode.rst b/Doc/c-api/unicode.rst
index 302316a55f..54a006c027 100644
--- a/Doc/c-api/unicode.rst
+++ b/Doc/c-api/unicode.rst
@@ -861,7 +861,12 @@ wchar_t Support
    Copy the Unicode object contents into the :c:type:`wchar_t` buffer *wstr*.  At most
    *size* :c:type:`wchar_t` characters are copied (excluding a possibly trailing
    null termination character).  Return the number of :c:type:`wchar_t` characters
-   copied or ``-1`` in case of an error.  Note that the resulting :c:expr:`wchar_t*`
+   copied or ``-1`` in case of an error.
+
+   When *wstr* is ``NULL``, instead return the *size* that would be required
+   to store all of *unicode* including a terminating null.
+
+   Note that the resulting :c:expr:`wchar_t*`
    string may or may not be null-terminated.  It is the responsibility of the caller
    to make sure that the :c:expr:`wchar_t*` string is null-terminated in case this is
    required by the application. Also, note that the :c:expr:`wchar_t*` string
diff --git a/Doc/c-api/utilities.rst b/Doc/c-api/utilities.rst
index ccbf14e185..48ae54aceb 100644
--- a/Doc/c-api/utilities.rst
+++ b/Doc/c-api/utilities.rst
@@ -17,6 +17,7 @@ and parsing function arguments and constructing Python values from C values.
    marshal.rst
    arg.rst
    conversion.rst
+   hash.rst
    reflection.rst
    codec.rst
    perfmaps.rst
diff --git a/Doc/c-api/veryhigh.rst b/Doc/c-api/veryhigh.rst
index 324518c035..67167444d0 100644
--- a/Doc/c-api/veryhigh.rst
+++ b/Doc/c-api/veryhigh.rst
@@ -322,7 +322,7 @@ the same library that the Python runtime is using.
 
 .. c:var:: int Py_eval_input
 
-   .. index:: single: Py_CompileString()
+   .. index:: single: Py_CompileString (C function)
 
    The start symbol from the Python grammar for isolated expressions; for use with
    :c:func:`Py_CompileString`.
@@ -330,7 +330,7 @@ the same library that the Python runtime is using.
 
 .. c:var:: int Py_file_input
 
-   .. index:: single: Py_CompileString()
+   .. index:: single: Py_CompileString (C function)
 
    The start symbol from the Python grammar for sequences of statements as read
    from a file or other source; for use with :c:func:`Py_CompileString`.  This is
@@ -339,7 +339,7 @@ the same library that the Python runtime is using.
 
 .. c:var:: int Py_single_input
 
-   .. index:: single: Py_CompileString()
+   .. index:: single: Py_CompileString (C function)
 
    The start symbol from the Python grammar for a single statement; for use with
    :c:func:`Py_CompileString`. This is the symbol used for the interactive
diff --git a/Doc/conf.py b/Doc/conf.py
index 5cc8f7e599..fdd4ac75df 100644
--- a/Doc/conf.py
+++ b/Doc/conf.py
@@ -58,6 +58,10 @@
 import patchlevel
 version, release = patchlevel.get_version_info()
 
+rst_epilog = f"""
+.. |python_version_literal| replace:: ``Python {version}``
+"""
+
 # There are two options for replacing |today|: either, you set today to some
 # non-false value, then it is used:
 today = ''
@@ -89,10 +93,13 @@
     ('c:func', 'dlopen'),
     ('c:func', 'exec'),
     ('c:func', 'fcntl'),
+    ('c:func', 'flock'),
     ('c:func', 'fork'),
     ('c:func', 'free'),
     ('c:func', 'gettimeofday'),
     ('c:func', 'gmtime'),
+    ('c:func', 'grantpt'),
+    ('c:func', 'ioctl'),
     ('c:func', 'localeconv'),
     ('c:func', 'localtime'),
     ('c:func', 'main'),
@@ -255,6 +262,7 @@
     ('py:attr', '__annotations__'),
     ('py:meth', '__missing__'),
     ('py:attr', '__wrapped__'),
+    ('py:attr', 'decimal.Context.clamp'),
     ('py:meth', 'index'),  # list.index, tuple.index, etc.
 ]
 
diff --git a/Doc/extending/extending.rst b/Doc/extending/extending.rst
index 68f8e0c667..394948a4d2 100644
--- a/Doc/extending/extending.rst
+++ b/Doc/extending/extending.rst
@@ -536,7 +536,7 @@ reference count of an object and are safe in the presence of ``NULL`` pointers
 (but note that *temp* will not be  ``NULL`` in this context).  More info on them
 in section :ref:`refcounts`.
 
-.. index:: single: PyObject_CallObject()
+.. index:: single: PyObject_CallObject (C function)
 
 Later, when it is time to call the function, you call the C function
 :c:func:`PyObject_CallObject`.  This function has two arguments, both pointers to
@@ -627,7 +627,7 @@ the above example, we use :c:func:`Py_BuildValue` to construct the dictionary. :
 Extracting Parameters in Extension Functions
 ============================================
 
-.. index:: single: PyArg_ParseTuple()
+.. index:: single: PyArg_ParseTuple (C function)
 
 The :c:func:`PyArg_ParseTuple` function is declared as follows::
 
@@ -719,7 +719,7 @@ Some example calls::
 Keyword Parameters for Extension Functions
 ==========================================
 
-.. index:: single: PyArg_ParseTupleAndKeywords()
+.. index:: single: PyArg_ParseTupleAndKeywords (C function)
 
 The :c:func:`PyArg_ParseTupleAndKeywords` function is declared as follows::
 
diff --git a/Doc/extending/newtypes.rst b/Doc/extending/newtypes.rst
index d3a7262cd4..e69a5808b2 100644
--- a/Doc/extending/newtypes.rst
+++ b/Doc/extending/newtypes.rst
@@ -89,8 +89,8 @@ If your type supports garbage collection, the destructor should call
    }
 
 .. index::
-   single: PyErr_Fetch()
-   single: PyErr_Restore()
+   single: PyErr_Fetch (C function)
+   single: PyErr_Restore (C function)
 
 One important requirement of the deallocator function is that it leaves any
 pending exceptions alone.  This is important since deallocators are frequently
diff --git a/Doc/faq/design.rst b/Doc/faq/design.rst
index 300e1b6cc4..c8beb64e39 100644
--- a/Doc/faq/design.rst
+++ b/Doc/faq/design.rst
@@ -259,9 +259,11 @@ is evaluated in all cases.
 Why isn't there a switch or case statement in Python?
 -----------------------------------------------------
 
-You can do this easily enough with a sequence of ``if... elif... elif... else``.
-For literal values, or constants within a namespace, you can also use a
-``match ... case`` statement.
+In general, structured switch statements execute one block of code
+when an expression has a particular value or set of values.
+Since Python 3.10 one can easily match literal values, or constants
+within a namespace, with a ``match ... case`` statement.
+An older alternative is a sequence of ``if... elif... elif... else``.
 
 For cases where you need to choose from a very large number of possibilities,
 you can create a dictionary mapping case values to functions to call.  For
@@ -290,6 +292,9 @@ It's suggested that you use a prefix for the method names, such as ``visit_`` in
 this example.  Without such a prefix, if values are coming from an untrusted
 source, an attacker would be able to call any method on your object.
 
+Imitating switch with fallthrough, as with C's switch-case-default,
+is possible, much harder, and less needed.
+
 
 Can't you emulate threads in the interpreter instead of relying on an OS-specific thread implementation?
 --------------------------------------------------------------------------------------------------------
diff --git a/Doc/faq/extending.rst b/Doc/faq/extending.rst
index 2a8b976925..1cff2c4091 100644
--- a/Doc/faq/extending.rst
+++ b/Doc/faq/extending.rst
@@ -50,7 +50,7 @@ to learn Python's C API.
 If you need to interface to some C or C++ library for which no Python extension
 currently exists, you can try wrapping the library's data types and functions
 with a tool such as `SWIG <https://www.swig.org>`_.  `SIP
-<https://riverbankcomputing.com/software/sip/intro>`__, `CXX
+<https://github.com/Python-SIP/sip>`__, `CXX
 <https://cxx.sourceforge.net/>`_ `Boost
 <https://www.boost.org/libs/python/doc/index.html>`_, or `Weave
 <https://github.com/scipy/weave>`_ are also
diff --git a/Doc/faq/general.rst b/Doc/faq/general.rst
index 8727332594..ec7c289759 100644
--- a/Doc/faq/general.rst
+++ b/Doc/faq/general.rst
@@ -133,8 +133,6 @@ Python versions are numbered "A.B.C" or "A.B":
   changes.
 * *C* is the micro version number -- it is incremented for each bugfix release.
 
-See :pep:`6` for more information about bugfix releases.
-
 Not all releases are bugfix releases.  In the run-up to a new feature release, a
 series of development releases are made, denoted as alpha, beta, or release
 candidate.  Alphas are early releases in which interfaces aren't yet finalized;
@@ -157,7 +155,11 @@ unreleased versions, built directly from the CPython development repository.  In
 practice, after a final minor release is made, the version is incremented to the
 next minor version, which becomes the "a0" version, e.g. "2.4a0".
 
-See also the documentation for :data:`sys.version`, :data:`sys.hexversion`, and
+See the `Developer's Guide
+<https://devguide.python.org/developer-workflow/development-cycle/>`__
+for more information about the development cycle, and
+:pep:`387` to learn more about Python's backward compatibility policy.  See also
+the documentation for :data:`sys.version`, :data:`sys.hexversion`, and
 :data:`sys.version_info`.
 
 
diff --git a/Doc/glossary.rst b/Doc/glossary.rst
index b475cb80a8..36ab707671 100644
--- a/Doc/glossary.rst
+++ b/Doc/glossary.rst
@@ -726,18 +726,6 @@ Glossary
       thread removes *key* from *mapping* after the test, but before the lookup.
       This issue can be solved with locks or by using the EAFP approach.
 
-   locale encoding
-      On Unix, it is the encoding of the LC_CTYPE locale. It can be set with
-      :func:`locale.setlocale(locale.LC_CTYPE, new_locale) <locale.setlocale>`.
-
-      On Windows, it is the ANSI code page (ex: ``"cp1252"``).
-
-      On Android and VxWorks, Python uses ``"utf-8"`` as the locale encoding.
-
-      ``locale.getencoding()`` can be used to get the locale encoding.
-
-      See also the :term:`filesystem encoding and error handler`.
-
    list
       A built-in Python :term:`sequence`.  Despite its name it is more akin
       to an array in other languages than to a linked list since access to
@@ -757,6 +745,18 @@ Glossary
       :term:`finder`. See :pep:`302` for details and
       :class:`importlib.abc.Loader` for an :term:`abstract base class`.
 
+   locale encoding
+      On Unix, it is the encoding of the LC_CTYPE locale. It can be set with
+      :func:`locale.setlocale(locale.LC_CTYPE, new_locale) <locale.setlocale>`.
+
+      On Windows, it is the ANSI code page (ex: ``"cp1252"``).
+
+      On Android and VxWorks, Python uses ``"utf-8"`` as the locale encoding.
+
+      :func:`locale.getencoding` can be used to get the locale encoding.
+
+      See also the :term:`filesystem encoding and error handler`.
+
    magic method
       .. index:: pair: magic; method
 
@@ -840,10 +840,11 @@ Glossary
       Some named tuples are built-in types (such as the above examples).
       Alternatively, a named tuple can be created from a regular class
       definition that inherits from :class:`tuple` and that defines named
-      fields.  Such a class can be written by hand or it can be created with
-      the factory function :func:`collections.namedtuple`.  The latter
-      technique also adds some extra methods that may not be found in
-      hand-written or built-in named tuples.
+      fields.  Such a class can be written by hand, or it can be created by
+      inheriting :class:`typing.NamedTuple`, or with the factory function
+      :func:`collections.namedtuple`.  The latter techniques also add some
+      extra methods that may not be found in hand-written or built-in named
+      tuples.
 
    namespace
       The place where a variable is stored.  Namespaces are implemented as
diff --git a/Doc/howto/descriptor.rst b/Doc/howto/descriptor.rst
index 1346b0d135..330402d183 100644
--- a/Doc/howto/descriptor.rst
+++ b/Doc/howto/descriptor.rst
@@ -1,8 +1,8 @@
 .. _descriptorhowto:
 
-======================
-Descriptor HowTo Guide
-======================
+================
+Descriptor Guide
+================
 
 :Author: Raymond Hettinger
 :Contact: <python at rcn dot com>
diff --git a/Doc/howto/gdb_helpers.rst b/Doc/howto/gdb_helpers.rst
new file mode 100644
index 0000000000..53bbf7ddaa
--- /dev/null
+++ b/Doc/howto/gdb_helpers.rst
@@ -0,0 +1,449 @@
+.. _gdb:
+
+=========================================================
+Debugging C API extensions and CPython Internals with GDB
+=========================================================
+
+.. highlight:: none
+
+This document explains how the Python GDB extension, ``python-gdb.py``, can
+be used with the GDB debugger to debug CPython extensions and the
+CPython interpreter itself.
+
+When debugging low-level problems such as crashes or deadlocks, a low-level
+debugger, such as GDB, is useful to diagnose and correct the issue.
+By default, GDB (or any of its front-ends) doesn't support high-level
+information specific to the CPython interpreter.
+
+The ``python-gdb.py`` extension adds CPython interpreter information to GDB.
+The extension helps introspect the stack of currently executing Python functions.
+Given a Python object represented by a :c:expr:`PyObject *` pointer,
+the extension surfaces the type and value of the object.
+
+Developers who are working on CPython extensions or tinkering with parts
+of CPython that are written in C can use this document to learn how to use the
+``python-gdb.py`` extension with GDB.
+
+.. note::
+
+   This document assumes that you are familiar with the basics of GDB and the
+   CPython C API. It consolidates guidance from the
+   `devguide <https://devguide.python.org>`_  and the
+   `Python wiki <https://wiki.python.org/moin/DebuggingWithGdb>`_.
+
+
+Prerequisites
+=============
+
+You need to have:
+
+- GDB 7 or later. (For earlier versions of GDB, see ``Misc/gdbinit`` in the
+  sources of Python 3.11 or earlier.)
+- GDB-compatible debugging information for Python and any extension you are
+  debugging.
+- The ``python-gdb.py`` extension.
+
+The extension is built with Python, but might be distributed separately or
+not at all. Below, we include tips for a few common systems as examples.
+Note that even if the instructions match your system, they might be outdated.
+
+
+Setup with Python built from source
+-----------------------------------
+
+When you build CPython from source, debugging information should be available,
+and the build should add a ``python-gdb.py`` file to the root directory of
+your repository.
+
+To activate support, you must add the directory containing ``python-gdb.py``
+to GDB's "auto-load-safe-path".
+If you haven't done this, recent versions of GDB will print out a warning
+with instructions on how to do this.
+
+.. note::
+
+   If you do not see instructions for your version of GDB, put this in your
+   configuration file (``~/.gdbinit`` or ``~/.config/gdb/gdbinit``)::
+
+      add-auto-load-safe-path /path/to/cpython
+
+   You can also add multiple paths, separated by ``:``.
+
+
+Setup for Python from a Linux distro
+------------------------------------
+
+Most Linux systems provide debug information for the system Python
+in a package called ``python-debuginfo``, ``python-dbg`` or similar.
+For example:
+
+- Fedora:
+
+   .. code-block:: shell
+
+      sudo dnf install gdb
+      sudo dnf debuginfo-install python3
+
+- Ubuntu:
+
+   .. code-block:: shell
+
+      sudo apt install gdb python3-dbg
+
+On several recent Linux systems, GDB can download debugging symbols
+automatically using *debuginfod*.
+However, this will not install the ``python-gdb.py`` extension;
+you generally do need to install the debug info package separately.
+
+
+Using the Debug build and Development mode
+==========================================
+
+For easier debugging, you might want to:
+
+- Use a :ref:`debug build <debug-build>` of Python. (When building from source,
+  use ``configure --with-pydebug``. On Linux distros, install and run a package
+  like ``python-debug`` or ``python-dbg``, if available.)
+- Use the runtime :ref:`development mode <devmode>` (``-X dev``).
+
+Both enable extra assertions and disable some optimizations.
+Sometimes this hides the bug you are trying to find, but in most cases they
+make the process easier.
+
+
+Using the ``python-gdb`` extension
+==================================
+
+When the extension is loaded, it provides two main features:
+pretty printers for Python values, and additional commands.
+
+Pretty-printers
+---------------
+
+This is what a GDB backtrace looks like (truncated) when this extension is
+enabled::
+
+   #0  0x000000000041a6b1 in PyObject_Malloc (nbytes=Cannot access memory at address 0x7fffff7fefe8
+   ) at Objects/obmalloc.c:748
+   #1  0x000000000041b7c0 in _PyObject_DebugMallocApi (id=111 'o', nbytes=24) at Objects/obmalloc.c:1445
+   #2  0x000000000041b717 in _PyObject_DebugMalloc (nbytes=24) at Objects/obmalloc.c:1412
+   #3  0x000000000044060a in _PyUnicode_New (length=11) at Objects/unicodeobject.c:346
+   #4  0x00000000004466aa in PyUnicodeUCS2_DecodeUTF8Stateful (s=0x5c2b8d "__lltrace__", size=11, errors=0x0, consumed=
+       0x0) at Objects/unicodeobject.c:2531
+   #5  0x0000000000446647 in PyUnicodeUCS2_DecodeUTF8 (s=0x5c2b8d "__lltrace__", size=11, errors=0x0)
+       at Objects/unicodeobject.c:2495
+   #6  0x0000000000440d1b in PyUnicodeUCS2_FromStringAndSize (u=0x5c2b8d "__lltrace__", size=11)
+       at Objects/unicodeobject.c:551
+   #7  0x0000000000440d94 in PyUnicodeUCS2_FromString (u=0x5c2b8d "__lltrace__") at Objects/unicodeobject.c:569
+   #8  0x0000000000584abd in PyDict_GetItemString (v=
+       {'Yuck': <type at remote 0xad4730>, '__builtins__': <module at remote 0x7ffff7fd5ee8>, '__file__': 'Lib/test/crashers/nasty_eq_vs_dict.py', '__package__': None, 'y': <Yuck(i=0) at remote 0xaacd80>, 'dict': {0: 0, 1: 1, 2: 2, 3: 3}, '__cached__': None, '__name__': '__main__', 'z': <Yuck(i=0) at remote 0xaace60>, '__doc__': None}, key=
+       0x5c2b8d "__lltrace__") at Objects/dictobject.c:2171
+
+Notice how the dictionary argument to ``PyDict_GetItemString`` is displayed
+as its ``repr()``, rather than an opaque ``PyObject *`` pointer.
+
+The extension works by supplying a custom printing routine for values of type
+``PyObject *``.  If you need to access lower-level details of an object, then
+cast the value to a pointer of the appropriate type.  For example::
+
+    (gdb) p globals
+    $1 = {'__builtins__': <module at remote 0x7ffff7fb1868>, '__name__':
+    '__main__', 'ctypes': <module at remote 0x7ffff7f14360>, '__doc__': None,
+    '__package__': None}
+
+    (gdb) p *(PyDictObject*)globals
+    $2 = {ob_refcnt = 3, ob_type = 0x3dbdf85820, ma_fill = 5, ma_used = 5,
+    ma_mask = 7, ma_table = 0x63d0f8, ma_lookup = 0x3dbdc7ea70
+    <lookdict_string>, ma_smalltable = {{me_hash = 7065186196740147912,
+    me_key = '__builtins__', me_value = <module at remote 0x7ffff7fb1868>},
+    {me_hash = -368181376027291943, me_key = '__name__',
+    me_value ='__main__'}, {me_hash = 0, me_key = 0x0, me_value = 0x0},
+    {me_hash = 0, me_key = 0x0, me_value = 0x0},
+    {me_hash = -9177857982131165996, me_key = 'ctypes',
+    me_value = <module at remote 0x7ffff7f14360>},
+    {me_hash = -8518757509529533123, me_key = '__doc__', me_value = None},
+    {me_hash = 0, me_key = 0x0, me_value = 0x0}, {
+      me_hash = 6614918939584953775, me_key = '__package__', me_value = None}}}
+
+Note that the pretty-printers do not actually call ``repr()``.
+For basic types, they try to match its result closely.
+
+An area that can be confusing is that the custom printer for some types look a
+lot like GDB's built-in printer for standard types.  For example, the
+pretty-printer for a Python ``int`` (:c:expr:`PyLongObject *`)
+gives a representation that is not distinguishable from one of a
+regular machine-level integer::
+
+    (gdb) p some_machine_integer
+    $3 = 42
+
+    (gdb) p some_python_integer
+    $4 = 42
+
+The internal structure can be revealed with a cast to :c:expr:`PyLongObject *`:
+
+    (gdb) p *(PyLongObject*)some_python_integer
+    $5 = {ob_base = {ob_base = {ob_refcnt = 8, ob_type = 0x3dad39f5e0}, ob_size = 1},
+    ob_digit = {42}}
+
+A similar confusion can arise with the ``str`` type, where the output looks a
+lot like gdb's built-in printer for ``char *``::
+
+    (gdb) p ptr_to_python_str
+    $6 = '__builtins__'
+
+The pretty-printer for ``str`` instances defaults to using single-quotes (as
+does Python's ``repr`` for strings) whereas the standard printer for ``char *``
+values uses double-quotes and contains a hexadecimal address::
+
+    (gdb) p ptr_to_char_star
+    $7 = 0x6d72c0 "hello world"
+
+Again, the implementation details can be revealed with a cast to
+:c:expr:`PyUnicodeObject *`::
+
+    (gdb) p *(PyUnicodeObject*)$6
+    $8 = {ob_base = {ob_refcnt = 33, ob_type = 0x3dad3a95a0}, length = 12,
+    str = 0x7ffff2128500, hash = 7065186196740147912, state = 1, defenc = 0x0}
+
+``py-list``
+-----------
+
+   The extension adds a ``py-list`` command, which
+   lists the Python source code (if any) for the current frame in the selected
+   thread.  The current line is marked with a ">"::
+
+        (gdb) py-list
+         901        if options.profile:
+         902            options.profile = False
+         903            profile_me()
+         904            return
+         905
+        >906        u = UI()
+         907        if not u.quit:
+         908            try:
+         909                gtk.main()
+         910            except KeyboardInterrupt:
+         911                # properly quit on a keyboard interrupt...
+
+   Use ``py-list START`` to list at a different line number within the Python
+   source, and ``py-list START,END`` to list a specific range of lines within
+   the Python source.
+
+``py-up`` and ``py-down``
+-------------------------
+
+   The ``py-up`` and ``py-down`` commands are analogous to GDB's regular ``up``
+   and ``down`` commands, but try to move at the level of CPython frames, rather
+   than C frames.
+
+   GDB is not always able to read the relevant frame information, depending on
+   the optimization level with which CPython was compiled. Internally, the
+   commands look for C frames that are executing the default frame evaluation
+   function (that is, the core bytecode interpreter loop within CPython) and
+   look up the value of the related ``PyFrameObject *``.
+
+   They emit the frame number (at the C level) within the thread.
+
+   For example::
+
+        (gdb) py-up
+        #37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/
+        gnome_sudoku/main.py, line 906, in start_game ()
+            u = UI()
+        (gdb) py-up
+        #40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/
+        gnome_sudoku/gnome_sudoku.py, line 22, in start_game(main=<module at remote 0xb771b7f4>)
+            main.start_game()
+        (gdb) py-up
+        Unable to find an older python frame
+
+   so we're at the top of the Python stack.
+
+   The frame numbers correspond to those displayed by GDB's standard
+   ``backtrace`` command.
+   The command skips C frames which are not executing Python code.
+
+   Going back down::
+
+        (gdb) py-down
+        #37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main.py, line 906, in start_game ()
+            u = UI()
+        (gdb) py-down
+        #34 (unable to read python frame information)
+        (gdb) py-down
+        #23 (unable to read python frame information)
+        (gdb) py-down
+        #19 (unable to read python frame information)
+        (gdb) py-down
+        #14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game_selector.py, line 201, in run_swallowed_dialog (self=<NewOrSavedGameSelector(new_game_model=<gtk.ListStore at remote 0x98fab44>, puzzle=None, saved_games=[{'gsd.auto_fills': 0, 'tracking': {}, 'trackers': {}, 'notes': [], 'saved_at': 1270084485, 'game': '7 8 0 0 0 0 0 5 6 0 0 9 0 8 0 1 0 0 0 4 6 0 0 0 0 7 0 6 5 0 0 0 4 7 9 2 0 0 0 9 0 1 0 0 0 3 9 7 6 0 0 0 1 8 0 6 0 0 0 0 2 8 0 0 0 5 0 4 0 6 0 0 2 1 0 0 0 0 0 4 5\n7 8 0 0 0 0 0 5 6 0 0 9 0 8 0 1 0 0 0 4 6 0 0 0 0 7 0 6 5 1 8 3 4 7 9 2 0 0 0 9 0 1 0 0 0 3 9 7 6 0 0 0 1 8 0 6 0 0 0 0 2 8 0 0 0 5 0 4 0 6 0 0 2 1 0 0 0 0 0 4 5', 'gsd.impossible_hints': 0, 'timer.__absolute_start_time__': <float at remote 0x984b474>, 'gsd.hints': 0, 'timer.active_time': <float at remote 0x984b494>, 'timer.total_time': <float at remote 0x984b464>}], dialog=<gtk.Dialog at remote 0x98faaa4>, saved_game_model=<gtk.ListStore at remote 0x98fad24>, sudoku_maker=<SudokuMaker(terminated=False, played=[], batch_siz...(truncated)
+                    swallower.run_dialog(self.dialog)
+        (gdb) py-down
+        #11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dialog_swallower.py, line 48, in run_dialog (self=<SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>, main_page=0) at remote 0x98fa6e4>, d=<gtk.Dialog at remote 0x98faaa4>)
+                    gtk.main()
+        (gdb) py-down
+        #8 (unable to read python frame information)
+        (gdb) py-down
+        Unable to find a newer python frame
+
+   and we're at the bottom of the Python stack.
+
+   Note that in Python 3.12 and newer, the same C stack frame can be used for
+   multiple Python stack frames. This means that ``py-up`` and ``py-down``
+   may move multiple Python frames at once. For example::
+
+      (gdb) py-up
+      #6 Frame 0x7ffff7fb62b0, for file /tmp/rec.py, line 5, in recursive_function (n=0)
+         time.sleep(5)
+      #6 Frame 0x7ffff7fb6240, for file /tmp/rec.py, line 7, in recursive_function (n=1)
+         recursive_function(n-1)
+      #6 Frame 0x7ffff7fb61d0, for file /tmp/rec.py, line 7, in recursive_function (n=2)
+         recursive_function(n-1)
+      #6 Frame 0x7ffff7fb6160, for file /tmp/rec.py, line 7, in recursive_function (n=3)
+         recursive_function(n-1)
+      #6 Frame 0x7ffff7fb60f0, for file /tmp/rec.py, line 7, in recursive_function (n=4)
+         recursive_function(n-1)
+      #6 Frame 0x7ffff7fb6080, for file /tmp/rec.py, line 7, in recursive_function (n=5)
+         recursive_function(n-1)
+      #6 Frame 0x7ffff7fb6020, for file /tmp/rec.py, line 9, in <module> ()
+         recursive_function(5)
+      (gdb) py-up
+      Unable to find an older python frame
+
+
+``py-bt``
+---------
+
+   The ``py-bt`` command attempts to display a Python-level backtrace of the
+   current thread.
+
+   For example::
+
+        (gdb) py-bt
+        #8 (unable to read python frame information)
+        #11 Frame 0x9aead74, for file /usr/lib/python2.6/site-packages/gnome_sudoku/dialog_swallower.py, line 48, in run_dialog (self=<SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>, main_page=0) at remote 0x98fa6e4>, d=<gtk.Dialog at remote 0x98faaa4>)
+                    gtk.main()
+        #14 Frame 0x99262ac, for file /usr/lib/python2.6/site-packages/gnome_sudoku/game_selector.py, line 201, in run_swallowed_dialog (self=<NewOrSavedGameSelector(new_game_model=<gtk.ListStore at remote 0x98fab44>, puzzle=None, saved_games=[{'gsd.auto_fills': 0, 'tracking': {}, 'trackers': {}, 'notes': [], 'saved_at': 1270084485, 'game': '7 8 0 0 0 0 0 5 6 0 0 9 0 8 0 1 0 0 0 4 6 0 0 0 0 7 0 6 5 0 0 0 4 7 9 2 0 0 0 9 0 1 0 0 0 3 9 7 6 0 0 0 1 8 0 6 0 0 0 0 2 8 0 0 0 5 0 4 0 6 0 0 2 1 0 0 0 0 0 4 5\n7 8 0 0 0 0 0 5 6 0 0 9 0 8 0 1 0 0 0 4 6 0 0 0 0 7 0 6 5 1 8 3 4 7 9 2 0 0 0 9 0 1 0 0 0 3 9 7 6 0 0 0 1 8 0 6 0 0 0 0 2 8 0 0 0 5 0 4 0 6 0 0 2 1 0 0 0 0 0 4 5', 'gsd.impossible_hints': 0, 'timer.__absolute_start_time__': <float at remote 0x984b474>, 'gsd.hints': 0, 'timer.active_time': <float at remote 0x984b494>, 'timer.total_time': <float at remote 0x984b464>}], dialog=<gtk.Dialog at remote 0x98faaa4>, saved_game_model=<gtk.ListStore at remote 0x98fad24>, sudoku_maker=<SudokuMaker(terminated=False, played=[], batch_siz...(truncated)
+                    swallower.run_dialog(self.dialog)
+        #19 (unable to read python frame information)
+        #23 (unable to read python frame information)
+        #34 (unable to read python frame information)
+        #37 Frame 0x9420b04, for file /usr/lib/python2.6/site-packages/gnome_sudoku/main.py, line 906, in start_game ()
+            u = UI()
+        #40 Frame 0x948e82c, for file /usr/lib/python2.6/site-packages/gnome_sudoku/gnome_sudoku.py, line 22, in start_game (main=<module at remote 0xb771b7f4>)
+            main.start_game()
+
+   The frame numbers correspond to those displayed by GDB's standard
+   ``backtrace`` command.
+
+``py-print``
+------------
+
+   The ``py-print`` command looks up a Python name and tries to print it.
+   It looks in locals within the current thread, then globals, then finally
+   builtins::
+
+        (gdb) py-print self
+        local 'self' = <SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>,
+        main_page=0) at remote 0x98fa6e4>
+        (gdb) py-print __name__
+        global '__name__' = 'gnome_sudoku.dialog_swallower'
+        (gdb) py-print len
+        builtin 'len' = <built-in function len>
+        (gdb) py-print scarlet_pimpernel
+        'scarlet_pimpernel' not found
+
+   If the current C frame corresponds to multiple Python frames, ``py-print``
+   only considers the first one.
+
+``py-locals``
+-------------
+
+   The ``py-locals`` command looks up all Python locals within the current
+   Python frame in the selected thread, and prints their representations::
+
+        (gdb) py-locals
+        self = <SwappableArea(running=<gtk.Dialog at remote 0x98faaa4>,
+        main_page=0) at remote 0x98fa6e4>
+        d = <gtk.Dialog at remote 0x98faaa4>
+
+   If the current C frame corresponds to multiple Python frames, locals from
+   all of them will be shown::
+
+      (gdb) py-locals
+      Locals for recursive_function
+      n = 0
+      Locals for recursive_function
+      n = 1
+      Locals for recursive_function
+      n = 2
+      Locals for recursive_function
+      n = 3
+      Locals for recursive_function
+      n = 4
+      Locals for recursive_function
+      n = 5
+      Locals for <module>
+
+
+Use with GDB commands
+=====================
+
+The extension commands complement GDB's built-in commands.
+For example, you can use a frame numbers shown by ``py-bt`` with the ``frame``
+command to go a specific frame within the selected thread, like this::
+
+        (gdb) py-bt
+        (output snipped)
+        #68 Frame 0xaa4560, for file Lib/test/regrtest.py, line 1548, in <module> ()
+                main()
+        (gdb) frame 68
+        #68 0x00000000004cd1e6 in PyEval_EvalFrameEx (f=Frame 0xaa4560, for file Lib/test/regrtest.py, line 1548, in <module> (), throwflag=0) at Python/ceval.c:2665
+        2665                            x = call_function(&sp, oparg);
+        (gdb) py-list
+        1543        # Run the tests in a context manager that temporary changes the CWD to a
+        1544        # temporary and writable directory. If it's not possible to create or
+        1545        # change the CWD, the original CWD will be used. The original CWD is
+        1546        # available from test_support.SAVEDCWD.
+        1547        with test_support.temp_cwd(TESTCWD, quiet=True):
+        >1548            main()
+
+The ``info threads`` command will give you a list of the threads within the
+process, and you can use the ``thread`` command to select a different one::
+
+        (gdb) info threads
+          105 Thread 0x7fffefa18710 (LWP 10260)  sem_wait () at ../nptl/sysdeps/unix/sysv/linux/x86_64/sem_wait.S:86
+          104 Thread 0x7fffdf5fe710 (LWP 10259)  sem_wait () at ../nptl/sysdeps/unix/sysv/linux/x86_64/sem_wait.S:86
+        * 1 Thread 0x7ffff7fe2700 (LWP 10145)  0x00000038e46d73e3 in select () at ../sysdeps/unix/syscall-template.S:82
+
+You can use ``thread apply all COMMAND`` or (``t a a COMMAND`` for short) to run
+a command on all threads.  With ``py-bt``, this lets you see what every
+thread is doing at the Python level::
+
+        (gdb) t a a py-bt
+
+        Thread 105 (Thread 0x7fffefa18710 (LWP 10260)):
+        #5 Frame 0x7fffd00019d0, for file /home/david/coding/python-svn/Lib/threading.py, line 155, in _acquire_restore (self=<_RLock(_Verbose__verbose=False, _RLock__owner=140737354016512, _RLock__block=<thread.lock at remote 0x858770>, _RLock__count=1) at remote 0xd7ff40>, count_owner=(1, 140737213728528), count=1, owner=140737213728528)
+                self.__block.acquire()
+        #8 Frame 0x7fffac001640, for file /home/david/coding/python-svn/Lib/threading.py, line 269, in wait (self=<_Condition(_Condition__lock=<_RLock(_Verbose__verbose=False, _RLock__owner=140737354016512, _RLock__block=<thread.lock at remote 0x858770>, _RLock__count=1) at remote 0xd7ff40>, acquire=<instancemethod at remote 0xd80260>, _is_owned=<instancemethod at remote 0xd80160>, _release_save=<instancemethod at remote 0xd803e0>, release=<instancemethod at remote 0xd802e0>, _acquire_restore=<instancemethod at remote 0xd7ee60>, _Verbose__verbose=False, _Condition__waiters=[]) at remote 0xd7fd10>, timeout=None, waiter=<thread.lock at remote 0x858a90>, saved_state=(1, 140737213728528))
+                    self._acquire_restore(saved_state)
+        #12 Frame 0x7fffb8001a10, for file /home/david/coding/python-svn/Lib/test/lock_tests.py, line 348, in f ()
+                    cond.wait()
+        #16 Frame 0x7fffb8001c40, for file /home/david/coding/python-svn/Lib/test/lock_tests.py, line 37, in task (tid=140737213728528)
+                        f()
+
+        Thread 104 (Thread 0x7fffdf5fe710 (LWP 10259)):
+        #5 Frame 0x7fffe4001580, for file /home/david/coding/python-svn/Lib/threading.py, line 155, in _acquire_restore (self=<_RLock(_Verbose__verbose=False, _RLock__owner=140737354016512, _RLock__block=<thread.lock at remote 0x858770>, _RLock__count=1) at remote 0xd7ff40>, count_owner=(1, 140736940992272), count=1, owner=140736940992272)
+                self.__block.acquire()
+        #8 Frame 0x7fffc8002090, for file /home/david/coding/python-svn/Lib/threading.py, line 269, in wait (self=<_Condition(_Condition__lock=<_RLock(_Verbose__verbose=False, _RLock__owner=140737354016512, _RLock__block=<thread.lock at remote 0x858770>, _RLock__count=1) at remote 0xd7ff40>, acquire=<instancemethod at remote 0xd80260>, _is_owned=<instancemethod at remote 0xd80160>, _release_save=<instancemethod at remote 0xd803e0>, release=<instancemethod at remote 0xd802e0>, _acquire_restore=<instancemethod at remote 0xd7ee60>, _Verbose__verbose=False, _Condition__waiters=[]) at remote 0xd7fd10>, timeout=None, waiter=<thread.lock at remote 0x858860>, saved_state=(1, 140736940992272))
+                    self._acquire_restore(saved_state)
+        #12 Frame 0x7fffac001c90, for file /home/david/coding/python-svn/Lib/test/lock_tests.py, line 348, in f ()
+                    cond.wait()
+        #16 Frame 0x7fffac0011c0, for file /home/david/coding/python-svn/Lib/test/lock_tests.py, line 37, in task (tid=140736940992272)
+                        f()
+
+        Thread 1 (Thread 0x7ffff7fe2700 (LWP 10145)):
+        #5 Frame 0xcb5380, for file /home/david/coding/python-svn/Lib/test/lock_tests.py, line 16, in _wait ()
+            time.sleep(0.01)
+        #8 Frame 0x7fffd00024a0, for file /home/david/coding/python-svn/Lib/test/lock_tests.py, line 378, in _check_notify (self=<ConditionTests(_testMethodName='test_notify', _resultForDoCleanups=<TestResult(_original_stdout=<cStringIO.StringO at remote 0xc191e0>, skipped=[], _mirrorOutput=False, testsRun=39, buffer=False, _original_stderr=<file at remote 0x7ffff7fc6340>, _stdout_buffer=<cStringIO.StringO at remote 0xc9c7f8>, _stderr_buffer=<cStringIO.StringO at remote 0xc9c790>, _moduleSetUpFailed=False, expectedFailures=[], errors=[], _previousTestClass=<type at remote 0x928310>, unexpectedSuccesses=[], failures=[], shouldStop=False, failfast=False) at remote 0xc185a0>, _threads=(0,), _cleanups=[], _type_equality_funcs={<type at remote 0x7eba00>: <instancemethod at remote 0xd750e0>, <type at remote 0x7e7820>: <instancemethod at remote 0xd75160>, <type at remote 0x7e30e0>: <instancemethod at remote 0xd75060>, <type at remote 0x7e7d20>: <instancemethod at remote 0xd751e0>, <type at remote 0x7f19e0...(truncated)
+                _wait()
diff --git a/Doc/howto/index.rst b/Doc/howto/index.rst
index 6280f05771..c0ef01df86 100644
--- a/Doc/howto/index.rst
+++ b/Doc/howto/index.rst
@@ -13,10 +13,10 @@ Currently, the HOWTOs are:
 .. toctree::
    :maxdepth: 1
 
-   pyporting.rst
    cporting.rst
    curses.rst
    descriptor.rst
+   gdb_helpers.rst
    enum.rst
    functional.rst
    logging.rst
diff --git a/Doc/howto/logging-cookbook.rst b/Doc/howto/logging-cookbook.rst
index 33c57ae734..fe13a7cbe8 100644
--- a/Doc/howto/logging-cookbook.rst
+++ b/Doc/howto/logging-cookbook.rst
@@ -1744,13 +1744,11 @@ to the above, as in the following example::
             return self.fmt.format(*self.args)
 
     class StyleAdapter(logging.LoggerAdapter):
-        def __init__(self, logger, extra=None):
-            super().__init__(logger, extra or {})
-
-        def log(self, level, msg, /, *args, **kwargs):
+        def log(self, level, msg, /, *args, stacklevel=1, **kwargs):
             if self.isEnabledFor(level):
                 msg, kwargs = self.process(msg, kwargs)
-                self.logger._log(level, Message(msg, args), (), **kwargs)
+                self.logger.log(level, Message(msg, args), **kwargs,
+                                stacklevel=stacklevel+1)
 
     logger = StyleAdapter(logging.getLogger(__name__))
 
@@ -1762,7 +1760,7 @@ to the above, as in the following example::
         main()
 
 The above script should log the message ``Hello, world!`` when run with
-Python 3.2 or later.
+Python 3.8 or later.
 
 
 .. currentmodule:: logging
@@ -1848,8 +1846,11 @@ the use of a :class:`Filter` does not provide the desired result.
 
 .. _zeromq-handlers:
 
-Subclassing QueueHandler - a ZeroMQ example
--------------------------------------------
+Subclassing QueueHandler and QueueListener- a ZeroMQ example
+------------------------------------------------------------
+
+Subclass ``QueueHandler``
+^^^^^^^^^^^^^^^^^^^^^^^^^
 
 You can use a :class:`QueueHandler` subclass to send messages to other kinds
 of queues, for example a ZeroMQ 'publish' socket. In the example below,the
@@ -1887,8 +1888,8 @@ data needed by the handler to create the socket::
             self.queue.close()
 
 
-Subclassing QueueListener - a ZeroMQ example
---------------------------------------------
+Subclass ``QueueListener``
+^^^^^^^^^^^^^^^^^^^^^^^^^^
 
 You can also subclass :class:`QueueListener` to get messages from other kinds
 of queues, for example a ZeroMQ 'subscribe' socket. Here's an example::
@@ -1905,25 +1906,134 @@ of queues, for example a ZeroMQ 'subscribe' socket. Here's an example::
             msg = self.queue.recv_json()
             return logging.makeLogRecord(msg)
 
+.. _pynng-handlers:
 
-.. seealso::
+Subclassing QueueHandler and QueueListener- a ``pynng`` example
+---------------------------------------------------------------
 
-   Module :mod:`logging`
-      API reference for the logging module.
+In a similar way to the above section, we can implement a listener and handler
+using `pynng <https://pypi.org/project/pynng/>`_, which is a Python binding to
+`NNG <https://nng.nanomsg.org/>`_, billed as a spiritual successor to ZeroMQ.
+The following snippets illustrate -- you can test them in an environment which has
+``pynng`` installed. Juat for variety, we present the listener first.
 
-   Module :mod:`logging.config`
-      Configuration API for the logging module.
 
-   Module :mod:`logging.handlers`
-      Useful handlers included with the logging module.
+Subclass ``QueueListener``
+^^^^^^^^^^^^^^^^^^^^^^^^^^
 
-   :ref:`A basic logging tutorial <logging-basic-tutorial>`
+.. code-block:: python
+
+    import json
+    import logging
+    import logging.handlers
+
+    import pynng
+
+    DEFAULT_ADDR = "tcp://localhost:13232"
+
+    interrupted = False
+
+    class NNGSocketListener(logging.handlers.QueueListener):
+
+        def __init__(self, uri, /, *handlers, **kwargs):
+            # Have a timeout for interruptability, and open a
+            # subscriber socket
+            socket = pynng.Sub0(listen=uri, recv_timeout=500)
+            # The b'' subscription matches all topics
+            topics = kwargs.pop('topics', None) or b''
+            socket.subscribe(topics)
+            # We treat the socket as a queue
+            super().__init__(socket, *handlers, **kwargs)
+
+        def dequeue(self, block):
+            data = None
+            # Keep looping while not interrupted and no data received over the
+            # socket
+            while not interrupted:
+                try:
+                    data = self.queue.recv(block=block)
+                    break
+                except pynng.Timeout:
+                    pass
+                except pynng.Closed:  # sometimes hit when you hit Ctrl-C
+                    break
+            if data is None:
+                return None
+            # Get the logging event sent from a publisher
+            event = json.loads(data.decode('utf-8'))
+            return logging.makeLogRecord(event)
+
+        def enqueue_sentinel(self):
+            # Not used in this implementation, as the socket isn't really a
+            # queue
+            pass
+
+    logging.getLogger('pynng').propagate = False
+    listener = NNGSocketListener(DEFAULT_ADDR, logging.StreamHandler(), topics=b'')
+    listener.start()
+    print('Press Ctrl-C to stop.')
+    try:
+        while True:
+            pass
+    except KeyboardInterrupt:
+        interrupted = True
+    finally:
+        listener.stop()
 
-   :ref:`A more advanced logging tutorial <logging-advanced-tutorial>`
 
+Subclass ``QueueHandler``
+^^^^^^^^^^^^^^^^^^^^^^^^^
 
 .. currentmodule:: logging
 
+.. code-block:: python
+
+    import json
+    import logging
+    import logging.handlers
+    import time
+    import random
+
+    import pynng
+
+    DEFAULT_ADDR = "tcp://localhost:13232"
+
+    class NNGSocketHandler(logging.handlers.QueueHandler):
+
+        def __init__(self, uri):
+            socket = pynng.Pub0(dial=uri, send_timeout=500)
+            super().__init__(socket)
+
+        def enqueue(self, record):
+            # Send the record as UTF-8 encoded JSON
+            d = dict(record.__dict__)
+            data = json.dumps(d)
+            self.queue.send(data.encode('utf-8'))
+
+        def close(self):
+            self.queue.close()
+
+    logging.getLogger('pynng').propagate = False
+    handler = NNGSocketHandler(DEFAULT_ADDR)
+    logging.basicConfig(level=logging.DEBUG,
+                        handlers=[logging.StreamHandler(), handler],
+                        format='%(levelname)-8s %(name)10s %(message)s')
+    levels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR,
+              logging.CRITICAL)
+    logger_names = ('myapp', 'myapp.lib1', 'myapp.lib2')
+    msgno = 1
+    while True:
+        # Just randomly select some loggers and levels and log away
+        level = random.choice(levels)
+        logger = logging.getLogger(random.choice(logger_names))
+        logger.log(level, 'Message no. %5d' % msgno)
+        msgno += 1
+        delay = random.random() * 2 + 0.5
+        time.sleep(delay)
+
+You can run the above two snippets in separate command shells.
+
+
 An example dictionary-based configuration
 -----------------------------------------
 
@@ -3420,9 +3530,10 @@ The worker thread is implemented using Qt's ``QThread`` class rather than the
 :mod:`threading` module, as there are circumstances where one has to use
 ``QThread``, which offers better integration with other ``Qt`` components.
 
-The code should work with recent releases of either ``PySide2`` or ``PyQt5``.
-You should be able to adapt the approach to earlier versions of Qt. Please
-refer to the comments in the code snippet for more detailed information.
+The code should work with recent releases of any of ``PySide6``, ``PyQt6``,
+``PySide2`` or ``PyQt5``. You should be able to adapt the approach to earlier
+versions of Qt. Please refer to the comments in the code snippet for more
+detailed information.
 
 .. code-block:: python3
 
@@ -3432,16 +3543,25 @@ refer to the comments in the code snippet for more detailed information.
     import sys
     import time
 
-    # Deal with minor differences between PySide2 and PyQt5
+    # Deal with minor differences between different Qt packages
     try:
-        from PySide2 import QtCore, QtGui, QtWidgets
+        from PySide6 import QtCore, QtGui, QtWidgets
         Signal = QtCore.Signal
         Slot = QtCore.Slot
     except ImportError:
-        from PyQt5 import QtCore, QtGui, QtWidgets
-        Signal = QtCore.pyqtSignal
-        Slot = QtCore.pyqtSlot
-
+        try:
+            from PyQt6 import QtCore, QtGui, QtWidgets
+            Signal = QtCore.pyqtSignal
+            Slot = QtCore.pyqtSlot
+        except ImportError:
+            try:
+                from PySide2 import QtCore, QtGui, QtWidgets
+                Signal = QtCore.Signal
+                Slot = QtCore.Slot
+            except ImportError:
+                from PyQt5 import QtCore, QtGui, QtWidgets
+                Signal = QtCore.pyqtSignal
+                Slot = QtCore.pyqtSlot
 
     logger = logging.getLogger(__name__)
 
@@ -3513,8 +3633,14 @@ refer to the comments in the code snippet for more detailed information.
             while not QtCore.QThread.currentThread().isInterruptionRequested():
                 delay = 0.5 + random.random() * 2
                 time.sleep(delay)
-                level = random.choice(LEVELS)
-                logger.log(level, 'Message after delay of %3.1f: %d', delay, i, extra=extra)
+                try:
+                    if random.random() < 0.1:
+                        raise ValueError('Exception raised: %d' % i)
+                    else:
+                        level = random.choice(LEVELS)
+                        logger.log(level, 'Message after delay of %3.1f: %d', delay, i, extra=extra)
+                except ValueError as e:
+                    logger.exception('Failed: %s', e, extra=extra)
                 i += 1
 
     #
@@ -3541,7 +3667,10 @@ refer to the comments in the code snippet for more detailed information.
             self.textedit = te = QtWidgets.QPlainTextEdit(self)
             # Set whatever the default monospace font is for the platform
             f = QtGui.QFont('nosuchfont')
-            f.setStyleHint(f.Monospace)
+            if hasattr(f, 'Monospace'):
+                f.setStyleHint(f.Monospace)
+            else:
+                f.setStyleHint(f.StyleHint.Monospace)  # for Qt6
             te.setFont(f)
             te.setReadOnly(True)
             PB = QtWidgets.QPushButton
@@ -3628,7 +3757,11 @@ refer to the comments in the code snippet for more detailed information.
         app = QtWidgets.QApplication(sys.argv)
         example = Window(app)
         example.show()
-        sys.exit(app.exec_())
+        if hasattr(app, 'exec'):
+            rc = app.exec()
+        else:
+            rc = app.exec_()
+        sys.exit(rc)
 
     if __name__=='__main__':
         main()
diff --git a/Doc/howto/logging.rst b/Doc/howto/logging.rst
index 55c7c02e98..877cb24328 100644
--- a/Doc/howto/logging.rst
+++ b/Doc/howto/logging.rst
@@ -25,10 +25,12 @@ or *severity*.
 When to use logging
 ^^^^^^^^^^^^^^^^^^^
 
-Logging provides a set of convenience functions for simple logging usage. These
-are :func:`debug`, :func:`info`, :func:`warning`, :func:`error` and
-:func:`critical`. To determine when to use logging, see the table below, which
-states, for each of a set of common tasks, the best tool to use for it.
+You can access logging functionality by creating a logger via ``logger =
+getLogger(__name__)``, and then calling the logger's :meth:`~Logger.debug`,
+:meth:`~Logger.info`, :meth:`~Logger.warning`, :meth:`~Logger.error` and
+:meth:`~Logger.critical` methods. To determine when to use logging, and to see
+which logger methods to use when, see the table below. It states, for each of a
+set of common tasks, the best tool to use for that task.
 
 +-------------------------------------+--------------------------------------+
 | Task you want to perform            | The best tool for the task           |
@@ -37,8 +39,8 @@ states, for each of a set of common tasks, the best tool to use for it.
 | usage of a command line script or   |                                      |
 | program                             |                                      |
 +-------------------------------------+--------------------------------------+
-| Report events that occur during     | :func:`logging.info` (or             |
-| normal operation of a program (e.g. | :func:`logging.debug` for very       |
+| Report events that occur during     | A logger's :meth:`~Logger.info` (or  |
+| normal operation of a program (e.g. | :meth:`~Logger.debug` method for very|
 | for status monitoring or fault      | detailed output for diagnostic       |
 | investigation)                      | purposes)                            |
 +-------------------------------------+--------------------------------------+
@@ -47,22 +49,23 @@ states, for each of a set of common tasks, the best tool to use for it.
 |                                     | the client application should be     |
 |                                     | modified to eliminate the warning    |
 |                                     |                                      |
-|                                     | :func:`logging.warning` if there is  |
-|                                     | nothing the client application can do|
-|                                     | about the situation, but the event   |
-|                                     | should still be noted                |
+|                                     | A logger's :meth:`~Logger.warning`   |
+|                                     | method if there is nothing the client|
+|                                     | application can do about the         |
+|                                     | situation, but the event should still|
+|                                     | be noted                             |
 +-------------------------------------+--------------------------------------+
 | Report an error regarding a         | Raise an exception                   |
 | particular runtime event            |                                      |
 +-------------------------------------+--------------------------------------+
-| Report suppression of an error      | :func:`logging.error`,               |
-| without raising an exception (e.g.  | :func:`logging.exception` or         |
-| error handler in a long-running     | :func:`logging.critical` as          |
+| Report suppression of an error      | A logger's :meth:`~Logger.error`,    |
+| without raising an exception (e.g.  | :meth:`~Logger.exception` or         |
+| error handler in a long-running     | :meth:`~Logger.critical` method as   |
 | server process)                     | appropriate for the specific error   |
 |                                     | and application domain               |
 +-------------------------------------+--------------------------------------+
 
-The logging functions are named after the level or severity of the events
+The logger methods are named after the level or severity of the events
 they are used to track. The standard levels and their applicability are
 described below (in increasing order of severity):
 
@@ -116,12 +119,18 @@ If you type these lines into a script and run it, you'll see:
    WARNING:root:Watch out!
 
 printed out on the console. The ``INFO`` message doesn't appear because the
-default level is ``WARNING``. The printed message includes the indication of
-the level and the description of the event provided in the logging call, i.e.
-'Watch out!'. Don't worry about the 'root' part for now: it will be explained
-later. The actual output can be formatted quite flexibly if you need that;
-formatting options will also be explained later.
-
+default level is ``WARNING``. The printed message includes the indication of the
+level and the description of the event provided in the logging call, i.e.
+'Watch out!'. The actual output can be formatted quite flexibly if you need
+that; formatting options will also be explained later.
+
+Notice that in this example, we use functions directly on the ``logging``
+module, like ``logging.debug``, rather than creating a logger and calling
+functions on it. These functions operation on the root logger, but can be useful
+as they will call :func:`~logging.basicConfig` for you if it has not been called yet, like in
+this example.  In larger programs you'll usually want to control the logging
+configuration explicitly however - so for that reason as well as others, it's
+better to create loggers and call their methods.
 
 Logging to a file
 ^^^^^^^^^^^^^^^^^
@@ -131,11 +140,12 @@ look at that next. Be sure to try the following in a newly started Python
 interpreter, and don't just continue from the session described above::
 
    import logging
+   logger = logging.getLogger(__name__)
    logging.basicConfig(filename='example.log', encoding='utf-8', level=logging.DEBUG)
-   logging.debug('This message should go to the log file')
-   logging.info('So should this')
-   logging.warning('And this, too')
-   logging.error('And non-ASCII stuff, too, like resund and Malm')
+   logger.debug('This message should go to the log file')
+   logger.info('So should this')
+   logger.warning('And this, too')
+   logger.error('And non-ASCII stuff, too, like resund and Malm')
 
 .. versionchanged:: 3.9
    The *encoding* argument was added. In earlier Python versions, or if not
@@ -149,10 +159,10 @@ messages:
 
 .. code-block:: none
 
-   DEBUG:root:This message should go to the log file
-   INFO:root:So should this
-   WARNING:root:And this, too
-   ERROR:root:And non-ASCII stuff, too, like resund and Malm
+   DEBUG:__main__:This message should go to the log file
+   INFO:__main__:So should this
+   WARNING:__main__:And this, too
+   ERROR:__main__:And non-ASCII stuff, too, like resund and Malm
 
 This example also shows how you can set the logging level which acts as the
 threshold for tracking. In this case, because we set the threshold to
@@ -181,11 +191,9 @@ following example::
        raise ValueError('Invalid log level: %s' % loglevel)
    logging.basicConfig(level=numeric_level, ...)
 
-The call to :func:`basicConfig` should come *before* any calls to
-:func:`debug`, :func:`info`, etc. Otherwise, those functions will call
-:func:`basicConfig` for you with the default options. As it's intended as a
-one-off simple configuration facility, only the first call will actually do
-anything: subsequent calls are effectively no-ops.
+The call to :func:`basicConfig` should come *before* any calls to a logger's
+methods such as :meth:`~Logger.debug`, :meth:`~Logger.info`, etc. Otherwise,
+that logging event may not be handled in the desired manner.
 
 If you run the above script several times, the messages from successive runs
 are appended to the file *example.log*. If you want each run to start afresh,
@@ -198,50 +206,6 @@ The output will be the same as before, but the log file is no longer appended
 to, so the messages from earlier runs are lost.
 
 
-Logging from multiple modules
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-If your program consists of multiple modules, here's an example of how you
-could organize logging in it::
-
-   # myapp.py
-   import logging
-   import mylib
-
-   def main():
-       logging.basicConfig(filename='myapp.log', level=logging.INFO)
-       logging.info('Started')
-       mylib.do_something()
-       logging.info('Finished')
-
-   if __name__ == '__main__':
-       main()
-
-::
-
-   # mylib.py
-   import logging
-
-   def do_something():
-       logging.info('Doing something')
-
-If you run *myapp.py*, you should see this in *myapp.log*:
-
-.. code-block:: none
-
-   INFO:root:Started
-   INFO:root:Doing something
-   INFO:root:Finished
-
-which is hopefully what you were expecting to see. You can generalize this to
-multiple modules, using the pattern in *mylib.py*. Note that for this simple
-usage pattern, you won't know, by looking in the log file, *where* in your
-application your messages came from, apart from looking at the event
-description. If you want to track the location of your messages, you'll need
-to refer to the documentation beyond the tutorial level -- see
-:ref:`logging-advanced-tutorial`.
-
-
 Logging variable data
 ^^^^^^^^^^^^^^^^^^^^^
 
diff --git a/Doc/howto/pyporting.rst b/Doc/howto/pyporting.rst
index 501b16d82d..d560364107 100644
--- a/Doc/howto/pyporting.rst
+++ b/Doc/howto/pyporting.rst
@@ -1,3 +1,5 @@
+:orphan:
+
 .. _pyporting-howto:
 
 *************************************
@@ -6,423 +8,30 @@ How to port Python 2 Code to Python 3
 
 :author: Brett Cannon
 
-.. topic:: Abstract
-
-   Python 2 reached its official end-of-life at the start of 2020. This means
-   that no new bug reports, fixes, or changes will be made to Python 2 - it's
-   no longer supported.
-
-   This guide is intended to provide you with a path to Python 3 for your
-   code, that includes compatibility with Python 2 as a first step.
-
-   If you are looking to port an extension module instead of pure Python code,
-   please see :ref:`cporting-howto`.
-
-   The archived python-porting_ mailing list may contain some useful guidance.
-
-
-The Short Explanation
-=====================
-
-To achieve Python 2/3 compatibility in a single code base, the basic steps
-are:
-
-#. Only worry about supporting Python 2.7
-#. Make sure you have good test coverage (coverage.py_ can help;
-   ``python -m pip install coverage``)
-#. Learn the differences between Python 2 and 3
-#. Use Futurize_ (or Modernize_) to update your code (e.g. ``python -m pip install future``)
-#. Use Pylint_ to help make sure you don't regress on your Python 3 support
-   (``python -m pip install pylint``)
-#. Use caniusepython3_ to find out which of your dependencies are blocking your
-   use of Python 3 (``python -m pip install caniusepython3``)
-#. Once your dependencies are no longer blocking you, use continuous integration
-   to make sure you stay compatible with Python 2 and 3 (tox_ can help test
-   against multiple versions of Python; ``python -m pip install tox``)
-#. Consider using optional :term:`static type checking <static type checker>`
-   to make sure your type usage
-   works in both Python 2 and 3 (e.g. use mypy_ to check your typing under both
-   Python 2 and Python 3; ``python -m pip install mypy``).
-
-.. note::
-
-   Note: Using ``python -m pip install`` guarantees that the ``pip`` you invoke
-   is the one installed for the Python currently in use, whether it be
-   a system-wide ``pip`` or one installed within a
-   :ref:`virtual environment <tut-venv>`.
-
-Details
-=======
-
-Even if other factors - say, dependencies over which you have no control -
-still require you to support Python 2, that does not prevent you taking the
-step of including Python 3 support.
-
-Most changes required to support Python 3 lead to cleaner code using newer
-practices even in Python 2 code.
-
-
-Different versions of Python 2
-------------------------------
-
-Ideally, your code should be compatible with Python 2.7, which was the
-last supported version of Python 2.
-
-Some of the tools mentioned in this guide will not work with Python 2.6.
-
-If absolutely necessary, the six_ project can help you support Python 2.5 and
-3 simultaneously. Do realize, though, that nearly all the projects listed in
-this guide will not be available to you.
-
-If you are able to skip Python 2.5 and older, the required changes to your
-code will be minimal. At worst you will have to use a function instead of a
-method in some instances or have to import a function instead of using a
-built-in one.
-
-
-Make sure you specify the proper version support in your ``setup.py`` file
---------------------------------------------------------------------------
-
-In your ``setup.py`` file you should have the proper `trove classifier`_
-specifying what versions of Python you support. As your project does not support
-Python 3 yet you should at least have
-``Programming Language :: Python :: 2 :: Only`` specified. Ideally you should
-also specify each major/minor version of Python that you do support, e.g.
-``Programming Language :: Python :: 2.7``.
-
-
-Have good test coverage
------------------------
-
-Once you have your code supporting the oldest version of Python 2 you want it
-to, you will want to make sure your test suite has good coverage. A good rule of
-thumb is that if you want to be confident enough in your test suite that any
-failures that appear after having tools rewrite your code are actual bugs in the
-tools and not in your code. If you want a number to aim for, try to get over 80%
-coverage (and don't feel bad if you find it hard to get better than 90%
-coverage). If you don't already have a tool to measure test coverage then
-coverage.py_ is recommended.
-
-
-Be aware of the differences between Python 2 and 3
---------------------------------------------------
-
-Once you have your code well-tested you are ready to begin porting your code to
-Python 3! But to fully understand how your code is going to change and what
-you want to look out for while you code, you will want to learn what changes
-Python 3 makes in terms of Python 2.
-
-Some resources for understanding the differences and their implications for you
-code:
-
-* the :ref:`"What's New" <whatsnew-index>` doc for each release of Python 3
-* the `Porting to Python 3`_ book (which is free online)
-* the handy `cheat sheet`_ from the Python-Future project.
-
-
-Update your code
-----------------
-
-There are tools available that can port your code automatically.
-
-Futurize_ does its best to make Python 3 idioms and practices exist in Python
-2, e.g. backporting the ``bytes`` type from Python 3 so that you have
-semantic parity between the major versions of Python. This is the better
-approach for most cases.
-
-Modernize_, on the other hand, is more conservative and targets a Python 2/3
-subset of Python, directly relying on six_ to help provide compatibility.
-
-A good approach is to run the tool over your test suite first and visually
-inspect the diff to make sure the transformation is accurate. After you have
-transformed your test suite and verified that all the tests still pass as
-expected, then you can transform your application code knowing that any tests
-which fail is a translation failure.
-
-Unfortunately the tools can't automate everything to make your code work under
-Python 3, and you will also need to read the tools' documentation in case some
-options you need are turned off by default.
-
-Key issues to be aware of and check for:
-
-Division
-++++++++
-
-In Python 3, ``5 / 2 == 2.5`` and not ``2`` as it was in Python 2; all
-division between ``int`` values result in a ``float``. This change has
-actually been planned since Python 2.2 which was released in 2002. Since then
-users have been encouraged to add ``from __future__ import division`` to any
-and all files which use the ``/`` and ``//`` operators or to be running the
-interpreter with the ``-Q`` flag. If you have not been doing this then you
-will need to go through your code and do two things:
-
-#. Add ``from __future__ import division`` to your files
-#. Update any division operator as necessary to either use ``//`` to use floor
-   division or continue using ``/`` and expect a float
-
-The reason that ``/`` isn't simply translated to ``//`` automatically is that if
-an object defines a ``__truediv__`` method but not ``__floordiv__`` then your
-code would begin to fail (e.g. a user-defined class that uses ``/`` to
-signify some operation but not ``//`` for the same thing or at all).
+Python 2 reached its official end-of-life at the start of 2020. This means
+that no new bug reports, fixes, or changes will be made to Python 2 - it's
+no longer supported: see :pep:`373` and
+`status of Python versions <https://devguide.python.org/versions>`_.
 
+If you are looking to port an extension module instead of pure Python code,
+please see :ref:`cporting-howto`.
 
-Text versus binary data
-+++++++++++++++++++++++
+The archived python-porting_ mailing list may contain some useful guidance.
 
-In Python 2 you could use the ``str`` type for both text and binary data.
-Unfortunately this confluence of two different concepts could lead to brittle
-code which sometimes worked for either kind of data, sometimes not. It also
-could lead to confusing APIs if people didn't explicitly state that something
-that accepted ``str`` accepted either text or binary data instead of one
-specific type. This complicated the situation especially for anyone supporting
-multiple languages as APIs wouldn't bother explicitly supporting ``unicode``
-when they claimed text data support.
+Since Python 3.13 the original porting guide was discontinued.
+You can find the old guide in the
+`archive <https://docs.python.org/3.12/howto/pyporting.html>`_.
 
-Python 3 made text and binary data distinct types that cannot simply be mixed
-together. For any code that deals only with text or only binary data, this
-separation doesn't pose an issue. But for code that has to deal with both, it
-does mean you might have to now care about when you are using text compared
-to binary data, which is why this cannot be entirely automated.
 
-Decide which APIs take text and which take binary (it is **highly** recommended
-you don't design APIs that can take both due to the difficulty of keeping the
-code working; as stated earlier it is difficult to do well). In Python 2 this
-means making sure the APIs that take text can work with ``unicode`` and those
-that work with binary data work with the ``bytes`` type from Python 3
-(which is a subset of ``str`` in Python 2 and acts as an alias for ``bytes``
-type in Python 2). Usually the biggest issue is realizing which methods exist
-on which types in Python 2 and 3 simultaneously (for text that's ``unicode``
-in Python 2 and ``str`` in Python 3, for binary that's ``str``/``bytes`` in
-Python 2 and ``bytes`` in Python 3).
+Third-party guides
+==================
 
-The following table lists the **unique** methods of each data type across
-Python 2 and 3 (e.g., the ``decode()`` method is usable on the equivalent binary
-data type in either Python 2 or 3, but it can't be used by the textual data
-type consistently between Python 2 and 3 because ``str`` in Python 3 doesn't
-have the method). Do note that as of Python 3.5 the ``__mod__`` method was
-added to the bytes type.
+There are also multiple third-party guides that might be useful:
 
-======================== =====================
-**Text data**            **Binary data**
------------------------- ---------------------
-\                        decode
------------------------- ---------------------
-encode
------------------------- ---------------------
-format
------------------------- ---------------------
-isdecimal
------------------------- ---------------------
-isnumeric
-======================== =====================
+- `Guide by Fedora <https://portingguide.readthedocs.io>`_
+- `PyCon 2020 tutorial <https://www.youtube.com/watch?v=JgIgEjASOlk>`_
+- `Guide by DigitalOcean <https://www.digitalocean.com/community/tutorials/how-to-port-python-2-code-to-python-3>`_
+- `Guide by ActiveState <https://www.activestate.com/blog/how-to-migrate-python-2-applications-to-python-3>`_
 
-Making the distinction easier to handle can be accomplished by encoding and
-decoding between binary data and text at the edge of your code. This means that
-when you receive text in binary data, you should immediately decode it. And if
-your code needs to send text as binary data then encode it as late as possible.
-This allows your code to work with only text internally and thus eliminates
-having to keep track of what type of data you are working with.
 
-The next issue is making sure you know whether the string literals in your code
-represent text or binary data. You should add a ``b`` prefix to any
-literal that presents binary data. For text you should add a ``u`` prefix to
-the text literal. (There is a :mod:`__future__` import to force all unspecified
-literals to be Unicode, but usage has shown it isn't as effective as adding a
-``b`` or ``u`` prefix to all literals explicitly)
-
-You also need to be careful about opening files. Possibly you have not always
-bothered to add the ``b`` mode when opening a binary file (e.g., ``rb`` for
-binary reading).  Under Python 3, binary files and text files are clearly
-distinct and mutually incompatible; see the :mod:`io` module for details.
-Therefore, you **must** make a decision of whether a file will be used for
-binary access (allowing binary data to be read and/or written) or textual access
-(allowing text data to be read and/or written). You should also use :func:`io.open`
-for opening files instead of the built-in :func:`open` function as the :mod:`io`
-module is consistent from Python 2 to 3 while the built-in :func:`open` function
-is not (in Python 3 it's actually :func:`io.open`). Do not bother with the
-outdated practice of using :func:`codecs.open` as that's only necessary for
-keeping compatibility with Python 2.5.
-
-The constructors of both ``str`` and ``bytes`` have different semantics for the
-same arguments between Python 2 and 3. Passing an integer to ``bytes`` in Python 2
-will give you the string representation of the integer: ``bytes(3) == '3'``.
-But in Python 3, an integer argument to ``bytes`` will give you a bytes object
-as long as the integer specified, filled with null bytes:
-``bytes(3) == b'\x00\x00\x00'``. A similar worry is necessary when passing a
-bytes object to ``str``. In Python 2 you just get the bytes object back:
-``str(b'3') == b'3'``. But in Python 3 you get the string representation of the
-bytes object: ``str(b'3') == "b'3'"``.
-
-Finally, the indexing of binary data requires careful handling (slicing does
-**not** require any special handling). In Python 2,
-``b'123'[1] == b'2'`` while in Python 3 ``b'123'[1] == 50``. Because binary data
-is simply a collection of binary numbers, Python 3 returns the integer value for
-the byte you index on. But in Python 2 because ``bytes == str``, indexing
-returns a one-item slice of bytes. The six_ project has a function
-named ``six.indexbytes()`` which will return an integer like in Python 3:
-``six.indexbytes(b'123', 1)``.
-
-To summarize:
-
-#. Decide which of your APIs take text and which take binary data
-#. Make sure that your code that works with text also works with ``unicode`` and
-   code for binary data works with ``bytes`` in Python 2 (see the table above
-   for what methods you cannot use for each type)
-#. Mark all binary literals with a ``b`` prefix, textual literals with a ``u``
-   prefix
-#. Decode binary data to text as soon as possible, encode text as binary data as
-   late as possible
-#. Open files using :func:`io.open` and make sure to specify the ``b`` mode when
-   appropriate
-#. Be careful when indexing into binary data
-
-
-Use feature detection instead of version detection
-++++++++++++++++++++++++++++++++++++++++++++++++++
-
-Inevitably you will have code that has to choose what to do based on what
-version of Python is running. The best way to do this is with feature detection
-of whether the version of Python you're running under supports what you need.
-If for some reason that doesn't work then you should make the version check be
-against Python 2 and not Python 3. To help explain this, let's look at an
-example.
-
-Let's pretend that you need access to a feature of :mod:`importlib` that
-is available in Python's standard library since Python 3.3 and available for
-Python 2 through importlib2_ on PyPI. You might be tempted to write code to
-access e.g. the :mod:`importlib.abc` module by doing the following::
-
-  import sys
-
-  if sys.version_info[0] == 3:
-      from importlib import abc
-  else:
-      from importlib2 import abc
-
-The problem with this code is what happens when Python 4 comes out? It would
-be better to treat Python 2 as the exceptional case instead of Python 3 and
-assume that future Python versions will be more compatible with Python 3 than
-Python 2::
-
-  import sys
-
-  if sys.version_info[0] > 2:
-      from importlib import abc
-  else:
-      from importlib2 import abc
-
-The best solution, though, is to do no version detection at all and instead rely
-on feature detection. That avoids any potential issues of getting the version
-detection wrong and helps keep you future-compatible::
-
-  try:
-      from importlib import abc
-  except ImportError:
-      from importlib2 import abc
-
-
-Prevent compatibility regressions
----------------------------------
-
-Once you have fully translated your code to be compatible with Python 3, you
-will want to make sure your code doesn't regress and stop working under
-Python 3. This is especially true if you have a dependency which is blocking you
-from actually running under Python 3 at the moment.
-
-To help with staying compatible, any new modules you create should have
-at least the following block of code at the top of it::
-
-    from __future__ import absolute_import
-    from __future__ import division
-    from __future__ import print_function
-
-You can also run Python 2 with the ``-3`` flag to be warned about various
-compatibility issues your code triggers during execution. If you turn warnings
-into errors with ``-Werror`` then you can make sure that you don't accidentally
-miss a warning.
-
-You can also use the Pylint_ project and its ``--py3k`` flag to lint your code
-to receive warnings when your code begins to deviate from Python 3
-compatibility. This also prevents you from having to run Modernize_ or Futurize_
-over your code regularly to catch compatibility regressions. This does require
-you only support Python 2.7 and Python 3.4 or newer as that is Pylint's
-minimum Python version support.
-
-
-Check which dependencies block your transition
-----------------------------------------------
-
-**After** you have made your code compatible with Python 3 you should begin to
-care about whether your dependencies have also been ported. The caniusepython3_
-project was created to help you determine which projects
--- directly or indirectly -- are blocking you from supporting Python 3. There
-is both a command-line tool as well as a web interface at
-https://caniusepython3.com.
-
-The project also provides code which you can integrate into your test suite so
-that you will have a failing test when you no longer have dependencies blocking
-you from using Python 3. This allows you to avoid having to manually check your
-dependencies and to be notified quickly when you can start running on Python 3.
-
-
-Update your ``setup.py`` file to denote Python 3 compatibility
---------------------------------------------------------------
-
-Once your code works under Python 3, you should update the classifiers in
-your ``setup.py`` to contain ``Programming Language :: Python :: 3`` and to not
-specify sole Python 2 support. This will tell anyone using your code that you
-support Python 2 **and** 3. Ideally you will also want to add classifiers for
-each major/minor version of Python you now support.
-
-
-Use continuous integration to stay compatible
----------------------------------------------
-
-Once you are able to fully run under Python 3 you will want to make sure your
-code always works under both Python 2 and 3. Probably the best tool for running
-your tests under multiple Python interpreters is tox_. You can then integrate
-tox with your continuous integration system so that you never accidentally break
-Python 2 or 3 support.
-
-You may also want to use the ``-bb`` flag with the Python 3 interpreter to
-trigger an exception when you are comparing bytes to strings or bytes to an int
-(the latter is available starting in Python 3.5). By default type-differing
-comparisons simply return ``False``, but if you made a mistake in your
-separation of text/binary data handling or indexing on bytes you wouldn't easily
-find the mistake. This flag will raise an exception when these kinds of
-comparisons occur, making the mistake much easier to track down.
-
-
-Consider using optional static type checking
---------------------------------------------
-
-Another way to help port your code is to use a :term:`static type checker` like
-mypy_ or pytype_ on your code. These tools can be used to analyze your code as
-if it's being run under Python 2, then you can run the tool a second time as if
-your code is running under Python 3. By running a static type checker twice like
-this you can discover if you're e.g. misusing binary data type in one version
-of Python compared to another. If you add optional type hints to your code you
-can also explicitly state whether your APIs use textual or binary data, helping
-to make sure everything functions as expected in both versions of Python.
-
-
-.. _caniusepython3: https://pypi.org/project/caniusepython3
-.. _cheat sheet: https://python-future.org/compatible_idioms.html
-.. _coverage.py: https://pypi.org/project/coverage
-.. _Futurize: https://python-future.org/automatic_conversion.html
-.. _importlib2: https://pypi.org/project/importlib2
-.. _Modernize: https://python-modernize.readthedocs.io/
-.. _mypy: https://mypy-lang.org/
-.. _Porting to Python 3: http://python3porting.com/
-.. _Pylint: https://pypi.org/project/pylint
-
-.. _Python 3 Q & A: https://ncoghlan-devs-python-notes.readthedocs.io/en/latest/python3/questions_and_answers.html
-
-.. _pytype: https://github.com/google/pytype
-.. _python-future: https://python-future.org/
 .. _python-porting: https://mail.python.org/pipermail/python-porting/
-.. _six: https://pypi.org/project/six
-.. _tox: https://pypi.org/project/tox
-.. _trove classifier: https://pypi.org/classifiers
-
-.. _Why Python 3 exists: https://snarky.ca/why-python-3-exists
diff --git a/Doc/howto/sorting.rst b/Doc/howto/sorting.rst
index 38dd09f0a7..b98f91e023 100644
--- a/Doc/howto/sorting.rst
+++ b/Doc/howto/sorting.rst
@@ -1,10 +1,9 @@
 .. _sortinghowto:
 
-Sorting HOW TO
-**************
+Sorting Techniques
+******************
 
 :Author: Andrew Dalke and Raymond Hettinger
-:Release: 0.1
 
 
 Python lists have a built-in :meth:`list.sort` method that modifies the list
@@ -56,7 +55,7 @@ For example, here's a case-insensitive string comparison:
 
 .. doctest::
 
-    >>> sorted("This is a test string from Andrew".split(), key=str.lower)
+    >>> sorted("This is a test string from Andrew".split(), key=str.casefold)
     ['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']
 
 The value of the *key* parameter should be a function (or other callable) that
@@ -97,10 +96,14 @@ The same technique works for objects with named attributes. For example:
     >>> sorted(student_objects, key=lambda student: student.age)   # sort by age
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]
 
-Operator Module Functions
-=========================
+Objects with named attributes can be made by a regular class as shown
+above, or they can be instances of :class:`~dataclasses.dataclass` or
+a :term:`named tuple`.
 
-The key-function patterns shown above are very common, so Python provides
+Operator Module Functions and Partial Function Evaluation
+=========================================================
+
+The :term:`key function` patterns shown above are very common, so Python provides
 convenience functions to make accessor functions easier and faster. The
 :mod:`operator` module has :func:`~operator.itemgetter`,
 :func:`~operator.attrgetter`, and a :func:`~operator.methodcaller` function.
@@ -128,6 +131,24 @@ sort by *grade* then by *age*:
     >>> sorted(student_objects, key=attrgetter('grade', 'age'))
     [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]
 
+The :mod:`functools` module provides another helpful tool for making
+key-functions.  The :func:`~functools.partial` function can reduce the
+`arity <https://en.wikipedia.org/wiki/Arity>`_ of a multi-argument
+function making it suitable for use as a key-function.
+
+.. doctest::
+
+    >>> from functools import partial
+    >>> from unicodedata import normalize
+
+    >>> names = 'Zo bjrn Nez lana Zeke Abe Nubia Eloise'.split()
+
+    >>> sorted(names, key=partial(normalize, 'NFD'))
+    ['Abe', 'bjrn', 'Eloise', 'lana', 'Nubia', 'Nez', 'Zeke', 'Zo']
+
+    >>> sorted(names, key=partial(normalize, 'NFC'))
+    ['Abe', 'Eloise', 'Nubia', 'Nez', 'Zeke', 'Zo', 'bjrn', 'lana']
+
 Ascending and Descending
 ========================
 
@@ -200,6 +221,8 @@ This idiom is called Decorate-Sort-Undecorate after its three steps:
 
 For example, to sort the student data by *grade* using the DSU approach:
 
+.. doctest::
+
     >>> decorated = [(student.grade, i, student) for i, student in enumerate(student_objects)]
     >>> decorated.sort()
     >>> [student for grade, i, student in decorated]               # undecorate
@@ -282,7 +305,11 @@ Odds and Ends
     [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]
 
   However, note that ``<`` can fall back to using :meth:`~object.__gt__` if
-  :meth:`~object.__lt__` is not implemented (see :func:`object.__lt__`).
+  :meth:`~object.__lt__` is not implemented (see :func:`object.__lt__`
+  for details on the mechanics).  To avoid surprises, :pep:`8`
+  recommends that all six comparison methods be implemented.
+  The :func:`~functools.total_ordering` decorator is provided to make that
+  task easier.
 
 * Key functions need not depend directly on the objects being sorted. A key
   function can also access external resources. For instance, if the student grades
@@ -295,3 +322,24 @@ Odds and Ends
     >>> newgrades = {'john': 'F', 'jane':'A', 'dave': 'C'}
     >>> sorted(students, key=newgrades.__getitem__)
     ['jane', 'dave', 'john']
+
+Partial Sorts
+=============
+
+Some applications require only some of the data to be ordered.  The standard
+library provides several tools that do less work than a full sort:
+
+* :func:`min` and :func:`max` return the smallest and largest values,
+  respectively.  These functions make a single pass over the input data and
+  require almost no auxiliary memory.
+
+* :func:`heapq.nsmallest` and :func:`heapq.nlargest` return
+  the *n* smallest and largest values, respectively.  These functions
+  make a single pass over the data keeping only *n* elements in memory
+  at a time.  For values of *n* that are small relative to the number of
+  inputs, these functions make far fewer comparisons than a full sort.
+
+* :func:`heapq.heappush` and :func:`heapq.heappop` create and maintain a
+  partially sorted arrangement of data that keeps the smallest element
+  at position ``0``.  These functions are suitable for implementing
+  priority queues which are commonly used for task scheduling.
diff --git a/Doc/library/abc.rst b/Doc/library/abc.rst
index c073ea955a..10e2cba50e 100644
--- a/Doc/library/abc.rst
+++ b/Doc/library/abc.rst
@@ -101,11 +101,11 @@ a helper class :class:`ABC` to alternatively define ABCs through inheritance:
       subclass of the ABC.  (This class method is called from the
       :meth:`~class.__subclasscheck__` method of the ABC.)
 
-      This method should return ``True``, ``False`` or ``NotImplemented``.  If
+      This method should return ``True``, ``False`` or :data:`NotImplemented`.  If
       it returns ``True``, the *subclass* is considered a subclass of this ABC.
       If it returns ``False``, the *subclass* is not considered a subclass of
       this ABC, even if it would normally be one.  If it returns
-      ``NotImplemented``, the subclass check is continued with the usual
+      :data:`!NotImplemented`, the subclass check is continued with the usual
       mechanism.
 
       .. XXX explain the "usual mechanism"
diff --git a/Doc/library/array.rst b/Doc/library/array.rst
index 788dd763ff..51947a3a1e 100644
--- a/Doc/library/array.rst
+++ b/Doc/library/array.rst
@@ -273,4 +273,3 @@ Examples::
 
    `NumPy <https://numpy.org/>`_
       The NumPy package defines another array type.
-
diff --git a/Doc/library/ast.rst b/Doc/library/ast.rst
index 770eabf0c4..6be58747be 100644
--- a/Doc/library/ast.rst
+++ b/Doc/library/ast.rst
@@ -2178,14 +2178,17 @@ and classes for traversing abstract syntax trees:
    modified to correspond to :pep:`484` "signature type comments",
    e.g. ``(str, int) -> List[str]``.
 
-   Also, setting ``feature_version`` to a tuple ``(major, minor)``
-   will attempt to parse using that Python version's grammar.
-   Currently ``major`` must equal to ``3``.  For example, setting
-   ``feature_version=(3, 4)`` will allow the use of ``async`` and
-   ``await`` as variable names.  The lowest supported version is
-   ``(3, 4)``; the highest is ``sys.version_info[0:2]``.
-
-   If source contains a null character ('\0'), :exc:`ValueError` is raised.
+   Setting ``feature_version`` to a tuple ``(major, minor)`` will result in
+   a "best-effort" attempt to parse using that Python version's grammar.
+   For example, setting ``feature_version=(3, 9)`` will attempt to disallow
+   parsing of :keyword:`match` statements.
+   Currently ``major`` must equal to ``3``. The lowest supported version is
+   ``(3, 4)`` (and this may increase in future Python versions);
+   the highest is ``sys.version_info[0:2]``. "Best-effort" attempt means there
+   is no guarantee that the parse (or success of the parse) is the same as
+   when run on the Python version corresponding to ``feature_version``.
+
+   If source contains a null character (``\0``), :exc:`ValueError` is raised.
 
    .. warning::
       Note that successfully parsing source code into an AST object doesn't
diff --git a/Doc/library/asyncio-eventloop.rst b/Doc/library/asyncio-eventloop.rst
index 78704d9bb2..ba0ee1b6c2 100644
--- a/Doc/library/asyncio-eventloop.rst
+++ b/Doc/library/asyncio-eventloop.rst
@@ -605,6 +605,9 @@ Opening network connections
       The *family*, *proto*, *flags*, *reuse_address*, *reuse_port*,
       *allow_broadcast*, and *sock* parameters were added.
 
+   .. versionchanged:: 3.8
+      Added support for Windows.
+
    .. versionchanged:: 3.8.1
       The *reuse_address* parameter is no longer supported, as using
       :ref:`socket.SO_REUSEADDR <socket-unix-constants>`
@@ -622,11 +625,8 @@ Opening network connections
       prevents processes with differing UIDs from assigning sockets to the same
       socket address.
 
-   .. versionchanged:: 3.8
-      Added support for Windows.
-
    .. versionchanged:: 3.11
-      The *reuse_address* parameter, disabled since Python 3.9.0, 3.8.1,
+      The *reuse_address* parameter, disabled since Python 3.8.1,
       3.7.6 and 3.6.10, has been entirely removed.
 
 .. coroutinemethod:: loop.create_unix_connection(protocol_factory, \
diff --git a/Doc/library/asyncio-protocol.rst b/Doc/library/asyncio-protocol.rst
index 48fa02937b..e60f0ae679 100644
--- a/Doc/library/asyncio-protocol.rst
+++ b/Doc/library/asyncio-protocol.rst
@@ -417,8 +417,8 @@ Subprocess Transports
 
    Stop the subprocess.
 
-   On POSIX systems, this method sends SIGTERM to the subprocess.
-   On Windows, the Windows API function TerminateProcess() is called to
+   On POSIX systems, this method sends :py:const:`~signal.SIGTERM` to the subprocess.
+   On Windows, the Windows API function :c:func:`!TerminateProcess` is called to
    stop the subprocess.
 
    See also :meth:`subprocess.Popen.terminate`.
diff --git a/Doc/library/asyncio-stream.rst b/Doc/library/asyncio-stream.rst
index 3ce6f4fa7d..0b384eb95c 100644
--- a/Doc/library/asyncio-stream.rst
+++ b/Doc/library/asyncio-stream.rst
@@ -347,7 +347,7 @@ StreamWriter
       be resumed.  When there is nothing to wait for, the :meth:`drain`
       returns immediately.
 
-   .. coroutinemethod:: start_tls(sslcontext, \*, server_hostname=None, \
+   .. coroutinemethod:: start_tls(sslcontext, *, server_hostname=None, \
                           ssl_handshake_timeout=None, ssl_shutdown_timeout=None)
 
       Upgrade an existing stream-based connection to TLS.
diff --git a/Doc/library/asyncio-subprocess.rst b/Doc/library/asyncio-subprocess.rst
index bf35b1cb79..817a6ff305 100644
--- a/Doc/library/asyncio-subprocess.rst
+++ b/Doc/library/asyncio-subprocess.rst
@@ -240,7 +240,7 @@ their completion.
 
       .. note::
 
-         On Windows, :py:data:`SIGTERM` is an alias for :meth:`terminate`.
+         On Windows, :py:const:`~signal.SIGTERM` is an alias for :meth:`terminate`.
          ``CTRL_C_EVENT`` and ``CTRL_BREAK_EVENT`` can be sent to processes
          started with a *creationflags* parameter which includes
          ``CREATE_NEW_PROCESS_GROUP``.
@@ -249,10 +249,10 @@ their completion.
 
       Stop the child process.
 
-      On POSIX systems this method sends :py:const:`signal.SIGTERM` to the
+      On POSIX systems this method sends :py:const:`~signal.SIGTERM` to the
       child process.
 
-      On Windows the Win32 API function :c:func:`TerminateProcess` is
+      On Windows the Win32 API function :c:func:`!TerminateProcess` is
       called to stop the child process.
 
    .. method:: kill()
diff --git a/Doc/library/audit_events.rst b/Doc/library/audit_events.rst
index 8227a7955b..a2a90a00d0 100644
--- a/Doc/library/audit_events.rst
+++ b/Doc/library/audit_events.rst
@@ -7,7 +7,7 @@ Audit events table
 
 This table contains all events raised by :func:`sys.audit` or
 :c:func:`PySys_Audit` calls throughout the CPython runtime and the
-standard library.  These calls were added in 3.8.0 or later (see :pep:`578`).
+standard library.  These calls were added in 3.8 or later (see :pep:`578`).
 
 See :func:`sys.addaudithook` and :c:func:`PySys_AddAuditHook` for
 information on handling these events.
diff --git a/Doc/library/bdb.rst b/Doc/library/bdb.rst
index 52f0ca7c01..7bf4308a96 100644
--- a/Doc/library/bdb.rst
+++ b/Doc/library/bdb.rst
@@ -148,8 +148,8 @@ The :mod:`bdb` module also defines two classes:
 
    .. method:: reset()
 
-      Set the :attr:`botframe`, :attr:`stopframe`, :attr:`returnframe` and
-      :attr:`quitting` attributes with values ready to start debugging.
+      Set the :attr:`!botframe`, :attr:`!stopframe`, :attr:`!returnframe` and
+      :attr:`quitting <Bdb.set_quit>` attributes with values ready to start debugging.
 
    .. method:: trace_dispatch(frame, event, arg)
 
@@ -182,7 +182,7 @@ The :mod:`bdb` module also defines two classes:
 
       If the debugger should stop on the current line, invoke the
       :meth:`user_line` method (which should be overridden in subclasses).
-      Raise a :exc:`BdbQuit` exception if the :attr:`Bdb.quitting` flag is set
+      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
       (which can be set from :meth:`user_line`).  Return a reference to the
       :meth:`trace_dispatch` method for further tracing in that scope.
 
@@ -190,7 +190,7 @@ The :mod:`bdb` module also defines two classes:
 
       If the debugger should stop on this function call, invoke the
       :meth:`user_call` method (which should be overridden in subclasses).
-      Raise a :exc:`BdbQuit` exception if the :attr:`Bdb.quitting` flag is set
+      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
       (which can be set from :meth:`user_call`).  Return a reference to the
       :meth:`trace_dispatch` method for further tracing in that scope.
 
@@ -198,7 +198,7 @@ The :mod:`bdb` module also defines two classes:
 
       If the debugger should stop on this function return, invoke the
       :meth:`user_return` method (which should be overridden in subclasses).
-      Raise a :exc:`BdbQuit` exception if the :attr:`Bdb.quitting` flag is set
+      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
       (which can be set from :meth:`user_return`).  Return a reference to the
       :meth:`trace_dispatch` method for further tracing in that scope.
 
@@ -206,7 +206,7 @@ The :mod:`bdb` module also defines two classes:
 
       If the debugger should stop at this exception, invokes the
       :meth:`user_exception` method (which should be overridden in subclasses).
-      Raise a :exc:`BdbQuit` exception if the :attr:`Bdb.quitting` flag is set
+      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
       (which can be set from :meth:`user_exception`).  Return a reference to the
       :meth:`trace_dispatch` method for further tracing in that scope.
 
@@ -293,7 +293,9 @@ The :mod:`bdb` module also defines two classes:
 
    .. method:: set_quit()
 
-      Set the :attr:`quitting` attribute to ``True``.  This raises :exc:`BdbQuit` in
+      .. index:: single: quitting (bdb.Bdb attribute)
+
+      Set the :attr:`!quitting` attribute to ``True``.  This raises :exc:`BdbQuit` in
       the next call to one of the :meth:`!dispatch_\*` methods.
 
 
@@ -383,7 +385,7 @@ The :mod:`bdb` module also defines two classes:
    .. method:: run(cmd, globals=None, locals=None)
 
       Debug a statement executed via the :func:`exec` function.  *globals*
-      defaults to :attr:`__main__.__dict__`, *locals* defaults to *globals*.
+      defaults to :attr:`!__main__.__dict__`, *locals* defaults to *globals*.
 
    .. method:: runeval(expr, globals=None, locals=None)
 
diff --git a/Doc/library/bz2.rst b/Doc/library/bz2.rst
index 6a95a4a6e8..5e0aa3e493 100644
--- a/Doc/library/bz2.rst
+++ b/Doc/library/bz2.rst
@@ -156,7 +156,6 @@ The :mod:`bz2` module contains:
       Support was added for *filename* being a :term:`file object` instead of an
       actual filename.
 
-   .. versionchanged:: 3.3
       The ``'a'`` (append) mode was added, along with support for reading
       multi-stream files.
 
diff --git a/Doc/library/codecs.rst b/Doc/library/codecs.rst
index 9ce5848747..894986cb73 100644
--- a/Doc/library/codecs.rst
+++ b/Doc/library/codecs.rst
@@ -1542,13 +1542,13 @@ This module implements the ANSI codepage (CP_ACP).
 
 .. availability:: Windows.
 
-.. versionchanged:: 3.3
-   Support any error handler.
-
 .. versionchanged:: 3.2
    Before 3.2, the *errors* argument was ignored; ``'replace'`` was always used
    to encode, and ``'ignore'`` to decode.
 
+.. versionchanged:: 3.3
+   Support any error handler.
+
 
 :mod:`encodings.utf_8_sig` --- UTF-8 codec with BOM signature
 -------------------------------------------------------------
diff --git a/Doc/library/collections.rst b/Doc/library/collections.rst
index 1a3084ef10..6ed2ebb409 100644
--- a/Doc/library/collections.rst
+++ b/Doc/library/collections.rst
@@ -343,7 +343,7 @@ superset relationships: ``==``, ``!=``, ``<``, ``<=``, ``>``, ``>=``.
 All of those tests treat missing elements as having zero counts so that
 ``Counter(a=1) == Counter(a=1, b=0)`` returns true.
 
-.. versionadded:: 3.10
+.. versionchanged:: 3.10
    Rich comparison operations were added.
 
 .. versionchanged:: 3.10
diff --git a/Doc/library/constants.rst b/Doc/library/constants.rst
index 401dc9a320..93a7244f87 100644
--- a/Doc/library/constants.rst
+++ b/Doc/library/constants.rst
@@ -33,27 +33,27 @@ A small number of constants live in the built-in namespace.  They are:
    the other type; may be returned by the in-place binary special methods
    (e.g. :meth:`~object.__imul__`, :meth:`~object.__iand__`, etc.) for the same purpose.
    It should not be evaluated in a boolean context.
-   ``NotImplemented`` is the sole instance of the :data:`types.NotImplementedType` type.
+   :data:`!NotImplemented` is the sole instance of the :data:`types.NotImplementedType` type.
 
    .. note::
 
-      When a binary (or in-place) method returns ``NotImplemented`` the
+      When a binary (or in-place) method returns :data:`!NotImplemented` the
       interpreter will try the reflected operation on the other type (or some
       other fallback, depending on the operator).  If all attempts return
-      ``NotImplemented``, the interpreter will raise an appropriate exception.
-      Incorrectly returning ``NotImplemented`` will result in a misleading
-      error message or the ``NotImplemented`` value being returned to Python code.
+      :data:`!NotImplemented`, the interpreter will raise an appropriate exception.
+      Incorrectly returning :data:`!NotImplemented` will result in a misleading
+      error message or the :data:`!NotImplemented` value being returned to Python code.
 
       See :ref:`implementing-the-arithmetic-operations` for examples.
 
    .. note::
 
-      ``NotImplementedError`` and ``NotImplemented`` are not interchangeable,
+      ``NotImplementedError`` and :data:`!NotImplemented` are not interchangeable,
       even though they have similar names and purposes.
       See :exc:`NotImplementedError` for details on when to use it.
 
    .. versionchanged:: 3.9
-      Evaluating ``NotImplemented`` in a boolean context is deprecated. While
+      Evaluating :data:`!NotImplemented` in a boolean context is deprecated. While
       it currently evaluates as true, it will emit a :exc:`DeprecationWarning`.
       It will raise a :exc:`TypeError` in a future version of Python.
 
diff --git a/Doc/library/ctypes.rst b/Doc/library/ctypes.rst
index f8c0a53e3d..9482497835 100644
--- a/Doc/library/ctypes.rst
+++ b/Doc/library/ctypes.rst
@@ -93,7 +93,6 @@ Accessing functions from loaded dlls
 
 Functions are accessed as attributes of dll objects::
 
-   >>> from ctypes import *
    >>> libc.printf
    <_FuncPtr object at 0x...>
    >>> print(windll.kernel32.GetModuleHandleA)  # doctest: +WINDOWS
@@ -1113,10 +1112,6 @@ api::
    >>> print(hex(version.value))
    0x30c00a0
 
-If the interpreter would have been started with :option:`-O`, the sample would
-have printed ``c_long(1)``, or ``c_long(2)`` if :option:`-OO` would have been
-specified.
-
 An extended example which also demonstrates the use of pointers accesses the
 :c:data:`PyImport_FrozenModules` pointer exported by Python.
 
diff --git a/Doc/library/dataclasses.rst b/Doc/library/dataclasses.rst
index 020818a081..c038d5513a 100644
--- a/Doc/library/dataclasses.rst
+++ b/Doc/library/dataclasses.rst
@@ -1,5 +1,5 @@
-:mod:`dataclasses` --- Data Classes
-===================================
+:mod:`!dataclasses` --- Data Classes
+====================================
 
 .. module:: dataclasses
     :synopsis: Generate special methods on user-defined classes.
@@ -31,7 +31,7 @@ using :pep:`526` type annotations.  For example, this code::
       def total_cost(self) -> float:
           return self.unit_price * self.quantity_on_hand
 
-will add, among other things, a :meth:`~object.__init__` that looks like::
+will add, among other things, a :meth:`!__init__` that looks like::
 
   def __init__(self, name: str, unit_price: float, quantity_on_hand: int = 0):
       self.name = name
@@ -49,26 +49,26 @@ Module contents
 .. decorator:: dataclass(*, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False, weakref_slot=False)
 
    This function is a :term:`decorator` that is used to add generated
-   :term:`special method`\s to classes, as described below.
+   :term:`special methods <special method>` to classes, as described below.
 
-   The :func:`dataclass` decorator examines the class to find
+   The ``@dataclass`` decorator examines the class to find
    ``field``\s.  A ``field`` is defined as a class variable that has a
    :term:`type annotation <variable annotation>`.  With two
-   exceptions described below, nothing in :func:`dataclass`
+   exceptions described below, nothing in ``@dataclass``
    examines the type specified in the variable annotation.
 
    The order of the fields in all of the generated methods is the
    order in which they appear in the class definition.
 
-   The :func:`dataclass` decorator will add various "dunder" methods to
+   The ``@dataclass`` decorator will add various "dunder" methods to
    the class, described below.  If any of the added methods already
    exist in the class, the behavior depends on the parameter, as documented
    below. The decorator returns the same class that it is called on; no new
    class is created.
 
-   If :func:`dataclass` is used just as a simple decorator with no parameters,
+   If ``@dataclass`` is used just as a simple decorator with no parameters,
    it acts as if it has the default values documented in this
-   signature.  That is, these three uses of :func:`dataclass` are
+   signature.  That is, these three uses of ``@dataclass`` are
    equivalent::
 
      @dataclass
@@ -84,12 +84,12 @@ Module contents
      class C:
          ...
 
-   The parameters to :func:`dataclass` are:
+   The parameters to ``@dataclass`` are:
 
    - ``init``: If true (the default), a :meth:`~object.__init__` method will be
      generated.
 
-     If the class already defines :meth:`~object.__init__`, this parameter is
+     If the class already defines :meth:`!__init__`, this parameter is
      ignored.
 
    - ``repr``: If true (the default), a :meth:`~object.__repr__` method will be
@@ -99,7 +99,7 @@ Module contents
      are not included.  For example:
      ``InventoryItem(name='widget', unit_price=3.0, quantity_on_hand=10)``.
 
-     If the class already defines :meth:`~object.__repr__`, this parameter is
+     If the class already defines :meth:`!__repr__`, this parameter is
      ignored.
 
    - ``eq``: If true (the default), an :meth:`~object.__eq__` method will be
@@ -107,7 +107,7 @@ Module contents
      of its fields, in order.  Both instances in the comparison must
      be of the identical type.
 
-     If the class already defines :meth:`~object.__eq__`, this parameter is
+     If the class already defines :meth:`!__eq__`, this parameter is
      ignored.
 
    - ``order``: If true (the default is ``False``), :meth:`~object.__lt__`,
@@ -117,43 +117,43 @@ Module contents
      identical type.  If ``order`` is true and ``eq`` is false, a
      :exc:`ValueError` is raised.
 
-     If the class already defines any of :meth:`~object.__lt__`,
-     :meth:`~object.__le__`, :meth:`~object.__gt__`, or :meth:`~object.__ge__`, then
+     If the class already defines any of :meth:`!__lt__`,
+     :meth:`!__le__`, :meth:`!__gt__`, or :meth:`!__ge__`, then
      :exc:`TypeError` is raised.
 
    - ``unsafe_hash``: If ``False`` (the default), a :meth:`~object.__hash__` method
      is generated according to how ``eq`` and ``frozen`` are set.
 
-     :meth:`~object.__hash__` is used by built-in :meth:`hash()`, and when objects are
+     :meth:`!__hash__` is used by built-in :meth:`hash()`, and when objects are
      added to hashed collections such as dictionaries and sets.  Having a
-     :meth:`~object.__hash__` implies that instances of the class are immutable.
+     :meth:`!__hash__` implies that instances of the class are immutable.
      Mutability is a complicated property that depends on the programmer's
-     intent, the existence and behavior of :meth:`~object.__eq__`, and the values of
-     the ``eq`` and ``frozen`` flags in the :func:`dataclass` decorator.
+     intent, the existence and behavior of :meth:`!__eq__`, and the values of
+     the ``eq`` and ``frozen`` flags in the ``@dataclass`` decorator.
 
-     By default, :func:`dataclass` will not implicitly add a :meth:`~object.__hash__`
+     By default, ``@dataclass`` will not implicitly add a :meth:`~object.__hash__`
      method unless it is safe to do so.  Neither will it add or change an
-     existing explicitly defined :meth:`~object.__hash__` method.  Setting the class
+     existing explicitly defined :meth:`!__hash__` method.  Setting the class
      attribute ``__hash__ = None`` has a specific meaning to Python, as
-     described in the :meth:`~object.__hash__` documentation.
+     described in the :meth:`!__hash__` documentation.
 
-     If :meth:`~object.__hash__` is not explicitly defined, or if it is set to ``None``,
-     then :func:`dataclass` *may* add an implicit :meth:`~object.__hash__` method.
-     Although not recommended, you can force :func:`dataclass` to create a
-     :meth:`~object.__hash__` method with ``unsafe_hash=True``. This might be the case
-     if your class is logically immutable but can nonetheless be mutated.
+     If :meth:`!__hash__` is not explicitly defined, or if it is set to ``None``,
+     then ``@dataclass`` *may* add an implicit :meth:`!__hash__` method.
+     Although not recommended, you can force ``@dataclass`` to create a
+     :meth:`!__hash__` method with ``unsafe_hash=True``. This might be the case
+     if your class is logically immutable but can still be mutated.
      This is a specialized use case and should be considered carefully.
 
-     Here are the rules governing implicit creation of a :meth:`~object.__hash__`
-     method.  Note that you cannot both have an explicit :meth:`~object.__hash__`
+     Here are the rules governing implicit creation of a :meth:`!__hash__`
+     method.  Note that you cannot both have an explicit :meth:`!__hash__`
      method in your dataclass and set ``unsafe_hash=True``; this will result
      in a :exc:`TypeError`.
 
-     If ``eq`` and ``frozen`` are both true, by default :func:`dataclass` will
-     generate a :meth:`~object.__hash__` method for you.  If ``eq`` is true and
-     ``frozen`` is false, :meth:`~object.__hash__` will be set to ``None``, marking it
+     If ``eq`` and ``frozen`` are both true, by default ``@dataclass`` will
+     generate a :meth:`!__hash__` method for you.  If ``eq`` is true and
+     ``frozen`` is false, :meth:`!__hash__` will be set to ``None``, marking it
      unhashable (which it is, since it is mutable).  If ``eq`` is false,
-     :meth:`~object.__hash__` will be left untouched meaning the :meth:`~object.__hash__`
+     :meth:`!__hash__` will be left untouched meaning the :meth:`!__hash__`
      method of the superclass will be used (if the superclass is
      :class:`object`, this means it will fall back to id-based hashing).
 
@@ -165,7 +165,7 @@ Module contents
    - ``match_args``: If true (the default is ``True``), the
      ``__match_args__`` tuple will be created from the list of
      parameters to the generated :meth:`~object.__init__` method (even if
-     :meth:`~object.__init__` is not generated, see above).  If false, or if
+     :meth:`!__init__` is not generated, see above).  If false, or if
      ``__match_args__`` is already defined in the class, then
      ``__match_args__`` will not be generated.
 
@@ -175,7 +175,7 @@ Module contents
      fields will be marked as keyword-only.  If a field is marked as
      keyword-only, then the only effect is that the :meth:`~object.__init__`
      parameter generated from a keyword-only field must be specified
-     with a keyword when :meth:`~object.__init__` is called.  There is no
+     with a keyword when :meth:`!__init__` is called.  There is no
      effect on any other aspect of dataclasses.  See the
      :term:`parameter` glossary entry for details.  Also see the
      :const:`KW_ONLY` section.
@@ -184,7 +184,7 @@ Module contents
 
    - ``slots``: If true (the default is ``False``), :attr:`~object.__slots__` attribute
      will be generated and new class will be returned instead of the original one.
-     If :attr:`~object.__slots__` is already defined in the class, then :exc:`TypeError`
+     If :attr:`!__slots__` is already defined in the class, then :exc:`TypeError`
      is raised.
 
     .. versionadded:: 3.10
@@ -229,7 +229,7 @@ Module contents
    required.  There are, however, some dataclass features that
    require additional per-field information.  To satisfy this need for
    additional information, you can replace the default field value
-   with a call to the provided :func:`field` function.  For example::
+   with a call to the provided :func:`!field` function.  For example::
 
      @dataclass
      class C:
@@ -243,10 +243,10 @@ Module contents
    used because ``None`` is a valid value for some parameters with
    a distinct meaning.  No code should directly use the :const:`MISSING` value.
 
-   The parameters to :func:`field` are:
+   The parameters to :func:`!field` are:
 
    - ``default``: If provided, this will be the default value for this
-     field.  This is needed because the :meth:`field` call itself
+     field.  This is needed because the :func:`!field` call itself
      replaces the normal position of the default value.
 
    - ``default_factory``: If provided, it must be a zero-argument
@@ -293,10 +293,10 @@ Module contents
     .. versionadded:: 3.10
 
    If the default value of a field is specified by a call to
-   :func:`field()`, then the class attribute for this field will be
+   :func:`!field`, then the class attribute for this field will be
    replaced by the specified ``default`` value.  If no ``default`` is
    provided, then the class attribute will be deleted.  The intent is
-   that after the :func:`dataclass` decorator runs, the class
+   that after the :func:`@dataclass <dataclass>` decorator runs, the class
    attributes will all contain the default values for the fields, just
    as if the default value itself were specified.  For example,
    after::
@@ -314,10 +314,10 @@ Module contents
 
 .. class:: Field
 
-   :class:`Field` objects describe each defined field. These objects
+   :class:`!Field` objects describe each defined field. These objects
    are created internally, and are returned by the :func:`fields`
    module-level method (see below).  Users should never instantiate a
-   :class:`Field` object directly.  Its documented attributes are:
+   :class:`!Field` object directly.  Its documented attributes are:
 
    - ``name``: The name of the field.
    - ``type``: The type of the field.
@@ -343,7 +343,7 @@ Module contents
    lists, and tuples are recursed into.  Other objects are copied with
    :func:`copy.deepcopy`.
 
-   Example of using :func:`asdict` on nested dataclasses::
+   Example of using :func:`!asdict` on nested dataclasses::
 
      @dataclass
      class Point:
@@ -364,7 +364,7 @@ Module contents
 
      dict((field.name, getattr(obj, field.name)) for field in fields(obj))
 
-   :func:`asdict` raises :exc:`TypeError` if ``obj`` is not a dataclass
+   :func:`!asdict` raises :exc:`TypeError` if ``obj`` is not a dataclass
    instance.
 
 .. function:: astuple(obj, *, tuple_factory=tuple)
@@ -384,7 +384,7 @@ Module contents
 
      tuple(getattr(obj, field.name) for field in dataclasses.fields(obj))
 
-   :func:`astuple` raises :exc:`TypeError` if ``obj`` is not a dataclass
+   :func:`!astuple` raises :exc:`TypeError` if ``obj`` is not a dataclass
    instance.
 
 .. function:: make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False, weakref_slot=False, module=None)
@@ -397,7 +397,7 @@ Module contents
    ``typing.Any`` is used for ``type``.  The values of ``init``,
    ``repr``, ``eq``, ``order``, ``unsafe_hash``, ``frozen``,
    ``match_args``, ``kw_only``, ``slots``, and ``weakref_slot`` have
-   the same meaning as they do in :func:`dataclass`.
+   the same meaning as they do in :func:`@dataclass <dataclass>`.
 
    If ``module`` is defined, the ``__module__`` attribute
    of the dataclass is set to that value.
@@ -405,7 +405,7 @@ Module contents
 
    This function is not strictly required, because any Python
    mechanism for creating a new class with ``__annotations__`` can
-   then apply the :func:`dataclass` function to convert that class to
+   then apply the ``@dataclass`` function to convert that class to
    a dataclass.  This function is provided as a convenience.  For
    example::
 
@@ -438,15 +438,15 @@ Module contents
    :meth:`__post_init__`, if present, is also called.
 
    Init-only variables without default values, if any exist, must be
-   specified on the call to :func:`replace` so that they can be passed to
-   :meth:`~object.__init__` and :meth:`__post_init__`.
+   specified on the call to :func:`!replace` so that they can be passed to
+   :meth:`!__init__` and :meth:`__post_init__`.
 
    It is an error for ``changes`` to contain any fields that are
    defined as having ``init=False``.  A :exc:`ValueError` will be raised
    in this case.
 
    Be forewarned about how ``init=False`` fields work during a call to
-   :func:`replace`.  They are not copied from the source object, but
+   :func:`!replace`.  They are not copied from the source object, but
    rather are initialized in :meth:`__post_init__`, if they're
    initialized at all.  It is expected that ``init=False`` fields will
    be rarely and judiciously used.  If they are used, it might be wise
@@ -473,11 +473,11 @@ Module contents
 .. data:: KW_ONLY
 
    A sentinel value used as a type annotation.  Any fields after a
-   pseudo-field with the type of :const:`KW_ONLY` are marked as
+   pseudo-field with the type of :const:`!KW_ONLY` are marked as
    keyword-only fields.  Note that a pseudo-field of type
-   :const:`KW_ONLY` is otherwise completely ignored.  This includes the
+   :const:`!KW_ONLY` is otherwise completely ignored.  This includes the
    name of such a field.  By convention, a name of ``_`` is used for a
-   :const:`KW_ONLY` field.  Keyword-only fields signify
+   :const:`!KW_ONLY` field.  Keyword-only fields signify
    :meth:`~object.__init__` parameters that must be specified as keywords when
    the class is instantiated.
 
@@ -493,7 +493,7 @@ Module contents
     p = Point(0, y=1.5, z=2.0)
 
    In a single dataclass, it is an error to specify more than one
-   field whose type is :const:`KW_ONLY`.
+   field whose type is :const:`!KW_ONLY`.
 
    .. versionadded:: 3.10
 
@@ -513,9 +513,9 @@ Post-init processing
    When defined on the class, it will be called by the generated
    :meth:`~object.__init__`, normally as ``self.__post_init__()``.
    However, if any ``InitVar`` fields are defined, they will also be
-   passed to :meth:`__post_init__` in the order they were defined in the
-   class.  If no :meth:`~object.__init__` method is generated, then
-   :meth:`__post_init__` will not automatically be called.
+   passed to :meth:`!__post_init__` in the order they were defined in the
+   class.  If no :meth:`!__init__` method is generated, then
+   :meth:`!__post_init__` will not automatically be called.
 
    Among other uses, this allows for initializing field values that
    depend on one or more other fields.  For example::
@@ -529,8 +529,8 @@ Post-init processing
          def __post_init__(self):
              self.c = self.a + self.b
 
-The :meth:`~object.__init__` method generated by :func:`dataclass` does not call base
-class :meth:`~object.__init__` methods. If the base class has an :meth:`~object.__init__` method
+The :meth:`~object.__init__` method generated by :func:`@dataclass <dataclass>` does not call base
+class :meth:`!__init__` methods. If the base class has an :meth:`!__init__` method
 that has to be called, it is common to call this method in a
 :meth:`__post_init__` method::
 
@@ -546,18 +546,18 @@ that has to be called, it is common to call this method in a
         def __post_init__(self):
             super().__init__(self.side, self.side)
 
-Note, however, that in general the dataclass-generated :meth:`~object.__init__` methods
+Note, however, that in general the dataclass-generated :meth:`!__init__` methods
 don't need to be called, since the derived dataclass will take care of
 initializing all fields of any base class that is a dataclass itself.
 
 See the section below on init-only variables for ways to pass
-parameters to :meth:`__post_init__`.  Also see the warning about how
+parameters to :meth:`!__post_init__`.  Also see the warning about how
 :func:`replace` handles ``init=False`` fields.
 
 Class variables
 ---------------
 
-One of the few places where :func:`dataclass` actually inspects the type
+One of the few places where :func:`@dataclass <dataclass>` actually inspects the type
 of a field is to determine if a field is a class variable as defined
 in :pep:`526`.  It does this by checking if the type of the field is
 ``typing.ClassVar``.  If a field is a ``ClassVar``, it is excluded
@@ -568,7 +568,7 @@ module-level :func:`fields` function.
 Init-only variables
 -------------------
 
-Another place where :func:`dataclass` inspects a type annotation is to
+Another place where :func:`@dataclass <dataclass>` inspects a type annotation is to
 determine if a field is an init-only variable.  It does this by seeing
 if the type of a field is of type ``dataclasses.InitVar``.  If a field
 is an ``InitVar``, it is considered a pseudo-field called an init-only
@@ -600,19 +600,19 @@ Frozen instances
 ----------------
 
 It is not possible to create truly immutable Python objects.  However,
-by passing ``frozen=True`` to the :meth:`dataclass` decorator you can
+by passing ``frozen=True`` to the :func:`@dataclass <dataclass>` decorator you can
 emulate immutability.  In that case, dataclasses will add
 :meth:`~object.__setattr__` and :meth:`~object.__delattr__` methods to the class.  These
 methods will raise a :exc:`FrozenInstanceError` when invoked.
 
 There is a tiny performance penalty when using ``frozen=True``:
 :meth:`~object.__init__` cannot use simple assignment to initialize fields, and
-must use :meth:`!object.__setattr__`.
+must use :meth:`!__setattr__`.
 
 Inheritance
 -----------
 
-When the dataclass is being created by the :meth:`dataclass` decorator,
+When the dataclass is being created by the :func:`@dataclass <dataclass>` decorator,
 it looks through all of the class's base classes in reverse MRO (that
 is, starting at :class:`object`) and, for each dataclass that it finds,
 adds the fields from that base class to an ordered mapping of fields.
@@ -639,8 +639,8 @@ The generated :meth:`~object.__init__` method for ``C`` will look like::
 
   def __init__(self, x: int = 15, y: int = 0, z: int = 10):
 
-Re-ordering of keyword-only parameters in :meth:`~object.__init__`
-------------------------------------------------------------------
+Re-ordering of keyword-only parameters in :meth:`!__init__`
+-----------------------------------------------------------
 
 After the parameters needed for :meth:`~object.__init__` are computed, any
 keyword-only parameters are moved to come after all regular
@@ -663,7 +663,7 @@ fields, and ``Base.x`` and ``D.z`` are regular fields::
       z: int = 10
       t: int = field(kw_only=True, default=0)
 
-The generated :meth:`~object.__init__` method for ``D`` will look like::
+The generated :meth:`!__init__` method for ``D`` will look like::
 
   def __init__(self, x: Any = 15.0, z: int = 10, *, y: int = 0, w: int = 1, t: int = 0):
 
@@ -672,7 +672,7 @@ the list of fields: parameters derived from regular fields are
 followed by parameters derived from keyword-only fields.
 
 The relative ordering of keyword-only parameters is maintained in the
-re-ordered :meth:`~object.__init__` parameter list.
+re-ordered :meth:`!__init__` parameter list.
 
 
 Default factory functions
@@ -687,7 +687,7 @@ example, to create a new instance of a list, use::
 If a field is excluded from :meth:`~object.__init__` (using ``init=False``)
 and the field also specifies ``default_factory``, then the default
 factory function will always be called from the generated
-:meth:`~object.__init__` function.  This happens because there is no other
+:meth:`!__init__` function.  This happens because there is no other
 way to give the field an initial value.
 
 Mutable default values
@@ -717,7 +717,7 @@ Using dataclasses, *if* this code was valid::
   class D:
       x: list = []      # This code raises ValueError
       def add(self, element):
-          self.x += element
+          self.x.append(element)
 
 it would generate code similar to::
 
@@ -726,7 +726,7 @@ it would generate code similar to::
       def __init__(self, x=x):
           self.x = x
       def add(self, element):
-          self.x += element
+          self.x.append(element)
 
   assert D().x is D().x
 
@@ -736,7 +736,7 @@ for ``x`` when creating a class instance will share the same copy
 of ``x``.  Because dataclasses just use normal Python class
 creation they also share this behavior.  There is no general way
 for Data Classes to detect this condition.  Instead, the
-:func:`dataclass` decorator will raise a :exc:`ValueError` if it
+:func:`@dataclass <dataclass>` decorator will raise a :exc:`ValueError` if it
 detects an unhashable default parameter.  The assumption is that if
 a value is unhashable, it is mutable.  This is a partial solution,
 but it does protect against many common errors.
@@ -762,15 +762,17 @@ Descriptor-typed fields
 Fields that are assigned :ref:`descriptor objects <descriptors>` as their
 default value have the following special behaviors:
 
-* The value for the field passed to the dataclass's ``__init__`` method is
-  passed to the descriptor's ``__set__`` method rather than overwriting the
+* The value for the field passed to the dataclass's :meth:`~object.__init__` method is
+  passed to the descriptor's :meth:`~object.__set__` method rather than overwriting the
   descriptor object.
+
 * Similarly, when getting or setting the field, the descriptor's
-  ``__get__`` or ``__set__`` method is called rather than returning or
+  :meth:`~object.__get__` or :meth:`!__set__` method is called rather than returning or
   overwriting the descriptor object.
-* To determine whether a field contains a default value, ``dataclasses``
-  will call the descriptor's ``__get__`` method using its class access
-  form (i.e. ``descriptor.__get__(obj=None, type=cls)``.  If the
+
+* To determine whether a field contains a default value, :func:`@dataclass <dataclass>`
+  will call the descriptor's :meth:`!__get__` method using its class access
+  form: ``descriptor.__get__(obj=None, type=cls)``.  If the
   descriptor returns a value in this case, it will be used as the
   field's default. On the other hand, if the descriptor raises
   :exc:`AttributeError` in this situation, no default value will be
diff --git a/Doc/library/datetime.rst b/Doc/library/datetime.rst
index daf023f320..3a7fe4676a 100644
--- a/Doc/library/datetime.rst
+++ b/Doc/library/datetime.rst
@@ -1193,6 +1193,9 @@ Supported operations:
    that are not also :class:`!datetime` instances, even if they represent
    the same date.
 
+   If both comparands are aware, and have the same :attr:`!tzinfo` attribute,
+   the :attr:`!tzinfo` and :attr:`~.datetime.fold` attributes are ignored and
+   the base datetimes are compared.
    If both comparands are aware and have different :attr:`~.datetime.tzinfo`
    attributes, the comparison acts as comparands were first converted to UTC
    datetimes except that the implementation never overflows.
@@ -1207,6 +1210,9 @@ Supported operations:
    as well as a :class:`!datetime` object and a :class:`!date` object
    that is not also a :class:`!datetime` instance, raises :exc:`TypeError`.
 
+   If both comparands are aware, and have the same :attr:`!tzinfo` attribute,
+   the :attr:`!tzinfo` and :attr:`~.datetime.fold` attributes are ignored and
+   the base datetimes are compared.
    If both comparands are aware and have different :attr:`~.datetime.tzinfo`
    attributes, the comparison acts as comparands were first converted to UTC
    datetimes except that the implementation never overflows.
@@ -1752,8 +1758,8 @@ Naive and aware :class:`!time` objects are never equal.
 Order comparison between naive and aware :class:`!time` objects raises
 :exc:`TypeError`.
 
-If both comparands are aware, and have
-the same :attr:`~.time.tzinfo` attribute, the common :attr:`!tzinfo` attribute is
+If both comparands are aware, and have the same :attr:`~.time.tzinfo`
+attribute, the :attr:`!tzinfo` and :attr:`!fold` attributes are
 ignored and the base times are compared. If both comparands are aware and
 have different :attr:`!tzinfo` attributes, the comparands are first adjusted by
 subtracting their UTC offsets (obtained from ``self.utcoffset()``).
@@ -1785,7 +1791,7 @@ Other constructor:
       be truncated).
    4. Fractional hours and minutes are not supported.
 
-   Examples::
+   Examples:
 
    .. doctest::
 
diff --git a/Doc/library/dbm.rst b/Doc/library/dbm.rst
index 413d244617..74f96b6c43 100644
--- a/Doc/library/dbm.rst
+++ b/Doc/library/dbm.rst
@@ -56,10 +56,6 @@ the Oracle Berkeley DB.
    The Unix file access mode of the file (default: octal ``0o666``),
    used only when the database has to be created.
 
-.. |incompat_note| replace::
-   The file formats created by :mod:`dbm.gnu` and :mod:`dbm.ndbm` are incompatible
-   and can not be used interchangeably.
-
 .. function:: open(file, flag='r', mode=0o666)
 
    Open a database and return the corresponding database object.
@@ -160,11 +156,10 @@ The :mod:`dbm.gnu` module provides an interface to the :abbr:`GDBM (GNU dbm)`
 library, similar to the :mod:`dbm.ndbm` module, but with additional
 functionality like crash tolerance.
 
-:class:`!gdbm` objects behave similar to :term:`mappings <mapping>`,
-except that keys and values are always converted to :class:`bytes` before storing,
-and the :meth:`!items` and :meth:`!values` methods are not supported.
+.. note::
 
-.. note:: |incompat_note|
+   The file formats created by :mod:`dbm.gnu` and :mod:`dbm.ndbm` are incompatible
+   and can not be used interchangeably.
 
 .. exception:: error
 
@@ -211,8 +206,9 @@ and the :meth:`!items` and :meth:`!values` methods are not supported.
 
       A string of characters the *flag* parameter of :meth:`~dbm.gnu.open` supports.
 
-   In addition to the dictionary-like methods, :class:`gdbm` objects have the
-   following methods and attributes:
+   :class:`!gdbm` objects behave similar to :term:`mappings <mapping>`,
+   but :meth:`!items` and :meth:`!values` methods are not supported.
+   The following methods are also provided:
 
    .. method:: gdbm.firstkey()
 
@@ -263,14 +259,13 @@ and the :meth:`!items` and :meth:`!values` methods are not supported.
 
 The :mod:`dbm.ndbm` module provides an interface to the
 :abbr:`NDBM (New Database Manager)` library.
-:class:`!ndbm` objects behave similar to :term:`mappings <mapping>`,
-except that keys and values are always stored as :class:`bytes`,
-and the :meth:`!items` and :meth:`!values` methods are not supported.
-
 This module can be used with the "classic" NDBM interface or the
 :abbr:`GDBM (GNU dbm)` compatibility interface.
 
-.. note:: |incompat_note|
+.. note::
+
+   The file formats created by :mod:`dbm.gnu` and :mod:`dbm.ndbm` are incompatible
+   and can not be used interchangeably.
 
 .. warning::
 
@@ -308,8 +303,9 @@ This module can be used with the "classic" NDBM interface or the
    :param int mode:
       |mode_param_doc|
 
-   In addition to the dictionary-like methods, :class:`!ndbm` objects
-   provide the following method:
+   :class:`!ndbm` objects behave similar to :term:`mappings <mapping>`,
+   but :meth:`!items` and :meth:`!values` methods are not supported.
+   The following methods are also provided:
 
    .. versionchanged:: 3.11
       Accepts :term:`path-like object` for filename.
@@ -342,8 +338,6 @@ The :mod:`dbm.dumb` module provides a persistent :class:`dict`-like
 interface which is written entirely in Python.
 Unlike other :mod:`dbm` backends, such as :mod:`dbm.gnu`, no
 external library is required.
-As with other :mod:`dbm` backends,
-the keys and values are always stored as :class:`bytes`.
 
 The :mod:`!dbm.dumb` module defines the following:
 
diff --git a/Doc/library/decimal.rst b/Doc/library/decimal.rst
index 08bbb7ff58..4d99c6d927 100644
--- a/Doc/library/decimal.rst
+++ b/Doc/library/decimal.rst
@@ -1517,7 +1517,7 @@ are also included in the pure Python version for compatibility.
    the C version uses a thread-local rather than a coroutine-local context and the value
    is ``False``.  This is slightly faster in some nested context scenarios.
 
-.. versionadded:: 3.9 backported to 3.7 and 3.8.
+.. versionadded:: 3.8.3
 
 
 Rounding modes
diff --git a/Doc/library/dis.rst b/Doc/library/dis.rst
index abcc3cde23..2dd11e0389 100644
--- a/Doc/library/dis.rst
+++ b/Doc/library/dis.rst
@@ -1116,7 +1116,7 @@ iterations of the loop.
    except that ``namei`` is shifted left by 2 bits instead of 1.
 
    The low bit of ``namei`` signals to attempt a method load, as with
-   :opcode:`LOAD_ATTR`, which results in pushing ``None`` and the loaded method.
+   :opcode:`LOAD_ATTR`, which results in pushing ``NULL`` and the loaded method.
    When it is unset a single value is pushed to the stack.
 
    The second-low bit of ``namei``, if set, means that this was a two-argument
diff --git a/Doc/library/enum.rst b/Doc/library/enum.rst
index 3b874594b1..bc5b3d7cd4 100644
--- a/Doc/library/enum.rst
+++ b/Doc/library/enum.rst
@@ -170,7 +170,7 @@ Data Types
    final *enum*, as well as creating the enum members, properly handling
    duplicates, providing iteration over the enum class, etc.
 
-   .. method:: EnumType.__call__(cls, value, names=None, \*, module=None, qualname=None, type=None, start=1, boundary=None)
+   .. method:: EnumType.__call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None)
 
       This method is called in two different ways:
 
@@ -235,6 +235,10 @@ Data Types
         >>> len(Color)
         3
 
+   .. attribute:: EnumType.__members__
+
+      Returns a mapping of every enum name to its member, including aliases
+
    .. method:: EnumType.__reversed__(cls)
 
       Returns each member in *cls* in reverse definition order::
@@ -265,6 +269,8 @@ Data Types
          >>> Color.RED.value
          1
 
+      Value of the member, can be set in :meth:`~object.__new__`.
+
       .. note:: Enum member values
 
          Member values can be anything: :class:`int`, :class:`str`, etc.  If
@@ -272,6 +278,24 @@ Data Types
          appropriate value will be chosen for you.  See :class:`auto` for the
          details.
 
+         While mutable/unhashable values, such as :class:`dict`, :class:`list` or
+         a mutable :class:`~dataclasses.dataclass`, can be used, they will have a
+         quadratic performance impact during creation relative to the
+         total number of mutable/unhashable values in the enum.
+
+   .. attribute:: Enum._name_
+
+      Name of the member.
+
+   .. attribute:: Enum._value_
+
+      Value of the member, can be set in :meth:`~object.__new__`.
+
+   .. attribute:: Enum._order_
+
+      No longer used, kept for backward compatibility.
+      (class attribute, removed during class creation).
+
    .. attribute:: Enum._ignore_
 
       ``_ignore_`` is only used during creation and is removed from the
@@ -323,7 +347,18 @@ Data Types
          >>> PowersOfThree.SECOND.value
          9
 
-   .. method:: Enum.__init_subclass__(cls, \**kwds)
+   .. method:: Enum.__init__(self, *args, **kwds)
+
+      By default, does nothing.  If multiple values are given in the member
+      assignment, those values become separate arguments to ``__init__``; e.g.
+
+         >>> from enum import Enum
+         >>> class Weekday(Enum):
+         ...     MONDAY = 1, 'Mon'
+
+      ``Weekday.__init__()`` would be called as ``Weekday.__init__(self, 1, 'Mon')``
+
+   .. method:: Enum.__init_subclass__(cls, **kwds)
 
       A *classmethod* that is used to further configure subsequent subclasses.
       By default, does nothing.
@@ -350,6 +385,21 @@ Data Types
          >>> Build('deBUG')
          <Build.DEBUG: 'debug'>
 
+   .. method:: Enum.__new__(cls, *args, **kwds)
+
+      By default, doesn't exist.  If specified, either in the enum class
+      definition or in a mixin class (such as ``int``), all values given
+      in the member assignment will be passed; e.g.
+
+         >>> from enum import Enum
+         >>> class MyIntEnum(Enum):
+         ...     SEVENTEEN = '1a', 16
+
+      results in the call ``int('1a', 16)`` and a value of ``17`` for the member.
+
+      ..note:: When writing a custom ``__new__``, do not use ``super().__new__`` --
+               call the appropriate ``__new__`` instead.
+
    .. method:: Enum.__repr__(self)
 
       Returns the string used for *repr()* calls.  By default, returns the
@@ -463,9 +513,9 @@ Data Types
 
 .. class:: Flag
 
-   *Flag* members support the bitwise operators ``&`` (*AND*), ``|`` (*OR*),
-   ``^`` (*XOR*), and ``~`` (*INVERT*); the results of those operators are members
-   of the enumeration.
+   ``Flag`` is the same as :class:`Enum`, but its members support the bitwise
+   operators ``&`` (*AND*), ``|`` (*OR*), ``^`` (*XOR*), and ``~`` (*INVERT*);
+   the results of those operators are members of the enumeration.
 
    .. method:: __contains__(self, value)
 
@@ -497,9 +547,7 @@ Data Types
          >>> list(purple)
          [<Color.RED: 1>, <Color.BLUE: 4>]
 
-      .. versionchanged:: 3.11
-
-         Aliases are no longer returned during iteration.
+      .. versionadded:: 3.11
 
    .. method:: __len__(self):
 
@@ -777,18 +825,17 @@ all the members are created it is no longer used.
 Supported ``_sunder_`` names
 """"""""""""""""""""""""""""
 
-- ``_name_`` -- name of the member
-- ``_value_`` -- value of the member; can be set / modified in ``__new__``
-
-- ``_missing_`` -- a lookup function used when a value is not found; may be
-  overridden
-- ``_ignore_`` -- a list of names, either as a :class:`list` or a :class:`str`,
-  that will not be transformed into members, and will be removed from the final
-  class
-- ``_order_`` -- used in Python 2/3 code to ensure member order is consistent
-  (class attribute, removed during class creation)
-- ``_generate_next_value_`` -- used to get an appropriate value for an enum
-  member; may be overridden
+- :attr:`~Enum._name_` -- name of the member
+- :attr:`~Enum._value_` -- value of the member; can be set in ``__new__``
+- :meth:`~Enum._missing_` -- a lookup function used when a value is not found;
+  may be overridden
+- :attr:`~Enum._ignore_` -- a list of names, either as a :class:`list` or a
+  :class:`str`, that will not be transformed into members, and will be removed
+  from the final class
+- :attr:`~Enum._order_` -- no longer used, kept for backward
+  compatibility (class attribute, removed during class creation)
+- :meth:`~Enum._generate_next_value_` -- used to get an appropriate value for
+  an enum member; may be overridden
 
   .. note::
 
diff --git a/Doc/library/exceptions.rst b/Doc/library/exceptions.rst
index eed0ad18b9..60600b2436 100644
--- a/Doc/library/exceptions.rst
+++ b/Doc/library/exceptions.rst
@@ -335,9 +335,9 @@ The following exceptions are the exceptions that are usually raised.
 
    .. note::
 
-      ``NotImplementedError`` and ``NotImplemented`` are not interchangeable,
+      ``NotImplementedError`` and :data:`NotImplemented` are not interchangeable,
       even though they have similar names and purposes.  See
-      :data:`NotImplemented` for details on when to use it.
+      :data:`!NotImplemented` for details on when to use it.
 
 .. exception:: OSError([arg])
                OSError(errno, strerror[, filename[, winerror[, filename2]]])
diff --git a/Doc/library/faulthandler.rst b/Doc/library/faulthandler.rst
index f64dfeb5e0..96593ee97a 100644
--- a/Doc/library/faulthandler.rst
+++ b/Doc/library/faulthandler.rst
@@ -118,12 +118,12 @@ Dumping the tracebacks after a timeout
 
    This function is implemented using a watchdog thread.
 
-   .. versionchanged:: 3.7
-      This function is now always available.
-
    .. versionchanged:: 3.5
       Added support for passing file descriptor to this function.
 
+   .. versionchanged:: 3.7
+      This function is now always available.
+
 .. function:: cancel_dump_traceback_later()
 
    Cancel the last call to :func:`dump_traceback_later`.
diff --git a/Doc/library/fcntl.rst b/Doc/library/fcntl.rst
index 309ad652d4..4e083e122b 100644
--- a/Doc/library/fcntl.rst
+++ b/Doc/library/fcntl.rst
@@ -13,10 +13,10 @@
 
 ----------------
 
-This module performs file control and I/O control on file descriptors. It is an
-interface to the :c:func:`fcntl` and :c:func:`ioctl` Unix routines.  For a
-complete description of these calls, see :manpage:`fcntl(2)` and
-:manpage:`ioctl(2)` Unix manual pages.
+This module performs file and I/O control on file descriptors. It is an
+interface to the :c:func:`fcntl` and :c:func:`ioctl` Unix routines.
+See the :manpage:`fcntl(2)` and :manpage:`ioctl(2)` Unix manual pages
+for full details.
 
 .. availability:: Unix, not Emscripten, not WASI.
 
@@ -80,7 +80,7 @@ The module defines the following functions:
    most likely to result in a segmentation violation or a more subtle data
    corruption.
 
-   If the :c:func:`fcntl` fails, an :exc:`OSError` is raised.
+   If the :c:func:`fcntl` call fails, an :exc:`OSError` is raised.
 
    .. audit-event:: fcntl.fcntl fd,cmd,arg fcntl.fcntl
 
@@ -118,7 +118,7 @@ The module defines the following functions:
    buffer 1024 bytes long which is then passed to :func:`ioctl` and copied back
    into the supplied buffer.
 
-   If the :c:func:`ioctl` fails, an :exc:`OSError` exception is raised.
+   If the :c:func:`ioctl` call fails, an :exc:`OSError` exception is raised.
 
    An example::
 
@@ -143,7 +143,7 @@ The module defines the following functions:
    :manpage:`flock(2)` for details.  (On some systems, this function is emulated
    using :c:func:`fcntl`.)
 
-   If the :c:func:`flock` fails, an :exc:`OSError` exception is raised.
+   If the :c:func:`flock` call fails, an :exc:`OSError` exception is raised.
 
    .. audit-event:: fcntl.flock fd,operation fcntl.flock
 
@@ -155,17 +155,28 @@ The module defines the following functions:
    method are accepted as well) of the file to lock or unlock, and *cmd*
    is one of the following values:
 
-   * :const:`LOCK_UN` -- unlock
-   * :const:`LOCK_SH` -- acquire a shared lock
-   * :const:`LOCK_EX` -- acquire an exclusive lock
+   .. data:: LOCK_UN
 
-   When *cmd* is :const:`LOCK_SH` or :const:`LOCK_EX`, it can also be
-   bitwise ORed with :const:`LOCK_NB` to avoid blocking on lock acquisition.
-   If :const:`LOCK_NB` is used and the lock cannot be acquired, an
+      Release an existing lock.
+
+   .. data:: LOCK_SH
+
+      Acquire a shared lock.
+
+   .. data:: LOCK_EX
+
+      Acquire an exclusive lock.
+
+   .. data:: LOCK_NB
+
+      Bitwise OR with any of the other three ``LOCK_*`` constants to make
+      the request non-blocking.
+
+   If :const:`!LOCK_NB` is used and the lock cannot be acquired, an
    :exc:`OSError` will be raised and the exception will have an *errno*
-   attribute set to :const:`EACCES` or :const:`EAGAIN` (depending on the
+   attribute set to :const:`~errno.EACCES` or :const:`~errno.EAGAIN` (depending on the
    operating system; for portability, check for both values).  On at least some
-   systems, :const:`LOCK_EX` can only be used if the file descriptor refers to a
+   systems, :const:`!LOCK_EX` can only be used if the file descriptor refers to a
    file opened for writing.
 
    *len* is the number of bytes to lock, *start* is the byte offset at
diff --git a/Doc/library/ftplib.rst b/Doc/library/ftplib.rst
index 2f98a272c2..8d1aae018a 100644
--- a/Doc/library/ftplib.rst
+++ b/Doc/library/ftplib.rst
@@ -104,7 +104,7 @@ FTP objects
    :param timeout:
       A timeout in seconds for blocking operations like :meth:`connect`
       (default: the global default timeout setting).
-   :type timeout: int | None
+   :type timeout: float | None
 
    :param source_address:
       |param_doc_source_address|
@@ -178,7 +178,7 @@ FTP objects
       :param timeout:
          A timeout in seconds for the connection attempt
          (default: the global default timeout setting).
-      :type timeout: int | None
+      :type timeout: float | None
 
       :param source_address:
          |param_doc_source_address|
@@ -232,8 +232,8 @@ FTP objects
    .. method:: FTP.voidcmd(cmd)
 
       Send a simple command string to the server and handle the response.  Return
-      nothing if a response code corresponding to success (codes in the range
-      200--299) is received.  Raise :exc:`error_reply` otherwise.
+      the response string if the response code corresponds to success (codes in
+      the range 200--299).  Raise :exc:`error_reply` otherwise.
 
       .. audit-event:: ftplib.sendcmd self,cmd ftplib.FTP.voidcmd
 
@@ -483,7 +483,7 @@ FTP_TLS objects
    :param timeout:
       A timeout in seconds for blocking operations like :meth:`~FTP.connect`
       (default: the global default timeout setting).
-   :type timeout: int | None
+   :type timeout: float | None
 
    :param source_address:
       |param_doc_source_address|
diff --git a/Doc/library/functions.rst b/Doc/library/functions.rst
index fd16763b81..fdc960c01d 100644
--- a/Doc/library/functions.rst
+++ b/Doc/library/functions.rst
@@ -1569,6 +1569,16 @@ are always available.  They are listed here in alphabetical order.
    If :func:`sys.displayhook` is not accessible, this function will raise
    :exc:`RuntimeError`.
 
+   This class has a custom representation that can be evaluated::
+
+      class Person:
+         def __init__(self, name, age):
+            self.name = name
+            self.age = age
+
+         def __repr__(self):
+            return f"Person('{self.name}', {self.age})"
+
 
 .. function:: reversed(seq)
 
diff --git a/Doc/library/functools.rst b/Doc/library/functools.rst
index 724caa68dd..7e8ef4663e 100644
--- a/Doc/library/functools.rst
+++ b/Doc/library/functools.rst
@@ -665,13 +665,9 @@ The :mod:`functools` module defines the following functions:
    on the wrapper function). :exc:`AttributeError` is still raised if the
    wrapper function itself is missing any attributes named in *updated*.
 
-   .. versionadded:: 3.2
-      Automatic addition of the ``__wrapped__`` attribute.
-
-   .. versionadded:: 3.2
-      Copying of the ``__annotations__`` attribute by default.
-
    .. versionchanged:: 3.2
+      The ``__wrapped__`` attribute is now automatically added.
+      The ``__annotations__`` attribute is now copied by default.
       Missing attributes no longer trigger an :exc:`AttributeError`.
 
    .. versionchanged:: 3.4
diff --git a/Doc/library/hashlib.rst b/Doc/library/hashlib.rst
index eb650c180d..34f0dbdfab 100644
--- a/Doc/library/hashlib.rst
+++ b/Doc/library/hashlib.rst
@@ -77,8 +77,6 @@ accessible by name via :func:`new`.  See :data:`algorithms_available`.
    SHA3 (Keccak) and SHAKE constructors :func:`sha3_224`, :func:`sha3_256`,
    :func:`sha3_384`, :func:`sha3_512`, :func:`shake_128`, :func:`shake_256`
    were added.
-
-.. versionadded:: 3.6
    :func:`blake2b` and :func:`blake2s` were added.
 
 .. _hashlib-usedforsecurity:
@@ -121,7 +119,7 @@ More condensed:
 Constructors
 ------------
 
-.. function:: new(name[, data], \*, usedforsecurity=True)
+.. function:: new(name[, data], *, usedforsecurity=True)
 
    Is a generic constructor that takes the string *name* of the desired
    algorithm as its first parameter.  It also exists to allow access to the
diff --git a/Doc/library/http.cookiejar.rst b/Doc/library/http.cookiejar.rst
index 12a6d76843..2fe188be64 100644
--- a/Doc/library/http.cookiejar.rst
+++ b/Doc/library/http.cookiejar.rst
@@ -649,6 +649,11 @@ internal consistency, so you should know what you're doing if you do that.
    :const:`None`.
 
 
+.. attribute:: Cookie.domain
+
+   Cookie domain (a string).
+
+
 .. attribute:: Cookie.path
 
    Cookie path (a string, eg. ``'/acme/rocket_launchers'``).
diff --git a/Doc/library/http.server.rst b/Doc/library/http.server.rst
index eb3a6a87a1..e6d3bb45ef 100644
--- a/Doc/library/http.server.rst
+++ b/Doc/library/http.server.rst
@@ -507,6 +507,12 @@ the ``--cgi`` option::
 
         python -m http.server --cgi
 
+.. warning::
+
+   :class:`CGIHTTPRequestHandler` and the ``--cgi`` command line option
+   are not intended for use by untrusted clients and may be vulnerable
+   to exploitation. Always use within a secure environment.
+
 .. _http.server-security:
 
 Security Considerations
diff --git a/Doc/library/idle.rst b/Doc/library/idle.rst
index 249dc0ea6b..17a5144b4c 100644
--- a/Doc/library/idle.rst
+++ b/Doc/library/idle.rst
@@ -604,7 +604,7 @@ in an editor window.
 The editing features described in previous subsections work when entering
 code interactively.  IDLE's Shell window also responds to the following:
 
-* :kbd:`C-c` attemps to interrupt statement execution (but may fail).
+* :kbd:`C-c` attempts to interrupt statement execution (but may fail).
 
 * :kbd:`C-d` closes Shell if typed at a ``>>>`` prompt.
 
diff --git a/Doc/library/imaplib.rst b/Doc/library/imaplib.rst
index 1f774e64b0..b16275fc14 100644
--- a/Doc/library/imaplib.rst
+++ b/Doc/library/imaplib.rst
@@ -622,7 +622,7 @@ retrieves and prints all messages::
 
    import getpass, imaplib
 
-   M = imaplib.IMAP4()
+   M = imaplib.IMAP4(host='example.org')
    M.login(getpass.getuser(), getpass.getpass())
    M.select()
    typ, data = M.search(None, 'ALL')
diff --git a/Doc/library/importlib.metadata.rst b/Doc/library/importlib.metadata.rst
index d2cc769e2c..9abd516239 100644
--- a/Doc/library/importlib.metadata.rst
+++ b/Doc/library/importlib.metadata.rst
@@ -217,7 +217,6 @@ all the metadata in a JSON-compatible form per :PEP:`566`::
    The ``Description`` is now included in the metadata when presented
    through the payload. Line continuation characters have been removed.
 
-.. versionadded:: 3.10
    The ``json`` attribute was added.
 
 
diff --git a/Doc/library/importlib.rst b/Doc/library/importlib.rst
index 2402bc5cd3..d92bb2f8e5 100644
--- a/Doc/library/importlib.rst
+++ b/Doc/library/importlib.rst
@@ -265,7 +265,7 @@ ABC hierarchy::
       when invalidating the caches of all finders on :data:`sys.meta_path`.
 
       .. versionchanged:: 3.4
-         Returns ``None`` when called instead of ``NotImplemented``.
+         Returns ``None`` when called instead of :data:`NotImplemented`.
 
 
 .. class:: PathEntryFinder
diff --git a/Doc/library/inspect.rst b/Doc/library/inspect.rst
index a1178cfccd..698a3e92b3 100644
--- a/Doc/library/inspect.rst
+++ b/Doc/library/inspect.rst
@@ -55,6 +55,11 @@ attributes (see :ref:`import-mod-attrs` for module attributes):
 |           | __module__        | name of module in which   |
 |           |                   | this class was defined    |
 +-----------+-------------------+---------------------------+
+|           | __type_params__   | A tuple containing the    |
+|           |                   | :ref:`type parameters     |
+|           |                   | <type-params>` of         |
+|           |                   | a generic class           |
++-----------+-------------------+---------------------------+
 | method    | __doc__           | documentation string      |
 +-----------+-------------------+---------------------------+
 |           | __name__          | name with which this      |
@@ -103,6 +108,11 @@ attributes (see :ref:`import-mod-attrs` for module attributes):
 |           |                   | reserved for return       |
 |           |                   | annotations.              |
 +-----------+-------------------+---------------------------+
+|           | __type_params__   | A tuple containing the    |
+|           |                   | :ref:`type parameters     |
+|           |                   | <type-params>` of         |
+|           |                   | a generic function        |
++-----------+-------------------+---------------------------+
 |           | __module__        | name of module in which   |
 |           |                   | this function was defined |
 +-----------+-------------------+---------------------------+
@@ -655,9 +665,6 @@ function.
    Accepts a wide range of Python callables, from plain functions and classes to
    :func:`functools.partial` objects.
 
-   If the passed object has a ``__signature__`` attribute, this function
-   returns it without further computations.
-
    For objects defined in modules using stringized annotations
    (``from __future__ import annotations``), :func:`signature` will
    attempt to automatically un-stringize the annotations using
@@ -692,6 +699,13 @@ function.
       Python.  For example, in CPython, some built-in functions defined in
       C provide no metadata about their arguments.
 
+   .. impl-detail::
+
+      If the passed object has a :attr:`!__signature__` attribute,
+      we may use it to create the signature.
+      The exact semantics are an implementation detail and are subject to
+      unannounced changes. Consult the source code for current semantics.
+
 
 .. class:: Signature(parameters=None, *, return_annotation=Signature.empty)
 
diff --git a/Doc/library/ipaddress.rst b/Doc/library/ipaddress.rst
index 9c2dff5570..03dc956cd1 100644
--- a/Doc/library/ipaddress.rst
+++ b/Doc/library/ipaddress.rst
@@ -121,22 +121,12 @@ write code that handles both IP versions correctly.  Address objects are
       Leading zeros are tolerated, even in ambiguous cases that look like
       octal notation.
 
-   .. versionchanged:: 3.10
+   .. versionchanged:: 3.9.5
 
       Leading zeros are no longer tolerated and are treated as an error.
       IPv4 address strings are now parsed as strict as glibc
       :func:`~socket.inet_pton`.
 
-   .. versionchanged:: 3.9.5
-
-      The above change was also included in Python 3.9 starting with
-      version 3.9.5.
-
-   .. versionchanged:: 3.8.12
-
-      The above change was also included in Python 3.8 starting with
-      version 3.8.12.
-
    .. attribute:: version
 
       The appropriate version number: ``4`` for IPv4, ``6`` for IPv6.
diff --git a/Doc/library/itertools.rst b/Doc/library/itertools.rst
index 67dc8f6d87..09e04a39a1 100644
--- a/Doc/library/itertools.rst
+++ b/Doc/library/itertools.rst
@@ -41,9 +41,9 @@ operator can be mapped across two vectors to form an efficient dot-product:
 ==================  =================       =================================================               =========================================
 Iterator            Arguments               Results                                                         Example
 ==================  =================       =================================================               =========================================
-:func:`count`       [start[, step]]         start, start+step, start+2*step, ...                            ``count(10) --> 10 11 12 13 14 ...``
-:func:`cycle`       p                       p0, p1, ... plast, p0, p1, ...                                  ``cycle('ABCD') --> A B C D A B C D ...``
-:func:`repeat`      elem [,n]               elem, elem, elem, ... endlessly or up to n times                ``repeat(10, 3) --> 10 10 10``
+:func:`count`       [start[, step]]         start, start+step, start+2*step, ...                            ``count(10)  10 11 12 13 14 ...``
+:func:`cycle`       p                       p0, p1, ... plast, p0, p1, ...                                  ``cycle('ABCD')  A B C D A B C D ...``
+:func:`repeat`      elem [,n]               elem, elem, elem, ... endlessly or up to n times                ``repeat(10, 3)  10 10 10``
 ==================  =================       =================================================               =========================================
 
 **Iterators terminating on the shortest input sequence:**
@@ -51,20 +51,20 @@ Iterator            Arguments               Results
 ============================    ============================    =================================================   =============================================================
 Iterator                        Arguments                       Results                                             Example
 ============================    ============================    =================================================   =============================================================
-:func:`accumulate`              p [,func]                       p0, p0+p1, p0+p1+p2, ...                            ``accumulate([1,2,3,4,5]) --> 1 3 6 10 15``
-:func:`batched`                 p, n                            (p0, p1, ..., p_n-1), ...                           ``batched('ABCDEFG', n=3) --> ABC DEF G``
-:func:`chain`                   p, q, ...                       p0, p1, ... plast, q0, q1, ...                      ``chain('ABC', 'DEF') --> A B C D E F``
-:func:`chain.from_iterable`     iterable                        p0, p1, ... plast, q0, q1, ...                      ``chain.from_iterable(['ABC', 'DEF']) --> A B C D E F``
-:func:`compress`                data, selectors                 (d[0] if s[0]), (d[1] if s[1]), ...                 ``compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F``
-:func:`dropwhile`               pred, seq                       seq[n], seq[n+1], starting when pred fails          ``dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1``
-:func:`filterfalse`             pred, seq                       elements of seq where pred(elem) is false           ``filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8``
+:func:`accumulate`              p [,func]                       p0, p0+p1, p0+p1+p2, ...                            ``accumulate([1,2,3,4,5])  1 3 6 10 15``
+:func:`batched`                 p, n                            (p0, p1, ..., p_n-1), ...                           ``batched('ABCDEFG', n=3)  ABC DEF G``
+:func:`chain`                   p, q, ...                       p0, p1, ... plast, q0, q1, ...                      ``chain('ABC', 'DEF')  A B C D E F``
+:func:`chain.from_iterable`     iterable                        p0, p1, ... plast, q0, q1, ...                      ``chain.from_iterable(['ABC', 'DEF'])  A B C D E F``
+:func:`compress`                data, selectors                 (d[0] if s[0]), (d[1] if s[1]), ...                 ``compress('ABCDEF', [1,0,1,0,1,1])  A C E F``
+:func:`dropwhile`               predicate, seq                  seq[n], seq[n+1], starting when predicate fails     ``dropwhile(lambda x: x<5, [1,4,6,4,1])  6 4 1``
+:func:`filterfalse`             predicate, seq                  elements of seq where predicate(elem) fails         ``filterfalse(lambda x: x%2, range(10))  0 2 4 6 8``
 :func:`groupby`                 iterable[, key]                 sub-iterators grouped by value of key(v)
-:func:`islice`                  seq, [start,] stop [, step]     elements from seq[start:stop:step]                  ``islice('ABCDEFG', 2, None) --> C D E F G``
-:func:`pairwise`                iterable                        (p[0], p[1]), (p[1], p[2])                          ``pairwise('ABCDEFG') --> AB BC CD DE EF FG``
-:func:`starmap`                 func, seq                       func(\*seq[0]), func(\*seq[1]), ...                 ``starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000``
-:func:`takewhile`               pred, seq                       seq[0], seq[1], until pred fails                    ``takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4``
+:func:`islice`                  seq, [start,] stop [, step]     elements from seq[start:stop:step]                  ``islice('ABCDEFG', 2, None)  C D E F G``
+:func:`pairwise`                iterable                        (p[0], p[1]), (p[1], p[2])                          ``pairwise('ABCDEFG')  AB BC CD DE EF FG``
+:func:`starmap`                 func, seq                       func(\*seq[0]), func(\*seq[1]), ...                 ``starmap(pow, [(2,5), (3,2), (10,3)])  32 9 1000``
+:func:`takewhile`               predicate, seq                  seq[0], seq[1], until predicate fails               ``takewhile(lambda x: x<5, [1,4,6,4,1])  1 4``
 :func:`tee`                     it, n                           it1, it2, ... itn  splits one iterator into n
-:func:`zip_longest`             p, q, ...                       (p[0], q[0]), (p[1], q[1]), ...                     ``zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-``
+:func:`zip_longest`             p, q, ...                       (p[0], q[0]), (p[1], q[1]), ...                     ``zip_longest('ABCD', 'xy', fillvalue='-')  Ax By C- D-``
 ============================    ============================    =================================================   =============================================================
 
 **Combinatoric iterators:**
@@ -84,13 +84,13 @@ Examples                                         Results
 ``product('ABCD', repeat=2)``                    ``AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD``
 ``permutations('ABCD', 2)``                      ``AB AC AD BA BC BD CA CB CD DA DB DC``
 ``combinations('ABCD', 2)``                      ``AB AC AD BC BD CD``
-``combinations_with_replacement('ABCD',2)``      ``AA AB AC AD BB BC BD CC CD DD``
+``combinations_with_replacement('ABCD',2)``     ``AA AB AC AD BB BC BD CC CD DD``
 ==============================================   =============================================================
 
 
 .. _itertools-functions:
 
-Itertool functions
+Itertool Functions
 ------------------
 
 The following module functions all construct and return iterators. Some provide
@@ -119,9 +119,9 @@ loops that truncate the stream.
 
         def accumulate(iterable, func=operator.add, *, initial=None):
             'Return running totals'
-            # accumulate([1,2,3,4,5]) --> 1 3 6 10 15
-            # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115
-            # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120
+            # accumulate([1,2,3,4,5])  1 3 6 10 15
+            # accumulate([1,2,3,4,5], initial=100)  100 101 103 106 110 115
+            # accumulate([1,2,3,4,5], operator.mul)  1 2 6 24 120
             it = iter(iterable)
             total = initial
             if initial is None:
@@ -191,7 +191,7 @@ loops that truncate the stream.
    Roughly equivalent to::
 
       def batched(iterable, n):
-          # batched('ABCDEFG', 3) --> ABC DEF G
+          # batched('ABCDEFG', 3)  ABC DEF G
           if n < 1:
               raise ValueError('n must be at least one')
           it = iter(iterable)
@@ -209,7 +209,7 @@ loops that truncate the stream.
    Roughly equivalent to::
 
       def chain(*iterables):
-          # chain('ABC', 'DEF') --> A B C D E F
+          # chain('ABC', 'DEF')  A B C D E F
           for it in iterables:
               for element in it:
                   yield element
@@ -221,7 +221,7 @@ loops that truncate the stream.
    single iterable argument that is evaluated lazily.  Roughly equivalent to::
 
       def from_iterable(iterables):
-          # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
+          # chain.from_iterable(['ABC', 'DEF'])  A B C D E F
           for it in iterables:
               for element in it:
                   yield element
@@ -242,8 +242,8 @@ loops that truncate the stream.
    Roughly equivalent to::
 
         def combinations(iterable, r):
-            # combinations('ABCD', 2) --> AB AC AD BC BD CD
-            # combinations(range(4), 3) --> 012 013 023 123
+            # combinations('ABCD', 2)  AB AC AD BC BD CD
+            # combinations(range(4), 3)  012 013 023 123
             pool = tuple(iterable)
             n = len(pool)
             if r > n:
@@ -291,7 +291,7 @@ loops that truncate the stream.
    Roughly equivalent to::
 
         def combinations_with_replacement(iterable, r):
-            # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
+            # combinations_with_replacement('ABC', 2)  AA AB AC BB BC CC
             pool = tuple(iterable)
             n = len(pool)
             if not n and r:
@@ -331,7 +331,7 @@ loops that truncate the stream.
    Roughly equivalent to::
 
        def compress(data, selectors):
-           # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
+           # compress('ABCDEF', [1,0,1,0,1,1])  A C E F
            return (d for d, s in zip(data, selectors) if s)
 
    .. versionadded:: 3.1
@@ -344,8 +344,8 @@ loops that truncate the stream.
    Also, used with :func:`zip` to add sequence numbers.  Roughly equivalent to::
 
       def count(start=0, step=1):
-          # count(10) --> 10 11 12 13 14 ...
-          # count(2.5, 0.5) --> 2.5 3.0 3.5 ...
+          # count(10)  10 11 12 13 14 ...
+          # count(2.5, 0.5)  2.5 3.0 3.5 ...
           n = start
           while True:
               yield n
@@ -365,7 +365,7 @@ loops that truncate the stream.
    indefinitely.  Roughly equivalent to::
 
       def cycle(iterable):
-          # cycle('ABCD') --> A B C D A B C D A B C D ...
+          # cycle('ABCD')  A B C D A B C D A B C D ...
           saved = []
           for element in iterable:
               yield element
@@ -386,7 +386,7 @@ loops that truncate the stream.
    start-up time.  Roughly equivalent to::
 
       def dropwhile(predicate, iterable):
-          # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
+          # dropwhile(lambda x: x<5, [1,4,6,4,1])  6 4 1
           iterable = iter(iterable)
           for x in iterable:
               if not predicate(x):
@@ -402,7 +402,7 @@ loops that truncate the stream.
    that are false. Roughly equivalent to::
 
       def filterfalse(predicate, iterable):
-          # filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
+          # filterfalse(lambda x: x%2, range(10))  0 2 4 6 8
           if predicate is None:
               predicate = bool
           for x in iterable:
@@ -439,8 +439,8 @@ loops that truncate the stream.
    :func:`groupby` is roughly equivalent to::
 
       class groupby:
-          # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
-          # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
+          # [k for k, g in groupby('AAAABBBCCDAABBB')]  A B C D A B
+          # [list(g) for k, g in groupby('AAAABBBCCD')]  AAAA BBB CC D
 
           def __init__(self, iterable, key=None):
               if key is None:
@@ -491,10 +491,10 @@ loops that truncate the stream.
    Roughly equivalent to::
 
       def islice(iterable, *args):
-          # islice('ABCDEFG', 2) --> A B
-          # islice('ABCDEFG', 2, 4) --> C D
-          # islice('ABCDEFG', 2, None) --> C D E F G
-          # islice('ABCDEFG', 0, None, 2) --> A C E G
+          # islice('ABCDEFG', 2)  A B
+          # islice('ABCDEFG', 2, 4)  C D
+          # islice('ABCDEFG', 2, None)  C D E F G
+          # islice('ABCDEFG', 0, None, 2)  A C E G
           s = slice(*args)
           start, stop, step = s.start or 0, s.stop or sys.maxsize, s.step or 1
           it = iter(range(start, stop, step))
@@ -527,10 +527,12 @@ loops that truncate the stream.
    Roughly equivalent to::
 
         def pairwise(iterable):
-            # pairwise('ABCDEFG') --> AB BC CD DE EF FG
-            a, b = tee(iterable)
-            next(b, None)
-            return zip(a, b)
+            # pairwise('ABCDEFG')  AB BC CD DE EF FG
+            iterator = iter(iterable)
+            a = next(iterator, None)
+            for b in iterator:
+                yield a, b
+                a = b
 
    .. versionadded:: 3.10
 
@@ -554,8 +556,8 @@ loops that truncate the stream.
    Roughly equivalent to::
 
         def permutations(iterable, r=None):
-            # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
-            # permutations(range(3)) --> 012 021 102 120 201 210
+            # permutations('ABCD', 2)  AB AC AD BA BC BD CA CB CD DA DB DC
+            # permutations(range(3))  012 021 102 120 201 210
             pool = tuple(iterable)
             n = len(pool)
             r = n if r is None else r
@@ -613,8 +615,8 @@ loops that truncate the stream.
    actual implementation does not build up intermediate results in memory::
 
        def product(*args, repeat=1):
-           # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
-           # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
+           # product('ABCD', 'xy')  Ax Ay Bx By Cx Cy Dx Dy
+           # product(range(2), repeat=3)  000 001 010 011 100 101 110 111
            pools = [tuple(pool) for pool in args] * repeat
            result = [[]]
            for pool in pools:
@@ -634,7 +636,7 @@ loops that truncate the stream.
    Roughly equivalent to::
 
       def repeat(object, times=None):
-          # repeat(10, 3) --> 10 10 10
+          # repeat(10, 3)  10 10 10
           if times is None:
               while True:
                   yield object
@@ -662,7 +664,7 @@ loops that truncate the stream.
    equivalent to::
 
       def starmap(function, iterable):
-          # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
+          # starmap(pow, [(2,5), (3,2), (10,3)])  32 9 1000
           for args in iterable:
               yield function(*args)
 
@@ -673,13 +675,21 @@ loops that truncate the stream.
    predicate is true.  Roughly equivalent to::
 
       def takewhile(predicate, iterable):
-          # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
+          # takewhile(lambda x: x<5, [1,4,6,4,1])  1 4
           for x in iterable:
               if predicate(x):
                   yield x
               else:
                   break
 
+   Note, the element that first fails the predicate condition is
+   consumed from the input iterator and there is no way to access it.
+   This could be an issue if an application wants to further consume the
+   input iterator after takewhile has been run to exhaustion.  To work
+   around this problem, consider using `more-iterools before_and_after()
+   <https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.before_and_after>`_
+   instead.
+
 
 .. function:: tee(iterable, n=2)
 
@@ -725,7 +735,7 @@ loops that truncate the stream.
    Iteration continues until the longest iterable is exhausted.  Roughly equivalent to::
 
       def zip_longest(*args, fillvalue=None):
-          # zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
+          # zip_longest('ABCD', 'xy', fillvalue='-')  Ax By C- D-
           iterators = [iter(it) for it in args]
           num_active = len(iterators)
           if not num_active:
@@ -762,15 +772,15 @@ The primary purpose of the itertools recipes is educational.  The recipes show
 various ways of thinking about individual tools  for example, that
 ``chain.from_iterable`` is related to the concept of flattening.  The recipes
 also give ideas about ways that the tools can be combined  for example, how
-``compress()`` and ``range()`` can work together.  The recipes also show patterns
+``starmap()`` and ``repeat()`` can work together.  The recipes also show patterns
 for using itertools with the :mod:`operator` and :mod:`collections` modules as
 well as with the built-in itertools such as ``map()``, ``filter()``,
 ``reversed()``, and ``enumerate()``.
 
 A secondary purpose of the recipes is to serve as an incubator.  The
 ``accumulate()``, ``compress()``, and ``pairwise()`` itertools started out as
-recipes.  Currently, the ``sliding_window()`` and ``iter_index()`` recipes
-are being tested to see whether they prove their worth.
+recipes.  Currently, the ``sliding_window()``, ``iter_index()``, and ``sieve()``
+recipes are being tested to see whether they prove their worth.
 
 Substantially all of these recipes and many, many others can be installed from
 the `more-itertools project <https://pypi.org/project/more-itertools/>`_ found
@@ -779,12 +789,12 @@ on the Python Package Index::
     python -m pip install more-itertools
 
 Many of the recipes offer the same high performance as the underlying toolset.
-Superior memory performance is kept by processing elements one at a time
-rather than bringing the whole iterable into memory all at once. Code volume is
-kept small by linking the tools together in a functional style which helps
-eliminate temporary variables.  High speed is retained by preferring
-"vectorized" building blocks over the use of for-loops and :term:`generator`\s
-which incur interpreter overhead.
+Superior memory performance is kept by processing elements one at a time rather
+than bringing the whole iterable into memory all at once. Code volume is kept
+small by linking the tools together in a `functional style
+<https://www.cs.kent.ac.uk/people/staff/dat/miranda/whyfp90.pdf>`_.  High speed
+is retained by preferring "vectorized" building blocks over the use of for-loops
+and :term:`generators <generator>` which incur interpreter overhead.
 
 .. testcode::
 
@@ -800,7 +810,7 @@ which incur interpreter overhead.
 
    def prepend(value, iterable):
        "Prepend a single value in front of an iterable."
-       # prepend(1, [2, 3, 4]) --> 1 2 3 4
+       # prepend(1, [2, 3, 4])  1 2 3 4
        return chain([value], iterable)
 
    def tabulate(function, start=0):
@@ -826,7 +836,7 @@ which incur interpreter overhead.
 
    def tail(n, iterable):
        "Return an iterator over the last n items."
-       # tail(3, 'ABCDEFG') --> E F G
+       # tail(3, 'ABCDEFG')  E F G
        return iter(collections.deque(iterable, maxlen=n))
 
    def consume(iterator, n=None):
@@ -843,32 +853,33 @@ which incur interpreter overhead.
        "Returns the nth item or a default value."
        return next(islice(iterable, n, None), default)
 
-   def quantify(iterable, pred=bool):
+   def quantify(iterable, predicate=bool):
        "Given a predicate that returns True or False, count the True results."
-       return sum(map(pred, iterable))
-
-   def all_equal(iterable):
-       "Returns True if all the elements are equal to each other."
-       g = groupby(iterable)
-       return next(g, True) and not next(g, False)
+       return sum(map(predicate, iterable))
 
-   def first_true(iterable, default=False, pred=None):
-       """Returns the first true value in the iterable.
+   def first_true(iterable, default=False, predicate=None):
+       "Returns the first true value or the *default* if there is no true value."
+       # first_true([a,b,c], x)  a or b or c or x
+       # first_true([a,b], x, f)  a if f(a) else b if f(b) else x
+       return next(filter(predicate, iterable), default)
 
-       If no true value is found, returns *default*
-
-       If *pred* is not None, returns the first item
-       for which pred(item) is true.
+   def all_equal(iterable, key=None):
+       "Returns True if all the elements are equal to each other."
+       # all_equal('4', key=int)  True
+       return len(take(2, groupby(iterable, key))) <= 1
 
-       """
-       # first_true([a,b,c], x) --> a or b or c or x
-       # first_true([a,b], x, f) --> a if f(a) else b if f(b) else x
-       return next(filter(pred, iterable), default)
+   def unique_justseen(iterable, key=None):
+       "List unique elements, preserving order. Remember only the element just seen."
+       # unique_justseen('AAAABBBCCDAABBB')  A B C D A B
+       # unique_justseen('ABBcCAD', str.casefold)  A B c A D
+       if key is None:
+           return map(operator.itemgetter(0), groupby(iterable))
+       return map(next, map(operator.itemgetter(1), groupby(iterable, key)))
 
    def unique_everseen(iterable, key=None):
        "List unique elements, preserving order. Remember all elements ever seen."
-       # unique_everseen('AAAABBBCCDAABBB') --> A B C D
-       # unique_everseen('ABBcCAD', str.casefold) --> A B c D
+       # unique_everseen('AAAABBBCCDAABBB')  A B C D
+       # unique_everseen('ABBcCAD', str.casefold)  A B c D
        seen = set()
        if key is None:
            for element in filterfalse(seen.__contains__, iterable):
@@ -881,37 +892,9 @@ which incur interpreter overhead.
                    seen.add(k)
                    yield element
 
-   def unique_justseen(iterable, key=None):
-       "List unique elements, preserving order. Remember only the element just seen."
-       # unique_justseen('AAAABBBCCDAABBB') --> A B C D A B
-       # unique_justseen('ABBcCAD', str.casefold) --> A B c A D
-       if key is None:
-           return map(operator.itemgetter(0), groupby(iterable))
-       return map(next, map(operator.itemgetter(1), groupby(iterable, key)))
-
-   def iter_index(iterable, value, start=0, stop=None):
-       "Return indices where a value occurs in a sequence or iterable."
-       # iter_index('AABCADEAF', 'A') --> 0 1 4 7
-       seq_index = getattr(iterable, 'index', None)
-       if seq_index is None:
-           # Slow path for general iterables
-           it = islice(iterable, start, stop)
-           for i, element in enumerate(it, start):
-               if element is value or element == value:
-                   yield i
-       else:
-           # Fast path for sequences
-           stop = len(iterable) if stop is None else stop
-           i = start - 1
-           try:
-               while True:
-                   yield (i := seq_index(value, i+1, stop))
-           except ValueError:
-               pass
-
    def sliding_window(iterable, n):
        "Collect data into overlapping fixed-length chunks or blocks."
-       # sliding_window('ABCDEFG', 4) --> ABCD BCDE CDEF DEFG
+       # sliding_window('ABCDEFG', 4)  ABCD BCDE CDEF DEFG
        it = iter(iterable)
        window = collections.deque(islice(it, n-1), maxlen=n)
        for x in it:
@@ -920,156 +903,125 @@ which incur interpreter overhead.
 
    def grouper(iterable, n, *, incomplete='fill', fillvalue=None):
        "Collect data into non-overlapping fixed-length chunks or blocks."
-       # grouper('ABCDEFG', 3, fillvalue='x') --> ABC DEF Gxx
-       # grouper('ABCDEFG', 3, incomplete='strict') --> ABC DEF ValueError
-       # grouper('ABCDEFG', 3, incomplete='ignore') --> ABC DEF
-       args = [iter(iterable)] * n
+       # grouper('ABCDEFG', 3, fillvalue='x')  ABC DEF Gxx
+       # grouper('ABCDEFG', 3, incomplete='strict')  ABC DEF ValueError
+       # grouper('ABCDEFG', 3, incomplete='ignore')  ABC DEF
+       iterators = [iter(iterable)] * n
        match incomplete:
            case 'fill':
-               return zip_longest(*args, fillvalue=fillvalue)
+               return zip_longest(*iterators, fillvalue=fillvalue)
            case 'strict':
-               return zip(*args, strict=True)
+               return zip(*iterators, strict=True)
            case 'ignore':
-               return zip(*args)
+               return zip(*iterators)
            case _:
                raise ValueError('Expected fill, strict, or ignore')
 
    def roundrobin(*iterables):
        "Visit input iterables in a cycle until each is exhausted."
-       # roundrobin('ABC', 'D', 'EF') --> A D E B F C
-       # Recipe credited to George Sakkis
-       num_active = len(iterables)
-       nexts = cycle(iter(it).__next__ for it in iterables)
-       while num_active:
-           try:
-               for next in nexts:
-                   yield next()
-           except StopIteration:
-               # Remove the iterator we just exhausted from the cycle.
-               num_active -= 1
-               nexts = cycle(islice(nexts, num_active))
-
-   def partition(pred, iterable):
+       # roundrobin('ABC', 'D', 'EF')  A D E B F C
+       # Algorithm credited to George Sakkis
+       iterators = map(iter, iterables)
+       for num_active in range(len(iterables), 0, -1):
+           iterators = cycle(islice(iterators, num_active))
+           yield from map(next, iterators)
+
+   def partition(predicate, iterable):
        """Partition entries into false entries and true entries.
 
-       If *pred* is slow, consider wrapping it with functools.lru_cache().
+       If *predicate* is slow, consider wrapping it with functools.lru_cache().
        """
-       # partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9
+       # partition(is_odd, range(10))  0 2 4 6 8   and  1 3 5 7 9
        t1, t2 = tee(iterable)
-       return filterfalse(pred, t1), filter(pred, t2)
+       return filterfalse(predicate, t1), filter(predicate, t2)
 
    def subslices(seq):
        "Return all contiguous non-empty subslices of a sequence."
-       # subslices('ABCD') --> A AB ABC ABCD B BC BCD C CD D
+       # subslices('ABCD')  A AB ABC ABCD B BC BCD C CD D
        slices = starmap(slice, combinations(range(len(seq) + 1), 2))
        return map(operator.getitem, repeat(seq), slices)
 
+   def iter_index(iterable, value, start=0, stop=None):
+       "Return indices where a value occurs in a sequence or iterable."
+       # iter_index('AABCADEAF', 'A')  0 1 4 7
+       seq_index = getattr(iterable, 'index', None)
+       if seq_index is None:
+           # Path for general iterables
+           it = islice(iterable, start, stop)
+           for i, element in enumerate(it, start):
+               if element is value or element == value:
+                   yield i
+       else:
+           # Path for sequences with an index() method
+           stop = len(iterable) if stop is None else stop
+           i = start
+           try:
+               while True:
+                   yield (i := seq_index(value, i, stop))
+                   i += 1
+           except ValueError:
+               pass
+
    def iter_except(func, exception, first=None):
        """ Call a function repeatedly until an exception is raised.
 
        Converts a call-until-exception interface to an iterator interface.
-       Like builtins.iter(func, sentinel) but uses an exception instead
-       of a sentinel to end the loop.
-
-       Priority queue iterator:
-           iter_except(functools.partial(heappop, h), IndexError)
-
-       Non-blocking dictionary iterator:
-           iter_except(d.popitem, KeyError)
-
-       Non-blocking deque iterator:
-           iter_except(d.popleft, IndexError)
-
-       Non-blocking iterator over a producer Queue:
-           iter_except(q.get_nowait, Queue.Empty)
-
-       Non-blocking set iterator:
-           iter_except(s.pop, KeyError)
-
        """
+       # iter_except(d.popitem, KeyError)  non-blocking dictionary iterator
        try:
            if first is not None:
-               # For database APIs needing an initial call to db.first()
                yield first()
            while True:
                yield func()
        except exception:
            pass
 
-   def before_and_after(predicate, it):
-       """ Variant of takewhile() that allows complete
-           access to the remainder of the iterator.
-
-           >>> it = iter('ABCdEfGhI')
-           >>> all_upper, remainder = before_and_after(str.isupper, it)
-           >>> ''.join(all_upper)
-           'ABC'
-           >>> ''.join(remainder)     # takewhile() would lose the 'd'
-           'dEfGhI'
-
-           Note that the true iterator must be fully consumed
-           before the remainder iterator can generate valid results.
-       """
-       it = iter(it)
-       transition = []
-
-       def true_iterator():
-           for elem in it:
-               if predicate(elem):
-                   yield elem
-               else:
-                   transition.append(elem)
-                   return
-
-       return true_iterator(), chain(transition, it)
-
 
 The following recipes have a more mathematical flavor:
 
 .. testcode::
 
    def powerset(iterable):
-       "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
+       "powerset([1,2,3])  () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
        s = list(iterable)
        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))
 
-   def sum_of_squares(it):
+   def sum_of_squares(iterable):
        "Add up the squares of the input values."
-       # sum_of_squares([10, 20, 30]) -> 1400
-       return math.sumprod(*tee(it))
+       # sum_of_squares([10, 20, 30])  1400
+       return math.sumprod(*tee(iterable))
 
    def reshape(matrix, cols):
        "Reshape a 2-D matrix to have a given number of columns."
-       # reshape([(0, 1), (2, 3), (4, 5)], 3) -->  (0, 1, 2), (3, 4, 5)
+       # reshape([(0, 1), (2, 3), (4, 5)], 3)   (0, 1, 2), (3, 4, 5)
        return batched(chain.from_iterable(matrix), cols)
 
    def transpose(matrix):
        "Swap the rows and columns of a 2-D matrix."
-       # transpose([(1, 2, 3), (11, 22, 33)]) --> (1, 11) (2, 22) (3, 33)
+       # transpose([(1, 2, 3), (11, 22, 33)])  (1, 11) (2, 22) (3, 33)
        return zip(*matrix, strict=True)
 
    def matmul(m1, m2):
        "Multiply two matrices."
-       # matmul([(7, 5), (3, 5)], [(2, 5), (7, 9)]) --> (49, 80), (41, 60)
+       # matmul([(7, 5), (3, 5)], [(2, 5), (7, 9)])  (49, 80), (41, 60)
        n = len(m2[0])
        return batched(starmap(math.sumprod, product(m1, transpose(m2))), n)
 
    def convolve(signal, kernel):
        """Discrete linear convolution of two iterables.
+       Equivalent to polynomial multiplication.
 
-       The kernel is fully consumed before the calculations begin.
-       The signal is consumed lazily and can be infinite.
-
-       Convolutions are mathematically commutative.
-       If the signal and kernel are swapped,
-       the output will be the same.
+       Convolutions are mathematically commutative; however, the inputs are
+       evaluated differently.  The signal is consumed lazily and can be
+       infinite. The kernel is fully consumed before the calculations begin.
 
        Article:  https://betterexplained.com/articles/intuitive-convolution/
        Video:    https://www.youtube.com/watch?v=KuXjwB4LzSA
        """
-       # convolve(data, [0.25, 0.25, 0.25, 0.25]) --> Moving average (blur)
-       # convolve(data, [1/2, 0, -1/2]) --> 1st derivative estimate
-       # convolve(data, [1, -2, 1]) --> 2nd derivative estimate
+       # convolve([1, -1, -20], [1, -3])  1 -4 -17 60
+       # convolve(data, [0.25, 0.25, 0.25, 0.25])  Moving average (blur)
+       # convolve(data, [1/2, 0, -1/2])  1st derivative estimate
+       # convolve(data, [1, -2, 1])  2nd derivative estimate
        kernel = tuple(kernel)[::-1]
        n = len(kernel)
        padded_signal = chain(repeat(0, n-1), signal, repeat(0, n-1))
@@ -1081,7 +1033,7 @@ The following recipes have a more mathematical flavor:
 
           (x - 5) (x + 4) (x - 3)  expands to:   x -4x -17x + 60
        """
-       # polynomial_from_roots([5, -4, 3]) --> [1, -4, -17, 60]
+       # polynomial_from_roots([5, -4, 3])  [1, -4, -17, 60]
        factors = zip(repeat(1), map(operator.neg, roots))
        return list(functools.reduce(convolve, factors, [1]))
 
@@ -1090,8 +1042,8 @@ The following recipes have a more mathematical flavor:
 
        Computes with better numeric stability than Horner's method.
        """
-       # Evaluate x -4x -17x + 60 at x = 2.5
-       # polynomial_eval([1, -4, -17, 60], x=2.5) --> 8.125
+       # Evaluate x -4x -17x + 60 at x = 5
+       # polynomial_eval([1, -4, -17, 60], x=5)  0
        n = len(coefficients)
        if not n:
            return type(x)(0)
@@ -1104,14 +1056,14 @@ The following recipes have a more mathematical flavor:
           f(x)  =  x -4x -17x + 60
           f'(x) = 3x -8x  -17
        """
-       # polynomial_derivative([1, -4, -17, 60]) -> [3, -8, -17]
+       # polynomial_derivative([1, -4, -17, 60])  [3, -8, -17]
        n = len(coefficients)
        powers = reversed(range(1, n))
        return list(map(operator.mul, coefficients, powers))
 
    def sieve(n):
        "Primes less than n."
-       # sieve(30) --> 2 3 5 7 11 13 17 19 23 29
+       # sieve(30)  2 3 5 7 11 13 17 19 23 29
        if n > 2:
            yield 2
        start = 3
@@ -1125,9 +1077,9 @@ The following recipes have a more mathematical flavor:
 
    def factor(n):
        "Prime factors of n."
-       # factor(99) --> 3 3 11
-       # factor(1_000_000_000_000_007) --> 47 59 360620266859
-       # factor(1_000_000_000_000_403) --> 1000000000000403
+       # factor(99)  3 3 11
+       # factor(1_000_000_000_000_007)  47 59 360620266859
+       # factor(1_000_000_000_000_403)  1000000000000403
        for prime in sieve(math.isqrt(n) + 1):
            while not n % prime:
                yield prime
@@ -1140,7 +1092,7 @@ The following recipes have a more mathematical flavor:
    def totient(n):
        "Count of natural numbers up to n that are coprime to n."
        # https://mathworld.wolfram.com/TotientFunction.html
-       # totient(12) --> 4 because len([1, 5, 7, 11]) == 4
+       # totient(12)  4 because len([1, 5, 7, 11]) == 4
        for p in unique_justseen(factor(n)):
            n -= n // p
        return n
@@ -1206,6 +1158,12 @@ The following recipes have a more mathematical flavor:
 
     >>> take(10, count())
     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
+    >>> # Verify that the input is consumed lazily
+    >>> it = iter('abcdef')
+    >>> take(3, it)
+    ['a', 'b', 'c']
+    >>> list(it)
+    ['d', 'e', 'f']
 
     >>> list(prepend(1, [2, 3, 4]))
     [1, 2, 3, 4]
@@ -1218,23 +1176,45 @@ The following recipes have a more mathematical flavor:
 
     >>> list(tail(3, 'ABCDEFG'))
     ['E', 'F', 'G']
+    >>> # Verify the input is consumed greedily
+    >>> input_iterator = iter('ABCDEFG')
+    >>> output_iterator = tail(3, input_iterator)
+    >>> list(input_iterator)
+    []
 
     >>> it = iter(range(10))
     >>> consume(it, 3)
+    >>> # Verify the input is consumed lazily
     >>> next(it)
     3
+    >>> # Verify the input is consumed completely
     >>> consume(it)
     >>> next(it, 'Done')
     'Done'
 
     >>> nth('abcde', 3)
     'd'
-
     >>> nth('abcde', 9) is None
     True
+    >>> # Verify that the input is consumed lazily
+    >>> it = iter('abcde')
+    >>> nth(it, 2)
+    'c'
+    >>> list(it)
+    ['d', 'e']
 
     >>> [all_equal(s) for s in ('', 'A', 'AAAA', 'AAAB', 'AAABA')]
     [True, True, True, False, False]
+    >>> [all_equal(s, key=str.casefold) for s in ('', 'A', 'AaAa', 'AAAB', 'AAABA')]
+    [True, True, True, False, False]
+    >>> # Verify that the input is consumed lazily and that only
+    >>> # one element of a second equivalence class is used to disprove
+    >>> # the assertion that all elements are equal.
+    >>> it = iter('aaabbbccc')
+    >>> all_equal(it)
+    False
+    >>> ''.join(it)
+    'bbccc'
 
     >>> quantify(range(99), lambda x: x%2==0)
     50
@@ -1242,7 +1222,7 @@ The following recipes have a more mathematical flavor:
     >>> quantify([True, False, False, True, True])
     3
 
-    >>> quantify(range(12), pred=lambda x: x%2==1)
+    >>> quantify(range(12), predicate=lambda x: x%2==1)
     6
 
     >>> a = [[1, 2, 3], [4, 5, 6]]
@@ -1257,6 +1237,11 @@ The following recipes have a more mathematical flavor:
 
     >>> list(ncycles('abc', 3))
     ['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c']
+    >>> # Verify greedy consumption of input iterator
+    >>> input_iterator = iter('abc')
+    >>> output_iterator = ncycles(input_iterator, 3)
+    >>> list(input_iterator)
+    []
 
     >>> sum_of_squares([10, 20, 30])
     1400
@@ -1279,12 +1264,22 @@ The following recipes have a more mathematical flavor:
 
     >>> list(transpose([(1, 2, 3), (11, 22, 33)]))
     [(1, 11), (2, 22), (3, 33)]
+    >>> # Verify that the inputs are consumed lazily
+    >>> input1 = iter([1, 2, 3])
+    >>> input2 = iter([11, 22, 33])
+    >>> output_iterator = transpose([input1, input2])
+    >>> next(output_iterator)
+    (1, 11)
+    >>> list(zip(input1, input2))
+    [(2, 22), (3, 33)]
 
     >>> list(matmul([(7, 5), (3, 5)], [[2, 5], [7, 9]]))
     [(49, 80), (41, 60)]
     >>> list(matmul([[2, 5], [7, 9], [3, 4]], [[7, 11, 5, 4, 9], [3, 5, 2, 6, 3]]))
     [(29, 47, 20, 38, 33), (76, 122, 53, 82, 90), (33, 53, 23, 36, 39)]
 
+    >>> list(convolve([1, -1, -20], [1, -3])) == [1, -4, -17, 60]
+    True
     >>> data = [20, 40, 24, 32, 20, 28, 16]
     >>> list(convolve(data, [0.25, 0.25, 0.25, 0.25]))
     [5.0, 15.0, 21.0, 29.0, 29.0, 26.0, 24.0, 16.0, 11.0, 4.0]
@@ -1292,13 +1287,25 @@ The following recipes have a more mathematical flavor:
     [20, 20, -16, 8, -12, 8, -12, -16]
     >>> list(convolve(data, [1, -2, 1]))
     [20, 0, -36, 24, -20, 20, -20, -4, 16]
+    >>> # Verify signal is consumed lazily and the kernel greedily
+    >>> signal_iterator = iter([10, 20, 30, 40, 50])
+    >>> kernel_iterator = iter([1, 2, 3])
+    >>> output_iterator = convolve(signal_iterator, kernel_iterator)
+    >>> list(kernel_iterator)
+    []
+    >>> next(output_iterator)
+    10
+    >>> next(output_iterator)
+    40
+    >>> list(signal_iterator)
+    [30, 40, 50]
 
     >>> from fractions import Fraction
     >>> from decimal import Decimal
-    >>> polynomial_eval([1, -4, -17, 60], x=2)
-    18
-    >>> x = 2; x**3 - 4*x**2 -17*x + 60
-    18
+    >>> polynomial_eval([1, -4, -17, 60], x=5)
+    0
+    >>> x = 5; x**3 - 4*x**2 -17*x + 60
+    0
     >>> polynomial_eval([1, -4, -17, 60], x=2.5)
     8.125
     >>> x = 2.5; x**3 - 4*x**2 -17*x + 60
@@ -1379,6 +1386,33 @@ The following recipes have a more mathematical flavor:
     >>> # Test list input. Lists do not support None for the stop argument
     >>> list(iter_index(list('AABCADEAF'), 'A'))
     [0, 1, 4, 7]
+    >>> # Verify that input is consumed lazily
+    >>> input_iterator = iter('AABCADEAF')
+    >>> output_iterator = iter_index(input_iterator, 'A')
+    >>> next(output_iterator)
+    0
+    >>> next(output_iterator)
+    1
+    >>> next(output_iterator)
+    4
+    >>> ''.join(input_iterator)
+    'DEAF'
+
+    >>> # Verify that the target value can be a sequence.
+    >>> seq = [[10, 20], [30, 40], 30, 40, [30, 40], 50]
+    >>> target = [30, 40]
+    >>> list(iter_index(seq, target))
+    [1, 4]
+
+    >>> # Verify faithfulness to type specific index() method behaviors.
+    >>> # For example, bytes and str perform continuous-subsequence searches
+    >>> # that do not match the general behavior specified
+    >>> # in collections.abc.Sequence.index().
+    >>> seq = 'abracadabra'
+    >>> target = 'ab'
+    >>> list(iter_index(seq, target))
+    [0, 7]
+
 
     >>> list(sieve(30))
     [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
@@ -1521,6 +1555,16 @@ The following recipes have a more mathematical flavor:
 
     >>> list(roundrobin('abc', 'd', 'ef'))
     ['a', 'd', 'e', 'b', 'f', 'c']
+    >>> ranges = [range(5, 1000), range(4, 3000), range(0), range(3, 2000), range(2, 5000), range(1, 3500)]
+    >>> collections.Counter(roundrobin(*ranges)) == collections.Counter(chain(*ranges))
+    True
+    >>> # Verify that the inputs are consumed lazily
+    >>> input_iterators = list(map(iter, ['abcd', 'ef', '', 'ghijk', 'l', 'mnopqr']))
+    >>> output_iterator = roundrobin(*input_iterators)
+    >>> ''.join(islice(output_iterator, 10))
+    'aeglmbfhnc'
+    >>> ''.join(chain(*input_iterators))
+    'dijkopqr'
 
     >>> def is_odd(x):
     ...     return x % 2 == 1
@@ -1530,13 +1574,17 @@ The following recipes have a more mathematical flavor:
     [0, 2, 4, 6, 8]
     >>> list(odds)
     [1, 3, 5, 7, 9]
-
-    >>> it = iter('ABCdEfGhI')
-    >>> all_upper, remainder = before_and_after(str.isupper, it)
-    >>> ''.join(all_upper)
-    'ABC'
-    >>> ''.join(remainder)
-    'dEfGhI'
+    >>> # Verify that the input is consumed lazily
+    >>> input_iterator = iter(range(10))
+    >>> evens, odds = partition(is_odd, input_iterator)
+    >>> next(odds)
+    1
+    >>> next(odds)
+    3
+    >>> next(evens)
+    0
+    >>> list(input_iterator)
+    [4, 5, 6, 7, 8, 9]
 
     >>> list(subslices('ABCD'))
     ['A', 'AB', 'ABC', 'ABCD', 'B', 'BC', 'BCD', 'C', 'CD', 'D']
@@ -1556,6 +1604,13 @@ The following recipes have a more mathematical flavor:
     ['A', 'B', 'C', 'D']
     >>> list(unique_everseen('ABBcCAD', str.casefold))
     ['A', 'B', 'c', 'D']
+    >>> # Verify that the input is consumed lazily
+    >>> input_iterator = iter('AAAABBBCCDAABBB')
+    >>> output_iterator = unique_everseen(input_iterator)
+    >>> next(output_iterator)
+    'A'
+    >>> ''.join(input_iterator)
+    'AAABBBCCDAABBB'
 
     >>> list(unique_justseen('AAAABBBCCDAABBB'))
     ['A', 'B', 'C', 'D', 'A', 'B']
@@ -1563,6 +1618,13 @@ The following recipes have a more mathematical flavor:
     ['A', 'B', 'C', 'A', 'D']
     >>> list(unique_justseen('ABBcCAD', str.casefold))
     ['A', 'B', 'c', 'A', 'D']
+    >>> # Verify that the input is consumed lazily
+    >>> input_iterator = iter('AAAABBBCCDAABBB')
+    >>> output_iterator = unique_justseen(input_iterator)
+    >>> next(output_iterator)
+    'A'
+    >>> ''.join(input_iterator)
+    'AAABBBCCDAABBB'
 
     >>> d = dict(a=1, b=2, c=3)
     >>> it = iter_except(d.popitem, KeyError)
@@ -1583,6 +1645,12 @@ The following recipes have a more mathematical flavor:
 
     >>> first_true('ABC0DEF1', '9', str.isdigit)
     '0'
+    >>> # Verify that inputs are consumed lazily
+    >>> it = iter('ABC0DEF1')
+    >>> first_true(it, predicate=str.isdigit)
+    '0'
+    >>> ''.join(it)
+    'DEF1'
 
 
 .. testcode::
@@ -1606,7 +1674,7 @@ The following recipes have a more mathematical flavor:
 
     def triplewise(iterable):
         "Return overlapping triplets from an iterable"
-        # triplewise('ABCDEFG') --> ABC BCD CDE DEF EFG
+        # triplewise('ABCDEFG')  ABC BCD CDE DEF EFG
         for (a, _), (b, c) in pairwise(pairwise(iterable)):
             yield a, b, c
 
@@ -1628,6 +1696,32 @@ The following recipes have a more mathematical flavor:
             result.append(pool[-1-n])
         return tuple(result)
 
+    def before_and_after(predicate, it):
+       """ Variant of takewhile() that allows complete
+           access to the remainder of the iterator.
+
+           >>> it = iter('ABCdEfGhI')
+           >>> all_upper, remainder = before_and_after(str.isupper, it)
+           >>> ''.join(all_upper)
+           'ABC'
+           >>> ''.join(remainder)     # takewhile() would lose the 'd'
+           'dEfGhI'
+
+           Note that the true iterator must be fully consumed
+           before the remainder iterator can generate valid results.
+       """
+       it = iter(it)
+       transition = []
+
+       def true_iterator():
+           for elem in it:
+               if predicate(elem):
+                   yield elem
+               else:
+                   transition.append(elem)
+                   return
+
+       return true_iterator(), chain(transition, it)
 
 .. doctest::
     :hide:
@@ -1657,3 +1751,10 @@ The following recipes have a more mathematical flavor:
     >>> combos = list(combinations(iterable, r))
     >>> all(nth_combination(iterable, r, i) == comb for i, comb in enumerate(combos))
     True
+
+    >>> it = iter('ABCdEfGhI')
+    >>> all_upper, remainder = before_and_after(str.isupper, it)
+    >>> ''.join(all_upper)
+    'ABC'
+    >>> ''.join(remainder)
+    'dEfGhI'
diff --git a/Doc/library/json.rst b/Doc/library/json.rst
index e234fe92bc..226d1c3dbf 100644
--- a/Doc/library/json.rst
+++ b/Doc/library/json.rst
@@ -95,7 +95,7 @@ Extending :class:`JSONEncoder`::
     ...         if isinstance(obj, complex):
     ...             return [obj.real, obj.imag]
     ...         # Let the base class default method raise the TypeError
-    ...         return json.JSONEncoder.default(self, obj)
+    ...         return super().default(obj)
     ...
     >>> json.dumps(2 + 1j, cls=ComplexEncoder)
     '[2.0, 1.0]'
@@ -493,7 +493,7 @@ Encoders and Decoders
             else:
                 return list(iterable)
             # Let the base class default method raise the TypeError
-            return json.JSONEncoder.default(self, o)
+            return super().default(o)
 
 
    .. method:: encode(o)
diff --git a/Doc/library/logging.rst b/Doc/library/logging.rst
index 6759544ef2..2bfa8a133d 100644
--- a/Doc/library/logging.rst
+++ b/Doc/library/logging.rst
@@ -30,13 +30,53 @@ is that all Python modules can participate in logging, so your application log
 can include your own messages integrated with messages from third-party
 modules.
 
-The simplest example:
+Here's a simple example of idiomatic usage: ::
+
+   # myapp.py
+   import logging
+   import mylib
+   logger = logging.getLogger(__name__)
+
+   def main():
+       logging.basicConfig(filename='myapp.log', level=logging.INFO)
+       logger.info('Started')
+       mylib.do_something()
+       logger.info('Finished')
+
+   if __name__ == '__main__':
+       main()
+
+::
+
+   # mylib.py
+   import logging
+   logger = logging.getLogger(__name__)
+
+   def do_something():
+       logger.info('Doing something')
+
+If you run *myapp.py*, you should see this in *myapp.log*:
 
 .. code-block:: none
 
-    >>> import logging
-    >>> logging.warning('Watch out!')
-    WARNING:root:Watch out!
+   INFO:__main__:Started
+   INFO:mylib:Doing something
+   INFO:__main__:Finished
+
+The key features of this idiomatic usage is that the majority of code is simply
+creating a module level logger with ``getLogger(__name__)``, and using that
+logger to do any needed logging. This is concise while allowing downstream code
+fine grained control if needed. Logged messages to the module-level logger get
+forwarded up to handlers of loggers in higher-level modules, all the way up to
+the root logger; for this reason this approach is known as hierarchical logging.
+
+For logging to be useful, it needs to be configured: setting the levels and
+destinations for each logger, potentially changing how specific modules log,
+often based on command-line arguments or application configuration. In most
+cases, like the one above, only the root logger needs to be so configured, since
+all the lower level loggers at module level eventually forward their messages to
+its handlers.  :func:`~logging.basicConfig` provides a quick way to configure
+the root logger that handles many use cases.
 
 The module provides a lot of functionality and flexibility.  If you are
 unfamiliar with logging, the best way to get to grips with it is to view the
@@ -77,6 +117,27 @@ is the module's name in the Python package namespace.
 
 .. class:: Logger
 
+   .. attribute:: Logger.name
+
+      This is the logger's name, and is the value that was passed to :func:`getLogger`
+      to obtain the logger.
+
+      .. note:: This attribute should be treated as read-only.
+
+   .. attribute:: Logger.level
+
+      The threshold of this logger, as set by the :meth:`setLevel` method.
+
+      .. note:: Do not set this attribute directly - always use :meth:`setLevel`,
+         which has checks for the level passed to it.
+
+   .. attribute:: Logger.parent
+
+      The parent logger of this logger. It may change based on later instantiation
+      of loggers which are higher up in the namespace hierarchy.
+
+      .. note:: This value should be treated as read-only.
+
    .. attribute:: Logger.propagate
 
       If this attribute evaluates to true, events logged to this logger will be
@@ -108,6 +169,21 @@ is the module's name in the Python package namespace.
          scenario is to attach handlers only to the root logger, and to let
          propagation take care of the rest.
 
+   .. attribute:: Logger.handlers
+
+      The list of handlers directly attached to this logger instance.
+
+      .. note:: This attribute should be treated as read-only; it is normally changed via
+         the :meth:`addHandler` and :meth:`removeHandler` methods, which use locks to ensure
+         thread-safe operation.
+
+   .. attribute:: Logger.disabled
+
+      This attribute disables handling of any events. It is set to ``False`` in the
+      initializer, and only changed by logging configuration code.
+
+      .. note:: This attribute should be treated as read-only.
+
    .. method:: Logger.setLevel(level)
 
       Sets the threshold for this logger to *level*. Logging messages which are less
@@ -1102,89 +1178,31 @@ functions.
 
 .. function:: debug(msg, *args, **kwargs)
 
-   Logs a message with level :const:`DEBUG` on the root logger. The *msg* is the
-   message format string, and the *args* are the arguments which are merged into
-   *msg* using the string formatting operator. (Note that this means that you can
-   use keywords in the format string, together with a single dictionary argument.)
-
-   There are three keyword arguments in *kwargs* which are inspected: *exc_info*
-   which, if it does not evaluate as false, causes exception information to be
-   added to the logging message. If an exception tuple (in the format returned by
-   :func:`sys.exc_info`) or an exception instance is provided, it is used;
-   otherwise, :func:`sys.exc_info` is called to get the exception information.
-
-   The second optional keyword argument is *stack_info*, which defaults to
-   ``False``. If true, stack information is added to the logging
-   message, including the actual logging call. Note that this is not the same
-   stack information as that displayed through specifying *exc_info*: The
-   former is stack frames from the bottom of the stack up to the logging call
-   in the current thread, whereas the latter is information about stack frames
-   which have been unwound, following an exception, while searching for
-   exception handlers.
-
-   You can specify *stack_info* independently of *exc_info*, e.g. to just show
-   how you got to a certain point in your code, even when no exceptions were
-   raised. The stack frames are printed following a header line which says:
-
-   .. code-block:: none
-
-       Stack (most recent call last):
+   This is a convenience function that calls :meth:`Logger.debug`, on the root
+   logger. The handling of the arguments is in every way identical
+   to what is described in that method.
 
-   This mimics the ``Traceback (most recent call last):`` which is used when
-   displaying exception frames.
+   The only difference is that if the root logger has no handlers, then
+   :func:`basicConfig` is called, prior to calling ``debug`` on the root logger.
 
-   The third optional keyword argument is *extra* which can be used to pass a
-   dictionary which is used to populate the __dict__ of the LogRecord created for
-   the logging event with user-defined attributes. These custom attributes can then
-   be used as you like. For example, they could be incorporated into logged
-   messages. For example::
+   For very short scripts or quick demonstrations of ``logging`` facilities,
+   ``debug`` and the other module-level functions may be convenient. However,
+   most programs will want to carefully and explicitly control the logging
+   configuration, and should therefore prefer creating a module-level logger and
+   calling :meth:`Logger.debug` (or other level-specific methods) on it, as
+   described at the beginnning of this documentation.
 
-      FORMAT = '%(asctime)s %(clientip)-15s %(user)-8s %(message)s'
-      logging.basicConfig(format=FORMAT)
-      d = {'clientip': '192.168.0.1', 'user': 'fbloggs'}
-      logging.warning('Protocol problem: %s', 'connection reset', extra=d)
-
-   would print something like:
-
-   .. code-block:: none
-
-      2006-02-08 22:20:02,165 192.168.0.1 fbloggs  Protocol problem: connection reset
-
-   The keys in the dictionary passed in *extra* should not clash with the keys used
-   by the logging system. (See the :class:`Formatter` documentation for more
-   information on which keys are used by the logging system.)
-
-   If you choose to use these attributes in logged messages, you need to exercise
-   some care. In the above example, for instance, the :class:`Formatter` has been
-   set up with a format string which expects 'clientip' and 'user' in the attribute
-   dictionary of the LogRecord. If these are missing, the message will not be
-   logged because a string formatting exception will occur. So in this case, you
-   always need to pass the *extra* dictionary with these keys.
-
-   While this might be annoying, this feature is intended for use in specialized
-   circumstances, such as multi-threaded servers where the same code executes in
-   many contexts, and interesting conditions which arise are dependent on this
-   context (such as remote client IP address and authenticated user name, in the
-   above example). In such circumstances, it is likely that specialized
-   :class:`Formatter`\ s would be used with particular :class:`Handler`\ s.
-
-   This function (as well as :func:`info`, :func:`warning`, :func:`error` and
-   :func:`critical`) will call :func:`basicConfig` if the root logger doesn't
-   have any handler attached.
-
-   .. versionchanged:: 3.2
-      The *stack_info* parameter was added.
 
 .. function:: info(msg, *args, **kwargs)
 
-   Logs a message with level :const:`INFO` on the root logger. The arguments are
-   interpreted as for :func:`debug`.
+   Logs a message with level :const:`INFO` on the root logger. The arguments and behavior
+   are otherwise the same as for :func:`debug`.
 
 
 .. function:: warning(msg, *args, **kwargs)
 
-   Logs a message with level :const:`WARNING` on the root logger. The arguments
-   are interpreted as for :func:`debug`.
+   Logs a message with level :const:`WARNING` on the root logger. The arguments and behavior
+   are otherwise the same as for :func:`debug`.
 
    .. note:: There is an obsolete function ``warn`` which is functionally
       identical to ``warning``. As ``warn`` is deprecated, please do not use
@@ -1193,26 +1211,26 @@ functions.
 
 .. function:: error(msg, *args, **kwargs)
 
-   Logs a message with level :const:`ERROR` on the root logger. The arguments are
-   interpreted as for :func:`debug`.
+   Logs a message with level :const:`ERROR` on the root logger. The arguments and behavior
+   are otherwise the same as for :func:`debug`.
 
 
 .. function:: critical(msg, *args, **kwargs)
 
-   Logs a message with level :const:`CRITICAL` on the root logger. The arguments
-   are interpreted as for :func:`debug`.
+   Logs a message with level :const:`CRITICAL` on the root logger. The arguments and behavior
+   are otherwise the same as for :func:`debug`.
 
 
 .. function:: exception(msg, *args, **kwargs)
 
-   Logs a message with level :const:`ERROR` on the root logger. The arguments are
-   interpreted as for :func:`debug`. Exception info is added to the logging
+   Logs a message with level :const:`ERROR` on the root logger. The arguments and behavior
+   are otherwise the same as for :func:`debug`. Exception info is added to the logging
    message. This function should only be called from an exception handler.
 
 .. function:: log(level, msg, *args, **kwargs)
 
-   Logs a message with level *level* on the root logger. The other arguments are
-   interpreted as for :func:`debug`.
+   Logs a message with level *level* on the root logger. The arguments and behavior
+   are otherwise the same as for :func:`debug`.
 
 .. function:: disable(level=CRITICAL)
 
diff --git a/Doc/library/math.rst b/Doc/library/math.rst
index 9e58b55257..32fbf1c082 100644
--- a/Doc/library/math.rst
+++ b/Doc/library/math.rst
@@ -239,11 +239,11 @@ Number-theoretic and representation functions
 
    See also :func:`math.ulp`.
 
+   .. versionadded:: 3.9
+
    .. versionchanged:: 3.12
       Added the *steps* argument.
 
-   .. versionadded:: 3.9
-
 .. function:: perm(n, k=None)
 
    Return the number of ways to choose *k* items from *n* items
@@ -592,7 +592,7 @@ Special functions
 
    The :func:`erf` function can be used to compute traditional statistical
    functions such as the `cumulative standard normal distribution
-   <https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_functions>`_::
+   <https://en.wikipedia.org/wiki/Cumulative_distribution_function>`_::
 
      def phi(x):
          'Cumulative distribution function for the standard normal distribution'
@@ -680,11 +680,11 @@ Constants
       >>> math.isnan(float('nan'))
       True
 
+   .. versionadded:: 3.5
+
    .. versionchanged:: 3.11
       It is now always available.
 
-   .. versionadded:: 3.5
-
 
 .. impl-detail::
 
diff --git a/Doc/library/msvcrt.rst b/Doc/library/msvcrt.rst
index 32693e3d00..2cc7b8aba2 100644
--- a/Doc/library/msvcrt.rst
+++ b/Doc/library/msvcrt.rst
@@ -157,4 +157,18 @@ Other Functions
 .. function:: heapmin()
 
    Force the :c:func:`malloc` heap to clean itself up and return unused blocks to
-   the operating system.  On failure, this raises :exc:`OSError`.
+   the operating system. On failure, this raises :exc:`OSError`.
+
+.. data:: CRT_ASSEMBLY_VERSION
+
+   The CRT Assembly version, from the :file:`crtassem.h` header file.
+
+
+.. data:: VC_ASSEMBLY_PUBLICKEYTOKEN
+
+   The VC Assembly public key token, from the :file:`crtassem.h` header file.
+
+
+.. data:: LIBRARIES_ASSEMBLY_NAME_PREFIX
+
+   The Libraries Assembly name prefix, from the :file:`crtassem.h` header file.
diff --git a/Doc/library/multiprocessing.rst b/Doc/library/multiprocessing.rst
index ac49e7054e..3bea5f001a 100644
--- a/Doc/library/multiprocessing.rst
+++ b/Doc/library/multiprocessing.rst
@@ -150,18 +150,18 @@ to start a process.  These *start methods* are
     over Unix pipes such as Linux.
 
 
-.. versionchanged:: 3.8
-
-   On macOS, the *spawn* start method is now the default.  The *fork* start
-   method should be considered unsafe as it can lead to crashes of the
-   subprocess as macOS system libraries may start threads. See :issue:`33725`.
-
 .. versionchanged:: 3.4
    *spawn* added on all POSIX platforms, and *forkserver* added for
    some POSIX platforms.
    Child processes no longer inherit all of the parents inheritable
    handles on Windows.
 
+.. versionchanged:: 3.8
+
+   On macOS, the *spawn* start method is now the default.  The *fork* start
+   method should be considered unsafe as it can lead to crashes of the
+   subprocess as macOS system libraries may start threads. See :issue:`33725`.
+
 On POSIX using the *spawn* or *forkserver* start methods will also
 start a *resource tracker* process which tracks the unlinked named
 system resources (such as named semaphores or
@@ -519,7 +519,7 @@ The :mod:`multiprocessing` package mostly replicates the API of the
    to the process.
 
    .. versionchanged:: 3.3
-      Added the *daemon* argument.
+      Added the *daemon* parameter.
 
    .. method:: run()
 
@@ -649,8 +649,8 @@ The :mod:`multiprocessing` package mostly replicates the API of the
 
    .. method:: terminate()
 
-      Terminate the process.  On POSIX this is done using the ``SIGTERM`` signal;
-      on Windows :c:func:`TerminateProcess` is used.  Note that exit handlers and
+      Terminate the process.  On POSIX this is done using the :py:const:`~signal.SIGTERM` signal;
+      on Windows :c:func:`!TerminateProcess` is used.  Note that exit handlers and
       finally clauses, etc., will not be executed.
 
       Note that descendant processes of the process will *not* be terminated --
@@ -1077,13 +1077,13 @@ Miscellaneous
    The return value can be ``'fork'``, ``'spawn'``, ``'forkserver'``
    or ``None``.  See :ref:`multiprocessing-start-methods`.
 
-.. versionchanged:: 3.8
+   .. versionadded:: 3.4
 
-   On macOS, the *spawn* start method is now the default.  The *fork* start
-   method should be considered unsafe as it can lead to crashes of the
-   subprocess. See :issue:`33725`.
+   .. versionchanged:: 3.8
 
-   .. versionadded:: 3.4
+      On macOS, the *spawn* start method is now the default.  The *fork* start
+      method should be considered unsafe as it can lead to crashes of the
+      subprocess. See :issue:`33725`.
 
 .. function:: set_executable(executable)
 
@@ -1238,8 +1238,7 @@ Connection objects are usually created using
       Connection objects themselves can now be transferred between processes
       using :meth:`Connection.send` and :meth:`Connection.recv`.
 
-   .. versionadded:: 3.3
-      Connection objects now support the context management protocol -- see
+      Connection objects also now support the context management protocol -- see
       :ref:`typecontextmanager`.  :meth:`~contextmanager.__enter__` returns the
       connection object, and :meth:`~contextmanager.__exit__` calls :meth:`close`.
 
@@ -2243,11 +2242,11 @@ with the :class:`Pool` class.
       as CPython does not assure that the finalizer of the pool will be called
       (see :meth:`object.__del__` for more information).
 
-   .. versionadded:: 3.2
-      *maxtasksperchild*
+   .. versionchanged:: 3.2
+      Added the *maxtasksperchild* parameter.
 
-   .. versionadded:: 3.4
-      *context*
+   .. versionchanged:: 3.4
+      Added the *context* parameter.
 
    .. note::
 
@@ -2369,7 +2368,7 @@ with the :class:`Pool` class.
       Wait for the worker processes to exit.  One must call :meth:`close` or
       :meth:`terminate` before using :meth:`join`.
 
-   .. versionadded:: 3.3
+   .. versionchanged:: 3.3
       Pool objects now support the context management protocol -- see
       :ref:`typecontextmanager`.  :meth:`~contextmanager.__enter__` returns the
       pool object, and :meth:`~contextmanager.__exit__` calls :meth:`terminate`.
@@ -2538,7 +2537,7 @@ multiple connections at the same time.
       The address from which the last accepted connection came.  If this is
       unavailable then it is ``None``.
 
-   .. versionadded:: 3.3
+   .. versionchanged:: 3.3
       Listener objects now support the context management protocol -- see
       :ref:`typecontextmanager`.  :meth:`~contextmanager.__enter__` returns the
       listener object, and :meth:`~contextmanager.__exit__` calls :meth:`close`.
@@ -2969,7 +2968,7 @@ Beware of replacing :data:`sys.stdin` with a "file like object"
 The *spawn* and *forkserver* start methods
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 
-There are a few extra restriction which don't apply to the *fork*
+There are a few extra restrictions which don't apply to the *fork*
 start method.
 
 More picklability
diff --git a/Doc/library/numbers.rst b/Doc/library/numbers.rst
index 17d1a275f0..306bdd94aa 100644
--- a/Doc/library/numbers.rst
+++ b/Doc/library/numbers.rst
@@ -166,7 +166,7 @@ Complex``. I'll consider ``a + b``:
 2. If ``A`` falls back to the boilerplate code, and it were to
    return a value from :meth:`~object.__add__`, we'd miss the possibility
    that ``B`` defines a more intelligent :meth:`~object.__radd__`, so the
-   boilerplate should return :const:`NotImplemented` from
+   boilerplate should return :data:`NotImplemented` from
    :meth:`!__add__`. (Or ``A`` may not implement :meth:`!__add__` at
    all.)
 3. Then ``B``'s :meth:`~object.__radd__` gets a chance. If it accepts
diff --git a/Doc/library/os.rst b/Doc/library/os.rst
index c3e7e1f66d..870e110b6c 100644
--- a/Doc/library/os.rst
+++ b/Doc/library/os.rst
@@ -2544,7 +2544,6 @@ features:
    .. versionchanged:: 3.8
       Accepts a :term:`path-like object` and a bytes object on Windows.
 
-   .. versionchanged:: 3.8
       Added support for directory junctions, and changed to return the
       substitution path (which typically includes ``\\?\`` prefix) rather
       than the optional "print name" field that was previously returned.
@@ -3045,21 +3044,21 @@ features:
 
       Time of most recent access expressed in nanoseconds as an integer.
 
-      .. versionadded: 3.3
+      .. versionadded:: 3.3
 
    .. attribute:: st_mtime_ns
 
       Time of most recent content modification expressed in nanoseconds as an
       integer.
 
-      .. versionadded: 3.3
+      .. versionadded:: 3.3
 
    .. attribute:: st_ctime_ns
 
       Time of most recent metadata change expressed in nanoseconds as an
       integer.
 
-      .. versionadded: 3.3
+      .. versionadded:: 3.3
 
       .. versionchanged:: 3.12
          ``st_ctime_ns`` is deprecated on Windows. Use ``st_birthtime_ns``
@@ -3187,10 +3186,10 @@ features:
       Windows now returns the file index as :attr:`st_ino` when
       available.
 
-   .. versionadded:: 3.7
+   .. versionchanged:: 3.7
       Added the :attr:`st_fstype` member to Solaris/derivatives.
 
-   .. versionadded:: 3.8
+   .. versionchanged:: 3.8
       Added the :attr:`st_reparse_tag` member on Windows.
 
    .. versionchanged:: 3.8
@@ -3204,16 +3203,13 @@ features:
       platforms, but for now still contains creation time.
       Use :attr:`st_birthtime` for the creation time.
 
-   .. versionchanged:: 3.12
       On Windows, :attr:`st_ino` may now be up to 128 bits, depending
       on the file system. Previously it would not be above 64 bits, and
       larger file identifiers would be arbitrarily packed.
 
-   .. versionchanged:: 3.12
       On Windows, :attr:`st_rdev` no longer returns a value. Previously
       it would contain the same as :attr:`st_dev`, which was incorrect.
 
-   .. versionadded:: 3.12
       Added the :attr:`st_birthtime` member on Windows.
 
 
@@ -4215,15 +4211,15 @@ written in Python, such as a mail server's external command delivery program.
       On macOS the use of this function is unsafe when mixed with using
       higher-level system APIs, and that includes using :mod:`urllib.request`.
 
+   .. versionchanged:: 3.8
+      Calling ``forkpty()`` in a subinterpreter is no longer supported
+      (:exc:`RuntimeError` is raised).
+
    .. versionchanged:: 3.12
       If Python is able to detect that your process has multiple
       threads, this now raises a :exc:`DeprecationWarning`. See the
       longer explanation on :func:`os.fork`.
 
-   .. versionchanged:: 3.8
-      Calling ``forkpty()`` in a subinterpreter is no longer supported
-      (:exc:`RuntimeError` is raised).
-
    .. availability:: Unix, not Emscripten, not WASI.
 
 
@@ -5390,20 +5386,20 @@ Random numbers
       easy-to-use interface to the random number generator provided by your
       platform, please see :class:`random.SystemRandom`.
 
-   .. versionchanged:: 3.6.0
-      On Linux, ``getrandom()`` is now used in blocking mode to increase the
-      security.
-
-   .. versionchanged:: 3.5.2
-      On Linux, if the ``getrandom()`` syscall blocks (the urandom entropy pool
-      is not initialized yet), fall back on reading ``/dev/urandom``.
-
    .. versionchanged:: 3.5
       On Linux 3.17 and newer, the ``getrandom()`` syscall is now used
       when available.  On OpenBSD 5.6 and newer, the C ``getentropy()``
       function is now used. These functions avoid the usage of an internal file
       descriptor.
 
+   .. versionchanged:: 3.5.2
+      On Linux, if the ``getrandom()`` syscall blocks (the urandom entropy pool
+      is not initialized yet), fall back on reading ``/dev/urandom``.
+
+   .. versionchanged:: 3.6
+      On Linux, ``getrandom()`` is now used in blocking mode to increase the
+      security.
+
    .. versionchanged:: 3.11
       On Windows, ``BCryptGenRandom()`` is used instead of ``CryptGenRandom()``
       which is deprecated.
diff --git a/Doc/library/pdb.rst b/Doc/library/pdb.rst
index 785a8ab0c8..b8f15aaa5a 100644
--- a/Doc/library/pdb.rst
+++ b/Doc/library/pdb.rst
@@ -284,19 +284,20 @@ There are three preset *convenience variables*:
 
 If a file :file:`.pdbrc` exists in the user's home directory or in the current
 directory, it is read with ``'utf-8'`` encoding and executed as if it had been
-typed at the debugger prompt.  This is particularly useful for aliases.  If both
+typed at the debugger prompt, with the exception that empty lines and lines
+starting with ``#`` are ignored.  This is particularly useful for aliases.  If both
 files exist, the one in the home directory is read first and aliases defined there
 can be overridden by the local file.
 
-.. versionchanged:: 3.11
-   :file:`.pdbrc` is now read with ``'utf-8'`` encoding. Previously, it was read
-   with the system locale encoding.
-
 .. versionchanged:: 3.2
    :file:`.pdbrc` can now contain commands that continue debugging, such as
    :pdbcmd:`continue` or :pdbcmd:`next`.  Previously, these commands had no
    effect.
 
+.. versionchanged:: 3.11
+   :file:`.pdbrc` is now read with ``'utf-8'`` encoding. Previously, it was read
+   with the system locale encoding.
+
 
 .. pdbcommand:: h(elp) [command]
 
diff --git a/Doc/library/pickle.rst b/Doc/library/pickle.rst
index c622469d5d..49417ad24d 100644
--- a/Doc/library/pickle.rst
+++ b/Doc/library/pickle.rst
@@ -373,7 +373,7 @@ The :mod:`pickle` module exports three classes, :class:`Pickler`,
       Special reducer that can be defined in :class:`Pickler` subclasses. This
       method has priority over any reducer in the :attr:`dispatch_table`.  It
       should conform to the same interface as a :meth:`~object.__reduce__` method, and
-      can optionally return ``NotImplemented`` to fallback on
+      can optionally return :data:`NotImplemented` to fallback on
       :attr:`dispatch_table`-registered reducers to pickle ``obj``.
 
       For a detailed example, see :ref:`reducer_override`.
@@ -495,7 +495,7 @@ What can be pickled and unpickled?
 The following types can be pickled:
 
 * built-in constants (``None``, ``True``, ``False``, ``Ellipsis``, and
-  ``NotImplemented``);
+  :data:`NotImplemented`);
 
 * integers, floating-point numbers, complex numbers;
 
@@ -645,8 +645,8 @@ methods:
 
    .. note::
 
-      If :meth:`__getstate__` returns a false value, the :meth:`__setstate__`
-      method will not be called upon unpickling.
+      If :meth:`__reduce__` returns a state with value ``None`` at pickling,
+      the :meth:`__setstate__` method will not be called upon unpickling.
 
 
 Refer to the section :ref:`pickle-state` for more information about how to use
@@ -897,7 +897,7 @@ functions and classes.
 For those cases, it is possible to subclass from the :class:`Pickler` class and
 implement a :meth:`~Pickler.reducer_override` method. This method can return an
 arbitrary reduction tuple (see :meth:`~object.__reduce__`). It can alternatively return
-``NotImplemented`` to fallback to the traditional behavior.
+:data:`NotImplemented` to fallback to the traditional behavior.
 
 If both the :attr:`~Pickler.dispatch_table` and
 :meth:`~Pickler.reducer_override` are defined, then
diff --git a/Doc/library/pprint.rst b/Doc/library/pprint.rst
index e883acd67d..eebd270a09 100644
--- a/Doc/library/pprint.rst
+++ b/Doc/library/pprint.rst
@@ -31,7 +31,96 @@ Dictionaries are sorted by key before the display is computed.
 .. versionchanged:: 3.10
    Added support for pretty-printing :class:`dataclasses.dataclass`.
 
-The :mod:`pprint` module defines one class:
+.. _pprint-functions:
+
+Functions
+---------
+
+.. function:: pp(object, *args, sort_dicts=False, **kwargs)
+
+   Prints the formatted representation of *object* followed by a newline.
+   If *sort_dicts* is false (the default), dictionaries will be displayed with
+   their keys in insertion order, otherwise the dict keys will be sorted.
+   *args* and *kwargs* will be passed to :func:`~pprint.pprint` as formatting
+   parameters.
+
+      >>> import pprint
+      >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
+      >>> stuff.insert(0, stuff)
+      >>> pprint.pp(stuff)
+      [<Recursion on list with id=...>,
+       'spam',
+       'eggs',
+       'lumberjack',
+       'knights',
+       'ni']
+
+   .. versionadded:: 3.8
+
+
+.. function:: pprint(object, stream=None, indent=1, width=80, depth=None, *, \
+                     compact=False, sort_dicts=True, underscore_numbers=False)
+
+   Prints the formatted representation of *object* on *stream*, followed by a
+   newline.  If *stream* is ``None``, :data:`sys.stdout` is used. This may be used
+   in the interactive interpreter instead of the :func:`print` function for
+   inspecting values (you can even reassign ``print = pprint.pprint`` for use
+   within a scope).
+
+   The configuration parameters *stream*, *indent*, *width*, *depth*,
+   *compact*, *sort_dicts* and *underscore_numbers* are passed to the
+   :class:`PrettyPrinter` constructor and their meanings are as
+   described in its documentation below.
+
+   Note that *sort_dicts* is ``True`` by default and you might want to use
+   :func:`~pprint.pp` instead where it is ``False`` by default.
+
+.. function:: pformat(object, indent=1, width=80, depth=None, *, \
+                      compact=False, sort_dicts=True, underscore_numbers=False)
+
+   Return the formatted representation of *object* as a string.  *indent*,
+   *width*, *depth*, *compact*, *sort_dicts* and *underscore_numbers* are
+   passed to the :class:`PrettyPrinter` constructor as formatting parameters
+   and their meanings are as described in its documentation below.
+
+
+.. function:: isreadable(object)
+
+   .. index:: pair: built-in function; eval
+
+   Determine if the formatted representation of *object* is "readable", or can be
+   used to reconstruct the value using :func:`eval`.  This always returns ``False``
+   for recursive objects.
+
+      >>> pprint.isreadable(stuff)
+      False
+
+
+.. function:: isrecursive(object)
+
+   Determine if *object* requires a recursive representation.  This function is
+   subject to the same limitations as noted in :func:`saferepr` below and may raise an
+   :exc:`RecursionError` if it fails to detect a recursive object.
+
+
+.. function:: saferepr(object)
+
+   Return a string representation of *object*, protected against recursion in
+   some common data structures, namely instances of :class:`dict`, :class:`list`
+   and :class:`tuple` or subclasses whose ``__repr__`` has not been overridden.  If the
+   representation of object exposes a recursive entry, the recursive reference
+   will be represented as ``<Recursion on typename with id=number>``.  The
+   representation is not otherwise formatted.
+
+   >>> pprint.saferepr(stuff)
+   "[<Recursion on list with id=...>, 'spam', 'eggs', 'lumberjack', 'knights', 'ni']"
+
+.. _prettyprinter-objects:
+
+PrettyPrinter Objects
+---------------------
+
+This module defines one class:
 
 .. First the implementation class:
 
@@ -44,9 +133,9 @@ The :mod:`pprint` module defines one class:
    Construct a :class:`PrettyPrinter` instance.  This constructor understands
    several keyword parameters.
 
-   *stream* (default ``sys.stdout``) is a :term:`file-like object` to
+   *stream* (default :data:`!sys.stdout`) is a :term:`file-like object` to
    which the output will be written by calling its :meth:`!write` method.
-   If both *stream* and ``sys.stdout`` are ``None``, then
+   If both *stream* and :data:`!sys.stdout` are ``None``, then
    :meth:`~PrettyPrinter.pprint` silently returns.
 
    Other values configure the manner in which nesting of complex data
@@ -87,7 +176,7 @@ The :mod:`pprint` module defines one class:
       Added the *underscore_numbers* parameter.
 
    .. versionchanged:: 3.11
-      No longer attempts to write to ``sys.stdout`` if it is ``None``.
+      No longer attempts to write to :data:`!sys.stdout` if it is ``None``.
 
       >>> import pprint
       >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
@@ -112,89 +201,6 @@ The :mod:`pprint` module defines one class:
       >>> pp.pprint(tup)
       ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead', (...)))))))
 
-.. function:: pformat(object, indent=1, width=80, depth=None, *, \
-                      compact=False, sort_dicts=True, underscore_numbers=False)
-
-   Return the formatted representation of *object* as a string.  *indent*,
-   *width*, *depth*, *compact*, *sort_dicts* and *underscore_numbers* are
-   passed to the :class:`PrettyPrinter` constructor as formatting parameters
-   and their meanings are as described in its documentation above.
-
-
-.. function:: pp(object, *args, sort_dicts=False, **kwargs)
-
-   Prints the formatted representation of *object* followed by a newline.
-   If *sort_dicts* is false (the default), dictionaries will be displayed with
-   their keys in insertion order, otherwise the dict keys will be sorted.
-   *args* and *kwargs* will be passed to :func:`pprint` as formatting
-   parameters.
-
-   .. versionadded:: 3.8
-
-
-.. function:: pprint(object, stream=None, indent=1, width=80, depth=None, *, \
-                     compact=False, sort_dicts=True, underscore_numbers=False)
-
-   Prints the formatted representation of *object* on *stream*, followed by a
-   newline.  If *stream* is ``None``, ``sys.stdout`` is used. This may be used
-   in the interactive interpreter instead of the :func:`print` function for
-   inspecting values (you can even reassign ``print = pprint.pprint`` for use
-   within a scope).
-
-   The configuration parameters *stream*, *indent*, *width*, *depth*,
-   *compact*, *sort_dicts* and *underscore_numbers* are passed to the
-   :class:`PrettyPrinter` constructor and their meanings are as
-   described in its documentation above.
-
-      >>> import pprint
-      >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
-      >>> stuff.insert(0, stuff)
-      >>> pprint.pprint(stuff)
-      [<Recursion on list with id=...>,
-       'spam',
-       'eggs',
-       'lumberjack',
-       'knights',
-       'ni']
-
-.. function:: isreadable(object)
-
-   .. index:: pair: built-in function; eval
-
-   Determine if the formatted representation of *object* is "readable", or can be
-   used to reconstruct the value using :func:`eval`.  This always returns ``False``
-   for recursive objects.
-
-      >>> pprint.isreadable(stuff)
-      False
-
-
-.. function:: isrecursive(object)
-
-   Determine if *object* requires a recursive representation.  This function is
-   subject to the same limitations as noted in :func:`saferepr` below and may raise an
-   :exc:`RecursionError` if it fails to detect a recursive object.
-
-
-One more support function is also defined:
-
-.. function:: saferepr(object)
-
-   Return a string representation of *object*, protected against recursion in
-   some common data structures, namely instances of :class:`dict`, :class:`list`
-   and :class:`tuple` or subclasses whose ``__repr__`` has not been overridden.  If the
-   representation of object exposes a recursive entry, the recursive reference
-   will be represented as ``<Recursion on typename with id=number>``.  The
-   representation is not otherwise formatted.
-
-   >>> pprint.saferepr(stuff)
-   "[<Recursion on list with id=...>, 'spam', 'eggs', 'lumberjack', 'knights', 'ni']"
-
-
-.. _prettyprinter-objects:
-
-PrettyPrinter Objects
----------------------
 
 :class:`PrettyPrinter` instances have the following methods:
 
@@ -258,7 +264,7 @@ are converted to strings.  The default implementation uses the internals of the
 Example
 -------
 
-To demonstrate several uses of the :func:`pprint` function and its parameters,
+To demonstrate several uses of the :func:`~pprint.pp` function and its parameters,
 let's fetch information about a project from `PyPI <https://pypi.org>`_::
 
    >>> import json
@@ -267,9 +273,9 @@ let's fetch information about a project from `PyPI <https://pypi.org>`_::
    >>> with urlopen('https://pypi.org/pypi/sampleproject/json') as resp:
    ...     project_info = json.load(resp)['info']
 
-In its basic form, :func:`pprint` shows the whole object::
+In its basic form, :func:`~pprint.pp` shows the whole object::
 
-   >>> pprint.pprint(project_info)
+   >>> pprint.pp(project_info)
    {'author': 'The Python Packaging Authority',
     'author_email': 'pypa-dev@googlegroups.com',
     'bugtrack_url': None,
@@ -326,7 +332,7 @@ In its basic form, :func:`pprint` shows the whole object::
 The result can be limited to a certain *depth* (ellipsis is used for deeper
 contents)::
 
-   >>> pprint.pprint(project_info, depth=1)
+   >>> pprint.pp(project_info, depth=1)
    {'author': 'The Python Packaging Authority',
     'author_email': 'pypa-dev@googlegroups.com',
     'bugtrack_url': None,
@@ -372,7 +378,7 @@ contents)::
 Additionally, maximum character *width* can be suggested. If a long object
 cannot be split, the specified width will be exceeded::
 
-   >>> pprint.pprint(project_info, depth=1, width=60)
+   >>> pprint.pp(project_info, depth=1, width=60)
    {'author': 'The Python Packaging Authority',
     'author_email': 'pypa-dev@googlegroups.com',
     'bugtrack_url': None,
diff --git a/Doc/library/pydoc.rst b/Doc/library/pydoc.rst
index 03e0915bf6..df969b2fc7 100644
--- a/Doc/library/pydoc.rst
+++ b/Doc/library/pydoc.rst
@@ -16,19 +16,19 @@
 
 --------------
 
-The :mod:`pydoc` module automatically generates documentation from Python
+The :mod:`!pydoc` module automatically generates documentation from Python
 modules.  The documentation can be presented as pages of text on the console,
 served to a web browser, or saved to HTML files.
 
 For modules, classes, functions and methods, the displayed documentation is
-derived from the docstring (i.e. the :attr:`__doc__` attribute) of the object,
+derived from the docstring (i.e. the :attr:`!__doc__` attribute) of the object,
 and recursively of its documentable members.  If there is no docstring,
-:mod:`pydoc` tries to obtain a description from the block of comment lines just
+:mod:`!pydoc` tries to obtain a description from the block of comment lines just
 above the definition of the class, function or method in the source file, or at
 the top of the module (see :func:`inspect.getcomments`).
 
 The built-in function :func:`help` invokes the online help system in the
-interactive interpreter, which uses :mod:`pydoc` to generate its documentation
+interactive interpreter, which uses :mod:`!pydoc` to generate its documentation
 as text on the console.  The same text documentation can also be viewed from
 outside the Python interpreter by running :program:`pydoc` as a script at the
 operating system's command prompt. For example, running ::
@@ -46,7 +46,7 @@ produced for that file.
 
 .. note::
 
-   In order to find objects and their documentation, :mod:`pydoc` imports the
+   In order to find objects and their documentation, :mod:`!pydoc` imports the
    module(s) to be documented.  Therefore, any code on module level will be
    executed on that occasion.  Use an ``if __name__ == '__main__':`` guard to
    only execute code when a file is invoked as a script and not just imported.
@@ -90,7 +90,7 @@ Python interpreter and typed ``import spam``.
 Module docs for core modules are assumed to reside in
 ``https://docs.python.org/X.Y/library/`` where ``X`` and ``Y`` are the
 major and minor version numbers of the Python interpreter.  This can
-be overridden by setting the :envvar:`PYTHONDOCS` environment variable
+be overridden by setting the :envvar:`!PYTHONDOCS` environment variable
 to a different URL or to a local directory containing the Library
 Reference Manual pages.
 
@@ -101,7 +101,7 @@ Reference Manual pages.
    The ``-g`` command line option was removed.
 
 .. versionchanged:: 3.4
-   :mod:`pydoc` now uses :func:`inspect.signature` rather than
+   :mod:`!pydoc` now uses :func:`inspect.signature` rather than
    :func:`inspect.getfullargspec` to extract signature information from
    callables.
 
diff --git a/Doc/library/pyexpat.rst b/Doc/library/pyexpat.rst
index 935e872480..cb05375b39 100644
--- a/Doc/library/pyexpat.rst
+++ b/Doc/library/pyexpat.rst
@@ -196,6 +196,42 @@ XMLParser Objects
    :exc:`ExpatError` to be raised with the :attr:`code` attribute set to
    ``errors.codes[errors.XML_ERROR_CANT_CHANGE_FEATURE_ONCE_PARSING]``.
 
+.. method:: xmlparser.SetReparseDeferralEnabled(enabled)
+
+   .. warning::
+
+      Calling ``SetReparseDeferralEnabled(False)`` has security implications,
+      as detailed below; please make sure to understand these consequences
+      prior to using the ``SetReparseDeferralEnabled`` method.
+
+   Expat 2.6.0 introduced a security mechanism called "reparse deferral"
+   where instead of causing denial of service through quadratic runtime
+   from reparsing large tokens, reparsing of unfinished tokens is now delayed
+   by default until a sufficient amount of input is reached.
+   Due to this delay, registered handlers may  depending of the sizing of
+   input chunks pushed to Expat  no longer be called right after pushing new
+   input to the parser.  Where immediate feedback and taking over responsiblity
+   of protecting against denial of service from large tokens are both wanted,
+   calling ``SetReparseDeferralEnabled(False)`` disables reparse deferral
+   for the current Expat parser instance, temporarily or altogether.
+   Calling ``SetReparseDeferralEnabled(True)`` allows re-enabling reparse
+   deferral.
+
+   Note that :meth:`SetReparseDeferralEnabled` has been backported to some
+   prior releases of CPython as a security fix.  Check for availability of
+   :meth:`SetReparseDeferralEnabled` using :func:`hasattr` if used in code
+   running across a variety of Python versions.
+
+   .. versionadded:: 3.12.3
+
+.. method:: xmlparser.GetReparseDeferralEnabled()
+
+   Returns whether reparse deferral is currently enabled for the given
+   Expat parser instance.
+
+   .. versionadded:: 3.12.3
+
+
 :class:`xmlparser` objects have the following attributes:
 
 
@@ -214,7 +250,8 @@ XMLParser Objects
    :meth:`CharacterDataHandler` callback whenever possible.  This can improve
    performance substantially since Expat normally breaks character data into chunks
    at every line ending.  This attribute is false by default, and may be changed at
-   any time.
+   any time. Note that when it is false, data that does not contain newlines
+   may be chunked too.
 
 
 .. attribute:: xmlparser.buffer_used
@@ -372,7 +409,10 @@ otherwise stated.
    marked content, and ignorable whitespace.  Applications which must distinguish
    these cases can use the :attr:`StartCdataSectionHandler`,
    :attr:`EndCdataSectionHandler`, and :attr:`ElementDeclHandler` callbacks to
-   collect the required information.
+   collect the required information. Note that the character data may be
+   chunked even if it is short and so you may receive more than one call to
+   :meth:`CharacterDataHandler`. Set the :attr:`buffer_text` instance attribute
+   to ``True`` to avoid that.
 
 
 .. method:: xmlparser.UnparsedEntityDeclHandler(entityName, base, systemId, publicId, notationName)
diff --git a/Doc/library/random.rst b/Doc/library/random.rst
index d0ced2416c..8fbce18c56 100644
--- a/Doc/library/random.rst
+++ b/Doc/library/random.rst
@@ -301,7 +301,8 @@ be found in any statistics text.
    ``a <= b`` and ``b <= N <= a`` for ``b < a``.
 
    The end-point value ``b`` may or may not be included in the range
-   depending on floating-point rounding in the equation ``a + (b-a) * random()``.
+   depending on floating-point rounding in the expression
+   ``a + (b-a) * random()``.
 
 
 .. function:: triangular(low, high, mode)
diff --git a/Doc/library/re.rst b/Doc/library/re.rst
index 61aaf14ada..e7d3c32a0f 100644
--- a/Doc/library/re.rst
+++ b/Doc/library/re.rst
@@ -1338,7 +1338,8 @@ when there is no match, you can test whether there was a match with a simple
    Escapes such as ``\n`` are converted to the appropriate characters,
    and numeric backreferences (``\1``, ``\2``) and named backreferences
    (``\g<1>``, ``\g<name>``) are replaced by the contents of the
-   corresponding group.
+   corresponding group. The backreference ``\g<0>`` will be
+   replaced by the entire match.
 
    .. versionchanged:: 3.5
       Unmatched groups are replaced with an empty string.
@@ -1591,7 +1592,7 @@ To find out what card the pair consists of, one could use the
 Simulating scanf()
 ^^^^^^^^^^^^^^^^^^
 
-.. index:: single: scanf()
+.. index:: single: scanf (C function)
 
 Python does not currently have an equivalent to :c:func:`!scanf`.  Regular
 expressions are generally more powerful, though also more verbose, than
diff --git a/Doc/library/resource.rst b/Doc/library/resource.rst
index 4e58b043f1..389a63f089 100644
--- a/Doc/library/resource.rst
+++ b/Doc/library/resource.rst
@@ -177,6 +177,8 @@ platform.
 
    The largest area of mapped memory which the process may occupy.
 
+   .. availability:: FreeBSD >= 11.
+
 
 .. data:: RLIMIT_AS
 
diff --git a/Doc/library/sched.rst b/Doc/library/sched.rst
index 01bac5afd0..4c980dd97f 100644
--- a/Doc/library/sched.rst
+++ b/Doc/library/sched.rst
@@ -36,7 +36,7 @@ scheduler:
 Example::
 
    >>> import sched, time
-   >>> s = sched.scheduler(time.monotonic, time.sleep)
+   >>> s = sched.scheduler(time.time, time.sleep)
    >>> def print_time(a='default'):
    ...     print("From print_time", time.time(), a)
    ...
diff --git a/Doc/library/shutil.rst b/Doc/library/shutil.rst
index 3b98a196a8..c9d367cb7e 100644
--- a/Doc/library/shutil.rst
+++ b/Doc/library/shutil.rst
@@ -39,7 +39,7 @@ Directory and files operations
 
 .. function:: copyfileobj(fsrc, fdst[, length])
 
-   Copy the contents of the file-like object *fsrc* to the file-like object *fdst*.
+   Copy the contents of the :term:`file-like object <file object>` *fsrc* to the file-like object *fdst*.
    The integer *length*, if given, is the buffer size. In particular, a negative
    *length* value means to copy the data without looping over the source data in
    chunks; by default the data is read in chunks to avoid uncontrolled memory
@@ -52,7 +52,7 @@ Directory and files operations
 
    Copy the contents (no metadata) of the file named *src* to a file named
    *dst* and return *dst* in the most efficient way possible.
-   *src* and *dst* are path-like objects or path names given as strings.
+   *src* and *dst* are :term:`path-like objects <path-like object>` or path names given as strings.
 
    *dst* must be the complete target file name; look at :func:`~shutil.copy`
    for a copy that accepts a target directory path.  If *src* and *dst*
@@ -94,7 +94,7 @@ Directory and files operations
 .. function:: copymode(src, dst, *, follow_symlinks=True)
 
    Copy the permission bits from *src* to *dst*.  The file contents, owner, and
-   group are unaffected.  *src* and *dst* are path-like objects or path names
+   group are unaffected.  *src* and *dst* are :term:`path-like objects <path-like object>` or path names
    given as strings.
    If *follow_symlinks* is false, and both *src* and *dst* are symbolic links,
    :func:`copymode` will attempt to modify the mode of *dst* itself (rather
@@ -113,7 +113,7 @@ Directory and files operations
    Copy the permission bits, last access time, last modification time, and
    flags from *src* to *dst*.  On Linux, :func:`copystat` also copies the
    "extended attributes" where possible.  The file contents, owner, and
-   group are unaffected.  *src* and *dst* are path-like objects or path
+   group are unaffected.  *src* and *dst* are :term:`path-like objects <path-like object>` or path
    names given as strings.
 
    If *follow_symlinks* is false, and *src* and *dst* both
@@ -274,16 +274,16 @@ Directory and files operations
 
    .. audit-event:: shutil.copytree src,dst shutil.copytree
 
-   .. versionchanged:: 3.3
-      Copy metadata when *symlinks* is false.
-      Now returns *dst*.
-
    .. versionchanged:: 3.2
       Added the *copy_function* argument to be able to provide a custom copy
       function.
       Added the *ignore_dangling_symlinks* argument to silence dangling symlinks
       errors when *symlinks* is false.
 
+   .. versionchanged:: 3.3
+      Copy metadata when *symlinks* is false.
+      Now returns *dst*.
+
    .. versionchanged:: 3.8
       Platform-specific fast-copy syscalls may be used internally in order to
       copy the file more efficiently. See
diff --git a/Doc/library/socket.rst b/Doc/library/socket.rst
index 4bfb0d8c2c..dccf78ef8c 100644
--- a/Doc/library/socket.rst
+++ b/Doc/library/socket.rst
@@ -1605,8 +1605,9 @@ to sockets.
 
    Receive data from the socket.  The return value is a bytes object representing the
    data received.  The maximum amount of data to be received at once is specified
-   by *bufsize*.  See the Unix manual page :manpage:`recv(2)` for the meaning of
-   the optional argument *flags*; it defaults to zero.
+   by *bufsize*. A returned empty bytes object indicates that the client has disconnected.
+   See the Unix manual page :manpage:`recv(2)` for the meaning of the optional argument
+   *flags*; it defaults to zero.
 
    .. note::
 
diff --git a/Doc/library/sqlite3.rst b/Doc/library/sqlite3.rst
index bd45cc8800..4c71e5202f 100644
--- a/Doc/library/sqlite3.rst
+++ b/Doc/library/sqlite3.rst
@@ -1104,7 +1104,7 @@ Connection objects
       .. versionchanged:: 3.12
          Added the *entrypoint* parameter.
 
-   .. _Loading an Extension: https://www.sqlite.org/loadext.html#loading_an_extension_
+   .. _Loading an Extension: https://www.sqlite.org/loadext.html#loading_an_extension
 
    .. method:: iterdump
 
diff --git a/Doc/library/ssl.rst b/Doc/library/ssl.rst
index 4caee84985..f1c39a7366 100644
--- a/Doc/library/ssl.rst
+++ b/Doc/library/ssl.rst
@@ -735,11 +735,11 @@ Constants
    When Python has been compiled against an older version of OpenSSL, the
    flag defaults to *0*.
 
-   .. versionadded:: 3.7
+   .. versionadded:: 3.6.3
 
    .. deprecated:: 3.7
-      The option is deprecated since OpenSSL 1.1.0. It was added to 2.7.15,
-      3.6.3 and 3.7.0 for backwards compatibility with OpenSSL 1.0.2.
+      The option is deprecated since OpenSSL 1.1.0. It was added to 2.7.15 and
+      3.6.3 for backwards compatibility with OpenSSL 1.0.2.
 
 .. data:: OP_NO_RENEGOTIATION
 
@@ -1765,6 +1765,9 @@ to speed up repeated connections from the same clients.
 
    *session*, see :attr:`~SSLSocket.session`.
 
+   To wrap an :class:`SSLSocket` in another :class:`SSLSocket`, use
+   :meth:`SSLContext.wrap_bio`.
+
    .. versionchanged:: 3.5
       Always allow a server_hostname to be passed, even if OpenSSL does not
       have SNI.
@@ -1950,7 +1953,7 @@ to speed up repeated connections from the same clients.
 
    .. versionchanged:: 3.10
 
-      The flag had no effect with OpenSSL before version 1.1.1k. Python 3.8.9,
+      The flag had no effect with OpenSSL before version 1.1.1l. Python 3.8.9,
       3.9.3, and 3.10 include workarounds for previous versions.
 
 .. attribute:: SSLContext.security_level
diff --git a/Doc/library/statistics.rst b/Doc/library/statistics.rst
index 3a4d265a6a..d0274e8b20 100644
--- a/Doc/library/statistics.rst
+++ b/Doc/library/statistics.rst
@@ -79,7 +79,7 @@ or sample.
 :func:`median`           Median (middle value) of data.
 :func:`median_low`       Low median of data.
 :func:`median_high`      High median of data.
-:func:`median_grouped`   Median, or 50th percentile, of grouped data.
+:func:`median_grouped`   Median (50th percentile) of grouped data.
 :func:`mode`             Single mode (most common value) of discrete or nominal data.
 :func:`multimode`        List of modes (most common values) of discrete or nominal data.
 :func:`quantiles`        Divide data into intervals with equal probability.
@@ -329,55 +329,56 @@ However, for reading convenience, most of the examples show sorted sequences.
    be an actual data point rather than interpolated.
 
 
-.. function:: median_grouped(data, interval=1)
+.. function:: median_grouped(data, interval=1.0)
 
-   Return the median of grouped continuous data, calculated as the 50th
-   percentile, using interpolation.  If *data* is empty, :exc:`StatisticsError`
-   is raised.  *data* can be a sequence or iterable.
+   Estimates the median for numeric data that has been `grouped or binned
+   <https://en.wikipedia.org/wiki/Data_binning>`_ around the midpoints
+   of consecutive, fixed-width intervals.
 
-   .. doctest::
+   The *data* can be any iterable of numeric data with each value being
+   exactly the midpoint of a bin.  At least one value must be present.
 
-      >>> median_grouped([52, 52, 53, 54])
-      52.5
+   The *interval* is the width of each bin.
 
-   In the following example, the data are rounded, so that each value represents
-   the midpoint of data classes, e.g. 1 is the midpoint of the class 0.5--1.5, 2
-   is the midpoint of 1.5--2.5, 3 is the midpoint of 2.5--3.5, etc.  With the data
-   given, the middle value falls somewhere in the class 3.5--4.5, and
-   interpolation is used to estimate it:
+   For example, demographic information may have been summarized into
+   consecutive ten-year age groups with each group being represented
+   by the 5-year midpoints of the intervals:
 
    .. doctest::
 
-      >>> median_grouped([1, 2, 2, 3, 4, 4, 4, 4, 4, 5])
-      3.7
-
-   Optional argument *interval* represents the class interval, and defaults
-   to 1.  Changing the class interval naturally will change the interpolation:
+      >>> from collections import Counter
+      >>> demographics = Counter({
+      ...    25: 172,   # 20 to 30 years old
+      ...    35: 484,   # 30 to 40 years old
+      ...    45: 387,   # 40 to 50 years old
+      ...    55:  22,   # 50 to 60 years old
+      ...    65:   6,   # 60 to 70 years old
+      ... })
+      ...
+
+   The 50th percentile (median) is the 536th person out of the 1071
+   member cohort.  That person is in the 30 to 40 year old age group.
+
+   The regular :func:`median` function would assume that everyone in the
+   tricenarian age group was exactly 35 years old.  A more tenable
+   assumption is that the 484 members of that age group are evenly
+   distributed between 30 and 40.  For that, we use
+   :func:`median_grouped`:
 
    .. doctest::
 
-      >>> median_grouped([1, 3, 3, 5, 7], interval=1)
-      3.25
-      >>> median_grouped([1, 3, 3, 5, 7], interval=2)
-      3.5
-
-   This function does not check whether the data points are at least
-   *interval* apart.
-
-   .. impl-detail::
-
-      Under some circumstances, :func:`median_grouped` may coerce data points to
-      floats.  This behaviour is likely to change in the future.
-
-   .. seealso::
+       >>> data = list(demographics.elements())
+       >>> median(data)
+       35
+       >>> round(median_grouped(data, interval=10), 1)
+       37.5
 
-      * "Statistics for the Behavioral Sciences", Frederick J Gravetter and
-        Larry B Wallnau (8th Edition).
+   The caller is responsible for making sure the data points are separated
+   by exact multiples of *interval*.  This is essential for getting a
+   correct result.  The function does not check this precondition.
 
-      * The `SSMEDIAN
-        <https://help.gnome.org/users/gnumeric/stable/gnumeric.html#gnumeric-function-SSMEDIAN>`_
-        function in the Gnome Gnumeric spreadsheet, including `this discussion
-        <https://mail.gnome.org/archives/gnumeric-list/2011-April/msg00018.html>`_.
+   Inputs may be any numeric type that can be coerced to a float during
+   the interpolation step.
 
 
 .. function:: mode(data)
@@ -938,8 +939,8 @@ of applications in statistics.
     .. versionadded:: 3.8
 
 
-:class:`NormalDist` Examples and Recipes
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+Examples and Recipes
+--------------------
 
 
 Classic probability problems
@@ -974,7 +975,7 @@ Find the `quartiles <https://en.wikipedia.org/wiki/Quartile>`_ and `deciles
 Monte Carlo inputs for simulations
 **********************************
 
-To estimate the distribution for a model than isn't easy to solve
+To estimate the distribution for a model that isn't easy to solve
 analytically, :class:`NormalDist` can generate input samples for a `Monte
 Carlo simulation <https://en.wikipedia.org/wiki/Monte_Carlo_method>`_:
 
diff --git a/Doc/library/stdtypes.rst b/Doc/library/stdtypes.rst
index ccc00198b6..249a1c58d0 100644
--- a/Doc/library/stdtypes.rst
+++ b/Doc/library/stdtypes.rst
@@ -1491,8 +1491,7 @@ objects that compare equal might have different :attr:`~range.start`,
    sequence of values they define (instead of comparing based on
    object identity).
 
-.. versionadded:: 3.3
-   The :attr:`~range.start`, :attr:`~range.stop` and :attr:`~range.step`
+   Added the :attr:`~range.start`, :attr:`~range.stop` and :attr:`~range.step`
    attributes.
 
 .. seealso::
@@ -5447,10 +5446,10 @@ The NotImplemented Object
 
 This object is returned from comparisons and binary operations when they are
 asked to operate on types they don't support. See :ref:`comparisons` for more
-information.  There is exactly one ``NotImplemented`` object.
-``type(NotImplemented)()`` produces the singleton instance.
+information.  There is exactly one :data:`NotImplemented` object.
+:code:`type(NotImplemented)()` produces the singleton instance.
 
-It is written as ``NotImplemented``.
+It is written as :code:`NotImplemented`.
 
 
 .. _typesinternal:
diff --git a/Doc/library/struct.rst b/Doc/library/struct.rst
index c94dfde4d5..5de003f958 100644
--- a/Doc/library/struct.rst
+++ b/Doc/library/struct.rst
@@ -156,6 +156,21 @@ following table:
 
 If the first character is not one of these, ``'@'`` is assumed.
 
+.. note::
+
+   The number 1023 (``0x3ff`` in hexadecimal) has the following byte representations:
+
+   * ``03 ff`` in big-endian (``>``)
+   * ``ff 03`` in little-endian (``<``)
+
+   Python example:
+
+       >>> import struct
+       >>> struct.pack('>h', 1023)
+       b'\x03\xff'
+       >>> struct.pack('<h', 1023)
+       b'\xff\x03'
+
 Native byte order is big-endian or little-endian, depending on the
 host system. For example, Intel x86, AMD64 (x86-64), and Apple M1 are
 little-endian; IBM z and many legacy architectures are big-endian.
diff --git a/Doc/library/subprocess.rst b/Doc/library/subprocess.rst
index f63ca73b3e..5281bae90a 100644
--- a/Doc/library/subprocess.rst
+++ b/Doc/library/subprocess.rst
@@ -52,10 +52,12 @@ underlying :class:`Popen` interface can be used directly.
 
    If *capture_output* is true, stdout and stderr will be captured.
    When used, the internal :class:`Popen` object is automatically created with
-   ``stdout=PIPE`` and ``stderr=PIPE``. The *stdout* and *stderr* arguments may
-   not be supplied at the same time as *capture_output*.  If you wish to capture
-   and combine both streams into one, use ``stdout=PIPE`` and ``stderr=STDOUT``
-   instead of *capture_output*.
+   *stdout* and *stdin* both set to :data:`~subprocess.PIPE`.
+   The *stdout* and *stderr* arguments may not be supplied at the same time as *capture_output*.
+   If you wish to capture and combine both streams into one,
+   set *stdout* to :data:`~subprocess.PIPE`
+   and *stderr* to :data:`~subprocess.STDOUT`,
+   instead of using *capture_output*.
 
    A *timeout* may be specified in seconds, it is internally passed on to
    :meth:`Popen.communicate`. If the timeout expires, the child process will be
@@ -69,7 +71,8 @@ underlying :class:`Popen` interface can be used directly.
    subprocess's stdin.  If used it must be a byte sequence, or a string if
    *encoding* or *errors* is specified or *text* is true.  When
    used, the internal :class:`Popen` object is automatically created with
-   ``stdin=PIPE``, and the *stdin* argument may not be used as well.
+   *stdin* set to :data:`~subprocess.PIPE`,
+   and the *stdin* argument may not be used as well.
 
    If *check* is true, and the process exits with a non-zero exit code, a
    :exc:`CalledProcessError` exception will be raised. Attributes of that
@@ -857,8 +860,8 @@ Instances of the :class:`Popen` class have the following methods:
 
 .. method:: Popen.terminate()
 
-   Stop the child. On POSIX OSs the method sends SIGTERM to the
-   child. On Windows the Win32 API function :c:func:`TerminateProcess` is called
+   Stop the child. On POSIX OSs the method sends :py:const:`~signal.SIGTERM` to the
+   child. On Windows the Win32 API function :c:func:`!TerminateProcess` is called
    to stop the child.
 
 
diff --git a/Doc/library/sys.rst b/Doc/library/sys.rst
index 198422307b..1672441448 100644
--- a/Doc/library/sys.rst
+++ b/Doc/library/sys.rst
@@ -16,11 +16,13 @@ always available.
    On POSIX systems where Python was built with the standard ``configure``
    script, this contains the ABI flags as specified by :pep:`3149`.
 
+   .. versionadded:: 3.2
+
    .. versionchanged:: 3.8
       Default flags became an empty string (``m`` flag for pymalloc has been
       removed).
 
-   .. versionadded:: 3.2
+   .. availability:: Unix.
 
 
 .. function:: addaudithook(hook)
diff --git a/Doc/library/test.rst b/Doc/library/test.rst
index cad1023021..7d28f62534 100644
--- a/Doc/library/test.rst
+++ b/Doc/library/test.rst
@@ -324,9 +324,9 @@ The :mod:`test.support` module defines the following constants:
 
 .. data:: Py_DEBUG
 
-   True if Python is built with the :c:macro:`Py_DEBUG` macro defined: if
-   Python is :ref:`built in debug mode <debug-build>`
-   (:option:`./configure --with-pydebug <--with-pydebug>`).
+   True if Python was built with the :c:macro:`Py_DEBUG` macro
+   defined, that is, if
+   Python was :ref:`built in debug mode <debug-build>`.
 
    .. versionadded:: 3.12
 
diff --git a/Doc/library/threading.rst b/Doc/library/threading.rst
index 23d8cd158a..719ee15968 100644
--- a/Doc/library/threading.rst
+++ b/Doc/library/threading.rst
@@ -360,12 +360,12 @@ since it is impossible to detect the termination of alien threads.
    base class constructor (``Thread.__init__()``) before doing anything else to
    the thread.
 
+   .. versionchanged:: 3.3
+      Added the *daemon* parameter.
+
    .. versionchanged:: 3.10
       Use the *target* name if *name* argument is omitted.
 
-   .. versionchanged:: 3.3
-      Added the *daemon* argument.
-
    .. method:: start()
 
       Start the thread's activity.
@@ -983,18 +983,15 @@ method.  The :meth:`~Event.wait` method blocks until the flag is true.
 
    .. method:: wait(timeout=None)
 
-      Block until the internal flag is true.  If the internal flag is true on
-      entry, return immediately.  Otherwise, block until another thread calls
-      :meth:`.set` to set the flag to true, or until the optional timeout occurs.
+      Block as long as the internal flag is false and the timeout, if given,
+      has not expired. The return value represents the
+      reason that this blocking method returned; ``True`` if returning because
+      the internal flag is set to true, or ``False`` if a timeout is given and
+      the the internal flag did not become true within the given wait time.
 
       When the timeout argument is present and not ``None``, it should be a
-      floating point number specifying a timeout for the operation in seconds
-      (or fractions thereof).
-
-      This method returns ``True`` if and only if the internal flag has been set to
-      true, either before the wait call or after the wait starts, so it will
-      always return ``True`` except if a timeout is given and the operation
-      times out.
+      floating point number specifying a timeout for the operation in seconds,
+      or fractions thereof.
 
       .. versionchanged:: 3.1
          Previously, the method always returned ``None``.
diff --git a/Doc/library/time.rst b/Doc/library/time.rst
index 93eceed29d..ab99314683 100644
--- a/Doc/library/time.rst
+++ b/Doc/library/time.rst
@@ -381,15 +381,14 @@ Functions
    * Or use ``nanosleep()`` if available (resolution: 1 nanosecond);
    * Or use ``select()`` (resolution: 1 microsecond).
 
-   .. versionchanged:: 3.11
-      On Unix, the ``clock_nanosleep()`` and ``nanosleep()`` functions are now
-      used if available. On Windows, a waitable timer is now used.
-
    .. versionchanged:: 3.5
       The function now sleeps at least *secs* even if the sleep is interrupted
       by a signal, except if the signal handler raises an exception (see
       :pep:`475` for the rationale).
 
+   .. versionchanged:: 3.11
+      On Unix, the ``clock_nanosleep()`` and ``nanosleep()`` functions are now
+      used if available. On Windows, a waitable timer is now used.
 
 .. index::
    single: % (percent); datetime format
@@ -428,6 +427,10 @@ Functions
    | ``%d``    | Day of the month as a decimal number [01,31].  |       |
    |           |                                                |       |
    +-----------+------------------------------------------------+-------+
+   | ``%f``    | Microseconds as a decimal number               | \(1)  |
+   |           |    [000000,999999].                            |       |
+   |           |                                                |       |
+   +-----------+------------------------------------------------+-------+
    | ``%H``    | Hour (24-hour clock) as a decimal number       |       |
    |           | [00,23].                                       |       |
    +-----------+------------------------------------------------+-------+
@@ -443,13 +446,13 @@ Functions
    | ``%M``    | Minute as a decimal number [00,59].            |       |
    |           |                                                |       |
    +-----------+------------------------------------------------+-------+
-   | ``%p``    | Locale's equivalent of either AM or PM.        | \(1)  |
+   | ``%p``    | Locale's equivalent of either AM or PM.        | \(2)  |
    |           |                                                |       |
    +-----------+------------------------------------------------+-------+
-   | ``%S``    | Second as a decimal number [00,61].            | \(2)  |
+   | ``%S``    | Second as a decimal number [00,61].            | \(3)  |
    |           |                                                |       |
    +-----------+------------------------------------------------+-------+
-   | ``%U``    | Week number of the year (Sunday as the first   | \(3)  |
+   | ``%U``    | Week number of the year (Sunday as the first   | \(4)  |
    |           | day of the week) as a decimal number [00,53].  |       |
    |           | All days in a new year preceding the first     |       |
    |           | Sunday are considered to be in week 0.         |       |
@@ -460,7 +463,7 @@ Functions
    | ``%w``    | Weekday as a decimal number [0(Sunday),6].     |       |
    |           |                                                |       |
    +-----------+------------------------------------------------+-------+
-   | ``%W``    | Week number of the year (Monday as the first   | \(3)  |
+   | ``%W``    | Week number of the year (Monday as the first   | \(4)  |
    |           | day of the week) as a decimal number [00,53].  |       |
    |           | All days in a new year preceding the first     |       |
    |           | Monday are considered to be in week 0.         |       |
@@ -495,17 +498,23 @@ Functions
    Notes:
 
    (1)
+       The ``%f`` format directive only applies to :func:`strptime`,
+       not to :func:`strftime`. However, see also :meth:`datetime.datetime.strptime` and
+       :meth:`datetime.datetime.strftime` where the ``%f`` format directive
+       :ref:`applies to microseconds <format-codes>`.
+
+   (2)
       When used with the :func:`strptime` function, the ``%p`` directive only affects
       the output hour field if the ``%I`` directive is used to parse the hour.
 
    .. _leap-second:
 
-   (2)
+   (3)
       The range really is ``0`` to ``61``; value ``60`` is valid in
       timestamps representing `leap seconds`_ and value ``61`` is supported
       for historical reasons.
 
-   (3)
+   (4)
       When used with the :func:`strptime` function, ``%U`` and ``%W`` are only used in
       calculations when the day of the week and the year are specified.
 
diff --git a/Doc/library/turtle.rst b/Doc/library/turtle.rst
index 4e1a0948b0..ae05b2059a 100644
--- a/Doc/library/turtle.rst
+++ b/Doc/library/turtle.rst
@@ -598,7 +598,7 @@ Turtle motion
       >>> turtle.pos()
       (20.00,30.00)
 
-   .. versionadded: 3.12
+   .. versionadded:: 3.12
 
 
 .. function:: setx(x)
diff --git a/Doc/library/types.rst b/Doc/library/types.rst
index f9e0ba4567..3c426498f0 100644
--- a/Doc/library/types.rst
+++ b/Doc/library/types.rst
@@ -188,7 +188,7 @@ Standard names are defined for the following types:
 
    .. index:: pair: built-in function; compile
 
-   The type for code objects such as returned by :func:`compile`.
+   The type of :ref:`code objects <code-objects>` such as returned by :func:`compile`.
 
    .. audit-event:: code.__new__ code,filename,name,argcount,posonlyargcount,kwonlyargcount,nlocals,stacksize,flags types.CodeType
 
@@ -196,12 +196,6 @@ Standard names are defined for the following types:
    required by the initializer.  The audit event only occurs for direct
    instantiation of code objects, and is not raised for normal compilation.
 
-   .. method:: CodeType.replace(**kwargs)
-
-     Return a copy of the code object with new values for the specified fields.
-
-     .. versionadded:: 3.8
-
 .. data:: CellType
 
    The type for cell objects: such objects are used as containers for
diff --git a/Doc/library/typing.rst b/Doc/library/typing.rst
index c8e7729961..cea1f37a07 100644
--- a/Doc/library/typing.rst
+++ b/Doc/library/typing.rst
@@ -23,27 +23,25 @@
 
 --------------
 
-This module provides runtime support for type hints. For the original
-specification of the typing system, see :pep:`484`. For a simplified
-introduction to type hints, see :pep:`483`.
+This module provides runtime support for type hints.
 
+Consider the function below::
 
-The function below takes and returns a string and is annotated as follows::
+   def moon_weight(earth_weight: float) -> str:
+       return f'On the moon, you would weigh {earth_weight * 0.166} kilograms.'
 
-   def greeting(name: str) -> str:
-       return 'Hello ' + name
+The function ``moon_weight`` takes an argument expected to be an instance of :class:`float`,
+as indicated by the *type hint* ``earth_weight: float``. The function is expected to
+return an instance of :class:`str`, as indicated by the ``-> str`` hint.
 
-In the function ``greeting``, the argument ``name`` is expected to be of type
-:class:`str` and the return type :class:`str`. Subtypes are accepted as
-arguments.
+While type hints can be simple classes like :class:`float` or :class:`str`,
+they can also be more complex. The :mod:`typing` module provides a vocabulary of
+more advanced type hints.
 
 New features are frequently added to the ``typing`` module.
 The `typing_extensions <https://pypi.org/project/typing-extensions/>`_ package
 provides backports of these new features to older versions of Python.
 
-For a summary of deprecated features and a deprecation timeline, please see
-`Deprecation Timeline of Major Features`_.
-
 .. seealso::
 
    `"Typing cheat sheet" <https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html>`_
@@ -61,67 +59,11 @@ For a summary of deprecated features and a deprecation timeline, please see
 
 .. _relevant-peps:
 
-Relevant PEPs
-=============
-
-Since the initial introduction of type hints in :pep:`484` and :pep:`483`, a
-number of PEPs have modified and enhanced Python's framework for type
-annotations:
-
-.. raw:: html
-
-   <details>
-   <summary><a style="cursor:pointer;">The full list of PEPs</a></summary>
-
-* :pep:`526`: Syntax for Variable Annotations
-     *Introducing* syntax for annotating variables outside of function
-     definitions, and :data:`ClassVar`
-* :pep:`544`: Protocols: Structural subtyping (static duck typing)
-     *Introducing* :class:`Protocol` and the
-     :func:`@runtime_checkable<runtime_checkable>` decorator
-* :pep:`585`: Type Hinting Generics In Standard Collections
-     *Introducing* :class:`types.GenericAlias` and the ability to use standard
-     library classes as :ref:`generic types<types-genericalias>`
-* :pep:`586`: Literal Types
-     *Introducing* :data:`Literal`
-* :pep:`589`: TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys
-     *Introducing* :class:`TypedDict`
-* :pep:`591`: Adding a final qualifier to typing
-     *Introducing* :data:`Final` and the :func:`@final<final>` decorator
-* :pep:`593`: Flexible function and variable annotations
-     *Introducing* :data:`Annotated`
-* :pep:`604`: Allow writing union types as ``X | Y``
-     *Introducing* :data:`types.UnionType` and the ability to use
-     the binary-or operator ``|`` to signify a
-     :ref:`union of types<types-union>`
-* :pep:`612`: Parameter Specification Variables
-     *Introducing* :class:`ParamSpec` and :data:`Concatenate`
-* :pep:`613`: Explicit Type Aliases
-     *Introducing* :data:`TypeAlias`
-* :pep:`646`: Variadic Generics
-     *Introducing* :data:`TypeVarTuple`
-* :pep:`647`: User-Defined Type Guards
-     *Introducing* :data:`TypeGuard`
-* :pep:`655`: Marking individual TypedDict items as required or potentially missing
-     *Introducing* :data:`Required` and :data:`NotRequired`
-* :pep:`673`: Self type
-    *Introducing* :data:`Self`
-* :pep:`675`: Arbitrary Literal String Type
-    *Introducing* :data:`LiteralString`
-* :pep:`681`: Data Class Transforms
-    *Introducing* the :func:`@dataclass_transform<dataclass_transform>` decorator
-* :pep:`692`: Using ``TypedDict`` for more precise ``**kwargs`` typing
-    *Introducing* a new way of typing ``**kwargs`` with :data:`Unpack` and
-    :data:`TypedDict`
-* :pep:`695`: Type Parameter Syntax
-    *Introducing* builtin syntax for creating generic functions, classes, and type aliases.
-* :pep:`698`: Adding an override decorator to typing
-    *Introducing* the :func:`@override<override>` decorator
-
-.. raw:: html
-
-   </details>
-   <br>
+Specification for the Python Type System
+========================================
+
+The canonical, up-to-date specification of the Python type system can be
+found at `"Specification for the Python type system" <https://typing.readthedocs.io/en/latest/spec/index.html>`_.
 
 .. _type-aliases:
 
@@ -944,7 +886,6 @@ using ``[]``.
    be used for this concept instead. Type checkers should treat the two
    equivalently.
 
-   .. versionadded:: 3.5.4
    .. versionadded:: 3.6.2
 
 .. data:: Self
@@ -3234,7 +3175,6 @@ Aliases to types in :mod:`collections`
 
    Deprecated alias to :class:`collections.ChainMap`.
 
-   .. versionadded:: 3.5.4
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
@@ -3245,7 +3185,6 @@ Aliases to types in :mod:`collections`
 
    Deprecated alias to :class:`collections.Counter`.
 
-   .. versionadded:: 3.5.4
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
@@ -3256,7 +3195,6 @@ Aliases to types in :mod:`collections`
 
    Deprecated alias to :class:`collections.deque`.
 
-   .. versionadded:: 3.5.4
    .. versionadded:: 3.6.1
 
    .. deprecated:: 3.9
@@ -3339,7 +3277,7 @@ Aliases to container ABCs in :mod:`collections.abc`
 
    Deprecated alias to :class:`collections.abc.Collection`.
 
-   .. versionadded:: 3.6.0
+   .. versionadded:: 3.6
 
    .. deprecated:: 3.9
       :class:`collections.abc.Collection` now supports subscripting (``[]``).
@@ -3631,7 +3569,6 @@ Aliases to :mod:`contextlib` ABCs
    Deprecated alias to :class:`contextlib.AbstractContextManager`.
 
    .. versionadded:: 3.5.4
-   .. versionadded:: 3.6.0
 
    .. deprecated:: 3.9
       :class:`contextlib.AbstractContextManager`
@@ -3642,7 +3579,6 @@ Aliases to :mod:`contextlib` ABCs
 
    Deprecated alias to :class:`contextlib.AbstractAsyncContextManager`.
 
-   .. versionadded:: 3.5.4
    .. versionadded:: 3.6.2
 
    .. deprecated:: 3.9
diff --git a/Doc/library/unittest.mock.rst b/Doc/library/unittest.mock.rst
index d11307447b..108b5efff5 100644
--- a/Doc/library/unittest.mock.rst
+++ b/Doc/library/unittest.mock.rst
@@ -2094,10 +2094,10 @@ to change the default.
 
 Methods and their defaults:
 
-* ``__lt__``: ``NotImplemented``
-* ``__gt__``: ``NotImplemented``
-* ``__le__``: ``NotImplemented``
-* ``__ge__``: ``NotImplemented``
+* ``__lt__``: :data:`NotImplemented`
+* ``__gt__``: :data:`!NotImplemented`
+* ``__le__``: :data:`!NotImplemented`
+* ``__ge__``: :data:`!NotImplemented`
 * ``__int__``: ``1``
 * ``__contains__``: ``False``
 * ``__len__``: ``0``
@@ -2377,6 +2377,14 @@ passed in.
     >>> m.mock_calls == [call(1), call(1, 2), ANY]
     True
 
+:data:`ANY` is not limited to comparisons with call objects and so
+can also be used in test assertions::
+
+    class TestStringMethods(unittest.TestCase):
+
+        def test_split(self):
+            s = 'hello world'
+            self.assertEqual(s.split(), ['hello', ANY])
 
 
 FILTER_DIR
@@ -2774,3 +2782,123 @@ Sealing mocks
         >>> mock.not_submock.attribute2  # This won't raise.
 
     .. versionadded:: 3.7
+
+
+Order of precedence of :attr:`side_effect`, :attr:`return_value` and *wraps*
+----------------------------------------------------------------------------
+
+The order of their precedence is:
+
+1. :attr:`~Mock.side_effect`
+2. :attr:`~Mock.return_value`
+3. *wraps*
+
+If all three are set, mock will return the value from :attr:`~Mock.side_effect`,
+ignoring :attr:`~Mock.return_value` and the wrapped object altogether. If any
+two are set, the one with the higher precedence will return the value.
+Regardless of the order of which was set first, the order of precedence
+remains unchanged.
+
+    >>> from unittest.mock import Mock
+    >>> class Order:
+    ...     @staticmethod
+    ...     def get_value():
+    ...         return "third"
+    ...
+    >>> order_mock = Mock(spec=Order, wraps=Order)
+    >>> order_mock.get_value.side_effect = ["first"]
+    >>> order_mock.get_value.return_value = "second"
+    >>> order_mock.get_value()
+    'first'
+
+As ``None`` is the default value of :attr:`~Mock.side_effect`, if you reassign
+its value back to ``None``, the order of precedence will be checked between
+:attr:`~Mock.return_value` and the wrapped object, ignoring
+:attr:`~Mock.side_effect`.
+
+    >>> order_mock.get_value.side_effect = None
+    >>> order_mock.get_value()
+    'second'
+
+If the value being returned by :attr:`~Mock.side_effect` is :data:`DEFAULT`,
+it is ignored and the order of precedence moves to the successor to obtain the
+value to return.
+
+    >>> from unittest.mock import DEFAULT
+    >>> order_mock.get_value.side_effect = [DEFAULT]
+    >>> order_mock.get_value()
+    'second'
+
+When :class:`Mock` wraps an object, the default value of
+:attr:`~Mock.return_value` will be :data:`DEFAULT`.
+
+    >>> order_mock = Mock(spec=Order, wraps=Order)
+    >>> order_mock.return_value
+    sentinel.DEFAULT
+    >>> order_mock.get_value.return_value
+    sentinel.DEFAULT
+
+The order of precedence will ignore this value and it will move to the last
+successor which is the wrapped object.
+
+As the real call is being made to the wrapped object, creating an instance of
+this mock will return the real instance of the class. The positional arguments,
+if any, required by the wrapped object must be passed.
+
+    >>> order_mock_instance = order_mock()
+    >>> isinstance(order_mock_instance, Order)
+    True
+    >>> order_mock_instance.get_value()
+    'third'
+
+    >>> order_mock.get_value.return_value = DEFAULT
+    >>> order_mock.get_value()
+    'third'
+
+    >>> order_mock.get_value.return_value = "second"
+    >>> order_mock.get_value()
+    'second'
+
+But if you assign ``None`` to it, this will not be ignored as it is an
+explicit assignment. So, the order of precedence will not move to the wrapped
+object.
+
+    >>> order_mock.get_value.return_value = None
+    >>> order_mock.get_value() is None
+    True
+
+Even if you set all three at once when initializing the mock, the order of
+precedence remains the same:
+
+    >>> order_mock = Mock(spec=Order, wraps=Order,
+    ...                   **{"get_value.side_effect": ["first"],
+    ...                      "get_value.return_value": "second"}
+    ...                   )
+    ...
+    >>> order_mock.get_value()
+    'first'
+    >>> order_mock.get_value.side_effect = None
+    >>> order_mock.get_value()
+    'second'
+    >>> order_mock.get_value.return_value = DEFAULT
+    >>> order_mock.get_value()
+    'third'
+
+If :attr:`~Mock.side_effect` is exhausted, the order of precedence will not
+cause a value to be obtained from the successors. Instead, ``StopIteration``
+exception is raised.
+
+    >>> order_mock = Mock(spec=Order, wraps=Order)
+    >>> order_mock.get_value.side_effect = ["first side effect value",
+    ...                                     "another side effect value"]
+    >>> order_mock.get_value.return_value = "second"
+
+    >>> order_mock.get_value()
+    'first side effect value'
+    >>> order_mock.get_value()
+    'another side effect value'
+
+    >>> order_mock.get_value()
+    Traceback (most recent call last):
+     ...
+    StopIteration
diff --git a/Doc/library/urllib.request.rst b/Doc/library/urllib.request.rst
index 3751e81ecf..c6fc325cfd 100644
--- a/Doc/library/urllib.request.rst
+++ b/Doc/library/urllib.request.rst
@@ -105,11 +105,9 @@ The :mod:`urllib.request` module defines the following functions:
    .. versionchanged:: 3.2
       *cafile* and *capath* were added.
 
-   .. versionchanged:: 3.2
       HTTPS virtual hosts are now supported if possible (that is, if
       :const:`ssl.HAS_SNI` is true).
 
-   .. versionadded:: 3.2
       *data* can be an iterable object.
 
    .. versionchanged:: 3.3
diff --git a/Doc/library/venv.rst b/Doc/library/venv.rst
index 8aaf5050b9..f1189cb12b 100644
--- a/Doc/library/venv.rst
+++ b/Doc/library/venv.rst
@@ -54,7 +54,7 @@ See :pep:`405` for more background on Python virtual environments.
 .. seealso::
 
    `Python Packaging User Guide: Creating and using virtual environments
-   <https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment>`__
+   <https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/#create-and-use-virtual-environments>`__
 
 .. include:: ../includes/wasm-notavail.rst
 
@@ -276,15 +276,15 @@ creation according to their needs, the :class:`EnvBuilder` class.
           the virtual environment.
 
 
-        .. versionchanged:: 3.12
-           The attribute ``lib_path`` was added to the context, and the context
-           object was documented.
-
         .. versionchanged:: 3.11
            The *venv*
            :ref:`sysconfig installation scheme <installation_paths>`
            is used to construct the paths of the created directories.
 
+        .. versionchanged:: 3.12
+           The attribute ``lib_path`` was added to the context, and the context
+           object was documented.
+
     .. method:: create_configuration(context)
 
         Creates the ``pyvenv.cfg`` configuration file in the environment.
diff --git a/Doc/library/xml.etree.elementtree.rst b/Doc/library/xml.etree.elementtree.rst
index bb6773c361..09aa81cc47 100644
--- a/Doc/library/xml.etree.elementtree.rst
+++ b/Doc/library/xml.etree.elementtree.rst
@@ -49,7 +49,7 @@ and its sub-elements are done on the :class:`Element` level.
 Parsing XML
 ^^^^^^^^^^^
 
-We'll be using the following XML document as the sample data for this section:
+We'll be using the fictive :file:`country_data.xml` XML document as the sample data for this section:
 
 .. code-block:: xml
 
@@ -166,6 +166,11 @@ data but would still like to have incremental parsing capabilities, take a look
 at :func:`iterparse`.  It can be useful when you're reading a large XML document
 and don't want to hold it wholly in memory.
 
+Where *immediate* feedback through events is wanted, calling method
+:meth:`XMLPullParser.flush` can help reduce delay;
+please make sure to study the related security notes.
+
+
 Finding interesting elements
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 
@@ -1382,6 +1387,24 @@ XMLParser Objects
 
       Feeds data to the parser.  *data* is encoded data.
 
+
+   .. method:: flush()
+
+      Triggers parsing of any previously fed unparsed data, which can be
+      used to ensure more immediate feedback, in particular with Expat >=2.6.0.
+      The implementation of :meth:`flush` temporarily disables reparse deferral
+      with Expat (if currently enabled) and triggers a reparse.
+      Disabling reparse deferral has security consequences; please see
+      :meth:`xml.parsers.expat.xmlparser.SetReparseDeferralEnabled` for details.
+
+      Note that :meth:`flush` has been backported to some prior releases of
+      CPython as a security fix.  Check for availability of :meth:`flush`
+      using :func:`hasattr` if used in code running across a variety of Python
+      versions.
+
+      .. versionadded:: 3.12.3
+
+
    :meth:`XMLParser.feed` calls *target*\'s ``start(tag, attrs_dict)`` method
    for each opening tag, its ``end(tag)`` method for each closing tag, and data
    is processed by method ``data(data)``.  For further supported callback
@@ -1443,6 +1466,22 @@ XMLPullParser Objects
 
       Feed the given bytes data to the parser.
 
+   .. method:: flush()
+
+      Triggers parsing of any previously fed unparsed data, which can be
+      used to ensure more immediate feedback, in particular with Expat >=2.6.0.
+      The implementation of :meth:`flush` temporarily disables reparse deferral
+      with Expat (if currently enabled) and triggers a reparse.
+      Disabling reparse deferral has security consequences; please see
+      :meth:`xml.parsers.expat.xmlparser.SetReparseDeferralEnabled` for details.
+
+      Note that :meth:`flush` has been backported to some prior releases of
+      CPython as a security fix.  Check for availability of :meth:`flush`
+      using :func:`hasattr` if used in code running across a variety of Python
+      versions.
+
+      .. versionadded:: 3.12.3
+
    .. method:: close()
 
       Signal the parser that the data stream is terminated. Unlike
diff --git a/Doc/library/xml.rst b/Doc/library/xml.rst
index 909022ea4b..662cc45919 100644
--- a/Doc/library/xml.rst
+++ b/Doc/library/xml.rst
@@ -68,6 +68,7 @@ quadratic blowup           **Vulnerable** (1)  **Vulnerable** (1)  **Vulnerable*
 external entity expansion  Safe (5)            Safe (2)            Safe (3)            Safe (5)            Safe (4)
 `DTD`_ retrieval           Safe (5)            Safe                Safe                Safe (5)            Safe
 decompression bomb         Safe                Safe                Safe                Safe                **Vulnerable**
+large tokens               **Vulnerable** (6)  **Vulnerable** (6)  **Vulnerable** (6)  **Vulnerable** (6)  **Vulnerable** (6)
 =========================  ==================  ==================  ==================  ==================  ==================
 
 1. Expat 2.4.1 and newer is not vulnerable to the "billion laughs" and
@@ -81,6 +82,11 @@ decompression bomb         Safe                Safe                Safe
 4. :mod:`xmlrpc.client` doesn't expand external entities and omits them.
 5. Since Python 3.7.1, external general entities are no longer processed by
    default.
+6. Expat 2.6.0 and newer is not vulnerable to denial of service
+   through quadratic runtime caused by parsing large tokens.
+   Items still listed as vulnerable due to
+   potential reliance on system-provided libraries. Check
+   :const:`!pyexpat.EXPAT_VERSION`.
 
 
 billion laughs / exponential entity expansion
@@ -114,6 +120,13 @@ decompression bomb
   files. For an attacker it can reduce the amount of transmitted data by three
   magnitudes or more.
 
+large tokens
+  Expat needs to re-parse unfinished tokens; without the protection
+  introduced in Expat 2.6.0, this can lead to quadratic runtime that can
+  be used to cause denial of service in the application parsing XML.
+  The issue is known as
+  `CVE-2023-52425 <https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-52425>`_.
+
 The documentation for `defusedxml`_ on PyPI has further information about
 all known attack vectors with examples and references.
 
diff --git a/Doc/reference/datamodel.rst b/Doc/reference/datamodel.rst
index fcb65b8919..afe13818f1 100644
--- a/Doc/reference/datamodel.rst
+++ b/Doc/reference/datamodel.rst
@@ -34,7 +34,7 @@ represented by objects.)
 
 Every object has an identity, a type and a value.  An object's *identity* never
 changes once it has been created; you may think of it as the object's address in
-memory.  The ':keyword:`is`' operator compares the identity of two objects; the
+memory.  The :keyword:`is` operator compares the identity of two objects; the
 :func:`id` function returns an integer representing its identity.
 
 .. impl-detail::
@@ -81,7 +81,7 @@ are still reachable.
 
 Note that the use of the implementation's tracing or debugging facilities may
 keep objects alive that would normally be collectable. Also note that catching
-an exception with a ':keyword:`try`...\ :keyword:`except`' statement may keep
+an exception with a :keyword:`try`...\ :keyword:`except` statement may keep
 objects alive.
 
 Some objects contain references to "external" resources such as open files or
@@ -89,8 +89,8 @@ windows.  It is understood that these resources are freed when the object is
 garbage-collected, but since garbage collection is not guaranteed to happen,
 such objects also provide an explicit way to release the external resource,
 usually a :meth:`!close` method. Programs are strongly recommended to explicitly
-close such objects.  The ':keyword:`try`...\ :keyword:`finally`' statement
-and the ':keyword:`with`' statement provide convenient ways to do this.
+close such objects.  The :keyword:`try`...\ :keyword:`finally` statement
+and the :keyword:`with` statement provide convenient ways to do this.
 
 .. index:: single: container
 
@@ -159,7 +159,7 @@ NotImplemented
 .. index:: pair: object; NotImplemented
 
 This type has a single value.  There is a single object with this value. This
-object is accessed through the built-in name ``NotImplemented``. Numeric methods
+object is accessed through the built-in name :data:`NotImplemented`. Numeric methods
 and rich comparison methods should return this value if they do not implement the
 operation for the operands provided.  (The interpreter will then try the
 reflected operation, or some other fallback, depending on the operator.)  It
@@ -170,7 +170,7 @@ See
 for more details.
 
 .. versionchanged:: 3.9
-   Evaluating ``NotImplemented`` in a boolean context is deprecated. While
+   Evaluating :data:`NotImplemented` in a boolean context is deprecated. While
    it currently evaluates as true, it will emit a :exc:`DeprecationWarning`.
    It will raise a :exc:`TypeError` in a future version of Python.
 
@@ -299,14 +299,17 @@ Sequences
 These represent finite ordered sets indexed by non-negative numbers. The
 built-in function :func:`len` returns the number of items of a sequence. When
 the length of a sequence is *n*, the index set contains the numbers 0, 1,
-..., *n*-1.  Item *i* of sequence *a* is selected by ``a[i]``.
+..., *n*-1.  Item *i* of sequence *a* is selected by ``a[i]``. Some sequences,
+including built-in sequences, interpret negative subscripts by adding the
+sequence length. For example, ``a[-2]`` equals ``a[n-2]``, the second to last
+item of sequence a with length ``n``.
 
 .. index:: single: slicing
 
 Sequences also support slicing: ``a[i:j]`` selects all items with index *k* such
 that *i* ``<=`` *k* ``<`` *j*.  When used as an expression, a slice is a
-sequence of the same type.  This implies that the index set is renumbered so
-that it starts at 0.
+sequence of the same type. The comment above about negative indexes also applies
+to negative slice positions.
 
 Some sequences also support "extended slicing" with a third "step" parameter:
 ``a[i:j:k]`` selects all items of *a* with index *x* where ``x = i + n*k``, *n*
@@ -1134,6 +1137,8 @@ Special read-only attributes
    * - .. attribute:: codeobject.co_qualname
      - The fully qualified function name
 
+       .. versionadded:: 3.11
+
    * - .. attribute:: codeobject.co_argcount
      - The total number of positional :term:`parameters <parameter>`
        (including positional-only parameters and parameters with default values)
@@ -1290,6 +1295,12 @@ Methods on code objects
       :pep:`626` - Precise line numbers for debugging and other tools.
          The PEP that introduced the :meth:`!co_lines` method.
 
+.. method:: codeobject.replace(**kwargs)
+
+   Return a copy of the code object with new values for the specified fields.
+
+   .. versionadded:: 3.8
+
 
 .. _frame-objects:
 
@@ -1772,7 +1783,7 @@ Basic customization
    ``x.__ne__(y)``, ``x>y`` calls ``x.__gt__(y)``, and ``x>=y`` calls
    ``x.__ge__(y)``.
 
-   A rich comparison method may return the singleton ``NotImplemented`` if it does
+   A rich comparison method may return the singleton :data:`NotImplemented` if it does
    not implement the operation for a given pair of arguments. By convention,
    ``False`` and ``True`` are returned for a successful comparison. However, these
    methods can return any value, so if the comparison operator is used in a Boolean
@@ -1780,10 +1791,10 @@ Basic customization
    :func:`bool` on the value to determine if the result is true or false.
 
    By default, ``object`` implements :meth:`__eq__` by using ``is``, returning
-   ``NotImplemented`` in the case of a false comparison:
+   :data:`NotImplemented` in the case of a false comparison:
    ``True if x is y else NotImplemented``. For :meth:`__ne__`, by default it
    delegates to :meth:`__eq__` and inverts the result unless it is
-   ``NotImplemented``.  There are no other implied relationships among the
+   :data:`!NotImplemented`.  There are no other implied relationships among the
    comparison operators or default implementations; for example, the truth of
    ``(x<y or x==y)`` does not imply ``x<=y``. To automatically generate ordering
    operations from a single root operation, see :func:`functools.total_ordering`.
@@ -1797,12 +1808,15 @@ Basic customization
    rather, :meth:`__lt__` and :meth:`__gt__` are each other's reflection,
    :meth:`__le__` and :meth:`__ge__` are each other's reflection, and
    :meth:`__eq__` and :meth:`__ne__` are their own reflection.
-   If the operands are of different types, and right operand's type is
+   If the operands are of different types, and the right operand's type is
    a direct or indirect subclass of the left operand's type,
    the reflected method of the right operand has priority, otherwise
    the left operand's method has priority.  Virtual subclassing is
    not considered.
 
+   When no appropriate method returns any value other than :data:`NotImplemented`, the
+   ``==`` and ``!=`` operators will fall back to ``is`` and ``is not``, respectively.
+
 .. method:: object.__hash__(self)
 
    .. index::
@@ -1983,8 +1997,8 @@ access (use of, assignment to, or deletion of ``x.name``) for class instances.
 
 .. method:: object.__dir__(self)
 
-   Called when :func:`dir` is called on the object. A sequence must be
-   returned. :func:`dir` converts the returned sequence to a list and sorts it.
+   Called when :func:`dir` is called on the object. An iterable must be
+   returned. :func:`dir` converts the returned iterable to a list and sorts it.
 
 
 Customizing module attribute access
@@ -2004,7 +2018,7 @@ not found on a module object through the normal lookup, i.e.
 the module ``__dict__`` before raising an :exc:`AttributeError`. If found,
 it is called with the attribute name and the result is returned.
 
-The ``__dir__`` function should accept no arguments, and return a sequence of
+The ``__dir__`` function should accept no arguments, and return an iterable of
 strings that represents the names accessible on module. If present, this
 function overrides the standard :func:`dir` search on a module.
 
@@ -2813,7 +2827,7 @@ through the object's keys; for sequences, it should iterate through the values.
    Called to implement :func:`operator.length_hint`. Should return an estimated
    length for the object (which may be greater or less than the actual length).
    The length must be an integer ``>=`` 0. The return value may also be
-   :const:`NotImplemented`, which is treated the same as if the
+   :data:`NotImplemented`, which is treated the same as if the
    ``__length_hint__`` method didn't exist at all. This method is purely an
    optimization and is never required for correctness.
 
@@ -2965,7 +2979,7 @@ left undefined.
    function is to be supported.
 
    If one of those methods does not support the operation with the supplied
-   arguments, it should return ``NotImplemented``.
+   arguments, it should return :data:`NotImplemented`.
 
 
 .. method:: object.__radd__(self, other)
@@ -2995,7 +3009,7 @@ left undefined.
    types. [#]_ For instance, to evaluate the expression ``x - y``, where *y* is
    an instance of a class that has an :meth:`__rsub__` method,
    ``type(y).__rsub__(y, x)`` is called if ``type(x).__sub__(x, y)`` returns
-   *NotImplemented*.
+   :data:`NotImplemented`.
 
    .. index:: pair: built-in function; pow
 
@@ -3029,10 +3043,12 @@ left undefined.
    (``+=``, ``-=``, ``*=``, ``@=``, ``/=``, ``//=``, ``%=``, ``**=``, ``<<=``,
    ``>>=``, ``&=``, ``^=``, ``|=``).  These methods should attempt to do the
    operation in-place (modifying *self*) and return the result (which could be,
-   but does not have to be, *self*).  If a specific method is not defined, the
+   but does not have to be, *self*).  If a specific method is not defined, or if
+   that method returns :data:`NotImplemented`, the
    augmented assignment falls back to the normal methods.  For instance, if *x*
    is an instance of a class with an :meth:`__iadd__` method, ``x += y`` is
-   equivalent to ``x = x.__iadd__(y)`` . Otherwise, ``x.__add__(y)`` and
+   equivalent to ``x = x.__iadd__(y)`` . If :meth:`__iadd__` does not exist, or if ``x.__iadd__(y)``
+   returns :data:`!NotImplemented`, ``x.__add__(y)`` and
    ``y.__radd__(x)`` are considered, as with the evaluation of ``x + y``. In
    certain situations, augmented assignment can result in unexpected errors (see
    :ref:`faq-augmented-assignment-tuple-error`), but this behavior is in fact
@@ -3487,7 +3503,7 @@ An example of an asynchronous context manager class::
    the behavior that ``None`` is not callable.
 
 .. [#] "Does not support" here means that the class has no such method, or
-   the method returns ``NotImplemented``.  Do not set the method to
+   the method returns :data:`NotImplemented`.  Do not set the method to
    ``None`` if you want to force fallback to the right operand's reflected
    methodthat will instead have the opposite effect of explicitly
    *blocking* such fallback.
diff --git a/Doc/reference/expressions.rst b/Doc/reference/expressions.rst
index 8f7c014a6a..38f00ae2aa 100644
--- a/Doc/reference/expressions.rst
+++ b/Doc/reference/expressions.rst
@@ -1532,7 +1532,7 @@ built-in types.
   ``x == x`` are all false, while ``x != x`` is true.  This behavior is
   compliant with IEEE 754.
 
-* ``None`` and ``NotImplemented`` are singletons.  :PEP:`8` advises that
+* ``None`` and :data:`NotImplemented` are singletons.  :PEP:`8` advises that
   comparisons for singletons should always be done with ``is`` or ``is not``,
   never the equality operators.
 
diff --git a/Doc/reference/lexical_analysis.rst b/Doc/reference/lexical_analysis.rst
index 73542cfe50..103d6ef05e 100644
--- a/Doc/reference/lexical_analysis.rst
+++ b/Doc/reference/lexical_analysis.rst
@@ -96,10 +96,9 @@ which is recognized also by GNU Emacs, and ::
 
 which is recognized by Bram Moolenaar's VIM.
 
-If no encoding declaration is found, the default encoding is UTF-8.  In
-addition, if the first bytes of the file are the UTF-8 byte-order mark
-(``b'\xef\xbb\xbf'``), the declared file encoding is UTF-8 (this is supported,
-among others, by Microsoft's :program:`notepad`).
+If no encoding declaration is found, the default encoding is UTF-8.  If the
+implicit or explicit encoding of a file is UTF-8, an initial UTF-8 byte-order
+mark (b'\xef\xbb\xbf') is ignored rather than being a syntax error.
 
 If an encoding is declared, the encoding name must be recognized by Python
 (see :ref:`standard-encodings`). The
@@ -514,7 +513,6 @@ is not supported.
    The ``'rb'`` prefix of raw bytes literals has been added as a synonym
    of ``'br'``.
 
-.. versionadded:: 3.3
    Support for the unicode legacy literal (``u'value'``) was reintroduced
    to simplify the maintenance of dual Python 2.x and 3.x codebases.
    See :pep:`414` for more information.
@@ -734,7 +732,7 @@ for the contents of the string is:
                :   ("," `conditional_expression` | "," "*" `or_expr`)* [","]
                : | `yield_expression`
    conversion: "s" | "r" | "a"
-   format_spec: (`literal_char` | NULL | `replacement_field`)*
+   format_spec: (`literal_char` | `replacement_field`)*
    literal_char: <any code point except "{", "}" or NULL>
 
 The parts of the string outside curly braces are treated literally,
diff --git a/Doc/reference/simple_stmts.rst b/Doc/reference/simple_stmts.rst
index 04132c78ce..a253482156 100644
--- a/Doc/reference/simple_stmts.rst
+++ b/Doc/reference/simple_stmts.rst
@@ -664,8 +664,7 @@ and information about handling exceptions is in section :ref:`try`.
 .. versionchanged:: 3.3
     :const:`None` is now permitted as ``Y`` in ``raise X from Y``.
 
-.. versionadded:: 3.3
-    The :attr:`~BaseException.__suppress_context__` attribute to suppress
+    Added the :attr:`~BaseException.__suppress_context__` attribute to suppress
     automatic display of the exception context.
 
 .. versionchanged:: 3.11
@@ -1007,25 +1006,29 @@ The :keyword:`!nonlocal` statement
 .. productionlist:: python-grammar
    nonlocal_stmt: "nonlocal" `identifier` ("," `identifier`)*
 
-The :keyword:`nonlocal` statement causes the listed identifiers to refer to
-previously bound variables in the nearest enclosing scope excluding globals.
-This is important because the default behavior for binding is to search the
-local namespace first.  The statement allows encapsulated code to rebind
-variables outside of the local scope besides the global (module) scope.
+When the definition of a function or class is nested (enclosed) within
+the definitions of other functions, its nonlocal scopes are the local
+scopes of the enclosing functions. The :keyword:`nonlocal` statement
+causes the listed identifiers to refer to names previously bound in
+nonlocal scopes. It allows encapsulated code to rebind such nonlocal
+identifiers.  If a name is bound in more than one nonlocal scope, the
+nearest binding is used. If a name is not bound in any nonlocal scope,
+or if there is no nonlocal scope, a :exc:`SyntaxError` is raised.
 
-Names listed in a :keyword:`nonlocal` statement, unlike those listed in a
-:keyword:`global` statement, must refer to pre-existing bindings in an
-enclosing scope (the scope in which a new binding should be created cannot
-be determined unambiguously).
-
-Names listed in a :keyword:`nonlocal` statement must not collide with
-pre-existing bindings in the local scope.
+The nonlocal statement applies to the entire scope of a function or
+class body. A :exc:`SyntaxError` is raised if a variable is used or
+assigned to prior to its nonlocal declaration in the scope.
 
 .. seealso::
 
    :pep:`3104` - Access to Names in Outer Scopes
       The specification for the :keyword:`nonlocal` statement.
 
+**Programmer's note:** :keyword:`nonlocal` is a directive to the parser
+and applies only to code parsed along with it.  See the note for the
+:keyword:`global` statement.
+
+
 .. _type:
 
 The :keyword:`!type` statement
diff --git a/Doc/tools/.nitignore b/Doc/tools/.nitignore
index 4a1cea435d..7b7fe8622a 100644
--- a/Doc/tools/.nitignore
+++ b/Doc/tools/.nitignore
@@ -4,16 +4,12 @@
 
 Doc/c-api/arg.rst
 Doc/c-api/descriptor.rst
-Doc/c-api/exceptions.rst
 Doc/c-api/float.rst
-Doc/c-api/gcsupport.rst
 Doc/c-api/init.rst
 Doc/c-api/init_config.rst
 Doc/c-api/intro.rst
 Doc/c-api/module.rst
-Doc/c-api/object.rst
 Doc/c-api/stable.rst
-Doc/c-api/sys.rst
 Doc/c-api/type.rst
 Doc/c-api/typeobj.rst
 Doc/extending/extending.rst
@@ -27,7 +23,6 @@ Doc/library/asyncio-extending.rst
 Doc/library/asyncio-policy.rst
 Doc/library/asyncio-subprocess.rst
 Doc/library/audioop.rst
-Doc/library/bdb.rst
 Doc/library/cgi.rst
 Doc/library/chunk.rst
 Doc/library/collections.rst
@@ -39,10 +34,8 @@ Doc/library/email.compat32-message.rst
 Doc/library/email.errors.rst
 Doc/library/email.parser.rst
 Doc/library/email.policy.rst
-Doc/library/enum.rst
 Doc/library/exceptions.rst
 Doc/library/faulthandler.rst
-Doc/library/fcntl.rst
 Doc/library/functools.rst
 Doc/library/getopt.rst
 Doc/library/http.cookiejar.rst
@@ -62,7 +55,6 @@ Doc/library/pickletools.rst
 Doc/library/platform.rst
 Doc/library/plistlib.rst
 Doc/library/profile.rst
-Doc/library/pydoc.rst
 Doc/library/pyexpat.rst
 Doc/library/readline.rst
 Doc/library/resource.rst
@@ -102,15 +94,11 @@ Doc/reference/compound_stmts.rst
 Doc/reference/datamodel.rst
 Doc/tutorial/datastructures.rst
 Doc/using/windows.rst
-Doc/whatsnew/2.0.rst
-Doc/whatsnew/2.1.rst
 Doc/whatsnew/2.4.rst
 Doc/whatsnew/2.5.rst
 Doc/whatsnew/2.6.rst
 Doc/whatsnew/2.7.rst
 Doc/whatsnew/3.0.rst
-Doc/whatsnew/3.1.rst
-Doc/whatsnew/3.2.rst
 Doc/whatsnew/3.3.rst
 Doc/whatsnew/3.4.rst
 Doc/whatsnew/3.5.rst
diff --git a/Doc/tools/static/changelog_search.js b/Doc/tools/static/changelog_search.js
index c881a9bd4c..0a77c0d71a 100644
--- a/Doc/tools/static/changelog_search.js
+++ b/Doc/tools/static/changelog_search.js
@@ -1,53 +1,59 @@
-$(document).ready(function() {
-    // add the search form and bind the events
-    $('h1').after([
-      '<p>Filter entries by content:',
-      '<input type="text" value="" id="searchbox" style="width: 50%">',
-      '<input type="submit" id="searchbox-submit" value="Filter"></p>'
-    ].join('\n'));
+document.addEventListener("DOMContentLoaded", function () {
+  // add the search form and bind the events
+  document
+    .querySelector("h1")
+    .insertAdjacentHTML(
+      "afterend",
+      [
+        "<p>Filter entries by content:",
+        '<input type="text" value="" id="searchbox" style="width: 50%">',
+        '<input type="submit" id="searchbox-submit" value="Filter"></p>',
+      ].join("\n"),
+    );
 
-    function dofilter() {
-        try {
-            var query = new RegExp($('#searchbox').val(), 'i');
+  function doFilter() {
+    let query;
+    try {
+      query = new RegExp(document.querySelector("#searchbox").value, "i");
+    } catch (e) {
+      return; // not a valid regex (yet)
+    }
+    // find headers for the versions (What's new in Python X.Y.Z?)
+    const h2s = document.querySelectorAll("#changelog h2");
+    for (const h2 of h2s) {
+      let sections_found = 0;
+      // find headers for the sections (Core, Library, etc.)
+      const h3s = h2.parentNode.querySelectorAll("h3");
+      for (const h3 of h3s) {
+        let entries_found = 0;
+        // find all the entries
+        const lis = h3.parentNode.querySelectorAll("li");
+        for (let li of lis) {
+          // check if the query matches the entry
+          if (query.test(li.textContent)) {
+            li.style.display = "block";
+            entries_found++;
+          } else {
+            li.style.display = "none";
+          }
         }
-        catch (e) {
-            return; // not a valid regex (yet)
+        // if there are entries, show the section, otherwise hide it
+        if (entries_found > 0) {
+          h3.parentNode.style.display = "block";
+          sections_found++;
+        } else {
+          h3.parentNode.style.display = "none";
         }
-        // find headers for the versions (What's new in Python X.Y.Z?)
-        $('#changelog h2').each(function(index1, h2) {
-            var h2_parent = $(h2).parent();
-            var sections_found = 0;
-            // find headers for the sections (Core, Library, etc.)
-            h2_parent.find('h3').each(function(index2, h3) {
-                var h3_parent = $(h3).parent();
-                var entries_found = 0;
-                // find all the entries
-                h3_parent.find('li').each(function(index3, li) {
-                    var li = $(li);
-                    // check if the query matches the entry
-                    if (query.test(li.text())) {
-                        li.show();
-                        entries_found++;
-                    }
-                    else {
-                        li.hide();
-                    }
-                });
-                // if there are entries, show the section, otherwise hide it
-                if (entries_found > 0) {
-                    h3_parent.show();
-                    sections_found++;
-                }
-                else {
-                    h3_parent.hide();
-                }
-            });
-            if (sections_found > 0)
-                h2_parent.show();
-            else
-                h2_parent.hide();
-        });
+      }
+      if (sections_found > 0) {
+        h2.parentNode.style.display = "block";
+      } else {
+        h2.parentNode.style.display = "none";
+      }
     }
-    $('#searchbox').keyup(dofilter);
-    $('#searchbox-submit').click(dofilter);
+  }
+  document.querySelector("#searchbox").addEventListener("keyup", doFilter);
+  document
+    .querySelector("#searchbox-submit")
+    .addEventListener("click", doFilter);
 });
diff --git a/Doc/tools/templates/indexcontent.html b/Doc/tools/templates/indexcontent.html
index 1e3ab7cfe0..6f854e86ab 100644
--- a/Doc/tools/templates/indexcontent.html
+++ b/Doc/tools/templates/indexcontent.html
@@ -7,62 +7,62 @@ <h1>{{ docstitle|e }}</h1>
   <p>
   {% trans %}Welcome! This is the official documentation for Python {{ release }}.{% endtrans %}
   </p>
-  <p><strong>{% trans %}Parts of the documentation:{% endtrans %}</strong></p>
+  <p><strong>{% trans %}Documentation sections:{% endtrans %}</strong></p>
   <table class="contentstable" align="center"><tr>
     <td width="50%">
       <p class="biglink"><a class="biglink" href="{{ pathto("whatsnew/" + version) }}">{% trans %}What's new in Python {{ version }}?{% endtrans %}</a><br/>
-        <span class="linkdescr"> {% trans whatsnew_index=pathto("whatsnew/index") %}or <a href="{{ whatsnew_index }}">all "What's new" documents</a> since 2.0{% endtrans %}</span></p>
+         <span class="linkdescr"> {% trans whatsnew_index=pathto("whatsnew/index") %}Or <a href="{{ whatsnew_index }}">all "What's new" documents since Python 2.0</a>{% endtrans %}</span></p>
       <p class="biglink"><a class="biglink" href="{{ pathto("tutorial/index") }}">{% trans %}Tutorial{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}start here{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("library/index") }}">{% trans %}Library Reference{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}keep this under your pillow{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("reference/index") }}">{% trans %}Language Reference{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}describes syntax and language elements{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("using/index") }}">{% trans %}Python Setup and Usage{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}how to use Python on different platforms{% endtrans %}</span></p>
+         <span class="linkdescr">{% trans %}Start here: a tour of Python's syntax and features{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("library/index") }}">{% trans %}Library reference{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}Standard library and builtins{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("reference/index") }}">{% trans %}Language reference{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}Syntax and language elements{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("using/index") }}">{% trans %}Python setup and usage{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}How to install, configure, and use Python{% endtrans %}</span></p>
       <p class="biglink"><a class="biglink" href="{{ pathto("howto/index") }}">{% trans %}Python HOWTOs{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}in-depth documents on specific topics{% endtrans %}</span></p>
+         <span class="linkdescr">{% trans %}In-depth topic manuals{% endtrans %}</span></p>
     </td><td width="50%">
-      <p class="biglink"><a class="biglink" href="{{ pathto("installing/index") }}">{% trans %}Installing Python Modules{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}installing from the Python Package Index &amp; other sources{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("distributing/index") }}">{% trans %}Distributing Python Modules{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}publishing modules for installation by others{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("extending/index") }}">{% trans %}Extending and Embedding{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}tutorial for C/C++ programmers{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("c-api/index") }}">{% trans %}Python/C API{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}reference for C/C++ programmers{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("installing/index") }}">{% trans %}Installing Python modules{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}Third-party modules and PyPI.org{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("distributing/index") }}">{% trans %}Distributing Python modules{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}Publishing modules for use by other people{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("extending/index") }}">{% trans %}Extending and embedding{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}For C/C++ programmers{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("c-api/index") }}">{% trans %}Python's C API{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}C API reference{% endtrans %}</span></p>
       <p class="biglink"><a class="biglink" href="{{ pathto("faq/index") }}">{% trans %}FAQs{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}frequently asked questions (with answers!){% endtrans %}</span></p>
+         <span class="linkdescr">{% trans %}Frequently asked questions (with answers!){% endtrans %}</span></p>
     </td></tr>
   </table>
 
-  <p><strong>{% trans %}Indices and tables:{% endtrans %}</strong></p>
+  <p><strong>{% trans %}Indices, glossary, and search:{% endtrans %}</strong></p>
   <table class="contentstable" align="center"><tr>
     <td width="50%">
-      <p class="biglink"><a class="biglink" href="{{ pathto("py-modindex") }}">{% trans %}Global Module Index{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}quick access to all modules{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("genindex") }}">{% trans %}General Index{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}all functions, classes, terms{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("py-modindex") }}">{% trans %}Global module index{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}All modules and libraries{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("genindex") }}">{% trans %}General index{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}All functions, classes, and terms{% endtrans %}</span></p>
       <p class="biglink"><a class="biglink" href="{{ pathto("glossary") }}">{% trans %}Glossary{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}the most important terms explained{% endtrans %}</span></p>
+         <span class="linkdescr">{% trans %}Terms explained{% endtrans %}</span></p>
     </td><td width="50%">
       <p class="biglink"><a class="biglink" href="{{ pathto("search") }}">{% trans %}Search page{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}search this documentation{% endtrans %}</span></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("contents") }}">{% trans %}Complete Table of Contents{% endtrans %}</a><br/>
-         <span class="linkdescr">{% trans %}lists all sections and subsections{% endtrans %}</span></p>
+         <span class="linkdescr">{% trans %}Search this documentation{% endtrans %}</span></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("contents") }}">{% trans %}Complete table of contents{% endtrans %}</a><br/>
+         <span class="linkdescr">{% trans %}Lists all sections and subsections{% endtrans %}</span></p>
     </td></tr>
   </table>
 
-  <p><strong>{% trans %}Meta information:{% endtrans %}</strong></p>
+  <p><strong>{% trans %}Project information:{% endtrans %}</strong></p>
   <table class="contentstable" align="center"><tr>
     <td width="50%">
-      <p class="biglink"><a class="biglink" href="{{ pathto("bugs") }}">{% trans %}Reporting bugs{% endtrans %}</a></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("bugs") }}">{% trans %}Reporting issues{% endtrans %}</a></p>
       <p class="biglink"><a class="biglink" href="https://devguide.python.org/docquality/#helping-with-documentation">{% trans %}Contributing to Docs{% endtrans %}</a></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("about") }}">{% trans %}About the documentation{% endtrans %}</a></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("download") }}">{% trans %}Download the documentation{% endtrans %}</a></p>
     </td><td width="50%">
-      <p class="biglink"><a class="biglink" href="{{ pathto("license") }}">{% trans %}History and License of Python{% endtrans %}</a></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("license") }}">{% trans %}History and license of Python{% endtrans %}</a></p>
       <p class="biglink"><a class="biglink" href="{{ pathto("copyright") }}">{% trans %}Copyright{% endtrans %}</a></p>
-      <p class="biglink"><a class="biglink" href="{{ pathto("download") }}">{% trans %}Download the documentation{% endtrans %}</a></p>
+      <p class="biglink"><a class="biglink" href="{{ pathto("about") }}">{% trans %}About the documentation{% endtrans %}</a></p>
     </td></tr>
   </table>
 {% endblock %}
diff --git a/Doc/tutorial/errors.rst b/Doc/tutorial/errors.rst
index 4058ebe8ef..0b9acd00fd 100644
--- a/Doc/tutorial/errors.rst
+++ b/Doc/tutorial/errors.rst
@@ -20,12 +20,12 @@ complaint you get while you are still learning Python::
    >>> while True print('Hello world')
      File "<stdin>", line 1
        while True print('Hello world')
-                      ^
+                  ^^^^^
    SyntaxError: invalid syntax
 
-The parser repeats the offending line and displays a little 'arrow' pointing at
-the earliest point in the line where the error was detected.  The error is
-caused by (or at least detected at) the token *preceding* the arrow: in the
+The parser repeats the offending line and displays little 'arrow's pointing
+at the token in the line where the error was detected.  The error may be
+caused by the absence of a token *before* the indicated token.  In the
 example, the error is detected at the function :func:`print`, since a colon
 (``':'``) is missing before it.  File name and line number are printed so you
 know where to look in case the input came from a script.
diff --git a/Doc/tutorial/introduction.rst b/Doc/tutorial/introduction.rst
index 4536ab9486..0f16dae8b1 100644
--- a/Doc/tutorial/introduction.rst
+++ b/Doc/tutorial/introduction.rst
@@ -405,13 +405,6 @@ indexed and sliced::
    >>> squares[-3:]  # slicing returns a new list
    [9, 16, 25]
 
-All slice operations return a new list containing the requested elements.  This
-means that the following slice returns a
-:ref:`shallow copy <shallow_vs_deep_copy>` of the list::
-
-   >>> squares[:]
-   [1, 4, 9, 16, 25]
-
 Lists also support operations like concatenation::
 
    >>> squares + [36, 49, 64, 81, 100]
@@ -435,6 +428,30 @@ the :meth:`!list.append` *method* (we will see more about methods later)::
    >>> cubes
    [1, 8, 27, 64, 125, 216, 343]
 
+Simple assignment in Python never copies data. When you assign a list
+to a variable, the variable refers to the *existing list*.
+Any changes you make to the list through one variable will be seen
+through all other variables that refer to it.::
+
+   >>> rgb = ["Red", "Green", "Blue"]
+   >>> rgba = rgb
+   >>> id(rgb) == id(rgba)  # they reference the same object
+   True
+   >>> rgba.append("Alph")
+   >>> rgb
+   ["Red", "Green", "Blue", "Alph"]
+
+All slice operations return a new list containing the requested elements.  This
+means that the following slice returns a
+:ref:`shallow copy <shallow_vs_deep_copy>` of the list::
+
+   >>> correct_rgba = rgba[:]
+   >>> correct_rgba[-1] = "Alpha"
+   >>> correct_rgba
+   ["Red", "Green", "Blue", "Alpha"]
+   >>> rgba
+   ["Red", "Green", "Blue", "Alph"]
+
 Assignment to slices is also possible, and this can even change the size of the
 list or clear it entirely::
 
diff --git a/Doc/using/cmdline.rst b/Doc/using/cmdline.rst
index 9da28dafdd..3058d9bc2e 100644
--- a/Doc/using/cmdline.rst
+++ b/Doc/using/cmdline.rst
@@ -242,12 +242,13 @@ Miscellaneous options
 
 .. option:: -b
 
-   Issue a warning when comparing :class:`bytes` or :class:`bytearray` with
-   :class:`str` or :class:`bytes` with :class:`int`.  Issue an error when the
-   option is given twice (:option:`!-bb`).
+   Issue a warning when converting :class:`bytes` or :class:`bytearray` to
+   :class:`str` without specifying encoding or comparing :class:`!bytes` or
+   :class:`!bytearray` with :class:`!str` or :class:`!bytes` with :class:`int`.
+   Issue an error when the option is given twice (:option:`!-bb`).
 
    .. versionchanged:: 3.5
-      Affects comparisons of :class:`bytes` with :class:`int`.
+      Affects also comparisons of :class:`bytes` with :class:`int`.
 
 .. option:: -B
 
@@ -375,17 +376,19 @@ Miscellaneous options
    :envvar:`PYTHONHASHSEED` allows you to set a fixed value for the hash
    seed secret.
 
+   .. versionadded:: 3.2.3
+
    .. versionchanged:: 3.7
       The option is no longer ignored.
 
-   .. versionadded:: 3.2.3
-
 
 .. option:: -s
 
    Don't add the :data:`user site-packages directory <site.USER_SITE>` to
    :data:`sys.path`.
 
+   See also :envvar:`PYTHONNOUSERSITE`.
+
    .. seealso::
 
       :pep:`370` -- Per user site-packages directory
@@ -517,7 +520,7 @@ Miscellaneous options
      asyncio'``.  See also :envvar:`PYTHONPROFILEIMPORTTIME`.
    * ``-X dev``: enable :ref:`Python Development Mode <devmode>`, introducing
      additional runtime checks that are too expensive to be enabled by
-     default.
+     default.  See also :envvar:`PYTHONDEVMODE`.
    * ``-X utf8`` enables the :ref:`Python UTF-8 Mode <utf8-mode>`.
      ``-X utf8=0`` explicitly disables :ref:`Python UTF-8 Mode <utf8-mode>`
      (even when it would otherwise activate automatically).
@@ -550,23 +553,22 @@ Miscellaneous options
    It also allows passing arbitrary values and retrieving them through the
    :data:`sys._xoptions` dictionary.
 
-   .. versionchanged:: 3.2
-      The :option:`-X` option was added.
+   .. versionadded:: 3.2
 
-   .. versionadded:: 3.3
-      The ``-X faulthandler`` option.
+   .. versionchanged:: 3.3
+      Added the ``-X faulthandler`` option.
 
-   .. versionadded:: 3.4
-      The ``-X showrefcount`` and ``-X tracemalloc`` options.
+   .. versionchanged:: 3.4
+      Added the ``-X showrefcount`` and ``-X tracemalloc`` options.
 
-   .. versionadded:: 3.6
-      The ``-X showalloccount`` option.
+   .. versionchanged:: 3.6
+      Added the ``-X showalloccount`` option.
 
-   .. versionadded:: 3.7
-      The ``-X importtime``, ``-X dev`` and ``-X utf8`` options.
+   .. versionchanged:: 3.7
+      Added the ``-X importtime``, ``-X dev`` and ``-X utf8`` options.
 
-   .. versionadded:: 3.8
-      The ``-X pycache_prefix`` option. The ``-X dev`` option now logs
+   .. versionchanged:: 3.8
+      Added the ``-X pycache_prefix`` option. The ``-X dev`` option now logs
       ``close()`` exceptions in :class:`io.IOBase` destructor.
 
    .. versionchanged:: 3.9
@@ -575,21 +577,16 @@ Miscellaneous options
 
       The ``-X showalloccount`` option has been removed.
 
-   .. versionadded:: 3.10
-      The ``-X warn_default_encoding`` option.
+   .. versionchanged:: 3.10
+      Added the ``-X warn_default_encoding`` option.
       Removed the ``-X oldparser`` option.
 
-   .. versionadded:: 3.11
-      The ``-X no_debug_ranges`` option.
+   .. versionchanged:: 3.11
+      Added the ``-X no_debug_ranges``, ``-X frozen_modules`` and
+      ``-X int_max_str_digits`` options.
 
-   .. versionadded:: 3.11
-      The ``-X frozen_modules`` option.
-
-   .. versionadded:: 3.11
-      The ``-X int_max_str_digits`` option.
-
-   .. versionadded:: 3.12
-      The ``-X perf`` option.
+   .. versionchanged:: 3.12
+      Added the ``-X perf`` option.
 
 
 Options you shouldn't use
@@ -909,11 +906,11 @@ conflict.
    * ``malloc_debug``: same as ``malloc`` but also install debug hooks.
    * ``pymalloc_debug``: same as ``pymalloc`` but also install debug hooks.
 
+   .. versionadded:: 3.6
+
    .. versionchanged:: 3.7
       Added the ``"default"`` allocator.
 
-   .. versionadded:: 3.6
-
 
 .. envvar:: PYTHONMALLOCSTATS
 
diff --git a/Doc/using/configure.rst b/Doc/using/configure.rst
index 7f250f1b2c..45263a3ee1 100644
--- a/Doc/using/configure.rst
+++ b/Doc/using/configure.rst
@@ -2,6 +2,8 @@
 Configure Python
 ****************
 
+.. highlight:: sh
+
 Build Requirements
 ==================
 
@@ -22,22 +24,22 @@ Features required to build CPython:
 
 * On Windows, Microsoft Visual Studio 2017 or later is required.
 
-.. versionchanged:: 3.11
-   C11 compiler, IEEE 754 and NaN support are now required.
-   On Windows, Visual Studio 2017 or later is required.
+.. versionchanged:: 3.5
+   On Windows, Visual Studio 2015 or later is required.
 
-.. versionchanged:: 3.10
-   OpenSSL 1.1.1 is now required.
+.. versionchanged:: 3.6
+   Selected C99 features are now required, like ``<stdint.h>`` and ``static
+   inline`` functions.
 
 .. versionchanged:: 3.7
    Thread support and OpenSSL 1.0.2 are now required.
 
-.. versionchanged:: 3.6
-   Selected C99 features are now required, like ``<stdint.h>`` and ``static
-   inline`` functions.
+.. versionchanged:: 3.10
+   OpenSSL 1.1.1 is now required.
 
-.. versionchanged:: 3.5
-   On Windows, Visual Studio 2015 or later is required.
+.. versionchanged:: 3.11
+   C11 compiler, IEEE 754 and NaN support are now required.
+   On Windows, Visual Studio 2017 or later is required.
 
 See also :pep:`7` "Style Guide for C Code" and :pep:`11` "CPython platform
 support".
@@ -689,7 +691,9 @@ the version of the cross compiled host Python.
 
    An environment variable that points to a file with configure overrides.
 
-   Example *config.site* file::
+   Example *config.site* file:
+
+   .. code-block:: ini
 
       # config.site-aarch64
       ac_cv_buggy_getaddrinfo=no
@@ -752,7 +756,9 @@ C extensions
 
 Some C extensions are built as built-in modules, like the ``sys`` module.
 They are built with the ``Py_BUILD_CORE_BUILTIN`` macro defined.
-Built-in modules have no ``__file__`` attribute::
+Built-in modules have no ``__file__`` attribute:
+
+.. code-block:: pycon
 
     >>> import sys
     >>> sys
@@ -764,7 +770,9 @@ Built-in modules have no ``__file__`` attribute::
 
 Other C extensions are built as dynamic libraries, like the ``_asyncio`` module.
 They are built with the ``Py_BUILD_CORE_MODULE`` macro defined.
-Example on Linux x86-64::
+Example on Linux x86-64:
+
+.. code-block:: pycon
 
     >>> import _asyncio
     >>> _asyncio
diff --git a/Doc/using/mac.rst b/Doc/using/mac.rst
index eb1413af2c..8f3372b8e0 100644
--- a/Doc/using/mac.rst
+++ b/Doc/using/mac.rst
@@ -10,41 +10,46 @@ Using Python on a Mac
 
 Python on a Mac running macOS is in principle very similar to Python on
 any other Unix platform, but there are a number of additional features such as
-the IDE and the Package Manager that are worth pointing out.
+the integrated development environment (IDE) and the Package Manager that are
+worth pointing out.
+
 
 .. _getting-osx:
+.. _getting-and-installing-macpython:
 
-Getting and Installing MacPython
-================================
+Getting and Installing Python
+=============================
 
 macOS used to come with Python 2.7 pre-installed between versions
 10.8 and `12.3 <https://developer.apple.com/documentation/macos-release-notes/macos-12_3-release-notes#Python>`_.
-You are invited to install the most recent version of Python 3 from the Python
-website (https://www.python.org).  A current "universal binary" build of Python,
-which runs natively on the Mac's new Intel and legacy PPC CPU's, is available
-there.
+You are invited to install the most recent version of Python 3 from the `Python
+website <https://www.python.org/downloads/macos/>`__.
+A current "universal2 binary" build of Python, which runs natively on the Mac's
+new Apple Silicon and legacy Intel processors, is available there.
 
 What you get after installing is a number of things:
 
-* A :file:`Python 3.12` folder in your :file:`Applications` folder. In here
+* A |python_version_literal| folder in your :file:`Applications` folder. In here
   you find IDLE, the development environment that is a standard part of official
-  Python distributions; and PythonLauncher, which handles double-clicking Python
+  Python distributions; and :program:`Python Launcher`, which handles double-clicking Python
   scripts from the Finder.
 
 * A framework :file:`/Library/Frameworks/Python.framework`, which includes the
   Python executable and libraries. The installer adds this location to your shell
-  path. To uninstall MacPython, you can simply remove these three things. A
-  symlink to the Python executable is placed in /usr/local/bin/.
-
-The Apple-provided build of Python is installed in
-:file:`/System/Library/Frameworks/Python.framework` and :file:`/usr/bin/python`,
-respectively. You should never modify or delete these, as they are
-Apple-controlled and are used by Apple- or third-party software.  Remember that
-if you choose to install a newer Python version from python.org, you will have
-two different but functional Python installations on your computer, so it will
-be important that your paths and usages are consistent with what you want to do.
-
-IDLE includes a help menu that allows you to access Python documentation. If you
+  path. To uninstall Python, you can remove these three things. A
+  symlink to the Python executable is placed in :file:`/usr/local/bin/`.
+
+.. note::
+
+   On macOS 10.8-12.3, the Apple-provided build of Python is installed in
+   :file:`/System/Library/Frameworks/Python.framework` and :file:`/usr/bin/python`,
+   respectively. You should never modify or delete these, as they are
+   Apple-controlled and are used by Apple- or third-party software.  Remember that
+   if you choose to install a newer Python version from python.org, you will have
+   two different but functional Python installations on your computer, so it will
+   be important that your paths and usages are consistent with what you want to do.
+
+IDLE includes a Help menu that allows you to access Python documentation. If you
 are completely new to Python you should start reading the tutorial introduction
 in that document.
 
@@ -56,29 +61,29 @@ How to run a Python script
 --------------------------
 
 Your best way to get started with Python on macOS is through the IDLE
-integrated development environment, see section :ref:`ide` and use the Help menu
+integrated development environment; see section :ref:`ide` and use the Help menu
 when the IDE is running.
 
 If you want to run Python scripts from the Terminal window command line or from
 the Finder you first need an editor to create your script. macOS comes with a
-number of standard Unix command line editors, :program:`vim` and
-:program:`emacs` among them. If you want a more Mac-like editor,
-:program:`BBEdit` or :program:`TextWrangler` from Bare Bones Software (see
-http://www.barebones.com/products/bbedit/index.html) are good choices, as is
-:program:`TextMate` (see https://macromates.com/). Other editors include
-:program:`Gvim` (https://macvim.org/macvim/) and :program:`Aquamacs`
-(http://aquamacs.org/).
+number of standard Unix command line editors, :program:`vim`
+:program:`nano` among them. If you want a more Mac-like editor,
+:program:`BBEdit` from Bare Bones Software (see
+https://www.barebones.com/products/bbedit/index.html) are good choices, as is
+:program:`TextMate` (see https://macromates.com). Other editors include
+:program:`MacVim` (https://macvim.org) and :program:`Aquamacs`
+(https://aquamacs.org).
 
 To run your script from the Terminal window you must make sure that
 :file:`/usr/local/bin` is in your shell search path.
 
 To run your script from the Finder you have two options:
 
-* Drag it to :program:`PythonLauncher`
+* Drag it to :program:`Python Launcher`.
 
-* Select :program:`PythonLauncher` as the default application to open your
-  script (or any .py script) through the finder Info window and double-click it.
-  :program:`PythonLauncher` has various preferences to control how your script is
+* Select :program:`Python Launcher` as the default application to open your
+  script (or any ``.py`` script) through the finder Info window and double-click it.
+  :program:`Python Launcher` has various preferences to control how your script is
   launched. Option-dragging allows you to change these for one invocation, or use
   its Preferences menu to change things globally.
 
@@ -103,10 +108,11 @@ Python on macOS honors all standard Unix environment variables such as
 :envvar:`PYTHONPATH`, but setting these variables for programs started from the
 Finder is non-standard as the Finder does not read your :file:`.profile` or
 :file:`.cshrc` at startup. You need to create a file
-:file:`~/.MacOSX/environment.plist`. See Apple's Technical Document QA1067 for
-details.
+:file:`~/.MacOSX/environment.plist`. See Apple's
+`Technical Q&A QA1067 <https://developer.apple.com/library/archive/qa/qa1067/_index.html>`__
+for details.
 
-For more information on installation Python packages in MacPython, see section
+For more information on installation Python packages, see section
 :ref:`mac-package-manager`.
 
 
@@ -115,9 +121,9 @@ For more information on installation Python packages in MacPython, see section
 The IDE
 =======
 
-MacPython ships with the standard IDLE development environment. A good
+Python ships with the standard IDLE development environment. A good
 introduction to using IDLE can be found at
-http://www.hashcollision.org/hkn/python/idle_intro/index.html.
+https://www.hashcollision.org/hkn/python/idle_intro/index.html.
 
 
 .. _mac-package-manager:
@@ -130,8 +136,10 @@ This section has moved to the `Python Packaging User Guide`_.
 .. _Python Packaging User Guide: https://packaging.python.org/en/latest/tutorials/installing-packages/
 
 
-GUI Programming on the Mac
-==========================
+.. _gui-programming-on-the-mac:
+
+GUI Programming
+===============
 
 There are several options for building GUI applications on the Mac with Python.
 
@@ -144,31 +152,50 @@ Tk toolkit (https://www.tcl.tk). An Aqua-native version of Tk is bundled with
 macOS by Apple, and the latest version can be downloaded and installed from
 https://www.activestate.com; it can also be built from source.
 
-*wxPython* is another popular cross-platform GUI toolkit that runs natively on
-macOS. Packages and documentation are available from https://www.wxpython.org.
+A number of alternative macOS GUI toolkits are available:
+
+* `PySide <https://www.qt.io/qt-for-python>`__: Official Python bindings to the
+  `Qt GUI toolkit <https://qt.io>`__.
 
-*PyQt* is another popular cross-platform GUI toolkit that runs natively on
-macOS. More information can be found at
-https://riverbankcomputing.com/software/pyqt/intro.
+* `PyQt <https://riverbankcomputing.com/software/pyqt/intro>`__: Alternative
+  Python bindings to Qt.
 
+* `Kivy <https://kivy.org>`__: A cross-platform GUI toolkit that supports
+  desktop and mobile platforms.
 
-Distributing Python Applications on the Mac
-===========================================
+* `Toga <https://toga.readthedocs.io>`__: Part of the `BeeWare Project
+  <https://beeware.org>`__; supports desktop, mobile, web and console apps.
 
-The standard tool for deploying standalone Python applications on the Mac is
-:program:`py2app`. More information on installing and using py2app can be found
-at https://pypi.org/project/py2app/.
+* `wxPython <https://www.wxpython.org>`__: A cross-platform toolkit that
+  supports desktop operating systems.
 
+.. _distributing-python-applications-on-the-mac:
+
+Distributing Python Applications
+================================
+
+A range of tools exist for converting your Python code into a standalone
+distributable application:
+
+* `py2app <https://pypi.org/project/py2app/>`__: Supports creating macOS ``.app``
+  bundles from a Python project.
+
+* `Briefcase <https://briefcase.readthedocs.io>`__: Part of the `BeeWare Project
+  <https://beeware.org>`__; a cross-platform packaging tool that supports
+  creation of ``.app`` bundles on macOS, as well as managing signing and
+  notarization.
+
+* `PyInstaller <https://pyinstaller.org/>`__: A cross-platform packaging tool that creates
+  a single file or folder as a distributable artifact.
 
 Other Resources
 ===============
 
-The MacPython mailing list is an excellent support resource for Python users and
-developers on the Mac:
+The Pythonmac-SIG mailing list is an excellent support resource for Python users
+and developers on the Mac:
 
 https://www.python.org/community/sigs/current/pythonmac-sig/
 
 Another useful resource is the MacPython wiki:
 
 https://wiki.python.org/moin/MacPython
-
diff --git a/Doc/using/venv-create.inc b/Doc/using/venv-create.inc
index 2fc9012648..14bd1c8765 100644
--- a/Doc/using/venv-create.inc
+++ b/Doc/using/venv-create.inc
@@ -14,14 +14,14 @@ used at environment creation time). It also creates an (initially empty)
 ``Lib\site-packages``). If an existing directory is specified, it will be
 re-used.
 
+.. versionchanged:: 3.5
+   The use of ``venv`` is now recommended for creating virtual environments.
+
 .. deprecated:: 3.6
    ``pyvenv`` was the recommended tool for creating virtual environments for
    Python 3.3 and 3.4, and is
    :ref:`deprecated in Python 3.6 <whatsnew36-venv>`.
 
-.. versionchanged:: 3.5
-   The use of ``venv`` is now recommended for creating virtual environments.
-
 .. highlight:: none
 
 On Windows, invoke the ``venv`` command as follows::
diff --git a/Doc/using/windows.rst b/Doc/using/windows.rst
index e5843eeeb5..cc744b5797 100644
--- a/Doc/using/windows.rst
+++ b/Doc/using/windows.rst
@@ -14,8 +14,8 @@ know about when using Python on Microsoft Windows.
 
 Unlike most Unix systems and services, Windows does not include a system
 supported installation of Python. To make Python available, the CPython team
-has compiled Windows installers (MSI packages) with every `release
-<https://www.python.org/download/releases/>`_ for many years. These installers
+has compiled Windows installers with every `release
+<https://www.python.org/downloads/>`_ for many years. These installers
 are primarily intended to add a per-user installation of Python, with the
 core interpreter and library being used by a single user. The installer is also
 able to install for all users of a single machine, and a separate ZIP file is
diff --git a/Doc/whatsnew/2.0.rst b/Doc/whatsnew/2.0.rst
index 65dfc3aa09..ec283697f3 100644
--- a/Doc/whatsnew/2.0.rst
+++ b/Doc/whatsnew/2.0.rst
@@ -217,13 +217,13 @@ often use the ``codecs.lookup(encoding)`` function, which returns a
   was consumed.
 
 * *stream_reader* is a class that supports decoding input from a stream.
-  *stream_reader(file_obj)* returns an object that supports the :meth:`read`,
-  :meth:`readline`, and :meth:`readlines` methods.  These methods will all
+  *stream_reader(file_obj)* returns an object that supports the :meth:`!read`,
+  :meth:`!readline`, and :meth:`!readlines` methods.  These methods will all
   translate from the given encoding and return Unicode strings.
 
 * *stream_writer*, similarly, is a class that supports encoding output to a
   stream.  *stream_writer(file_obj)* returns an object that supports the
-  :meth:`write` and :meth:`writelines` methods.  These methods expect Unicode
+  :meth:`!write` and :meth:`!writelines` methods.  These methods expect Unicode
   strings, translating them to the given encoding on output.
 
 For example, the following code writes a Unicode string into a file,  encoding
@@ -356,8 +356,8 @@ variable  ``a`` by 2, equivalent to the slightly lengthier ``a = a + 2``.
 The full list of supported assignment operators is ``+=``, ``-=``, ``*=``,
 ``/=``, ``%=``, ``**=``, ``&=``, ``|=``, ``^=``, ``>>=``, and ``<<=``.  Python
 classes can override the augmented assignment operators by defining methods
-named :meth:`__iadd__`, :meth:`__isub__`, etc.  For example, the following
-:class:`Number` class stores a number and supports using += to create a new
+named :meth:`!__iadd__`, :meth:`!__isub__`, etc.  For example, the following
+:class:`!Number` class stores a number and supports using += to create a new
 instance with an incremented value.
 
 .. The empty groups below prevent conversion to guillemets.
@@ -374,7 +374,7 @@ instance with an incremented value.
    n += 3
    print n.value
 
-The :meth:`__iadd__` special method is called with the value of the increment,
+The :meth:`!__iadd__` special method is called with the value of the increment,
 and should return a new instance with an appropriately modified value; this
 return value is bound as the new value of the variable on the left-hand side.
 
@@ -390,10 +390,10 @@ String Methods
 ==============
 
 Until now string-manipulation functionality was in the :mod:`string` module,
-which was usually a front-end for the :mod:`strop` module written in C.  The
-addition of Unicode posed a difficulty for the :mod:`strop` module, because the
+which was usually a front-end for the :mod:`!strop` module written in C.  The
+addition of Unicode posed a difficulty for the :mod:`!strop` module, because the
 functions would all need to be rewritten in order to accept either 8-bit or
-Unicode strings.  For functions such as :func:`string.replace`, which takes 3
+Unicode strings.  For functions such as :func:`!string.replace`, which takes 3
 string arguments, that means eight possible permutations, and correspondingly
 complicated code.
 
@@ -416,13 +416,13 @@ The old :mod:`string` module is still around for backwards compatibility, but it
 mostly acts as a front-end to the new string methods.
 
 Two methods which have no parallel in pre-2.0 versions, although they did exist
-in JPython for quite some time, are :meth:`startswith` and :meth:`endswith`.
+in JPython for quite some time, are :meth:`!startswith` and :meth:`!endswith`.
 ``s.startswith(t)`` is equivalent to ``s[:len(t)] == t``, while
 ``s.endswith(t)`` is equivalent to ``s[-len(t):] == t``.
 
-One other method which deserves special mention is :meth:`join`.  The
-:meth:`join` method of a string receives one parameter, a sequence of strings,
-and is equivalent to the :func:`string.join` function from the old :mod:`string`
+One other method which deserves special mention is :meth:`!join`.  The
+:meth:`!join` method of a string receives one parameter, a sequence of strings,
+and is equivalent to the :func:`!string.join` function from the old :mod:`string`
 module, with the arguments reversed. In other words, ``s.join(seq)`` is
 equivalent to the old ``string.join(seq, s)``.
 
@@ -503,9 +503,9 @@ Minor Language Changes
 
 A new syntax makes it more convenient to call a given function with a tuple of
 arguments and/or a dictionary of keyword arguments. In Python 1.5 and earlier,
-you'd use the :func:`apply` built-in function: ``apply(f, args, kw)`` calls the
-function :func:`f` with the argument tuple *args* and the keyword arguments in
-the dictionary *kw*.  :func:`apply`  is the same in 2.0, but thanks to a patch
+you'd use the :func:`!apply` built-in function: ``apply(f, args, kw)`` calls the
+function :func:`!f` with the argument tuple *args* and the keyword arguments in
+the dictionary *kw*.  :func:`!apply`  is the same in 2.0, but thanks to a patch
 from Greg Ewing, ``f(*args, **kw)`` is a shorter and clearer way to achieve the
 same effect.  This syntax is symmetrical with the syntax for defining
 functions::
@@ -518,7 +518,7 @@ functions::
 The ``print`` statement can now have its output directed to a file-like
 object by following the ``print`` with  ``>> file``, similar to the
 redirection operator in Unix shells. Previously you'd either have to use the
-:meth:`write` method of the file-like object, which lacks the convenience and
+:meth:`!write` method of the file-like object, which lacks the convenience and
 simplicity of ``print``, or you could assign a new value to
 ``sys.stdout`` and then restore the old value.  For sending output to standard
 error, it's much easier to write this::
@@ -540,7 +540,7 @@ Previously there was no way to implement a class that overrode Python's built-in
 true if *obj* is present in the sequence *seq*; Python computes this by simply
 trying every index of the sequence until either *obj* is found or an
 :exc:`IndexError` is encountered.  Moshe Zadka contributed a patch which adds a
-:meth:`__contains__` magic method for providing a custom implementation for
+:meth:`!__contains__` magic method for providing a custom implementation for
 :keyword:`!in`. Additionally, new built-in objects written in C can define what
 :keyword:`!in` means for them via a new slot in the sequence protocol.
 
@@ -562,7 +562,7 @@ the python-dev mailing list for the discussion leading up to this
 implementation, and some useful relevant links.    Note that comparisons can now
 also raise exceptions. In earlier versions of Python, a comparison operation
 such as ``cmp(a,b)`` would always produce an answer, even if a user-defined
-:meth:`__cmp__` method encountered an error, since the resulting exception would
+:meth:`!__cmp__` method encountered an error, since the resulting exception would
 simply be silently swallowed.
 
 .. Starting URL:
@@ -607,7 +607,7 @@ seq1, seq2)`` is that :func:`map` pads the sequences with ``None`` if the
 sequences aren't all of the same length, while :func:`zip` truncates the
 returned list to the length of the shortest argument sequence.
 
-The :func:`int` and :func:`long` functions now accept an optional "base"
+The :func:`int` and :func:`!long` functions now accept an optional "base"
 parameter when the first argument is a string. ``int('123', 10)`` returns 123,
 while ``int('123', 16)`` returns 291.  ``int(123, 16)`` raises a
 :exc:`TypeError` exception with the message "can't convert non-string with
@@ -620,8 +620,8 @@ would be ``(2, 0, 1, 'beta', 1)``. *level* is a string such as ``"alpha"``,
 ``"beta"``, or ``"final"`` for a final release.
 
 Dictionaries have an odd new method, ``setdefault(key, default)``, which
-behaves similarly to the existing :meth:`get` method.  However, if the key is
-missing, :meth:`setdefault` both returns the value of *default* as :meth:`get`
+behaves similarly to the existing :meth:`!get` method.  However, if the key is
+missing, :meth:`!setdefault` both returns the value of *default* as :meth:`!get`
 would do, and also inserts it into the dictionary as the value for *key*.  Thus,
 the following lines of code::
 
@@ -656,7 +656,7 @@ break.
 The change which will probably break the most code is tightening up the
 arguments accepted by some methods.  Some methods would take multiple arguments
 and treat them as a tuple, particularly various list methods such as
-:meth:`append` and :meth:`insert`. In earlier versions of Python, if ``L`` is
+:meth:`!append` and :meth:`!insert`. In earlier versions of Python, if ``L`` is
 a list, ``L.append( 1,2 )`` appends the tuple ``(1,2)`` to the list.  In Python
 2.0 this causes a :exc:`TypeError` exception to be raised, with the message:
 'append requires exactly 1 argument; 2 given'.  The fix is to simply add an
@@ -693,7 +693,7 @@ advantage of this fact will break in 2.0.
 
 Some work has been done to make integers and long integers a bit more
 interchangeable.  In 1.5.2, large-file support was added for Solaris, to allow
-reading files larger than 2 GiB; this made the :meth:`tell` method of file
+reading files larger than 2 GiB; this made the :meth:`!tell` method of file
 objects return a long integer instead of a regular integer.  Some code would
 subtract two file offsets and attempt to use the result to multiply a sequence
 or slice a string, but this raised a :exc:`TypeError`.  In 2.0, long integers
@@ -701,7 +701,7 @@ can be used to multiply or slice a sequence, and it'll behave as you'd
 intuitively expect it to; ``3L * 'abc'`` produces 'abcabcabc', and
 ``(0,1,2,3)[2L:4L]`` produces (2,3). Long integers can also be used in various
 contexts where previously only integers were accepted, such as in the
-:meth:`seek` method of file objects, and in the formats supported by the ``%``
+:meth:`!seek` method of file objects, and in the formats supported by the ``%``
 operator (``%d``, ``%i``, ``%x``, etc.).  For example, ``"%d" % 2L**64`` will
 produce the string ``18446744073709551616``.
 
@@ -715,7 +715,7 @@ digit.
 
 Taking the :func:`repr` of a float now uses a different formatting precision
 than :func:`str`.  :func:`repr` uses ``%.17g`` format string for C's
-:func:`sprintf`, while :func:`str` uses ``%.12g`` as before.  The effect is that
+:func:`!sprintf`, while :func:`str` uses ``%.12g`` as before.  The effect is that
 :func:`repr` may occasionally show more decimal places than  :func:`str`, for
 certain numbers.  For example, the number 8.1 can't be represented exactly in
 binary, so ``repr(8.1)`` is ``'8.0999999999999996'``, while str(8.1) is
@@ -723,7 +723,7 @@ binary, so ``repr(8.1)`` is ``'8.0999999999999996'``, while str(8.1) is
 
 The ``-X`` command-line option, which turned all standard exceptions into
 strings instead of classes, has been removed; the standard exceptions will now
-always be classes.  The :mod:`exceptions` module containing the standard
+always be classes.  The :mod:`!exceptions` module containing the standard
 exceptions was translated from Python to a built-in C module, written by Barry
 Warsaw and Fredrik Lundh.
 
@@ -879,11 +879,11 @@ joins the basic set of Python documentation.
 XML Modules
 ===========
 
-Python 1.5.2 included a simple XML parser in the form of the :mod:`xmllib`
+Python 1.5.2 included a simple XML parser in the form of the :mod:`!xmllib`
 module, contributed by Sjoerd Mullender.  Since 1.5.2's release, two different
 interfaces for processing XML have become common: SAX2 (version 2 of the Simple
 API for XML) provides an event-driven interface with some similarities to
-:mod:`xmllib`, and the DOM (Document Object Model) provides a tree-based
+:mod:`!xmllib`, and the DOM (Document Object Model) provides a tree-based
 interface, transforming an XML document into a tree of nodes that can be
 traversed and modified.  Python 2.0 includes a SAX2 interface and a stripped-down
 DOM interface as part of the :mod:`xml` package. Here we will give a brief
@@ -898,9 +898,9 @@ SAX2 Support
 SAX defines an event-driven interface for parsing XML.  To use SAX, you must
 write a SAX handler class.  Handler classes inherit from various classes
 provided by SAX, and override various methods that will then be called by the
-XML parser.  For example, the :meth:`startElement` and :meth:`endElement`
+XML parser.  For example, the :meth:`~xml.sax.handler.ContentHandler.startElement` and :meth:`~xml.sax.handler.ContentHandler.endElement`
 methods are called for every starting and end tag encountered by the parser, the
-:meth:`characters` method is called for every chunk of character data, and so
+:meth:`~xml.sax.handler.ContentHandler.characters` method is called for every chunk of character data, and so
 forth.
 
 The advantage of the event-driven approach is that the whole document doesn't
@@ -940,8 +940,8 @@ DOM Support
 -----------
 
 The Document Object Model is a tree-based representation for an XML document.  A
-top-level :class:`Document` instance is the root of the tree, and has a single
-child which is the top-level :class:`Element` instance. This :class:`Element`
+top-level :class:`!Document` instance is the root of the tree, and has a single
+child which is the top-level :class:`!Element` instance. This :class:`!Element`
 has children nodes representing character data and any sub-elements, which may
 have further children of their own, and so forth.  Using the DOM you can
 traverse the resulting tree any way you like, access element and attribute
@@ -955,18 +955,18 @@ simply writing ``<tag1>``...\ ``</tag1>`` to a file.
 
 The DOM implementation included with Python lives in the :mod:`xml.dom.minidom`
 module.  It's a lightweight implementation of the Level 1 DOM with support for
-XML namespaces.  The  :func:`parse` and :func:`parseString` convenience
+XML namespaces.  The  :func:`!parse` and :func:`!parseString` convenience
 functions are provided for generating a DOM tree::
 
    from xml.dom import minidom
    doc = minidom.parse('hamlet.xml')
 
-``doc`` is a :class:`Document` instance.  :class:`Document`, like all the other
-DOM classes such as :class:`Element` and :class:`Text`, is a subclass of the
-:class:`Node` base class.  All the nodes in a DOM tree therefore support certain
-common methods, such as :meth:`toxml` which returns a string containing the XML
+``doc`` is a :class:`!Document` instance.  :class:`!Document`, like all the other
+DOM classes such as :class:`!Element` and :class:`Text`, is a subclass of the
+:class:`!Node` base class.  All the nodes in a DOM tree therefore support certain
+common methods, such as :meth:`!toxml` which returns a string containing the XML
 representation of the node and its children.  Each class also has special
-methods of its own; for example, :class:`Element` and :class:`Document`
+methods of its own; for example, :class:`!Element` and :class:`!Document`
 instances have a method to find all child elements with a given tag name.
 Continuing from the previous 2-line example::
 
@@ -995,7 +995,7 @@ its children can be easily modified by deleting, adding, or removing nodes::
    root.insertBefore( root.childNodes[0], root.childNodes[20] )
 
 Again, I will refer you to the Python documentation for a complete listing of
-the different :class:`Node` classes and their various methods.
+the different :class:`!Node` classes and their various methods.
 
 
 Relationship to PyXML
@@ -1020,7 +1020,7 @@ features in PyXML include:
 
 * The xmlproc validating parser, written by Lars Marius Garshol.
 
-* The :mod:`sgmlop` parser accelerator module, written by Fredrik Lundh.
+* The :mod:`!sgmlop` parser accelerator module, written by Fredrik Lundh.
 
 .. ======================================================================
 
@@ -1031,7 +1031,7 @@ Module changes
 Lots of improvements and bugfixes were made to Python's extensive standard
 library; some of the affected modules include :mod:`readline`,
 :mod:`ConfigParser <configparser>`, :mod:`cgi`, :mod:`calendar`, :mod:`posix`, :mod:`readline`,
-:mod:`xmllib`, :mod:`aifc`, :mod:`chunk, wave`, :mod:`random`, :mod:`shelve`,
+:mod:`!xmllib`, :mod:`aifc`, :mod:`chunk` :mod:`wave`, :mod:`random`, :mod:`shelve`,
 and :mod:`nntplib`.  Consult the CVS logs for the exact patch-by-patch details.
 
 Brian Gallew contributed OpenSSL support for the :mod:`socket` module.  OpenSSL
@@ -1044,11 +1044,12 @@ were also changed to support ``https://`` URLs, though no one has implemented
 FTP or SMTP over SSL.
 
 The :mod:`httplib <http>` module has been rewritten by Greg Stein to support HTTP/1.1.
+
 Backward compatibility with the 1.5 version of :mod:`!httplib` is provided,
 though using HTTP/1.1 features such as pipelining will require rewriting code to
 use a different set of interfaces.
 
-The :mod:`Tkinter` module now supports Tcl/Tk version 8.1, 8.2, or 8.3, and
+The :mod:`!Tkinter` module now supports Tcl/Tk version 8.1, 8.2, or 8.3, and
 support for the older 7.x versions has been dropped.  The Tkinter module now
 supports displaying Unicode strings in Tk widgets. Also, Fredrik Lundh
 contributed an optimization which makes operations like ``create_line`` and
@@ -1083,11 +1084,11 @@ module.
   calling :func:`atexit.register` with  the function to be called on exit.
   (Contributed by Skip Montanaro.)
 
-* :mod:`codecs`, :mod:`encodings`, :mod:`unicodedata`:  Added as part of the new
+* :mod:`codecs`, :mod:`!encodings`, :mod:`unicodedata`:  Added as part of the new
   Unicode support.
 
-* :mod:`filecmp`: Supersedes the old :mod:`cmp`, :mod:`cmpcache` and
-  :mod:`dircmp` modules, which have now become deprecated. (Contributed by Gordon
+* :mod:`filecmp`: Supersedes the old :mod:`!cmp`, :mod:`!cmpcache` and
+  :mod:`!dircmp` modules, which have now become deprecated. (Contributed by Gordon
   MacMillan and Moshe Zadka.)
 
 * :mod:`gettext`: This module provides internationalization (I18N) and
@@ -1105,7 +1106,7 @@ module.
   be passed to functions that expect ordinary strings, such as the :mod:`re`
   module. (Contributed by Sam Rushing, with some extensions by A.M. Kuchling.)
 
-* :mod:`pyexpat`: An interface to the Expat XML parser. (Contributed by Paul
+* :mod:`!pyexpat`: An interface to the Expat XML parser. (Contributed by Paul
   Prescod.)
 
 * :mod:`robotparser <urllib.robotparser>`: Parse a :file:`robots.txt` file, which is used for writing
@@ -1117,7 +1118,7 @@ module.
 * :mod:`tabnanny`: A module/script to  check Python source code for ambiguous
   indentation. (Contributed by Tim Peters.)
 
-* :mod:`UserString`: A base class useful for deriving objects that behave like
+* :mod:`!UserString`: A base class useful for deriving objects that behave like
   strings.
 
 * :mod:`webbrowser`: A module that provides a platform independent way to launch
@@ -1184,13 +1185,13 @@ Deleted and Deprecated Modules
 ==============================
 
 A few modules have been dropped because they're obsolete, or because there are
-now better ways to do the same thing.  The :mod:`stdwin` module is gone; it was
+now better ways to do the same thing.  The :mod:`!stdwin` module is gone; it was
 for a platform-independent windowing toolkit that's no longer developed.
 
 A number of modules have been moved to the :file:`lib-old` subdirectory:
-:mod:`cmp`, :mod:`cmpcache`, :mod:`dircmp`, :mod:`dump`,  :mod:`find`,
-:mod:`grep`, :mod:`packmail`,  :mod:`poly`, :mod:`util`, :mod:`whatsound`,
-:mod:`zmod`.  If you have code which relies on a module  that's been moved to
+:mod:`!cmp`, :mod:`!cmpcache`, :mod:`!dircmp`, :mod:`!dump`,  :mod:`!find`,
+:mod:`!grep`, :mod:`!packmail`,  :mod:`!poly`, :mod:`!util`, :mod:`!whatsound`,
+:mod:`!zmod`.  If you have code which relies on a module  that's been moved to
 :file:`lib-old`, you can simply add that directory to ``sys.path``   to get them
 back, but you're encouraged to update any code that uses these modules.
 
diff --git a/Doc/whatsnew/2.1.rst b/Doc/whatsnew/2.1.rst
index 6d2d3cc02b..b4002f06e9 100644
--- a/Doc/whatsnew/2.1.rst
+++ b/Doc/whatsnew/2.1.rst
@@ -48,7 +48,7 @@ nested recursive function definition doesn't work::
            return g(value-1) + 1
        ...
 
-The function :func:`g` will always raise a :exc:`NameError` exception, because
+The function :func:`!g` will always raise a :exc:`NameError` exception, because
 the binding of the name ``g`` isn't in either its local namespace or in the
 module-level namespace.  This isn't much of a problem in practice (how often do
 you recursively define interior functions like this?), but this also made using
@@ -104,7 +104,7 @@ To make the preceding explanation a bit clearer, here's an example::
 
 Line 4 containing the ``exec`` statement is a syntax error, since
 ``exec`` would define a new local variable named ``x`` whose value should
-be accessed by :func:`g`.
+be accessed by :func:`!g`.
 
 This shouldn't be much of a limitation, since ``exec`` is rarely used in
 most Python code (and when it is used, it's often a sign of a poor design
@@ -161,7 +161,7 @@ PEP 207: Rich Comparisons
 
 In earlier versions, Python's support for implementing comparisons on user-defined
 classes and extension types was quite simple. Classes could implement a
-:meth:`__cmp__` method that was given two instances of a class, and could only
+:meth:`!__cmp__` method that was given two instances of a class, and could only
 return 0 if they were equal or +1 or -1 if they weren't; the method couldn't
 raise an exception or return anything other than a Boolean value.  Users of
 Numeric Python often found this model too weak and restrictive, because in the
@@ -175,21 +175,21 @@ In Python 2.1, rich comparisons were added in order to support this need.
 Python classes can now individually overload each of the ``<``, ``<=``, ``>``,
 ``>=``, ``==``, and ``!=`` operations.  The new magic method names are:
 
-+-----------+----------------+
-| Operation | Method name    |
-+===========+================+
-| ``<``     | :meth:`__lt__` |
-+-----------+----------------+
-| ``<=``    | :meth:`__le__` |
-+-----------+----------------+
-| ``>``     | :meth:`__gt__` |
-+-----------+----------------+
-| ``>=``    | :meth:`__ge__` |
-+-----------+----------------+
-| ``==``    | :meth:`__eq__` |
-+-----------+----------------+
-| ``!=``    | :meth:`__ne__` |
-+-----------+----------------+
++-----------+------------------------+
+| Operation | Method name            |
++===========+========================+
+| ``<``     | :meth:`~object.__lt__` |
++-----------+------------------------+
+| ``<=``    | :meth:`~object.__le__` |
++-----------+------------------------+
+| ``>``     | :meth:`~object.__gt__` |
++-----------+------------------------+
+| ``>=``    | :meth:`~object.__ge__` |
++-----------+------------------------+
+| ``==``    | :meth:`~object.__eq__` |
++-----------+------------------------+
+| ``!=``    | :meth:`~object.__ne__` |
++-----------+------------------------+
 
 (The magic methods are named after the corresponding Fortran operators ``.LT.``.
 ``.LE.``, &c.  Numeric programmers are almost certainly quite familiar with
@@ -208,7 +208,7 @@ The built-in ``cmp(A,B)`` function can use the rich comparison machinery,
 and now accepts an optional argument specifying which comparison operation to
 use; this is given as one of the strings ``"<"``, ``"<="``, ``">"``, ``">="``,
 ``"=="``, or ``"!="``.  If called without the optional third argument,
-:func:`cmp` will only return -1, 0, or +1 as in previous versions of Python;
+:func:`!cmp` will only return -1, 0, or +1 as in previous versions of Python;
 otherwise it will call the appropriate method and can return any Python object.
 
 There are also corresponding changes of interest to C programmers; there's a new
@@ -245,7 +245,7 @@ out warnings that you don't want to be displayed. Third-party modules can also
 use this framework to deprecate old features that they no longer wish to
 support.
 
-For example, in Python 2.1 the :mod:`regex` module is deprecated, so importing
+For example, in Python 2.1 the :mod:`!regex` module is deprecated, so importing
 it causes a warning to be printed::
 
    >>> import regex
@@ -262,7 +262,7 @@ can be used to specify a particular warning category.
 
 Filters can be added to disable certain warnings; a regular expression pattern
 can be applied to the message or to the module name in order to suppress a
-warning.  For example, you may have a program that uses the :mod:`regex` module
+warning.  For example, you may have a program that uses the :mod:`!regex` module
 and not want to spare the time to convert it to use the :mod:`re` module right
 now.  The warning can be suppressed by calling ::
 
@@ -274,7 +274,7 @@ now.  The warning can be suppressed by calling ::
 
 This adds a filter that will apply only to warnings of the class
 :class:`DeprecationWarning` triggered in the :mod:`__main__` module, and applies
-a regular expression to only match the message about the :mod:`regex` module
+a regular expression to only match the message about the :mod:`!regex` module
 being deprecated, and will cause such warnings to be ignored.  Warnings can also
 be printed only once, printed every time the offending code is executed, or
 turned into exceptions that will cause the program to stop (unless the
@@ -368,7 +368,7 @@ dictionary::
 This version works for simple things such as integers, but it has a side effect;
 the ``_cache`` dictionary holds a reference to the return values, so they'll
 never be deallocated until the Python process exits and cleans up. This isn't
-very noticeable for integers, but if :func:`f` returns an object, or a data
+very noticeable for integers, but if :func:`!f` returns an object, or a data
 structure that takes up a lot of memory, this can be a problem.
 
 Weak references provide a way to implement a cache that won't keep objects alive
@@ -379,7 +379,7 @@ created by calling ``wr = weakref.ref(obj)``.  The object being referred to is
 returned by calling the weak reference as if it were a function: ``wr()``.  It
 will return the referenced object, or ``None`` if the object no longer exists.
 
-This makes it possible to write a :func:`memoize` function whose cache doesn't
+This makes it possible to write a :func:`!memoize` function whose cache doesn't
 keep objects alive, by storing weak references in the cache. ::
 
    _cache = {}
@@ -402,7 +402,7 @@ weak references --- an object referenced only by proxy objects is deallocated --
 but instead of requiring an explicit call to retrieve the object, the proxy
 transparently forwards all operations to the object as long as the object still
 exists.  If the object is deallocated, attempting to use a proxy will cause a
-:exc:`weakref.ReferenceError` exception to be raised. ::
+:exc:`!weakref.ReferenceError` exception to be raised. ::
 
    proxy = weakref.proxy(obj)
    proxy.attr   # Equivalent to obj.attr
@@ -446,7 +446,7 @@ The dictionary containing attributes can be accessed as the function's
 :attr:`~object.__dict__`. Unlike the :attr:`~object.__dict__` attribute of class instances, in
 functions you can actually assign a new dictionary to :attr:`~object.__dict__`, though
 the new value is restricted to a regular Python dictionary; you *can't* be
-tricky and set it to a :class:`UserDict` instance, or any other random object
+tricky and set it to a :class:`!UserDict` instance, or any other random object
 that behaves like a mapping.
 
 
@@ -584,11 +584,11 @@ available from the Distutils SIG at https://www.python.org/community/sigs/curren
 New and Improved Modules
 ========================
 
-* Ka-Ping Yee contributed two new modules: :mod:`inspect.py`, a module for
-  getting information about live Python code, and :mod:`pydoc.py`, a module for
+* Ka-Ping Yee contributed two new modules: :mod:`!inspect.py`, a module for
+  getting information about live Python code, and :mod:`!pydoc.py`, a module for
   interactively converting docstrings to HTML or text.  As a bonus,
   :file:`Tools/scripts/pydoc`, which is now automatically installed, uses
-  :mod:`pydoc.py` to display documentation given a Python module, package, or
+  :mod:`!pydoc.py` to display documentation given a Python module, package, or
   class name.  For example, ``pydoc xml.dom`` displays the following::
 
      Python Library Documentation: package xml.dom in xml
@@ -617,7 +617,7 @@ New and Improved Modules
   Kent Beck's Smalltalk testing framework.  See https://pyunit.sourceforge.net/ for
   more information about PyUnit.
 
-* The :mod:`difflib` module contains a class, :class:`SequenceMatcher`, which
+* The :mod:`difflib` module contains a class, :class:`~difflib.SequenceMatcher`, which
   compares two sequences and computes the changes required to transform one
   sequence into the other.  For example, this module can be used to write a tool
   similar to the Unix :program:`diff` program, and in fact the sample program
@@ -633,7 +633,7 @@ New and Improved Modules
   2.1 includes an updated version of the :mod:`xml` package.  Some of the
   noteworthy changes include support for Expat 1.2 and later versions, the ability
   for Expat parsers to handle files in any encoding supported by Python, and
-  various bugfixes for SAX, DOM, and the :mod:`minidom` module.
+  various bugfixes for SAX, DOM, and the :mod:`!minidom` module.
 
 * Ping also contributed another hook for handling uncaught exceptions.
   :func:`sys.excepthook` can be set to a callable object.  When an exception isn't
@@ -643,8 +643,8 @@ New and Improved Modules
   printing an extended traceback that not only lists the stack frames, but also
   lists the function arguments and the local variables for each frame.
 
-* Various functions in the :mod:`time` module, such as :func:`asctime` and
-  :func:`localtime`, require a floating point argument containing the time in
+* Various functions in the :mod:`time` module, such as :func:`~time.asctime` and
+  :func:`~time.localtime`, require a floating point argument containing the time in
   seconds since the epoch.  The most common use of these functions is to work with
   the current time, so the floating point argument has been made optional; when a
   value isn't provided, the current time will be used.  For example, log file
@@ -724,10 +724,10 @@ of the more notable changes are:
   a discussion in comp.lang.python.
 
   A new module and method for file objects was also added, contributed by Jeff
-  Epler. The new method, :meth:`xreadlines`, is similar to the existing
-  :func:`xrange` built-in.  :func:`xreadlines` returns an opaque sequence object
+  Epler. The new method, :meth:`!xreadlines`, is similar to the existing
+  :func:`!xrange` built-in.  :func:`!xreadlines` returns an opaque sequence object
   that only supports being iterated over, reading a line on every iteration but
-  not reading the entire file into memory as the existing :meth:`readlines` method
+  not reading the entire file into memory as the existing :meth:`!readlines` method
   does. You'd use it like this::
 
      for line in sys.stdin.xreadlines():
@@ -737,7 +737,7 @@ of the more notable changes are:
   For a fuller discussion of the line I/O changes, see the python-dev summary for
   January 1--15, 2001 at https://mail.python.org/pipermail/python-dev/2001-January/.
 
-* A new method, :meth:`popitem`, was added to dictionaries to enable
+* A new method, :meth:`~dict.popitem`, was added to dictionaries to enable
   destructively iterating through the contents of a dictionary; this can be faster
   for large dictionaries because there's no need to construct a list containing
   all the keys or values. ``D.popitem()`` removes a random ``(key, value)`` pair
diff --git a/Doc/whatsnew/2.6.rst b/Doc/whatsnew/2.6.rst
index 8ced044ad4..524588e93b 100644
--- a/Doc/whatsnew/2.6.rst
+++ b/Doc/whatsnew/2.6.rst
@@ -2388,11 +2388,11 @@ changes, or look through the Subversion logs for all the details.
   using the format character ``'?'``.
   (Contributed by David Remahl.)
 
-* The :class:`Popen` objects provided by the :mod:`subprocess` module
-  now have :meth:`terminate`, :meth:`kill`, and :meth:`send_signal` methods.
-  On Windows, :meth:`send_signal` only supports the :const:`SIGTERM`
+* The :class:`~subprocess.Popen` objects provided by the :mod:`subprocess` module
+  now have :meth:`~subprocess.Popen.terminate`, :meth:`~subprocess.Popen.kill`, and :meth:`~subprocess.Popen.send_signal` methods.
+  On Windows, :meth:`!send_signal` only supports the :py:const:`~signal.SIGTERM`
   signal, and all these methods are aliases for the Win32 API function
-  :c:func:`TerminateProcess`.
+  :c:func:`!TerminateProcess`.
   (Contributed by Christian Heimes.)
 
 * A new variable in the :mod:`sys` module, :attr:`float_info`, is an
@@ -2992,6 +2992,33 @@ Changes to Python's build process and to the C API include:
   architectures (x86, PowerPC), 64-bit (x86-64 and PPC-64), or both.
   (Contributed by Ronald Oussoren.)
 
+* A new function added in Python 2.6.6, :c:func:`!PySys_SetArgvEx`, sets
+  the value of ``sys.argv`` and can optionally update ``sys.path`` to
+  include the directory containing the script named by ``sys.argv[0]``
+  depending on the value of an *updatepath* parameter.
+
+  This function was added to close a security hole for applications
+  that embed Python.  The old function, :c:func:`!PySys_SetArgv`, would
+  always update ``sys.path``, and sometimes it would add the current
+  directory.  This meant that, if you ran an application embedding
+  Python in a directory controlled by someone else, attackers could
+  put a Trojan-horse module in the directory (say, a file named
+  :file:`os.py`) that your application would then import and run.
+
+  If you maintain a C/C++ application that embeds Python, check
+  whether you're calling :c:func:`!PySys_SetArgv` and carefully consider
+  whether the application should be using :c:func:`!PySys_SetArgvEx`
+  with *updatepath* set to false.  Note that using this function will
+  break compatibility with Python versions 2.6.5 and earlier; if you
+  have to continue working with earlier versions, you can leave
+  the call to :c:func:`!PySys_SetArgv` alone and call
+  ``PyRun_SimpleString("sys.path.pop(0)\n")`` afterwards to discard
+  the first ``sys.path`` component.
+
+  Security issue reported as `CVE-2008-5983
+  <http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2008-5983>`_;
+  discussed in :gh:`50003`, and fixed by Antoine Pitrou.
+
 * The BerkeleyDB module now has a C API object, available as
   ``bsddb.db.api``.   This object can be used by other C extensions
   that wish to use the :mod:`bsddb` module for their own purposes.
@@ -3294,6 +3321,15 @@ that may require changes to your code:
   scoping rules, also cause warnings because such comparisons are forbidden
   entirely in 3.0.
 
+For applications that embed Python:
+
+* The :c:func:`!PySys_SetArgvEx` function was added in Python 2.6.6,
+  letting applications close a security hole when the existing
+  :c:func:`!PySys_SetArgv` function was used.  Check whether you're
+  calling :c:func:`!PySys_SetArgv` and carefully consider whether the
+  application should be using :c:func:`!PySys_SetArgvEx` with
+  *updatepath* set to false.
+
 .. ======================================================================
 
 
diff --git a/Doc/whatsnew/2.7.rst b/Doc/whatsnew/2.7.rst
index 401af6c8e0..383dd77da4 100644
--- a/Doc/whatsnew/2.7.rst
+++ b/Doc/whatsnew/2.7.rst
@@ -196,7 +196,7 @@ A partial list of 3.1 features that were backported to 2.7:
 
 Other new Python3-mode warnings include:
 
-* :func:`operator.isCallable` and :func:`operator.sequenceIncludes`,
+* :func:`!operator.isCallable` and :func:`!operator.sequenceIncludes`,
   which are not supported in 3.x, now trigger warnings.
 * The :option:`!-3` switch now automatically
   enables the :option:`!-Qwarn` switch that causes warnings
@@ -455,11 +455,11 @@ a varying number of handlers.
 All this flexibility can require a lot of configuration.  You can
 write Python statements to create objects and set their properties,
 but a complex set-up requires verbose but boring code.
-:mod:`logging` also supports a :func:`~logging.fileConfig`
+:mod:`logging` also supports a :func:`~logging.config.fileConfig`
 function that parses a file, but the file format doesn't support
 configuring filters, and it's messier to generate programmatically.
 
-Python 2.7 adds a :func:`~logging.dictConfig` function that
+Python 2.7 adds a :func:`~logging.config.dictConfig` function that
 uses a dictionary to configure logging.  There are many ways to
 produce a dictionary from different sources: construct one with code;
 parse a file containing JSON; or use a YAML parsing library if one is
@@ -533,7 +533,7 @@ implemented by Vinay Sajip, are:
   ``getLogger('app.network.listen')``.
 
 * The :class:`~logging.LoggerAdapter` class gained an
-  :meth:`~logging.LoggerAdapter.isEnabledFor` method that takes a
+  :meth:`~logging.Logger.isEnabledFor` method that takes a
   *level* and returns whether the underlying logger would
   process a message of that level of importance.
 
@@ -554,8 +554,8 @@ called a :dfn:`view` instead of a fully materialized list.
 It's not possible to change the return values of :meth:`~dict.keys`,
 :meth:`~dict.values`, and :meth:`~dict.items` in Python 2.7 because
 too much code would break.  Instead the 3.x versions were added
-under the new names :meth:`~dict.viewkeys`, :meth:`~dict.viewvalues`,
-and :meth:`~dict.viewitems`.
+under the new names :meth:`!viewkeys`, :meth:`!viewvalues`,
+and :meth:`!viewitems`.
 
 ::
 
@@ -720,7 +720,7 @@ Some smaller changes made to the core Python language are:
        with B() as b:
            ... suite of statements ...
 
-  The :func:`contextlib.nested` function provides a very similar
+  The :func:`!contextlib.nested` function provides a very similar
   function, so it's no longer necessary and has been deprecated.
 
   (Proposed in https://codereview.appspot.com/53094; implemented by
@@ -785,7 +785,7 @@ Some smaller changes made to the core Python language are:
   implemented by Mark Dickinson; :issue:`1811`.)
 
 * Implicit coercion for complex numbers has been removed; the interpreter
-  will no longer ever attempt to call a :meth:`__coerce__` method on complex
+  will no longer ever attempt to call a :meth:`!__coerce__` method on complex
   objects.  (Removed by Meador Inge and Mark Dickinson; :issue:`5211`.)
 
 * The :meth:`str.format` method now supports automatic numbering of the replacement
@@ -817,7 +817,7 @@ Some smaller changes made to the core Python language are:
 
   A low-level change: the :meth:`object.__format__` method now triggers
   a :exc:`PendingDeprecationWarning` if it's passed a format string,
-  because the :meth:`__format__` method for :class:`object` converts
+  because the :meth:`!__format__` method for :class:`object` converts
   the object to a string representation and formats that.  Previously
   the method silently applied the format string to the string
   representation, but that could hide mistakes in Python code.  If
@@ -825,7 +825,7 @@ Some smaller changes made to the core Python language are:
   precision, presumably you're expecting the formatting to be applied
   in some object-specific way.  (Fixed by Eric Smith; :issue:`7994`.)
 
-* The :func:`int` and :func:`long` types gained a ``bit_length``
+* The :func:`int` and :func:`!long` types gained a ``bit_length``
   method that returns the number of bits necessary to represent
   its argument in binary::
 
@@ -848,8 +848,8 @@ Some smaller changes made to the core Python language are:
   statements that were only working by accident.  (Fixed by Meador Inge;
   :issue:`7902`.)
 
-* It's now possible for a subclass of the built-in :class:`unicode` type
-  to override the :meth:`__unicode__` method.  (Implemented by
+* It's now possible for a subclass of the built-in :class:`!unicode` type
+  to override the :meth:`!__unicode__` method.  (Implemented by
   Victor Stinner; :issue:`1583863`.)
 
 * The :class:`bytearray` type's :meth:`~bytearray.translate` method now accepts
@@ -876,7 +876,7 @@ Some smaller changes made to the core Python language are:
   Forgeot d'Arc in :issue:`1616979`; CP858 contributed by Tim Hatch in
   :issue:`8016`.)
 
-* The :class:`file` object will now set the :attr:`filename` attribute
+* The :class:`!file` object will now set the :attr:`!filename` attribute
   on the :exc:`IOError` exception when trying to open a directory
   on POSIX platforms (noted by Jan Kaliszewski; :issue:`4764`), and
   now explicitly checks for and forbids writing to read-only file objects
@@ -966,7 +966,7 @@ Several performance enhancements have been added:
 
   Apart from the performance improvements this change should be
   invisible to end users, with one exception: for testing and
-  debugging purposes there's a new structseq :data:`sys.long_info` that
+  debugging purposes there's a new structseq :data:`!sys.long_info` that
   provides information about the internal format, giving the number of
   bits per digit and the size in bytes of the C type used to store
   each digit::
@@ -1005,8 +1005,8 @@ Several performance enhancements have been added:
   conversion function that supports arbitrary bases.
   (Patch by Gawain Bolton; :issue:`6713`.)
 
-* The :meth:`split`, :meth:`replace`, :meth:`rindex`,
-  :meth:`rpartition`, and :meth:`rsplit` methods of string-like types
+* The :meth:`!split`, :meth:`!replace`, :meth:`!rindex`,
+  :meth:`!rpartition`, and :meth:`!rsplit` methods of string-like types
   (strings, Unicode strings, and :class:`bytearray` objects) now use a
   fast reverse-search algorithm instead of a character-by-character
   scan.  This is sometimes faster by a factor of 10.  (Added by
@@ -1044,7 +1044,7 @@ changes, or look through the Subversion logs for all the details.
   used with :class:`memoryview` instances and other similar buffer objects.
   (Backported from 3.x by Florent Xicluna; :issue:`7703`.)
 
-* Updated module: the :mod:`bsddb` module has been updated from 4.7.2devel9
+* Updated module: the :mod:`!bsddb` module has been updated from 4.7.2devel9
   to version 4.8.4 of
   `the pybsddb package <https://www.jcea.es/programacion/pybsddb.htm>`__.
   The new version features better Python 3.x compatibility, various bug fixes,
@@ -1129,8 +1129,8 @@ changes, or look through the Subversion logs for all the details.
 
   (Added by Raymond Hettinger; :issue:`1818`.)
 
-  Finally, the :class:`~collections.Mapping` abstract base class now
-  returns :const:`NotImplemented` if a mapping is compared to
+  Finally, the :class:`~collections.abc.Mapping` abstract base class now
+  returns :data:`NotImplemented` if a mapping is compared to
   another type that isn't a :class:`Mapping`.
   (Fixed by Daniel Stutzbach; :issue:`8729`.)
 
@@ -1158,7 +1158,7 @@ changes, or look through the Subversion logs for all the details.
 
   (Contributed by Mats Kindahl; :issue:`7005`.)
 
-* Deprecated function: :func:`contextlib.nested`, which allows
+* Deprecated function: :func:`!contextlib.nested`, which allows
   handling more than one context manager with a single :keyword:`with`
   statement, has been deprecated, because the :keyword:`!with` statement
   now supports multiple context managers.
@@ -1184,7 +1184,7 @@ changes, or look through the Subversion logs for all the details.
 
 * New method: the :class:`~decimal.Decimal` class gained a
   :meth:`~decimal.Decimal.from_float` class method that performs an exact
-  conversion of a floating-point number to a :class:`~decimal.Decimal`.
+  conversion of a floating-point number to a :class:`!Decimal`.
   This exact conversion strives for the
   closest decimal approximation to the floating-point representation's value;
   the resulting decimal value will therefore still include the inaccuracy,
@@ -1198,9 +1198,9 @@ changes, or look through the Subversion logs for all the details.
   of the operands.  Previously such comparisons would fall back to
   Python's default rules for comparing objects, which produced arbitrary
   results based on their type.  Note that you still cannot combine
-  :class:`Decimal` and floating-point in other operations such as addition,
+  :class:`!Decimal` and floating-point in other operations such as addition,
   since you should be explicitly choosing how to convert between float and
-  :class:`~decimal.Decimal`.  (Fixed by Mark Dickinson; :issue:`2531`.)
+  :class:`!Decimal`.  (Fixed by Mark Dickinson; :issue:`2531`.)
 
   The constructor for :class:`~decimal.Decimal` now accepts
   floating-point numbers (added by Raymond Hettinger; :issue:`8257`)
@@ -1218,7 +1218,7 @@ changes, or look through the Subversion logs for all the details.
   more sensible for numeric types.  (Changed by Mark Dickinson; :issue:`6857`.)
 
   Comparisons involving a signaling NaN value (or ``sNAN``) now signal
-  :const:`InvalidOperation` instead of silently returning a true or
+  :const:`~decimal.InvalidOperation` instead of silently returning a true or
   false value depending on the comparison operator.  Quiet NaN values
   (or ``NaN``) are now hashable.  (Fixed by Mark Dickinson;
   :issue:`7279`.)
@@ -1235,13 +1235,13 @@ changes, or look through the Subversion logs for all the details.
   created some new files that should be included.
   (Fixed by Tarek Ziad; :issue:`8688`.)
 
-* The :mod:`doctest` module's :const:`IGNORE_EXCEPTION_DETAIL` flag
+* The :mod:`doctest` module's :const:`~doctest.IGNORE_EXCEPTION_DETAIL` flag
   will now ignore the name of the module containing the exception
   being tested.  (Patch by Lennart Regebro; :issue:`7490`.)
 
 * The :mod:`email` module's :class:`~email.message.Message` class will
   now accept a Unicode-valued payload, automatically converting the
-  payload to the encoding specified by :attr:`output_charset`.
+  payload to the encoding specified by :attr:`!output_charset`.
   (Added by R. David Murray; :issue:`1368247`.)
 
 * The :class:`~fractions.Fraction` class now accepts a single float or
@@ -1268,10 +1268,10 @@ changes, or look through the Subversion logs for all the details.
   :issue:`6845`.)
 
 * New class decorator: :func:`~functools.total_ordering` in the :mod:`functools`
-  module takes a class that defines an :meth:`__eq__` method and one of
-  :meth:`__lt__`, :meth:`__le__`, :meth:`__gt__`, or :meth:`__ge__`,
+  module takes a class that defines an :meth:`~object.__eq__` method and one of
+  :meth:`~object.__lt__`, :meth:`~object.__le__`, :meth:`~object.__gt__`, or :meth:`~object.__ge__`,
   and generates the missing comparison methods.  Since the
-  :meth:`__cmp__` method is being deprecated in Python 3.x,
+  :meth:`!__cmp__` method is being deprecated in Python 3.x,
   this decorator makes it easier to define ordered classes.
   (Added by Raymond Hettinger; :issue:`5479`.)
 
@@ -1300,7 +1300,7 @@ changes, or look through the Subversion logs for all the details.
   :mod:`gzip` module will now consume these trailing bytes.  (Fixed by
   Tadek Pietraszek and Brian Curtin; :issue:`2846`.)
 
-* New attribute: the :mod:`hashlib` module now has an :attr:`~hashlib.hashlib.algorithms`
+* New attribute: the :mod:`hashlib` module now has an :attr:`!algorithms`
   attribute containing a tuple naming the supported algorithms.
   In Python 2.7, ``hashlib.algorithms`` contains
   ``('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')``.
@@ -1348,10 +1348,10 @@ changes, or look through the Subversion logs for all the details.
 * Updated module: The :mod:`io` library has been upgraded to the version shipped with
   Python 3.1.  For 3.1, the I/O library was entirely rewritten in C
   and is 2 to 20 times faster depending on the task being performed.  The
-  original Python version was renamed to the :mod:`_pyio` module.
+  original Python version was renamed to the :mod:`!_pyio` module.
 
   One minor resulting change: the :class:`io.TextIOBase` class now
-  has an :attr:`errors` attribute giving the error setting
+  has an :attr:`~io.TextIOBase.errors` attribute giving the error setting
   used for encoding and decoding errors (one of ``'strict'``, ``'replace'``,
   ``'ignore'``).
 
@@ -1423,10 +1423,10 @@ changes, or look through the Subversion logs for all the details.
   passed to the callable.
   (Contributed by lekma; :issue:`5585`.)
 
-  The :class:`~multiprocessing.Pool` class, which controls a pool of worker processes,
+  The :class:`~multiprocessing.pool.Pool` class, which controls a pool of worker processes,
   now has an optional *maxtasksperchild* parameter.  Worker processes
   will perform the specified number of tasks and then exit, causing the
-  :class:`~multiprocessing.Pool` to start a new worker.  This is useful if tasks may leak
+  :class:`!Pool` to start a new worker.  This is useful if tasks may leak
   memory or other resources, or if some tasks will cause the worker to
   become very large.
   (Contributed by Charles Cazabon; :issue:`6963`.)
@@ -1498,7 +1498,7 @@ changes, or look through the Subversion logs for all the details.
   global site-packages directories,
   :func:`~site.getusersitepackages` returns the path of the user's
   site-packages directory, and
-  :func:`~site.getuserbase` returns the value of the :envvar:`USER_BASE`
+  :func:`~site.getuserbase` returns the value of the :data:`~site.USER_BASE`
   environment variable, giving the path to a directory that can be used
   to store data.
   (Contributed by Tarek Ziad; :issue:`6693`.)
@@ -1540,11 +1540,11 @@ changes, or look through the Subversion logs for all the details.
 * The :mod:`ssl` module's :class:`~ssl.SSLSocket` objects now support the
   buffer API, which fixed a test suite failure (fix by Antoine Pitrou;
   :issue:`7133`) and automatically set
-  OpenSSL's :c:macro:`SSL_MODE_AUTO_RETRY`, which will prevent an error
+  OpenSSL's :c:macro:`!SSL_MODE_AUTO_RETRY`, which will prevent an error
   code being returned from :meth:`recv` operations that trigger an SSL
   renegotiation (fix by Antoine Pitrou; :issue:`8222`).
 
-  The :func:`ssl.wrap_socket` constructor function now takes a
+  The :func:`~ssl.SSLContext.wrap_socket` constructor function now takes a
   *ciphers* argument that's a string listing the encryption algorithms
   to be allowed; the format of the string is described
   `in the OpenSSL documentation
@@ -1568,8 +1568,8 @@ changes, or look through the Subversion logs for all the details.
   code (one of ``bBhHiIlLqQ``); it now always raises a
   :exc:`struct.error` exception.  (Changed by Mark Dickinson;
   :issue:`1523`.)  The :func:`~struct.pack` function will also
-  attempt to use :meth:`__index__` to convert and pack non-integers
-  before trying the :meth:`__int__` method or reporting an error.
+  attempt to use :meth:`~object.__index__` to convert and pack non-integers
+  before trying the :meth:`~object.__int__` method or reporting an error.
   (Changed by Mark Dickinson; :issue:`8300`.)
 
 * New function: the :mod:`subprocess` module's
@@ -1590,7 +1590,7 @@ changes, or look through the Subversion logs for all the details.
   (Contributed by Gregory P. Smith.)
 
   The :mod:`subprocess` module will now retry its internal system calls
-  on receiving an :const:`EINTR` signal.  (Reported by several people; final
+  on receiving an :const:`~errno.EINTR` signal.  (Reported by several people; final
   patch by Gregory P. Smith in :issue:`1068268`.)
 
 * New function: :func:`~symtable.Symbol.is_declared_global` in the :mod:`symtable` module
@@ -1602,16 +1602,16 @@ changes, or look through the Subversion logs for all the details.
   identifier instead of the previous default value of ``'python'``.
   (Changed by Sean Reifschneider; :issue:`8451`.)
 
-* The ``sys.version_info`` value is now a named tuple, with attributes
-  named :attr:`major`, :attr:`minor`, :attr:`micro`,
-  :attr:`releaselevel`, and :attr:`serial`.  (Contributed by Ross
+* The :attr:`sys.version_info` value is now a named tuple, with attributes
+  named :attr:`!major`, :attr:`!minor`, :attr:`!micro`,
+  :attr:`!releaselevel`, and :attr:`!serial`.  (Contributed by Ross
   Light; :issue:`4285`.)
 
   :func:`sys.getwindowsversion` also returns a named tuple,
-  with attributes named :attr:`major`, :attr:`minor`, :attr:`build`,
-  :attr:`platform`, :attr:`service_pack`, :attr:`service_pack_major`,
-  :attr:`service_pack_minor`, :attr:`suite_mask`, and
-  :attr:`product_type`.  (Contributed by Brian Curtin; :issue:`7766`.)
+  with attributes named :attr:`!major`, :attr:`!minor`, :attr:`!build`,
+  :attr:`!platform`, :attr:`!service_pack`, :attr:`!service_pack_major`,
+  :attr:`!service_pack_minor`, :attr:`!suite_mask`, and
+  :attr:`!product_type`.  (Contributed by Brian Curtin; :issue:`7766`.)
 
 * The :mod:`tarfile` module's default error handling has changed, to
   no longer suppress fatal errors.  The default error level was previously 0,
@@ -1691,7 +1691,7 @@ changes, or look through the Subversion logs for all the details.
   (Originally implemented in Python 3.x by Raymond Hettinger, and backported
   to 2.7 by Michael Foord.)
 
-* The ElementTree library, :mod:`xml.etree`, no longer escapes
+* The :mod:`xml.etree.ElementTree` library, no longer escapes
   ampersands and angle brackets when outputting an XML processing
   instruction (which looks like ``<?xml-stylesheet href="#style1"?>``)
   or comment (which looks like ``<!-- comment -->``).
@@ -1701,8 +1701,8 @@ changes, or look through the Subversion logs for all the details.
   :mod:`SimpleXMLRPCServer <xmlrpc.server>` modules, have improved performance by
   supporting HTTP/1.1 keep-alive and by optionally using gzip encoding
   to compress the XML being exchanged.  The gzip compression is
-  controlled by the :attr:`encode_threshold` attribute of
-  :class:`SimpleXMLRPCRequestHandler`, which contains a size in bytes;
+  controlled by the :attr:`!encode_threshold` attribute of
+  :class:`~xmlrpc.server.SimpleXMLRPCRequestHandler`, which contains a size in bytes;
   responses larger than this will be compressed.
   (Contributed by Kristjn Valur Jnsson; :issue:`6267`.)
 
@@ -1713,7 +1713,8 @@ changes, or look through the Subversion logs for all the details.
   :mod:`zipfile` now also supports archiving empty directories and
   extracts them correctly.  (Fixed by Kuba Wieczorek; :issue:`4710`.)
   Reading files out of an archive is faster, and interleaving
-  :meth:`~zipfile.ZipFile.read` and :meth:`~zipfile.ZipFile.readline` now works correctly.
+  :meth:`read() <io.BufferedIOBase.read>` and
+  :meth:`readline() <io.IOBase.readline>` now works correctly.
   (Contributed by Nir Aides; :issue:`7610`.)
 
   The :func:`~zipfile.is_zipfile` function now
@@ -1807,14 +1808,14 @@ closely resemble the native platform's widgets.  This widget
 set was originally called Tile, but was renamed to Ttk (for "themed Tk")
 on being added to Tcl/Tck release 8.5.
 
-To learn more, read the :mod:`ttk` module documentation.  You may also
+To learn more, read the :mod:`~tkinter.ttk` module documentation.  You may also
 wish to read the Tcl/Tk manual page describing the
 Ttk theme engine, available at
-https://www.tcl.tk/man/tcl8.5/TkCmd/ttk_intro.htm. Some
+https://www.tcl.tk/man/tcl8.5/TkCmd/ttk_intro.html. Some
 screenshots of the Python/Ttk code in use are at
 https://code.google.com/archive/p/python-ttk/wikis/Screenshots.wiki.
 
-The :mod:`ttk` module was written by Guilherme Polo and added in
+The :mod:`tkinter.ttk` module was written by Guilherme Polo and added in
 :issue:`2983`.  An alternate version called ``Tile.py``, written by
 Martin Franklin and maintained by Kevin Walzer, was proposed for
 inclusion in :issue:`2618`, but the authors argued that Guilherme
@@ -1830,7 +1831,7 @@ The :mod:`unittest` module was greatly enhanced; many
 new features were added.  Most of these features were implemented
 by Michael Foord, unless otherwise noted.  The enhanced version of
 the module is downloadable separately for use with Python versions 2.4 to 2.6,
-packaged as the :mod:`unittest2` package, from
+packaged as the :mod:`!unittest2` package, from
 https://pypi.org/project/unittest2.
 
 When used from the command line, the module can automatically discover
@@ -1938,19 +1939,20 @@ GvR worked on merging them into Python's version of :mod:`unittest`.
   differences in the two strings.  This comparison is now used by
   default when Unicode strings are compared with :meth:`~unittest.TestCase.assertEqual`.
 
-* :meth:`~unittest.TestCase.assertRegexpMatches` and
-  :meth:`~unittest.TestCase.assertNotRegexpMatches` checks whether the
+* :meth:`assertRegexpMatches() <unittest.TestCase.assertRegex>` and
+  :meth:`assertNotRegexpMatches() <unittest.TestCase.assertNotRegex>` checks whether the
   first argument is a string matching or not matching the regular
   expression provided as the second argument (:issue:`8038`).
 
-* :meth:`~unittest.TestCase.assertRaisesRegexp` checks whether a particular exception
+* :meth:`assertRaisesRegexp() <unittest.TestCase.assertRaisesRegex>` checks
+  whether a particular exception
   is raised, and then also checks that the string representation of
   the exception matches the provided regular expression.
 
 * :meth:`~unittest.TestCase.assertIn` and :meth:`~unittest.TestCase.assertNotIn`
   tests whether *first* is or is not in  *second*.
 
-* :meth:`~unittest.TestCase.assertItemsEqual` tests whether two provided sequences
+* :meth:`assertItemsEqual() <unittest.TestCase.assertCountEqual>` tests whether two provided sequences
   contain the same elements.
 
 * :meth:`~unittest.TestCase.assertSetEqual` compares whether two sets are equal, and
@@ -1966,7 +1968,7 @@ GvR worked on merging them into Python's version of :mod:`unittest`.
 
 * :meth:`~unittest.TestCase.assertDictEqual` compares two dictionaries and reports the
   differences; it's now used by default when you compare two dictionaries
-  using :meth:`~unittest.TestCase.assertEqual`.  :meth:`~unittest.TestCase.assertDictContainsSubset` checks whether
+  using :meth:`~unittest.TestCase.assertEqual`.  :meth:`!assertDictContainsSubset` checks whether
   all of the key/value pairs in *first* are found in *second*.
 
 * :meth:`~unittest.TestCase.assertAlmostEqual` and :meth:`~unittest.TestCase.assertNotAlmostEqual` test
@@ -2023,8 +2025,8 @@ version 1.3.  Some of the new features are:
     p = ET.XMLParser(encoding='utf-8')
     t = ET.XML("""<root/>""", parser=p)
 
-  Errors in parsing XML now raise a :exc:`ParseError` exception, whose
-  instances have a :attr:`position` attribute
+  Errors in parsing XML now raise a :exc:`~xml.etree.ElementTree.ParseError` exception, whose
+  instances have a :attr:`!position` attribute
   containing a (*line*, *column*) tuple giving the location of the problem.
 
 * ElementTree's code for converting trees to a string has been
@@ -2034,7 +2036,8 @@ version 1.3.  Some of the new features are:
   "xml" (the default), "html", or "text".  HTML mode will output empty
   elements as ``<empty></empty>`` instead of ``<empty/>``, and text
   mode will skip over elements and only output the text chunks.  If
-  you set the :attr:`tag` attribute of an element to ``None`` but
+  you set the :attr:`~xml.etree.ElementTree.Element.tag` attribute of an
+  element to ``None`` but
   leave its children in place, the element will be omitted when the
   tree is written out, so you don't need to do more extensive rearrangement
   to remove a single element.
@@ -2064,14 +2067,14 @@ version 1.3.  Some of the new features are:
     # Outputs <root><item>1</item>...</root>
     print ET.tostring(new)
 
-* New :class:`Element` method:
+* New :class:`~xml.etree.ElementTree.Element` method:
   :meth:`~xml.etree.ElementTree.Element.iter` yields the children of the
   element as a generator.  It's also possible to write ``for child in
   elem:`` to loop over an element's children.  The existing method
-  :meth:`getiterator` is now deprecated, as is :meth:`getchildren`
+  :meth:`!getiterator` is now deprecated, as is :meth:`!getchildren`
   which constructs and returns a list of children.
 
-* New :class:`Element` method:
+* New :class:`~xml.etree.ElementTree.Element` method:
   :meth:`~xml.etree.ElementTree.Element.itertext` yields all chunks of
   text that are descendants of the element.  For example::
 
@@ -2227,7 +2230,7 @@ Changes to Python's build process and to the C API include:
   (Fixed by Thomas Wouters; :issue:`1590864`.)
 
 * The :c:func:`Py_Finalize` function now calls the internal
-  :func:`threading._shutdown` function; this prevents some exceptions from
+  :func:`!threading._shutdown` function; this prevents some exceptions from
   being raised when an interpreter shuts down.
   (Patch by Adam Olsen; :issue:`1722344`.)
 
@@ -2242,7 +2245,7 @@ Changes to Python's build process and to the C API include:
   Heller; :issue:`3102`.)
 
 * New configure option: the :option:`!--with-system-expat` switch allows
-  building the :mod:`pyexpat` module to use the system Expat library.
+  building the :mod:`pyexpat <xml.parsers.expat>` module to use the system Expat library.
   (Contributed by Arfrever Frehtes Taifersar Arahesis; :issue:`7609`.)
 
 * New configure option: the
@@ -2329,9 +2332,9 @@ Port-Specific Changes: Windows
 
 * The :mod:`msvcrt` module now contains some constants from
   the :file:`crtassem.h` header file:
-  :data:`CRT_ASSEMBLY_VERSION`,
-  :data:`VC_ASSEMBLY_PUBLICKEYTOKEN`,
-  and :data:`LIBRARIES_ASSEMBLY_NAME_PREFIX`.
+  :data:`~msvcrt.CRT_ASSEMBLY_VERSION`,
+  :data:`~msvcrt.VC_ASSEMBLY_PUBLICKEYTOKEN`,
+  and :data:`~msvcrt.LIBRARIES_ASSEMBLY_NAME_PREFIX`.
   (Contributed by David Cournapeau; :issue:`4365`.)
 
 * The :mod:`_winreg <winreg>` module for accessing the registry now implements
@@ -2342,21 +2345,21 @@ Port-Specific Changes: Windows
   were also tested and documented.
   (Implemented by Brian Curtin: :issue:`7347`.)
 
-* The new :c:func:`_beginthreadex` API is used to start threads, and
+* The new :c:func:`!_beginthreadex` API is used to start threads, and
   the native thread-local storage functions are now used.
   (Contributed by Kristjn Valur Jnsson; :issue:`3582`.)
 
 * The :func:`os.kill` function now works on Windows.  The signal value
-  can be the constants :const:`CTRL_C_EVENT`,
-  :const:`CTRL_BREAK_EVENT`, or any integer.  The first two constants
+  can be the constants :const:`~signal.CTRL_C_EVENT`,
+  :const:`~signal.CTRL_BREAK_EVENT`, or any integer.  The first two constants
   will send :kbd:`Control-C` and :kbd:`Control-Break` keystroke events to
-  subprocesses; any other value will use the :c:func:`TerminateProcess`
+  subprocesses; any other value will use the :c:func:`!TerminateProcess`
   API.  (Contributed by Miki Tebeka; :issue:`1220212`.)
 
 * The :func:`os.listdir` function now correctly fails
   for an empty path.  (Fixed by Hirokazu Yamamoto; :issue:`5913`.)
 
-* The :mod:`mimelib` module will now read the MIME database from
+* The :mod:`mimetypes` module will now read the MIME database from
   the Windows registry when initializing.
   (Patch by Gabriel Genellina; :issue:`4969`.)
 
@@ -2385,7 +2388,7 @@ Port-Specific Changes: Mac OS X
 Port-Specific Changes: FreeBSD
 -----------------------------------
 
-* FreeBSD 7.1's :const:`SO_SETFIB` constant, used with the :func:`~socket.socket` methods
+* FreeBSD 7.1's :const:`!SO_SETFIB` constant, used with the :func:`~socket.socket` methods
   :func:`~socket.socket.getsockopt`/:func:`~socket.socket.setsockopt` to select an
   alternate routing table, is now available in the :mod:`socket`
   module.  (Added by Kyle VanderBeek; :issue:`8235`.)
@@ -2441,7 +2444,7 @@ This section lists previously described changes and other bugfixes
 that may require changes to your code:
 
 * The :func:`range` function processes its arguments more
-  consistently; it will now call :meth:`__int__` on non-float,
+  consistently; it will now call :meth:`~object.__int__` on non-float,
   non-integer arguments that are supplied to it.  (Fixed by Alexander
   Belopolsky; :issue:`1533`.)
 
@@ -2486,13 +2489,13 @@ In the standard library:
   (or ``NaN``) are now hashable.  (Fixed by Mark Dickinson;
   :issue:`7279`.)
 
-* The ElementTree library, :mod:`xml.etree`, no longer escapes
+* The :mod:`xml.etree.ElementTree` library no longer escapes
   ampersands and angle brackets when outputting an XML processing
   instruction (which looks like ``<?xml-stylesheet href="#style1"?>``)
   or comment (which looks like ``<!-- comment -->``).
   (Patch by Neil Muller; :issue:`2746`.)
 
-* The :meth:`~StringIO.StringIO.readline` method of :class:`~StringIO.StringIO` objects now does
+* The :meth:`!readline` method of :class:`~io.StringIO` objects now does
   nothing when a negative length is requested, as other file-like
   objects do.  (:issue:`7348`).
 
@@ -2577,11 +2580,11 @@ Two new environment variables for debug mode
 --------------------------------------------
 
 In debug mode, the ``[xxx refs]`` statistic is not written by default, the
-:envvar:`PYTHONSHOWREFCOUNT` environment variable now must also be set.
+:envvar:`!PYTHONSHOWREFCOUNT` environment variable now must also be set.
 (Contributed by Victor Stinner; :issue:`31733`.)
 
 When Python is compiled with ``COUNT_ALLOC`` defined, allocation counts are no
-longer dumped by default anymore: the :envvar:`PYTHONSHOWALLOCCOUNT` environment
+longer dumped by default anymore: the :envvar:`!PYTHONSHOWALLOCCOUNT` environment
 variable must now also be set. Moreover, allocation counts are now dumped into
 stderr, rather than stdout. (Contributed by Victor Stinner; :issue:`31692`.)
 
@@ -2712,7 +2715,8 @@ PEP 476: Enabling certificate verification by default for stdlib http clients
 -----------------------------------------------------------------------------
 
 :pep:`476` updated :mod:`httplib <http>` and modules which use it, such as
-:mod:`urllib2 <urllib.request>` and :mod:`xmlrpclib`, to now verify that the server
+:mod:`urllib2 <urllib.request>` and :mod:`xmlrpclib <xmlrpc.client>`, to now
+verify that the server
 presents a certificate which is signed by a Certificate Authority in the
 platform trust store and whose hostname matches the hostname being requested
 by default, significantly improving security for many applications. This
@@ -2753,7 +2757,7 @@ entire Python process back to the default permissive behaviour of Python 2.7.8
 and earlier.
 
 For cases where the connection establishment code can't be modified, but the
-overall application can be, the new :func:`ssl._https_verify_certificates`
+overall application can be, the new :func:`!ssl._https_verify_certificates`
 function can be used to adjust the default behaviour at runtime.
 
 
diff --git a/Doc/whatsnew/3.1.rst b/Doc/whatsnew/3.1.rst
index cc6619c53c..7ecc34abb7 100644
--- a/Doc/whatsnew/3.1.rst
+++ b/Doc/whatsnew/3.1.rst
@@ -80,6 +80,28 @@ Support was also added for third-party tools like `PyYAML <https://pyyaml.org/>`
       PEP written by Armin Ronacher and Raymond Hettinger.  Implementation
       written by Raymond Hettinger.
 
+Since an ordered dictionary remembers its insertion order, it can be used
+in conjunction with sorting to make a sorted dictionary::
+
+    >>> # regular unsorted dictionary
+    >>> d = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}
+
+    >>> # dictionary sorted by key
+    >>> OrderedDict(sorted(d.items(), key=lambda t: t[0]))
+    OrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)])
+
+    >>> # dictionary sorted by value
+    >>> OrderedDict(sorted(d.items(), key=lambda t: t[1]))
+    OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])
+
+    >>> # dictionary sorted by length of the key string
+    >>> OrderedDict(sorted(d.items(), key=lambda t: len(t[0])))
+    OrderedDict([('pear', 1), ('apple', 4), ('orange', 2), ('banana', 3)])
+
+The new sorted dictionaries maintain their sort order when entries
+are deleted.  But when new keys are added, the keys are appended
+to the end and the sort is not maintained.
+
 
 PEP 378: Format Specifier for Thousands Separator
 =================================================
@@ -152,7 +174,7 @@ Some smaller changes made to the core Python language are:
 
   (Contributed by Eric Smith; :issue:`5237`.)
 
-* The :func:`string.maketrans` function is deprecated and is replaced by new
+* The :func:`!string.maketrans` function is deprecated and is replaced by new
   static methods, :meth:`bytes.maketrans` and :meth:`bytearray.maketrans`.
   This change solves the confusion around which types were supported by the
   :mod:`string` module. Now, :class:`str`, :class:`bytes`, and
@@ -169,7 +191,7 @@ Some smaller changes made to the core Python language are:
     ...         if '<critical>' in line:
     ...             outfile.write(line)
 
-  With the new syntax, the :func:`contextlib.nested` function is no longer
+  With the new syntax, the :func:`!contextlib.nested` function is no longer
   needed and is now deprecated.
 
   (Contributed by Georg Brandl and Mattias Brndstrm;
@@ -359,16 +381,20 @@ New, Improved, and Deprecated Modules
               x / 0
 
   In addition, several new assertion methods were added including
-  :func:`assertSetEqual`, :func:`assertDictEqual`,
-  :func:`assertDictContainsSubset`, :func:`assertListEqual`,
-  :func:`assertTupleEqual`, :func:`assertSequenceEqual`,
-  :func:`assertRaisesRegexp`, :func:`assertIsNone`,
-  and :func:`assertIsNotNone`.
+  :meth:`~unittest.TestCase.assertSetEqual`,
+  :meth:`~unittest.TestCase.assertDictEqual`,
+  :meth:`!assertDictContainsSubset`,
+  :meth:`~unittest.TestCase.assertListEqual`,
+  :meth:`~unittest.TestCase.assertTupleEqual`,
+  :meth:`~unittest.TestCase.assertSequenceEqual`,
+  :meth:`assertRaisesRegexp() <unittest.TestCase.assertRaisesRegex>`,
+  :meth:`~unittest.TestCase.assertIsNone`,
+  and :meth:`~unittest.TestCase.assertIsNotNone`.
 
   (Contributed by Benjamin Peterson and Antoine Pitrou.)
 
-* The :mod:`io` module has three new constants for the :meth:`seek`
-  method :data:`SEEK_SET`, :data:`SEEK_CUR`, and :data:`SEEK_END`.
+* The :mod:`io` module has three new constants for the :meth:`~io.IOBase.seek`
+  method: :data:`~os.SEEK_SET`, :data:`~os.SEEK_CUR`, and :data:`~os.SEEK_END`.
 
 * The :data:`sys.version_info` tuple is now a named tuple::
 
diff --git a/Doc/whatsnew/3.10.rst b/Doc/whatsnew/3.10.rst
index 83f2da6ca3..aa4ab30030 100644
--- a/Doc/whatsnew/3.10.rst
+++ b/Doc/whatsnew/3.10.rst
@@ -828,7 +828,7 @@ Other Language Changes
   :meth:`~object.__index__` method).
   (Contributed by Serhiy Storchaka in :issue:`37999`.)
 
-* If :func:`object.__ipow__` returns :const:`NotImplemented`, the operator will
+* If :func:`object.__ipow__` returns :data:`NotImplemented`, the operator will
   correctly fall back to :func:`object.__pow__` and :func:`object.__rpow__` as expected.
   (Contributed by Alex Shkop in :issue:`38302`.)
 
@@ -1517,6 +1517,13 @@ functions internally.  For more details, please see their respective
 documentation.
 (Contributed by Adam Goldschmidt, Senthil Kumaran and Ken Jin in :issue:`42967`.)
 
+The presence of newline or tab characters in parts of a URL allows for some
+forms of attacks. Following the WHATWG specification that updates :rfc:`3986`,
+ASCII newline ``\n``, ``\r`` and tab ``\t`` characters are stripped from the
+URL by the parser in :mod:`urllib.parse` preventing such attacks. The removal
+characters are controlled by a new module level variable
+``urllib.parse._UNSAFE_URL_BYTES_TO_REMOVE``. (See :gh:`88048`)
+
 xml
 ---
 
@@ -2315,3 +2322,43 @@ Removed
 
 * The ``PyThreadState.use_tracing`` member has been removed to optimize Python.
   (Contributed by Mark Shannon in :issue:`43760`.)
+
+
+Notable security feature in 3.10.7
+==================================
+
+Converting between :class:`int` and :class:`str` in bases other than 2
+(binary), 4, 8 (octal), 16 (hexadecimal), or 32 such as base 10 (decimal)
+now raises a :exc:`ValueError` if the number of digits in string form is
+above a limit to avoid potential denial of service attacks due to the
+algorithmic complexity. This is a mitigation for `CVE-2020-10735
+<https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10735>`_.
+This limit can be configured or disabled by environment variable, command
+line flag, or :mod:`sys` APIs. See the :ref:`integer string conversion
+length limitation <int_max_str_digits>` documentation.  The default limit
+is 4300 digits in string form.
+
+Notable security feature in 3.10.8
+==================================
+
+The deprecated :mod:`!mailcap` module now refuses to inject unsafe text
+(filenames, MIME types, parameters) into shell commands. Instead of using such
+text, it will warn and act as if a match was not found (or for test commands,
+as if the test failed).
+(Contributed by Petr Viktorin in :gh:`98966`.)
+
+Notable changes in 3.10.12
+==========================
+
+tarfile
+-------
+
+* The extraction methods in :mod:`tarfile`, and :func:`shutil.unpack_archive`,
+  have a new a *filter* argument that allows limiting tar features than may be
+  surprising or dangerous, such as creating files outside the destination
+  directory.
+  See :ref:`tarfile-extraction-filter` for details.
+  In Python 3.12, use without the *filter* argument will show a
+  :exc:`DeprecationWarning`.
+  In Python 3.14, the default will switch to ``'data'``.
+  (Contributed by Petr Viktorin in :pep:`706`.)
diff --git a/Doc/whatsnew/3.2.rst b/Doc/whatsnew/3.2.rst
index ef4ba0ed89..a94382b5d1 100644
--- a/Doc/whatsnew/3.2.rst
+++ b/Doc/whatsnew/3.2.rst
@@ -344,8 +344,8 @@ aspects that are visible to the programmer:
 
 * The :mod:`importlib.abc` module has been updated with new :term:`abstract base
   classes <abstract base class>` for loading bytecode files.  The obsolete
-  ABCs, :class:`~importlib.abc.PyLoader` and
-  :class:`~importlib.abc.PyPycLoader`, have been deprecated (instructions on how
+  ABCs, :class:`!PyLoader` and
+  :class:`!PyPycLoader`, have been deprecated (instructions on how
   to stay Python 3.1 compatible are included with the documentation).
 
 .. seealso::
@@ -401,7 +401,7 @@ The *native strings* are always of type :class:`str` but are restricted to code
 points between *U+0000* through *U+00FF* which are translatable to bytes using
 *Latin-1* encoding.  These strings are used for the keys and values in the
 environment dictionary and for response headers and statuses in the
-:func:`start_response` function.  They must follow :rfc:`2616` with respect to
+:func:`!start_response` function.  They must follow :rfc:`2616` with respect to
 encoding. That is, they must either be *ISO-8859-1* characters or use
 :rfc:`2047` MIME encoding.
 
@@ -415,8 +415,8 @@ points:
   encoded in utf-8 was using ``h.encode('utf-8')`` now needs to convert from
   bytes to native strings using ``h.encode('utf-8').decode('latin-1')``.
 
-* Values yielded by an application or sent using the :meth:`write` method
-  must be byte strings.  The :func:`start_response` function and environ
+* Values yielded by an application or sent using the :meth:`!write` method
+  must be byte strings.  The :func:`!start_response` function and environ
   must use native strings.  The two cannot be mixed.
 
 For server implementers writing CGI-to-WSGI pathways or other CGI-style
@@ -499,7 +499,7 @@ Some smaller changes made to the core Python language are:
 
 * The :func:`hasattr` function works by calling :func:`getattr` and detecting
   whether an exception is raised.  This technique allows it to detect methods
-  created dynamically by :meth:`__getattr__` or :meth:`__getattribute__` which
+  created dynamically by :meth:`~object.__getattr__` or :meth:`~object.__getattribute__` which
   would otherwise be absent from the class dictionary.  Formerly, *hasattr*
   would catch any exception, possibly masking genuine errors.  Now, *hasattr*
   has been tightened to only catch :exc:`AttributeError` and let other
@@ -620,7 +620,7 @@ Some smaller changes made to the core Python language are:
 
 * :class:`range` objects now support *index* and *count* methods. This is part
   of an effort to make more objects fully implement the
-  :class:`collections.Sequence` :term:`abstract base class`.  As a result, the
+  :class:`collections.Sequence <collections.abc.Sequence>` :term:`abstract base class`.  As a result, the
   language will have a more uniform API.  In addition, :class:`range` objects
   now support slicing and negative indices, even with values larger than
   :data:`sys.maxsize`.  This makes *range* more interoperable with lists::
@@ -720,7 +720,7 @@ format.
 elementtree
 -----------
 
-The :mod:`xml.etree.ElementTree` package and its :mod:`xml.etree.cElementTree`
+The :mod:`xml.etree.ElementTree` package and its :mod:`!xml.etree.cElementTree`
 counterpart have been updated to version 1.3.
 
 Several new and useful functions and methods have been added:
@@ -743,8 +743,8 @@ Several new and useful functions and methods have been added:
 
 Two methods have been deprecated:
 
-* :meth:`xml.etree.ElementTree.getchildren` use ``list(elem)`` instead.
-* :meth:`xml.etree.ElementTree.getiterator` use ``Element.iter`` instead.
+* :meth:`!xml.etree.ElementTree.getchildren` use ``list(elem)`` instead.
+* :meth:`!xml.etree.ElementTree.getiterator` use ``Element.iter`` instead.
 
 For details of the update, see `Introducing ElementTree
 <https://web.archive.org/web/20200703234532/http://effbot.org/zone/elementtree-13-intro.htm>`_
@@ -1008,13 +1008,13 @@ datetime and time
   after 1900.  The new supported year range is from 1000 to 9999 inclusive.
 
 * Whenever a two-digit year is used in a time tuple, the interpretation has been
-  governed by :data:`time.accept2dyear`.  The default is ``True`` which means that
+  governed by :data:`!time.accept2dyear`.  The default is ``True`` which means that
   for a two-digit year, the century is guessed according to the POSIX rules
   governing the ``%y`` strptime format.
 
   Starting with Py3.2, use of the century guessing heuristic will emit a
   :exc:`DeprecationWarning`.  Instead, it is recommended that
-  :data:`time.accept2dyear` be set to ``False`` so that large date ranges
+  :data:`!time.accept2dyear` be set to ``False`` so that large date ranges
   can be used without guesswork::
 
     >>> import time, warnings
@@ -1032,7 +1032,7 @@ datetime and time
     'Fri Jan  1 12:34:56 11'
 
   Several functions now have significantly expanded date ranges.  When
-  :data:`time.accept2dyear` is false, the :func:`time.asctime` function will
+  :data:`!time.accept2dyear` is false, the :func:`time.asctime` function will
   accept any year that fits in a C int, while the :func:`time.mktime` and
   :func:`time.strftime` functions will accept the full range supported by the
   corresponding operating system functions.
@@ -1148,15 +1148,15 @@ for slice notation are well-suited to in-place editing::
 reprlib
 -------
 
-When writing a :meth:`__repr__` method for a custom container, it is easy to
+When writing a :meth:`~object.__repr__` method for a custom container, it is easy to
 forget to handle the case where a member refers back to the container itself.
 Python's builtin objects such as :class:`list` and :class:`set` handle
 self-reference by displaying "..." in the recursive part of the representation
 string.
 
-To help write such :meth:`__repr__` methods, the :mod:`reprlib` module has a new
+To help write such :meth:`~object.__repr__` methods, the :mod:`reprlib` module has a new
 decorator, :func:`~reprlib.recursive_repr`, for detecting recursive calls to
-:meth:`__repr__` and substituting a placeholder string instead::
+:meth:`!__repr__` and substituting a placeholder string instead::
 
         >>> class MyList(list):
         ...     @recursive_repr()
@@ -1308,7 +1308,7 @@ used for the imaginary part of a number:
 >>> sys.hash_info # doctest: +SKIP
 sys.hash_info(width=64, modulus=2305843009213693951, inf=314159, nan=0, imag=1000003)
 
-An early decision to limit the inter-operability of various numeric types has
+An early decision to limit the interoperability of various numeric types has
 been relaxed.  It is still unsupported (and ill-advised) to have implicit
 mixing in arithmetic expressions such as ``Decimal('1.1') + float('1.1')``
 because the latter loses information in the process of constructing the binary
@@ -1336,7 +1336,7 @@ Decimal('1.100000000000000088817841970012523233890533447265625')
 Fraction(2476979795053773, 2251799813685248)
 
 Another useful change for the :mod:`decimal` module is that the
-:attr:`Context.clamp` attribute is now public.  This is useful in creating
+:attr:`Context.clamp <decimal.Context.clamp>` attribute is now public.  This is useful in creating
 contexts that correspond to the decimal interchange formats specified in IEEE
 754 (see :issue:`8540`).
 
@@ -1428,7 +1428,7 @@ before compressing and decompressing:
 Aides and Brian Curtin in :issue:`9962`, :issue:`1675951`, :issue:`7471` and
 :issue:`2846`.)
 
-Also, the :class:`zipfile.ZipExtFile` class was reworked internally to represent
+Also, the :class:`zipfile.ZipExtFile <zipfile.ZipFile.open>` class was reworked internally to represent
 files stored inside an archive.  The new implementation is significantly faster
 and can be wrapped in an :class:`io.BufferedReader` object for more speedups.  It
 also solves an issue where interleaved calls to *read* and *readline* gave the
@@ -1596,7 +1596,7 @@ sqlite3
 
 The :mod:`sqlite3` module was updated to pysqlite version 2.6.0.  It has two new capabilities.
 
-* The :attr:`sqlite3.Connection.in_transit` attribute is true if there is an
+* The :attr:`!sqlite3.Connection.in_transit` attribute is true if there is an
   active transaction for uncommitted changes.
 
 * The :meth:`sqlite3.Connection.enable_load_extension` and
@@ -1643,11 +1643,11 @@ for secure (encrypted, authenticated) internet connections:
   other options. It includes a :meth:`~ssl.SSLContext.wrap_socket` for creating
   an SSL socket from an SSL context.
 
-* A new function, :func:`ssl.match_hostname`, supports server identity
+* A new function, :func:`!ssl.match_hostname`, supports server identity
   verification for higher-level protocols by implementing the rules of HTTPS
   (from :rfc:`2818`) which are also suitable for other protocols.
 
-* The :func:`ssl.wrap_socket` constructor function now takes a *ciphers*
+* The :func:`ssl.wrap_socket() <ssl.SSLContext.wrap_socket>` constructor function now takes a *ciphers*
   argument.  The *ciphers* string lists the allowed encryption algorithms using
   the format described in the `OpenSSL documentation
   <https://www.openssl.org/docs/man1.0.2/man1/ciphers.html#CIPHER-LIST-FORMAT>`__.
@@ -1759,7 +1759,7 @@ names.
   (Contributed by Michael Foord.)
 
 * Experimentation at the interactive prompt is now easier because the
-  :class:`unittest.case.TestCase` class can now be instantiated without
+  :class:`unittest.TestCase` class can now be instantiated without
   arguments:
 
   >>> from unittest import TestCase
@@ -1797,7 +1797,7 @@ names.
 * In addition, the method names in the module have undergone a number of clean-ups.
 
   For example, :meth:`~unittest.TestCase.assertRegex` is the new name for
-  :meth:`~unittest.TestCase.assertRegexpMatches` which was misnamed because the
+  :meth:`!assertRegexpMatches` which was misnamed because the
   test uses :func:`re.search`, not :func:`re.match`.  Other methods using
   regular expressions are now named using short form "Regex" in preference to
   "Regexp" -- this matches the names used in other unittest implementations,
@@ -1812,11 +1812,11 @@ names.
    ===============================   ==============================
    Old Name                          Preferred Name
    ===============================   ==============================
-   :meth:`assert_`                   :meth:`.assertTrue`
-   :meth:`assertEquals`              :meth:`.assertEqual`
-   :meth:`assertNotEquals`           :meth:`.assertNotEqual`
-   :meth:`assertAlmostEquals`        :meth:`.assertAlmostEqual`
-   :meth:`assertNotAlmostEquals`     :meth:`.assertNotAlmostEqual`
+   :meth:`!assert_`                   :meth:`.assertTrue`
+   :meth:`!assertEquals`              :meth:`.assertEqual`
+   :meth:`!assertNotEquals`           :meth:`.assertNotEqual`
+   :meth:`!assertAlmostEquals`        :meth:`.assertAlmostEqual`
+   :meth:`!assertNotAlmostEquals`     :meth:`.assertNotAlmostEqual`
    ===============================   ==============================
 
   Likewise, the ``TestCase.fail*`` methods deprecated in Python 3.1 are expected
@@ -1824,7 +1824,7 @@ names.
 
   (Contributed by Ezio Melotti; :issue:`9424`.)
 
-* The :meth:`~unittest.TestCase.assertDictContainsSubset` method was deprecated
+* The :meth:`!assertDictContainsSubset` method was deprecated
   because it was misimplemented with the arguments in the wrong order.  This
   created hard-to-debug optical illusions where tests like
   ``TestCase().assertDictContainsSubset({'a':1, 'b':2}, {'a':1})`` would fail.
@@ -1997,7 +1997,7 @@ under-the-hood.
 dbm
 ---
 
-All database modules now support the :meth:`get` and :meth:`setdefault` methods.
+All database modules now support the :meth:`!get` and :meth:`!setdefault` methods.
 
 (Suggested by Ray Allen in :issue:`9523`.)
 
@@ -2118,7 +2118,7 @@ The :mod:`pdb` debugger module gained a number of usability improvements:
   :file:`.pdbrc` script file.
 * A :file:`.pdbrc` script file can contain ``continue`` and ``next`` commands
   that continue debugging.
-* The :class:`Pdb` class constructor now accepts a *nosigint* argument.
+* The :class:`~pdb.Pdb` class constructor now accepts a *nosigint* argument.
 * New commands: ``l(list)``, ``ll(long list)`` and ``source`` for
   listing source code.
 * New commands: ``display`` and ``undisplay`` for showing or hiding
@@ -2394,11 +2394,11 @@ A number of small performance enhancements have been added:
 
   (Contributed by Antoine Pitrou; :issue:`3001`.)
 
-* The fast-search algorithm in stringlib is now used by the :meth:`split`,
-  :meth:`rsplit`, :meth:`splitlines` and :meth:`replace` methods on
+* The fast-search algorithm in stringlib is now used by the :meth:`~str.split`,
+  :meth:`~str.rsplit`, :meth:`~str.splitlines` and :meth:`~str.replace` methods on
   :class:`bytes`, :class:`bytearray` and :class:`str` objects. Likewise, the
-  algorithm is also used by :meth:`rfind`, :meth:`rindex`, :meth:`rsplit` and
-  :meth:`rpartition`.
+  algorithm is also used by :meth:`~str.rfind`, :meth:`~str.rindex`, :meth:`~str.rsplit` and
+  :meth:`~str.rpartition`.
 
   (Patch by Florent Xicluna in :issue:`7622` and :issue:`7462`.)
 
@@ -2410,8 +2410,8 @@ A number of small performance enhancements have been added:
 
 There were several other minor optimizations. Set differencing now runs faster
 when one operand is much larger than the other (patch by Andress Bennetts in
-:issue:`8685`).  The :meth:`array.repeat` method has a faster implementation
-(:issue:`1569291` by Alexander Belopolsky). The :class:`BaseHTTPRequestHandler`
+:issue:`8685`).  The :meth:`!array.repeat` method has a faster implementation
+(:issue:`1569291` by Alexander Belopolsky). The :class:`~http.server.BaseHTTPRequestHandler`
 has more efficient buffering (:issue:`3709` by Andrew Schaaf).  The
 :func:`operator.attrgetter` function has been sped-up (:issue:`10160` by
 Christos Georgiou).  And :class:`~configparser.ConfigParser` loads multi-line arguments a bit
@@ -2562,11 +2562,11 @@ Changes to Python's build process and to the C API include:
   (Suggested by Raymond Hettinger and implemented by Benjamin Peterson;
   :issue:`9778`.)
 
-* A new macro :c:macro:`Py_VA_COPY` copies the state of the variable argument
+* A new macro :c:macro:`!Py_VA_COPY` copies the state of the variable argument
   list.  It is equivalent to C99 *va_copy* but available on all Python platforms
   (:issue:`2443`).
 
-* A new C API function :c:func:`PySys_SetArgvEx` allows an embedded interpreter
+* A new C API function :c:func:`!PySys_SetArgvEx` allows an embedded interpreter
   to set :data:`sys.argv` without also modifying :data:`sys.path`
   (:issue:`5753`).
 
@@ -2650,8 +2650,9 @@ require changes to your code:
 * :class:`bytearray` objects can no longer be used as filenames; instead,
   they should be converted to :class:`bytes`.
 
-* The :meth:`array.tostring` and :meth:`array.fromstring` have been renamed to
-  :meth:`array.tobytes` and :meth:`array.frombytes` for clarity.  The old names
+* The :meth:`!array.tostring` and :meth:`!array.fromstring` have been renamed to
+  :meth:`array.tobytes() <array.array.tobytes>` and
+  :meth:`array.frombytes() <array.array.frombytes>` for clarity.  The old names
   have been deprecated. (See :issue:`8990`.)
 
 * ``PyArg_Parse*()`` functions:
@@ -2664,7 +2665,7 @@ require changes to your code:
   instead; the new type has a well-defined interface for passing typing safety
   information and a less complicated signature for calling a destructor.
 
-* The :func:`sys.setfilesystemencoding` function was removed because
+* The :func:`!sys.setfilesystemencoding` function was removed because
   it had a flawed design.
 
 * The :func:`random.seed` function and method now salt string seeds with an
@@ -2672,7 +2673,7 @@ require changes to your code:
   reproduce Python 3.1 sequences, set the *version* argument to *1*,
   ``random.seed(s, version=1)``.
 
-* The previously deprecated :func:`string.maketrans` function has been removed
+* The previously deprecated :func:`!string.maketrans` function has been removed
   in favor of the static methods :meth:`bytes.maketrans` and
   :meth:`bytearray.maketrans`.  This change solves the confusion around which
   types were supported by the :mod:`string` module.  Now, :class:`str`,
@@ -2682,7 +2683,7 @@ require changes to your code:
 
   (Contributed by Georg Brandl; :issue:`5675`.)
 
-* The previously deprecated :func:`contextlib.nested` function has been removed
+* The previously deprecated :func:`!contextlib.nested` function has been removed
   in favor of a plain :keyword:`with` statement which can accept multiple
   context managers.  The latter technique is faster (because it is built-in),
   and it does a better job finalizing multiple context managers when one of them
diff --git a/Doc/whatsnew/3.4.rst b/Doc/whatsnew/3.4.rst
index 4fb4f3e5be..5a629cd78a 100644
--- a/Doc/whatsnew/3.4.rst
+++ b/Doc/whatsnew/3.4.rst
@@ -872,7 +872,7 @@ multiple implementations of an operation that allows it to work with
       PEP written and implemented by ukasz Langa.
 
 :func:`~functools.total_ordering` now supports a return value of
-:const:`NotImplemented` from the underlying comparison function.  (Contributed
+:data:`NotImplemented` from the underlying comparison function.  (Contributed
 by Katie Miller in :issue:`10042`.)
 
 A pure-python version of the :func:`~functools.partial` function is now in the
diff --git a/Doc/whatsnew/3.6.rst b/Doc/whatsnew/3.6.rst
index ed186de0b2..a73bc33f8f 100644
--- a/Doc/whatsnew/3.6.rst
+++ b/Doc/whatsnew/3.6.rst
@@ -1472,6 +1472,10 @@ Server and client-side specific TLS protocols for :class:`~ssl.SSLContext`
 were added.
 (Contributed by Christian Heimes in :issue:`28085`.)
 
+Added :attr:`ssl.SSLContext.post_handshake_auth` to enable and
+:meth:`ssl.SSLSocket.verify_client_post_handshake` to initiate TLS 1.3
+post-handshake authentication.
+(Contributed by Christian Heimes in :gh:`78851`.)
 
 statistics
 ----------
@@ -2063,6 +2067,15 @@ connected to and thus what Python interpreter will be used by the virtual
 environment.  (Contributed by Brett Cannon in :issue:`25154`.)
 
 
+xml
+---
+
+* As mitigation against DTD and external entity retrieval, the
+  :mod:`xml.dom.minidom` and :mod:`xml.sax` modules no longer process
+  external entities by default.
+  (Contributed by Christian Heimes in :gh:`61441`.)
+
+
 Deprecated functions and types of the C API
 -------------------------------------------
 
@@ -2430,9 +2443,13 @@ The :func:`locale.localeconv` function now sets temporarily the ``LC_CTYPE``
 locale to the ``LC_NUMERIC`` locale in some cases.
 (Contributed by Victor Stinner in :issue:`31900`.)
 
+
 Notable changes in Python 3.6.7
 ===============================
 
+:mod:`xml.dom.minidom` and :mod:`xml.sax` modules no longer process
+external entities by default. See also :gh:`61441`.
+
 In 3.6.7 the :mod:`tokenize` module now implicitly emits a ``NEWLINE`` token
 when provided with input that does not have a trailing new line.  This behavior
 now matches what the C tokenizer does internally.
@@ -2460,3 +2477,19 @@ separator key, with ``&`` as the default.  This change also affects
 functions internally. For more details, please see their respective
 documentation.
 (Contributed by Adam Goldschmidt, Senthil Kumaran and Ken Jin in :issue:`42967`.)
+
+Notable changes in Python 3.6.14
+================================
+
+A security fix alters the :class:`ftplib.FTP` behavior to not trust the
+IPv4 address sent from the remote server when setting up a passive data
+channel.  We reuse the ftp server IP address instead.  For unusual code
+requiring the old behavior, set a ``trust_server_pasv_ipv4_address``
+attribute on your FTP instance to ``True``.  (See :gh:`87451`)
+
+The presence of newline or tab characters in parts of a URL allows for some
+forms of attacks. Following the WHATWG specification that updates RFC 3986,
+ASCII newline ``\n``, ``\r`` and tab ``\t`` characters are stripped from the
+URL by the parser :func:`urllib.parse` preventing such attacks. The removal
+characters are controlled by a new module level variable
+``urllib.parse._UNSAFE_URL_BYTES_TO_REMOVE``. (See :gh:`88048`)
diff --git a/Doc/whatsnew/3.7.rst b/Doc/whatsnew/3.7.rst
index a981083e90..21bc797bb1 100644
--- a/Doc/whatsnew/3.7.rst
+++ b/Doc/whatsnew/3.7.rst
@@ -1380,6 +1380,10 @@ Supported protocols are indicated by several new flags, such as
 :data:`~ssl.HAS_TLSv1_1`.
 (Contributed by Christian Heimes in :issue:`32609`.)
 
+Added :attr:`ssl.SSLContext.post_handshake_auth` to enable and
+:meth:`ssl.SSLSocket.verify_client_post_handshake` to initiate TLS 1.3
+post-handshake authentication.
+(Contributed by Christian Heimes in :gh:`78851`.)
 
 string
 ------
@@ -1599,6 +1603,15 @@ at the interactive prompt.  See :ref:`whatsnew37-pep565` for details.
 (Contributed by Nick Coghlan in :issue:`31975`.)
 
 
+xml
+---
+
+As mitigation against DTD and external entity retrieval, the
+:mod:`xml.dom.minidom` and :mod:`xml.sax` modules no longer process
+external entities by default.
+(Contributed by Christian Heimes in :gh:`61441`.)
+
+
 xml.etree
 ---------
 
@@ -2571,3 +2584,34 @@ separator key, with ``&`` as the default.  This change also affects
 functions internally. For more details, please see their respective
 documentation.
 (Contributed by Adam Goldschmidt, Senthil Kumaran and Ken Jin in :issue:`42967`.)
+
+Notable changes in Python 3.7.11
+================================
+
+A security fix alters the :class:`ftplib.FTP` behavior to not trust the
+IPv4 address sent from the remote server when setting up a passive data
+channel.  We reuse the ftp server IP address instead.  For unusual code
+requiring the old behavior, set a ``trust_server_pasv_ipv4_address``
+attribute on your FTP instance to ``True``.  (See :gh:`87451`)
+
+
+The presence of newline or tab characters in parts of a URL allows for some
+forms of attacks. Following the WHATWG specification that updates RFC 3986,
+ASCII newline ``\n``, ``\r`` and tab ``\t`` characters are stripped from the
+URL by the parser :func:`urllib.parse` preventing such attacks. The removal
+characters are controlled by a new module level variable
+``urllib.parse._UNSAFE_URL_BYTES_TO_REMOVE``. (See :gh:`88048`)
+
+Notable security feature in 3.7.14
+==================================
+
+Converting between :class:`int` and :class:`str` in bases other than 2
+(binary), 4, 8 (octal), 16 (hexadecimal), or 32 such as base 10 (decimal)
+now raises a :exc:`ValueError` if the number of digits in string form is
+above a limit to avoid potential denial of service attacks due to the
+algorithmic complexity. This is a mitigation for `CVE-2020-10735
+<https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10735>`_.
+This limit can be configured or disabled by environment variable, command
+line flag, or :mod:`sys` APIs. See the :ref:`integer string conversion
+length limitation <int_max_str_digits>` documentation.  The default limit
+is 4300 digits in string form.
diff --git a/Doc/whatsnew/3.8.rst b/Doc/whatsnew/3.8.rst
index bfe8f2b818..d07ab0d3b6 100644
--- a/Doc/whatsnew/3.8.rst
+++ b/Doc/whatsnew/3.8.rst
@@ -2243,6 +2243,21 @@ details, see the documentation for ``loop.create_datagram_endpoint()``.
 (Contributed by Kyle Stanley, Antoine Pitrou, and Yury Selivanov in
 :issue:`37228`.)
 
+Notable changes in Python 3.8.2
+===============================
+
+Fixed a regression with the ``ignore`` callback of :func:`shutil.copytree`.
+The argument types are now str and List[str] again.
+(Contributed by Manuel Barkhau and Giampaolo Rodola in :gh:`83571`.)
+
+Notable changes in Python 3.8.3
+===============================
+
+The constant values of future flags in the :mod:`__future__` module
+are updated in order to prevent collision with compiler flags. Previously
+``PyCF_ALLOW_TOP_LEVEL_AWAIT`` was clashing with ``CO_FUTURE_DIVISION``.
+(Contributed by Batuhan Taskaya in :gh:`83743`)
+
 Notable changes in Python 3.8.8
 ===============================
 
@@ -2256,9 +2271,55 @@ functions internally. For more details, please see their respective
 documentation.
 (Contributed by Adam Goldschmidt, Senthil Kumaran and Ken Jin in :issue:`42967`.)
 
+Notable changes in Python 3.8.9
+===============================
+
+A security fix alters the :class:`ftplib.FTP` behavior to not trust the
+IPv4 address sent from the remote server when setting up a passive data
+channel.  We reuse the ftp server IP address instead.  For unusual code
+requiring the old behavior, set a ``trust_server_pasv_ipv4_address``
+attribute on your FTP instance to ``True``.  (See :gh:`87451`)
+
+Notable changes in Python 3.8.10
+================================
+
+macOS 11.0 (Big Sur) and Apple Silicon Mac support
+--------------------------------------------------
+
+As of 3.8.10, Python now supports building and running on macOS 11
+(Big Sur) and on Apple Silicon Macs (based on the ``ARM64`` architecture).
+A new universal build variant, ``universal2``, is now available to natively
+support both ``ARM64`` and ``Intel 64`` in one set of executables.
+Note that support for "weaklinking", building binaries targeted for newer
+versions of macOS that will also run correctly on older versions by
+testing at runtime for missing features, is not included in this backport
+from Python 3.9; to support a range of macOS versions, continue to target
+for and build on the oldest version in the range.
+
+(Originally contributed by Ronald Oussoren and Lawrence D'Anna in :gh:`85272`,
+with fixes by FX Coudert and Eli Rykoff, and backported to 3.8 by Maxime Blanger
+and Ned Deily)
+
+Notable changes in Python 3.8.10
+================================
+
+urllib.parse
+------------
+
+The presence of newline or tab characters in parts of a URL allows for some
+forms of attacks. Following the WHATWG specification that updates :rfc:`3986`,
+ASCII newline ``\n``, ``\r`` and tab ``\t`` characters are stripped from the
+URL by the parser in :mod:`urllib.parse` preventing such attacks. The removal
+characters are controlled by a new module level variable
+``urllib.parse._UNSAFE_URL_BYTES_TO_REMOVE``. (See :issue:`43882`)
+
+
 Notable changes in Python 3.8.12
 ================================
 
+Changes in the Python API
+-------------------------
+
 Starting with Python 3.8.12 the :mod:`ipaddress` module no longer accepts
 any leading zeros in IPv4 address strings. Leading zeros are ambiguous and
 interpreted as octal notation by some libraries. For example the legacy
@@ -2268,3 +2329,33 @@ any leading zeros.
 
 (Originally contributed by Christian Heimes in :issue:`36384`, and backported
 to 3.8 by Achraf Merzouki.)
+
+Notable security feature in 3.8.14
+==================================
+
+Converting between :class:`int` and :class:`str` in bases other than 2
+(binary), 4, 8 (octal), 16 (hexadecimal), or 32 such as base 10 (decimal)
+now raises a :exc:`ValueError` if the number of digits in string form is
+above a limit to avoid potential denial of service attacks due to the
+algorithmic complexity. This is a mitigation for `CVE-2020-10735
+<https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10735>`_.
+This limit can be configured or disabled by environment variable, command
+line flag, or :mod:`sys` APIs. See the :ref:`integer string conversion
+length limitation <int_max_str_digits>` documentation.  The default limit
+is 4300 digits in string form.
+
+Notable changes in 3.8.17
+=========================
+
+tarfile
+-------
+
+* The extraction methods in :mod:`tarfile`, and :func:`shutil.unpack_archive`,
+  have a new a *filter* argument that allows limiting tar features than may be
+  surprising or dangerous, such as creating files outside the destination
+  directory.
+  See :ref:`tarfile-extraction-filter` for details.
+  In Python 3.12, use without the *filter* argument will show a
+  :exc:`DeprecationWarning`.
+  In Python 3.14, the default will switch to ``'data'``.
+  (Contributed by Petr Viktorin in :pep:`706`.)
diff --git a/Doc/whatsnew/3.9.rst b/Doc/whatsnew/3.9.rst
index 9f81e8e6b9..d3cdd8271c 100644
--- a/Doc/whatsnew/3.9.rst
+++ b/Doc/whatsnew/3.9.rst
@@ -1126,7 +1126,7 @@ Changes in the Python API
   ``logging.getLogger(__name__)`` in some top-level module called ``'root.py'``.
   (Contributed by Vinay Sajip in :issue:`37742`.)
 
-* Division handling of :class:`~pathlib.PurePath` now returns ``NotImplemented``
+* Division handling of :class:`~pathlib.PurePath` now returns :data:`NotImplemented`
   instead of raising a :exc:`TypeError` when passed something other than an
   instance of ``str`` or :class:`~pathlib.PurePath`.  This allows creating
   compatible classes that don't inherit from those mentioned types.
@@ -1562,3 +1562,55 @@ separator key, with ``&`` as the default.  This change also affects
 functions internally. For more details, please see their respective
 documentation.
 (Contributed by Adam Goldschmidt, Senthil Kumaran and Ken Jin in :issue:`42967`.)
+
+Notable changes in Python 3.9.3
+===============================
+
+A security fix alters the :class:`ftplib.FTP` behavior to not trust the
+IPv4 address sent from the remote server when setting up a passive data
+channel.  We reuse the ftp server IP address instead.  For unusual code
+requiring the old behavior, set a ``trust_server_pasv_ipv4_address``
+attribute on your FTP instance to ``True``.  (See :gh:`87451`)
+
+Notable changes in Python 3.9.5
+===============================
+
+urllib.parse
+------------
+
+The presence of newline or tab characters in parts of a URL allows for some
+forms of attacks. Following the WHATWG specification that updates :rfc:`3986`,
+ASCII newline ``\n``, ``\r`` and tab ``\t`` characters are stripped from the
+URL by the parser in :mod:`urllib.parse` preventing such attacks. The removal
+characters are controlled by a new module level variable
+``urllib.parse._UNSAFE_URL_BYTES_TO_REMOVE``. (See :gh:`88048`)
+
+Notable security feature in 3.9.14
+==================================
+
+Converting between :class:`int` and :class:`str` in bases other than 2
+(binary), 4, 8 (octal), 16 (hexadecimal), or 32 such as base 10 (decimal)
+now raises a :exc:`ValueError` if the number of digits in string form is
+above a limit to avoid potential denial of service attacks due to the
+algorithmic complexity. This is a mitigation for `CVE-2020-10735
+<https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10735>`_.
+This limit can be configured or disabled by environment variable, command
+line flag, or :mod:`sys` APIs. See the :ref:`integer string conversion
+length limitation <int_max_str_digits>` documentation.  The default limit
+is 4300 digits in string form.
+
+Notable changes in 3.9.17
+=========================
+
+tarfile
+-------
+
+* The extraction methods in :mod:`tarfile`, and :func:`shutil.unpack_archive`,
+  have a new a *filter* argument that allows limiting tar features than may be
+  surprising or dangerous, such as creating files outside the destination
+  directory.
+  See :ref:`tarfile-extraction-filter` for details.
+  In Python 3.12, use without the *filter* argument will show a
+  :exc:`DeprecationWarning`.
+  In Python 3.14, the default will switch to ``'data'``.
+  (Contributed by Petr Viktorin in :pep:`706`.)
diff --git a/Grammar/python.gram b/Grammar/python.gram
index a4fd3f27db..19dd92de89 100644
--- a/Grammar/python.gram
+++ b/Grammar/python.gram
@@ -392,7 +392,7 @@ for_stmt[stmt_ty]:
 with_stmt[stmt_ty]:
     | invalid_with_stmt_indent
     | 'with' '(' a[asdl_withitem_seq*]=','.with_item+ ','? ')' ':' b=block {
-        CHECK_VERSION(stmt_ty, 9, "Parenthesized context managers are", _PyAST_With(a, b, NULL, EXTRA)) }
+        _PyAST_With(a, b, NULL, EXTRA) }
     | 'with' a[asdl_withitem_seq*]=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
         _PyAST_With(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }
     | ASYNC 'with' '(' a[asdl_withitem_seq*]=','.with_item+ ','? ')' ':' b=block {
diff --git a/Include/Python.h b/Include/Python.h
index 52a7aac6ba..5eddda6336 100644
--- a/Include/Python.h
+++ b/Include/Python.h
@@ -49,6 +49,9 @@
 #include "bytearrayobject.h"
 #include "bytesobject.h"
 #include "unicodeobject.h"
+#include "cpython/initconfig.h"
+#include "pystate.h"
+#include "pyerrors.h"
 #include "longobject.h"
 #include "cpython/longintrepr.h"
 #include "boolobject.h"
@@ -74,8 +77,6 @@
 #include "sliceobject.h"
 #include "cpython/cellobject.h"
 #include "iterobject.h"
-#include "cpython/initconfig.h"
-#include "pystate.h"
 #include "cpython/genobject.h"
 #include "descrobject.h"
 #include "genericaliasobject.h"
@@ -85,7 +86,6 @@
 #include "cpython/picklebufobject.h"
 #include "cpython/pytime.h"
 #include "codecs.h"
-#include "pyerrors.h"
 #include "pythread.h"
 #include "cpython/context.h"
 #include "modsupport.h"
diff --git a/Include/cpython/code.h b/Include/cpython/code.h
index 03834b20c3..311cffec11 100644
--- a/Include/cpython/code.h
+++ b/Include/cpython/code.h
@@ -75,7 +75,7 @@ typedef struct {
     PyObject *_co_freevars;
 } _PyCoCached;
 
-/* Ancilliary data structure used for instrumentation.
+/* Ancillary data structure used for instrumentation.
    Line instrumentation creates an array of
    these. One entry per code unit.*/
 typedef struct {
diff --git a/Include/cpython/longintrepr.h b/Include/cpython/longintrepr.h
index 692c69ba76..78ac79a7cb 100644
--- a/Include/cpython/longintrepr.h
+++ b/Include/cpython/longintrepr.h
@@ -116,9 +116,10 @@ _PyLong_IsCompact(const PyLongObject* op) {
 static inline Py_ssize_t
 _PyLong_CompactValue(const PyLongObject *op)
 {
+    Py_ssize_t sign;
     assert(PyType_HasFeature((op)->ob_base.ob_type, Py_TPFLAGS_LONG_SUBCLASS));
     assert(PyUnstable_Long_IsCompact(op));
-    Py_ssize_t sign = 1 - (op->long_value.lv_tag & _PyLong_SIGN_MASK);
+    sign = 1 - (op->long_value.lv_tag & _PyLong_SIGN_MASK);
     return sign * (Py_ssize_t)op->long_value.ob_digit[0];
 }
 
diff --git a/Include/cpython/pystate.h b/Include/cpython/pystate.h
index 628f2e0996..95fad89378 100644
--- a/Include/cpython/pystate.h
+++ b/Include/cpython/pystate.h
@@ -251,12 +251,24 @@ struct _ts {
 /* WASI has limited call stack. Python's recursion limit depends on code
    layout, optimization, and WASI runtime. Wasmtime can handle about 700
    recursions, sometimes less. 500 is a more conservative limit. */
-#ifndef C_RECURSION_LIMIT
-#  ifdef __wasi__
+#ifdef Py_DEBUG
+#  if defined(__wasi__)
+#    define C_RECURSION_LIMIT 150
+#  else
+#    define C_RECURSION_LIMIT 500
+#  endif
+#else
+#  if defined(__wasi__)
 #    define C_RECURSION_LIMIT 500
+#  elif defined(__s390x__)
+#    define C_RECURSION_LIMIT 800
+#  elif defined(_WIN32)
+#    define C_RECURSION_LIMIT 3000
+#  elif defined(_Py_ADDRESS_SANITIZER)
+#    define C_RECURSION_LIMIT 4000
 #  else
-    // This value is duplicated in Lib/test/support/__init__.py
-#    define C_RECURSION_LIMIT 1500
+     // This value is duplicated in Lib/test/support/__init__.py
+#    define C_RECURSION_LIMIT 10000
 #  endif
 #endif
 
diff --git a/Include/internal/pycore_instruments.h b/Include/internal/pycore_instruments.h
index 87f70d2dc0..b8591563d7 100644
--- a/Include/internal/pycore_instruments.h
+++ b/Include/internal/pycore_instruments.h
@@ -40,7 +40,7 @@ extern "C" {
 #define PY_MONITORING_EVENT_RERAISE 14
 
 
-/* Ancilliary events */
+/* Ancillary events */
 
 #define PY_MONITORING_EVENT_C_RETURN 15
 #define PY_MONITORING_EVENT_C_RAISE 16
diff --git a/Include/internal/pycore_symtable.h b/Include/internal/pycore_symtable.h
index c8e0578a23..b2fef17720 100644
--- a/Include/internal/pycore_symtable.h
+++ b/Include/internal/pycore_symtable.h
@@ -109,18 +109,18 @@ extern PyObject* _Py_Mangle(PyObject *p, PyObject *name);
 
 /* Flags for def-use information */
 
-#define DEF_GLOBAL 1           /* global stmt */
-#define DEF_LOCAL 2            /* assignment in code block */
-#define DEF_PARAM 2<<1         /* formal parameter */
-#define DEF_NONLOCAL 2<<2      /* nonlocal stmt */
-#define USE 2<<3               /* name is used */
-#define DEF_FREE 2<<4          /* name used but not defined in nested block */
-#define DEF_FREE_CLASS 2<<5    /* free variable from class's method */
-#define DEF_IMPORT 2<<6        /* assignment occurred via import */
-#define DEF_ANNOT 2<<7         /* this name is annotated */
-#define DEF_COMP_ITER 2<<8     /* this name is a comprehension iteration variable */
-#define DEF_TYPE_PARAM 2<<9    /* this name is a type parameter */
-#define DEF_COMP_CELL 2<<10    /* this name is a cell in an inlined comprehension */
+#define DEF_GLOBAL 1             /* global stmt */
+#define DEF_LOCAL 2              /* assignment in code block */
+#define DEF_PARAM (2<<1)         /* formal parameter */
+#define DEF_NONLOCAL (2<<2)      /* nonlocal stmt */
+#define USE (2<<3)               /* name is used */
+#define DEF_FREE (2<<4)          /* name used but not defined in nested block */
+#define DEF_FREE_CLASS (2<<5)    /* free variable from class's method */
+#define DEF_IMPORT (2<<6)        /* assignment occurred via import */
+#define DEF_ANNOT (2<<7)         /* this name is annotated */
+#define DEF_COMP_ITER (2<<8)     /* this name is a comprehension iteration variable */
+#define DEF_TYPE_PARAM (2<<9)    /* this name is a type parameter */
+#define DEF_COMP_CELL (2<<10)    /* this name is a cell in an inlined comprehension */
 
 #define DEF_BOUND (DEF_LOCAL | DEF_PARAM | DEF_IMPORT)
 
diff --git a/Include/longobject.h b/Include/longobject.h
index e090dd024a..c8b7497353 100644
--- a/Include/longobject.h
+++ b/Include/longobject.h
@@ -34,7 +34,24 @@ PyAPI_FUNC(PyObject *) PyLong_GetInfo(void);
 #if !defined(SIZEOF_PID_T) || SIZEOF_PID_T == SIZEOF_INT
 #define _Py_PARSE_PID "i"
 #define PyLong_FromPid PyLong_FromLong
-#define PyLong_AsPid PyLong_AsLong
+# ifndef Py_LIMITED_API
+#   define PyLong_AsPid _PyLong_AsInt
+# elif SIZEOF_INT == SIZEOF_LONG
+#   define PyLong_AsPid PyLong_AsLong
+# else
+static inline int
+PyLong_AsPid(PyObject *obj)
+{
+    int overflow;
+    long result = PyLong_AsLongAndOverflow(obj, &overflow);
+    if (overflow || result > INT_MAX || result < INT_MIN) {
+        PyErr_SetString(PyExc_OverflowError,
+                        "Python int too large to convert to C int");
+        return -1;
+    }
+    return (int)result;
+}
+# endif
 #elif SIZEOF_PID_T == SIZEOF_LONG
 #define _Py_PARSE_PID "l"
 #define PyLong_FromPid PyLong_FromLong
diff --git a/Include/object.h b/Include/object.h
index 5c30c77bc2..0d94cf8255 100644
--- a/Include/object.h
+++ b/Include/object.h
@@ -230,8 +230,7 @@ PyAPI_DATA(PyTypeObject) PyBool_Type;
 static inline Py_ssize_t Py_SIZE(PyObject *ob) {
     assert(ob->ob_type != &PyLong_Type);
     assert(ob->ob_type != &PyBool_Type);
-    PyVarObject *var_ob = _PyVarObject_CAST(ob);
-    return var_ob->ob_size;
+    return  _PyVarObject_CAST(ob)->ob_size;
 }
 #if !defined(Py_LIMITED_API) || Py_LIMITED_API+0 < 0x030b0000
 #  define Py_SIZE(ob) Py_SIZE(_PyObject_CAST(ob))
diff --git a/Include/patchlevel.h b/Include/patchlevel.h
index e7316df367..7fb7fe1ad3 100644
--- a/Include/patchlevel.h
+++ b/Include/patchlevel.h
@@ -23,7 +23,7 @@
 #define PY_RELEASE_SERIAL       0
 
 /* Version as a string */
-#define PY_VERSION              "3.12.2"
+#define PY_VERSION              "3.12.2+"
 /*--end constants--*/
 
 /* Version as a single 4-byte hex number, e.g. 0x010502B2 == 1.5.2b2.
diff --git a/Include/pyexpat.h b/Include/pyexpat.h
index 07020b5dc9..9824d099c3 100644
--- a/Include/pyexpat.h
+++ b/Include/pyexpat.h
@@ -48,8 +48,10 @@ struct PyExpat_CAPI
     enum XML_Status (*SetEncoding)(XML_Parser parser, const XML_Char *encoding);
     int (*DefaultUnknownEncodingHandler)(
         void *encodingHandlerData, const XML_Char *name, XML_Encoding *info);
-    /* might be none for expat < 2.1.0 */
+    /* might be NULL for expat < 2.1.0 */
     int (*SetHashSalt)(XML_Parser parser, unsigned long hash_salt);
+    /* might be NULL for expat < 2.6.0 */
+    XML_Bool (*SetReparseDeferralEnabled)(XML_Parser parser, XML_Bool enabled);
     /* always add new stuff to the end! */
 };
 
diff --git a/Include/pyport.h b/Include/pyport.h
index 35eca7234c..30b9c8ebc4 100644
--- a/Include/pyport.h
+++ b/Include/pyport.h
@@ -748,6 +748,11 @@ extern char * _getpty(int *, int, mode_t, int);
 #      define _Py_ADDRESS_SANITIZER
 #    endif
 #  endif
+#  if __has_feature(thread_sanitizer)
+#    if !defined(_Py_THREAD_SANITIZER)
+#      define _Py_THREAD_SANITIZER
+#    endif
+#  endif
 #elif defined(__GNUC__)
 #  if defined(__SANITIZE_ADDRESS__)
 #    define _Py_ADDRESS_SANITIZER
diff --git a/Lib/_pyio.py b/Lib/_pyio.py
index 9641d43101..687076fbe9 100644
--- a/Lib/_pyio.py
+++ b/Lib/_pyio.py
@@ -1209,7 +1209,8 @@ def _readinto(self, buf, read1):
         return written
 
     def tell(self):
-        return _BufferedIOMixin.tell(self) - len(self._read_buf) + self._read_pos
+        # GH-95782: Keep return value non-negative
+        return max(_BufferedIOMixin.tell(self) - len(self._read_buf) + self._read_pos, 0)
 
     def seek(self, pos, whence=0):
         if whence not in valid_seek_flags:
diff --git a/Lib/argparse.py b/Lib/argparse.py
index 484a1efde4..120cb6c845 100644
--- a/Lib/argparse.py
+++ b/Lib/argparse.py
@@ -225,7 +225,8 @@ def format_help(self):
             # add the heading if the section was non-empty
             if self.heading is not SUPPRESS and self.heading is not None:
                 current_indent = self.formatter._current_indent
-                heading = '%*s%s:\n' % (current_indent, '', self.heading)
+                heading_text = _('%(heading)s:') % dict(heading=self.heading)
+                heading = '%*s%s\n' % (current_indent, '', heading_text)
             else:
                 heading = ''
 
@@ -415,6 +416,8 @@ def _format_actions_usage(self, actions, groups):
                             suppressed_actions_count += 1
 
                     exposed_actions_count = group_action_count - suppressed_actions_count
+                    if not exposed_actions_count:
+                        continue
 
                     if not group.required:
                         if start in inserts:
@@ -720,7 +723,7 @@ def _get_help_string(self, action):
             if action.default is not SUPPRESS:
                 defaulting_nargs = [OPTIONAL, ZERO_OR_MORE]
                 if action.option_strings or action.nargs in defaulting_nargs:
-                    help += ' (default: %(default)s)'
+                    help += _(' (default: %(default)s)')
         return help
 
 
@@ -1149,7 +1152,9 @@ def __init__(self,
                  version=None,
                  dest=SUPPRESS,
                  default=SUPPRESS,
-                 help="show program's version number and exit"):
+                 help=None):
+        if help is None:
+            help = _("show program's version number and exit")
         super(_VersionAction, self).__init__(
             option_strings=option_strings,
             dest=dest,
@@ -2004,7 +2009,7 @@ def consume_optional(start_index):
 
             # get the optional identified at this index
             option_tuple = option_string_indices[start_index]
-            action, option_string, explicit_arg = option_tuple
+            action, option_string, sep, explicit_arg = option_tuple
 
             # identify additional optionals in the same arg string
             # (e.g. -xyz is the same as -x -y -z if no args are required)
@@ -2031,18 +2036,27 @@ def consume_optional(start_index):
                         and option_string[1] not in chars
                         and explicit_arg != ''
                     ):
+                        if sep or explicit_arg[0] in chars:
+                            msg = _('ignored explicit argument %r')
+                            raise ArgumentError(action, msg % explicit_arg)
                         action_tuples.append((action, [], option_string))
                         char = option_string[0]
                         option_string = char + explicit_arg[0]
-                        new_explicit_arg = explicit_arg[1:] or None
                         optionals_map = self._option_string_actions
                         if option_string in optionals_map:
                             action = optionals_map[option_string]
-                            explicit_arg = new_explicit_arg
+                            explicit_arg = explicit_arg[1:]
+                            if not explicit_arg:
+                                sep = explicit_arg = None
+                            elif explicit_arg[0] == '=':
+                                sep = '='
+                                explicit_arg = explicit_arg[1:]
+                            else:
+                                sep = ''
                         else:
-                            msg = _('ignored explicit argument %r')
-                            raise ArgumentError(action, msg % explicit_arg)
-
+                            extras.append(char + explicit_arg)
+                            stop = start_index + 1
+                            break
                     # if the action expect exactly one argument, we've
                     # successfully matched the option; exit the loop
                     elif arg_count == 1:
@@ -2262,18 +2276,17 @@ def _parse_optional(self, arg_string):
         # if the option string is present in the parser, return the action
         if arg_string in self._option_string_actions:
             action = self._option_string_actions[arg_string]
-            return action, arg_string, None
+            return action, arg_string, None, None
 
         # if it's just a single character, it was meant to be positional
         if len(arg_string) == 1:
             return None
 
         # if the option string before the "=" is present, return the action
-        if '=' in arg_string:
-            option_string, explicit_arg = arg_string.split('=', 1)
-            if option_string in self._option_string_actions:
-                action = self._option_string_actions[option_string]
-                return action, option_string, explicit_arg
+        option_string, sep, explicit_arg = arg_string.partition('=')
+        if sep and option_string in self._option_string_actions:
+            action = self._option_string_actions[option_string]
+            return action, option_string, sep, explicit_arg
 
         # search through all possible prefixes of the option string
         # and all actions in the parser for possible interpretations
@@ -2282,7 +2295,7 @@ def _parse_optional(self, arg_string):
         # if multiple actions match, the option string was ambiguous
         if len(option_tuples) > 1:
             options = ', '.join([option_string
-                for action, option_string, explicit_arg in option_tuples])
+                for action, option_string, sep, explicit_arg in option_tuples])
             args = {'option': arg_string, 'matches': options}
             msg = _('ambiguous option: %(option)s could match %(matches)s')
             self.error(msg % args)
@@ -2306,7 +2319,7 @@ def _parse_optional(self, arg_string):
 
         # it was meant to be an optional but there is no such option
         # in this parser (though it might be a valid option in a subparser)
-        return None, arg_string, None
+        return None, arg_string, None, None
 
     def _get_option_tuples(self, option_string):
         result = []
@@ -2316,15 +2329,13 @@ def _get_option_tuples(self, option_string):
         chars = self.prefix_chars
         if option_string[0] in chars and option_string[1] in chars:
             if self.allow_abbrev:
-                if '=' in option_string:
-                    option_prefix, explicit_arg = option_string.split('=', 1)
-                else:
-                    option_prefix = option_string
-                    explicit_arg = None
+                option_prefix, sep, explicit_arg = option_string.partition('=')
+                if not sep:
+                    sep = explicit_arg = None
                 for option_string in self._option_string_actions:
                     if option_string.startswith(option_prefix):
                         action = self._option_string_actions[option_string]
-                        tup = action, option_string, explicit_arg
+                        tup = action, option_string, sep, explicit_arg
                         result.append(tup)
 
         # single character options can be concatenated with their arguments
@@ -2332,18 +2343,17 @@ def _get_option_tuples(self, option_string):
         # separate
         elif option_string[0] in chars and option_string[1] not in chars:
             option_prefix = option_string
-            explicit_arg = None
             short_option_prefix = option_string[:2]
             short_explicit_arg = option_string[2:]
 
             for option_string in self._option_string_actions:
                 if option_string == short_option_prefix:
                     action = self._option_string_actions[option_string]
-                    tup = action, option_string, short_explicit_arg
+                    tup = action, option_string, '', short_explicit_arg
                     result.append(tup)
                 elif option_string.startswith(option_prefix):
                     action = self._option_string_actions[option_string]
-                    tup = action, option_string, explicit_arg
+                    tup = action, option_string, None, None
                     result.append(tup)
 
         # shouldn't ever get here
diff --git a/Lib/ast.py b/Lib/ast.py
index de940d2e9c..b0995fa7f1 100644
--- a/Lib/ast.py
+++ b/Lib/ast.py
@@ -1268,14 +1268,18 @@ def visit_JoinedStr(self, node):
         quote_type = quote_types[0]
         self.write(f"{quote_type}{value}{quote_type}")
 
-    def _write_fstring_inner(self, node, scape_newlines=False):
+    def _write_fstring_inner(self, node, is_format_spec=False):
         if isinstance(node, JoinedStr):
             # for both the f-string itself, and format_spec
             for value in node.values:
-                self._write_fstring_inner(value, scape_newlines=scape_newlines)
+                self._write_fstring_inner(value, is_format_spec=is_format_spec)
         elif isinstance(node, Constant) and isinstance(node.value, str):
             value = node.value.replace("{", "{{").replace("}", "}}")
-            if scape_newlines:
+
+            if is_format_spec:
+                value = value.replace("\\", "\\\\")
+                value = value.replace("'", "\\'")
+                value = value.replace('"', '\\"')
                 value = value.replace("\n", "\\n")
             self.write(value)
         elif isinstance(node, FormattedValue):
@@ -1299,10 +1303,7 @@ def unparse_inner(inner):
                 self.write(f"!{chr(node.conversion)}")
             if node.format_spec:
                 self.write(":")
-                self._write_fstring_inner(
-                    node.format_spec,
-                    scape_newlines=True
-                )
+                self._write_fstring_inner(node.format_spec, is_format_spec=True)
 
     def visit_Name(self, node):
         self.write(node.id)
diff --git a/Lib/asyncio/base_events.py b/Lib/asyncio/base_events.py
index c16c445bde..29eff0499c 100644
--- a/Lib/asyncio/base_events.py
+++ b/Lib/asyncio/base_events.py
@@ -45,6 +45,7 @@
 from . import sslproto
 from . import staggered
 from . import tasks
+from . import timeouts
 from . import transports
 from . import trsock
 from .log import logger
@@ -596,23 +597,24 @@ async def shutdown_default_executor(self, timeout=None):
         thread = threading.Thread(target=self._do_shutdown, args=(future,))
         thread.start()
         try:
-            await future
-        finally:
-            thread.join(timeout)
-
-        if thread.is_alive():
+            async with timeouts.timeout(timeout):
+                await future
+        except TimeoutError:
             warnings.warn("The executor did not finishing joining "
-                             f"its threads within {timeout} seconds.",
-                             RuntimeWarning, stacklevel=2)
+                          f"its threads within {timeout} seconds.",
+                          RuntimeWarning, stacklevel=2)
             self._default_executor.shutdown(wait=False)
+        else:
+            thread.join()
 
     def _do_shutdown(self, future):
         try:
             self._default_executor.shutdown(wait=True)
             if not self.is_closed():
-                self.call_soon_threadsafe(future.set_result, None)
+                self.call_soon_threadsafe(futures._set_result_unless_cancelled,
+                                          future, None)
         except Exception as ex:
-            if not self.is_closed():
+            if not self.is_closed() and not future.cancelled():
                 self.call_soon_threadsafe(future.set_exception, ex)
 
     def _check_running(self):
diff --git a/Lib/asyncio/tasks.py b/Lib/asyncio/tasks.py
index 65f2a6ef80..0b22e28d8e 100644
--- a/Lib/asyncio/tasks.py
+++ b/Lib/asyncio/tasks.py
@@ -480,7 +480,7 @@ async def wait_for(fut, timeout):
 
     If the wait is cancelled, the task is also cancelled.
 
-    If the task supresses the cancellation and returns a value instead,
+    If the task suppresses the cancellation and returns a value instead,
     that value is returned.
 
     This function is a coroutine.
diff --git a/Lib/asyncio/windows_events.py b/Lib/asyncio/windows_events.py
index c9a5fb841c..cb613451a5 100644
--- a/Lib/asyncio/windows_events.py
+++ b/Lib/asyncio/windows_events.py
@@ -8,6 +8,7 @@
 import _overlapped
 import _winapi
 import errno
+from functools import partial
 import math
 import msvcrt
 import socket
@@ -323,13 +324,13 @@ def run_forever(self):
             if self._self_reading_future is not None:
                 ov = self._self_reading_future._ov
                 self._self_reading_future.cancel()
-                # self_reading_future was just cancelled so if it hasn't been
-                # finished yet, it never will be (it's possible that it has
-                # already finished and its callback is waiting in the queue,
-                # where it could still happen if the event loop is restarted).
-                # Unregister it otherwise IocpProactor.close will wait for it
-                # forever
-                if ov is not None:
+                # self_reading_future always uses IOCP, so even though it's
+                # been cancelled, we need to make sure that the IOCP message
+                # is received so that the kernel is not holding on to the
+                # memory, possibly causing memory corruption later. Only
+                # unregister it if IO is complete in all respects. Otherwise
+                # we need another _poll() later to complete the IO.
+                if ov is not None and not ov.pending:
                     self._proactor._unregister(ov)
                 self._self_reading_future = None
 
@@ -466,6 +467,18 @@ def finish_socket_func(trans, key, ov):
             else:
                 raise
 
+    @classmethod
+    def _finish_recvfrom(cls, trans, key, ov, *, empty_result):
+        try:
+            return cls.finish_socket_func(trans, key, ov)
+        except OSError as exc:
+            # WSARecvFrom will report ERROR_PORT_UNREACHABLE when the same
+            # socket is used to send to an address that is not listening.
+            if exc.winerror == _overlapped.ERROR_PORT_UNREACHABLE:
+                return empty_result, None
+            else:
+                raise
+
     def recv(self, conn, nbytes, flags=0):
         self._register_with_iocp(conn)
         ov = _overlapped.Overlapped(NULL)
@@ -500,7 +513,8 @@ def recvfrom(self, conn, nbytes, flags=0):
         except BrokenPipeError:
             return self._result((b'', None))
 
-        return self._register(ov, conn, self.finish_socket_func)
+        return self._register(ov, conn, partial(self._finish_recvfrom,
+                                                empty_result=b''))
 
     def recvfrom_into(self, conn, buf, flags=0):
         self._register_with_iocp(conn)
@@ -510,17 +524,8 @@ def recvfrom_into(self, conn, buf, flags=0):
         except BrokenPipeError:
             return self._result((0, None))
 
-        def finish_recv(trans, key, ov):
-            try:
-                return ov.getresult()
-            except OSError as exc:
-                if exc.winerror in (_overlapped.ERROR_NETNAME_DELETED,
-                                    _overlapped.ERROR_OPERATION_ABORTED):
-                    raise ConnectionResetError(*exc.args)
-                else:
-                    raise
-
-        return self._register(ov, conn, finish_recv)
+        return self._register(ov, conn, partial(self._finish_recvfrom,
+                                                empty_result=0))
 
     def sendto(self, conn, buf, flags=0, addr=None):
         self._register_with_iocp(conn)
diff --git a/Lib/collections/__init__.py b/Lib/collections/__init__.py
index 8652dc8a4e..5f000b5f2c 100644
--- a/Lib/collections/__init__.py
+++ b/Lib/collections/__init__.py
@@ -638,7 +638,8 @@ def elements(self):
         >>> sorted(c.elements())
         ['A', 'A', 'B', 'B', 'C', 'C']
 
-        # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
+        Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
+
         >>> import math
         >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})
         >>> math.prod(prime_factors.elements())
@@ -679,7 +680,7 @@ def update(self, iterable=None, /, **kwds):
 
         '''
         # The regular dict.update() operation makes no sense here because the
-        # replace behavior results in the some of original untouched counts
+        # replace behavior results in some of the original untouched counts
         # being mixed-in with all of the other counts for a mismash that
         # doesn't have a straight-forward interpretation in most counting
         # contexts.  Instead, we implement straight-addition.  Both the inputs
diff --git a/Lib/configparser.py b/Lib/configparser.py
index e8aae21794..f96704eb45 100644
--- a/Lib/configparser.py
+++ b/Lib/configparser.py
@@ -995,100 +995,102 @@ def _read(self, fp, fpname):
         lineno = 0
         indent_level = 0
         e = None                              # None, or an exception
-        for lineno, line in enumerate(fp, start=1):
-            comment_start = sys.maxsize
-            # strip inline comments
-            inline_prefixes = {p: -1 for p in self._inline_comment_prefixes}
-            while comment_start == sys.maxsize and inline_prefixes:
-                next_prefixes = {}
-                for prefix, index in inline_prefixes.items():
-                    index = line.find(prefix, index+1)
-                    if index == -1:
-                        continue
-                    next_prefixes[prefix] = index
-                    if index == 0 or (index > 0 and line[index-1].isspace()):
-                        comment_start = min(comment_start, index)
-                inline_prefixes = next_prefixes
-            # strip full line comments
-            for prefix in self._comment_prefixes:
-                if line.strip().startswith(prefix):
-                    comment_start = 0
-                    break
-            if comment_start == sys.maxsize:
-                comment_start = None
-            value = line[:comment_start].strip()
-            if not value:
-                if self._empty_lines_in_values:
-                    # add empty line to the value, but only if there was no
-                    # comment on the line
-                    if (comment_start is None and
-                        cursect is not None and
-                        optname and
-                        cursect[optname] is not None):
-                        cursect[optname].append('') # newlines added at join
-                else:
-                    # empty line marks end of value
-                    indent_level = sys.maxsize
-                continue
-            # continuation line?
-            first_nonspace = self.NONSPACECRE.search(line)
-            cur_indent_level = first_nonspace.start() if first_nonspace else 0
-            if (cursect is not None and optname and
-                cur_indent_level > indent_level):
-                cursect[optname].append(value)
-            # a section header or option header?
-            else:
-                indent_level = cur_indent_level
-                # is it a section header?
-                mo = self.SECTCRE.match(value)
-                if mo:
-                    sectname = mo.group('header')
-                    if sectname in self._sections:
-                        if self._strict and sectname in elements_added:
-                            raise DuplicateSectionError(sectname, fpname,
-                                                        lineno)
-                        cursect = self._sections[sectname]
-                        elements_added.add(sectname)
-                    elif sectname == self.default_section:
-                        cursect = self._defaults
+        try:
+            for lineno, line in enumerate(fp, start=1):
+                comment_start = sys.maxsize
+                # strip inline comments
+                inline_prefixes = {p: -1 for p in self._inline_comment_prefixes}
+                while comment_start == sys.maxsize and inline_prefixes:
+                    next_prefixes = {}
+                    for prefix, index in inline_prefixes.items():
+                        index = line.find(prefix, index+1)
+                        if index == -1:
+                            continue
+                        next_prefixes[prefix] = index
+                        if index == 0 or (index > 0 and line[index-1].isspace()):
+                            comment_start = min(comment_start, index)
+                    inline_prefixes = next_prefixes
+                # strip full line comments
+                for prefix in self._comment_prefixes:
+                    if line.strip().startswith(prefix):
+                        comment_start = 0
+                        break
+                if comment_start == sys.maxsize:
+                    comment_start = None
+                value = line[:comment_start].strip()
+                if not value:
+                    if self._empty_lines_in_values:
+                        # add empty line to the value, but only if there was no
+                        # comment on the line
+                        if (comment_start is None and
+                            cursect is not None and
+                            optname and
+                            cursect[optname] is not None):
+                            cursect[optname].append('') # newlines added at join
                     else:
-                        cursect = self._dict()
-                        self._sections[sectname] = cursect
-                        self._proxies[sectname] = SectionProxy(self, sectname)
-                        elements_added.add(sectname)
-                    # So sections can't start with a continuation line
-                    optname = None
-                # no section header in the file?
-                elif cursect is None:
-                    raise MissingSectionHeaderError(fpname, lineno, line)
-                # an option line?
+                        # empty line marks end of value
+                        indent_level = sys.maxsize
+                    continue
+                # continuation line?
+                first_nonspace = self.NONSPACECRE.search(line)
+                cur_indent_level = first_nonspace.start() if first_nonspace else 0
+                if (cursect is not None and optname and
+                    cur_indent_level > indent_level):
+                    cursect[optname].append(value)
+                # a section header or option header?
                 else:
-                    mo = self._optcre.match(value)
+                    indent_level = cur_indent_level
+                    # is it a section header?
+                    mo = self.SECTCRE.match(value)
                     if mo:
-                        optname, vi, optval = mo.group('option', 'vi', 'value')
-                        if not optname:
-                            e = self._handle_error(e, fpname, lineno, line)
-                        optname = self.optionxform(optname.rstrip())
-                        if (self._strict and
-                            (sectname, optname) in elements_added):
-                            raise DuplicateOptionError(sectname, optname,
-                                                       fpname, lineno)
-                        elements_added.add((sectname, optname))
-                        # This check is fine because the OPTCRE cannot
-                        # match if it would set optval to None
-                        if optval is not None:
-                            optval = optval.strip()
-                            cursect[optname] = [optval]
+                        sectname = mo.group('header')
+                        if sectname in self._sections:
+                            if self._strict and sectname in elements_added:
+                                raise DuplicateSectionError(sectname, fpname,
+                                                            lineno)
+                            cursect = self._sections[sectname]
+                            elements_added.add(sectname)
+                        elif sectname == self.default_section:
+                            cursect = self._defaults
                         else:
-                            # valueless option handling
-                            cursect[optname] = None
+                            cursect = self._dict()
+                            self._sections[sectname] = cursect
+                            self._proxies[sectname] = SectionProxy(self, sectname)
+                            elements_added.add(sectname)
+                        # So sections can't start with a continuation line
+                        optname = None
+                    # no section header in the file?
+                    elif cursect is None:
+                        raise MissingSectionHeaderError(fpname, lineno, line)
+                    # an option line?
                     else:
-                        # a non-fatal parsing error occurred. set up the
-                        # exception but keep going. the exception will be
-                        # raised at the end of the file and will contain a
-                        # list of all bogus lines
-                        e = self._handle_error(e, fpname, lineno, line)
-        self._join_multiline_values()
+                        mo = self._optcre.match(value)
+                        if mo:
+                            optname, vi, optval = mo.group('option', 'vi', 'value')
+                            if not optname:
+                                e = self._handle_error(e, fpname, lineno, line)
+                            optname = self.optionxform(optname.rstrip())
+                            if (self._strict and
+                                (sectname, optname) in elements_added):
+                                raise DuplicateOptionError(sectname, optname,
+                                                           fpname, lineno)
+                            elements_added.add((sectname, optname))
+                            # This check is fine because the OPTCRE cannot
+                            # match if it would set optval to None
+                            if optval is not None:
+                                optval = optval.strip()
+                                cursect[optname] = [optval]
+                            else:
+                                # valueless option handling
+                                cursect[optname] = None
+                        else:
+                            # a non-fatal parsing error occurred. set up the
+                            # exception but keep going. the exception will be
+                            # raised at the end of the file and will contain a
+                            # list of all bogus lines
+                            e = self._handle_error(e, fpname, lineno, line)
+        finally:
+            self._join_multiline_values()
         # if any parsing errors occurred, raise an exception
         if e:
             raise e
diff --git a/Lib/dataclasses.py b/Lib/dataclasses.py
index 3eacba840d..12b2dfd145 100644
--- a/Lib/dataclasses.py
+++ b/Lib/dataclasses.py
@@ -1168,8 +1168,10 @@ def _dataclass_setstate(self, state):
 
 def _get_slots(cls):
     match cls.__dict__.get('__slots__'):
+        # A class which does not define __slots__ at all is equivalent
+        # to a class defining __slots__ = ('__dict__', '__weakref__')
         case None:
-            return
+            yield from ('__dict__', '__weakref__')
         case str(slot):
             yield slot
         # Slots may be any iterable, but we cannot handle an iterator
diff --git a/Lib/doctest.py b/Lib/doctest.py
index 4630e4007e..696bb96654 100644
--- a/Lib/doctest.py
+++ b/Lib/doctest.py
@@ -1124,7 +1124,7 @@ def _find_lineno(self, obj, source_lines):
             obj = obj.fget
         if inspect.isfunction(obj) and getattr(obj, '__doc__', None):
             # We don't use `docstring` var here, because `obj` can be changed.
-            obj = obj.__code__
+            obj = inspect.unwrap(obj).__code__
         if inspect.istraceback(obj): obj = obj.tb_frame
         if inspect.isframe(obj): obj = obj.f_code
         if inspect.iscode(obj):
@@ -2203,13 +2203,13 @@ def __init__(self, test, optionflags=0, setUp=None, tearDown=None,
         unittest.TestCase.__init__(self)
         self._dt_optionflags = optionflags
         self._dt_checker = checker
-        self._dt_globs = test.globs.copy()
         self._dt_test = test
         self._dt_setUp = setUp
         self._dt_tearDown = tearDown
 
     def setUp(self):
         test = self._dt_test
+        self._dt_globs = test.globs.copy()
 
         if self._dt_setUp is not None:
             self._dt_setUp(test)
diff --git a/Lib/email/_header_value_parser.py b/Lib/email/_header_value_parser.py
index 5b653f66c1..e4a342d446 100644
--- a/Lib/email/_header_value_parser.py
+++ b/Lib/email/_header_value_parser.py
@@ -949,6 +949,7 @@ class _InvalidEwError(errors.HeaderParseError):
 # up other parse trees.  Maybe should have  tests for that, too.
 DOT = ValueTerminal('.', 'dot')
 ListSeparator = ValueTerminal(',', 'list-separator')
+ListSeparator.as_ew_allowed = False
 RouteComponentMarker = ValueTerminal('@', 'route-component-marker')
 
 #
@@ -2022,7 +2023,7 @@ def get_address_list(value):
             address_list.defects.append(errors.InvalidHeaderDefect(
                 "invalid address in address-list"))
         if value:  # Must be a , at this point.
-            address_list.append(ValueTerminal(',', 'list-separator'))
+            address_list.append(ListSeparator)
             value = value[1:]
     return address_list, value
 
diff --git a/Lib/email/generator.py b/Lib/email/generator.py
index 7ccbe10eb7..c8056ad47b 100644
--- a/Lib/email/generator.py
+++ b/Lib/email/generator.py
@@ -243,7 +243,7 @@ def _handle_text(self, msg):
                 # existing message.
                 msg = deepcopy(msg)
                 del msg['content-transfer-encoding']
-                msg.set_payload(payload, charset)
+                msg.set_payload(msg._payload, charset)
                 payload = msg.get_payload()
                 self._munge_cte = (msg['content-transfer-encoding'],
                                    msg['content-type'])
diff --git a/Lib/email/message.py b/Lib/email/message.py
index fe769580fe..a14cca56b3 100644
--- a/Lib/email/message.py
+++ b/Lib/email/message.py
@@ -340,7 +340,7 @@ def set_payload(self, payload, charset=None):
                 return
             if not isinstance(charset, Charset):
                 charset = Charset(charset)
-            payload = payload.encode(charset.output_charset)
+            payload = payload.encode(charset.output_charset, 'surrogateescape')
         if hasattr(payload, 'decode'):
             self._payload = payload.decode('ascii', 'surrogateescape')
         else:
diff --git a/Lib/enum.py b/Lib/enum.py
index 1502bfe915..af5613838d 100644
--- a/Lib/enum.py
+++ b/Lib/enum.py
@@ -166,6 +166,11 @@ def _dedent(text):
         lines[j] = l[i:]
     return '\n'.join(lines)
 
+class _not_given:
+    def __repr__(self):
+        return('<not given>')
+_not_given = _not_given()
+
 class _auto_null:
     def __repr__(self):
         return '_auto_null'
@@ -283,9 +288,10 @@ def __set_name__(self, enum_class, member_name):
         enum_member._sort_order_ = len(enum_class._member_names_)
 
         if Flag is not None and issubclass(enum_class, Flag):
-            enum_class._flag_mask_ |= value
-            if _is_single_bit(value):
-                enum_class._singles_mask_ |= value
+            if isinstance(value, int):
+                enum_class._flag_mask_ |= value
+                if _is_single_bit(value):
+                    enum_class._singles_mask_ |= value
             enum_class._all_bits_ = 2 ** ((enum_class._flag_mask_).bit_length()) - 1
 
         # If another member with the same value was already defined, the
@@ -313,6 +319,7 @@ def __set_name__(self, enum_class, member_name):
             elif (
                     Flag is not None
                     and issubclass(enum_class, Flag)
+                    and isinstance(value, int)
                     and _is_single_bit(value)
                 ):
                 # no other instances found, record this member in _member_names_
@@ -457,10 +464,11 @@ def __setitem__(self, key, value):
             if isinstance(value, auto):
                 single = True
                 value = (value, )
-            if type(value) is tuple and any(isinstance(v, auto) for v in value):
+            if isinstance(value, tuple) and any(isinstance(v, auto) for v in value):
                 # insist on an actual tuple, no subclasses, in keeping with only supporting
                 # top-level auto() usage (not contained in any other data structure)
                 auto_valued = []
+                t = type(value)
                 for v in value:
                     if isinstance(v, auto):
                         non_auto_store = False
@@ -475,7 +483,12 @@ def __setitem__(self, key, value):
                 if single:
                     value = auto_valued[0]
                 else:
-                    value = tuple(auto_valued)
+                    try:
+                        # accepts iterable as multiple arguments?
+                        value = t(auto_valued)
+                    except TypeError:
+                        # then pass them in singlely
+                        value = t(*auto_valued)
             self._member_names[key] = None
             if non_auto_store:
                 self._last_values.append(value)
@@ -710,7 +723,7 @@ def __bool__(cls):
         """
         return True
 
-    def __call__(cls, value, names=None, *values, module=None, qualname=None, type=None, start=1, boundary=None):
+    def __call__(cls, value, names=_not_given, *values, module=None, qualname=None, type=None, start=1, boundary=None):
         """
         Either returns an existing member, or creates a new enum class.
 
@@ -739,18 +752,18 @@ def __call__(cls, value, names=None, *values, module=None, qualname=None, type=N
         """
         if cls._member_map_:
             # simple value lookup if members exist
-            if names:
+            if names is not _not_given:
                 value = (value, names) + values
             return cls.__new__(cls, value)
         # otherwise, functional API: we're creating a new Enum type
-        if names is None and type is None:
+        if names is _not_given and type is None:
             # no body? no data-type? possibly wrong usage
             raise TypeError(
                     f"{cls} has no members; specify `names=()` if you meant to create a new, empty, enum"
                     )
         return cls._create_(
                 class_name=value,
-                names=names,
+                names=None if names is _not_given else names,
                 module=module,
                 qualname=qualname,
                 type=type,
@@ -1528,37 +1541,50 @@ def __str__(self):
     def __bool__(self):
         return bool(self._value_)
 
+    def _get_value(self, flag):
+        if isinstance(flag, self.__class__):
+            return flag._value_
+        elif self._member_type_ is not object and isinstance(flag, self._member_type_):
+            return flag
+        return NotImplemented
+
     def __or__(self, other):
-        if isinstance(other, self.__class__):
-            other = other._value_
-        elif self._member_type_ is not object and isinstance(other, self._member_type_):
-            other = other
-        else:
+        other_value = self._get_value(other)
+        if other_value is NotImplemented:
             return NotImplemented
+
+        for flag in self, other:
+            if self._get_value(flag) is None:
+                raise TypeError(f"'{flag}' cannot be combined with other flags with |")
         value = self._value_
-        return self.__class__(value | other)
+        return self.__class__(value | other_value)
 
     def __and__(self, other):
-        if isinstance(other, self.__class__):
-            other = other._value_
-        elif self._member_type_ is not object and isinstance(other, self._member_type_):
-            other = other
-        else:
+        other_value = self._get_value(other)
+        if other_value is NotImplemented:
             return NotImplemented
+
+        for flag in self, other:
+            if self._get_value(flag) is None:
+                raise TypeError(f"'{flag}' cannot be combined with other flags with &")
         value = self._value_
-        return self.__class__(value & other)
+        return self.__class__(value & other_value)
 
     def __xor__(self, other):
-        if isinstance(other, self.__class__):
-            other = other._value_
-        elif self._member_type_ is not object and isinstance(other, self._member_type_):
-            other = other
-        else:
+        other_value = self._get_value(other)
+        if other_value is NotImplemented:
             return NotImplemented
+
+        for flag in self, other:
+            if self._get_value(flag) is None:
+                raise TypeError(f"'{flag}' cannot be combined with other flags with ^")
         value = self._value_
-        return self.__class__(value ^ other)
+        return self.__class__(value ^ other_value)
 
     def __invert__(self):
+        if self._get_value(self) is None:
+            raise TypeError(f"'{self}' cannot be inverted")
+
         if self._inverted_ is None:
             if self._boundary_ in (EJECT, KEEP):
                 self._inverted_ = self.__class__(~self._value_)
@@ -1625,7 +1651,7 @@ def global_flag_repr(self):
     cls_name = self.__class__.__name__
     if self._name_ is None:
         return "%s.%s(%r)" % (module, cls_name, self._value_)
-    if _is_single_bit(self):
+    if _is_single_bit(self._value_):
         return '%s.%s' % (module, self._name_)
     if self._boundary_ is not FlagBoundary.KEEP:
         return '|'.join(['%s.%s' % (module, name) for name in self.name.split('|')])
diff --git a/Lib/glob.py b/Lib/glob.py
index a7256422d5..50beef37f4 100644
--- a/Lib/glob.py
+++ b/Lib/glob.py
@@ -132,7 +132,8 @@ def glob1(dirname, pattern):
 
 def _glob2(dirname, pattern, dir_fd, dironly, include_hidden=False):
     assert _isrecursive(pattern)
-    yield pattern[:0]
+    if not dirname or _isdir(dirname, dir_fd):
+        yield pattern[:0]
     yield from _rlistdir(dirname, dir_fd, dironly,
                          include_hidden=include_hidden)
 
diff --git a/Lib/http/client.py b/Lib/http/client.py
index 5eebfccafb..a353716a85 100644
--- a/Lib/http/client.py
+++ b/Lib/http/client.py
@@ -936,17 +936,23 @@ def _get_hostport(self, host, port):
                 host = host[:i]
             else:
                 port = self.default_port
-            if host and host[0] == '[' and host[-1] == ']':
-                host = host[1:-1]
+        if host and host[0] == '[' and host[-1] == ']':
+            host = host[1:-1]
 
         return (host, port)
 
     def set_debuglevel(self, level):
         self.debuglevel = level
 
+    def _wrap_ipv6(self, ip):
+        if b':' in ip and ip[0] != b'['[0]:
+            return b"[" + ip + b"]"
+        return ip
+
     def _tunnel(self):
         connect = b"CONNECT %s:%d %s\r\n" % (
-            self._tunnel_host.encode("idna"), self._tunnel_port,
+            self._wrap_ipv6(self._tunnel_host.encode("idna")),
+            self._tunnel_port,
             self._http_vsn_str.encode("ascii"))
         headers = [connect]
         for header, value in self._tunnel_headers.items():
@@ -1221,9 +1227,8 @@ def putrequest(self, method, url, skip_host=False,
 
                     # As per RFC 273, IPv6 address should be wrapped with []
                     # when used as Host header
-
+                    host_enc = self._wrap_ipv6(host_enc)
                     if ":" in host:
-                        host_enc = b'[' + host_enc + b']'
                         host_enc = _strip_ipv6_iface(host_enc)
 
                     if port == self.default_port:
diff --git a/Lib/idlelib/editor.py b/Lib/idlelib/editor.py
index 8ee8eba643..7bfa093250 100644
--- a/Lib/idlelib/editor.py
+++ b/Lib/idlelib/editor.py
@@ -1044,7 +1044,9 @@ def open_recent_file(fn_closure=file_name):
     def saved_change_hook(self):
         short = self.short_title()
         long = self.long_title()
-        if short and long:
+        if short and long and not macosx.isCocoaTk():
+            # Don't use both values on macOS because
+            # that doesn't match platform conventions.
             title = short + " - " + long + _py_version
         elif short:
             title = short
@@ -1059,6 +1061,13 @@ def saved_change_hook(self):
         self.top.wm_title(title)
         self.top.wm_iconname(icon)
 
+        if macosx.isCocoaTk():
+            # Add a proxy icon to the window title
+            self.top.wm_attributes("-titlepath", long)
+
+            # Maintain the modification status for the window
+            self.top.wm_attributes("-modified", not self.get_saved())
+
     def get_saved(self):
         return self.undo.get_saved()
 
diff --git a/Lib/importlib/_bootstrap_external.py b/Lib/importlib/_bootstrap_external.py
index e6f75a9f6f..61dafc0f4c 100644
--- a/Lib/importlib/_bootstrap_external.py
+++ b/Lib/importlib/_bootstrap_external.py
@@ -1450,6 +1450,9 @@ def invalidate_caches():
         # https://bugs.python.org/issue45703
         _NamespacePath._epoch += 1
 
+        from importlib.metadata import MetadataPathFinder
+        MetadataPathFinder.invalidate_caches()
+
     @staticmethod
     def _path_hooks(path):
         """Search sys.path_hooks for a finder for 'path'."""
diff --git a/Lib/importlib/metadata/__init__.py b/Lib/importlib/metadata/__init__.py
index 82e0ce1b28..54156e93af 100644
--- a/Lib/importlib/metadata/__init__.py
+++ b/Lib/importlib/metadata/__init__.py
@@ -795,6 +795,7 @@ def _search_paths(cls, name, paths):
             path.search(prepared) for path in map(FastPath, paths)
         )
 
+    @classmethod
     def invalidate_caches(cls):
         FastPath.__new__.cache_clear()
 
diff --git a/Lib/importlib/resources/simple.py b/Lib/importlib/resources/simple.py
index 7770c922c8..96f117fec6 100644
--- a/Lib/importlib/resources/simple.py
+++ b/Lib/importlib/resources/simple.py
@@ -88,7 +88,7 @@ def is_dir(self):
     def open(self, mode='r', *args, **kwargs):
         stream = self.parent.reader.open_binary(self.name)
         if 'b' not in mode:
-            stream = io.TextIOWrapper(*args, **kwargs)
+            stream = io.TextIOWrapper(stream, *args, **kwargs)
         return stream
 
     def joinpath(self, name):
diff --git a/Lib/importlib/util.py b/Lib/importlib/util.py
index f4d6e82331..3743e6aa91 100644
--- a/Lib/importlib/util.py
+++ b/Lib/importlib/util.py
@@ -13,6 +13,7 @@
 
 import _imp
 import sys
+import threading
 import types
 
 
@@ -145,7 +146,7 @@ class _incompatible_extension_module_restrictions:
 
     You can get the same effect as this function by implementing the
     basic interface of multi-phase init (PEP 489) and lying about
-    support for mulitple interpreters (or per-interpreter GIL).
+    support for multiple interpreters (or per-interpreter GIL).
     """
 
     def __init__(self, *, disable_check):
@@ -171,36 +172,53 @@ class _LazyModule(types.ModuleType):
 
     def __getattribute__(self, attr):
         """Trigger the load of the module and return the attribute."""
-        # All module metadata must be garnered from __spec__ in order to avoid
-        # using mutated values.
-        # Stop triggering this method.
-        self.__class__ = types.ModuleType
-        # Get the original name to make sure no object substitution occurred
-        # in sys.modules.
-        original_name = self.__spec__.name
-        # Figure out exactly what attributes were mutated between the creation
-        # of the module and now.
-        attrs_then = self.__spec__.loader_state['__dict__']
-        attrs_now = self.__dict__
-        attrs_updated = {}
-        for key, value in attrs_now.items():
-            # Code that set the attribute may have kept a reference to the
-            # assigned object, making identity more important than equality.
-            if key not in attrs_then:
-                attrs_updated[key] = value
-            elif id(attrs_now[key]) != id(attrs_then[key]):
-                attrs_updated[key] = value
-        self.__spec__.loader.exec_module(self)
-        # If exec_module() was used directly there is no guarantee the module
-        # object was put into sys.modules.
-        if original_name in sys.modules:
-            if id(self) != id(sys.modules[original_name]):
-                raise ValueError(f"module object for {original_name!r} "
-                                  "substituted in sys.modules during a lazy "
-                                  "load")
-        # Update after loading since that's what would happen in an eager
-        # loading situation.
-        self.__dict__.update(attrs_updated)
+        __spec__ = object.__getattribute__(self, '__spec__')
+        loader_state = __spec__.loader_state
+        with loader_state['lock']:
+            # Only the first thread to get the lock should trigger the load
+            # and reset the module's class. The rest can now getattr().
+            if object.__getattribute__(self, '__class__') is _LazyModule:
+                # Reentrant calls from the same thread must be allowed to proceed without
+                # triggering the load again.
+                # exec_module() and self-referential imports are the primary ways this can
+                # happen, but in any case we must return something to avoid deadlock.
+                if loader_state['is_loading']:
+                    return object.__getattribute__(self, attr)
+                loader_state['is_loading'] = True
+
+                __dict__ = object.__getattribute__(self, '__dict__')
+
+                # All module metadata must be gathered from __spec__ in order to avoid
+                # using mutated values.
+                # Get the original name to make sure no object substitution occurred
+                # in sys.modules.
+                original_name = __spec__.name
+                # Figure out exactly what attributes were mutated between the creation
+                # of the module and now.
+                attrs_then = loader_state['__dict__']
+                attrs_now = __dict__
+                attrs_updated = {}
+                for key, value in attrs_now.items():
+                    # Code that set an attribute may have kept a reference to the
+                    # assigned object, making identity more important than equality.
+                    if key not in attrs_then:
+                        attrs_updated[key] = value
+                    elif id(attrs_now[key]) != id(attrs_then[key]):
+                        attrs_updated[key] = value
+                __spec__.loader.exec_module(self)
+                # If exec_module() was used directly there is no guarantee the module
+                # object was put into sys.modules.
+                if original_name in sys.modules:
+                    if id(self) != id(sys.modules[original_name]):
+                        raise ValueError(f"module object for {original_name!r} "
+                                          "substituted in sys.modules during a lazy "
+                                          "load")
+                # Update after loading since that's what would happen in an eager
+                # loading situation.
+                __dict__.update(attrs_updated)
+                # Finally, stop triggering this method.
+                self.__class__ = types.ModuleType
+
         return getattr(self, attr)
 
     def __delattr__(self, attr):
@@ -244,5 +262,7 @@ def exec_module(self, module):
         loader_state = {}
         loader_state['__dict__'] = module.__dict__.copy()
         loader_state['__class__'] = module.__class__
+        loader_state['lock'] = threading.RLock()
+        loader_state['is_loading'] = False
         module.__spec__.loader_state = loader_state
         module.__class__ = _LazyModule
diff --git a/Lib/inspect.py b/Lib/inspect.py
index a550202bb0..819ce940ee 100644
--- a/Lib/inspect.py
+++ b/Lib/inspect.py
@@ -760,18 +760,14 @@ def unwrap(func, *, stop=None):
    :exc:`ValueError` is raised if a cycle is encountered.
 
     """
-    if stop is None:
-        def _is_wrapper(f):
-            return hasattr(f, '__wrapped__')
-    else:
-        def _is_wrapper(f):
-            return hasattr(f, '__wrapped__') and not stop(f)
     f = func  # remember the original func for error reporting
     # Memoise by id to tolerate non-hashable objects, but store objects to
     # ensure they aren't destroyed, which would allow their IDs to be reused.
     memo = {id(f): f}
     recursion_limit = sys.getrecursionlimit()
-    while _is_wrapper(func):
+    while not isinstance(func, type) and hasattr(func, '__wrapped__'):
+        if stop is not None and stop(func):
+            break
         func = func.__wrapped__
         id_func = id(func)
         if (id_func in memo) or (len(memo) >= recursion_limit):
@@ -2007,15 +2003,17 @@ def _signature_get_user_defined_method(cls, method_name):
     named ``method_name`` and returns it only if it is a
     pure python function.
     """
-    try:
-        meth = getattr(cls, method_name)
-    except AttributeError:
-        return
+    if method_name == '__new__':
+        meth = getattr(cls, method_name, None)
     else:
-        if not isinstance(meth, _NonUserDefinedCallables):
-            # Once '__signature__' will be added to 'C'-level
-            # callables, this check won't be necessary
-            return meth
+        meth = getattr_static(cls, method_name, None)
+    if meth is None or isinstance(meth, _NonUserDefinedCallables):
+        # Once '__signature__' will be added to 'C'-level
+        # callables, this check won't be necessary
+        return None
+    if method_name != '__new__':
+        meth = _descriptor_get(meth, cls)
+    return meth
 
 
 def _signature_get_partial(wrapped_sig, partial, extra_args=()):
@@ -2460,6 +2458,15 @@ def _signature_from_function(cls, func, skip_bound_arg=True,
                __validate_parameters__=is_duck_function)
 
 
+def _descriptor_get(descriptor, obj):
+    if isclass(descriptor):
+        return descriptor
+    get = getattr(type(descriptor), '__get__', _sentinel)
+    if get is _sentinel:
+        return descriptor
+    return get(descriptor, obj, type(obj))
+
+
 def _signature_from_callable(obj, *,
                              follow_wrapper_chains=True,
                              skip_bound_arg=True,
@@ -2568,7 +2575,6 @@ def _signature_from_callable(obj, *,
         wrapped_sig = _get_signature_of(obj.func)
         return _signature_get_partial(wrapped_sig, obj)
 
-    sig = None
     if isinstance(obj, type):
         # obj is a class or a metaclass
 
@@ -2576,88 +2582,65 @@ def _signature_from_callable(obj, *,
         # in its metaclass
         call = _signature_get_user_defined_method(type(obj), '__call__')
         if call is not None:
-            sig = _get_signature_of(call)
-        else:
-            factory_method = None
-            new = _signature_get_user_defined_method(obj, '__new__')
-            init = _signature_get_user_defined_method(obj, '__init__')
-
-            # Go through the MRO and see if any class has user-defined
-            # pure Python __new__ or __init__ method
-            for base in obj.__mro__:
-                # Now we check if the 'obj' class has an own '__new__' method
-                if new is not None and '__new__' in base.__dict__:
-                    factory_method = new
-                    break
-                # or an own '__init__' method
-                elif init is not None and '__init__' in base.__dict__:
-                    factory_method = init
-                    break
+            return _get_signature_of(call)
 
-            if factory_method is not None:
-                sig = _get_signature_of(factory_method)
-
-        if sig is None:
-            # At this point we know, that `obj` is a class, with no user-
-            # defined '__init__', '__new__', or class-level '__call__'
-
-            for base in obj.__mro__[:-1]:
-                # Since '__text_signature__' is implemented as a
-                # descriptor that extracts text signature from the
-                # class docstring, if 'obj' is derived from a builtin
-                # class, its own '__text_signature__' may be 'None'.
-                # Therefore, we go through the MRO (except the last
-                # class in there, which is 'object') to find the first
-                # class with non-empty text signature.
-                try:
-                    text_sig = base.__text_signature__
-                except AttributeError:
-                    pass
-                else:
-                    if text_sig:
-                        # If 'base' class has a __text_signature__ attribute:
-                        # return a signature based on it
-                        return _signature_fromstr(sigcls, base, text_sig)
-
-            # No '__text_signature__' was found for the 'obj' class.
-            # Last option is to check if its '__init__' is
-            # object.__init__ or type.__init__.
-            if type not in obj.__mro__:
-                # We have a class (not metaclass), but no user-defined
-                # __init__ or __new__ for it
-                if (obj.__init__ is object.__init__ and
-                    obj.__new__ is object.__new__):
-                    # Return a signature of 'object' builtin.
-                    return sigcls.from_callable(object)
-                else:
-                    raise ValueError(
-                        'no signature found for builtin type {!r}'.format(obj))
+        new = _signature_get_user_defined_method(obj, '__new__')
+        init = _signature_get_user_defined_method(obj, '__init__')
 
-    elif not isinstance(obj, _NonUserDefinedCallables):
-        # An object with __call__
-        # We also check that the 'obj' is not an instance of
-        # types.WrapperDescriptorType or types.MethodWrapperType to avoid
-        # infinite recursion (and even potential segfault)
-        call = _signature_get_user_defined_method(type(obj), '__call__')
-        if call is not None:
+        # Go through the MRO and see if any class has user-defined
+        # pure Python __new__ or __init__ method
+        for base in obj.__mro__:
+            # Now we check if the 'obj' class has an own '__new__' method
+            if new is not None and '__new__' in base.__dict__:
+                sig = _get_signature_of(new)
+                if skip_bound_arg:
+                    sig = _signature_bound_method(sig)
+                return sig
+            # or an own '__init__' method
+            elif init is not None and '__init__' in base.__dict__:
+                return _get_signature_of(init)
+
+        # At this point we know, that `obj` is a class, with no user-
+        # defined '__init__', '__new__', or class-level '__call__'
+
+        for base in obj.__mro__[:-1]:
+            # Since '__text_signature__' is implemented as a
+            # descriptor that extracts text signature from the
+            # class docstring, if 'obj' is derived from a builtin
+            # class, its own '__text_signature__' may be 'None'.
+            # Therefore, we go through the MRO (except the last
+            # class in there, which is 'object') to find the first
+            # class with non-empty text signature.
             try:
-                sig = _get_signature_of(call)
-            except ValueError as ex:
-                msg = 'no signature found for {!r}'.format(obj)
-                raise ValueError(msg) from ex
-
-    if sig is not None:
-        # For classes and objects we skip the first parameter of their
-        # __call__, __new__, or __init__ methods
-        if skip_bound_arg:
-            return _signature_bound_method(sig)
-        else:
-            return sig
+                text_sig = base.__text_signature__
+            except AttributeError:
+                pass
+            else:
+                if text_sig:
+                    # If 'base' class has a __text_signature__ attribute:
+                    # return a signature based on it
+                    return _signature_fromstr(sigcls, base, text_sig)
+
+        # No '__text_signature__' was found for the 'obj' class.
+        # Last option is to check if its '__init__' is
+        # object.__init__ or type.__init__.
+        if type not in obj.__mro__:
+            # We have a class (not metaclass), but no user-defined
+            # __init__ or __new__ for it
+            if (obj.__init__ is object.__init__ and
+                obj.__new__ is object.__new__):
+                # Return a signature of 'object' builtin.
+                return sigcls.from_callable(object)
+            else:
+                raise ValueError(
+                    'no signature found for builtin type {!r}'.format(obj))
 
-    if isinstance(obj, types.BuiltinFunctionType):
-        # Raise a nicer error message for builtins
-        msg = 'no signature found for builtin function {!r}'.format(obj)
-        raise ValueError(msg)
+    else:
+        # An object with __call__
+        call = getattr_static(type(obj), '__call__', None)
+        if call is not None:
+            call = _descriptor_get(call, obj)
+            return _get_signature_of(call)
 
     raise ValueError('callable {!r} is not supported by signature'.format(obj))
 
diff --git a/Lib/json/encoder.py b/Lib/json/encoder.py
index 45f5477418..597849eca0 100644
--- a/Lib/json/encoder.py
+++ b/Lib/json/encoder.py
@@ -174,7 +174,7 @@ def default(self, o):
                 else:
                     return list(iterable)
                 # Let the base class default method raise the TypeError
-                return JSONEncoder.default(self, o)
+                return super().default(o)
 
         """
         raise TypeError(f'Object of type {o.__class__.__name__} '
diff --git a/Lib/linecache.py b/Lib/linecache.py
index 97644a8e37..ed4c9700dc 100644
--- a/Lib/linecache.py
+++ b/Lib/linecache.py
@@ -166,13 +166,11 @@ def lazycache(filename, module_globals):
         return False
     # Try for a __loader__, if available
     if module_globals and '__name__' in module_globals:
-        name = module_globals['__name__']
-        if (loader := module_globals.get('__loader__')) is None:
-            if spec := module_globals.get('__spec__'):
-                try:
-                    loader = spec.loader
-                except AttributeError:
-                    pass
+        spec = module_globals.get('__spec__')
+        name = getattr(spec, 'name', None) or module_globals['__name__']
+        loader = getattr(spec, 'loader', None)
+        if loader is None:
+            loader = module_globals.get('__loader__')
         get_source = getattr(loader, 'get_source', None)
 
         if name and get_source:
diff --git a/Lib/logging/__init__.py b/Lib/logging/__init__.py
index 056380fb22..22d3198332 100644
--- a/Lib/logging/__init__.py
+++ b/Lib/logging/__init__.py
@@ -1521,7 +1521,7 @@ def debug(self, msg, *args, **kwargs):
         To pass exception information, use the keyword argument exc_info with
         a true value, e.g.
 
-        logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
+        logger.debug("Houston, we have a %s", "thorny problem", exc_info=True)
         """
         if self.isEnabledFor(DEBUG):
             self._log(DEBUG, msg, args, **kwargs)
@@ -1533,7 +1533,7 @@ def info(self, msg, *args, **kwargs):
         To pass exception information, use the keyword argument exc_info with
         a true value, e.g.
 
-        logger.info("Houston, we have a %s", "notable problem", exc_info=1)
+        logger.info("Houston, we have a %s", "notable problem", exc_info=True)
         """
         if self.isEnabledFor(INFO):
             self._log(INFO, msg, args, **kwargs)
@@ -1545,7 +1545,7 @@ def warning(self, msg, *args, **kwargs):
         To pass exception information, use the keyword argument exc_info with
         a true value, e.g.
 
-        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
+        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=True)
         """
         if self.isEnabledFor(WARNING):
             self._log(WARNING, msg, args, **kwargs)
@@ -1562,7 +1562,7 @@ def error(self, msg, *args, **kwargs):
         To pass exception information, use the keyword argument exc_info with
         a true value, e.g.
 
-        logger.error("Houston, we have a %s", "major problem", exc_info=1)
+        logger.error("Houston, we have a %s", "major problem", exc_info=True)
         """
         if self.isEnabledFor(ERROR):
             self._log(ERROR, msg, args, **kwargs)
@@ -1580,7 +1580,7 @@ def critical(self, msg, *args, **kwargs):
         To pass exception information, use the keyword argument exc_info with
         a true value, e.g.
 
-        logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
+        logger.critical("Houston, we have a %s", "major disaster", exc_info=True)
         """
         if self.isEnabledFor(CRITICAL):
             self._log(CRITICAL, msg, args, **kwargs)
@@ -1598,7 +1598,7 @@ def log(self, level, msg, *args, **kwargs):
         To pass exception information, use the keyword argument exc_info with
         a true value, e.g.
 
-        logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
+        logger.log(level, "We have a %s", "mysterious problem", exc_info=True)
         """
         if not isinstance(level, int):
             if raiseExceptions:
@@ -1985,18 +1985,11 @@ def hasHandlers(self):
         """
         return self.logger.hasHandlers()
 
-    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):
+    def _log(self, level, msg, args, **kwargs):
         """
         Low-level log implementation, proxied to allow nested logger adapters.
         """
-        return self.logger._log(
-            level,
-            msg,
-            args,
-            exc_info=exc_info,
-            extra=extra,
-            stack_info=stack_info,
-        )
+        return self.logger._log(level, msg, args, **kwargs)
 
     @property
     def manager(self):
@@ -2056,7 +2049,7 @@ def basicConfig(**kwargs):
               that this argument is incompatible with 'filename' - if both
               are present, 'stream' is ignored.
     handlers  If specified, this should be an iterable of already created
-              handlers, which will be added to the root handler. Any handler
+              handlers, which will be added to the root logger. Any handler
               in the list which does not have a formatter assigned will be
               assigned the formatter created in this function.
     force     If this keyword  is specified as true, any existing handlers
diff --git a/Lib/logging/handlers.py b/Lib/logging/handlers.py
index 6e88184b51..1ae6bb8443 100644
--- a/Lib/logging/handlers.py
+++ b/Lib/logging/handlers.py
@@ -232,19 +232,19 @@ def __init__(self, filename, when='h', interval=1, backupCount=0,
         if self.when == 'S':
             self.interval = 1 # one second
             self.suffix = "%Y-%m-%d_%H-%M-%S"
-            self.extMatch = r"^\d{4}-\d{2}-\d{2}_\d{2}-\d{2}-\d{2}(\.\w+)?$"
+            extMatch = r"(?<!\d)\d{4}-\d{2}-\d{2}_\d{2}-\d{2}-\d{2}(?!\d)"
         elif self.when == 'M':
             self.interval = 60 # one minute
             self.suffix = "%Y-%m-%d_%H-%M"
-            self.extMatch = r"^\d{4}-\d{2}-\d{2}_\d{2}-\d{2}(\.\w+)?$"
+            extMatch = r"(?<!\d)\d{4}-\d{2}-\d{2}_\d{2}-\d{2}(?!\d)"
         elif self.when == 'H':
             self.interval = 60 * 60 # one hour
             self.suffix = "%Y-%m-%d_%H"
-            self.extMatch = r"^\d{4}-\d{2}-\d{2}_\d{2}(\.\w+)?$"
+            extMatch = r"(?<!\d)\d{4}-\d{2}-\d{2}_\d{2}(?!\d)"
         elif self.when == 'D' or self.when == 'MIDNIGHT':
             self.interval = 60 * 60 * 24 # one day
             self.suffix = "%Y-%m-%d"
-            self.extMatch = r"^\d{4}-\d{2}-\d{2}(\.\w+)?$"
+            extMatch = r"(?<!\d)\d{4}-\d{2}-\d{2}(?!\d)"
         elif self.when.startswith('W'):
             self.interval = 60 * 60 * 24 * 7 # one week
             if len(self.when) != 2:
@@ -253,11 +253,17 @@ def __init__(self, filename, when='h', interval=1, backupCount=0,
                 raise ValueError("Invalid day specified for weekly rollover: %s" % self.when)
             self.dayOfWeek = int(self.when[1])
             self.suffix = "%Y-%m-%d"
-            self.extMatch = r"^\d{4}-\d{2}-\d{2}(\.\w+)?$"
+            extMatch = r"(?<!\d)\d{4}-\d{2}-\d{2}(?!\d)"
         else:
             raise ValueError("Invalid rollover interval specified: %s" % self.when)
 
-        self.extMatch = re.compile(self.extMatch, re.ASCII)
+        # extMatch is a pattern for matching a datetime suffix in a file name.
+        # After custom naming, it is no longer guaranteed to be separated by
+        # periods from other parts of the filename.  The lookup statements
+        # (?<!\d) and (?!\d) ensure that the datetime suffix (which itself
+        # starts and ends with digits) is not preceded or followed by digits.
+        # This reduces the number of false matches and improves performance.
+        self.extMatch = re.compile(extMatch, re.ASCII)
         self.interval = self.interval * interval # multiply by units requested
         # The following line added because the filename passed in could be a
         # path object (see Issue #27493), but self.baseFilename will be a string
@@ -299,7 +305,7 @@ def computeRollover(self, currentTime):
 
             r = rotate_ts - ((currentHour * 60 + currentMinute) * 60 +
                 currentSecond)
-            if r < 0:
+            if r <= 0:
                 # Rotate time is before the current time (for example when
                 # self.rotateAt is 13:45 and it now 14:15), rotation is
                 # tomorrow.
@@ -328,17 +334,21 @@ def computeRollover(self, currentTime):
                         daysToWait = self.dayOfWeek - day
                     else:
                         daysToWait = 6 - day + self.dayOfWeek + 1
-                    newRolloverAt = result + (daysToWait * (60 * 60 * 24))
-                    if not self.utc:
-                        dstNow = t[-1]
-                        dstAtRollover = time.localtime(newRolloverAt)[-1]
-                        if dstNow != dstAtRollover:
-                            if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour
-                                addend = -3600
-                            else:           # DST bows out before next rollover, so we need to add an hour
-                                addend = 3600
-                            newRolloverAt += addend
-                    result = newRolloverAt
+                    result += daysToWait * _MIDNIGHT
+                result += self.interval - _MIDNIGHT * 7
+            else:
+                result += self.interval - _MIDNIGHT
+            if not self.utc:
+                dstNow = t[-1]
+                dstAtRollover = time.localtime(result)[-1]
+                if dstNow != dstAtRollover:
+                    if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour
+                        addend = -3600
+                        if not time.localtime(result-3600)[-1]:
+                            addend = 0
+                    else:           # DST bows out before next rollover, so we need to add an hour
+                        addend = 3600
+                    result += addend
         return result
 
     def shouldRollover(self, record):
@@ -369,32 +379,28 @@ def getFilesToDelete(self):
         dirName, baseName = os.path.split(self.baseFilename)
         fileNames = os.listdir(dirName)
         result = []
-        # See bpo-44753: Don't use the extension when computing the prefix.
-        n, e = os.path.splitext(baseName)
-        prefix = n + '.'
-        plen = len(prefix)
-        for fileName in fileNames:
-            if self.namer is None:
-                # Our files will always start with baseName
-                if not fileName.startswith(baseName):
-                    continue
-            else:
-                # Our files could be just about anything after custom naming, but
-                # likely candidates are of the form
-                # foo.log.DATETIME_SUFFIX or foo.DATETIME_SUFFIX.log
-                if (not fileName.startswith(baseName) and fileName.endswith(e) and
-                    len(fileName) > (plen + 1) and not fileName[plen+1].isdigit()):
-                    continue
-
-            if fileName[:plen] == prefix:
-                suffix = fileName[plen:]
-                # See bpo-45628: The date/time suffix could be anywhere in the
-                # filename
-                parts = suffix.split('.')
-                for part in parts:
-                    if self.extMatch.match(part):
+        if self.namer is None:
+            prefix = baseName + '.'
+            plen = len(prefix)
+            for fileName in fileNames:
+                if fileName[:plen] == prefix:
+                    suffix = fileName[plen:]
+                    if self.extMatch.fullmatch(suffix):
+                        result.append(os.path.join(dirName, fileName))
+        else:
+            for fileName in fileNames:
+                # Our files could be just about anything after custom naming,
+                # but they should contain the datetime suffix.
+                # Try to find the datetime suffix in the file name and verify
+                # that the file name can be generated by this handler.
+                m = self.extMatch.search(fileName)
+                while m:
+                    dfn = self.namer(self.baseFilename + "." + m[0])
+                    if os.path.basename(dfn) == fileName:
                         result.append(os.path.join(dirName, fileName))
                         break
+                    m = self.extMatch.search(fileName, m.start() + 1)
+
         if len(result) < self.backupCount:
             result = []
         else:
@@ -410,17 +416,14 @@ def doRollover(self):
         then we have to get a list of matching filenames, sort them and remove
         the one with the oldest suffix.
         """
-        if self.stream:
-            self.stream.close()
-            self.stream = None
         # get the time that this sequence started at and make it a TimeTuple
         currentTime = int(time.time())
-        dstNow = time.localtime(currentTime)[-1]
         t = self.rolloverAt - self.interval
         if self.utc:
             timeTuple = time.gmtime(t)
         else:
             timeTuple = time.localtime(t)
+            dstNow = time.localtime(currentTime)[-1]
             dstThen = timeTuple[-1]
             if dstNow != dstThen:
                 if dstNow:
@@ -431,26 +434,19 @@ def doRollover(self):
         dfn = self.rotation_filename(self.baseFilename + "." +
                                      time.strftime(self.suffix, timeTuple))
         if os.path.exists(dfn):
-            os.remove(dfn)
+            # Already rolled over.
+            return
+
+        if self.stream:
+            self.stream.close()
+            self.stream = None
         self.rotate(self.baseFilename, dfn)
         if self.backupCount > 0:
             for s in self.getFilesToDelete():
                 os.remove(s)
         if not self.delay:
             self.stream = self._open()
-        newRolloverAt = self.computeRollover(currentTime)
-        while newRolloverAt <= currentTime:
-            newRolloverAt = newRolloverAt + self.interval
-        #If DST changes and midnight or weekly rollover, adjust for this.
-        if (self.when == 'MIDNIGHT' or self.when.startswith('W')) and not self.utc:
-            dstAtRollover = time.localtime(newRolloverAt)[-1]
-            if dstNow != dstAtRollover:
-                if not dstNow:  # DST kicks in before next rollover, so we need to deduct an hour
-                    addend = -3600
-                else:           # DST bows out before next rollover, so we need to add an hour
-                    addend = 3600
-                newRolloverAt += addend
-        self.rolloverAt = newRolloverAt
+        self.rolloverAt = self.computeRollover(currentTime)
 
 class WatchedFileHandler(logging.FileHandler):
     """
diff --git a/Lib/mimetypes.py b/Lib/mimetypes.py
index 37228de482..3cc027aa36 100644
--- a/Lib/mimetypes.py
+++ b/Lib/mimetypes.py
@@ -120,7 +120,13 @@ def guess_type(self, url, strict=True):
         but non-standard types.
         """
         url = os.fspath(url)
-        scheme, url = urllib.parse._splittype(url)
+        p = urllib.parse.urlparse(url)
+        if p.scheme and len(p.scheme) > 1:
+            scheme = p.scheme
+            url = p.path
+        else:
+            scheme = None
+            url = os.path.splitdrive(url)[1]
         if scheme == 'data':
             # syntax of data URLs:
             # dataurl   := "data:" [ mediatype ] [ ";base64" ] "," data
diff --git a/Lib/multiprocessing/connection.py b/Lib/multiprocessing/connection.py
index dbbf106f68..d0582e3cd5 100644
--- a/Lib/multiprocessing/connection.py
+++ b/Lib/multiprocessing/connection.py
@@ -476,8 +476,9 @@ def accept(self):
         '''
         if self._listener is None:
             raise OSError('listener is closed')
+
         c = self._listener.accept()
-        if self._authkey:
+        if self._authkey is not None:
             deliver_challenge(c, self._authkey)
             answer_challenge(c, self._authkey)
         return c
diff --git a/Lib/os.py b/Lib/os.py
index 598c9e5023..7ee7d695d9 100644
--- a/Lib/os.py
+++ b/Lib/os.py
@@ -473,7 +473,7 @@ def fwalk(top=".", topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=
         # lstat()/open()/fstat() trick.
         if not follow_symlinks:
             orig_st = stat(top, follow_symlinks=False, dir_fd=dir_fd)
-        topfd = open(top, O_RDONLY, dir_fd=dir_fd)
+        topfd = open(top, O_RDONLY | O_NONBLOCK, dir_fd=dir_fd)
         try:
             if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode) and
                                     path.samestat(orig_st, stat(topfd)))):
@@ -522,7 +522,7 @@ def _fwalk(topfd, toppath, isbytes, topdown, onerror, follow_symlinks):
                         assert entries is not None
                         name, entry = name
                         orig_st = entry.stat(follow_symlinks=False)
-                dirfd = open(name, O_RDONLY, dir_fd=topfd)
+                dirfd = open(name, O_RDONLY | O_NONBLOCK, dir_fd=topfd)
             except OSError as err:
                 if onerror is not None:
                     onerror(err)
diff --git a/Lib/pdb.py b/Lib/pdb.py
index a838a26b03..225c9f253e 100755
--- a/Lib/pdb.py
+++ b/Lib/pdb.py
@@ -154,6 +154,7 @@ def namespace(self):
             __name__='__main__',
             __file__=self,
             __builtins__=__builtins__,
+            __spec__=None,
         )
 
     @property
@@ -298,26 +299,13 @@ def setup(self, f, tb):
         # cache it here to ensure that modifications are not overwritten.
         self.curframe_locals = self.curframe.f_locals
         self.set_convenience_variable(self.curframe, '_frame', self.curframe)
-        return self.execRcLines()
 
-    # Can be executed earlier than 'setup' if desired
-    def execRcLines(self):
-        if not self.rcLines:
-            return
-        # local copy because of recursion
-        rcLines = self.rcLines
-        rcLines.reverse()
-        # execute every line only once
-        self.rcLines = []
-        while rcLines:
-            line = rcLines.pop().strip()
-            if line and line[0] != '#':
-                if self.onecmd(line):
-                    # if onecmd returns True, the command wants to exit
-                    # from the interaction, save leftover rc lines
-                    # to execute before next interaction
-                    self.rcLines += reversed(rcLines)
-                    return True
+        if self.rcLines:
+            self.cmdqueue = [
+                line for line in self.rcLines
+                if line.strip() and not line.strip().startswith("#")
+            ]
+            self.rcLines = []
 
     # Override Bdb methods
 
@@ -430,12 +418,10 @@ def interaction(self, frame, traceback):
                 pass
             else:
                 Pdb._previous_sigint_handler = None
-        if self.setup(frame, traceback):
-            # no interaction desired at this time (happens if .pdbrc contains
-            # a command like "continue")
-            self.forget()
-            return
-        self.print_stack_entry(self.stack[self.curindex])
+        self.setup(frame, traceback)
+        # if we have more commands to process, do not show the stack entry
+        if not self.cmdqueue:
+            self.print_stack_entry(self.stack[self.curindex])
         self._cmdloop()
         self.forget()
 
@@ -522,7 +508,7 @@ def precmd(self, line):
             if marker >= 0:
                 # queue up everything after marker
                 next = line[marker+2:].lstrip()
-                self.cmdqueue.append(next)
+                self.cmdqueue.insert(0, next)
                 line = line[:marker].rstrip()
 
         # Replace all the convenience variables
@@ -546,13 +532,12 @@ def handle_command_def(self, line):
         """Handles one command line during command list definition."""
         cmd, arg, line = self.parseline(line)
         if not cmd:
-            return
+            return False
         if cmd == 'silent':
             self.commands_silent[self.commands_bnum] = True
-            return # continue to handle other cmd def in the cmd list
+            return False  # continue to handle other cmd def in the cmd list
         elif cmd == 'end':
-            self.cmdqueue = []
-            return 1 # end of cmd list
+            return True  # end of cmd list
         cmdlist = self.commands[self.commands_bnum]
         if arg:
             cmdlist.append(cmd+' '+arg)
@@ -566,9 +551,8 @@ def handle_command_def(self, line):
         # one of the resuming commands
         if func.__name__ in self.commands_resuming:
             self.commands_doprompt[self.commands_bnum] = False
-            self.cmdqueue = []
-            return 1
-        return
+            return True
+        return False
 
     # interface abstraction functions
 
diff --git a/Lib/pickletools.py b/Lib/pickletools.py
index 95a77aeb2a..51ee4a7a26 100644
--- a/Lib/pickletools.py
+++ b/Lib/pickletools.py
@@ -1253,7 +1253,7 @@ def __init__(self, name, code, arg,
       stack_before=[],
       stack_after=[pyint],
       proto=2,
-      doc="""Long integer using found-byte length.
+      doc="""Long integer using four-byte length.
 
       A more efficient encoding of a Python long; the long4 encoding
       says it all."""),
diff --git a/Lib/pydoc.py b/Lib/pydoc.py
index 84bbf588dc..9a8812392a 100755
--- a/Lib/pydoc.py
+++ b/Lib/pydoc.py
@@ -204,6 +204,19 @@ def classname(object, modname):
         name = object.__module__ + '.' + name
     return name
 
+def parentname(object, modname):
+    """Get a name of the enclosing class (qualified it with a module name
+    if necessary) or module."""
+    if '.' in object.__qualname__:
+        name = object.__qualname__.rpartition('.')[0]
+        if object.__module__ != modname:
+            return object.__module__ + '.' + name
+        else:
+            return name
+    else:
+        if object.__module__ != modname:
+            return object.__module__
+
 def isdata(object):
     """Check if an object is of a type that probably means it's data."""
     return not (inspect.ismodule(object) or inspect.isclass(object) or
@@ -298,13 +311,15 @@ def visiblename(name, all=None, obj=None):
         return not name.startswith('_')
 
 def classify_class_attrs(object):
-    """Wrap inspect.classify_class_attrs, with fixup for data descriptors."""
+    """Wrap inspect.classify_class_attrs, with fixup for data descriptors and bound methods."""
     results = []
     for (name, kind, cls, value) in inspect.classify_class_attrs(object):
         if inspect.isdatadescriptor(value):
             kind = 'data descriptor'
             if isinstance(value, property) and value.fset is None:
                 kind = 'readonly property'
+        elif kind == 'method' and _is_bound_method(value):
+            kind = 'static method'
         results.append((name, kind, cls, value))
     return results
 
@@ -514,7 +529,7 @@ def getdocloc(self, object, basedir=sysconfig.get_path('stdlib')):
                                  '_thread', 'zipimport') or
              (file.startswith(basedir) and
               not file.startswith(os.path.join(basedir, 'site-packages')))) and
-            object.__name__ not in ('xml.etree', 'test.pydoc_mod')):
+            object.__name__ not in ('xml.etree', 'test.test_pydoc.pydoc_mod')):
             if docloc.startswith(("http://", "https://")):
                 docloc = "{}/{}.html".format(docloc.rstrip("/"), object.__name__.lower())
             else:
@@ -658,6 +673,25 @@ def classlink(self, object, modname):
                 module.__name__, name, classname(object, modname))
         return classname(object, modname)
 
+    def parentlink(self, object, modname):
+        """Make a link for the enclosing class or module."""
+        link = None
+        name, module = object.__name__, sys.modules.get(object.__module__)
+        if hasattr(module, name) and getattr(module, name) is object:
+            if '.' in object.__qualname__:
+                name = object.__qualname__.rpartition('.')[0]
+                if object.__module__ != modname:
+                    link = '%s.html#%s' % (module.__name__, name)
+                else:
+                    link = '#%s' % name
+            else:
+                if object.__module__ != modname:
+                    link = '%s.html' % module.__name__
+        if link:
+            return '<a href="%s">%s</a>' % (link, parentname(object, modname))
+        else:
+            return parentname(object, modname)
+
     def modulelink(self, object):
         """Make a link for a module."""
         return '<a href="%s.html">%s</a>' % (object.__name__, object.__name__)
@@ -902,7 +936,7 @@ def spill(msg, attrs, predicate):
                         push(self.docdata(value, name, mod))
                     else:
                         push(self.document(value, name, mod,
-                                        funcs, classes, mdict, object))
+                                        funcs, classes, mdict, object, homecls))
                     push('\n')
             return attrs
 
@@ -1025,24 +1059,44 @@ def formatvalue(self, object):
         return self.grey('=' + self.repr(object))
 
     def docroutine(self, object, name=None, mod=None,
-                   funcs={}, classes={}, methods={}, cl=None):
+                   funcs={}, classes={}, methods={}, cl=None, homecls=None):
         """Produce HTML documentation for a function or method object."""
         realname = object.__name__
         name = name or realname
-        anchor = (cl and cl.__name__ or '') + '-' + name
+        if homecls is None:
+            homecls = cl
+        anchor = ('' if cl is None else cl.__name__) + '-' + name
         note = ''
-        skipdocs = 0
+        skipdocs = False
+        imfunc = None
         if _is_bound_method(object):
-            imclass = object.__self__.__class__
-            if cl:
-                if imclass is not cl:
-                    note = ' from ' + self.classlink(imclass, mod)
+            imself = object.__self__
+            if imself is cl:
+                imfunc = getattr(object, '__func__', None)
+            elif inspect.isclass(imself):
+                note = ' class method of %s' % self.classlink(imself, mod)
             else:
-                if object.__self__ is not None:
-                    note = ' method of %s instance' % self.classlink(
-                        object.__self__.__class__, mod)
-                else:
-                    note = ' unbound %s method' % self.classlink(imclass,mod)
+                note = ' method of %s instance' % self.classlink(
+                    imself.__class__, mod)
+        elif (inspect.ismethoddescriptor(object) or
+              inspect.ismethodwrapper(object)):
+            try:
+                objclass = object.__objclass__
+            except AttributeError:
+                pass
+            else:
+                if cl is None:
+                    note = ' unbound %s method' % self.classlink(objclass, mod)
+                elif objclass is not homecls:
+                    note = ' from ' + self.classlink(objclass, mod)
+        else:
+            imfunc = object
+        if inspect.isfunction(imfunc) and homecls is not None and (
+            imfunc.__module__ != homecls.__module__ or
+            imfunc.__qualname__ != homecls.__qualname__ + '.' + realname):
+            pname = self.parentlink(imfunc, mod)
+            if pname:
+                note = ' from %s' % pname
 
         if (inspect.iscoroutinefunction(object) or
                 inspect.isasyncgenfunction(object)):
@@ -1053,10 +1107,13 @@ def docroutine(self, object, name=None, mod=None,
         if name == realname:
             title = '<a name="%s"><strong>%s</strong></a>' % (anchor, realname)
         else:
-            if cl and inspect.getattr_static(cl, realname, []) is object:
+            if (cl is not None and
+                inspect.getattr_static(cl, realname, []) is object):
                 reallink = '<a href="#%s">%s</a>' % (
                     cl.__name__ + '-' + realname, realname)
-                skipdocs = 1
+                skipdocs = True
+                if note.startswith(' from '):
+                    note = ''
             else:
                 reallink = realname
             title = '<a name="%s"><strong>%s</strong></a> = %s' % (
@@ -1074,7 +1131,8 @@ def docroutine(self, object, name=None, mod=None,
                     # XXX lambda's won't usually have func_annotations['return']
                     # since the syntax doesn't support but it is possible.
                     # So removing parentheses isn't truly safe.
-                    argspec = argspec[1:-1] # remove parentheses
+                    if not object.__annotations__:
+                        argspec = argspec[1:-1] # remove parentheses
         if not argspec:
             argspec = '(...)'
 
@@ -1089,7 +1147,7 @@ def docroutine(self, object, name=None, mod=None,
             doc = doc and '<dd><span class="code">%s</span></dd>' % doc
             return '<dl><dt>%s</dt>%s</dl>\n' % (decl, doc)
 
-    def docdata(self, object, name=None, mod=None, cl=None):
+    def docdata(self, object, name=None, mod=None, cl=None, *ignored):
         """Produce html documentation for a data descriptor."""
         results = []
         push = results.append
@@ -1200,7 +1258,7 @@ def formattree(self, tree, modname, parent=None, prefix=''):
                     entry, modname, c, prefix + '    ')
         return result
 
-    def docmodule(self, object, name=None, mod=None):
+    def docmodule(self, object, name=None, mod=None, *ignored):
         """Produce text documentation for a given module object."""
         name = object.__name__ # ignore the passed-in name
         synop, desc = splitdoc(getdoc(object))
@@ -1384,7 +1442,7 @@ def spill(msg, attrs, predicate):
                         push(self.docdata(value, name, mod))
                     else:
                         push(self.document(value,
-                                        name, mod, object))
+                                        name, mod, object, homecls))
             return attrs
 
         def spilldescriptors(msg, attrs, predicate):
@@ -1459,23 +1517,43 @@ def formatvalue(self, object):
         """Format an argument default value as text."""
         return '=' + self.repr(object)
 
-    def docroutine(self, object, name=None, mod=None, cl=None):
+    def docroutine(self, object, name=None, mod=None, cl=None, homecls=None):
         """Produce text documentation for a function or method object."""
         realname = object.__name__
         name = name or realname
+        if homecls is None:
+            homecls = cl
         note = ''
-        skipdocs = 0
+        skipdocs = False
+        imfunc = None
         if _is_bound_method(object):
-            imclass = object.__self__.__class__
-            if cl:
-                if imclass is not cl:
-                    note = ' from ' + classname(imclass, mod)
+            imself = object.__self__
+            if imself is cl:
+                imfunc = getattr(object, '__func__', None)
+            elif inspect.isclass(imself):
+                note = ' class method of %s' % classname(imself, mod)
             else:
-                if object.__self__ is not None:
-                    note = ' method of %s instance' % classname(
-                        object.__self__.__class__, mod)
-                else:
-                    note = ' unbound %s method' % classname(imclass,mod)
+                note = ' method of %s instance' % classname(
+                    imself.__class__, mod)
+        elif (inspect.ismethoddescriptor(object) or
+              inspect.ismethodwrapper(object)):
+            try:
+                objclass = object.__objclass__
+            except AttributeError:
+                pass
+            else:
+                if cl is None:
+                    note = ' unbound %s method' % classname(objclass, mod)
+                elif objclass is not homecls:
+                    note = ' from ' + classname(objclass, mod)
+        else:
+            imfunc = object
+        if inspect.isfunction(imfunc) and homecls is not None and (
+            imfunc.__module__ != homecls.__module__ or
+            imfunc.__qualname__ != homecls.__qualname__ + '.' + realname):
+            pname = parentname(imfunc, mod)
+            if pname:
+                note = ' from %s' % pname
 
         if (inspect.iscoroutinefunction(object) or
                 inspect.isasyncgenfunction(object)):
@@ -1486,8 +1564,11 @@ def docroutine(self, object, name=None, mod=None, cl=None):
         if name == realname:
             title = self.bold(realname)
         else:
-            if cl and inspect.getattr_static(cl, realname, []) is object:
-                skipdocs = 1
+            if (cl is not None and
+                inspect.getattr_static(cl, realname, []) is object):
+                skipdocs = True
+                if note.startswith(' from '):
+                    note = ''
             title = self.bold(name) + ' = ' + realname
         argspec = None
 
@@ -1503,7 +1584,8 @@ def docroutine(self, object, name=None, mod=None, cl=None):
                     # XXX lambda's won't usually have func_annotations['return']
                     # since the syntax doesn't support but it is possible.
                     # So removing parentheses isn't truly safe.
-                    argspec = argspec[1:-1] # remove parentheses
+                    if not object.__annotations__:
+                        argspec = argspec[1:-1] # remove parentheses
         if not argspec:
             argspec = '(...)'
         decl = asyncqualifier + title + argspec + note
@@ -1514,7 +1596,7 @@ def docroutine(self, object, name=None, mod=None, cl=None):
             doc = getdoc(object) or ''
             return decl + '\n' + (doc and self.indent(doc).rstrip() + '\n')
 
-    def docdata(self, object, name=None, mod=None, cl=None):
+    def docdata(self, object, name=None, mod=None, cl=None, *ignored):
         """Produce text documentation for a data descriptor."""
         results = []
         push = results.append
@@ -1530,7 +1612,8 @@ def docdata(self, object, name=None, mod=None, cl=None):
 
     docproperty = docdata
 
-    def docother(self, object, name=None, mod=None, parent=None, maxlen=None, doc=None):
+    def docother(self, object, name=None, mod=None, parent=None, *ignored,
+                 maxlen=None, doc=None):
         """Produce text documentation for a data object."""
         repr = self.repr(object)
         if maxlen:
@@ -2410,6 +2493,7 @@ def __init__(self, urlhandler, host, port):
             threading.Thread.__init__(self)
             self.serving = False
             self.error = None
+            self.docserver = None
 
         def run(self):
             """Start the server."""
@@ -2442,9 +2526,9 @@ def stop(self):
 
     thread = ServerThread(urlhandler, hostname, port)
     thread.start()
-    # Wait until thread.serving is True to make sure we are
-    # really up before returning.
-    while not thread.error and not thread.serving:
+    # Wait until thread.serving is True and thread.docserver is set
+    # to make sure we are really up before returning.
+    while not thread.error and not (thread.serving and thread.docserver):
         time.sleep(.01)
     return thread
 
diff --git a/Lib/shutil.py b/Lib/shutil.py
index 96463007d1..3a2b6be39b 100644
--- a/Lib/shutil.py
+++ b/Lib/shutil.py
@@ -676,7 +676,7 @@ def _rmtree_safe_fd(topfd, path, onexc):
                     continue
         if is_dir:
             try:
-                dirfd = os.open(entry.name, os.O_RDONLY, dir_fd=topfd)
+                dirfd = os.open(entry.name, os.O_RDONLY | os.O_NONBLOCK, dir_fd=topfd)
                 dirfd_closed = False
             except OSError as err:
                 onexc(os.open, fullname, err)
@@ -775,7 +775,7 @@ def onexc(*args):
             onexc(os.lstat, path, err)
             return
         try:
-            fd = os.open(path, os.O_RDONLY, dir_fd=dir_fd)
+            fd = os.open(path, os.O_RDONLY | os.O_NONBLOCK, dir_fd=dir_fd)
             fd_closed = False
         except Exception as err:
             onexc(os.open, path, err)
diff --git a/Lib/subprocess.py b/Lib/subprocess.py
index 3264d9afc7..1d17ae3608 100644
--- a/Lib/subprocess.py
+++ b/Lib/subprocess.py
@@ -1581,6 +1581,8 @@ def _wait(self, timeout):
             """Internal implementation of wait() on Windows."""
             if timeout is None:
                 timeout_millis = _winapi.INFINITE
+            elif timeout <= 0:
+                timeout_millis = 0
             else:
                 timeout_millis = int(timeout * 1000)
             if self.returncode is None:
diff --git a/Lib/test/_test_multiprocessing.py b/Lib/test/_test_multiprocessing.py
index e42c7ab4bd..9e688efb1e 100644
--- a/Lib/test/_test_multiprocessing.py
+++ b/Lib/test/_test_multiprocessing.py
@@ -3466,6 +3466,30 @@ def test_context(self):
         if self.TYPE == 'processes':
             self.assertRaises(OSError, l.accept)
 
+    def test_empty_authkey(self):
+        # bpo-43952: allow empty bytes as authkey
+        def handler(*args):
+            raise RuntimeError('Connection took too long...')
+
+        def run(addr, authkey):
+            client = self.connection.Client(addr, authkey=authkey)
+            client.send(1729)
+
+        key = b''
+
+        with self.connection.Listener(authkey=key) as listener:
+            thread = threading.Thread(target=run, args=(listener.address, key))
+            thread.start()
+            try:
+                with listener.accept() as d:
+                    self.assertEqual(d.recv(), 1729)
+            finally:
+                thread.join()
+
+        if self.TYPE == 'processes':
+            with self.assertRaises(OSError):
+                listener.accept()
+
     @unittest.skipUnless(util.abstract_sockets_supported,
                          "test needs abstract socket support")
     def test_abstract_socket(self):
@@ -3933,6 +3957,21 @@ def _new_shm_name(self, prefix):
         # test_multiprocessing_spawn, etc) in parallel.
         return prefix + str(os.getpid())
 
+    def test_shared_memory_name_with_embedded_null(self):
+        name_tsmb = self._new_shm_name('test01_null')
+        sms = shared_memory.SharedMemory(name_tsmb, create=True, size=512)
+        self.addCleanup(sms.unlink)
+        with self.assertRaises(ValueError):
+            shared_memory.SharedMemory(name_tsmb + '\0a', create=False, size=512)
+        if shared_memory._USE_POSIX:
+            orig_name = sms._name
+            try:
+                sms._name = orig_name + '\0a'
+                with self.assertRaises(ValueError):
+                    sms.unlink()
+            finally:
+                sms._name = orig_name
+
     def test_shared_memory_basics(self):
         name_tsmb = self._new_shm_name('test01_tsmb')
         sms = shared_memory.SharedMemory(name_tsmb, create=True, size=512)
@@ -4067,7 +4106,7 @@ def test_shared_memory_recreate(self):
             self.addCleanup(shm2.unlink)
             self.assertEqual(shm2._name, names[1])
 
-    def test_invalid_shared_memory_cration(self):
+    def test_invalid_shared_memory_creation(self):
         # Test creating a shared memory segment with negative size
         with self.assertRaises(ValueError):
             sms_invalid = shared_memory.SharedMemory(create=True, size=-1)
diff --git a/Lib/test/bisect_cmd.py b/Lib/test/bisect_cmd.py
index 5cb804bd46..aee2e8ac12 100755
--- a/Lib/test/bisect_cmd.py
+++ b/Lib/test/bisect_cmd.py
@@ -51,6 +51,7 @@ def python_cmd():
     cmd = [sys.executable]
     cmd.extend(subprocess._args_from_interpreter_flags())
     cmd.extend(subprocess._optim_args_from_interpreter_flags())
+    cmd.extend(('-X', 'faulthandler'))
     return cmd
 
 
@@ -77,9 +78,13 @@ def run_tests(args, tests, huntrleaks=None):
         write_tests(tmp, tests)
 
         cmd = python_cmd()
-        cmd.extend(['-m', 'test', '--matchfile', tmp])
+        cmd.extend(['-u', '-m', 'test', '--matchfile', tmp])
         cmd.extend(args.test_args)
         print("+ %s" % format_shell_args(cmd))
+
+        sys.stdout.flush()
+        sys.stderr.flush()
+
         proc = subprocess.run(cmd)
         return proc.returncode
     finally:
@@ -137,8 +142,8 @@ def main():
             ntest = max(ntest // 2, 1)
             subtests = random.sample(tests, ntest)
 
-            print("[+] Iteration %s: run %s tests/%s"
-                  % (iteration, len(subtests), len(tests)))
+            print(f"[+] Iteration {iteration}/{args.max_iter}: "
+                  f"run {len(subtests)} tests/{len(tests)}")
             print()
 
             exitcode = run_tests(args, subtests)
@@ -170,10 +175,10 @@ def main():
     if len(tests) <= args.max_tests:
         print("Bisection completed in %s iterations and %s"
               % (iteration, datetime.timedelta(seconds=dt)))
-        sys.exit(1)
     else:
         print("Bisection failed after %s iterations and %s"
               % (iteration, datetime.timedelta(seconds=dt)))
+        sys.exit(1)
 
 
 if __name__ == "__main__":
diff --git a/Lib/test/libregrtest/cmdline.py b/Lib/test/libregrtest/cmdline.py
index 23ca356566..03c83953ce 100644
--- a/Lib/test/libregrtest/cmdline.py
+++ b/Lib/test/libregrtest/cmdline.py
@@ -164,6 +164,7 @@ def __init__(self, **kwargs) -> None:
         self.match_tests: TestFilter = []
         self.pgo = False
         self.pgo_extended = False
+        self.tsan = False
         self.worker_json = None
         self.start = None
         self.timeout = None
@@ -172,6 +173,7 @@ def __init__(self, **kwargs) -> None:
         self.fail_rerun = False
         self.tempdir = None
         self._add_python_opts = True
+        self.xmlpath = None
 
         super().__init__(**kwargs)
 
@@ -333,6 +335,8 @@ def _create_parser():
                        help='enable Profile Guided Optimization (PGO) training')
     group.add_argument('--pgo-extended', action='store_true',
                        help='enable extended PGO training (slower training)')
+    group.add_argument('--tsan', dest='tsan', action='store_true',
+                       help='run a subset of test cases that are proper for the TSAN test')
     group.add_argument('--fail-env-changed', action='store_true',
                        help='if a test file alters the environment, mark '
                             'the test as failed')
@@ -347,6 +351,8 @@ def _create_parser():
                        help='override the working directory for the test run')
     group.add_argument('--cleanup', action='store_true',
                        help='remove old test_python_* directories')
+    group.add_argument('--bisect', action='store_true',
+                       help='if some tests fail, run test.bisect_cmd on them')
     group.add_argument('--dont-add-python-opts', dest='_add_python_opts',
                        action='store_false',
                        help="internal option, don't use it")
@@ -494,17 +500,28 @@ def _parse_args(args, **kwargs):
         ns.randomize = True
     if ns.verbose:
         ns.header = True
+
     # When -jN option is used, a worker process does not use --verbose3
     # and so -R 3:3 -jN --verbose3 just works as expected: there is no false
     # alarm about memory leak.
     if ns.huntrleaks and ns.verbose3 and ns.use_mp is None:
-        ns.verbose3 = False
         # run_single_test() replaces sys.stdout with io.StringIO if verbose3
         # is true. In this case, huntrleaks sees an write into StringIO as
         # a memory leak, whereas it is not (gh-71290).
+        ns.verbose3 = False
         print("WARNING: Disable --verbose3 because it's incompatible with "
               "--huntrleaks without -jN option",
               file=sys.stderr)
+
+    if ns.huntrleaks and ns.xmlpath:
+        # The XML data is written into a file outside runtest_refleak(), so
+        # it looks like a leak but it's not. Simply disable XML output when
+        # hunting for reference leaks (gh-83434).
+        ns.xmlpath = None
+        print("WARNING: Disable --junit-xml because it's incompatible "
+              "with --huntrleaks",
+              file=sys.stderr)
+
     if ns.forever:
         # --forever implies --failfast
         ns.failfast = True
diff --git a/Lib/test/libregrtest/filter.py b/Lib/test/libregrtest/filter.py
index 817624d79e..41372e427f 100644
--- a/Lib/test/libregrtest/filter.py
+++ b/Lib/test/libregrtest/filter.py
@@ -27,6 +27,11 @@ def _is_full_match_test(pattern):
     return ('.' in pattern) and (not re.search(r'[?*\[\]]', pattern))
 
 
+def get_match_tests():
+    global _test_patterns
+    return _test_patterns
+
+
 def set_match_tests(patterns):
     global _test_matchers, _test_patterns
 
diff --git a/Lib/test/libregrtest/findtests.py b/Lib/test/libregrtest/findtests.py
index ee890b5b1d..4ac95e23a5 100644
--- a/Lib/test/libregrtest/findtests.py
+++ b/Lib/test/libregrtest/findtests.py
@@ -23,6 +23,7 @@
     "test_future_stmt",
     "test_gdb",
     "test_inspect",
+    "test_pydoc",
     "test_multiprocessing_fork",
     "test_multiprocessing_forkserver",
     "test_multiprocessing_spawn",
diff --git a/Lib/test/libregrtest/main.py b/Lib/test/libregrtest/main.py
index a9725fa967..e41646d2d1 100644
--- a/Lib/test/libregrtest/main.py
+++ b/Lib/test/libregrtest/main.py
@@ -6,8 +6,7 @@
 import sysconfig
 import time
 
-from test import support
-from test.support import os_helper, MS_WINDOWS
+from test.support import os_helper, MS_WINDOWS, flush_std_streams
 
 from .cmdline import _parse_args, Namespace
 from .findtests import findtests, split_test_packages, list_cases
@@ -18,6 +17,7 @@
 from .runtests import RunTests, HuntRefleak
 from .setup import setup_process, setup_test_dir
 from .single import run_single_test, PROGRESS_MIN_TIME
+from .tsan import setup_tsan_tests
 from .utils import (
     StrPath, StrJSON, TestName, TestList, TestTuple, TestFilter,
     strip_py_suffix, count, format_duration,
@@ -56,6 +56,7 @@ def __init__(self, ns: Namespace, _add_python_opts: bool = False):
         self.quiet: bool = ns.quiet
         self.pgo: bool = ns.pgo
         self.pgo_extended: bool = ns.pgo_extended
+        self.tsan: bool = ns.tsan
 
         # Test results
         self.results: TestResults = TestResults()
@@ -72,6 +73,7 @@ def __init__(self, ns: Namespace, _add_python_opts: bool = False):
         self.want_cleanup: bool = ns.cleanup
         self.want_rerun: bool = ns.rerun
         self.want_run_leaks: bool = ns.runleaks
+        self.want_bisect: bool = ns.bisect
 
         self.ci_mode: bool = (ns.fast_ci or ns.slow_ci)
         self.want_add_python_opts: bool = (_add_python_opts
@@ -182,6 +184,9 @@ def find_tests(self, tests: TestList | None = None) -> tuple[TestTuple, TestList
             # add default PGO tests if no tests are specified
             setup_pgo_tests(self.cmdline_args, self.pgo_extended)
 
+        if self.tsan:
+            setup_tsan_tests(self.cmdline_args)
+
         exclude_tests = set()
         if self.exclude:
             for arg in self.cmdline_args:
@@ -272,6 +277,55 @@ def rerun_failed_tests(self, runtests: RunTests):
 
         self.display_result(rerun_runtests)
 
+    def _run_bisect(self, runtests: RunTests, test: str, progress: str) -> bool:
+        print()
+        title = f"Bisect {test}"
+        if progress:
+            title = f"{title} ({progress})"
+        print(title)
+        print("#" * len(title))
+        print()
+
+        cmd = runtests.create_python_cmd()
+        cmd.extend([
+            "-u", "-m", "test.bisect_cmd",
+            # Limit to 25 iterations (instead of 100) to not abuse CI resources
+            "--max-iter", "25",
+            "-v",
+            # runtests.match_tests is not used (yet) for bisect_cmd -i arg
+        ])
+        cmd.extend(runtests.bisect_cmd_args())
+        cmd.append(test)
+        print("+", shlex.join(cmd), flush=True)
+
+        flush_std_streams()
+
+        import subprocess
+        proc = subprocess.run(cmd, timeout=runtests.timeout)
+        exitcode = proc.returncode
+
+        title = f"{title}: exit code {exitcode}"
+        print(title)
+        print("#" * len(title))
+        print(flush=True)
+
+        if exitcode:
+            print(f"Bisect failed with exit code {exitcode}")
+            return False
+
+        return True
+
+    def run_bisect(self, runtests: RunTests) -> None:
+        tests, _ = self.results.prepare_rerun(clear=False)
+
+        for index, name in enumerate(tests, 1):
+            if len(tests) > 1:
+                progress = f"{index}/{len(tests)}"
+            else:
+                progress = ""
+            if not self._run_bisect(runtests, name, progress):
+                return
+
     def display_result(self, runtests):
         # If running the test suite for PGO then no one cares about results.
         if runtests.pgo:
@@ -453,7 +507,7 @@ def _run_tests(self, selected: TestTuple, tests: TestList | None) -> int:
 
         setup_process()
 
-        if self.hunt_refleak and not self.num_workers:
+        if (runtests.hunt_refleak is not None) and (not self.num_workers):
             # gh-109739: WindowsLoadTracker thread interfers with refleak check
             use_load_tracker = False
         else:
@@ -473,6 +527,9 @@ def _run_tests(self, selected: TestTuple, tests: TestList | None) -> int:
 
             if self.want_rerun and self.results.need_rerun():
                 self.rerun_failed_tests(runtests)
+
+            if self.want_bisect and self.results.need_rerun():
+                self.run_bisect(runtests)
         finally:
             if use_load_tracker:
                 self.logger.stop_load_tracker()
diff --git a/Lib/test/libregrtest/refleak.py b/Lib/test/libregrtest/refleak.py
index 5836a8421c..7d1f608188 100644
--- a/Lib/test/libregrtest/refleak.py
+++ b/Lib/test/libregrtest/refleak.py
@@ -87,9 +87,12 @@ def get_pooled_int(value):
     rc_before = alloc_before = fd_before = interned_before = 0
 
     if not quiet:
-        print("beginning", repcount, "repetitions", file=sys.stderr)
-        print(("1234567890"*(repcount//10 + 1))[:repcount], file=sys.stderr,
-              flush=True)
+        print("beginning", repcount, "repetitions. Showing number of leaks "
+                "(. for 0 or less, X for 10 or more)",
+              file=sys.stderr)
+        numbers = ("1234567890"*(repcount//10 + 1))[:repcount]
+        numbers = numbers[:warmups] + ':' + numbers[warmups:]
+        print(numbers, file=sys.stderr, flush=True)
 
     results = None
     dash_R_cleanup(fs, ps, pic, zdc, abcs)
@@ -110,13 +113,27 @@ def get_pooled_int(value):
         rc_after = gettotalrefcount() - interned_after * 2
         fd_after = fd_count()
 
-        if not quiet:
-            print('.', end='', file=sys.stderr, flush=True)
-
         rc_deltas[i] = get_pooled_int(rc_after - rc_before)
         alloc_deltas[i] = get_pooled_int(alloc_after - alloc_before)
         fd_deltas[i] = get_pooled_int(fd_after - fd_before)
 
+        if not quiet:
+            # use max, not sum, so total_leaks is one of the pooled ints
+            total_leaks = max(rc_deltas[i], alloc_deltas[i], fd_deltas[i])
+            if total_leaks <= 0:
+                symbol = '.'
+            elif total_leaks < 10:
+                symbol = (
+                    '.', '1', '2', '3', '4', '5', '6', '7', '8', '9',
+                    )[total_leaks]
+            else:
+                symbol = 'X'
+            if i == warmups:
+                print(' ', end='', file=sys.stderr, flush=True)
+            print(symbol, end='', file=sys.stderr, flush=True)
+            del total_leaks
+            del symbol
+
         alloc_before = alloc_after
         rc_before = rc_after
         fd_before = fd_after
@@ -152,14 +169,20 @@ def check_fd_deltas(deltas):
     ]:
         # ignore warmup runs
         deltas = deltas[warmups:]
-        if checker(deltas):
+        failing = checker(deltas)
+        suspicious = any(deltas)
+        if failing or suspicious:
             msg = '%s leaked %s %s, sum=%s' % (
                 test_name, deltas, item_name, sum(deltas))
-            print(msg, file=sys.stderr, flush=True)
-            with open(filename, "a", encoding="utf-8") as refrep:
-                print(msg, file=refrep)
-                refrep.flush()
-            failed = True
+            print(msg, end='', file=sys.stderr)
+            if failing:
+                print(file=sys.stderr, flush=True)
+                with open(filename, "a", encoding="utf-8") as refrep:
+                    print(msg, file=refrep)
+                    refrep.flush()
+                failed = True
+            else:
+                print(' (this is fine)', file=sys.stderr, flush=True)
     return (failed, results)
 
 
diff --git a/Lib/test/libregrtest/results.py b/Lib/test/libregrtest/results.py
index 477de777f2..a1abe89f4c 100644
--- a/Lib/test/libregrtest/results.py
+++ b/Lib/test/libregrtest/results.py
@@ -129,7 +129,7 @@ def accumulate_result(self, result: TestResult, runtests: RunTests):
     def need_rerun(self):
         return bool(self.rerun_results)
 
-    def prepare_rerun(self) -> tuple[TestTuple, FilterDict]:
+    def prepare_rerun(self, *, clear: bool = True) -> tuple[TestTuple, FilterDict]:
         tests: TestList = []
         match_tests_dict = {}
         for result in self.rerun_results:
@@ -140,11 +140,12 @@ def prepare_rerun(self) -> tuple[TestTuple, FilterDict]:
             if match_tests:
                 match_tests_dict[result.test_name] = match_tests
 
-        # Clear previously failed tests
-        self.rerun_bad.extend(self.bad)
-        self.bad.clear()
-        self.env_changed.clear()
-        self.rerun_results.clear()
+        if clear:
+            # Clear previously failed tests
+            self.rerun_bad.extend(self.bad)
+            self.bad.clear()
+            self.env_changed.clear()
+            self.rerun_results.clear()
 
         return (tuple(tests), match_tests_dict)
 
diff --git a/Lib/test/libregrtest/run_workers.py b/Lib/test/libregrtest/run_workers.py
index 7d2c1cd84c..3083a873fc 100644
--- a/Lib/test/libregrtest/run_workers.py
+++ b/Lib/test/libregrtest/run_workers.py
@@ -209,7 +209,7 @@ def _run_process(self, runtests: WorkerRunTests, output_fd: int,
             self._popen = None
 
     def create_stdout(self, stack: contextlib.ExitStack) -> TextIO:
-        """Create stdout temporay file (file descriptor)."""
+        """Create stdout temporary file (file descriptor)."""
 
         if MS_WINDOWS:
             # gh-95027: When stdout is not a TTY, Python uses the ANSI code
diff --git a/Lib/test/libregrtest/runtests.py b/Lib/test/libregrtest/runtests.py
index 4bf2b1fb57..2116dec83e 100644
--- a/Lib/test/libregrtest/runtests.py
+++ b/Lib/test/libregrtest/runtests.py
@@ -2,7 +2,9 @@
 import dataclasses
 import json
 import os
+import shlex
 import subprocess
+import sys
 from typing import Any
 
 from test import support
@@ -67,6 +69,11 @@ class HuntRefleak:
     runs: int
     filename: StrPath
 
+    def bisect_cmd_args(self) -> list[str]:
+        # Ignore filename since it can contain colon (":"),
+        # and usually it's not used. Use the default filename.
+        return ["-R", f"{self.warmups}:{self.runs}:"]
+
 
 @dataclasses.dataclass(slots=True, frozen=True)
 class RunTests:
@@ -136,6 +143,47 @@ def json_file_use_stdout(self) -> bool:
             or support.is_wasi
         )
 
+    def create_python_cmd(self) -> list[str]:
+        python_opts = support.args_from_interpreter_flags()
+        if self.python_cmd is not None:
+            executable = self.python_cmd
+            # Remove -E option, since --python=COMMAND can set PYTHON
+            # environment variables, such as PYTHONPATH, in the worker
+            # process.
+            python_opts = [opt for opt in python_opts if opt != "-E"]
+        else:
+            executable = (sys.executable,)
+        cmd = [*executable, *python_opts]
+        if '-u' not in python_opts:
+            cmd.append('-u')  # Unbuffered stdout and stderr
+        return cmd
+
+    def bisect_cmd_args(self) -> list[str]:
+        args = []
+        if self.fail_fast:
+            args.append("--failfast")
+        if self.fail_env_changed:
+            args.append("--fail-env-changed")
+        if self.timeout:
+            args.append(f"--timeout={self.timeout}")
+        if self.hunt_refleak is not None:
+            args.extend(self.hunt_refleak.bisect_cmd_args())
+        if self.test_dir:
+            args.extend(("--testdir", self.test_dir))
+        if self.memory_limit:
+            args.extend(("--memlimit", self.memory_limit))
+        if self.gc_threshold:
+            args.append(f"--threshold={self.gc_threshold}")
+        if self.use_resources:
+            args.extend(("-u", ','.join(self.use_resources)))
+        if self.python_cmd:
+            cmd = shlex.join(self.python_cmd)
+            args.extend(("--python", cmd))
+        if self.randomize:
+            args.append(f"--randomize")
+        args.append(f"--randseed={self.random_seed}")
+        return args
+
 
 @dataclasses.dataclass(slots=True, frozen=True)
 class WorkerRunTests(RunTests):
diff --git a/Lib/test/libregrtest/tsan.py b/Lib/test/libregrtest/tsan.py
new file mode 100644
index 0000000000..99cef88e68
--- /dev/null
+++ b/Lib/test/libregrtest/tsan.py
@@ -0,0 +1,31 @@
+# Set of tests run by default if --tsan is specified.  The tests below were
+# chosen because they use threads and run in a reasonable amount of time.
+
+TSAN_TESTS = [
+    'test_capi',
+    'test_code',
+    'test_enum',
+    'test_functools',
+    'test_httpservers',
+    'test_imaplib',
+    'test_importlib',
+    'test_io',
+    'test_logging',
+    'test_queue',
+    'test_signal',
+    'test_socket',
+    'test_sqlite3',
+    'test_ssl',
+    'test_syslog',
+    'test_thread',
+    'test_threadedtempfile',
+    'test_threading',
+    'test_threading_local',
+    'test_threadsignals',
+    'test_weakref',
+]
+
+
+def setup_tsan_tests(cmdline_args):
+    if not cmdline_args:
+        cmdline_args[:] = TSAN_TESTS[:]
diff --git a/Lib/test/libregrtest/utils.py b/Lib/test/libregrtest/utils.py
index af61e4220e..25017e8717 100644
--- a/Lib/test/libregrtest/utils.py
+++ b/Lib/test/libregrtest/utils.py
@@ -276,6 +276,15 @@ def clear_caches():
         pass
     else:
         inspect._shadowed_dict_from_mro_tuple.cache_clear()
+        inspect._filesbymodname.clear()
+        inspect.modulesbyfile.clear()
+
+    try:
+        importlib_metadata = sys.modules['importlib.metadata']
+    except KeyError:
+        pass
+    else:
+        importlib_metadata.FastPath.__new__.cache_clear()
 
 
 def get_build_info():
@@ -340,6 +349,9 @@ def get_build_info():
     # --with-undefined-behavior-sanitizer
     if support.check_sanitizer(ub=True):
         sanitizers.append("UBSAN")
+    # --with-thread-sanitizer
+    if support.check_sanitizer(thread=True):
+        sanitizers.append("TSAN")
     if sanitizers:
         build.append('+'.join(sanitizers))
 
@@ -419,7 +431,7 @@ def get_work_dir(parent_dir: StrPath, worker: bool = False) -> StrPath:
     # the tests. The name of the dir includes the pid to allow parallel
     # testing (see the -j option).
     # Emscripten and WASI have stubbed getpid(), Emscripten has only
-    # milisecond clock resolution. Use randint() instead.
+    # millisecond clock resolution. Use randint() instead.
     if support.is_emscripten or support.is_wasi:
         nounce = random.randint(0, 1_000_000)
     else:
@@ -640,6 +652,7 @@ def display_header(use_resources: tuple[str, ...],
     asan = support.check_sanitizer(address=True)
     msan = support.check_sanitizer(memory=True)
     ubsan = support.check_sanitizer(ub=True)
+    tsan = support.check_sanitizer(thread=True)
     sanitizers = []
     if asan:
         sanitizers.append("address")
@@ -647,12 +660,15 @@ def display_header(use_resources: tuple[str, ...],
         sanitizers.append("memory")
     if ubsan:
         sanitizers.append("undefined behavior")
+    if tsan:
+        sanitizers.append("thread")
     if sanitizers:
         print(f"== sanitizers: {', '.join(sanitizers)}")
         for sanitizer, env_var in (
             (asan, "ASAN_OPTIONS"),
             (msan, "MSAN_OPTIONS"),
             (ubsan, "UBSAN_OPTIONS"),
+            (tsan, "TSAN_OPTIONS"),
         ):
             options= os.environ.get(env_var)
             if sanitizer and options is not None:
diff --git a/Lib/test/libregrtest/win_utils.py b/Lib/test/libregrtest/win_utils.py
index 5736cdfd3c..b51fde0af5 100644
--- a/Lib/test/libregrtest/win_utils.py
+++ b/Lib/test/libregrtest/win_utils.py
@@ -24,6 +24,10 @@ class WindowsLoadTracker():
     """
 
     def __init__(self):
+        # make __del__ not fail if pre-flight test fails
+        self._running = None
+        self._stopped = None
+
         # Pre-flight test for access to the performance data;
         # `PermissionError` will be raised if not allowed
         winreg.QueryInfoKey(winreg.HKEY_PERFORMANCE_DATA)
diff --git a/Lib/test/libregrtest/worker.py b/Lib/test/libregrtest/worker.py
index 581741f2b1..556706ee3a 100644
--- a/Lib/test/libregrtest/worker.py
+++ b/Lib/test/libregrtest/worker.py
@@ -3,7 +3,6 @@
 import os
 from typing import Any, NoReturn
 
-from test import support
 from test.support import os_helper
 
 from .setup import setup_process, setup_test_dir
@@ -19,21 +18,10 @@
 
 def create_worker_process(runtests: WorkerRunTests, output_fd: int,
                           tmp_dir: StrPath | None = None) -> subprocess.Popen:
-    python_cmd = runtests.python_cmd
     worker_json = runtests.as_json()
 
-    python_opts = support.args_from_interpreter_flags()
-    if python_cmd is not None:
-        executable = python_cmd
-        # Remove -E option, since --python=COMMAND can set PYTHON environment
-        # variables, such as PYTHONPATH, in the worker process.
-        python_opts = [opt for opt in python_opts if opt != "-E"]
-    else:
-        executable = (sys.executable,)
-    cmd = [*executable, *python_opts,
-           '-u',    # Unbuffered stdout and stderr
-           '-m', 'test.libregrtest.worker',
-           worker_json]
+    cmd = runtests.create_python_cmd()
+    cmd.extend(['-m', 'test.libregrtest.worker', worker_json])
 
     env = dict(os.environ)
     if tmp_dir is not None:
diff --git a/Lib/test/pydoc_mod.py b/Lib/test/pydoc_mod.py
deleted file mode 100644
index 80c287fb10..0000000000
--- a/Lib/test/pydoc_mod.py
+++ /dev/null
@@ -1,51 +0,0 @@
-"""This is a test module for test_pydoc"""
-
-from __future__ import print_function
-
-import types
-import typing
-
-__author__ = "Benjamin Peterson"
-__credits__ = "Nobody"
-__version__ = "1.2.3.4"
-__xyz__ = "X, Y and Z"
-
-class A:
-    """Hello and goodbye"""
-    def __init__():
-        """Wow, I have no function!"""
-        pass
-
-class B(object):
-    NO_MEANING: str = "eggs"
-    pass
-
-class C(object):
-    def say_no(self):
-        return "no"
-    def get_answer(self):
-        """ Return say_no() """
-        return self.say_no()
-    def is_it_true(self):
-        """ Return self.get_answer() """
-        return self.get_answer()
-    def __class_getitem__(self, item):
-        return types.GenericAlias(self, item)
-
-def doc_func():
-    """
-    This function solves all of the world's problems:
-    hunger
-    lack of Python
-    war
-    """
-
-def nodoc_func():
-    pass
-
-
-list_alias1 = typing.List[int]
-list_alias2 = list[int]
-c_alias = C[int]
-type_union1 = typing.Union[int, str]
-type_union2 = int | str
diff --git a/Lib/test/pydocfodder.py b/Lib/test/pydocfodder.py
deleted file mode 100644
index a3ef223124..0000000000
--- a/Lib/test/pydocfodder.py
+++ /dev/null
@@ -1,138 +0,0 @@
-"""Something just to look at via pydoc."""
-
-import types
-
-class A:
-    "A class."
-
-    def A_method(self):
-        "Method defined in A."
-    def AB_method(self):
-        "Method defined in A and B."
-    def AC_method(self):
-        "Method defined in A and C."
-    def AD_method(self):
-        "Method defined in A and D."
-    def ABC_method(self):
-        "Method defined in A, B and C."
-    def ABD_method(self):
-        "Method defined in A, B and D."
-    def ACD_method(self):
-        "Method defined in A, C and D."
-    def ABCD_method(self):
-        "Method defined in A, B, C and D."
-
-    def A_classmethod(cls, x):
-        "A class method defined in A."
-    A_classmethod = classmethod(A_classmethod)
-
-    def A_staticmethod():
-        "A static method defined in A."
-    A_staticmethod = staticmethod(A_staticmethod)
-
-    def _getx(self):
-        "A property getter function."
-    def _setx(self, value):
-        "A property setter function."
-    def _delx(self):
-        "A property deleter function."
-    A_property = property(fdel=_delx, fget=_getx, fset=_setx,
-                          doc="A sample property defined in A.")
-
-    A_int_alias = int
-
-class B(A):
-    "A class, derived from A."
-
-    def AB_method(self):
-        "Method defined in A and B."
-    def ABC_method(self):
-        "Method defined in A, B and C."
-    def ABD_method(self):
-        "Method defined in A, B and D."
-    def ABCD_method(self):
-        "Method defined in A, B, C and D."
-    def B_method(self):
-        "Method defined in B."
-    def BC_method(self):
-        "Method defined in B and C."
-    def BD_method(self):
-        "Method defined in B and D."
-    def BCD_method(self):
-        "Method defined in B, C and D."
-
-class C(A):
-    "A class, derived from A."
-
-    def AC_method(self):
-        "Method defined in A and C."
-    def ABC_method(self):
-        "Method defined in A, B and C."
-    def ACD_method(self):
-        "Method defined in A, C and D."
-    def ABCD_method(self):
-        "Method defined in A, B, C and D."
-    def BC_method(self):
-        "Method defined in B and C."
-    def BCD_method(self):
-        "Method defined in B, C and D."
-    def C_method(self):
-        "Method defined in C."
-    def CD_method(self):
-        "Method defined in C and D."
-
-class D(B, C):
-    """A class, derived from B and C.
-    """
-
-    def AD_method(self):
-        "Method defined in A and D."
-    def ABD_method(self):
-        "Method defined in A, B and D."
-    def ACD_method(self):
-        "Method defined in A, C and D."
-    def ABCD_method(self):
-        "Method defined in A, B, C and D."
-    def BD_method(self):
-        "Method defined in B and D."
-    def BCD_method(self):
-        "Method defined in B, C and D."
-    def CD_method(self):
-        "Method defined in C and D."
-    def D_method(self):
-        "Method defined in D."
-
-class FunkyProperties(object):
-    """From SF bug 472347, by Roeland Rengelink.
-
-    Property getters etc may not be vanilla functions or methods,
-    and this used to make GUI pydoc blow up.
-    """
-
-    def __init__(self):
-        self.desc = {'x':0}
-
-    class get_desc:
-        def __init__(self, attr):
-            self.attr = attr
-        def __call__(self, inst):
-            print('Get called', self, inst)
-            return inst.desc[self.attr]
-    class set_desc:
-        def __init__(self, attr):
-            self.attr = attr
-        def __call__(self, inst, val):
-            print('Set called', self, inst, val)
-            inst.desc[self.attr] = val
-    class del_desc:
-        def __init__(self, attr):
-            self.attr = attr
-        def __call__(self, inst):
-            print('Del called', self, inst)
-            del inst.desc[self.attr]
-
-    x = property(get_desc('x'), set_desc('x'), del_desc('x'), 'prop x')
-
-
-submodule = types.ModuleType(__name__ + '.submodule',
-    """A submodule, which should appear in its parent's summary""")
diff --git a/Lib/test/sortperf.py b/Lib/test/sortperf.py
deleted file mode 100644
index 14a9d827ed..0000000000
--- a/Lib/test/sortperf.py
+++ /dev/null
@@ -1,169 +0,0 @@
-"""Sort performance test.
-
-See main() for command line syntax.
-See tabulate() for output format.
-
-"""
-
-import sys
-import time
-import random
-import marshal
-import tempfile
-import os
-
-td = tempfile.gettempdir()
-
-def randfloats(n):
-    """Return a list of n random floats in [0, 1)."""
-    # Generating floats is expensive, so this writes them out to a file in
-    # a temp directory.  If the file already exists, it just reads them
-    # back in and shuffles them a bit.
-    fn = os.path.join(td, "rr%06d" % n)
-    try:
-        fp = open(fn, "rb")
-    except OSError:
-        r = random.random
-        result = [r() for i in range(n)]
-        try:
-            try:
-                fp = open(fn, "wb")
-                marshal.dump(result, fp)
-                fp.close()
-                fp = None
-            finally:
-                if fp:
-                    try:
-                        os.unlink(fn)
-                    except OSError:
-                        pass
-        except OSError as msg:
-            print("can't write", fn, ":", msg)
-    else:
-        result = marshal.load(fp)
-        fp.close()
-        # Shuffle it a bit...
-        for i in range(10):
-            i = random.randrange(n)
-            temp = result[:i]
-            del result[:i]
-            temp.reverse()
-            result.extend(temp)
-            del temp
-    assert len(result) == n
-    return result
-
-def flush():
-    sys.stdout.flush()
-
-def doit(L):
-    t0 = time.perf_counter()
-    L.sort()
-    t1 = time.perf_counter()
-    print("%6.2f" % (t1-t0), end=' ')
-    flush()
-
-def tabulate(r):
-    r"""Tabulate sort speed for lists of various sizes.
-
-    The sizes are 2**i for i in r (the argument, a list).
-
-    The output displays i, 2**i, and the time to sort arrays of 2**i
-    floating point numbers with the following properties:
-
-    *sort: random data
-    \sort: descending data
-    /sort: ascending data
-    3sort: ascending, then 3 random exchanges
-    +sort: ascending, then 10 random at the end
-    %sort: ascending, then randomly replace 1% of the elements w/ random values
-    ~sort: many duplicates
-    =sort: all equal
-    !sort: worst case scenario
-
-    """
-    cases = tuple([ch + "sort" for ch in r"*\/3+%~=!"])
-    fmt = ("%2s %7s" + " %6s"*len(cases))
-    print(fmt % (("i", "2**i") + cases))
-    for i in r:
-        n = 1 << i
-        L = randfloats(n)
-        print("%2d %7d" % (i, n), end=' ')
-        flush()
-        doit(L) # *sort
-        L.reverse()
-        doit(L) # \sort
-        doit(L) # /sort
-
-        # Do 3 random exchanges.
-        for dummy in range(3):
-            i1 = random.randrange(n)
-            i2 = random.randrange(n)
-            L[i1], L[i2] = L[i2], L[i1]
-        doit(L) # 3sort
-
-        # Replace the last 10 with random floats.
-        if n >= 10:
-            L[-10:] = [random.random() for dummy in range(10)]
-        doit(L) # +sort
-
-        # Replace 1% of the elements at random.
-        for dummy in range(n // 100):
-            L[random.randrange(n)] = random.random()
-        doit(L) # %sort
-
-        # Arrange for lots of duplicates.
-        if n > 4:
-            del L[4:]
-            L = L * (n // 4)
-            # Force the elements to be distinct objects, else timings can be
-            # artificially low.
-            L = list(map(lambda x: --x, L))
-        doit(L) # ~sort
-        del L
-
-        # All equal.  Again, force the elements to be distinct objects.
-        L = list(map(abs, [-0.5] * n))
-        doit(L) # =sort
-        del L
-
-        # This one looks like [3, 2, 1, 0, 0, 1, 2, 3].  It was a bad case
-        # for an older implementation of quicksort, which used the median
-        # of the first, last and middle elements as the pivot.
-        half = n // 2
-        L = list(range(half - 1, -1, -1))
-        L.extend(range(half))
-        # Force to float, so that the timings are comparable.  This is
-        # significantly faster if we leave them as ints.
-        L = list(map(float, L))
-        doit(L) # !sort
-        print()
-
-def main():
-    """Main program when invoked as a script.
-
-    One argument: tabulate a single row.
-    Two arguments: tabulate a range (inclusive).
-    Extra arguments are used to seed the random generator.
-
-    """
-    # default range (inclusive)
-    k1 = 15
-    k2 = 20
-    if sys.argv[1:]:
-        # one argument: single point
-        k1 = k2 = int(sys.argv[1])
-        if sys.argv[2:]:
-            # two arguments: specify range
-            k2 = int(sys.argv[2])
-            if sys.argv[3:]:
-                # derive random seed from remaining arguments
-                x = 1
-                for a in sys.argv[3:]:
-                    x = 69069 * x + hash(a)
-                random.seed(x)
-    r = range(k1, k2+1)                 # include the end point
-    tabulate(r)
-
-if __name__ == '__main__':
-    main()
diff --git a/Lib/test/support/__init__.py b/Lib/test/support/__init__.py
index 8c4b4e023f..4e793f1549 100644
--- a/Lib/test/support/__init__.py
+++ b/Lib/test/support/__init__.py
@@ -391,10 +391,10 @@ def skip_if_buildbot(reason=None):
         isbuildbot = False
     return unittest.skipIf(isbuildbot, reason)
 
-def check_sanitizer(*, address=False, memory=False, ub=False):
+def check_sanitizer(*, address=False, memory=False, ub=False, thread=False):
     """Returns True if Python is compiled with sanitizer support"""
-    if not (address or memory or ub):
-        raise ValueError('At least one of address, memory, or ub must be True')
+    if not (address or memory or ub or thread):
+        raise ValueError('At least one of address, memory, ub or thread must be True')
 
 
     cflags = sysconfig.get_config_var('CFLAGS') or ''
@@ -411,18 +411,23 @@ def check_sanitizer(*, address=False, memory=False, ub=False):
         '-fsanitize=undefined' in cflags or
         '--with-undefined-behavior-sanitizer' in config_args
     )
+    thread_sanitizer = (
+        '-fsanitize=thread' in cflags or
+        '--with-thread-sanitizer' in config_args
+    )
     return (
         (memory and memory_sanitizer) or
         (address and address_sanitizer) or
-        (ub and ub_sanitizer)
+        (ub and ub_sanitizer) or
+        (thread and thread_sanitizer)
     )
 
 
-def skip_if_sanitizer(reason=None, *, address=False, memory=False, ub=False):
+def skip_if_sanitizer(reason=None, *, address=False, memory=False, ub=False, thread=False):
     """Decorator raising SkipTest if running with a sanitizer active."""
     if not reason:
         reason = 'not working with sanitizers active'
-    skip = check_sanitizer(address=address, memory=memory, ub=ub)
+    skip = check_sanitizer(address=address, memory=memory, ub=ub, thread=thread)
     return unittest.skipIf(skip, reason)
 
 # gh-89363: True if fork() can hang if Python is built with Address Sanitizer
@@ -431,7 +436,7 @@ def skip_if_sanitizer(reason=None, *, address=False, memory=False, ub=False):
 
 
 def set_sanitizer_env_var(env, option):
-    for name in ('ASAN_OPTIONS', 'MSAN_OPTIONS', 'UBSAN_OPTIONS'):
+    for name in ('ASAN_OPTIONS', 'MSAN_OPTIONS', 'UBSAN_OPTIONS', 'TSAN_OPTIONS'):
         if name in env:
             env[name] += f':{option}'
         else:
@@ -2112,13 +2117,13 @@ def set_recursion_limit(limit):
     finally:
         sys.setrecursionlimit(original_limit)
 
-def infinite_recursion(max_depth=100):
-    """Set a lower limit for tests that interact with infinite recursions
-    (e.g test_ast.ASTHelpers_Test.test_recursion_direct) since on some
-    debug windows builds, due to not enough functions being inlined the
-    stack size might not handle the default recursion limit (1000). See
-    bpo-11105 for details."""
-    if max_depth < 3:
+def infinite_recursion(max_depth=None):
+    if max_depth is None:
+        # Pick a number large enough to cause problems
+        # but not take too long for code that can handle
+        # very deep recursion.
+        max_depth = 20_000
+    elif max_depth < 3:
         raise ValueError("max_depth must be at least 3, got {max_depth}")
     depth = get_recursion_depth()
     depth = max(depth - 1, 1)  # Ignore infinite_recursion() frame.
@@ -2362,7 +2367,22 @@ def adjust_int_max_str_digits(max_digits):
 EXCEEDS_RECURSION_LIMIT = 5000
 
 # The default C recursion limit (from Include/cpython/pystate.h).
-C_RECURSION_LIMIT = 1500
+if Py_DEBUG:
+    if is_wasi:
+        C_RECURSION_LIMIT = 150
+    else:
+        C_RECURSION_LIMIT = 500
+else:
+    if is_wasi:
+        C_RECURSION_LIMIT = 500
+    elif hasattr(os, 'uname') and os.uname().machine == 's390x':
+        C_RECURSION_LIMIT = 800
+    elif sys.platform.startswith('win'):
+        C_RECURSION_LIMIT = 3000
+    elif check_sanitizer(address=True):
+        C_RECURSION_LIMIT = 4000
+    else:
+        C_RECURSION_LIMIT = 10000
 
 #Windows doesn't have os.uname() but it doesn't support s390x.
 skip_on_s390x = unittest.skipIf(hasattr(os, 'uname') and os.uname().machine == 's390x',
diff --git a/Lib/test/support/import_helper.py b/Lib/test/support/import_helper.py
index 3d804f2b59..29c6f535b4 100644
--- a/Lib/test/support/import_helper.py
+++ b/Lib/test/support/import_helper.py
@@ -268,6 +268,18 @@ def modules_cleanup(oldmodules):
     sys.modules.update(oldmodules)
 
 
+@contextlib.contextmanager
+def isolated_modules():
+    """
+    Save modules on entry and cleanup on exit.
+    """
+    (saved,) = modules_setup()
+    try:
+        yield
+    finally:
+        modules_cleanup(saved)
+
+
 def mock_register_at_fork(func):
     # bpo-30599: Mock os.register_at_fork() when importing the random module,
     # since this function doesn't allow to unregister callbacks and would leak
diff --git a/Lib/test/support/script_helper.py b/Lib/test/support/script_helper.py
index c2b43f4060..565f3b54a0 100644
--- a/Lib/test/support/script_helper.py
+++ b/Lib/test/support/script_helper.py
@@ -64,8 +64,8 @@ class _PythonRunResult(collections.namedtuple("_PythonRunResult",
     """Helper for reporting Python subprocess run results"""
     def fail(self, cmd_line):
         """Provide helpful details about failed subcommand runs"""
-        # Limit to 80 lines to ASCII characters
-        maxlen = 80 * 100
+        # Limit to 300 lines of ASCII characters
+        maxlen = 300 * 100
         out, err = self.out, self.err
         if len(out) > maxlen:
             out = b'(... truncated stdout ...)' + out[-maxlen:]
diff --git a/Lib/test/test__xxsubinterpreters.py b/Lib/test/test__xxsubinterpreters.py
index 1ee18774d1..e8a386c0e6 100644
--- a/Lib/test/test__xxsubinterpreters.py
+++ b/Lib/test/test__xxsubinterpreters.py
@@ -7,14 +7,13 @@
 import threading
 import unittest
 
-import _testcapi
 from test import support
 from test.support import import_helper
 from test.support import script_helper
 
 
 interpreters = import_helper.import_module('_xxsubinterpreters')
-
+_testcapi = import_helper.import_module('_testcapi')
 
 ##################################
 # helpers
diff --git a/Lib/test/test_argparse.py b/Lib/test/test_argparse.py
index 88cc62a4cd..940c93bcb0 100644
--- a/Lib/test/test_argparse.py
+++ b/Lib/test/test_argparse.py
@@ -2210,6 +2210,34 @@ def test_parse_known_args(self):
             (NS(foo=False, bar=0.5, w=7, x='b'), ['-W', '-X', 'Y', 'Z']),
         )
 
+    def test_parse_known_args_with_single_dash_option(self):
+        parser = ErrorRaisingArgumentParser()
+        parser.add_argument('-k', '--known', action='count', default=0)
+        parser.add_argument('-n', '--new', action='count', default=0)
+        self.assertEqual(parser.parse_known_args(['-k', '-u']),
+                         (NS(known=1, new=0), ['-u']))
+        self.assertEqual(parser.parse_known_args(['-u', '-k']),
+                         (NS(known=1, new=0), ['-u']))
+        self.assertEqual(parser.parse_known_args(['-ku']),
+                         (NS(known=1, new=0), ['-u']))
+        self.assertArgumentParserError(parser.parse_known_args, ['-k=u'])
+        self.assertEqual(parser.parse_known_args(['-uk']),
+                         (NS(known=0, new=0), ['-uk']))
+        self.assertEqual(parser.parse_known_args(['-u=k']),
+                         (NS(known=0, new=0), ['-u=k']))
+        self.assertEqual(parser.parse_known_args(['-kunknown']),
+                         (NS(known=1, new=0), ['-unknown']))
+        self.assertArgumentParserError(parser.parse_known_args, ['-k=unknown'])
+        self.assertEqual(parser.parse_known_args(['-ku=nknown']),
+                         (NS(known=1, new=0), ['-u=nknown']))
+        self.assertEqual(parser.parse_known_args(['-knew']),
+                         (NS(known=1, new=1), ['-ew']))
+        self.assertArgumentParserError(parser.parse_known_args, ['-kn=ew'])
+        self.assertArgumentParserError(parser.parse_known_args, ['-k-new'])
+        self.assertArgumentParserError(parser.parse_known_args, ['-kn-ew'])
+        self.assertEqual(parser.parse_known_args(['-kne-w']),
+                         (NS(known=1, new=1), ['-e-w']))
+
     def test_dest(self):
         parser = ErrorRaisingArgumentParser()
         parser.add_argument('--foo', action='store_true')
@@ -2769,6 +2797,27 @@ def test_help(self):
               '''
         self.assertEqual(parser.format_help(), textwrap.dedent(expected))
 
+    def test_help_subparser_all_mutually_exclusive_group_members_suppressed(self):
+        self.maxDiff = None
+        parser = ErrorRaisingArgumentParser(prog='PROG')
+        commands = parser.add_subparsers(title="commands", dest="command")
+        cmd_foo = commands.add_parser("foo")
+        group = cmd_foo.add_mutually_exclusive_group()
+        group.add_argument('--verbose', action='store_true', help=argparse.SUPPRESS)
+        group.add_argument('--quiet', action='store_true', help=argparse.SUPPRESS)
+        longopt = '--' + 'long'*32
+        longmeta = 'LONG'*32
+        cmd_foo.add_argument(longopt)
+        expected = f'''\
+            usage: PROG foo [-h]
+                            [{longopt} {longmeta}]
+
+            options:
+              -h, --help            show this help message and exit
+              {longopt} {longmeta}
+              '''
+        self.assertEqual(cmd_foo.format_help(), textwrap.dedent(expected))
+
     def test_empty_group(self):
         # See issue 26952
         parser = argparse.ArgumentParser()
diff --git a/Lib/test/test_ast.py b/Lib/test/test_ast.py
index 3ba7cf7b04..a357fbfd22 100644
--- a/Lib/test/test_ast.py
+++ b/Lib/test/test_ast.py
@@ -1007,19 +1007,15 @@ def test_positional_only_feature_version(self):
         with self.assertRaises(SyntaxError):
             ast.parse('lambda x=1, /: ...', feature_version=(3, 7))
 
-    def test_parenthesized_with_feature_version(self):
-        ast.parse('with (CtxManager() as example): ...', feature_version=(3, 10))
-        # While advertised as a feature in Python 3.10, this was allowed starting 3.9
-        ast.parse('with (CtxManager() as example): ...', feature_version=(3, 9))
-        with self.assertRaises(SyntaxError):
-            ast.parse('with (CtxManager() as example): ...', feature_version=(3, 8))
-        ast.parse('with CtxManager() as example: ...', feature_version=(3, 8))
-
     def test_assignment_expression_feature_version(self):
         ast.parse('(x := 0)', feature_version=(3, 8))
         with self.assertRaises(SyntaxError):
             ast.parse('(x := 0)', feature_version=(3, 7))
 
+    def test_conditional_context_managers_parse_with_low_feature_version(self):
+        # regression test for gh-115881
+        ast.parse('with (x() if y else z()): ...', feature_version=(3, 8))
+
     def test_exception_groups_feature_version(self):
         code = dedent('''
         try: ...
@@ -1087,9 +1083,9 @@ def next(self):
     @unittest.skipIf(support.is_wasi, "exhausts limited stack on WASI")
     @support.cpython_only
     def test_ast_recursion_limit(self):
-        fail_depth = support.EXCEEDS_RECURSION_LIMIT
+        fail_depth = support.C_RECURSION_LIMIT + 1
         crash_depth = 100_000
-        success_depth = 1200
+        success_depth = int(support.C_RECURSION_LIMIT * 0.9)
 
         def check_limit(prefix, repeated):
             expect_ok = prefix + repeated * success_depth
diff --git a/Lib/test/test_asyncio/test_base_events.py b/Lib/test/test_asyncio/test_base_events.py
index 85c8152d49..f3abe7aa9d 100644
--- a/Lib/test/test_asyncio/test_base_events.py
+++ b/Lib/test/test_asyncio/test_base_events.py
@@ -231,6 +231,22 @@ def test_set_default_executor_error(self):
 
         self.assertIsNone(self.loop._default_executor)
 
+    def test_shutdown_default_executor_timeout(self):
+        class DummyExecutor(concurrent.futures.ThreadPoolExecutor):
+            def shutdown(self, wait=True, *, cancel_futures=False):
+                if wait:
+                    time.sleep(0.1)
+
+        self.loop._process_events = mock.Mock()
+        self.loop._write_to_self = mock.Mock()
+        executor = DummyExecutor()
+        self.loop.set_default_executor(executor)
+
+        with self.assertWarnsRegex(RuntimeWarning,
+                                   "The executor did not finishing joining"):
+            self.loop.run_until_complete(
+                self.loop.shutdown_default_executor(timeout=0.01))
+
     def test_call_soon(self):
         def cb():
             pass
diff --git a/Lib/test/test_asyncio/test_events.py b/Lib/test/test_asyncio/test_events.py
index ddc45fd99b..f25580371a 100644
--- a/Lib/test/test_asyncio/test_events.py
+++ b/Lib/test/test_asyncio/test_events.py
@@ -1126,12 +1126,16 @@ def test_create_server_ssl_match_failed(self):
         # incorrect server_hostname
         f_c = self.loop.create_connection(MyProto, host, port,
                                           ssl=sslcontext_client)
+
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            IP address mismatch, certificate is not valid for '127.0.0.1'   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED                                       # AWS-LC
+        )""", re.X)
         with mock.patch.object(self.loop, 'call_exception_handler'):
             with test_utils.disable_logger():
-                with self.assertRaisesRegex(
-                        ssl.CertificateError,
-                        "IP address mismatch, certificate is not valid for "
-                        "'127.0.0.1'"):
+                with self.assertRaisesRegex(ssl.CertificateError, regex):
                     self.loop.run_until_complete(f_c)
 
         # close connection
@@ -1375,6 +1379,80 @@ def test_create_datagram_endpoint_sock(self):
         tr.close()
         self.loop.run_until_complete(pr.done)
 
+    def test_datagram_send_to_non_listening_address(self):
+        # see:
+        #   https://github.com/python/cpython/issues/91227
+        #   https://github.com/python/cpython/issues/88906
+        #   https://bugs.python.org/issue47071
+        #   https://bugs.python.org/issue44743
+        # The Proactor event loop would fail to receive datagram messages after
+        # sending a message to an address that wasn't listening.
+        loop = self.loop
+
+        class Protocol(asyncio.DatagramProtocol):
+
+            _received_datagram = None
+
+            def datagram_received(self, data, addr):
+                self._received_datagram.set_result(data)
+
+            async def wait_for_datagram_received(self):
+                self._received_datagram = loop.create_future()
+                result = await asyncio.wait_for(self._received_datagram, 10)
+                self._received_datagram = None
+                return result
+
+        def create_socket():
+            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+            sock.setblocking(False)
+            sock.bind(('127.0.0.1', 0))
+            return sock
+
+        socket_1 = create_socket()
+        transport_1, protocol_1 = loop.run_until_complete(
+            loop.create_datagram_endpoint(Protocol, sock=socket_1)
+        )
+        addr_1 = socket_1.getsockname()
+
+        socket_2 = create_socket()
+        transport_2, protocol_2 = loop.run_until_complete(
+            loop.create_datagram_endpoint(Protocol, sock=socket_2)
+        )
+        addr_2 = socket_2.getsockname()
+
+        # creating and immediately closing this to try to get an address that
+        # is not listening
+        socket_3 = create_socket()
+        transport_3, protocol_3 = loop.run_until_complete(
+            loop.create_datagram_endpoint(Protocol, sock=socket_3)
+        )
+        addr_3 = socket_3.getsockname()
+        transport_3.abort()
+
+        transport_1.sendto(b'a', addr=addr_2)
+        self.assertEqual(loop.run_until_complete(
+            protocol_2.wait_for_datagram_received()
+        ), b'a')
+
+        transport_2.sendto(b'b', addr=addr_1)
+        self.assertEqual(loop.run_until_complete(
+            protocol_1.wait_for_datagram_received()
+        ), b'b')
+
+        # this should send to an address that isn't listening
+        transport_1.sendto(b'c', addr=addr_3)
+        loop.run_until_complete(asyncio.sleep(0))
+
+        # transport 1 should still be able to receive messages after sending to
+        # an address that wasn't listening
+        transport_2.sendto(b'd', addr=addr_1)
+        self.assertEqual(loop.run_until_complete(
+            protocol_1.wait_for_datagram_received()
+        ), b'd')
+
+        transport_1.close()
+        transport_2.close()
+
     def test_internal_fds(self):
         loop = self.create_event_loop()
         if not isinstance(loop, selector_events.BaseSelectorEventLoop):
diff --git a/Lib/test/test_asyncio/test_sock_lowlevel.py b/Lib/test/test_asyncio/test_sock_lowlevel.py
index 075113cbe8..acef24a703 100644
--- a/Lib/test/test_asyncio/test_sock_lowlevel.py
+++ b/Lib/test/test_asyncio/test_sock_lowlevel.py
@@ -555,12 +555,93 @@ class SelectEventLoopTests(BaseSockTestsMixin,
         def create_event_loop(self):
             return asyncio.SelectorEventLoop()
 
+
     class ProactorEventLoopTests(BaseSockTestsMixin,
                                  test_utils.TestCase):
 
         def create_event_loop(self):
             return asyncio.ProactorEventLoop()
 
+
+        async def _basetest_datagram_send_to_non_listening_address(self,
+                                                                   recvfrom):
+            # see:
+            #   https://github.com/python/cpython/issues/91227
+            #   https://github.com/python/cpython/issues/88906
+            #   https://bugs.python.org/issue47071
+            #   https://bugs.python.org/issue44743
+            # The Proactor event loop would fail to receive datagram messages
+            # after sending a message to an address that wasn't listening.
+
+            def create_socket():
+                sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+                sock.setblocking(False)
+                sock.bind(('127.0.0.1', 0))
+                return sock
+
+            socket_1 = create_socket()
+            addr_1 = socket_1.getsockname()
+
+            socket_2 = create_socket()
+            addr_2 = socket_2.getsockname()
+
+            # creating and immediately closing this to try to get an address
+            # that is not listening
+            socket_3 = create_socket()
+            addr_3 = socket_3.getsockname()
+            socket_3.shutdown(socket.SHUT_RDWR)
+            socket_3.close()
+
+            socket_1_recv_task = self.loop.create_task(recvfrom(socket_1))
+            socket_2_recv_task = self.loop.create_task(recvfrom(socket_2))
+            await asyncio.sleep(0)
+
+            await self.loop.sock_sendto(socket_1, b'a', addr_2)
+            self.assertEqual(await socket_2_recv_task, b'a')
+
+            await self.loop.sock_sendto(socket_2, b'b', addr_1)
+            self.assertEqual(await socket_1_recv_task, b'b')
+            socket_1_recv_task = self.loop.create_task(recvfrom(socket_1))
+            await asyncio.sleep(0)
+
+            # this should send to an address that isn't listening
+            await self.loop.sock_sendto(socket_1, b'c', addr_3)
+            self.assertEqual(await socket_1_recv_task, b'')
+            socket_1_recv_task = self.loop.create_task(recvfrom(socket_1))
+            await asyncio.sleep(0)
+
+            # socket 1 should still be able to receive messages after sending
+            # to an address that wasn't listening
+            socket_2.sendto(b'd', addr_1)
+            self.assertEqual(await socket_1_recv_task, b'd')
+
+            socket_1.shutdown(socket.SHUT_RDWR)
+            socket_1.close()
+            socket_2.shutdown(socket.SHUT_RDWR)
+            socket_2.close()
+
+
+        def test_datagram_send_to_non_listening_address_recvfrom(self):
+            async def recvfrom(socket):
+                data, _ = await self.loop.sock_recvfrom(socket, 4096)
+                return data
+
+            self.loop.run_until_complete(
+                self._basetest_datagram_send_to_non_listening_address(
+                    recvfrom))
+
+
+        def test_datagram_send_to_non_listening_address_recvfrom_into(self):
+            async def recvfrom_into(socket):
+                buf = bytearray(4096)
+                length, _ = await self.loop.sock_recvfrom_into(socket, buf,
+                                                               4096)
+                return buf[:length]
+
+            self.loop.run_until_complete(
+                self._basetest_datagram_send_to_non_listening_address(
+                    recvfrom_into))
+
 else:
     import selectors
 
diff --git a/Lib/test/test_asyncio/test_waitfor.py b/Lib/test/test_asyncio/test_waitfor.py
index d52f32534a..11a8eeeab3 100644
--- a/Lib/test/test_asyncio/test_waitfor.py
+++ b/Lib/test/test_asyncio/test_waitfor.py
@@ -249,8 +249,8 @@ async def test_cancel_wait_for(self):
         await self._test_cancel_wait_for(60.0)
 
     async def test_wait_for_cancel_suppressed(self):
-        # GH-86296: Supressing CancelledError is discouraged
-        # but if a task subpresses CancelledError and returns a value,
+        # GH-86296: Suppressing CancelledError is discouraged
+        # but if a task suppresses CancelledError and returns a value,
         # `wait_for` should return the value instead of raising CancelledError.
         # This is the same behavior as `asyncio.timeout`.
 
diff --git a/Lib/test/test_asyncio/test_windows_events.py b/Lib/test/test_asyncio/test_windows_events.py
index 6e6c90a247..0c128c599b 100644
--- a/Lib/test/test_asyncio/test_windows_events.py
+++ b/Lib/test/test_asyncio/test_windows_events.py
@@ -36,7 +36,23 @@ def data_received(self, data):
             self.trans.close()
 
 
-class ProactorLoopCtrlC(test_utils.TestCase):
+class WindowsEventsTestCase(test_utils.TestCase):
+    def _unraisablehook(self, unraisable):
+        # Storing unraisable.object can resurrect an object which is being
+        # finalized. Storing unraisable.exc_value creates a reference cycle.
+        self._unraisable = unraisable
+        print(unraisable)
+
+    def setUp(self):
+        self._prev_unraisablehook = sys.unraisablehook
+        self._unraisable = None
+        sys.unraisablehook = self._unraisablehook
+
+    def tearDown(self):
+        sys.unraisablehook = self._prev_unraisablehook
+        self.assertIsNone(self._unraisable)
+
+class ProactorLoopCtrlC(WindowsEventsTestCase):
 
     def test_ctrl_c(self):
 
@@ -58,7 +74,7 @@ def SIGINT_after_delay():
         thread.join()
 
 
-class ProactorMultithreading(test_utils.TestCase):
+class ProactorMultithreading(WindowsEventsTestCase):
     def test_run_from_nonmain_thread(self):
         finished = False
 
@@ -79,7 +95,7 @@ def func():
         self.assertTrue(finished)
 
 
-class ProactorTests(test_utils.TestCase):
+class ProactorTests(WindowsEventsTestCase):
 
     def setUp(self):
         super().setUp()
@@ -283,8 +299,32 @@ async def probe():
 
         return "done"
 
-
-class WinPolicyTests(test_utils.TestCase):
+    def test_loop_restart(self):
+        # We're fishing for the "RuntimeError: <_overlapped.Overlapped object at XXX>
+        # still has pending operation at deallocation, the process may crash" error
+        stop = threading.Event()
+        def threadMain():
+            while not stop.is_set():
+                self.loop.call_soon_threadsafe(lambda: None)
+                time.sleep(0.01)
+        thr = threading.Thread(target=threadMain)
+
+        # In 10 60-second runs of this test prior to the fix:
+        # time in seconds until failure: (none), 15.0, 6.4, (none), 7.6, 8.3, 1.7, 22.2, 23.5, 8.3
+        # 10 seconds had a 50% failure rate but longer would be more costly
+        end_time = time.time() + 10 # Run for 10 seconds
+        self.loop.call_soon(thr.start)
+        while not self._unraisable: # Stop if we got an unraisable exc
+            self.loop.stop()
+            self.loop.run_forever()
+            if time.time() >= end_time:
+                break
+
+        stop.set()
+        thr.join()
+
+
+class WinPolicyTests(WindowsEventsTestCase):
 
     def test_selector_win_policy(self):
         async def main():
diff --git a/Lib/test/test_baseexception.py b/Lib/test/test_baseexception.py
index 4c3cf0b964..6dc06c5e4b 100644
--- a/Lib/test/test_baseexception.py
+++ b/Lib/test/test_baseexception.py
@@ -129,7 +129,7 @@ class Value(str):
 
         d[HashThisKeyWillClearTheDict()] = Value()  # refcount of Value() is 1 now
 
-        # Exception.__setstate__ should aquire a strong reference of key and
+        # Exception.__setstate__ should acquire a strong reference of key and
         # value in the dict. Otherwise, Value()'s refcount would go below
         # zero in the tp_hash call in PyObject_SetAttr(), and it would cause
         # crash in GC.
diff --git a/Lib/test/test_builtin.py b/Lib/test/test_builtin.py
index 4d03c46382..211dd89ea4 100644
--- a/Lib/test/test_builtin.py
+++ b/Lib/test/test_builtin.py
@@ -586,6 +586,14 @@ def __dir__(self):
         self.assertIsInstance(res, list)
         self.assertTrue(res == ["a", "b", "c"])
 
+        # dir(obj__dir__iterable)
+        class Foo(object):
+            def __dir__(self):
+                return {"b", "c", "a"}
+        res = dir(Foo())
+        self.assertIsInstance(res, list)
+        self.assertEqual(sorted(res), ["a", "b", "c"])
+
         # dir(obj__dir__not_sequence)
         class Foo(object):
             def __dir__(self):
diff --git a/Lib/test/test_bz2.py b/Lib/test/test_bz2.py
index 1f0b9adc36..772f0eacce 100644
--- a/Lib/test/test_bz2.py
+++ b/Lib/test/test_bz2.py
@@ -3,19 +3,19 @@
 
 import array
 import unittest
+import io
 from io import BytesIO, DEFAULT_BUFFER_SIZE
 import os
 import pickle
 import glob
 import tempfile
-import pathlib
 import random
 import shutil
 import subprocess
 import threading
 from test.support import import_helper
 from test.support import threading_helper
-from test.support.os_helper import unlink
+from test.support.os_helper import unlink, FakePath
 import _compression
 import sys
 
@@ -537,12 +537,136 @@ def testMultiStreamOrdering(self):
         with BZ2File(self.filename) as bz2f:
             self.assertEqual(bz2f.read(), data1 + data2)
 
+    def testOpenFilename(self):
+        with BZ2File(self.filename, "wb") as f:
+            f.write(b'content')
+            self.assertIsInstance(f.fileno(), int)
+            self.assertIs(f.readable(), False)
+            self.assertIs(f.writable(), True)
+            self.assertIs(f.seekable(), False)
+            self.assertIs(f.closed, False)
+        self.assertIs(f.closed, True)
+        self.assertRaises(ValueError, f.fileno)
+        self.assertRaises(ValueError, f.readable)
+        self.assertRaises(ValueError, f.writable)
+        self.assertRaises(ValueError, f.seekable)
+
+        with BZ2File(self.filename, "ab") as f:
+            f.write(b'appendix')
+            self.assertIsInstance(f.fileno(), int)
+            self.assertIs(f.readable(), False)
+            self.assertIs(f.writable(), True)
+            self.assertIs(f.seekable(), False)
+            self.assertIs(f.closed, False)
+        self.assertIs(f.closed, True)
+        self.assertRaises(ValueError, f.fileno)
+        self.assertRaises(ValueError, f.readable)
+        self.assertRaises(ValueError, f.writable)
+        self.assertRaises(ValueError, f.seekable)
+
+        with BZ2File(self.filename, 'rb') as f:
+            self.assertEqual(f.read(), b'contentappendix')
+            self.assertIsInstance(f.fileno(), int)
+            self.assertIs(f.readable(), True)
+            self.assertIs(f.writable(), False)
+            self.assertIs(f.seekable(), True)
+            self.assertIs(f.closed, False)
+        self.assertIs(f.closed, True)
+        with self.assertRaises(ValueError):
+            f.fileno()
+        self.assertRaises(ValueError, f.readable)
+        self.assertRaises(ValueError, f.writable)
+        self.assertRaises(ValueError, f.seekable)
+
+    def testOpenFileWithName(self):
+        with open(self.filename, 'wb') as raw:
+            with BZ2File(raw, 'wb') as f:
+                f.write(b'content')
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertIs(f.readable(), False)
+                self.assertIs(f.writable(), True)
+                self.assertIs(f.seekable(), False)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertRaises(ValueError, f.fileno)
+            self.assertRaises(ValueError, f.readable)
+            self.assertRaises(ValueError, f.writable)
+            self.assertRaises(ValueError, f.seekable)
+
+        with open(self.filename, 'ab') as raw:
+            with BZ2File(raw, 'ab') as f:
+                f.write(b'appendix')
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertIs(f.readable(), False)
+                self.assertIs(f.writable(), True)
+                self.assertIs(f.seekable(), False)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertRaises(ValueError, f.fileno)
+            self.assertRaises(ValueError, f.readable)
+            self.assertRaises(ValueError, f.writable)
+            self.assertRaises(ValueError, f.seekable)
+
+        with open(self.filename, 'rb') as raw:
+            with BZ2File(raw, 'rb') as f:
+                self.assertEqual(f.read(), b'contentappendix')
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertIs(f.readable(), True)
+                self.assertIs(f.writable(), False)
+                self.assertIs(f.seekable(), True)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            with self.assertRaises(ValueError):
+                f.fileno()
+            self.assertRaises(ValueError, f.readable)
+            self.assertRaises(ValueError, f.writable)
+            self.assertRaises(ValueError, f.seekable)
+
+    def testOpenFileWithoutName(self):
+        bio = BytesIO()
+        with BZ2File(bio, 'wb') as f:
+            f.write(b'content')
+            self.assertRaises(io.UnsupportedOperation, f.fileno)
+        self.assertRaises(ValueError, f.fileno)
+
+        with BZ2File(bio, 'ab') as f:
+            f.write(b'appendix')
+            self.assertRaises(io.UnsupportedOperation, f.fileno)
+        self.assertRaises(ValueError, f.fileno)
+
+        bio.seek(0)
+        with BZ2File(bio, 'rb') as f:
+            self.assertEqual(f.read(), b'contentappendix')
+            self.assertRaises(io.UnsupportedOperation, f.fileno)
+        with self.assertRaises(ValueError):
+            f.fileno()
+
+    def testOpenFileWithIntName(self):
+        fd = os.open(self.filename, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)
+        with open(fd, 'wb') as raw:
+            with BZ2File(raw, 'wb') as f:
+                f.write(b'content')
+                self.assertEqual(f.fileno(), raw.fileno())
+            self.assertRaises(ValueError, f.fileno)
+
+        fd = os.open(self.filename, os.O_WRONLY | os.O_CREAT | os.O_APPEND)
+        with open(fd, 'ab') as raw:
+            with BZ2File(raw, 'ab') as f:
+                f.write(b'appendix')
+                self.assertEqual(f.fileno(), raw.fileno())
+            self.assertRaises(ValueError, f.fileno)
+
+        fd = os.open(self.filename, os.O_RDONLY)
+        with open(fd, 'rb') as raw:
+            with BZ2File(raw, 'rb') as f:
+                self.assertEqual(f.read(), b'contentappendix')
+                self.assertEqual(f.fileno(), raw.fileno())
+            with self.assertRaises(ValueError):
+                f.fileno()
+
     def testOpenBytesFilename(self):
         str_filename = self.filename
-        try:
-            bytes_filename = str_filename.encode("ascii")
-        except UnicodeEncodeError:
-            self.skipTest("Temporary file name needs to be ASCII")
+        bytes_filename = os.fsencode(str_filename)
         with BZ2File(bytes_filename, "wb") as f:
             f.write(self.DATA)
         with BZ2File(bytes_filename, "rb") as f:
@@ -552,7 +676,7 @@ def testOpenBytesFilename(self):
             self.assertEqual(f.read(), self.DATA)
 
     def testOpenPathLikeFilename(self):
-        filename = pathlib.Path(self.filename)
+        filename = FakePath(self.filename)
         with BZ2File(filename, "wb") as f:
             f.write(self.DATA)
         with BZ2File(filename, "rb") as f:
diff --git a/Lib/test/test_call.py b/Lib/test/test_call.py
index ec8dc29d36..46abf40605 100644
--- a/Lib/test/test_call.py
+++ b/Lib/test/test_call.py
@@ -1,5 +1,5 @@
 import unittest
-from test.support import cpython_only, requires_limited_api, skip_on_s390x
+from test.support import cpython_only, requires_limited_api, skip_on_s390x, is_wasi, Py_DEBUG
 try:
     import _testcapi
 except ImportError:
@@ -932,6 +932,7 @@ def test_multiple_values(self):
 class TestRecursion(unittest.TestCase):
 
     @skip_on_s390x
+    @unittest.skipIf(is_wasi and Py_DEBUG, "requires deep stack")
     def test_super_deep(self):
 
         def recurse(n):
diff --git a/Lib/test/test_capi/test_long.py b/Lib/test/test_capi/test_long.py
index 8261cc3829..39fef24f80 100644
--- a/Lib/test/test_capi/test_long.py
+++ b/Lib/test/test_capi/test_long.py
@@ -400,6 +400,29 @@ def test_long_asvoidptr(self):
         self.assertRaises(OverflowError, asvoidptr, -2**1000)
         # CRASHES asvoidptr(NULL)
 
+    def test_long_aspid(self):
+        # Test PyLong_AsPid()
+        aspid = _testcapi.pylong_aspid
+        from _testcapi import SIZEOF_PID_T
+        bits = 8 * SIZEOF_PID_T
+        PID_T_MIN = -2**(bits-1)
+        PID_T_MAX = 2**(bits-1) - 1
+        # round trip (object -> long -> object)
+        for value in (PID_T_MIN, PID_T_MAX, -1, 0, 1, 1234):
+            with self.subTest(value=value):
+                self.assertEqual(aspid(value), value)
+
+        self.assertEqual(aspid(IntSubclass(42)), 42)
+        self.assertEqual(aspid(Index(42)), 42)
+        self.assertEqual(aspid(MyIndexAndInt()), 10)
+
+        self.assertRaises(OverflowError, aspid, PID_T_MIN - 1)
+        self.assertRaises(OverflowError, aspid, PID_T_MAX + 1)
+        self.assertRaises(TypeError, aspid, 1.0)
+        self.assertRaises(TypeError, aspid, b'2')
+        self.assertRaises(TypeError, aspid, '3')
+        self.assertRaises(SystemError, aspid, NULL)
+
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_capi/test_misc.py b/Lib/test/test_capi/test_misc.py
index 403c4e9681..37dff355b1 100644
--- a/Lib/test/test_capi/test_misc.py
+++ b/Lib/test/test_capi/test_misc.py
@@ -1773,6 +1773,7 @@ def test_py_config_isoloated_per_interpreter(self):
         # double checked at the time this test was written.
         config = _testinternalcapi.get_config()
         config['int_max_str_digits'] = 55555
+        config['parse_argv'] = 0
         _testinternalcapi.set_config(config)
         sub_value = _testinternalcapi.get_config()['int_max_str_digits']
         assert sub_value == 55555, sub_value
diff --git a/Lib/test/test_capi/test_structmembers.py b/Lib/test/test_capi/test_structmembers.py
index a294c3b13a..08ca1f8285 100644
--- a/Lib/test/test_capi/test_structmembers.py
+++ b/Lib/test/test_capi/test_structmembers.py
@@ -81,36 +81,22 @@ def _test_int_range(self, name, minval, maxval, *, hardlimit=None,
             self._test_warn(name, maxval+1, minval)
             self._test_warn(name, hardmaxval)
 
-        if indexlimit is None:
-            indexlimit = hardlimit
-        if not indexlimit:
+        if indexlimit is False:
             self.assertRaises(TypeError, setattr, ts, name, Index(minval))
             self.assertRaises(TypeError, setattr, ts, name, Index(maxval))
         else:
-            hardminindexval, hardmaxindexval = indexlimit
             self._test_write(name, Index(minval), minval)
-            if minval < hardminindexval:
-                self._test_write(name, Index(hardminindexval), hardminindexval)
-            if maxval < hardmaxindexval:
-                self._test_write(name, Index(maxval), maxval)
-            else:
-                self._test_write(name, Index(hardmaxindexval), hardmaxindexval)
-            self._test_overflow(name, Index(hardminindexval-1))
-            if name in ('T_UINT', 'T_ULONG'):
-                self.assertRaises(TypeError, setattr, self.ts, name,
-                                  Index(hardmaxindexval+1))
-                self.assertRaises(TypeError, setattr, self.ts, name,
-                                  Index(2**1000))
-            else:
-                self._test_overflow(name, Index(hardmaxindexval+1))
-                self._test_overflow(name, Index(2**1000))
+            self._test_write(name, Index(maxval), maxval)
+            self._test_overflow(name, Index(hardminval-1))
+            self._test_overflow(name, Index(hardmaxval+1))
+            self._test_overflow(name, Index(2**1000))
             self._test_overflow(name, Index(-2**1000))
-            if hardminindexval < minval and name != 'T_ULONGLONG':
-                self._test_warn(name, Index(hardminindexval))
-                self._test_warn(name, Index(minval-1))
-            if maxval < hardmaxindexval:
-                self._test_warn(name, Index(maxval+1))
-                self._test_warn(name, Index(hardmaxindexval))
+            if hardminval < minval:
+                self._test_warn(name, Index(hardminval))
+                self._test_warn(name, Index(minval-1), maxval)
+            if maxval < hardmaxval:
+                self._test_warn(name, Index(maxval+1), minval)
+                self._test_warn(name, Index(hardmaxval))
 
     def test_bool(self):
         ts = self.ts
@@ -138,14 +124,12 @@ def test_int(self):
         self._test_int_range('T_INT', INT_MIN, INT_MAX,
                              hardlimit=(LONG_MIN, LONG_MAX))
         self._test_int_range('T_UINT', 0, UINT_MAX,
-                             hardlimit=(LONG_MIN, ULONG_MAX),
-                             indexlimit=(LONG_MIN, LONG_MAX))
+                             hardlimit=(LONG_MIN, ULONG_MAX))
 
     def test_long(self):
         self._test_int_range('T_LONG', LONG_MIN, LONG_MAX)
         self._test_int_range('T_ULONG', 0, ULONG_MAX,
-                             hardlimit=(LONG_MIN, ULONG_MAX),
-                             indexlimit=(LONG_MIN, LONG_MAX))
+                             hardlimit=(LONG_MIN, ULONG_MAX))
 
     def test_py_ssize_t(self):
         self._test_int_range('T_PYSSIZET', PY_SSIZE_T_MIN, PY_SSIZE_T_MAX, indexlimit=False)
@@ -153,7 +137,7 @@ def test_py_ssize_t(self):
     def test_longlong(self):
         self._test_int_range('T_LONGLONG', LLONG_MIN, LLONG_MAX)
         self._test_int_range('T_ULONGLONG', 0, ULLONG_MAX,
-                             indexlimit=(LONG_MIN, LONG_MAX))
+                             hardlimit=(LONG_MIN, ULLONG_MAX))
 
     def test_bad_assignments(self):
         ts = self.ts
diff --git a/Lib/test/test_clinic.py b/Lib/test/test_clinic.py
index e81d3824e0..3a0ff940d6 100644
--- a/Lib/test/test_clinic.py
+++ b/Lib/test/test_clinic.py
@@ -21,6 +21,20 @@
     from clinic import DSLParser
 
 
+def restore_dict(converters, old_converters):
+    converters.clear()
+    converters.update(old_converters)
+
+
+def save_restore_converters(testcase):
+    testcase.addCleanup(restore_dict, clinic.converters,
+                        clinic.converters.copy())
+    testcase.addCleanup(restore_dict, clinic.legacy_converters,
+                        clinic.legacy_converters.copy())
+    testcase.addCleanup(restore_dict, clinic.return_converters,
+                        clinic.return_converters.copy())
+
+
 class _ParserBase(TestCase):
     maxDiff = None
 
@@ -107,6 +121,7 @@ def directive(self, name, args):
 
 class ClinicWholeFileTest(_ParserBase):
     def setUp(self):
+        save_restore_converters(self)
         self.clinic = clinic.Clinic(clinic.CLanguage(None), filename="test.c")
 
     def expect_failure(self, raw):
@@ -1369,6 +1384,9 @@ class ClinicExternalTest(TestCase):
     maxDiff = None
     clinic_py = os.path.join(test_tools.toolsdir, "clinic", "clinic.py")
 
+    def setUp(self):
+        save_restore_converters(self)
+
     def _do_test(self, *args, expect_success=True):
         with subprocess.Popen(
             [sys.executable, "-Xutf8", self.clinic_py, *args],
diff --git a/Lib/test/test_cmd_line.py b/Lib/test/test_cmd_line.py
index 9429800306..a7d2bb0e3d 100644
--- a/Lib/test/test_cmd_line.py
+++ b/Lib/test/test_cmd_line.py
@@ -38,6 +38,7 @@ def verify_valid_flag(self, cmd_line):
         self.assertNotIn(b'Traceback', err)
         return out
 
+    @support.cpython_only
     def test_help(self):
         self.verify_valid_flag('-h')
         self.verify_valid_flag('-?')
@@ -48,14 +49,17 @@ def test_help(self):
         self.assertNotIn(b'-X dev', out)
         self.assertLess(len(lines), 50)
 
+    @support.cpython_only
     def test_help_env(self):
         out = self.verify_valid_flag('--help-env')
         self.assertIn(b'PYTHONHOME', out)
 
+    @support.cpython_only
     def test_help_xoptions(self):
         out = self.verify_valid_flag('--help-xoptions')
         self.assertIn(b'-X dev', out)
 
+    @support.cpython_only
     def test_help_all(self):
         out = self.verify_valid_flag('--help-all')
         lines = out.splitlines()
@@ -74,6 +78,7 @@ def test_optimize(self):
     def test_site_flag(self):
         self.verify_valid_flag('-S')
 
+    @support.cpython_only
     def test_version(self):
         version = ('Python %d.%d' % sys.version_info[:2]).encode("ascii")
         for switch in '-V', '--version', '-VV':
@@ -139,6 +144,7 @@ def run_python(*args):
         else:
             self.assertEqual(err, b'')
 
+    @support.cpython_only
     def test_xoption_frozen_modules(self):
         tests = {
             ('=on', 'FrozenImporter'),
@@ -567,6 +573,7 @@ def test_del___main__(self):
             print("del sys.modules['__main__']", file=script)
         assert_python_ok(filename)
 
+    @support.cpython_only
     def test_unknown_options(self):
         rc, out, err = assert_python_failure('-E', '-z')
         self.assertIn(b'Unknown option: -z', err)
@@ -681,6 +688,7 @@ def run_xdev(self, *args, check_exitcode=True, xdev=True):
             self.assertEqual(proc.returncode, 0, proc)
         return proc.stdout.rstrip()
 
+    @support.cpython_only
     def test_xdev(self):
         # sys.flags.dev_mode
         code = "import sys; print(sys.flags.dev_mode)"
@@ -855,6 +863,7 @@ def test_argv0_normalization(self):
         self.assertEqual(proc.returncode, 0, proc)
         self.assertEqual(proc.stdout.strip(), b'0')
 
+    @support.cpython_only
     def test_parsing_error(self):
         args = [sys.executable, '-I', '--unknown-option']
         proc = subprocess.run(args,
diff --git a/Lib/test/test_compile.py b/Lib/test/test_compile.py
index 42df670fe0..6ed7fe2b06 100644
--- a/Lib/test/test_compile.py
+++ b/Lib/test/test_compile.py
@@ -607,9 +607,9 @@ def test_compiler_recursion_limit(self):
         # Expected limit is C_RECURSION_LIMIT * 2
         # Duplicating the limit here is a little ugly.
         # Perhaps it should be exposed somewhere...
-        fail_depth = C_RECURSION_LIMIT * 2 + 1
+        fail_depth = C_RECURSION_LIMIT + 1
         crash_depth = C_RECURSION_LIMIT * 100
-        success_depth = int(C_RECURSION_LIMIT * 1.8)
+        success_depth = int(C_RECURSION_LIMIT * 0.9)
 
         def check_limit(prefix, repeated, mode="single"):
             expect_ok = prefix + repeated * success_depth
@@ -722,7 +722,7 @@ def f():
                 return "unused"
 
         self.assertEqual(f.__code__.co_consts,
-                         ("docstring", "used"))
+                         (f.__doc__, "used"))
 
     @support.cpython_only
     def test_remove_unused_consts_no_docstring(self):
@@ -767,7 +767,7 @@ def test_strip_unused_None(self):
         def f1():
             "docstring"
             return 42
-        self.assertEqual(f1.__code__.co_consts, ("docstring", 42))
+        self.assertEqual(f1.__code__.co_consts, (f1.__doc__, 42))
 
     # This is a regression test for a CPython specific peephole optimizer
     # implementation bug present in a few releases.  It's assertion verifies
@@ -996,6 +996,8 @@ def no_code2():
 
         for func in (no_code1, no_code2):
             with self.subTest(func=func):
+                if func is no_code1 and no_code1.__doc__ is None:
+                    continue
                 code = func.__code__
                 [(start, end, line)] = code.co_lines()
                 self.assertEqual(start, 0)
@@ -1394,6 +1396,7 @@ def test_multiline_boolean_expression(self):
         self.assertOpcodeSourcePositionIs(compiled_code, 'POP_JUMP_IF_TRUE',
             line=4, end_line=4, column=8, end_column=13, occurrence=2)
 
+    @unittest.skipIf(sys.flags.optimize, "Assertions are disabled in optimized mode")
     def test_multiline_assert(self):
         snippet = textwrap.dedent("""\
             assert (a > 0 and
@@ -1409,7 +1412,7 @@ def test_multiline_assert(self):
         self.assertOpcodeSourcePositionIs(compiled_code, 'CALL',
             line=1, end_line=3, column=0, end_column=30, occurrence=1)
         self.assertOpcodeSourcePositionIs(compiled_code, 'RAISE_VARARGS',
-            line=1, end_line=3, column=0, end_column=30, occurrence=1)
+            line=1, end_line=3, column=8, end_column=16, occurrence=1)
 
     def test_multiline_generator_expression(self):
         snippet = textwrap.dedent("""\
diff --git a/Lib/test/test_concurrent_futures/test_shutdown.py b/Lib/test/test_concurrent_futures/test_shutdown.py
index 45dab7a75f..7a4065afd4 100644
--- a/Lib/test/test_concurrent_futures/test_shutdown.py
+++ b/Lib/test/test_concurrent_futures/test_shutdown.py
@@ -247,7 +247,9 @@ def test_cancel_futures_wait_false(self):
         # Errors in atexit hooks don't change the process exit code, check
         # stderr manually.
         self.assertFalse(err)
-        self.assertEqual(out.strip(), b"apple")
+        # gh-116682: stdout may be empty if shutdown happens before task
+        # starts executing.
+        self.assertIn(out.strip(), [b"apple", b""])
 
 
 class ProcessPoolShutdownTest(ExecutorShutdownTest):
diff --git a/Lib/test/test_concurrent_futures/util.py b/Lib/test/test_concurrent_futures/util.py
index dc48bec796..fc6030e375 100644
--- a/Lib/test/test_concurrent_futures/util.py
+++ b/Lib/test/test_concurrent_futures/util.py
@@ -85,6 +85,8 @@ def get_context(self):
             self.skipTest("ProcessPoolExecutor unavailable on this system")
         if sys.platform == "win32":
             self.skipTest("require unix system")
+        if support.check_sanitizer(thread=True):
+            self.skipTest("TSAN doesn't support threads after fork")
         return super().get_context()
 
 
@@ -111,6 +113,8 @@ def get_context(self):
             self.skipTest("ProcessPoolExecutor unavailable on this system")
         if sys.platform == "win32":
             self.skipTest("require unix system")
+        if support.check_sanitizer(thread=True):
+            self.skipTest("TSAN doesn't support threads after fork")
         return super().get_context()
 
 
diff --git a/Lib/test/test_configparser.py b/Lib/test/test_configparser.py
index 14e4a2cf14..5e6e57ad57 100644
--- a/Lib/test/test_configparser.py
+++ b/Lib/test/test_configparser.py
@@ -647,6 +647,21 @@ def test_weird_errors(self):
                                      "'opt' in section 'Bar' already exists")
             self.assertEqual(e.args, ("Bar", "opt", "<dict>", None))
 
+    def test_get_after_duplicate_option_error(self):
+        cf = self.newconfig()
+        ini = textwrap.dedent("""\
+            [Foo]
+            x{equals}1
+            y{equals}2
+            y{equals}3
+        """.format(equals=self.delimiters[0]))
+        if self.strict:
+            with self.assertRaises(configparser.DuplicateOptionError):
+                cf.read_string(ini)
+        else:
+            cf.read_string(ini)
+        self.assertEqual(cf.get('Foo', 'x'), '1')
+
     def test_write(self):
         config_string = (
             "[Long Line]\n"
diff --git a/Lib/test/test_cprofile.py b/Lib/test/test_cprofile.py
index 3056fe84da..27e8a76790 100644
--- a/Lib/test/test_cprofile.py
+++ b/Lib/test/test_cprofile.py
@@ -83,8 +83,8 @@ def test_throw(self):
 
         for func, (cc, nc, _, _, _) in pr.stats.items():
             if func[2] == "<genexpr>":
-                self.assertEqual(cc, 2)
-                self.assertEqual(nc, 2)
+                self.assertEqual(cc, 1)
+                self.assertEqual(nc, 1)
 
 
 class TestCommandLine(unittest.TestCase):
diff --git a/Lib/test/test_csv.py b/Lib/test/test_csv.py
index 30383698d0..adb89d0df9 100644
--- a/Lib/test/test_csv.py
+++ b/Lib/test/test_csv.py
@@ -46,6 +46,20 @@ def _test_arg_valid(self, ctor, arg):
                           quoting=csv.QUOTE_ALL, quotechar=None)
         self.assertRaises(TypeError, ctor, arg,
                           quoting=csv.QUOTE_NONE, quotechar='')
+        ctor(arg, delimiter=' ')
+        ctor(arg, escapechar=' ')
+        ctor(arg, quotechar=' ')
+        ctor(arg, delimiter='\t', skipinitialspace=True)
+        ctor(arg, escapechar='\t', skipinitialspace=True)
+        ctor(arg, quotechar='\t', skipinitialspace=True)
+        ctor(arg, delimiter=' ', skipinitialspace=True)
+        ctor(arg, delimiter='^')
+        ctor(arg, escapechar='^')
+        ctor(arg, quotechar='^')
+        ctor(arg, delimiter='\x85')
+        ctor(arg, escapechar='\x85')
+        ctor(arg, quotechar='\x85')
+        ctor(arg, lineterminator='\x85')
 
     def test_reader_arg_valid(self):
         self._test_arg_valid(csv.reader, [])
@@ -152,9 +166,6 @@ def _write_error_test(self, exc, fields, **kwargs):
 
     def test_write_arg_valid(self):
         self._write_error_test(csv.Error, None)
-        self._write_test((), '')
-        self._write_test([None], '""')
-        self._write_error_test(csv.Error, [None], quoting = csv.QUOTE_NONE)
         # Check that exceptions are passed up the chain
         self._write_error_test(OSError, BadIterable())
         class BadList:
@@ -168,7 +179,6 @@ class BadItem:
             def __str__(self):
                 raise OSError
         self._write_error_test(OSError, [BadItem()])
-
     def test_write_bigfield(self):
         # This exercises the buffer realloc functionality
         bigstring = 'X' * 50000
@@ -230,9 +240,11 @@ def test_write_lineterminator(self):
                     writer = csv.writer(sio, lineterminator=lineterminator)
                     writer.writerow(['a', 'b'])
                     writer.writerow([1, 2])
+                    writer.writerow(['\r', '\n'])
                     self.assertEqual(sio.getvalue(),
                                      f'a,b{lineterminator}'
-                                     f'1,2{lineterminator}')
+                                     f'1,2{lineterminator}'
+                                     f'"\r","\n"{lineterminator}')
 
     def test_write_iterable(self):
         self._write_test(iter(['a', 1, 'p,q']), 'a,1,"p,q"')
@@ -275,6 +287,49 @@ def test_writerows_with_none(self):
             fileobj.seek(0)
             self.assertEqual(fileobj.read(), 'a\r\n""\r\n')
 
+
+    def test_write_empty_fields(self):
+        self._write_test((), '')
+        self._write_test([''], '""')
+        self._write_error_test(csv.Error, [''], quoting=csv.QUOTE_NONE)
+        self._write_test([''], '""', quoting=csv.QUOTE_STRINGS)
+        self._write_test([''], '""', quoting=csv.QUOTE_NOTNULL)
+        self._write_test([None], '""')
+        self._write_error_test(csv.Error, [None], quoting=csv.QUOTE_NONE)
+        self._write_error_test(csv.Error, [None], quoting=csv.QUOTE_STRINGS)
+        self._write_error_test(csv.Error, [None], quoting=csv.QUOTE_NOTNULL)
+        self._write_test(['', ''], ',')
+        self._write_test([None, None], ',')
+
+    def test_write_empty_fields_space_delimiter(self):
+        self._write_test([''], '""', delimiter=' ', skipinitialspace=False)
+        self._write_test([''], '""', delimiter=' ', skipinitialspace=True)
+        self._write_test([None], '""', delimiter=' ', skipinitialspace=False)
+        self._write_test([None], '""', delimiter=' ', skipinitialspace=True)
+
+        self._write_test(['', ''], ' ', delimiter=' ', skipinitialspace=False)
+        self._write_test(['', ''], '"" ""', delimiter=' ', skipinitialspace=True)
+        self._write_test([None, None], ' ', delimiter=' ', skipinitialspace=False)
+        self._write_test([None, None], '"" ""', delimiter=' ', skipinitialspace=True)
+
+        self._write_test(['', ''], ' ', delimiter=' ', skipinitialspace=False,
+                         quoting=csv.QUOTE_NONE)
+        self._write_error_test(csv.Error, ['', ''],
+                               delimiter=' ', skipinitialspace=True,
+                               quoting=csv.QUOTE_NONE)
+        for quoting in csv.QUOTE_STRINGS, csv.QUOTE_NOTNULL:
+            self._write_test(['', ''], '"" ""', delimiter=' ', skipinitialspace=False,
+                             quoting=quoting)
+            self._write_test(['', ''], '"" ""', delimiter=' ', skipinitialspace=True,
+                             quoting=quoting)
+
+        for quoting in csv.QUOTE_NONE, csv.QUOTE_STRINGS, csv.QUOTE_NOTNULL:
+            self._write_test([None, None], ' ', delimiter=' ', skipinitialspace=False,
+                             quoting=quoting)
+            self._write_error_test(csv.Error, [None, None],
+                                   delimiter=' ', skipinitialspace=True,
+                                   quoting=quoting)
+
     def test_writerows_errors(self):
         with TemporaryFile("w+", encoding="utf-8", newline='') as fileobj:
             writer = csv.writer(fileobj)
@@ -376,6 +431,14 @@ def test_read_skipinitialspace(self):
                         [['no space', 'space', 'spaces', '\ttab']],
                         skipinitialspace=True)
 
+    def test_read_space_delimiter(self):
+        self._read_test(['a   b', '  a  ', '  ', ''],
+                        [['a', '', '', 'b'], ['', '', 'a', '', ''], ['', '', ''], []],
+                        delimiter=' ', skipinitialspace=False)
+        self._read_test(['a   b', '  a  ', '  ', ''],
+                        [['a', 'b'], ['a', ''], [''], []],
+                        delimiter=' ', skipinitialspace=True)
+
     def test_read_bigfield(self):
         # This exercises the buffer realloc functionality and field size
         # limits.
@@ -408,22 +471,44 @@ def test_read_linenum(self):
         self.assertEqual(r.line_num, 3)
 
     def test_roundtrip_quoteed_newlines(self):
-        with TemporaryFile("w+", encoding="utf-8", newline='') as fileobj:
-            writer = csv.writer(fileobj)
-            rows = [['a\nb','b'],['c','x\r\nd']]
-            writer.writerows(rows)
-            fileobj.seek(0)
-            for i, row in enumerate(csv.reader(fileobj)):
-                self.assertEqual(row, rows[i])
+        rows = [
+            ['\na', 'b\nc', 'd\n'],
+            ['\re', 'f\rg', 'h\r'],
+            ['\r\ni', 'j\r\nk', 'l\r\n'],
+            ['\n\rm', 'n\n\ro', 'p\n\r'],
+            ['\r\rq', 'r\r\rs', 't\r\r'],
+            ['\n\nu', 'v\n\nw', 'x\n\n'],
+        ]
+        for lineterminator in '\r\n', '\n', '\r':
+            with self.subTest(lineterminator=lineterminator):
+                with TemporaryFile("w+", encoding="utf-8", newline='') as fileobj:
+                    writer = csv.writer(fileobj, lineterminator=lineterminator)
+                    writer.writerows(rows)
+                    fileobj.seek(0)
+                    for i, row in enumerate(csv.reader(fileobj)):
+                        self.assertEqual(row, rows[i])
 
     def test_roundtrip_escaped_unquoted_newlines(self):
-        with TemporaryFile("w+", encoding="utf-8", newline='') as fileobj:
-            writer = csv.writer(fileobj,quoting=csv.QUOTE_NONE,escapechar="\\")
-            rows = [['a\nb','b'],['c','x\r\nd']]
-            writer.writerows(rows)
-            fileobj.seek(0)
-            for i, row in enumerate(csv.reader(fileobj,quoting=csv.QUOTE_NONE,escapechar="\\")):
-                self.assertEqual(row,rows[i])
+        rows = [
+            ['\na', 'b\nc', 'd\n'],
+            ['\re', 'f\rg', 'h\r'],
+            ['\r\ni', 'j\r\nk', 'l\r\n'],
+            ['\n\rm', 'n\n\ro', 'p\n\r'],
+            ['\r\rq', 'r\r\rs', 't\r\r'],
+            ['\n\nu', 'v\n\nw', 'x\n\n'],
+        ]
+        for lineterminator in '\r\n', '\n', '\r':
+            with self.subTest(lineterminator=lineterminator):
+                with TemporaryFile("w+", encoding="utf-8", newline='') as fileobj:
+                    writer = csv.writer(fileobj, lineterminator=lineterminator,
+                                        quoting=csv.QUOTE_NONE, escapechar="\\")
+                    writer.writerows(rows)
+                    fileobj.seek(0)
+                    for i, row in enumerate(csv.reader(fileobj,
+                                                       quoting=csv.QUOTE_NONE,
+                                                       escapechar="\\")):
+                        self.assertEqual(row, rows[i])
+
 
 class TestDialectRegistry(unittest.TestCase):
     def test_registry_badargs(self):
@@ -502,10 +587,10 @@ class space(csv.excel):
             escapechar = "\\"
 
         with TemporaryFile("w+", encoding="utf-8") as fileobj:
-            fileobj.write("abc def\nc1ccccc1 benzene\n")
+            fileobj.write("abc   def\nc1ccccc1 benzene\n")
             fileobj.seek(0)
             reader = csv.reader(fileobj, dialect=space())
-            self.assertEqual(next(reader), ["abc", "def"])
+            self.assertEqual(next(reader), ["abc", "", "", "def"])
             self.assertEqual(next(reader), ["c1ccccc1", "benzene"])
 
     def compare_dialect_123(self, expected, *writeargs, **kwwriteargs):
diff --git a/Lib/test/test_ctypes/test_callbacks.py b/Lib/test/test_ctypes/test_callbacks.py
index a9c6524b4d..2bfabeec7a 100644
--- a/Lib/test/test_ctypes/test_callbacks.py
+++ b/Lib/test/test_ctypes/test_callbacks.py
@@ -151,9 +151,10 @@ def callback(a, b):
             print(f"a={a}, b={b}, c={c}")
             return c
         dll = cdll[_ctypes_test.__file__]
-        # With no fix for i38748, the next line will raise OSError and cause the test to fail.
-        self.assertEqual(dll._test_i38748_runCallback(callback, 5, 10), 15)
-
+        with support.captured_stdout() as out:
+            # With no fix for i38748, the next line will raise OSError and cause the test to fail.
+            self.assertEqual(dll._test_i38748_runCallback(callback, 5, 10), 15)
+            self.assertEqual(out.getvalue(), "a=5, b=10, c=15\n")
 
 @need_symbol('WINFUNCTYPE')
 class StdcallCallbacks(Callbacks):
diff --git a/Lib/test/test_ctypes/test_loading.py b/Lib/test/test_ctypes/test_loading.py
index f2434926a5..0ecd2b4186 100644
--- a/Lib/test/test_ctypes/test_loading.py
+++ b/Lib/test/test_ctypes/test_loading.py
@@ -55,11 +55,15 @@ def test_load_version(self):
         self.assertRaises(OSError, cdll.LoadLibrary, self.unknowndll)
 
     def test_find(self):
+        found = False
         for name in ("c", "m"):
             lib = find_library(name)
             if lib:
+                found = True
                 cdll.LoadLibrary(lib)
                 CDLL(lib)
+        if not found:
+            self.skipTest("Could not find c and m libraries")
 
     @unittest.skipUnless(os.name == "nt",
                          'test specific to Windows')
diff --git a/Lib/test/test_dataclasses/__init__.py b/Lib/test/test_dataclasses/__init__.py
index 2b09db03d4..4e05506cf1 100644
--- a/Lib/test/test_dataclasses/__init__.py
+++ b/Lib/test/test_dataclasses/__init__.py
@@ -22,6 +22,8 @@
 import typing       # Needed for the string "typing.ClassVar[int]" to work as an annotation.
 import dataclasses  # Needed for the string "dataclasses.InitVar[int]" to work as an annotation.
 
+from test import support
+
 # Just any custom exception we can catch.
 class CustomError(Exception): pass
 
@@ -2216,6 +2218,7 @@ def assertDocStrEqual(self, a, b):
         #  whitespace stripped.
         self.assertEqual(a.replace(' ', ''), b.replace(' ', ''))
 
+    @support.requires_docstrings
     def test_existing_docstring_not_overridden(self):
         @dataclass
         class C:
@@ -3400,6 +3403,17 @@ class A(Base):
         self.assertIs(a.__weakref__, a_ref)
 
 
+    def test_dataclass_derived_weakref_slot(self):
+        class A:
+            pass
+
+        @dataclass(slots=True, weakref_slot=True)
+        class B(A):
+            pass
+
+        B()
+
+
 class TestDescriptors(unittest.TestCase):
     def test_set_name(self):
         # See bpo-33141.
diff --git a/Lib/test/test_decimal.py b/Lib/test/test_decimal.py
index 4d3ea73221..ea74f6c435 100644
--- a/Lib/test/test_decimal.py
+++ b/Lib/test/test_decimal.py
@@ -37,7 +37,8 @@
                           requires_legacy_unicode_capi, check_sanitizer)
 from test.support import (TestFailed,
                           run_with_locale, cpython_only,
-                          darwin_malloc_err_warning, is_emscripten)
+                          darwin_malloc_err_warning, is_emscripten,
+                          skip_on_s390x)
 from test.support.import_helper import import_fresh_module
 from test.support import threading_helper
 from test.support import warnings_helper
@@ -1121,6 +1122,13 @@ def test_formatting(self):
             ('z>z6.1f', '-0.', 'zzz0.0'),
             ('x>z6.1f', '-0.', 'xxx0.0'),
             ('>z6.1f', '-0.', '0.0'),  # multi-byte fill char
+            ('\x00>z6.1f', '-0.', '\x00\x00\x000.0'),  # null fill char
+
+            # issue 114563 ('z' format on F type in cdecimal)
+            ('z3,.10F', '-6.24E-323', '0.0000000000'),
+
+            # issue 91060 ('#' format in cdecimal)
+            ('#', '0', '0.'),
 
             # issue 6850
             ('a=-7.0', '0.12345', 'aaaa0.1'),
@@ -5647,6 +5655,9 @@ def __abs__(self):
     @unittest.skipIf(check_sanitizer(address=True, memory=True),
                      "ASAN/MSAN sanitizer defaults to crashing "
                      "instead of returning NULL for malloc failure.")
+    # gh-114331: The test allocates 784 271 641 GiB and mimalloc does not fail
+    # to allocate it when using mimalloc on s390x.
+    @skip_on_s390x
     def test_maxcontext_exact_arith(self):
 
         # Make sure that exact operations do not raise MemoryError due
@@ -5712,6 +5723,21 @@ def test_c_signaldict_segfault(self):
         with self.assertRaisesRegex(ValueError, err_msg):
             sd.copy()
 
+    def test_format_fallback_capitals(self):
+        # Fallback to _pydecimal formatting (triggered by `#` format which
+        # is unsupported by mpdecimal) should honor the current context.
+        x = C.Decimal('6.09e+23')
+        self.assertEqual(format(x, '#'), '6.09E+23')
+        with C.localcontext(capitals=0):
+            self.assertEqual(format(x, '#'), '6.09e+23')
+
+    def test_format_fallback_rounding(self):
+        y = C.Decimal('6.09')
+        self.assertEqual(format(y, '#.1f'), '6.1')
+        with C.localcontext(rounding=C.ROUND_DOWN):
+            self.assertEqual(format(y, '#.1f'), '6.0')
+
+
 @requires_docstrings
 @requires_cdecimal
 class SignatureTest(unittest.TestCase):
diff --git a/Lib/test/test_deque.py b/Lib/test/test_deque.py
index ae1dfacd72..4679f297fd 100644
--- a/Lib/test/test_deque.py
+++ b/Lib/test/test_deque.py
@@ -166,7 +166,7 @@ def test_contains(self):
         with self.assertRaises(RuntimeError):
             n in d
 
-    def test_contains_count_stop_crashes(self):
+    def test_contains_count_index_stop_crashes(self):
         class A:
             def __eq__(self, other):
                 d.clear()
@@ -178,6 +178,10 @@ def __eq__(self, other):
         with self.assertRaises(RuntimeError):
             _ = d.count(3)
 
+        d = deque([A()])
+        with self.assertRaises(RuntimeError):
+            d.index(0)
+
     def test_extend(self):
         d = deque('a')
         self.assertRaises(TypeError, d.extend, 1)
diff --git a/Lib/test/test_descr.py b/Lib/test/test_descr.py
index bf4b8f9572..a969f04b10 100644
--- a/Lib/test/test_descr.py
+++ b/Lib/test/test_descr.py
@@ -1594,7 +1594,11 @@ def f(cls, arg):
 
         cm = classmethod(f)
         cm_dict = {'__annotations__': {},
-                   '__doc__': "f docstring",
+                   '__doc__': (
+                       "f docstring"
+                       if support.HAVE_DOCSTRINGS
+                       else None
+                    ),
                    '__module__': __name__,
                    '__name__': 'f',
                    '__qualname__': f.__qualname__}
diff --git a/Lib/test/test_descrtut.py b/Lib/test/test_descrtut.py
index 7796031ed0..9ecc0e4d50 100644
--- a/Lib/test/test_descrtut.py
+++ b/Lib/test/test_descrtut.py
@@ -39,16 +39,16 @@ def merge(self, other):
 Here's the new type at work:
 
     >>> print(defaultdict)              # show our type
-    <class 'test.test_descrtut.defaultdict'>
+    <class '%(modname)s.defaultdict'>
     >>> print(type(defaultdict))        # its metatype
     <class 'type'>
     >>> a = defaultdict(default=0.0)    # create an instance
     >>> print(a)                        # show the instance
     {}
     >>> print(type(a))                  # show its type
-    <class 'test.test_descrtut.defaultdict'>
+    <class '%(modname)s.defaultdict'>
     >>> print(a.__class__)              # show its class
-    <class 'test.test_descrtut.defaultdict'>
+    <class '%(modname)s.defaultdict'>
     >>> print(type(a) is a.__class__)   # its type is its class
     True
     >>> a[1] = 3.25                     # modify the instance
@@ -99,7 +99,7 @@ def merge(self, other):
     >>> print(sortdict(a.__dict__))
     {'default': -1000, 'x1': 100, 'x2': 200}
     >>>
-"""
+""" % {'modname': __name__}
 
 class defaultdict2(dict):
     __slots__ = ['default']
@@ -264,19 +264,19 @@ def merge(self, other):
     ...         print("classmethod", cls, y)
 
     >>> C.foo(1)
-    classmethod <class 'test.test_descrtut.C'> 1
+    classmethod <class '%(modname)s.C'> 1
     >>> c = C()
     >>> c.foo(1)
-    classmethod <class 'test.test_descrtut.C'> 1
+    classmethod <class '%(modname)s.C'> 1
 
     >>> class D(C):
     ...     pass
 
     >>> D.foo(1)
-    classmethod <class 'test.test_descrtut.D'> 1
+    classmethod <class '%(modname)s.D'> 1
     >>> d = D()
     >>> d.foo(1)
-    classmethod <class 'test.test_descrtut.D'> 1
+    classmethod <class '%(modname)s.D'> 1
 
 This prints "classmethod __main__.D 1" both times; in other words, the
 class passed as the first argument of foo() is the class involved in the
@@ -292,18 +292,18 @@ class passed as the first argument of foo() is the class involved in the
 
     >>> E.foo(1)
     E.foo() called
-    classmethod <class 'test.test_descrtut.C'> 1
+    classmethod <class '%(modname)s.C'> 1
     >>> e = E()
     >>> e.foo(1)
     E.foo() called
-    classmethod <class 'test.test_descrtut.C'> 1
+    classmethod <class '%(modname)s.C'> 1
 
 In this example, the call to C.foo() from E.foo() will see class C as its
 first argument, not class E. This is to be expected, since the call
 specifies the class C. But it stresses the difference between these class
 methods and methods defined in metaclasses (where an upcall to a metamethod
 would pass the target class as an explicit first argument).
-"""
+""" % {'modname': __name__}
 
 test_5 = """
 
diff --git a/Lib/test/test_doctest/decorator_mod.py b/Lib/test/test_doctest/decorator_mod.py
new file mode 100644
index 0000000000..9f10688841
--- /dev/null
+++ b/Lib/test/test_doctest/decorator_mod.py
@@ -0,0 +1,10 @@
+# This module is used in `doctest_lineno.py`.
+import functools
+
+
+def decorator(f):
+    @functools.wraps(f)
+    def inner():
+        return f()
+
+    return inner
diff --git a/Lib/test/test_doctest/doctest_lineno.py b/Lib/test/test_doctest/doctest_lineno.py
index 677c569cf7..0dbcd9a11e 100644
--- a/Lib/test/test_doctest/doctest_lineno.py
+++ b/Lib/test/test_doctest/doctest_lineno.py
@@ -67,3 +67,12 @@ def property_with_doctest(self):
 
 # https://github.com/python/cpython/issues/99433
 str_wrapper = object().__str__
+
+
+# https://github.com/python/cpython/issues/115392
+from test.test_doctest.decorator_mod import decorator
+
+@decorator
+@decorator
+def func_with_docstring_wrapped():
+    """Some unrelated info."""
diff --git a/Lib/test/test_doctest/test_doctest.py b/Lib/test/test_doctest/test_doctest.py
index 21f27edc06..9c8a8ba690 100644
--- a/Lib/test/test_doctest/test_doctest.py
+++ b/Lib/test/test_doctest/test_doctest.py
@@ -686,6 +686,7 @@ def basics(): r"""
      None  test.test_doctest.doctest_lineno.MethodWrapper.method_without_docstring
        61  test.test_doctest.doctest_lineno.MethodWrapper.property_with_doctest
         4  test.test_doctest.doctest_lineno.func_with_docstring
+       77  test.test_doctest.doctest_lineno.func_with_docstring_wrapped
        12  test.test_doctest.doctest_lineno.func_with_doctest
      None  test.test_doctest.doctest_lineno.func_without_docstring
 
diff --git a/Lib/test/test_email/test__header_value_parser.py b/Lib/test/test_email/test__header_value_parser.py
index bdb0e55f21..f7e80749c4 100644
--- a/Lib/test/test_email/test__header_value_parser.py
+++ b/Lib/test/test_email/test__header_value_parser.py
@@ -2985,6 +2985,11 @@ def test_address_list_with_unicode_names_in_quotes(self):
             '=?utf-8?q?H=C3=BCbsch?= Kaktus <beautiful@example.com>,\n'
                 ' =?utf-8?q?bei=C3=9Ft_bei=C3=9Ft?= <biter@example.com>\n')
 
+    def test_address_list_with_list_separator_after_fold(self):
+        to = '0123456789' * 8 + '@foo,  <foo@bar>'
+        self._test(parser.get_address_list(to)[0],
+                   '0123456789' * 8 + '@foo,\n =?utf-8?q?=C3=A4?= <foo@bar>\n')
+
     # XXX Need tests with comments on various sides of a unicode token,
     # and with unicode tokens in the comments.  Spaces inside the quotes
     # currently don't do the right thing.
diff --git a/Lib/test/test_email/test_email.py b/Lib/test/test_email/test_email.py
index 2a237095b9..a373c53c7c 100644
--- a/Lib/test/test_email/test_email.py
+++ b/Lib/test/test_email/test_email.py
@@ -336,6 +336,21 @@ def test_nonascii_as_string_without_cte(self):
         msg = email.message_from_bytes(source)
         self.assertEqual(msg.as_string(), expected)
 
+    def test_nonascii_as_string_with_ascii_charset(self):
+        m = textwrap.dedent("""\
+            MIME-Version: 1.0
+            Content-type: text/plain; charset="us-ascii"
+            Content-Transfer-Encoding: 8bit
+
+            Test if non-ascii messages with no Content-Transfer-Encoding set
+            can be as_string'd:
+            F br
+            """)
+        source = m.encode('iso-8859-1')
+        expected = source.decode('ascii', 'replace')
+        msg = email.message_from_bytes(source)
+        self.assertEqual(msg.as_string(), expected)
+
     def test_nonascii_as_string_without_content_type_and_cte(self):
         m = textwrap.dedent("""\
             MIME-Version: 1.0
diff --git a/Lib/test/test_enum.py b/Lib/test/test_enum.py
index 23be142c24..ccba0f91c8 100644
--- a/Lib/test/test_enum.py
+++ b/Lib/test/test_enum.py
@@ -1007,6 +1007,22 @@ class TestPlainEnumFunction(_EnumTests, _PlainOutputTests, unittest.TestCase):
 class TestPlainFlagClass(_EnumTests, _PlainOutputTests, _FlagTests, unittest.TestCase):
     enum_type = Flag
 
+    def test_none_member(self):
+        class FlagWithNoneMember(Flag):
+            A = 1
+            E = None
+
+        self.assertEqual(FlagWithNoneMember.A.value, 1)
+        self.assertIs(FlagWithNoneMember.E.value, None)
+        with self.assertRaisesRegex(TypeError, r"'FlagWithNoneMember.E' cannot be combined with other flags with |"):
+            FlagWithNoneMember.A | FlagWithNoneMember.E
+        with self.assertRaisesRegex(TypeError, r"'FlagWithNoneMember.E' cannot be combined with other flags with &"):
+            FlagWithNoneMember.E & FlagWithNoneMember.A
+        with self.assertRaisesRegex(TypeError, r"'FlagWithNoneMember.E' cannot be combined with other flags with \^"):
+            FlagWithNoneMember.A ^ FlagWithNoneMember.E
+        with self.assertRaisesRegex(TypeError, r"'FlagWithNoneMember.E' cannot be inverted"):
+            ~FlagWithNoneMember.E
+
 
 class TestPlainFlagFunction(_EnumTests, _PlainOutputTests, _FlagTests, unittest.TestCase):
     enum_type = Flag
@@ -2308,6 +2324,40 @@ class SomeTuple(tuple, Enum):
         globals()['SomeTuple'] = SomeTuple
         test_pickle_dump_load(self.assertIs, SomeTuple.first)
 
+    def test_tuple_subclass_with_auto_1(self):
+        from collections import namedtuple
+        T = namedtuple('T', 'index desc')
+        class SomeEnum(T, Enum):
+            __qualname__ = 'SomeEnum'      # needed for pickle protocol 4
+            first = auto(), 'for the money'
+            second = auto(), 'for the show'
+            third = auto(), 'for the music'
+        self.assertIs(type(SomeEnum.first), SomeEnum)
+        self.assertEqual(SomeEnum.third.value, (3, 'for the music'))
+        self.assertIsInstance(SomeEnum.third.value, T)
+        self.assertEqual(SomeEnum.first.index, 1)
+        self.assertEqual(SomeEnum.second.desc, 'for the show')
+        globals()['SomeEnum'] = SomeEnum
+        globals()['T'] = T
+        test_pickle_dump_load(self.assertIs, SomeEnum.first)
+
+    def test_tuple_subclass_with_auto_2(self):
+        from collections import namedtuple
+        T = namedtuple('T', 'index desc')
+        class SomeEnum(Enum):
+            __qualname__ = 'SomeEnum'      # needed for pickle protocol 4
+            first = T(auto(), 'for the money')
+            second = T(auto(), 'for the show')
+            third = T(auto(), 'for the music')
+        self.assertIs(type(SomeEnum.first), SomeEnum)
+        self.assertEqual(SomeEnum.third.value, (3, 'for the music'))
+        self.assertIsInstance(SomeEnum.third.value, T)
+        self.assertEqual(SomeEnum.first.value.index, 1)
+        self.assertEqual(SomeEnum.second.value.desc, 'for the show')
+        globals()['SomeEnum'] = SomeEnum
+        globals()['T'] = T
+        test_pickle_dump_load(self.assertIs, SomeEnum.first)
+
     def test_duplicate_values_give_unique_enum_items(self):
         class AutoNumber(Enum):
             first = ()
@@ -3262,6 +3312,36 @@ def __new__(cls, value):
                     member._value_ = Base(value)
                     return member
 
+    def test_second_tuple_item_is_falsey(self):
+        class Cardinal(Enum):
+            RIGHT = (1, 0)
+            UP = (0, 1)
+            LEFT = (-1, 0)
+            DOWN = (0, -1)
+        self.assertIs(Cardinal(1, 0), Cardinal.RIGHT)
+        self.assertIs(Cardinal(-1, 0), Cardinal.LEFT)
+
+    def test_no_members(self):
+        with self.assertRaisesRegex(
+                TypeError,
+                'has no members',
+            ):
+            Enum(7)
+        with self.assertRaisesRegex(
+                TypeError,
+                'has no members',
+            ):
+            Flag(7)
+
+    def test_empty_names(self):
+        for nothing in '', [], {}:
+            for e_type in None, int:
+                empty_enum = Enum('empty_enum', nothing, type=e_type)
+                self.assertEqual(len(empty_enum), 0)
+                self.assertRaisesRegex(TypeError, 'has no members', empty_enum, 0)
+        self.assertRaisesRegex(TypeError, '.int. object is not iterable', Enum, 'bad_enum', names=0)
+        self.assertRaisesRegex(TypeError, '.int. object is not iterable', Enum, 'bad_enum', 0, type=int)
+
 
 class TestOrder(unittest.TestCase):
     "test usage of the `_order_` attribute"
@@ -3879,6 +3959,8 @@ def test_global_repr_conform1(self):
                 )
 
     def test_global_enum_str(self):
+        self.assertEqual(repr(NoName.ONE), 'test_enum.ONE')
+        self.assertEqual(repr(NoName(0)), 'test_enum.NoName(0)')
         self.assertEqual(str(NoName.ONE & NoName.TWO), 'NoName(0)')
         self.assertEqual(str(NoName(0)), 'NoName(0)')
 
@@ -4718,22 +4800,22 @@ class Color(enum.Enum)
  |      The value of the Enum member.
  |
  |  ----------------------------------------------------------------------
- |  Methods inherited from enum.EnumType:
+ |  Static methods inherited from enum.EnumType:
  |
- |  __contains__(value) from enum.EnumType
+ |  __contains__(value)
  |      Return True if `value` is in `cls`.
  |
  |      `value` is in `cls` if:
  |      1) `value` is a member of `cls`, or
  |      2) `value` is the value of one of the `cls`'s members.
  |
- |  __getitem__(name) from enum.EnumType
+ |  __getitem__(name)
  |      Return the member matching `name`.
  |
- |  __iter__() from enum.EnumType
+ |  __iter__()
  |      Return members in definition order.
  |
- |  __len__() from enum.EnumType
+ |  __len__()
  |      Return the number of members (no aliases)
  |
  |  ----------------------------------------------------------------------
@@ -4758,11 +4840,11 @@ class Color(enum.Enum)
  |
  |  Data and other attributes defined here:
  |
- |  YELLOW = <Color.YELLOW: 3>
+ |  CYAN = <Color.CYAN: 1>
  |
  |  MAGENTA = <Color.MAGENTA: 2>
  |
- |  CYAN = <Color.CYAN: 1>
+ |  YELLOW = <Color.YELLOW: 3>
  |
  |  ----------------------------------------------------------------------
  |  Data descriptors inherited from enum.Enum:
@@ -4772,7 +4854,18 @@ class Color(enum.Enum)
  |  value
  |
  |  ----------------------------------------------------------------------
- |  Data descriptors inherited from enum.EnumType:
+ |  Static methods inherited from enum.EnumType:
+ |
+ |  __contains__(value)
+ |
+ |  __getitem__(name)
+ |
+ |  __iter__()
+ |
+ |  __len__()
+ |
+ |  ----------------------------------------------------------------------
+ |  Readonly properties inherited from enum.EnumType:
  |
  |  __members__"""
 
diff --git a/Lib/test/test_exceptions.py b/Lib/test/test_exceptions.py
index 2d6c333674..6c09c1793c 100644
--- a/Lib/test/test_exceptions.py
+++ b/Lib/test/test_exceptions.py
@@ -301,6 +301,7 @@ def baz():
             {
             6
             0="""''', 5, 13)
+        check('b"foo"'.encode(), 1, 1, 1, 10)
 
         # Errors thrown by symtable.c
         check('x = [(yield i) for i in range(3)]', 1, 7)
diff --git a/Lib/test/test_ftplib.py b/Lib/test/test_ftplib.py
index 2f191ea7a4..4c4a4498d6 100644
--- a/Lib/test/test_ftplib.py
+++ b/Lib/test/test_ftplib.py
@@ -542,8 +542,8 @@ def test_set_pasv(self):
         self.assertFalse(self.client.passiveserver)
 
     def test_voidcmd(self):
-        self.client.voidcmd('echo 200')
-        self.client.voidcmd('echo 299')
+        self.assertEqual(self.client.voidcmd('echo 200'), '200')
+        self.assertEqual(self.client.voidcmd('echo 299'), '299')
         self.assertRaises(ftplib.error_reply, self.client.voidcmd, 'echo 199')
         self.assertRaises(ftplib.error_reply, self.client.voidcmd, 'echo 300')
 
diff --git a/Lib/test/test_functools.py b/Lib/test/test_functools.py
index 80d0176033..b73e487894 100644
--- a/Lib/test/test_functools.py
+++ b/Lib/test/test_functools.py
@@ -2618,7 +2618,10 @@ def static_func(arg: int) -> str:
             A().static_func
         ):
             with self.subTest(meth=meth):
-                self.assertEqual(meth.__doc__, 'My function docstring')
+                self.assertEqual(meth.__doc__,
+                                 ('My function docstring'
+                                  if support.HAVE_DOCSTRINGS
+                                  else None))
                 self.assertEqual(meth.__annotations__['arg'], int)
 
         self.assertEqual(A.func.__name__, 'func')
@@ -2707,7 +2710,10 @@ def decorated_classmethod(cls, arg: int) -> str:
             WithSingleDispatch().decorated_classmethod
         ):
             with self.subTest(meth=meth):
-                self.assertEqual(meth.__doc__, 'My function docstring')
+                self.assertEqual(meth.__doc__,
+                                 ('My function docstring'
+                                  if support.HAVE_DOCSTRINGS
+                                  else None))
                 self.assertEqual(meth.__annotations__['arg'], int)
 
         self.assertEqual(
@@ -3035,7 +3041,10 @@ def test_access_from_class(self):
         self.assertIsInstance(CachedCostItem.cost, py_functools.cached_property)
 
     def test_doc(self):
-        self.assertEqual(CachedCostItem.cost.__doc__, "The cost of the item.")
+        self.assertEqual(CachedCostItem.cost.__doc__,
+                         ("The cost of the item."
+                          if support.HAVE_DOCSTRINGS
+                          else None))
 
     def test_subclass_with___set__(self):
         """Caching still works for a subclass defining __set__."""
diff --git a/Lib/test/test_gc.py b/Lib/test/test_gc.py
index db7cb9ace6..81bb5bb288 100644
--- a/Lib/test/test_gc.py
+++ b/Lib/test/test_gc.py
@@ -1387,6 +1387,31 @@ def __del__(self):
             # empty __dict__.
             self.assertEqual(x, None)
 
+    def test_indirect_calls_with_gc_disabled(self):
+        junk = []
+        i = 0
+        detector = GC_Detector()
+        while not detector.gc_happened:
+            i += 1
+            if i > 10000:
+                self.fail("gc didn't happen after 10000 iterations")
+            junk.append([])  # this will eventually trigger gc
+
+        try:
+            gc.disable()
+            junk = []
+            i = 0
+            detector = GC_Detector()
+            while not detector.gc_happened:
+                i += 1
+                if i > 10000:
+                    break
+                junk.append([])  # this may eventually trigger gc (if it is enabled)
+
+            self.assertEqual(i, 10001)
+        finally:
+            gc.enable()
+
 
 class PythonFinalizationTests(unittest.TestCase):
     def test_ast_fini(self):
diff --git a/Lib/test/test_glob.py b/Lib/test/test_glob.py
index f4b5821f40..e11ea81a7d 100644
--- a/Lib/test/test_glob.py
+++ b/Lib/test/test_glob.py
@@ -40,6 +40,11 @@ def setUp(self):
             os.symlink(self.norm('broken'), self.norm('sym1'))
             os.symlink('broken', self.norm('sym2'))
             os.symlink(os.path.join('a', 'bcd'), self.norm('sym3'))
+        self.open_dirfd()
+
+    def open_dirfd(self):
+        if self.dir_fd is not None:
+            os.close(self.dir_fd)
         if {os.open, os.stat} <= os.supports_dir_fd and os.scandir in os.supports_fd:
             self.dir_fd = os.open(self.tempdir, os.O_RDONLY | os.O_DIRECTORY)
         else:
@@ -332,6 +337,33 @@ def test_recursive_glob(self):
             eq(glob.glob('**', recursive=True, include_hidden=True),
                [join(*i) for i in full+rec])
 
+    def test_glob_non_directory(self):
+        eq = self.assertSequencesEqual_noorder
+        eq(self.rglob('EF'), self.joins(('EF',)))
+        eq(self.rglob('EF', ''), [])
+        eq(self.rglob('EF', '*'), [])
+        eq(self.rglob('EF', '**'), [])
+        eq(self.rglob('nonexistent'), [])
+        eq(self.rglob('nonexistent', ''), [])
+        eq(self.rglob('nonexistent', '*'), [])
+        eq(self.rglob('nonexistent', '**'), [])
+
+    @unittest.skipUnless(hasattr(os, "mkfifo"), 'requires os.mkfifo()')
+    @unittest.skipIf(sys.platform == "vxworks",
+                    "fifo requires special path on VxWorks")
+    def test_glob_named_pipe(self):
+        path = os.path.join(self.tempdir, 'mypipe')
+        os.mkfifo(path)
+
+        # gh-117127: Reopen self.dir_fd to pick up directory changes
+        self.open_dirfd()
+
+        self.assertEqual(self.rglob('mypipe'), [path])
+        self.assertEqual(self.rglob('mypipe*'), [path])
+        self.assertEqual(self.rglob('mypipe', ''), [])
+        self.assertEqual(self.rglob('mypipe', 'sub'), [])
+        self.assertEqual(self.rglob('mypipe', '*'), [])
+
     def test_glob_many_open_files(self):
         depth = 30
         base = os.path.join(self.tempdir, 'deep')
diff --git a/Lib/test/test_gzip.py b/Lib/test/test_gzip.py
index 128f933787..d220c7d06e 100644
--- a/Lib/test/test_gzip.py
+++ b/Lib/test/test_gzip.py
@@ -5,7 +5,6 @@
 import functools
 import io
 import os
-import pathlib
 import struct
 import sys
 import unittest
@@ -79,16 +78,18 @@ def test_write(self):
         f.close()
 
     def test_write_read_with_pathlike_file(self):
-        filename = pathlib.Path(self.filename)
+        filename = os_helper.FakePath(self.filename)
         with gzip.GzipFile(filename, 'w') as f:
             f.write(data1 * 50)
         self.assertIsInstance(f.name, str)
+        self.assertEqual(f.name, self.filename)
         with gzip.GzipFile(filename, 'a') as f:
             f.write(data1)
         with gzip.GzipFile(filename) as f:
             d = f.read()
         self.assertEqual(d, data1 * 51)
         self.assertIsInstance(f.name, str)
+        self.assertEqual(f.name, self.filename)
 
     # The following test_write_xy methods test that write accepts
     # the corresponding bytes-like object type as input
@@ -472,13 +473,118 @@ def test_textio_readlines(self):
             with io.TextIOWrapper(f, encoding="ascii") as t:
                 self.assertEqual(t.readlines(), lines)
 
+    def test_fileobj_with_name(self):
+        with open(self.filename, "xb") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="x") as f:
+                f.write(b'one')
+                self.assertEqual(f.name, raw.name)
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertEqual(f.mode, gzip.WRITE)
+                self.assertIs(f.readable(), False)
+                self.assertIs(f.writable(), True)
+                self.assertIs(f.seekable(), True)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertEqual(f.name, raw.name)
+            self.assertRaises(AttributeError, f.fileno)
+            self.assertEqual(f.mode, gzip.WRITE)
+            self.assertIs(f.readable(), False)
+            self.assertIs(f.writable(), True)
+            self.assertIs(f.seekable(), True)
+
+        with open(self.filename, "wb") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="w") as f:
+                f.write(b'two')
+                self.assertEqual(f.name, raw.name)
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertEqual(f.mode, gzip.WRITE)
+                self.assertIs(f.readable(), False)
+                self.assertIs(f.writable(), True)
+                self.assertIs(f.seekable(), True)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertEqual(f.name, raw.name)
+            self.assertRaises(AttributeError, f.fileno)
+            self.assertEqual(f.mode, gzip.WRITE)
+            self.assertIs(f.readable(), False)
+            self.assertIs(f.writable(), True)
+            self.assertIs(f.seekable(), True)
+
+        with open(self.filename, "ab") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="a") as f:
+                f.write(b'three')
+                self.assertEqual(f.name, raw.name)
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertEqual(f.mode, gzip.WRITE)
+                self.assertIs(f.readable(), False)
+                self.assertIs(f.writable(), True)
+                self.assertIs(f.seekable(), True)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertEqual(f.name, raw.name)
+            self.assertRaises(AttributeError, f.fileno)
+            self.assertEqual(f.mode, gzip.WRITE)
+            self.assertIs(f.readable(), False)
+            self.assertIs(f.writable(), True)
+            self.assertIs(f.seekable(), True)
+
+        with open(self.filename, "rb") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="r") as f:
+                self.assertEqual(f.read(), b'twothree')
+                self.assertEqual(f.name, raw.name)
+                self.assertEqual(f.fileno(), raw.fileno())
+                self.assertEqual(f.mode, gzip.READ)
+                self.assertIs(f.readable(), True)
+                self.assertIs(f.writable(), False)
+                self.assertIs(f.seekable(), True)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertEqual(f.name, raw.name)
+            self.assertRaises(AttributeError, f.fileno)
+            self.assertEqual(f.mode, gzip.READ)
+            self.assertIs(f.readable(), True)
+            self.assertIs(f.writable(), False)
+            self.assertIs(f.seekable(), True)
+
     def test_fileobj_from_fdopen(self):
         # Issue #13781: Opening a GzipFile for writing fails when using a
         # fileobj created with os.fdopen().
-        fd = os.open(self.filename, os.O_WRONLY | os.O_CREAT)
-        with os.fdopen(fd, "wb") as f:
-            with gzip.GzipFile(fileobj=f, mode="w") as g:
-                pass
+        fd = os.open(self.filename, os.O_WRONLY | os.O_CREAT | os.O_EXCL)
+        with os.fdopen(fd, "xb") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="x") as f:
+                f.write(b'one')
+                self.assertEqual(f.name, '')
+                self.assertEqual(f.fileno(), raw.fileno())
+            self.assertIs(f.closed, True)
+            self.assertEqual(f.name, '')
+            self.assertRaises(AttributeError, f.fileno)
+
+        fd = os.open(self.filename, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)
+        with os.fdopen(fd, "wb") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="w") as f:
+                f.write(b'two')
+                self.assertEqual(f.name, '')
+                self.assertEqual(f.fileno(), raw.fileno())
+            self.assertEqual(f.name, '')
+            self.assertRaises(AttributeError, f.fileno)
+
+        fd = os.open(self.filename, os.O_WRONLY | os.O_CREAT | os.O_APPEND)
+        with os.fdopen(fd, "ab") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="a") as f:
+                f.write(b'three')
+                self.assertEqual(f.name, '')
+                self.assertEqual(f.fileno(), raw.fileno())
+            self.assertEqual(f.name, '')
+            self.assertRaises(AttributeError, f.fileno)
+
+        fd = os.open(self.filename, os.O_RDONLY)
+        with os.fdopen(fd, "rb") as raw:
+            with gzip.GzipFile(fileobj=raw, mode="r") as f:
+                self.assertEqual(f.read(), b'twothree')
+                self.assertEqual(f.name, '')
+                self.assertEqual(f.fileno(), raw.fileno())
+            self.assertEqual(f.name, '')
+            self.assertRaises(AttributeError, f.fileno)
 
     def test_fileobj_mode(self):
         gzip.GzipFile(self.filename, "wb").close()
@@ -508,17 +614,69 @@ def test_fileobj_mode(self):
 
     def test_bytes_filename(self):
         str_filename = self.filename
-        try:
-            bytes_filename = str_filename.encode("ascii")
-        except UnicodeEncodeError:
-            self.skipTest("Temporary file name needs to be ASCII")
+        bytes_filename = os.fsencode(str_filename)
         with gzip.GzipFile(bytes_filename, "wb") as f:
             f.write(data1 * 50)
+        self.assertEqual(f.name, bytes_filename)
         with gzip.GzipFile(bytes_filename, "rb") as f:
             self.assertEqual(f.read(), data1 * 50)
+        self.assertEqual(f.name, bytes_filename)
         # Sanity check that we are actually operating on the right file.
         with gzip.GzipFile(str_filename, "rb") as f:
             self.assertEqual(f.read(), data1 * 50)
+        self.assertEqual(f.name, str_filename)
+
+    def test_fileobj_without_name(self):
+        bio = io.BytesIO()
+        with gzip.GzipFile(fileobj=bio, mode='wb') as f:
+            f.write(data1 * 50)
+            self.assertEqual(f.name, '')
+            self.assertRaises(io.UnsupportedOperation, f.fileno)
+            self.assertEqual(f.mode, gzip.WRITE)
+            self.assertIs(f.readable(), False)
+            self.assertIs(f.writable(), True)
+            self.assertIs(f.seekable(), True)
+            self.assertIs(f.closed, False)
+        self.assertIs(f.closed, True)
+        self.assertEqual(f.name, '')
+        self.assertRaises(AttributeError, f.fileno)
+        self.assertEqual(f.mode, gzip.WRITE)
+        self.assertIs(f.readable(), False)
+        self.assertIs(f.writable(), True)
+        self.assertIs(f.seekable(), True)
+
+        bio.seek(0)
+        with gzip.GzipFile(fileobj=bio, mode='rb') as f:
+            self.assertEqual(f.read(), data1 * 50)
+            self.assertEqual(f.name, '')
+            self.assertRaises(io.UnsupportedOperation, f.fileno)
+            self.assertEqual(f.mode, gzip.READ)
+            self.assertIs(f.readable(), True)
+            self.assertIs(f.writable(), False)
+            self.assertIs(f.seekable(), True)
+            self.assertIs(f.closed, False)
+        self.assertIs(f.closed, True)
+        self.assertEqual(f.name, '')
+        self.assertRaises(AttributeError, f.fileno)
+        self.assertEqual(f.mode, gzip.READ)
+        self.assertIs(f.readable(), True)
+        self.assertIs(f.writable(), False)
+        self.assertIs(f.seekable(), True)
+
+    def test_fileobj_and_filename(self):
+        filename2 = self.filename + 'new'
+        with (open(self.filename, 'wb') as fileobj,
+              gzip.GzipFile(fileobj=fileobj, filename=filename2, mode='wb') as f):
+            f.write(data1 * 50)
+            self.assertEqual(f.name, filename2)
+        with (open(self.filename, 'rb') as fileobj,
+              gzip.GzipFile(fileobj=fileobj, filename=filename2, mode='rb') as f):
+            self.assertEqual(f.read(), data1 * 50)
+            self.assertEqual(f.name, filename2)
+        # Sanity check that we are actually operating on the right file.
+        with gzip.GzipFile(self.filename, 'rb') as f:
+            self.assertEqual(f.read(), data1 * 50)
+            self.assertEqual(f.name, self.filename)
 
     def test_decompress_limited(self):
         """Decompressed data buffering should be limited"""
@@ -707,13 +865,16 @@ def test_binary_modes(self):
             self.assertEqual(file_data, uncompressed)
 
     def test_pathlike_file(self):
-        filename = pathlib.Path(self.filename)
+        filename = os_helper.FakePath(self.filename)
         with gzip.open(filename, "wb") as f:
             f.write(data1 * 50)
+        self.assertEqual(f.name, self.filename)
         with gzip.open(filename, "ab") as f:
             f.write(data1)
+        self.assertEqual(f.name, self.filename)
         with gzip.open(filename) as f:
             self.assertEqual(f.read(), data1 * 51)
+        self.assertEqual(f.name, self.filename)
 
     def test_implicit_binary_modes(self):
         # Test implicit binary modes (no "b" or "t" in mode string).
diff --git a/Lib/test/test_hmac.py b/Lib/test/test_hmac.py
index a39a2c45eb..1502fba9f3 100644
--- a/Lib/test/test_hmac.py
+++ b/Lib/test/test_hmac.py
@@ -479,6 +479,14 @@ def test_exercise_all_methods(self):
             self.fail("Exception raised during normal usage of HMAC class.")
 
 
+class UpdateTestCase(unittest.TestCase):
+    @hashlib_helper.requires_hashdigest('sha256')
+    def test_with_str_update(self):
+        with self.assertRaises(TypeError):
+            h = hmac.new(b"key", digestmod='sha256')
+            h.update("invalid update")
+
+
 class CopyTestCase(unittest.TestCase):
 
     @hashlib_helper.requires_hashdigest('sha256')
diff --git a/Lib/test/test_httplib.py b/Lib/test/test_httplib.py
index 089bf5be40..6e63a8872d 100644
--- a/Lib/test/test_httplib.py
+++ b/Lib/test/test_httplib.py
@@ -2408,6 +2408,22 @@ def test_connect_put_request(self):
         self.assertIn(b'PUT / HTTP/1.1\r\nHost: %(host)s\r\n' % d,
                       self.conn.sock.data)
 
+    def test_connect_put_request_ipv6(self):
+        self.conn.set_tunnel('[1:2:3::4]', 1234)
+        self.conn.request('PUT', '/', '')
+        self.assertEqual(self.conn.sock.host, self.host)
+        self.assertEqual(self.conn.sock.port, client.HTTP_PORT)
+        self.assertIn(b'CONNECT [1:2:3::4]:1234', self.conn.sock.data)
+        self.assertIn(b'Host: [1:2:3::4]:1234', self.conn.sock.data)
+
+    def test_connect_put_request_ipv6_port(self):
+        self.conn.set_tunnel('[1:2:3::4]:1234')
+        self.conn.request('PUT', '/', '')
+        self.assertEqual(self.conn.sock.host, self.host)
+        self.assertEqual(self.conn.sock.port, client.HTTP_PORT)
+        self.assertIn(b'CONNECT [1:2:3::4]:1234', self.conn.sock.data)
+        self.assertIn(b'Host: [1:2:3::4]:1234', self.conn.sock.data)
+
     def test_tunnel_debuglog(self):
         expected_header = 'X-Dummy: 1'
         response_text = 'HTTP/1.0 200 OK\r\n{}\r\n\r\n'.format(expected_header)
diff --git a/Lib/test/test_imaplib.py b/Lib/test/test_imaplib.py
index def9f45d63..86f70ed347 100644
--- a/Lib/test/test_imaplib.py
+++ b/Lib/test/test_imaplib.py
@@ -8,6 +8,7 @@
 import time
 import calendar
 import threading
+import re
 import socket
 
 from test.support import verbose, run_with_tz, run_with_locale, cpython_only, requires_resource
@@ -558,9 +559,13 @@ def test_ssl_raises(self):
         self.assertEqual(ssl_context.check_hostname, True)
         ssl_context.load_verify_locations(CAFILE)
 
-        with self.assertRaisesRegex(ssl.CertificateError,
-                "IP address mismatch, certificate is not valid for "
-                "'127.0.0.1'"):
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            IP address mismatch, certificate is not valid for '127.0.0.1'   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED                                       # AWS-LC
+        )""", re.X)
+        with self.assertRaisesRegex(ssl.CertificateError, regex):
             _, server = self._setup(SimpleIMAPHandler)
             client = self.imap_class(*server.server_address,
                                      ssl_context=ssl_context)
@@ -954,10 +959,13 @@ def test_ssl_verified(self):
         ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
         ssl_context.load_verify_locations(CAFILE)
 
-        with self.assertRaisesRegex(
-                ssl.CertificateError,
-                "IP address mismatch, certificate is not valid for "
-                "'127.0.0.1'"):
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            IP address mismatch, certificate is not valid for '127.0.0.1'   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED                                       # AWS-LC
+        )""", re.X)
+        with self.assertRaisesRegex(ssl.CertificateError, regex):
             with self.reaped_server(SimpleIMAPHandler) as server:
                 client = self.imap_class(*server.server_address,
                                          ssl_context=ssl_context)
diff --git a/Lib/test/test_importlib/extension/test_case_sensitivity.py b/Lib/test/test_importlib/extension/test_case_sensitivity.py
index 0bb74fff5f..40311627a1 100644
--- a/Lib/test/test_importlib/extension/test_case_sensitivity.py
+++ b/Lib/test/test_importlib/extension/test_case_sensitivity.py
@@ -8,7 +8,8 @@
 machinery = util.import_importlib('importlib.machinery')
 
 
-@unittest.skipIf(util.EXTENSIONS.filename is None, f'{util.EXTENSIONS.name} not available')
+@unittest.skipIf(util.EXTENSIONS is None or util.EXTENSIONS.filename is None,
+                 'dynamic loading not supported or test module not available')
 @util.case_insensitive_tests
 class ExtensionModuleCaseSensitivityTest(util.CASEOKTestBase):
 
diff --git a/Lib/test/test_importlib/extension/test_finder.py b/Lib/test/test_importlib/extension/test_finder.py
index 1d5b6e7a5d..3de120958f 100644
--- a/Lib/test/test_importlib/extension/test_finder.py
+++ b/Lib/test/test_importlib/extension/test_finder.py
@@ -11,7 +11,7 @@ class FinderTests(abc.FinderTests):
     """Test the finder for extension modules."""
 
     def setUp(self):
-        if not self.machinery.EXTENSION_SUFFIXES:
+        if not self.machinery.EXTENSION_SUFFIXES or not util.EXTENSIONS:
             raise unittest.SkipTest("Requires dynamic loading support.")
         if util.EXTENSIONS.name in sys.builtin_module_names:
             raise unittest.SkipTest(
diff --git a/Lib/test/test_importlib/extension/test_loader.py b/Lib/test/test_importlib/extension/test_loader.py
index 1b5a8baf29..12f9e43d12 100644
--- a/Lib/test/test_importlib/extension/test_loader.py
+++ b/Lib/test/test_importlib/extension/test_loader.py
@@ -19,7 +19,7 @@ class LoaderTests:
     """Test ExtensionFileLoader."""
 
     def setUp(self):
-        if not self.machinery.EXTENSION_SUFFIXES:
+        if not self.machinery.EXTENSION_SUFFIXES or not util.EXTENSIONS:
             raise unittest.SkipTest("Requires dynamic loading support.")
         if util.EXTENSIONS.name in sys.builtin_module_names:
             raise unittest.SkipTest(
@@ -101,7 +101,7 @@ class SinglePhaseExtensionModuleTests(abc.LoaderTests):
     # Test loading extension modules without multi-phase initialization.
 
     def setUp(self):
-        if not self.machinery.EXTENSION_SUFFIXES:
+        if not self.machinery.EXTENSION_SUFFIXES or not util.EXTENSIONS:
             raise unittest.SkipTest("Requires dynamic loading support.")
         self.name = '_testsinglephase'
         if self.name in sys.builtin_module_names:
@@ -182,7 +182,7 @@ class MultiPhaseExtensionModuleTests(abc.LoaderTests):
     # Test loading extension modules with multi-phase initialization (PEP 489).
 
     def setUp(self):
-        if not self.machinery.EXTENSION_SUFFIXES:
+        if not self.machinery.EXTENSION_SUFFIXES or not util.EXTENSIONS:
             raise unittest.SkipTest("Requires dynamic loading support.")
         self.name = '_testmultiphase'
         if self.name in sys.builtin_module_names:
diff --git a/Lib/test/test_importlib/extension/test_path_hook.py b/Lib/test/test_importlib/extension/test_path_hook.py
index ec9644dc52..314a635c77 100644
--- a/Lib/test/test_importlib/extension/test_path_hook.py
+++ b/Lib/test/test_importlib/extension/test_path_hook.py
@@ -5,6 +5,8 @@
 import unittest
 
 
+@unittest.skipIf(util.EXTENSIONS is None or util.EXTENSIONS.filename is None,
+                 'dynamic loading not supported or test module not available')
 class PathHookTests:
 
     """Test the path hook for extension modules."""
diff --git a/Lib/test/test_importlib/resources/test_files.py b/Lib/test/test_importlib/resources/test_files.py
index 1450cfb310..26c8b04e44 100644
--- a/Lib/test/test_importlib/resources/test_files.py
+++ b/Lib/test/test_importlib/resources/test_files.py
@@ -70,7 +70,7 @@ def setUp(self):
         self.addCleanup(self.fixtures.close)
         self.site_dir = self.fixtures.enter_context(os_helper.temp_dir())
         self.fixtures.enter_context(import_helper.DirsOnSysPath(self.site_dir))
-        self.fixtures.enter_context(import_helper.CleanImport())
+        self.fixtures.enter_context(import_helper.isolated_modules())
 
 
 class ModulesFilesTests(SiteDir, unittest.TestCase):
diff --git a/Lib/test/test_importlib/test_lazy.py b/Lib/test/test_importlib/test_lazy.py
index cc993f333e..4d2cc4eb62 100644
--- a/Lib/test/test_importlib/test_lazy.py
+++ b/Lib/test/test_importlib/test_lazy.py
@@ -2,9 +2,12 @@
 from importlib import abc
 from importlib import util
 import sys
+import time
+import threading
 import types
 import unittest
 
+from test.support import threading_helper
 from test.test_importlib import util as test_util
 
 
@@ -40,6 +43,7 @@ class TestingImporter(abc.MetaPathFinder, abc.Loader):
     module_name = 'lazy_loader_test'
     mutated_name = 'changed'
     loaded = None
+    load_count = 0
     source_code = 'attr = 42; __name__ = {!r}'.format(mutated_name)
 
     def find_spec(self, name, path, target=None):
@@ -48,8 +52,10 @@ def find_spec(self, name, path, target=None):
         return util.spec_from_loader(name, util.LazyLoader(self))
 
     def exec_module(self, module):
+        time.sleep(0.01)  # Simulate a slow load.
         exec(self.source_code, module.__dict__)
         self.loaded = module
+        self.load_count += 1
 
 
 class LazyLoaderTests(unittest.TestCase):
@@ -59,8 +65,9 @@ def test_init(self):
             # Classes that don't define exec_module() trigger TypeError.
             util.LazyLoader(object)
 
-    def new_module(self, source_code=None):
-        loader = TestingImporter()
+    def new_module(self, source_code=None, loader=None):
+        if loader is None:
+            loader = TestingImporter()
         if source_code is not None:
             loader.source_code = source_code
         spec = util.spec_from_loader(TestingImporter.module_name,
@@ -140,6 +147,55 @@ def test_module_already_in_sys(self):
             # Force the load; just care that no exception is raised.
             module.__name__
 
+    @threading_helper.requires_working_threading()
+    def test_module_load_race(self):
+        with test_util.uncache(TestingImporter.module_name):
+            loader = TestingImporter()
+            module = self.new_module(loader=loader)
+            self.assertEqual(loader.load_count, 0)
+
+            class RaisingThread(threading.Thread):
+                exc = None
+                def run(self):
+                    try:
+                        super().run()
+                    except Exception as exc:
+                        self.exc = exc
+
+            def access_module():
+                return module.attr
+
+            threads = []
+            for _ in range(2):
+                threads.append(thread := RaisingThread(target=access_module))
+                thread.start()
+
+            # Races could cause errors
+            for thread in threads:
+                thread.join()
+                self.assertIsNone(thread.exc)
+
+            # Or multiple load attempts
+            self.assertEqual(loader.load_count, 1)
+
+    def test_lazy_self_referential_modules(self):
+        # Directory modules with submodules that reference the parent can attempt to access
+        # the parent module during a load. Verify that this common pattern works with lazy loading.
+        # json is a good example in the stdlib.
+        json_modules = [name for name in sys.modules if name.startswith('json')]
+        with test_util.uncache(*json_modules):
+            # Standard lazy loading, unwrapped
+            spec = util.find_spec('json')
+            loader = util.LazyLoader(spec.loader)
+            spec.loader = loader
+            module = util.module_from_spec(spec)
+            sys.modules['json'] = module
+            loader.exec_module(module)
+
+            # Trigger load with attribute lookup, ensure expected behavior
+            test_load = module.loads('{}')
+            self.assertEqual(test_load, {})
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/Lib/test/test_importlib/test_spec.py b/Lib/test/test_importlib/test_spec.py
index 80aa3609c6..02318926f3 100644
--- a/Lib/test/test_importlib/test_spec.py
+++ b/Lib/test/test_importlib/test_spec.py
@@ -502,7 +502,8 @@ def test_spec_from_loader_is_package_true_with_fileloader(self):
         self.assertEqual(spec.loader, self.fileloader)
         self.assertEqual(spec.origin, self.path)
         self.assertIs(spec.loader_state, None)
-        self.assertEqual(spec.submodule_search_locations, [os.getcwd()])
+        location = cwd if (cwd := os.getcwd()) != '/' else ''
+        self.assertEqual(spec.submodule_search_locations, [location])
         self.assertEqual(spec.cached, self.cached)
         self.assertTrue(spec.has_location)
 
@@ -601,7 +602,8 @@ def test_spec_from_file_location_smsl_empty(self):
         self.assertEqual(spec.loader, self.fileloader)
         self.assertEqual(spec.origin, self.path)
         self.assertIs(spec.loader_state, None)
-        self.assertEqual(spec.submodule_search_locations, [os.getcwd()])
+        location = cwd if (cwd := os.getcwd()) != '/' else ''
+        self.assertEqual(spec.submodule_search_locations, [location])
         self.assertEqual(spec.cached, self.cached)
         self.assertTrue(spec.has_location)
 
@@ -626,7 +628,8 @@ def test_spec_from_file_location_smsl_default(self):
         self.assertEqual(spec.loader, self.pkgloader)
         self.assertEqual(spec.origin, self.path)
         self.assertIs(spec.loader_state, None)
-        self.assertEqual(spec.submodule_search_locations, [os.getcwd()])
+        location = cwd if (cwd := os.getcwd()) != '/' else ''
+        self.assertEqual(spec.submodule_search_locations, [location])
         self.assertEqual(spec.cached, self.cached)
         self.assertTrue(spec.has_location)
 
diff --git a/Lib/test/test_importlib/test_util.py b/Lib/test/test_importlib/test_util.py
index 217c1ad78b..e018af2e16 100644
--- a/Lib/test/test_importlib/test_util.py
+++ b/Lib/test/test_importlib/test_util.py
@@ -577,7 +577,7 @@ def test_cache_from_source_respects_pycache_prefix_relative(self):
         with util.temporary_pycache_prefix(pycache_prefix):
             self.assertEqual(
                 self.util.cache_from_source(path, optimization=''),
-                expect)
+                os.path.normpath(expect))
 
     @unittest.skipIf(sys.implementation.cache_tag is None,
                      'requires sys.implementation.cache_tag to not be None')
diff --git a/Lib/test/test_importlib/util.py b/Lib/test/test_importlib/util.py
index c25be096e5..a900cc1ddd 100644
--- a/Lib/test/test_importlib/util.py
+++ b/Lib/test/test_importlib/util.py
@@ -6,6 +6,7 @@
 import marshal
 import os
 import os.path
+from test import support
 from test.support import import_helper
 from test.support import os_helper
 import unittest
@@ -22,25 +23,34 @@
 if 'importlib' not in sys.builtin_module_names:
     BUILTINS.bad_name = 'importlib'
 
-EXTENSIONS = types.SimpleNamespace()
-EXTENSIONS.path = None
-EXTENSIONS.ext = None
-EXTENSIONS.filename = None
-EXTENSIONS.file_path = None
-EXTENSIONS.name = '_testsinglephase'
-
-def _extension_details():
-    global EXTENSIONS
-    for path in sys.path:
-        for ext in machinery.EXTENSION_SUFFIXES:
-            filename = EXTENSIONS.name + ext
-            file_path = os.path.join(path, filename)
-            if os.path.exists(file_path):
-                EXTENSIONS.path = path
-                EXTENSIONS.ext = ext
-                EXTENSIONS.filename = filename
-                EXTENSIONS.file_path = file_path
-                return
+if support.is_wasi:
+    # dlopen() is a shim for WASI as of WASI SDK which fails by default.
+    # We don't provide an implementation, so tests will fail.
+    # But we also don't want to turn off dynamic loading for those that provide
+    # a working implementation.
+    def _extension_details():
+        global EXTENSIONS
+        EXTENSIONS = None
+else:
+    EXTENSIONS = types.SimpleNamespace()
+    EXTENSIONS.path = None
+    EXTENSIONS.ext = None
+    EXTENSIONS.filename = None
+    EXTENSIONS.file_path = None
+    EXTENSIONS.name = '_testsinglephase'
+
+    def _extension_details():
+        global EXTENSIONS
+        for path in sys.path:
+            for ext in machinery.EXTENSION_SUFFIXES:
+                filename = EXTENSIONS.name + ext
+                file_path = os.path.join(path, filename)
+                if os.path.exists(file_path):
+                    EXTENSIONS.path = path
+                    EXTENSIONS.ext = ext
+                    EXTENSIONS.filename = filename
+                    EXTENSIONS.file_path = file_path
+                    return
 
 _extension_details()
 
diff --git a/Lib/test/test_inspect/test_inspect.py b/Lib/test/test_inspect/test_inspect.py
index ec50acecef..7afac1bb0f 100644
--- a/Lib/test/test_inspect/test_inspect.py
+++ b/Lib/test/test_inspect/test_inspect.py
@@ -33,11 +33,11 @@
 from test.support.script_helper import assert_python_ok, assert_python_failure
 from test import support
 
-from . import inspect_fodder as mod
-from . import inspect_fodder2 as mod2
-from . import inspect_stock_annotations
-from . import inspect_stringized_annotations
-from . import inspect_stringized_annotations_2
+from test.test_inspect import inspect_fodder as mod
+from test.test_inspect import inspect_fodder2 as mod2
+from test.test_inspect import inspect_stock_annotations
+from test.test_inspect import inspect_stringized_annotations
+from test.test_inspect import inspect_stringized_annotations_2
 
 
 # Functions tested in this suite:
@@ -2779,9 +2779,12 @@ def p(name): return signature.parameters[name].default
 
         # This doesn't work now.
         # (We don't have a valid signature for "type" in 3.4)
+        class ThisWorksNow:
+            __call__ = type
+        # TODO: Support type.
+        self.assertEqual(ThisWorksNow()(1), int)
+        self.assertEqual(ThisWorksNow()('A', (), {}).__name__, 'A')
         with self.assertRaisesRegex(ValueError, "no signature found"):
-            class ThisWorksNow:
-                __call__ = type
             test_callable(ThisWorksNow())
 
         # Regression test for issue #20786
@@ -3323,6 +3326,98 @@ def __init__(self, b):
                          ((('a', ..., ..., "positional_or_keyword"),),
                           ...))
 
+        with self.subTest('classmethod'):
+            class CM(type):
+                @classmethod
+                def __call__(cls, a):
+                    return a
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('staticmethod'):
+            class CM(type):
+                @staticmethod
+                def __call__(a):
+                    return a
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('MethodType'):
+            class A:
+                def call(self, a):
+                    return a
+            class CM(type):
+                __call__ = A().call
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partial'):
+            class CM(type):
+                __call__ = functools.partial(lambda x, a: (x, a), 2)
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(1), (2, 1))
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partialmethod'):
+            class CM(type):
+                __call__ = functools.partialmethod(lambda self, x, a: (x, a), 2)
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(1), (2, 1))
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('BuiltinMethodType'):
+            class CM(type):
+                __call__ = ':'.join
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(['a', 'bc']), 'a:bc')
+            # BUG: Returns '<Signature (b)>'
+            with self.assertRaises(AssertionError):
+                self.assertEqual(self.signature(C), self.signature(''.join))
+
+        with self.subTest('MethodWrapperType'):
+            class CM(type):
+                __call__ = (2).__pow__
+            class C(metaclass=CM):
+                def __init__(self, b):
+                    pass
+
+            self.assertEqual(C(3), 8)
+            self.assertEqual(C(3, 7), 1)
+            # BUG: Returns '<Signature (b)>'
+            with self.assertRaises(AssertionError):
+                self.assertEqual(self.signature(C), self.signature((0).__pow__))
+
         class CM(type):
             def __new__(mcls, name, bases, dct, *, foo=1):
                 return super().__new__(mcls, name, bases, dct)
@@ -3384,6 +3479,169 @@ def __init__(self, b):
                            ('bar', 2, ..., "keyword_only")),
                           ...))
 
+    def test_signature_on_class_with_init(self):
+        class C:
+            def __init__(self, b):
+                pass
+
+        C(1)  # does not raise
+        self.assertEqual(self.signature(C),
+                        ((('b', ..., ..., "positional_or_keyword"),),
+                        ...))
+
+        with self.subTest('classmethod'):
+            class C:
+                @classmethod
+                def __init__(cls, b):
+                    pass
+
+            C(1)  # does not raise
+            self.assertEqual(self.signature(C),
+                            ((('b', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('staticmethod'):
+            class C:
+                @staticmethod
+                def __init__(b):
+                    pass
+
+            C(1)  # does not raise
+            self.assertEqual(self.signature(C),
+                            ((('b', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('MethodType'):
+            class A:
+                def call(self, a):
+                    pass
+            class C:
+                __init__ = A().call
+
+            C(1)  # does not raise
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partial'):
+            class C:
+                __init__ = functools.partial(lambda x, a: None, 2)
+
+            C(1)  # does not raise
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partialmethod'):
+            class C:
+                def _init(self, x, a):
+                    self.a = (x, a)
+                __init__ = functools.partialmethod(_init, 2)
+
+            self.assertEqual(C(1).a, (2, 1))
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+    def test_signature_on_class_with_new(self):
+        with self.subTest('FunctionType'):
+            class C:
+                def __new__(cls, a):
+                    return a
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('classmethod'):
+            class C:
+                @classmethod
+                def __new__(cls, cls2, a):
+                    return a
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('staticmethod'):
+            class C:
+                @staticmethod
+                def __new__(cls, a):
+                    return a
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('MethodType'):
+            class A:
+                def call(self, cls, a):
+                    return a
+            class C:
+                __new__ = A().call
+
+            self.assertEqual(C(1), 1)
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partial'):
+            class C:
+                __new__ = functools.partial(lambda x, cls, a: (x, a), 2)
+
+            self.assertEqual(C(1), (2, 1))
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partialmethod'):
+            class C:
+                __new__ = functools.partialmethod(lambda cls, x, a: (x, a), 2)
+
+            self.assertEqual(C(1), (2, 1))
+            self.assertEqual(self.signature(C),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('BuiltinMethodType'):
+            class C:
+                __new__ = str.__subclasscheck__
+
+            self.assertEqual(C(), False)
+            # TODO: Support BuiltinMethodType
+            # self.assertEqual(self.signature(C), ((), ...))
+            self.assertRaises(ValueError, self.signature, C)
+
+        with self.subTest('MethodWrapperType'):
+            class C:
+                __new__ = type.__or__.__get__(int, type)
+
+            self.assertEqual(C(), C | int)
+            # TODO: Support MethodWrapperType
+            # self.assertEqual(self.signature(C), ((), ...))
+            self.assertRaises(ValueError, self.signature, C)
+
+        # TODO: Test ClassMethodDescriptorType
+
+        with self.subTest('MethodDescriptorType'):
+            class C:
+                __new__ = type.__dict__['__subclasscheck__']
+
+            self.assertEqual(C(C), True)
+            self.assertEqual(self.signature(C), self.signature(C.__subclasscheck__))
+
+        with self.subTest('WrapperDescriptorType'):
+            class C:
+                __new__ = type.__or__
+
+            self.assertEqual(C(int), C | int)
+            # TODO: Support WrapperDescriptorType
+            # self.assertEqual(self.signature(C), self.signature(C.__or__))
+            self.assertRaises(ValueError, self.signature, C)
+
     def test_signature_on_subclass(self):
         class A:
             def __new__(cls, a=1, *args, **kwargs):
@@ -3437,8 +3695,11 @@ class D(C): pass
         # Test meta-classes without user-defined __init__ or __new__
         class C(type): pass
         class D(C): pass
+        self.assertEqual(C('A', (), {}).__name__, 'A')
+        # TODO: Support type.
         with self.assertRaisesRegex(ValueError, "callable.*is not supported"):
             self.assertEqual(inspect.signature(C), None)
+        self.assertEqual(D('A', (), {}).__name__, 'A')
         with self.assertRaisesRegex(ValueError, "callable.*is not supported"):
             self.assertEqual(inspect.signature(D), None)
 
@@ -3488,16 +3749,117 @@ class Bar(Spam, Foo):
                          ((('a', ..., ..., "positional_or_keyword"),),
                           ...))
 
-        class Wrapped:
-            pass
-        Wrapped.__wrapped__ = lambda a: None
-        self.assertEqual(self.signature(Wrapped),
+        with self.subTest('classmethod'):
+            class C:
+                @classmethod
+                def __call__(cls, a):
+                    pass
+
+            self.assertEqual(self.signature(C()),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('staticmethod'):
+            class C:
+                @staticmethod
+                def __call__(a):
+                    pass
+
+            self.assertEqual(self.signature(C()),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('MethodType'):
+            class A:
+                def call(self, a):
+                    return a
+            class C:
+                __call__ = A().call
+
+            self.assertEqual(C()(1), 1)
+            self.assertEqual(self.signature(C()),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partial'):
+            class C:
+                __call__ = functools.partial(lambda x, a: (x, a), 2)
+
+            self.assertEqual(C()(1), (2, 1))
+            self.assertEqual(self.signature(C()),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('partialmethod'):
+            class C:
+                __call__ = functools.partialmethod(lambda self, x, a: (x, a), 2)
+
+            self.assertEqual(C()(1), (2, 1))
+            self.assertEqual(self.signature(C()),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+        with self.subTest('BuiltinMethodType'):
+            class C:
+                __call__ = ':'.join
+
+            self.assertEqual(C()(['a', 'bc']), 'a:bc')
+            self.assertEqual(self.signature(C()), self.signature(''.join))
+
+        with self.subTest('MethodWrapperType'):
+            class C:
+                __call__ = (2).__pow__
+
+            self.assertEqual(C()(3), 8)
+            self.assertEqual(self.signature(C()), self.signature((0).__pow__))
+
+        with self.subTest('ClassMethodDescriptorType'):
+            class C(dict):
+                __call__ = dict.__dict__['fromkeys']
+
+            res = C()([1, 2], 3)
+            self.assertEqual(res, {1: 3, 2: 3})
+            self.assertEqual(type(res), C)
+            self.assertEqual(self.signature(C()), self.signature(dict.fromkeys))
+
+        with self.subTest('MethodDescriptorType'):
+            class C(str):
+                __call__ = str.join
+
+            self.assertEqual(C(':')(['a', 'bc']), 'a:bc')
+            self.assertEqual(self.signature(C()), self.signature(''.join))
+
+        with self.subTest('WrapperDescriptorType'):
+            class C(int):
+                __call__ = int.__pow__
+
+            self.assertEqual(C(2)(3), 8)
+            self.assertEqual(self.signature(C()), self.signature((0).__pow__))
+
+        with self.subTest('MemberDescriptorType'):
+            class C:
+                __slots__ = '__call__'
+            c = C()
+            c.__call__ = lambda a: a
+            self.assertEqual(c(1), 1)
+            self.assertEqual(self.signature(c),
+                            ((('a', ..., ..., "positional_or_keyword"),),
+                            ...))
+
+    def test_signature_on_wrapper(self):
+        class Wrapper:
+            def __call__(self, b):
+                pass
+        wrapper = Wrapper()
+        wrapper.__wrapped__ = lambda a: None
+        self.assertEqual(self.signature(wrapper),
                          ((('a', ..., ..., "positional_or_keyword"),),
                           ...))
         # wrapper loop:
-        Wrapped.__wrapped__ = Wrapped
+        wrapper = Wrapper()
+        wrapper.__wrapped__ = wrapper
         with self.assertRaisesRegex(ValueError, 'wrapper loop'):
-            self.signature(Wrapped)
+            self.signature(wrapper)
 
     def test_signature_on_lambdas(self):
         self.assertEqual(self.signature((lambda a=10: a)),
@@ -4587,6 +4949,7 @@ def func(*args, **kwargs):
         with self.assertRaises(ValueError):
             inspect.signature(func)
 
+    @support.requires_docstrings
     def test_base_class_have_text_signature(self):
         # see issue 43118
         from test.typinganndata.ann_module7 import BufferedReader
@@ -4672,6 +5035,14 @@ def test_recursion_limit(self):
         with self.assertRaisesRegex(ValueError, 'wrapper loop'):
             inspect.unwrap(obj)
 
+    def test_wrapped_descriptor(self):
+        self.assertIs(inspect.unwrap(NTimesUnwrappable), NTimesUnwrappable)
+        self.assertIs(inspect.unwrap(staticmethod), staticmethod)
+        self.assertIs(inspect.unwrap(classmethod), classmethod)
+        self.assertIs(inspect.unwrap(staticmethod(classmethod)), classmethod)
+        self.assertIs(inspect.unwrap(classmethod(staticmethod)), staticmethod)
+
+
 class TestMain(unittest.TestCase):
     def test_only_source(self):
         module = importlib.import_module('unittest')
diff --git a/Lib/test/test_io.py b/Lib/test/test_io.py
index cceaed8af5..daa40a6ba3 100644
--- a/Lib/test/test_io.py
+++ b/Lib/test/test_io.py
@@ -263,6 +263,27 @@ class PyMockUnseekableIO(MockUnseekableIO, pyio.BytesIO):
     UnsupportedOperation = pyio.UnsupportedOperation
 
 
+class MockCharPseudoDevFileIO(MockFileIO):
+    # GH-95782
+    # ftruncate() does not work on these special files (and CPython then raises
+    # appropriate exceptions), so truncate() does not have to be accounted for
+    # here.
+    def __init__(self, data):
+        super().__init__(data)
+
+    def seek(self, *args):
+        return 0
+
+    def tell(self, *args):
+        return 0
+
+class CMockCharPseudoDevFileIO(MockCharPseudoDevFileIO, io.BytesIO):
+    pass
+
+class PyMockCharPseudoDevFileIO(MockCharPseudoDevFileIO, pyio.BytesIO):
+    pass
+
+
 class MockNonBlockWriterIO:
 
     def __init__(self):
@@ -1659,11 +1680,36 @@ def test_truncate_on_read_only(self):
         self.assertRaises(self.UnsupportedOperation, bufio.truncate)
         self.assertRaises(self.UnsupportedOperation, bufio.truncate, 0)
 
+    def test_tell_character_device_file(self):
+        # GH-95782
+        # For the (former) bug in BufferedIO to manifest, the wrapped IO obj
+        # must be able to produce at least 2 bytes.
+        raw = self.MockCharPseudoDevFileIO(b"12")
+        buf = self.tp(raw)
+        self.assertEqual(buf.tell(), 0)
+        self.assertEqual(buf.read(1), b"1")
+        self.assertEqual(buf.tell(), 0)
+
+    def test_seek_character_device_file(self):
+        raw = self.MockCharPseudoDevFileIO(b"12")
+        buf = self.tp(raw)
+        self.assertEqual(buf.seek(0, io.SEEK_CUR), 0)
+        self.assertEqual(buf.seek(1, io.SEEK_SET), 0)
+        self.assertEqual(buf.seek(0, io.SEEK_CUR), 0)
+        self.assertEqual(buf.read(1), b"1")
+
+        # In the C implementation, tell() sets the BufferedIO's abs_pos to 0,
+        # which means that the next seek() could return a negative offset if it
+        # does not sanity-check:
+        self.assertEqual(buf.tell(), 0)
+        self.assertEqual(buf.seek(0, io.SEEK_CUR), 0)
+
 
 class CBufferedReaderTest(BufferedReaderTest, SizeofTest):
     tp = io.BufferedReader
 
-    @skip_if_sanitizer(memory=True, address=True, reason= "sanitizer defaults to crashing "
+    @skip_if_sanitizer(memory=True, address=True, thread=True,
+                       reason="sanitizer defaults to crashing "
                        "instead of returning NULL for malloc failure.")
     def test_constructor(self):
         BufferedReaderTest.test_constructor(self)
@@ -2030,7 +2076,8 @@ def test_slow_close_from_thread(self):
 class CBufferedWriterTest(BufferedWriterTest, SizeofTest):
     tp = io.BufferedWriter
 
-    @skip_if_sanitizer(memory=True, address=True, reason= "sanitizer defaults to crashing "
+    @skip_if_sanitizer(memory=True, address=True, thread=True,
+                       reason="sanitizer defaults to crashing "
                        "instead of returning NULL for malloc failure.")
     def test_constructor(self):
         BufferedWriterTest.test_constructor(self)
@@ -2506,6 +2553,28 @@ def test_interleaved_read_write(self):
                 f.flush()
                 self.assertEqual(raw.getvalue(), b'a2c')
 
+    def test_read1_after_write(self):
+        with self.BytesIO(b'abcdef') as raw:
+            with self.tp(raw, 3) as f:
+                f.write(b"1")
+                self.assertEqual(f.read1(1), b'b')
+                f.flush()
+                self.assertEqual(raw.getvalue(), b'1bcdef')
+        with self.BytesIO(b'abcdef') as raw:
+            with self.tp(raw, 3) as f:
+                f.write(b"1")
+                self.assertEqual(f.read1(), b'bcd')
+                f.flush()
+                self.assertEqual(raw.getvalue(), b'1bcdef')
+        with self.BytesIO(b'abcdef') as raw:
+            with self.tp(raw, 3) as f:
+                f.write(b"1")
+                # XXX: read(100) returns different numbers of bytes
+                # in Python and C implementations.
+                self.assertEqual(f.read1(100)[:3], b'bcd')
+                f.flush()
+                self.assertEqual(raw.getvalue(), b'1bcdef')
+
     def test_interleaved_readline_write(self):
         with self.BytesIO(b'ab\ncdef\ng\n') as raw:
             with self.tp(raw) as f:
@@ -2529,7 +2598,8 @@ def test_interleaved_readline_write(self):
 class CBufferedRandomTest(BufferedRandomTest, SizeofTest):
     tp = io.BufferedRandom
 
-    @skip_if_sanitizer(memory=True, address=True, reason= "sanitizer defaults to crashing "
+    @skip_if_sanitizer(memory=True, address=True, thread=True,
+                       reason="sanitizer defaults to crashing "
                        "instead of returning NULL for malloc failure.")
     def test_constructor(self):
         BufferedRandomTest.test_constructor(self)
@@ -4866,7 +4936,7 @@ def load_tests(loader, tests, pattern):
     # classes in the __dict__ of each test.
     mocks = (MockRawIO, MisbehavedRawIO, MockFileIO, CloseFailureIO,
              MockNonBlockWriterIO, MockUnseekableIO, MockRawIOWithoutRead,
-             SlowFlushRawIO)
+             SlowFlushRawIO, MockCharPseudoDevFileIO)
     all_members = io.__all__
     c_io_ns = {name : getattr(io, name) for name in all_members}
     py_io_ns = {name : getattr(pyio, name) for name in all_members}
diff --git a/Lib/test/test_isinstance.py b/Lib/test/test_isinstance.py
index bf9332e40a..b3e317bd79 100644
--- a/Lib/test/test_isinstance.py
+++ b/Lib/test/test_isinstance.py
@@ -352,7 +352,7 @@ def blowstack(fxn, arg, compare_to):
     # Make sure that calling isinstance with a deeply nested tuple for its
     # argument will raise RecursionError eventually.
     tuple_arg = (compare_to,)
-    for cnt in range(support.EXCEEDS_RECURSION_LIMIT):
+    for cnt in range(support.C_RECURSION_LIMIT * 2):
         tuple_arg = (tuple_arg,)
         fxn(arg, tuple_arg)
 
diff --git a/Lib/test/test_iter.py b/Lib/test/test_iter.py
index 30aedb0db3..9606d5beab 100644
--- a/Lib/test/test_iter.py
+++ b/Lib/test/test_iter.py
@@ -302,7 +302,7 @@ def __eq__(self, other):
             # listiter_reduce_general
             self.assertEqual(
                 run("reversed", orig["reversed"](list(range(8)))),
-                (iter, ([],))
+                (reversed, ([],))
             )
 
             for case in types:
diff --git a/Lib/test/test_itertools.py b/Lib/test/test_itertools.py
index 705e880d98..3d20e70fc1 100644
--- a/Lib/test/test_itertools.py
+++ b/Lib/test/test_itertools.py
@@ -1,7 +1,7 @@
 import doctest
 import unittest
 from test import support
-from test.support import threading_helper
+from test.support import threading_helper, script_helper
 from itertools import *
 import weakref
 from decimal import Decimal
@@ -1695,6 +1695,14 @@ def test_tee(self):
             self.pickletest(proto, a, compare=ans)
             self.pickletest(proto, b, compare=ans)
 
+    def test_tee_dealloc_segfault(self):
+        # gh-115874: segfaults when accessing module state in tp_dealloc.
+        script = (
+            "import typing, copyreg, itertools; "
+            "copyreg.buggy_tee = itertools.tee(())"
+        )
+        script_helper.assert_python_ok("-c", script)
+
     # Issue 13454: Crash when deleting backward iterator from tee()
     def test_tee_del_backward(self):
         forward, backward = tee(repeat(None, 20000000))
diff --git a/Lib/test/test_linecache.py b/Lib/test/test_linecache.py
index 72dd40136c..e42df3d949 100644
--- a/Lib/test/test_linecache.py
+++ b/Lib/test/test_linecache.py
@@ -5,6 +5,7 @@
 import os.path
 import tempfile
 import tokenize
+from importlib.machinery import ModuleSpec
 from test import support
 from test.support import os_helper
 
@@ -97,6 +98,16 @@ class BadUnicode_WithDeclaration(GetLineTestsBadData, unittest.TestCase):
     file_byte_string = b'# coding=utf-8\n\x80abc'
 
 
+class FakeLoader:
+    def get_source(self, fullname):
+        return f'source for {fullname}'
+
+
+class NoSourceLoader:
+    def get_source(self, fullname):
+        return None
+
+
 class LineCacheTests(unittest.TestCase):
 
     def test_getline(self):
@@ -238,6 +249,33 @@ def raise_memoryerror(*args, **kwargs):
         self.assertEqual(lines3, [])
         self.assertEqual(linecache.getlines(FILENAME), lines)
 
+    def test_loader(self):
+        filename = 'scheme://path'
+
+        for loader in (None, object(), NoSourceLoader()):
+            linecache.clearcache()
+            module_globals = {'__name__': 'a.b.c', '__loader__': loader}
+            self.assertEqual(linecache.getlines(filename, module_globals), [])
+
+        linecache.clearcache()
+        module_globals = {'__name__': 'a.b.c', '__loader__': FakeLoader()}
+        self.assertEqual(linecache.getlines(filename, module_globals),
+                         ['source for a.b.c\n'])
+
+        for spec in (None, object(), ModuleSpec('', FakeLoader())):
+            linecache.clearcache()
+            module_globals = {'__name__': 'a.b.c', '__loader__': FakeLoader(),
+                              '__spec__': spec}
+            self.assertEqual(linecache.getlines(filename, module_globals),
+                             ['source for a.b.c\n'])
+
+        linecache.clearcache()
+        spec = ModuleSpec('x.y.z', FakeLoader())
+        module_globals = {'__name__': 'a.b.c', '__loader__': spec.loader,
+                          '__spec__': spec}
+        self.assertEqual(linecache.getlines(filename, module_globals),
+                         ['source for x.y.z\n'])
+
 
 class LineCacheInvalidationTests(unittest.TestCase):
     def setUp(self):
diff --git a/Lib/test/test_listcomps.py b/Lib/test/test_listcomps.py
index f95a78aff0..2868dd0154 100644
--- a/Lib/test/test_listcomps.py
+++ b/Lib/test/test_listcomps.py
@@ -156,6 +156,18 @@ def method(self):
         self.assertEqual(C.y, [4, 4, 4, 4, 4])
         self.assertIs(C().method(), C)
 
+    def test_references_super(self):
+        code = """
+            res = [super for x in [1]]
+        """
+        self._check_in_scopes(code, outputs={"res": [super]})
+
+    def test_references___class__(self):
+        code = """
+            res = [__class__ for x in [1]]
+        """
+        self._check_in_scopes(code, raises=NameError)
+
     def test_inner_cell_shadows_outer(self):
         code = """
             items = [(lambda: i) for i in range(5)]
diff --git a/Lib/test/test_logging.py b/Lib/test/test_logging.py
index d1ec2d6cf7..a4b2b4f9c8 100644
--- a/Lib/test/test_logging.py
+++ b/Lib/test/test_logging.py
@@ -80,6 +80,9 @@
 skip_if_asan_fork = unittest.skipIf(
     support.HAVE_ASAN_FORK_BUG,
     "libasan has a pthread_create() dead lock related to thread+fork")
+skip_if_tsan_fork = unittest.skipIf(
+    support.check_sanitizer(thread=True),
+    "TSAN doesn't support threads after fork")
 
 
 class BaseTest(unittest.TestCase):
@@ -737,6 +740,7 @@ def remove_loop(fname, tries):
     @support.requires_fork()
     @threading_helper.requires_working_threading()
     @skip_if_asan_fork
+    @skip_if_tsan_fork
     def test_post_fork_child_no_deadlock(self):
         """Ensure child logging locks are not held; bpo-6721 & bpo-36533."""
         class _OurHandler(logging.Handler):
@@ -5447,6 +5451,7 @@ def test_critical(self):
         self.assertEqual(record.levelno, logging.CRITICAL)
         self.assertEqual(record.msg, msg)
         self.assertEqual(record.args, (self.recording,))
+        self.assertEqual(record.funcName, 'test_critical')
 
     def test_is_enabled_for(self):
         old_disable = self.adapter.logger.manager.disable
@@ -5465,15 +5470,9 @@ def test_has_handlers(self):
         self.assertFalse(self.adapter.hasHandlers())
 
     def test_nested(self):
-        class Adapter(logging.LoggerAdapter):
-            prefix = 'Adapter'
-
-            def process(self, msg, kwargs):
-                return f"{self.prefix} {msg}", kwargs
-
         msg = 'Adapters can be nested, yo.'
-        adapter = Adapter(logger=self.logger, extra=None)
-        adapter_adapter = Adapter(logger=adapter, extra=None)
+        adapter = PrefixAdapter(logger=self.logger, extra=None)
+        adapter_adapter = PrefixAdapter(logger=adapter, extra=None)
         adapter_adapter.prefix = 'AdapterAdapter'
         self.assertEqual(repr(adapter), repr(adapter_adapter))
         adapter_adapter.log(logging.CRITICAL, msg, self.recording)
@@ -5482,6 +5481,7 @@ def process(self, msg, kwargs):
         self.assertEqual(record.levelno, logging.CRITICAL)
         self.assertEqual(record.msg, f"Adapter AdapterAdapter {msg}")
         self.assertEqual(record.args, (self.recording,))
+        self.assertEqual(record.funcName, 'test_nested')
         orig_manager = adapter_adapter.manager
         self.assertIs(adapter.manager, orig_manager)
         self.assertIs(self.logger.manager, orig_manager)
@@ -5497,6 +5497,101 @@ def process(self, msg, kwargs):
         self.assertIs(adapter.manager, orig_manager)
         self.assertIs(self.logger.manager, orig_manager)
 
+    def test_styled_adapter(self):
+        # Test an example from the Cookbook.
+        records = self.recording.records
+        adapter = StyleAdapter(self.logger)
+        adapter.warning('Hello, {}!', 'world')
+        self.assertEqual(str(records[-1].msg), 'Hello, world!')
+        self.assertEqual(records[-1].funcName, 'test_styled_adapter')
+        adapter.log(logging.WARNING, 'Goodbye {}.', 'world')
+        self.assertEqual(str(records[-1].msg), 'Goodbye world.')
+        self.assertEqual(records[-1].funcName, 'test_styled_adapter')
+
+    def test_nested_styled_adapter(self):
+        records = self.recording.records
+        adapter = PrefixAdapter(self.logger)
+        adapter.prefix = '{}'
+        adapter2 = StyleAdapter(adapter)
+        adapter2.warning('Hello, {}!', 'world')
+        self.assertEqual(str(records[-1].msg), '{} Hello, world!')
+        self.assertEqual(records[-1].funcName, 'test_nested_styled_adapter')
+        adapter2.log(logging.WARNING, 'Goodbye {}.', 'world')
+        self.assertEqual(str(records[-1].msg), '{} Goodbye world.')
+        self.assertEqual(records[-1].funcName, 'test_nested_styled_adapter')
+
+    def test_find_caller_with_stacklevel(self):
+        the_level = 1
+        trigger = self.adapter.warning
+
+        def innermost():
+            trigger('test', stacklevel=the_level)
+
+        def inner():
+            innermost()
+
+        def outer():
+            inner()
+
+        records = self.recording.records
+        outer()
+        self.assertEqual(records[-1].funcName, 'innermost')
+        lineno = records[-1].lineno
+        the_level += 1
+        outer()
+        self.assertEqual(records[-1].funcName, 'inner')
+        self.assertGreater(records[-1].lineno, lineno)
+        lineno = records[-1].lineno
+        the_level += 1
+        outer()
+        self.assertEqual(records[-1].funcName, 'outer')
+        self.assertGreater(records[-1].lineno, lineno)
+        lineno = records[-1].lineno
+        the_level += 1
+        outer()
+        self.assertEqual(records[-1].funcName, 'test_find_caller_with_stacklevel')
+        self.assertGreater(records[-1].lineno, lineno)
+
+    def test_extra_in_records(self):
+        self.adapter = logging.LoggerAdapter(logger=self.logger,
+                                             extra={'foo': '1'})
+
+        self.adapter.critical('foo should be here')
+        self.assertEqual(len(self.recording.records), 1)
+        record = self.recording.records[0]
+        self.assertTrue(hasattr(record, 'foo'))
+        self.assertEqual(record.foo, '1')
+
+    def test_extra_not_merged_by_default(self):
+        self.adapter.critical('foo should NOT be here', extra={'foo': 'nope'})
+        self.assertEqual(len(self.recording.records), 1)
+        record = self.recording.records[0]
+        self.assertFalse(hasattr(record, 'foo'))
+
+
+class PrefixAdapter(logging.LoggerAdapter):
+    prefix = 'Adapter'
+
+    def process(self, msg, kwargs):
+        return f"{self.prefix} {msg}", kwargs
+
+
+class Message:
+    def __init__(self, fmt, args):
+        self.fmt = fmt
+        self.args = args
+
+    def __str__(self):
+        return self.fmt.format(*self.args)
+
+
+class StyleAdapter(logging.LoggerAdapter):
+    def log(self, level, msg, /, *args, stacklevel=1, **kwargs):
+        if self.isEnabledFor(level):
+            msg, kwargs = self.process(msg, kwargs)
+            self.logger.log(level, Message(msg, args), **kwargs,
+                            stacklevel=stacklevel+1)
+
 
 class LoggerTest(BaseTest, AssertErrorMessage):
 
@@ -5934,6 +6029,52 @@ def test_rollover(self):
                     print(tf.read())
         self.assertTrue(found, msg=msg)
 
+    def test_rollover_at_midnight(self, weekly=False):
+        os_helper.unlink(self.fn)
+        now = datetime.datetime.now()
+        atTime = now.time()
+        if not 0.1 < atTime.microsecond/1e6 < 0.9:
+            # The test requires all records to be emitted within
+            # the range of the same whole second.
+            time.sleep((0.1 - atTime.microsecond/1e6) % 1.0)
+            now = datetime.datetime.now()
+            atTime = now.time()
+        atTime = atTime.replace(microsecond=0)
+        fmt = logging.Formatter('%(asctime)s %(message)s')
+        when = f'W{now.weekday()}' if weekly else 'MIDNIGHT'
+        for i in range(3):
+            fh = logging.handlers.TimedRotatingFileHandler(
+                self.fn, encoding="utf-8", when=when, atTime=atTime)
+            fh.setFormatter(fmt)
+            r2 = logging.makeLogRecord({'msg': f'testing1 {i}'})
+            fh.emit(r2)
+            fh.close()
+        self.assertLogFile(self.fn)
+        with open(self.fn, encoding="utf-8") as f:
+            for i, line in enumerate(f):
+                self.assertIn(f'testing1 {i}', line)
+
+        os.utime(self.fn, (now.timestamp() - 1,)*2)
+        for i in range(2):
+            fh = logging.handlers.TimedRotatingFileHandler(
+                self.fn, encoding="utf-8", when=when, atTime=atTime)
+            fh.setFormatter(fmt)
+            r2 = logging.makeLogRecord({'msg': f'testing2 {i}'})
+            fh.emit(r2)
+            fh.close()
+        rolloverDate = now - datetime.timedelta(days=7 if weekly else 1)
+        otherfn = f'{self.fn}.{rolloverDate:%Y-%m-%d}'
+        self.assertLogFile(otherfn)
+        with open(self.fn, encoding="utf-8") as f:
+            for i, line in enumerate(f):
+                self.assertIn(f'testing2 {i}', line)
+        with open(otherfn, encoding="utf-8") as f:
+            for i, line in enumerate(f):
+                self.assertIn(f'testing1 {i}', line)
+
+    def test_rollover_at_weekday(self):
+        self.test_rollover_at_midnight(weekly=True)
+
     def test_invalid(self):
         assertRaises = self.assertRaises
         assertRaises(ValueError, logging.handlers.TimedRotatingFileHandler,
@@ -5943,22 +6084,47 @@ def test_invalid(self):
         assertRaises(ValueError, logging.handlers.TimedRotatingFileHandler,
                      self.fn, 'W7', encoding="utf-8", delay=True)
 
+    # TODO: Test for utc=False.
     def test_compute_rollover_daily_attime(self):
         currentTime = 0
+        rh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT',
+            utc=True, atTime=None)
+        try:
+            actual = rh.computeRollover(currentTime)
+            self.assertEqual(actual, currentTime + 24 * 60 * 60)
+
+            actual = rh.computeRollover(currentTime + 24 * 60 * 60 - 1)
+            self.assertEqual(actual, currentTime + 24 * 60 * 60)
+
+            actual = rh.computeRollover(currentTime + 24 * 60 * 60)
+            self.assertEqual(actual, currentTime + 48 * 60 * 60)
+
+            actual = rh.computeRollover(currentTime + 25 * 60 * 60)
+            self.assertEqual(actual, currentTime + 48 * 60 * 60)
+        finally:
+            rh.close()
+
         atTime = datetime.time(12, 0, 0)
         rh = logging.handlers.TimedRotatingFileHandler(
-            self.fn, encoding="utf-8", when='MIDNIGHT', interval=1, backupCount=0,
+            self.fn, encoding="utf-8", when='MIDNIGHT',
             utc=True, atTime=atTime)
         try:
             actual = rh.computeRollover(currentTime)
             self.assertEqual(actual, currentTime + 12 * 60 * 60)
 
+            actual = rh.computeRollover(currentTime + 12 * 60 * 60 - 1)
+            self.assertEqual(actual, currentTime + 12 * 60 * 60)
+
+            actual = rh.computeRollover(currentTime + 12 * 60 * 60)
+            self.assertEqual(actual, currentTime + 36 * 60 * 60)
+
             actual = rh.computeRollover(currentTime + 13 * 60 * 60)
             self.assertEqual(actual, currentTime + 36 * 60 * 60)
         finally:
             rh.close()
 
-    #@unittest.skipIf(True, 'Temporarily skipped while failures investigated.')
+    # TODO: Test for utc=False.
     def test_compute_rollover_weekly_attime(self):
         currentTime = int(time.time())
         today = currentTime - currentTime % 86400
@@ -5983,14 +6149,28 @@ def test_compute_rollover_weekly_attime(self):
                 expected += 12 * 60 * 60
                 # Add in adjustment for today
                 expected += today
+
                 actual = rh.computeRollover(today)
                 if actual != expected:
                     print('failed in timezone: %d' % time.timezone)
                     print('local vars: %s' % locals())
                 self.assertEqual(actual, expected)
+
+                actual = rh.computeRollover(today + 12 * 60 * 60 - 1)
+                if actual != expected:
+                    print('failed in timezone: %d' % time.timezone)
+                    print('local vars: %s' % locals())
+                self.assertEqual(actual, expected)
+
                 if day == wday:
                     # goes into following week
                     expected += 7 * 24 * 60 * 60
+                actual = rh.computeRollover(today + 12 * 60 * 60)
+                if actual != expected:
+                    print('failed in timezone: %d' % time.timezone)
+                    print('local vars: %s' % locals())
+                self.assertEqual(actual, expected)
+
                 actual = rh.computeRollover(today + 13 * 60 * 60)
                 if actual != expected:
                     print('failed in timezone: %d' % time.timezone)
@@ -6008,7 +6188,7 @@ def test_compute_files_to_delete(self):
         for i in range(10):
             times.append(dt.strftime('%Y-%m-%d_%H-%M-%S'))
             dt += datetime.timedelta(seconds=5)
-        prefixes = ('a.b', 'a.b.c', 'd.e', 'd.e.f')
+        prefixes = ('a.b', 'a.b.c', 'd.e', 'd.e.f', 'g')
         files = []
         rotators = []
         for prefix in prefixes:
@@ -6021,10 +6201,22 @@ def test_compute_files_to_delete(self):
             if prefix.startswith('a.b'):
                 for t in times:
                     files.append('%s.log.%s' % (prefix, t))
-            else:
-                rotator.namer = lambda name: name.replace('.log', '') + '.log'
+            elif prefix.startswith('d.e'):
+                def namer(filename):
+                    dirname, basename = os.path.split(filename)
+                    basename = basename.replace('.log', '') + '.log'
+                    return os.path.join(dirname, basename)
+                rotator.namer = namer
                 for t in times:
                     files.append('%s.%s.log' % (prefix, t))
+            elif prefix == 'g':
+                def namer(filename):
+                    dirname, basename = os.path.split(filename)
+                    basename = 'g' + basename[6:] + '.oldlog'
+                    return os.path.join(dirname, basename)
+                rotator.namer = namer
+                for t in times:
+                    files.append('g%s.oldlog' % t)
         # Create empty files
         for fn in files:
             p = os.path.join(wd, fn)
@@ -6034,18 +6226,423 @@ def test_compute_files_to_delete(self):
         for i, prefix in enumerate(prefixes):
             rotator = rotators[i]
             candidates = rotator.getFilesToDelete()
-            self.assertEqual(len(candidates), 3)
+            self.assertEqual(len(candidates), 3, candidates)
             if prefix.startswith('a.b'):
                 p = '%s.log.' % prefix
                 for c in candidates:
                     d, fn = os.path.split(c)
                     self.assertTrue(fn.startswith(p))
-            else:
+            elif prefix.startswith('d.e'):
                 for c in candidates:
                     d, fn = os.path.split(c)
-                    self.assertTrue(fn.endswith('.log'))
+                    self.assertTrue(fn.endswith('.log'), fn)
                     self.assertTrue(fn.startswith(prefix + '.') and
                                     fn[len(prefix) + 2].isdigit())
+            elif prefix == 'g':
+                for c in candidates:
+                    d, fn = os.path.split(c)
+                    self.assertTrue(fn.endswith('.oldlog'))
+                    self.assertTrue(fn.startswith('g') and fn[1].isdigit())
+
+    def test_compute_files_to_delete_same_filename_different_extensions(self):
+        # See GH-93205 for background
+        wd = pathlib.Path(tempfile.mkdtemp(prefix='test_logging_'))
+        self.addCleanup(shutil.rmtree, wd)
+        times = []
+        dt = datetime.datetime.now()
+        n_files = 10
+        for _ in range(n_files):
+            times.append(dt.strftime('%Y-%m-%d_%H-%M-%S'))
+            dt += datetime.timedelta(seconds=5)
+        prefixes = ('a.log', 'a.log.b')
+        files = []
+        rotators = []
+        for i, prefix in enumerate(prefixes):
+            backupCount = i+1
+            rotator = logging.handlers.TimedRotatingFileHandler(wd / prefix, when='s',
+                                                                interval=5,
+                                                                backupCount=backupCount,
+                                                                delay=True)
+            rotators.append(rotator)
+            for t in times:
+                files.append('%s.%s' % (prefix, t))
+        for t in times:
+            files.append('a.log.%s.c' % t)
+        # Create empty files
+        for f in files:
+            (wd / f).touch()
+        # Now the checks that only the correct files are offered up for deletion
+        for i, prefix in enumerate(prefixes):
+            backupCount = i+1
+            rotator = rotators[i]
+            candidates = rotator.getFilesToDelete()
+            self.assertEqual(len(candidates), n_files - backupCount, candidates)
+            matcher = re.compile(r"^\d{4}-\d{2}-\d{2}_\d{2}-\d{2}-\d{2}\Z")
+            for c in candidates:
+                d, fn = os.path.split(c)
+                self.assertTrue(fn.startswith(prefix+'.'))
+                suffix = fn[(len(prefix)+1):]
+                self.assertRegex(suffix, matcher)
+
+    # Run with US-style DST rules: DST begins 2 a.m. on second Sunday in
+    # March (M3.2.0) and ends 2 a.m. on first Sunday in November (M11.1.0).
+    @support.run_with_tz('EST+05EDT,M3.2.0,M11.1.0')
+    def test_compute_rollover_MIDNIGHT_local(self):
+        # DST begins at 2012-3-11T02:00:00 and ends at 2012-11-4T02:00:00.
+        DT = datetime.datetime
+        def test(current, expected):
+            actual = fh.computeRollover(current.timestamp())
+            diff = actual - expected.timestamp()
+            if diff:
+                self.assertEqual(diff, 0, datetime.timedelta(seconds=diff))
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False)
+
+        test(DT(2012, 3, 10, 23, 59, 59), DT(2012, 3, 11, 0, 0))
+        test(DT(2012, 3, 11, 0, 0), DT(2012, 3, 12, 0, 0))
+        test(DT(2012, 3, 11, 1, 0), DT(2012, 3, 12, 0, 0))
+
+        test(DT(2012, 11, 3, 23, 59, 59), DT(2012, 11, 4, 0, 0))
+        test(DT(2012, 11, 4, 0, 0), DT(2012, 11, 5, 0, 0))
+        test(DT(2012, 11, 4, 1, 0), DT(2012, 11, 5, 0, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False,
+            atTime=datetime.time(12, 0, 0))
+
+        test(DT(2012, 3, 10, 11, 59, 59), DT(2012, 3, 10, 12, 0))
+        test(DT(2012, 3, 10, 12, 0), DT(2012, 3, 11, 12, 0))
+        test(DT(2012, 3, 10, 13, 0), DT(2012, 3, 11, 12, 0))
+
+        test(DT(2012, 11, 3, 11, 59, 59), DT(2012, 11, 3, 12, 0))
+        test(DT(2012, 11, 3, 12, 0), DT(2012, 11, 4, 12, 0))
+        test(DT(2012, 11, 3, 13, 0), DT(2012, 11, 4, 12, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False,
+            atTime=datetime.time(2, 0, 0))
+
+        test(DT(2012, 3, 10, 1, 59, 59), DT(2012, 3, 10, 2, 0))
+        # 2:00:00 is the same as 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 10, 2, 0), DT(2012, 3, 11, 3, 0))
+        test(DT(2012, 3, 10, 3, 0), DT(2012, 3, 11, 3, 0))
+
+        test(DT(2012, 3, 11, 1, 59, 59), DT(2012, 3, 11, 3, 0))
+        # No time between 2:00:00 and 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 11, 3, 0), DT(2012, 3, 12, 2, 0))
+        test(DT(2012, 3, 11, 4, 0), DT(2012, 3, 12, 2, 0))
+
+        test(DT(2012, 11, 3, 1, 59, 59), DT(2012, 11, 3, 2, 0))
+        test(DT(2012, 11, 3, 2, 0), DT(2012, 11, 4, 2, 0))
+        test(DT(2012, 11, 3, 3, 0), DT(2012, 11, 4, 2, 0))
+
+        # 1:00:00-2:00:00 is repeated twice at 2012-11-4.
+        test(DT(2012, 11, 4, 1, 59, 59), DT(2012, 11, 4, 2, 0))
+        test(DT(2012, 11, 4, 1, 59, 59, fold=1), DT(2012, 11, 4, 2, 0))
+        test(DT(2012, 11, 4, 2, 0), DT(2012, 11, 5, 2, 0))
+        test(DT(2012, 11, 4, 3, 0), DT(2012, 11, 5, 2, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False,
+            atTime=datetime.time(2, 30, 0))
+
+        test(DT(2012, 3, 10, 2, 29, 59), DT(2012, 3, 10, 2, 30))
+        # No time 2:30:00 at 2012-3-11.
+        test(DT(2012, 3, 10, 2, 30), DT(2012, 3, 11, 3, 30))
+        test(DT(2012, 3, 10, 3, 0), DT(2012, 3, 11, 3, 30))
+
+        test(DT(2012, 3, 11, 1, 59, 59), DT(2012, 3, 11, 3, 30))
+        # No time between 2:00:00 and 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 11, 3, 0), DT(2012, 3, 12, 2, 30))
+        test(DT(2012, 3, 11, 3, 30), DT(2012, 3, 12, 2, 30))
+
+        test(DT(2012, 11, 3, 2, 29, 59), DT(2012, 11, 3, 2, 30))
+        test(DT(2012, 11, 3, 2, 30), DT(2012, 11, 4, 2, 30))
+        test(DT(2012, 11, 3, 3, 0), DT(2012, 11, 4, 2, 30))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False,
+            atTime=datetime.time(1, 30, 0))
+
+        test(DT(2012, 3, 11, 1, 29, 59), DT(2012, 3, 11, 1, 30))
+        test(DT(2012, 3, 11, 1, 30), DT(2012, 3, 12, 1, 30))
+        test(DT(2012, 3, 11, 1, 59, 59), DT(2012, 3, 12, 1, 30))
+        # No time between 2:00:00 and 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 11, 3, 0), DT(2012, 3, 12, 1, 30))
+        test(DT(2012, 3, 11, 3, 30), DT(2012, 3, 12, 1, 30))
+
+        # 1:00:00-2:00:00 is repeated twice at 2012-11-4.
+        test(DT(2012, 11, 4, 1, 0), DT(2012, 11, 4, 1, 30))
+        test(DT(2012, 11, 4, 1, 29, 59), DT(2012, 11, 4, 1, 30))
+        test(DT(2012, 11, 4, 1, 30), DT(2012, 11, 5, 1, 30))
+        test(DT(2012, 11, 4, 1, 59, 59), DT(2012, 11, 5, 1, 30))
+        # It is weird, but the rollover date jumps back from 2012-11-5
+        # to 2012-11-4.
+        test(DT(2012, 11, 4, 1, 0, fold=1), DT(2012, 11, 4, 1, 30, fold=1))
+        test(DT(2012, 11, 4, 1, 29, 59, fold=1), DT(2012, 11, 4, 1, 30, fold=1))
+        test(DT(2012, 11, 4, 1, 30, fold=1), DT(2012, 11, 5, 1, 30))
+        test(DT(2012, 11, 4, 1, 59, 59, fold=1), DT(2012, 11, 5, 1, 30))
+        test(DT(2012, 11, 4, 2, 0), DT(2012, 11, 5, 1, 30))
+        test(DT(2012, 11, 4, 2, 30), DT(2012, 11, 5, 1, 30))
+
+        fh.close()
+
+    # Run with US-style DST rules: DST begins 2 a.m. on second Sunday in
+    # March (M3.2.0) and ends 2 a.m. on first Sunday in November (M11.1.0).
+    @support.run_with_tz('EST+05EDT,M3.2.0,M11.1.0')
+    def test_compute_rollover_W6_local(self):
+        # DST begins at 2012-3-11T02:00:00 and ends at 2012-11-4T02:00:00.
+        DT = datetime.datetime
+        def test(current, expected):
+            actual = fh.computeRollover(current.timestamp())
+            diff = actual - expected.timestamp()
+            if diff:
+                self.assertEqual(diff, 0, datetime.timedelta(seconds=diff))
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False)
+
+        test(DT(2012, 3, 4, 23, 59, 59), DT(2012, 3, 5, 0, 0))
+        test(DT(2012, 3, 5, 0, 0), DT(2012, 3, 12, 0, 0))
+        test(DT(2012, 3, 5, 1, 0), DT(2012, 3, 12, 0, 0))
+
+        test(DT(2012, 10, 28, 23, 59, 59), DT(2012, 10, 29, 0, 0))
+        test(DT(2012, 10, 29, 0, 0), DT(2012, 11, 5, 0, 0))
+        test(DT(2012, 10, 29, 1, 0), DT(2012, 11, 5, 0, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False,
+            atTime=datetime.time(0, 0, 0))
+
+        test(DT(2012, 3, 10, 23, 59, 59), DT(2012, 3, 11, 0, 0))
+        test(DT(2012, 3, 11, 0, 0), DT(2012, 3, 18, 0, 0))
+        test(DT(2012, 3, 11, 1, 0), DT(2012, 3, 18, 0, 0))
+
+        test(DT(2012, 11, 3, 23, 59, 59), DT(2012, 11, 4, 0, 0))
+        test(DT(2012, 11, 4, 0, 0), DT(2012, 11, 11, 0, 0))
+        test(DT(2012, 11, 4, 1, 0), DT(2012, 11, 11, 0, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False,
+            atTime=datetime.time(12, 0, 0))
+
+        test(DT(2012, 3, 4, 11, 59, 59), DT(2012, 3, 4, 12, 0))
+        test(DT(2012, 3, 4, 12, 0), DT(2012, 3, 11, 12, 0))
+        test(DT(2012, 3, 4, 13, 0), DT(2012, 3, 11, 12, 0))
+
+        test(DT(2012, 10, 28, 11, 59, 59), DT(2012, 10, 28, 12, 0))
+        test(DT(2012, 10, 28, 12, 0), DT(2012, 11, 4, 12, 0))
+        test(DT(2012, 10, 28, 13, 0), DT(2012, 11, 4, 12, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False,
+            atTime=datetime.time(2, 0, 0))
+
+        test(DT(2012, 3, 4, 1, 59, 59), DT(2012, 3, 4, 2, 0))
+        # 2:00:00 is the same as 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 4, 2, 0), DT(2012, 3, 11, 3, 0))
+        test(DT(2012, 3, 4, 3, 0), DT(2012, 3, 11, 3, 0))
+
+        test(DT(2012, 3, 11, 1, 59, 59), DT(2012, 3, 11, 3, 0))
+        # No time between 2:00:00 and 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 11, 3, 0), DT(2012, 3, 18, 2, 0))
+        test(DT(2012, 3, 11, 4, 0), DT(2012, 3, 18, 2, 0))
+
+        test(DT(2012, 10, 28, 1, 59, 59), DT(2012, 10, 28, 2, 0))
+        test(DT(2012, 10, 28, 2, 0), DT(2012, 11, 4, 2, 0))
+        test(DT(2012, 10, 28, 3, 0), DT(2012, 11, 4, 2, 0))
+
+        # 1:00:00-2:00:00 is repeated twice at 2012-11-4.
+        test(DT(2012, 11, 4, 1, 59, 59), DT(2012, 11, 4, 2, 0))
+        test(DT(2012, 11, 4, 1, 59, 59, fold=1), DT(2012, 11, 4, 2, 0))
+        test(DT(2012, 11, 4, 2, 0), DT(2012, 11, 11, 2, 0))
+        test(DT(2012, 11, 4, 3, 0), DT(2012, 11, 11, 2, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False,
+            atTime=datetime.time(2, 30, 0))
+
+        test(DT(2012, 3, 4, 2, 29, 59), DT(2012, 3, 4, 2, 30))
+        # No time 2:30:00 at 2012-3-11.
+        test(DT(2012, 3, 4, 2, 30), DT(2012, 3, 11, 3, 30))
+        test(DT(2012, 3, 4, 3, 0), DT(2012, 3, 11, 3, 30))
+
+        test(DT(2012, 3, 11, 1, 59, 59), DT(2012, 3, 11, 3, 30))
+        # No time between 2:00:00 and 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 11, 3, 0), DT(2012, 3, 18, 2, 30))
+        test(DT(2012, 3, 11, 3, 30), DT(2012, 3, 18, 2, 30))
+
+        test(DT(2012, 10, 28, 2, 29, 59), DT(2012, 10, 28, 2, 30))
+        test(DT(2012, 10, 28, 2, 30), DT(2012, 11, 4, 2, 30))
+        test(DT(2012, 10, 28, 3, 0), DT(2012, 11, 4, 2, 30))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False,
+            atTime=datetime.time(1, 30, 0))
+
+        test(DT(2012, 3, 11, 1, 29, 59), DT(2012, 3, 11, 1, 30))
+        test(DT(2012, 3, 11, 1, 30), DT(2012, 3, 18, 1, 30))
+        test(DT(2012, 3, 11, 1, 59, 59), DT(2012, 3, 18, 1, 30))
+        # No time between 2:00:00 and 3:00:00 at 2012-3-11.
+        test(DT(2012, 3, 11, 3, 0), DT(2012, 3, 18, 1, 30))
+        test(DT(2012, 3, 11, 3, 30), DT(2012, 3, 18, 1, 30))
+
+        # 1:00:00-2:00:00 is repeated twice at 2012-11-4.
+        test(DT(2012, 11, 4, 1, 0), DT(2012, 11, 4, 1, 30))
+        test(DT(2012, 11, 4, 1, 29, 59), DT(2012, 11, 4, 1, 30))
+        test(DT(2012, 11, 4, 1, 30), DT(2012, 11, 11, 1, 30))
+        test(DT(2012, 11, 4, 1, 59, 59), DT(2012, 11, 11, 1, 30))
+        # It is weird, but the rollover date jumps back from 2012-11-11
+        # to 2012-11-4.
+        test(DT(2012, 11, 4, 1, 0, fold=1), DT(2012, 11, 4, 1, 30, fold=1))
+        test(DT(2012, 11, 4, 1, 29, 59, fold=1), DT(2012, 11, 4, 1, 30, fold=1))
+        test(DT(2012, 11, 4, 1, 30, fold=1), DT(2012, 11, 11, 1, 30))
+        test(DT(2012, 11, 4, 1, 59, 59, fold=1), DT(2012, 11, 11, 1, 30))
+        test(DT(2012, 11, 4, 2, 0), DT(2012, 11, 11, 1, 30))
+        test(DT(2012, 11, 4, 2, 30), DT(2012, 11, 11, 1, 30))
+
+        fh.close()
+
+    # Run with US-style DST rules: DST begins 2 a.m. on second Sunday in
+    # March (M3.2.0) and ends 2 a.m. on first Sunday in November (M11.1.0).
+    @support.run_with_tz('EST+05EDT,M3.2.0,M11.1.0')
+    def test_compute_rollover_MIDNIGHT_local_interval(self):
+        # DST begins at 2012-3-11T02:00:00 and ends at 2012-11-4T02:00:00.
+        DT = datetime.datetime
+        def test(current, expected):
+            actual = fh.computeRollover(current.timestamp())
+            diff = actual - expected.timestamp()
+            if diff:
+                self.assertEqual(diff, 0, datetime.timedelta(seconds=diff))
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False, interval=3)
+
+        test(DT(2012, 3, 8, 23, 59, 59), DT(2012, 3, 11, 0, 0))
+        test(DT(2012, 3, 9, 0, 0), DT(2012, 3, 12, 0, 0))
+        test(DT(2012, 3, 9, 1, 0), DT(2012, 3, 12, 0, 0))
+        test(DT(2012, 3, 10, 23, 59, 59), DT(2012, 3, 13, 0, 0))
+        test(DT(2012, 3, 11, 0, 0), DT(2012, 3, 14, 0, 0))
+        test(DT(2012, 3, 11, 1, 0), DT(2012, 3, 14, 0, 0))
+
+        test(DT(2012, 11, 1, 23, 59, 59), DT(2012, 11, 4, 0, 0))
+        test(DT(2012, 11, 2, 0, 0), DT(2012, 11, 5, 0, 0))
+        test(DT(2012, 11, 2, 1, 0), DT(2012, 11, 5, 0, 0))
+        test(DT(2012, 11, 3, 23, 59, 59), DT(2012, 11, 6, 0, 0))
+        test(DT(2012, 11, 4, 0, 0), DT(2012, 11, 7, 0, 0))
+        test(DT(2012, 11, 4, 1, 0), DT(2012, 11, 7, 0, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='MIDNIGHT', utc=False, interval=3,
+            atTime=datetime.time(12, 0, 0))
+
+        test(DT(2012, 3, 8, 11, 59, 59), DT(2012, 3, 10, 12, 0))
+        test(DT(2012, 3, 8, 12, 0), DT(2012, 3, 11, 12, 0))
+        test(DT(2012, 3, 8, 13, 0), DT(2012, 3, 11, 12, 0))
+        test(DT(2012, 3, 10, 11, 59, 59), DT(2012, 3, 12, 12, 0))
+        test(DT(2012, 3, 10, 12, 0), DT(2012, 3, 13, 12, 0))
+        test(DT(2012, 3, 10, 13, 0), DT(2012, 3, 13, 12, 0))
+
+        test(DT(2012, 11, 1, 11, 59, 59), DT(2012, 11, 3, 12, 0))
+        test(DT(2012, 11, 1, 12, 0), DT(2012, 11, 4, 12, 0))
+        test(DT(2012, 11, 1, 13, 0), DT(2012, 11, 4, 12, 0))
+        test(DT(2012, 11, 3, 11, 59, 59), DT(2012, 11, 5, 12, 0))
+        test(DT(2012, 11, 3, 12, 0), DT(2012, 11, 6, 12, 0))
+        test(DT(2012, 11, 3, 13, 0), DT(2012, 11, 6, 12, 0))
+
+        fh.close()
+
+    # Run with US-style DST rules: DST begins 2 a.m. on second Sunday in
+    # March (M3.2.0) and ends 2 a.m. on first Sunday in November (M11.1.0).
+    @support.run_with_tz('EST+05EDT,M3.2.0,M11.1.0')
+    def test_compute_rollover_W6_local_interval(self):
+        # DST begins at 2012-3-11T02:00:00 and ends at 2012-11-4T02:00:00.
+        DT = datetime.datetime
+        def test(current, expected):
+            actual = fh.computeRollover(current.timestamp())
+            diff = actual - expected.timestamp()
+            if diff:
+                self.assertEqual(diff, 0, datetime.timedelta(seconds=diff))
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False, interval=3)
+
+        test(DT(2012, 2, 19, 23, 59, 59), DT(2012, 3, 5, 0, 0))
+        test(DT(2012, 2, 20, 0, 0), DT(2012, 3, 12, 0, 0))
+        test(DT(2012, 2, 20, 1, 0), DT(2012, 3, 12, 0, 0))
+        test(DT(2012, 3, 4, 23, 59, 59), DT(2012, 3, 19, 0, 0))
+        test(DT(2012, 3, 5, 0, 0), DT(2012, 3, 26, 0, 0))
+        test(DT(2012, 3, 5, 1, 0), DT(2012, 3, 26, 0, 0))
+
+        test(DT(2012, 10, 14, 23, 59, 59), DT(2012, 10, 29, 0, 0))
+        test(DT(2012, 10, 15, 0, 0), DT(2012, 11, 5, 0, 0))
+        test(DT(2012, 10, 15, 1, 0), DT(2012, 11, 5, 0, 0))
+        test(DT(2012, 10, 28, 23, 59, 59), DT(2012, 11, 12, 0, 0))
+        test(DT(2012, 10, 29, 0, 0), DT(2012, 11, 19, 0, 0))
+        test(DT(2012, 10, 29, 1, 0), DT(2012, 11, 19, 0, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False, interval=3,
+            atTime=datetime.time(0, 0, 0))
+
+        test(DT(2012, 2, 25, 23, 59, 59), DT(2012, 3, 11, 0, 0))
+        test(DT(2012, 2, 26, 0, 0), DT(2012, 3, 18, 0, 0))
+        test(DT(2012, 2, 26, 1, 0), DT(2012, 3, 18, 0, 0))
+        test(DT(2012, 3, 10, 23, 59, 59), DT(2012, 3, 25, 0, 0))
+        test(DT(2012, 3, 11, 0, 0), DT(2012, 4, 1, 0, 0))
+        test(DT(2012, 3, 11, 1, 0), DT(2012, 4, 1, 0, 0))
+
+        test(DT(2012, 10, 20, 23, 59, 59), DT(2012, 11, 4, 0, 0))
+        test(DT(2012, 10, 21, 0, 0), DT(2012, 11, 11, 0, 0))
+        test(DT(2012, 10, 21, 1, 0), DT(2012, 11, 11, 0, 0))
+        test(DT(2012, 11, 3, 23, 59, 59), DT(2012, 11, 18, 0, 0))
+        test(DT(2012, 11, 4, 0, 0), DT(2012, 11, 25, 0, 0))
+        test(DT(2012, 11, 4, 1, 0), DT(2012, 11, 25, 0, 0))
+
+        fh.close()
+
+        fh = logging.handlers.TimedRotatingFileHandler(
+            self.fn, encoding="utf-8", when='W6', utc=False, interval=3,
+            atTime=datetime.time(12, 0, 0))
+
+        test(DT(2012, 2, 18, 11, 59, 59), DT(2012, 3, 4, 12, 0))
+        test(DT(2012, 2, 19, 12, 0), DT(2012, 3, 11, 12, 0))
+        test(DT(2012, 2, 19, 13, 0), DT(2012, 3, 11, 12, 0))
+        test(DT(2012, 3, 4, 11, 59, 59), DT(2012, 3, 18, 12, 0))
+        test(DT(2012, 3, 4, 12, 0), DT(2012, 3, 25, 12, 0))
+        test(DT(2012, 3, 4, 13, 0), DT(2012, 3, 25, 12, 0))
+
+        test(DT(2012, 10, 14, 11, 59, 59), DT(2012, 10, 28, 12, 0))
+        test(DT(2012, 10, 14, 12, 0), DT(2012, 11, 4, 12, 0))
+        test(DT(2012, 10, 14, 13, 0), DT(2012, 11, 4, 12, 0))
+        test(DT(2012, 10, 28, 11, 59, 59), DT(2012, 11, 11, 12, 0))
+        test(DT(2012, 10, 28, 12, 0), DT(2012, 11, 18, 12, 0))
+        test(DT(2012, 10, 28, 13, 0), DT(2012, 11, 18, 12, 0))
+
+        fh.close()
 
 
 def secs(**kw):
@@ -6059,40 +6656,49 @@ def secs(**kw):
                   # current time (epoch start) is a Thursday, W0 means Monday
                   ('W0', secs(days=4, hours=24)),
                  ):
-    def test_compute_rollover(self, when=when, exp=exp):
-        rh = logging.handlers.TimedRotatingFileHandler(
-            self.fn, encoding="utf-8", when=when, interval=1, backupCount=0, utc=True)
-        currentTime = 0.0
-        actual = rh.computeRollover(currentTime)
-        if exp != actual:
-            # Failures occur on some systems for MIDNIGHT and W0.
-            # Print detailed calculation for MIDNIGHT so we can try to see
-            # what's going on
-            if when == 'MIDNIGHT':
-                try:
-                    if rh.utc:
-                        t = time.gmtime(currentTime)
-                    else:
-                        t = time.localtime(currentTime)
-                    currentHour = t[3]
-                    currentMinute = t[4]
-                    currentSecond = t[5]
-                    # r is the number of seconds left between now and midnight
-                    r = logging.handlers._MIDNIGHT - ((currentHour * 60 +
-                                                       currentMinute) * 60 +
-                            currentSecond)
-                    result = currentTime + r
-                    print('t: %s (%s)' % (t, rh.utc), file=sys.stderr)
-                    print('currentHour: %s' % currentHour, file=sys.stderr)
-                    print('currentMinute: %s' % currentMinute, file=sys.stderr)
-                    print('currentSecond: %s' % currentSecond, file=sys.stderr)
-                    print('r: %s' % r, file=sys.stderr)
-                    print('result: %s' % result, file=sys.stderr)
-                except Exception as e:
-                    print('exception in diagnostic code: %s' % e, file=sys.stderr)
-        self.assertEqual(exp, actual)
-        rh.close()
-    setattr(TimedRotatingFileHandlerTest, "test_compute_rollover_%s" % when, test_compute_rollover)
+    for interval in 1, 3:
+        def test_compute_rollover(self, when=when, interval=interval, exp=exp):
+            rh = logging.handlers.TimedRotatingFileHandler(
+                self.fn, encoding="utf-8", when=when, interval=interval, backupCount=0, utc=True)
+            currentTime = 0.0
+            actual = rh.computeRollover(currentTime)
+            if when.startswith('W'):
+                exp += secs(days=7*(interval-1))
+            else:
+                exp *= interval
+            if exp != actual:
+                # Failures occur on some systems for MIDNIGHT and W0.
+                # Print detailed calculation for MIDNIGHT so we can try to see
+                # what's going on
+                if when == 'MIDNIGHT':
+                    try:
+                        if rh.utc:
+                            t = time.gmtime(currentTime)
+                        else:
+                            t = time.localtime(currentTime)
+                        currentHour = t[3]
+                        currentMinute = t[4]
+                        currentSecond = t[5]
+                        # r is the number of seconds left between now and midnight
+                        r = logging.handlers._MIDNIGHT - ((currentHour * 60 +
+                                                        currentMinute) * 60 +
+                                currentSecond)
+                        result = currentTime + r
+                        print('t: %s (%s)' % (t, rh.utc), file=sys.stderr)
+                        print('currentHour: %s' % currentHour, file=sys.stderr)
+                        print('currentMinute: %s' % currentMinute, file=sys.stderr)
+                        print('currentSecond: %s' % currentSecond, file=sys.stderr)
+                        print('r: %s' % r, file=sys.stderr)
+                        print('result: %s' % result, file=sys.stderr)
+                    except Exception as e:
+                        print('exception in diagnostic code: %s' % e, file=sys.stderr)
+            self.assertEqual(exp, actual)
+            rh.close()
+        name = "test_compute_rollover_%s" % when
+        if interval > 1:
+            name += "_interval"
+        test_compute_rollover.__name__ = name
+        setattr(TimedRotatingFileHandlerTest, name, test_compute_rollover)
 
 
 @unittest.skipUnless(win32evtlog, 'win32evtlog/win32evtlogutil/pywintypes required for this test.')
diff --git a/Lib/test/test_lzma.py b/Lib/test/test_lzma.py
index 65e6488c5d..db290e1393 100644
--- a/Lib/test/test_lzma.py
+++ b/Lib/test/test_lzma.py
@@ -2,7 +2,6 @@
 import array
 from io import BytesIO, UnsupportedOperation, DEFAULT_BUFFER_SIZE
 import os
-import pathlib
 import pickle
 import random
 import sys
@@ -12,7 +11,7 @@
 from test.support import _4G, bigmemtest
 from test.support.import_helper import import_module
 from test.support.os_helper import (
-    TESTFN, unlink
+    TESTFN, unlink, FakePath
 )
 
 lzma = import_module("lzma")
@@ -548,7 +547,7 @@ def test_init(self):
             pass
 
     def test_init_with_PathLike_filename(self):
-        filename = pathlib.Path(TESTFN)
+        filename = FakePath(TESTFN)
         with TempFile(filename, COMPRESSED_XZ):
             with LZMAFile(filename) as f:
                 self.assertEqual(f.read(), INPUT)
@@ -585,11 +584,10 @@ def test_init_with_x_mode(self):
         self.addCleanup(unlink, TESTFN)
         for mode in ("x", "xb"):
             unlink(TESTFN)
-            with LZMAFile(TESTFN, mode):
+            with LZMAFile(TESTFN, mode) as f:
                 pass
             with self.assertRaises(FileExistsError):
-                with LZMAFile(TESTFN, mode):
-                    pass
+                LZMAFile(TESTFN, mode)
 
     def test_init_bad_mode(self):
         with self.assertRaises(ValueError):
@@ -867,17 +865,59 @@ def test_read_from_file(self):
             with LZMAFile(TESTFN) as f:
                 self.assertEqual(f.read(), INPUT)
                 self.assertEqual(f.read(), b"")
+                self.assertIsInstance(f.fileno(), int)
+                self.assertIs(f.readable(), True)
+                self.assertIs(f.writable(), False)
+                self.assertIs(f.seekable(), True)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertRaises(ValueError, f.fileno)
+            self.assertRaises(ValueError, f.readable)
+            self.assertRaises(ValueError, f.writable)
+            self.assertRaises(ValueError, f.seekable)
 
     def test_read_from_file_with_bytes_filename(self):
-        try:
-            bytes_filename = TESTFN.encode("ascii")
-        except UnicodeEncodeError:
-            self.skipTest("Temporary file name needs to be ASCII")
+        bytes_filename = os.fsencode(TESTFN)
         with TempFile(TESTFN, COMPRESSED_XZ):
             with LZMAFile(bytes_filename) as f:
                 self.assertEqual(f.read(), INPUT)
                 self.assertEqual(f.read(), b"")
 
+    def test_read_from_fileobj(self):
+        with TempFile(TESTFN, COMPRESSED_XZ):
+            with open(TESTFN, 'rb') as raw:
+                with LZMAFile(raw) as f:
+                    self.assertEqual(f.read(), INPUT)
+                    self.assertEqual(f.read(), b"")
+                    self.assertEqual(f.fileno(), raw.fileno())
+                    self.assertIs(f.readable(), True)
+                    self.assertIs(f.writable(), False)
+                    self.assertIs(f.seekable(), True)
+                    self.assertIs(f.closed, False)
+                self.assertIs(f.closed, True)
+                self.assertRaises(ValueError, f.fileno)
+                self.assertRaises(ValueError, f.readable)
+                self.assertRaises(ValueError, f.writable)
+                self.assertRaises(ValueError, f.seekable)
+
+    def test_read_from_fileobj_with_int_name(self):
+        with TempFile(TESTFN, COMPRESSED_XZ):
+            fd = os.open(TESTFN, os.O_RDONLY)
+            with open(fd, 'rb') as raw:
+                with LZMAFile(raw) as f:
+                    self.assertEqual(f.read(), INPUT)
+                    self.assertEqual(f.read(), b"")
+                    self.assertEqual(f.fileno(), raw.fileno())
+                    self.assertIs(f.readable(), True)
+                    self.assertIs(f.writable(), False)
+                    self.assertIs(f.seekable(), True)
+                    self.assertIs(f.closed, False)
+                self.assertIs(f.closed, True)
+                self.assertRaises(ValueError, f.fileno)
+                self.assertRaises(ValueError, f.readable)
+                self.assertRaises(ValueError, f.writable)
+                self.assertRaises(ValueError, f.seekable)
+
     def test_read_incomplete(self):
         with LZMAFile(BytesIO(COMPRESSED_XZ[:128])) as f:
             self.assertRaises(EOFError, f.read)
@@ -1051,6 +1091,17 @@ def test_write_to_file(self):
         try:
             with LZMAFile(TESTFN, "w") as f:
                 f.write(INPUT)
+                self.assertIsInstance(f.fileno(), int)
+                self.assertIs(f.readable(), False)
+                self.assertIs(f.writable(), True)
+                self.assertIs(f.seekable(), False)
+                self.assertIs(f.closed, False)
+            self.assertIs(f.closed, True)
+            self.assertRaises(ValueError, f.fileno)
+            self.assertRaises(ValueError, f.readable)
+            self.assertRaises(ValueError, f.writable)
+            self.assertRaises(ValueError, f.seekable)
+
             expected = lzma.compress(INPUT)
             with open(TESTFN, "rb") as f:
                 self.assertEqual(f.read(), expected)
@@ -1058,10 +1109,7 @@ def test_write_to_file(self):
             unlink(TESTFN)
 
     def test_write_to_file_with_bytes_filename(self):
-        try:
-            bytes_filename = TESTFN.encode("ascii")
-        except UnicodeEncodeError:
-            self.skipTest("Temporary file name needs to be ASCII")
+        bytes_filename = os.fsencode(TESTFN)
         try:
             with LZMAFile(bytes_filename, "w") as f:
                 f.write(INPUT)
@@ -1071,6 +1119,51 @@ def test_write_to_file_with_bytes_filename(self):
         finally:
             unlink(TESTFN)
 
+    def test_write_to_fileobj(self):
+        try:
+            with open(TESTFN, "wb") as raw:
+                with LZMAFile(raw, "w") as f:
+                    f.write(INPUT)
+                    self.assertEqual(f.fileno(), raw.fileno())
+                    self.assertIs(f.readable(), False)
+                    self.assertIs(f.writable(), True)
+                    self.assertIs(f.seekable(), False)
+                    self.assertIs(f.closed, False)
+                self.assertIs(f.closed, True)
+                self.assertRaises(ValueError, f.fileno)
+                self.assertRaises(ValueError, f.readable)
+                self.assertRaises(ValueError, f.writable)
+                self.assertRaises(ValueError, f.seekable)
+
+            expected = lzma.compress(INPUT)
+            with open(TESTFN, "rb") as f:
+                self.assertEqual(f.read(), expected)
+        finally:
+            unlink(TESTFN)
+
+    def test_write_to_fileobj_with_int_name(self):
+        try:
+            fd = os.open(TESTFN, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)
+            with open(fd, 'wb') as raw:
+                with LZMAFile(raw, "w") as f:
+                    f.write(INPUT)
+                    self.assertEqual(f.fileno(), raw.fileno())
+                    self.assertIs(f.readable(), False)
+                    self.assertIs(f.writable(), True)
+                    self.assertIs(f.seekable(), False)
+                    self.assertIs(f.closed, False)
+                self.assertIs(f.closed, True)
+                self.assertRaises(ValueError, f.fileno)
+                self.assertRaises(ValueError, f.readable)
+                self.assertRaises(ValueError, f.writable)
+                self.assertRaises(ValueError, f.seekable)
+
+            expected = lzma.compress(INPUT)
+            with open(TESTFN, "rb") as f:
+                self.assertEqual(f.read(), expected)
+        finally:
+            unlink(TESTFN)
+
     def test_write_append_to_file(self):
         part1 = INPUT[:1024]
         part2 = INPUT[1024:1536]
@@ -1276,7 +1369,7 @@ def test_filename(self):
                 self.assertEqual(f.read(), INPUT * 2)
 
     def test_with_pathlike_filename(self):
-        filename = pathlib.Path(TESTFN)
+        filename = FakePath(TESTFN)
         with TempFile(filename):
             with lzma.open(filename, "wb") as f:
                 f.write(INPUT)
diff --git a/Lib/test/test_mimetypes.py b/Lib/test/test_mimetypes.py
index d64aee71fc..cc91d539d4 100644
--- a/Lib/test/test_mimetypes.py
+++ b/Lib/test/test_mimetypes.py
@@ -1,5 +1,6 @@
 import io
 import mimetypes
+import os
 import pathlib
 import sys
 import unittest.mock
@@ -111,15 +112,40 @@ def test_filename_with_url_delimiters(self):
         # compared to when interpreted as filename because of the semicolon.
         eq = self.assertEqual
         gzip_expected = ('application/x-tar', 'gzip')
-        eq(self.db.guess_type(";1.tar.gz"), gzip_expected)
-        eq(self.db.guess_type("?1.tar.gz"), gzip_expected)
-        eq(self.db.guess_type("#1.tar.gz"), gzip_expected)
-        eq(self.db.guess_type("#1#.tar.gz"), gzip_expected)
-        eq(self.db.guess_type(";1#.tar.gz"), gzip_expected)
-        eq(self.db.guess_type(";&1=123;?.tar.gz"), gzip_expected)
-        eq(self.db.guess_type("?k1=v1&k2=v2.tar.gz"), gzip_expected)
+        for name in (
+                ';1.tar.gz',
+                '?1.tar.gz',
+                '#1.tar.gz',
+                '#1#.tar.gz',
+                ';1#.tar.gz',
+                ';&1=123;?.tar.gz',
+                '?k1=v1&k2=v2.tar.gz',
+            ):
+            for prefix in ('', '/', '\\',
+                           'c:', 'c:/', 'c:\\', 'c:/d/', 'c:\\d\\',
+                           '//share/server/', '\\\\share\\server\\'):
+                path = prefix + name
+                with self.subTest(path=path):
+                    eq(self.db.guess_type(path), gzip_expected)
+            expected = (None, None) if os.name == 'nt' else gzip_expected
+            for prefix in ('//', '\\\\', '//share/', '\\\\share\\'):
+                path = prefix + name
+                with self.subTest(path=path):
+                    eq(self.db.guess_type(path), expected)
         eq(self.db.guess_type(r" \"\`;b&b&c |.tar.gz"), gzip_expected)
 
+    def test_url(self):
+        result = self.db.guess_type('http://host.html')
+        msg = 'URL only has a host name, not a file'
+        self.assertSequenceEqual(result, (None, None), msg)
+        result = self.db.guess_type('http://example.com/host.html')
+        msg = 'Should be text/html'
+        self.assertSequenceEqual(result, ('text/html', None), msg)
+        result = self.db.guess_type('http://example.com/host.html#x.tar')
+        self.assertSequenceEqual(result, ('text/html', None))
+        result = self.db.guess_type('http://example.com/host.html?q=x.tar')
+        self.assertSequenceEqual(result, ('text/html', None))
+
     def test_guess_all_types(self):
         # First try strict.  Use a set here for testing the results because if
         # test_urllib2 is run before test_mimetypes, global state is modified
diff --git a/Lib/test/test_monitoring.py b/Lib/test/test_monitoring.py
index 8eaf581b8d..d5d271fe54 100644
--- a/Lib/test/test_monitoring.py
+++ b/Lib/test/test_monitoring.py
@@ -1743,3 +1743,21 @@ def test_gh108976(self):
         sys.monitoring.register_callback(0, E.INSTRUCTION, lambda *args: 0)
         sys.monitoring.set_events(0, E.LINE | E.INSTRUCTION)
         sys.monitoring.set_events(0, 0)
+
+    def test_call_function_ex(self):
+        def f(a=1, b=2):
+            return a + b
+        args = (1, 2)
+        empty_args = []
+
+        call_data = []
+        sys.monitoring.use_tool_id(0, "test")
+        self.addCleanup(sys.monitoring.free_tool_id, 0)
+        sys.monitoring.set_events(0, 0)
+        sys.monitoring.register_callback(0, E.CALL, lambda code, offset, callable, arg0: call_data.append((callable, arg0)))
+        sys.monitoring.set_events(0, E.CALL)
+        f(*args)
+        f(*empty_args)
+        sys.monitoring.set_events(0, 0)
+        self.assertEqual(call_data[0], (f, 1))
+        self.assertEqual(call_data[1], (f, sys.monitoring.MISSING))
diff --git a/Lib/test/test_named_expressions.py b/Lib/test/test_named_expressions.py
index 7b2fa84482..cf44080670 100644
--- a/Lib/test/test_named_expressions.py
+++ b/Lib/test/test_named_expressions.py
@@ -298,6 +298,82 @@ def test_named_expression_invalid_set_comprehension_iterable_expression(self):
                 with self.assertRaisesRegex(SyntaxError, msg):
                     exec(f"lambda: {code}", {}) # Function scope
 
+    def test_named_expression_invalid_rebinding_dict_comprehension_iteration_variable(self):
+        cases = [
+            ("Key reuse", 'i', "{(i := 0): 1 for i in range(5)}"),
+            ("Value reuse", 'i', "{1: (i := 0) for i in range(5)}"),
+            ("Both reuse", 'i', "{(i := 0): (i := 0) for i in range(5)}"),
+            ("Nested reuse", 'j', "{{(j := 0): 1 for i in range(5)} for j in range(5)}"),
+            ("Reuse inner loop target", 'j', "{(j := 0): 1 for i in range(5) for j in range(5)}"),
+            ("Unpacking key reuse", 'i', "{(i := 0): 1 for i, j in {(0, 1)}}"),
+            ("Unpacking value reuse", 'i', "{1: (i := 0) for i, j in {(0, 1)}}"),
+            ("Reuse in loop condition", 'i', "{i+1: 1 for i in range(5) if (i := 0)}"),
+            ("Unreachable reuse", 'i', "{(False or (i:=0)): 1 for i in range(5)}"),
+            ("Unreachable nested reuse", 'i',
+                "{i: j for i in range(5) for j in range(5) if True or (i:=10)}"),
+            # Regression tests from https://github.com/python/cpython/issues/87447
+            ("Complex expression: a", "a",
+                "{(a := 1): 1 for a, (*b, c[d+e::f(g)], h.i) in j}"),
+            ("Complex expression: b", "b",
+                "{(b := 1): 1 for a, (*b, c[d+e::f(g)], h.i) in j}"),
+        ]
+        for case, target, code in cases:
+            msg = f"assignment expression cannot rebind comprehension iteration variable '{target}'"
+            with self.subTest(case=case):
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(code, {}) # Module scope
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(code, {}, {}) # Class scope
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(f"lambda: {code}", {}) # Function scope
+
+    def test_named_expression_invalid_rebinding_dict_comprehension_inner_loop(self):
+        cases = [
+            ("Inner reuse", 'j', "{i: 1 for i in range(5) if (j := 0) for j in range(5)}"),
+            ("Inner unpacking reuse", 'j', "{i: 1 for i in range(5) if (j := 0) for j, k in {(0, 1)}}"),
+        ]
+        for case, target, code in cases:
+            msg = f"comprehension inner loop cannot rebind assignment expression target '{target}'"
+            with self.subTest(case=case):
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(code, {}) # Module scope
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(code, {}, {}) # Class scope
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(f"lambda: {code}", {}) # Function scope
+
+    def test_named_expression_invalid_dict_comprehension_iterable_expression(self):
+        cases = [
+            ("Top level", "{i: 1 for i in (i := range(5))}"),
+            ("Inside tuple", "{i: 1 for i in (2, 3, i := range(5))}"),
+            ("Inside list", "{i: 1 for i in [2, 3, i := range(5)]}"),
+            ("Different name", "{i: 1 for i in (j := range(5))}"),
+            ("Lambda expression", "{i: 1 for i in (lambda:(j := range(5)))()}"),
+            ("Inner loop", "{i: 1 for i in range(5) for j in (i := range(5))}"),
+            ("Nested comprehension", "{i: 1 for i in {j: 2 for j in (k := range(5))}}"),
+            ("Nested comprehension condition", "{i: 1 for i in {j: 2 for j in range(5) if (j := True)}}"),
+            ("Nested comprehension body", "{i: 1 for i in {(j := True) for j in range(5)}}"),
+        ]
+        msg = "assignment expression cannot be used in a comprehension iterable expression"
+        for case, code in cases:
+            with self.subTest(case=case):
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(code, {}) # Module scope
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(code, {}, {}) # Class scope
+                with self.assertRaisesRegex(SyntaxError, msg):
+                    exec(f"lambda: {code}", {}) # Function scope
+
+    def test_named_expression_invalid_mangled_class_variables(self):
+        code = """class Foo:
+            def bar(self):
+                [[(__x:=2) for _ in range(2)] for __x in range(2)]
+        """
+
+        with self.assertRaisesRegex(SyntaxError,
+            "assignment expression cannot rebind comprehension iteration variable '__x'"):
+            exec(code, {}, {})
+
 
 class NamedExpressionAssignmentTest(unittest.TestCase):
 
@@ -351,7 +427,7 @@ def test_named_expression_assignment_09(self):
 
     def test_named_expression_assignment_10(self):
         if (match := 10) == 10:
-            pass
+            self.assertEqual(match, 10)
         else: self.fail("variable was not assigned using named expression")
 
     def test_named_expression_assignment_11(self):
@@ -393,7 +469,7 @@ def test_named_expression_assignment_14(self):
 
     def test_named_expression_assignment_15(self):
         while a := False:
-            pass  # This will not run
+            self.fail("While body executed")  # This will not run
 
         self.assertEqual(a, False)
 
@@ -674,6 +750,18 @@ def test_named_expression_scope_in_genexp(self):
         for idx, elem in enumerate(genexp):
             self.assertEqual(elem, b[idx] + a)
 
+    def test_named_expression_scope_mangled_names(self):
+        class Foo:
+            def f(self_):
+                global __x1
+                __x1 = 0
+                [_Foo__x1 := 1 for a in [2]]
+                self.assertEqual(__x1, 1)
+                [__x1 := 2 for a in [3]]
+                self.assertEqual(__x1, 2)
+
+        Foo().f()
+        self.assertEqual(_Foo__x1, 2)
 
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_operator.py b/Lib/test/test_operator.py
index 1db738d228..0d34d67156 100644
--- a/Lib/test/test_operator.py
+++ b/Lib/test/test_operator.py
@@ -1,6 +1,8 @@
 import unittest
 import pickle
 import sys
+from decimal import Decimal
+from fractions import Fraction
 
 from test import support
 from test.support import import_helper
@@ -508,6 +510,44 @@ def __getitem__(self, other): return 5  # so that C is a sequence
         self.assertEqual(operator.ixor     (c, 5), "ixor")
         self.assertEqual(operator.iconcat  (c, c), "iadd")
 
+    def test_iconcat_without_getitem(self):
+        operator = self.module
+
+        msg = "'int' object can't be concatenated"
+        with self.assertRaisesRegex(TypeError, msg):
+            operator.iconcat(1, 0.5)
+
+    def test_index(self):
+        operator = self.module
+        class X:
+            def __index__(self):
+                return 1
+
+        self.assertEqual(operator.index(X()), 1)
+        self.assertEqual(operator.index(0), 0)
+        self.assertEqual(operator.index(1), 1)
+        self.assertEqual(operator.index(2), 2)
+        with self.assertRaises((AttributeError, TypeError)):
+            operator.index(1.5)
+        with self.assertRaises((AttributeError, TypeError)):
+            operator.index(Fraction(3, 7))
+        with self.assertRaises((AttributeError, TypeError)):
+            operator.index(Decimal(1))
+        with self.assertRaises((AttributeError, TypeError)):
+            operator.index(None)
+
+    def test_not_(self):
+        operator = self.module
+        class C:
+            def __bool__(self):
+                raise SyntaxError
+        self.assertRaises(TypeError, operator.not_)
+        self.assertRaises(SyntaxError, operator.not_, C())
+        self.assertFalse(operator.not_(5))
+        self.assertFalse(operator.not_([0]))
+        self.assertTrue(operator.not_(0))
+        self.assertTrue(operator.not_([]))
+
     def test_length_hint(self):
         operator = self.module
         class X(object):
@@ -533,6 +573,13 @@ def __length_hint__(self):
         with self.assertRaises(LookupError):
             operator.length_hint(X(LookupError))
 
+        class Y: pass
+
+        msg = "'str' object cannot be interpreted as an integer"
+        with self.assertRaisesRegex(TypeError, msg):
+            operator.length_hint(X(2), "abc")
+        self.assertEqual(operator.length_hint(Y(), 10), 10)
+
     def test_call(self):
         operator = self.module
 
diff --git a/Lib/test/test_os.py b/Lib/test/test_os.py
index fc58f8d2dc..e8f8004664 100644
--- a/Lib/test/test_os.py
+++ b/Lib/test/test_os.py
@@ -1290,6 +1290,7 @@ def test_ror_operator(self):
 
 class WalkTests(unittest.TestCase):
     """Tests for os.walk()."""
+    is_fwalk = False
 
     # Wrapper to hide minor differences between os.walk and os.fwalk
     # to tests both functions with the same code base
@@ -1324,14 +1325,14 @@ def setUp(self):
         self.sub11_path = join(self.sub1_path, "SUB11")
         sub2_path = join(self.walk_path, "SUB2")
         sub21_path = join(sub2_path, "SUB21")
-        tmp1_path = join(self.walk_path, "tmp1")
+        self.tmp1_path = join(self.walk_path, "tmp1")
         tmp2_path = join(self.sub1_path, "tmp2")
         tmp3_path = join(sub2_path, "tmp3")
         tmp5_path = join(sub21_path, "tmp3")
         self.link_path = join(sub2_path, "link")
         t2_path = join(os_helper.TESTFN, "TEST2")
         tmp4_path = join(os_helper.TESTFN, "TEST2", "tmp4")
-        broken_link_path = join(sub2_path, "broken_link")
+        self.broken_link_path = join(sub2_path, "broken_link")
         broken_link2_path = join(sub2_path, "broken_link2")
         broken_link3_path = join(sub2_path, "broken_link3")
 
@@ -1341,13 +1342,13 @@ def setUp(self):
         os.makedirs(sub21_path)
         os.makedirs(t2_path)
 
-        for path in tmp1_path, tmp2_path, tmp3_path, tmp4_path, tmp5_path:
+        for path in self.tmp1_path, tmp2_path, tmp3_path, tmp4_path, tmp5_path:
             with open(path, "x", encoding='utf-8') as f:
                 f.write("I'm " + path + " and proud of it.  Blame test_os.\n")
 
         if os_helper.can_symlink():
             os.symlink(os.path.abspath(t2_path), self.link_path)
-            os.symlink('broken', broken_link_path, True)
+            os.symlink('broken', self.broken_link_path, True)
             os.symlink(join('tmp3', 'broken'), broken_link2_path, True)
             os.symlink(join('SUB21', 'tmp5'), broken_link3_path, True)
             self.sub2_tree = (sub2_path, ["SUB21", "link"],
@@ -1443,6 +1444,11 @@ def test_walk_symlink(self):
         else:
             self.fail("Didn't follow symlink with followlinks=True")
 
+        walk_it = self.walk(self.broken_link_path, follow_symlinks=True)
+        if self.is_fwalk:
+            self.assertRaises(FileNotFoundError, next, walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+
     def test_walk_bad_dir(self):
         # Walk top-down.
         errors = []
@@ -1464,6 +1470,73 @@ def test_walk_bad_dir(self):
         finally:
             os.rename(path1new, path1)
 
+    def test_walk_bad_dir2(self):
+        walk_it = self.walk('nonexisting')
+        if self.is_fwalk:
+            self.assertRaises(FileNotFoundError, next, walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+
+        walk_it = self.walk('nonexisting', follow_symlinks=True)
+        if self.is_fwalk:
+            self.assertRaises(FileNotFoundError, next, walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+
+        walk_it = self.walk(self.tmp1_path)
+        self.assertRaises(StopIteration, next, walk_it)
+
+        walk_it = self.walk(self.tmp1_path, follow_symlinks=True)
+        if self.is_fwalk:
+            self.assertRaises(NotADirectoryError, next, walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+
+    @unittest.skipUnless(hasattr(os, "mkfifo"), 'requires os.mkfifo()')
+    @unittest.skipIf(sys.platform == "vxworks",
+                    "fifo requires special path on VxWorks")
+    def test_walk_named_pipe(self):
+        path = os_helper.TESTFN + '-pipe'
+        os.mkfifo(path)
+        self.addCleanup(os.unlink, path)
+
+        walk_it = self.walk(path)
+        self.assertRaises(StopIteration, next, walk_it)
+
+        walk_it = self.walk(path, follow_symlinks=True)
+        if self.is_fwalk:
+            self.assertRaises(NotADirectoryError, next, walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+
+    @unittest.skipUnless(hasattr(os, "mkfifo"), 'requires os.mkfifo()')
+    @unittest.skipIf(sys.platform == "vxworks",
+                    "fifo requires special path on VxWorks")
+    def test_walk_named_pipe2(self):
+        path = os_helper.TESTFN + '-dir'
+        os.mkdir(path)
+        self.addCleanup(shutil.rmtree, path)
+        os.mkfifo(os.path.join(path, 'mypipe'))
+
+        errors = []
+        walk_it = self.walk(path, onerror=errors.append)
+        next(walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+        self.assertEqual(errors, [])
+
+        errors = []
+        walk_it = self.walk(path, onerror=errors.append)
+        root, dirs, files = next(walk_it)
+        self.assertEqual(root, path)
+        self.assertEqual(dirs, [])
+        self.assertEqual(files, ['mypipe'])
+        dirs.extend(files)
+        files.clear()
+        if self.is_fwalk:
+            self.assertRaises(NotADirectoryError, next, walk_it)
+        self.assertRaises(StopIteration, next, walk_it)
+        if self.is_fwalk:
+            self.assertEqual(errors, [])
+        else:
+            self.assertEqual(len(errors), 1, errors)
+            self.assertIsInstance(errors[0], NotADirectoryError)
+
     def test_walk_many_open_files(self):
         depth = 30
         base = os.path.join(os_helper.TESTFN, 'deep')
@@ -1529,6 +1602,7 @@ def test_walk_above_recursion_limit(self):
 @unittest.skipUnless(hasattr(os, 'fwalk'), "Test needs os.fwalk()")
 class FwalkTests(WalkTests):
     """Tests for os.fwalk()."""
+    is_fwalk = True
 
     def walk(self, top, **kwargs):
         for root, dirs, files, root_fd in self.fwalk(top, **kwargs):
@@ -3121,10 +3195,9 @@ def cleanup():
         if support.verbose:
             print(" without access:", stat2)
 
-        # We cannot get st_dev/st_ino, so ensure those are 0 or else our test
-        # is not set up correctly
-        self.assertEqual(0, stat2.st_dev)
-        self.assertEqual(0, stat2.st_ino)
+        # We may not get st_dev/st_ino, so ensure those are 0 or match
+        self.assertIn(stat2.st_dev, (0, stat1.st_dev))
+        self.assertIn(stat2.st_ino, (0, stat1.st_ino))
 
         # st_mode and st_size should match (for a normal file, at least)
         self.assertEqual(stat1.st_mode, stat2.st_mode)
@@ -3485,22 +3558,22 @@ class ProgramPriorityTests(unittest.TestCase):
     """Tests for os.getpriority() and os.setpriority()."""
 
     def test_set_get_priority(self):
-
         base = os.getpriority(os.PRIO_PROCESS, os.getpid())
-        os.setpriority(os.PRIO_PROCESS, os.getpid(), base + 1)
-        try:
-            new_prio = os.getpriority(os.PRIO_PROCESS, os.getpid())
-            if base >= 19 and new_prio <= 19:
-                raise unittest.SkipTest("unable to reliably test setpriority "
-                                        "at current nice level of %s" % base)
-            else:
-                self.assertEqual(new_prio, base + 1)
-        finally:
-            try:
-                os.setpriority(os.PRIO_PROCESS, os.getpid(), base)
-            except OSError as err:
-                if err.errno != errno.EACCES:
-                    raise
+        code = f"""if 1:
+        import os
+        os.setpriority(os.PRIO_PROCESS, os.getpid(), {base} + 1)
+        print(os.getpriority(os.PRIO_PROCESS, os.getpid()))
+        """
+
+        # Subprocess inherits the current process' priority.
+        _, out, _ = assert_python_ok("-c", code)
+        new_prio = int(out)
+        # nice value cap is 19 for linux and 20 for FreeBSD
+        if base >= 19 and new_prio <= base:
+            raise unittest.SkipTest("unable to reliably test setpriority "
+                                    "at current nice level of %s" % base)
+        else:
+            self.assertEqual(new_prio, base + 1)
 
 
 @unittest.skipUnless(hasattr(os, 'sendfile'), "test needs os.sendfile()")
@@ -4767,20 +4840,21 @@ def test_fork_warns_when_non_python_thread_exists(self):
         self.assertEqual(err.decode("utf-8"), "")
         self.assertEqual(out.decode("utf-8"), "")
 
-    def test_fork_at_exit(self):
+    def test_fork_at_finalization(self):
         code = """if 1:
             import atexit
             import os
 
-            def exit_handler():
-                pid = os.fork()
-                if pid != 0:
-                    print("shouldn't be printed")
-
-            atexit.register(exit_handler)
+            class AtFinalization:
+                def __del__(self):
+                    print("OK")
+                    pid = os.fork()
+                    if pid != 0:
+                        print("shouldn't be printed")
+            at_finalization = AtFinalization()
         """
         _, out, err = assert_python_ok("-c", code)
-        self.assertEqual(b"", out)
+        self.assertEqual(b"OK\n", out)
         self.assertIn(b"can't fork at interpreter shutdown", err)
 
 
diff --git a/Lib/test/test_pathlib.py b/Lib/test/test_pathlib.py
index ec105ae1a0..ca604df70a 100644
--- a/Lib/test/test_pathlib.py
+++ b/Lib/test/test_pathlib.py
@@ -2634,15 +2634,15 @@ def test_is_char_device_false(self):
         self.assertIs((P / 'fileA\x00').is_char_device(), False)
 
     def test_is_char_device_true(self):
-        # Under Unix, /dev/null should generally be a char device.
-        P = self.cls('/dev/null')
+        # os.devnull should generally be a char device.
+        P = self.cls(os.devnull)
         if not P.exists():
-            self.skipTest("/dev/null required")
+            self.skipTest("null device required")
         self.assertTrue(P.is_char_device())
         self.assertFalse(P.is_block_device())
         self.assertFalse(P.is_file())
-        self.assertIs(self.cls('/dev/null\udfff').is_char_device(), False)
-        self.assertIs(self.cls('/dev/null\x00').is_char_device(), False)
+        self.assertIs(self.cls(f'{os.devnull}\udfff').is_char_device(), False)
+        self.assertIs(self.cls(f'{os.devnull}\x00').is_char_device(), False)
 
     def test_pickling_common(self):
         p = self.cls(BASE, 'fileA')
diff --git a/Lib/test/test_pdb.py b/Lib/test/test_pdb.py
index 51b844262e..5bdc5f22d0 100644
--- a/Lib/test/test_pdb.py
+++ b/Lib/test/test_pdb.py
@@ -1936,13 +1936,30 @@ def _run_pdb(self, pdb_args, commands, expected_returncode=0):
         )
         return stdout, stderr
 
-    def run_pdb_script(self, script, commands, expected_returncode=0):
+    def run_pdb_script(self, script, commands,
+                       expected_returncode=0,
+                       pdbrc=None,
+                       remove_home=False):
         """Run 'script' lines with pdb and the pdb 'commands'."""
         filename = 'main.py'
         with open(filename, 'w') as f:
             f.write(textwrap.dedent(script))
+
+        if pdbrc is not None:
+            with open('.pdbrc', 'w') as f:
+                f.write(textwrap.dedent(pdbrc))
+            self.addCleanup(os_helper.unlink, '.pdbrc')
         self.addCleanup(os_helper.unlink, filename)
-        return self._run_pdb([filename], commands, expected_returncode)
+
+        homesave = None
+        if remove_home:
+            homesave = os.environ.pop('HOME', None)
+        try:
+            stdout, stderr = self._run_pdb([filename], commands, expected_returncode)
+        finally:
+            if homesave is not None:
+                os.environ['HOME'] = homesave
+        return stdout, stderr
 
     def run_pdb_module(self, script, commands):
         """Runs the script code as part of a module"""
@@ -2013,6 +2030,18 @@ def br():
             ('br', 1),
         )
 
+    def test_spec(self):
+        # Test that __main__.__spec__ is set to None when running a script
+        script = """
+            import __main__
+            print(__main__.__spec__)
+        """
+
+        commands = "continue"
+
+        stdout, _ = self.run_pdb_script(script, commands)
+        self.assertIn('None', stdout)
+
     def test_issue7964(self):
         # open the file as binary so we can force \r\n newline
         with open(os_helper.TESTFN, 'wb') as f:
@@ -2170,37 +2199,99 @@ def test_issue26053(self):
         self.assertRegex(res, "Restarting .* with arguments:\na b c")
         self.assertRegex(res, "Restarting .* with arguments:\nd e f")
 
-    def test_readrc_kwarg(self):
+    def test_pdbrc_basic(self):
         script = textwrap.dedent("""
-            import pdb; pdb.Pdb(readrc=False).set_trace()
+            a = 1
+            b = 2
+        """)
 
-            print('hello')
+        pdbrc = textwrap.dedent("""
+            # Comments should be fine
+            n
+            p f"{a+8=}"
         """)
 
-        save_home = os.environ.pop('HOME', None)
-        try:
-            with os_helper.temp_cwd():
-                with open('.pdbrc', 'w') as f:
-                    f.write("invalid\n")
-
-                with open('main.py', 'w') as f:
-                    f.write(script)
-
-                cmd = [sys.executable, 'main.py']
-                proc = subprocess.Popen(
-                    cmd,
-                    stdout=subprocess.PIPE,
-                    stdin=subprocess.PIPE,
-                    stderr=subprocess.PIPE,
-                )
-                with proc:
-                    stdout, stderr = proc.communicate(b'q\n')
-                    self.assertNotIn(b"NameError: name 'invalid' is not defined",
-                                  stdout)
+        stdout, stderr = self.run_pdb_script(script, 'q\n', pdbrc=pdbrc, remove_home=True)
+        self.assertNotIn("SyntaxError", stdout)
+        self.assertIn("a+8=9", stdout)
 
-        finally:
-            if save_home is not None:
-                os.environ['HOME'] = save_home
+    def test_pdbrc_empty_line(self):
+        """Test that empty lines in .pdbrc are ignored."""
+
+        script = textwrap.dedent("""
+            a = 1
+            b = 2
+            c = 3
+        """)
+
+        pdbrc = textwrap.dedent("""
+            n
+
+        """)
+
+        stdout, stderr = self.run_pdb_script(script, 'q\n', pdbrc=pdbrc, remove_home=True)
+        self.assertIn("b = 2", stdout)
+        self.assertNotIn("c = 3", stdout)
+
+    def test_pdbrc_alias(self):
+        script = textwrap.dedent("""
+            class A:
+                def __init__(self):
+                    self.attr = 1
+            a = A()
+            b = 2
+        """)
+
+        pdbrc = textwrap.dedent("""
+            alias pi for k in %1.__dict__.keys(): print(f"%1.{k} = {%1.__dict__[k]}")
+            until 6
+            pi a
+        """)
+
+        stdout, stderr = self.run_pdb_script(script, 'q\n', pdbrc=pdbrc, remove_home=True)
+        self.assertIn("a.attr = 1", stdout)
+
+    def test_pdbrc_semicolon(self):
+        script = textwrap.dedent("""
+            class A:
+                def __init__(self):
+                    self.attr = 1
+            a = A()
+            b = 2
+        """)
+
+        pdbrc = textwrap.dedent("""
+            b 5;;c;;n
+        """)
+
+        stdout, stderr = self.run_pdb_script(script, 'q\n', pdbrc=pdbrc, remove_home=True)
+        self.assertIn("-> b = 2", stdout)
+
+    def test_pdbrc_commands(self):
+        script = textwrap.dedent("""
+            class A:
+                def __init__(self):
+                    self.attr = 1
+            a = A()
+            b = 2
+        """)
+
+        pdbrc = textwrap.dedent("""
+            b 6
+            commands 1 ;; p a;; end
+            c
+        """)
+
+        stdout, stderr = self.run_pdb_script(script, 'q\n', pdbrc=pdbrc, remove_home=True)
+        self.assertIn("<__main__.A object at", stdout)
+
+    def test_readrc_kwarg(self):
+        script = textwrap.dedent("""
+            print('hello')
+        """)
+
+        stdout, stderr = self.run_pdb_script(script, 'q\n', pdbrc='invalid', remove_home=True)
+        self.assertIn("NameError: name 'invalid' is not defined", stdout)
 
     def test_readrc_homedir(self):
         save_home = os.environ.pop("HOME", None)
@@ -2215,40 +2306,6 @@ def test_readrc_homedir(self):
                 if save_home is not None:
                     os.environ["HOME"] = save_home
 
-    def test_read_pdbrc_with_ascii_encoding(self):
-        script = textwrap.dedent("""
-            import pdb; pdb.Pdb().set_trace()
-            print('hello')
-        """)
-        save_home = os.environ.pop('HOME', None)
-        try:
-            with os_helper.temp_cwd():
-                with open('.pdbrc', 'w', encoding='utf-8') as f:
-                    f.write("Fran\u00E7ais")
-
-                with open('main.py', 'w', encoding='utf-8') as f:
-                    f.write(script)
-
-                cmd = [sys.executable, 'main.py']
-                env = {'PYTHONIOENCODING': 'ascii'}
-                if sys.platform == 'win32':
-                    env['PYTHONLEGACYWINDOWSSTDIO'] = 'non-empty-string'
-                proc = subprocess.Popen(
-                    cmd,
-                    stdout=subprocess.PIPE,
-                    stdin=subprocess.PIPE,
-                    stderr=subprocess.PIPE,
-                    env={**os.environ, **env}
-                )
-                with proc:
-                    stdout, stderr = proc.communicate(b'c\n')
-                    self.assertIn(b"UnicodeEncodeError: \'ascii\' codec can\'t encode character "
-                                  b"\'\\xe7\' in position 21: ordinal not in range(128)", stderr)
-
-        finally:
-            if save_home is not None:
-                os.environ['HOME'] = save_home
-
     def test_header(self):
         stdout = StringIO()
         header = 'Nobody expects... blah, blah, blah'
diff --git a/Lib/test/test_platform.py b/Lib/test/test_platform.py
index 2169733503..b62a9e3897 100644
--- a/Lib/test/test_platform.py
+++ b/Lib/test/test_platform.py
@@ -322,8 +322,36 @@ def test_java_ver(self):
         if sys.platform == 'java':  # Is never actually checked in CI
             self.assertTrue(all(res))
 
+    @unittest.skipUnless(support.MS_WINDOWS, 'This test only makes sense on Windows')
     def test_win32_ver(self):
-        res = platform.win32_ver()
+        release1, version1, csd1, ptype1 = 'a', 'b', 'c', 'd'
+        res = platform.win32_ver(release1, version1, csd1, ptype1)
+        self.assertEqual(len(res), 4)
+        release, version, csd, ptype = res
+        if release:
+            # Currently, release names always come from internal dicts,
+            # but this could change over time. For now, we just check that
+            # release is something different from what we have passed.
+            self.assertNotEqual(release, release1)
+        if version:
+            # It is rather hard to test explicit version without
+            # going deep into the details.
+            self.assertIn('.', version)
+            for v in version.split('.'):
+                int(v)  # should not fail
+        if csd:
+            self.assertTrue(csd.startswith('SP'), msg=csd)
+        if ptype:
+            if os.cpu_count() > 1:
+                self.assertIn('Multiprocessor', ptype)
+            else:
+                self.assertIn('Uniprocessor', ptype)
+
+    @unittest.skipIf(support.MS_WINDOWS, 'This test only makes sense on non Windows')
+    def test_win32_ver_on_non_windows(self):
+        release, version, csd, ptype = 'a', '1.0', 'c', 'd'
+        res = platform.win32_ver(release, version, csd, ptype)
+        self.assertSequenceEqual(res, (release, version, csd, ptype), seq_type=tuple)
 
     def test_mac_ver(self):
         res = platform.mac_ver()
diff --git a/Lib/test/test_plistlib.py b/Lib/test/test_plistlib.py
index 3f10f16d71..fa46050658 100644
--- a/Lib/test/test_plistlib.py
+++ b/Lib/test/test_plistlib.py
@@ -908,7 +908,7 @@ def test_cycles(self):
         self.assertIs(b['x'], b)
 
     def test_deep_nesting(self):
-        tests = [50, 100_000] if support.is_wasi else [50, 300, 100_000]
+        tests = [50, 100_000] if support.is_wasi else [50, 600, 100_000]
         for N in tests:
             chunks = [b'\xa1' + (i + 1).to_bytes(4, 'big') for i in range(N)]
             try:
diff --git a/Lib/test/test_posix.py b/Lib/test/test_posix.py
index 887420f8ca..f115aa874f 100644
--- a/Lib/test/test_posix.py
+++ b/Lib/test/test_posix.py
@@ -1327,12 +1327,21 @@ def test_sched_getaffinity(self):
     def test_sched_setaffinity(self):
         mask = posix.sched_getaffinity(0)
         self.addCleanup(posix.sched_setaffinity, 0, list(mask))
+
         if len(mask) > 1:
             # Empty masks are forbidden
             mask.pop()
         posix.sched_setaffinity(0, mask)
         self.assertEqual(posix.sched_getaffinity(0), mask)
-        self.assertRaises(OSError, posix.sched_setaffinity, 0, [])
+
+        try:
+            posix.sched_setaffinity(0, [])
+            # gh-117061: On RHEL9, sched_setaffinity(0, []) does not fail
+        except OSError:
+            # sched_setaffinity() manual page documents EINVAL error
+            # when the mask is empty.
+            pass
+
         self.assertRaises(ValueError, posix.sched_setaffinity, 0, [-10])
         self.assertRaises(ValueError, posix.sched_setaffinity, 0, map(int, "0X"))
         self.assertRaises(OverflowError, posix.sched_setaffinity, 0, [1<<128])
diff --git a/Lib/test/test_property.py b/Lib/test/test_property.py
index 45aa9e51c0..4de2bb3781 100644
--- a/Lib/test/test_property.py
+++ b/Lib/test/test_property.py
@@ -183,6 +183,24 @@ def test_refleaks_in___init__(self):
             fake_prop.__init__('fget', 'fset', 'fdel', 'doc')
         self.assertAlmostEqual(gettotalrefcount() - refs_before, 0, delta=10)
 
+    @support.refcount_test
+    def test_gh_115618(self):
+        # Py_XDECREF() was improperly called for None argument
+        # in property methods.
+        gettotalrefcount = support.get_attribute(sys, 'gettotalrefcount')
+        prop = property()
+        refs_before = gettotalrefcount()
+        for i in range(100):
+            prop = prop.getter(None)
+        self.assertIsNone(prop.fget)
+        for i in range(100):
+            prop = prop.setter(None)
+        self.assertIsNone(prop.fset)
+        for i in range(100):
+            prop = prop.deleter(None)
+        self.assertIsNone(prop.fdel)
+        self.assertAlmostEqual(gettotalrefcount() - refs_before, 0, delta=10)
+
     @unittest.skipIf(sys.flags.optimize >= 2,
                      "Docstrings are omitted with -O2 and above")
     def test_class_property(self):
@@ -245,6 +263,7 @@ class PropertySubSlots(property):
 
 class PropertySubclassTests(unittest.TestCase):
 
+    @support.requires_docstrings
     def test_slots_docstring_copy_exception(self):
         # A special case error that we preserve despite the GH-98963 behavior
         # that would otherwise silently ignore this error.
diff --git a/Lib/test/test_py_compile.py b/Lib/test/test_py_compile.py
index c4e6551f60..64387296e8 100644
--- a/Lib/test/test_py_compile.py
+++ b/Lib/test/test_py_compile.py
@@ -227,7 +227,8 @@ class PyCompileCLITestCase(unittest.TestCase):
     def setUp(self):
         self.directory = tempfile.mkdtemp()
         self.source_path = os.path.join(self.directory, '_test.py')
-        self.cache_path = importlib.util.cache_from_source(self.source_path)
+        self.cache_path = importlib.util.cache_from_source(self.source_path,
+                                optimization='' if __debug__ else 1)
         with open(self.source_path, 'w') as file:
             file.write('x = 123\n')
 
@@ -250,6 +251,7 @@ def pycompilecmd_failure(self, *args):
         return script_helper.assert_python_failure('-m', 'py_compile', *args)
 
     def test_stdin(self):
+        self.assertFalse(os.path.exists(self.cache_path))
         result = self.pycompilecmd('-', input=self.source_path)
         self.assertEqual(result.returncode, 0)
         self.assertEqual(result.stdout, b'')
diff --git a/Lib/test/test_pydoc.py b/Lib/test/test_pydoc.py
deleted file mode 100644
index dbd86a6b18..0000000000
--- a/Lib/test/test_pydoc.py
+++ /dev/null
@@ -1,1644 +0,0 @@
-import os
-import sys
-import contextlib
-import importlib.util
-import inspect
-import pydoc
-import py_compile
-import keyword
-import _pickle
-import pkgutil
-import re
-import stat
-import tempfile
-import test.support
-import types
-import typing
-import unittest
-import urllib.parse
-import xml.etree
-import xml.etree.ElementTree
-import textwrap
-from io import StringIO
-from collections import namedtuple
-from urllib.request import urlopen, urlcleanup
-from test.support import import_helper
-from test.support import os_helper
-from test.support.script_helper import (assert_python_ok,
-                                        assert_python_failure, spawn_python)
-from test.support import threading_helper
-from test.support import (reap_children, captured_output, captured_stdout,
-                          captured_stderr, is_emscripten, is_wasi,
-                          requires_docstrings, MISSING_C_DOCSTRINGS)
-from test.support.os_helper import (TESTFN, rmtree, unlink)
-from test import pydoc_mod
-
-
-class nonascii:
-    '  '
-    pass
-
-if test.support.HAVE_DOCSTRINGS:
-    expected_data_docstrings = (
-        'dictionary for instance variables',
-        'list of weak references to the object',
-        ) * 2
-else:
-    expected_data_docstrings = ('', '', '', '')
-
-expected_text_pattern = """
-NAME
-    test.pydoc_mod - This is a test module for test_pydoc
-%s
-CLASSES
-    builtins.object
-        A
-        B
-        C
-
-    class A(builtins.object)
-     |  Hello and goodbye
-     |
-     |  Methods defined here:
-     |
-     |  __init__()
-     |      Wow, I have no function!
-     |
-     |  ----------------------------------------------------------------------
-     |  Data descriptors defined here:
-     |
-     |  __dict__%s
-     |
-     |  __weakref__%s
-
-    class B(builtins.object)
-     |  Data descriptors defined here:
-     |
-     |  __dict__%s
-     |
-     |  __weakref__%s
-     |
-     |  ----------------------------------------------------------------------
-     |  Data and other attributes defined here:
-     |
-     |  NO_MEANING = 'eggs'
-     |
-     |  __annotations__ = {'NO_MEANING': <class 'str'>}
-
-    class C(builtins.object)
-     |  Methods defined here:
-     |
-     |  get_answer(self)
-     |      Return say_no()
-     |
-     |  is_it_true(self)
-     |      Return self.get_answer()
-     |
-     |  say_no(self)
-     |
-     |  ----------------------------------------------------------------------
-     |  Class methods defined here:
-     |
-     |  __class_getitem__(item) from builtins.type
-     |
-     |  ----------------------------------------------------------------------
-     |  Data descriptors defined here:
-     |
-     |  __dict__
-     |      dictionary for instance variables
-     |
-     |  __weakref__
-     |      list of weak references to the object
-
-FUNCTIONS
-    doc_func()
-        This function solves all of the world's problems:
-        hunger
-        lack of Python
-        war
-
-    nodoc_func()
-
-DATA
-    __xyz__ = 'X, Y and Z'
-    c_alias = test.pydoc_mod.C[int]
-    list_alias1 = typing.List[int]
-    list_alias2 = list[int]
-    type_union1 = typing.Union[int, str]
-    type_union2 = int | str
-
-VERSION
-    1.2.3.4
-
-AUTHOR
-    Benjamin Peterson
-
-CREDITS
-    Nobody
-
-FILE
-    %s
-""".strip()
-
-expected_text_data_docstrings = tuple('\n     |      ' + s if s else ''
-                                      for s in expected_data_docstrings)
-
-html2text_of_expected = """
-test.pydoc_mod (version 1.2.3.4)
-This is a test module for test_pydoc
-
-Modules
-    types
-    typing
-
-Classes
-    builtins.object
-    A
-    B
-    C
-
-class A(builtins.object)
-    Hello and goodbye
-
-    Methods defined here:
-        __init__()
-            Wow, I have no function!
-
-    Data descriptors defined here:
-        __dict__
-            dictionary for instance variables
-        __weakref__
-            list of weak references to the object
-
-class B(builtins.object)
-    Data descriptors defined here:
-        __dict__
-            dictionary for instance variables
-        __weakref__
-            list of weak references to the object
-    Data and other attributes defined here:
-        NO_MEANING = 'eggs'
-        __annotations__ = {'NO_MEANING': <class 'str'>}
-
-
-class C(builtins.object)
-    Methods defined here:
-        get_answer(self)
-            Return say_no()
-        is_it_true(self)
-            Return self.get_answer()
-        say_no(self)
-    Class methods defined here:
-        __class_getitem__(item) from builtins.type
-    Data descriptors defined here:
-        __dict__
-            dictionary for instance variables
-        __weakref__
-             list of weak references to the object
-
-Functions
-    doc_func()
-        This function solves all of the world's problems:
-        hunger
-        lack of Python
-        war
-    nodoc_func()
-
-Data
-    __xyz__ = 'X, Y and Z'
-    c_alias = test.pydoc_mod.C[int]
-    list_alias1 = typing.List[int]
-    list_alias2 = list[int]
-    type_union1 = typing.Union[int, str]
-    type_union2 = int | str
-
-Author
-    Benjamin Peterson
-
-Credits
-    Nobody
-"""
-
-expected_html_data_docstrings = tuple(s.replace(' ', '&nbsp;')
-                                      for s in expected_data_docstrings)
-
-# output pattern for missing module
-missing_pattern = '''\
-No Python documentation found for %r.
-Use help() to get the interactive help utility.
-Use help(str) for help on the str class.'''.replace('\n', os.linesep)
-
-# output pattern for module with bad imports
-badimport_pattern = "problem in %s - ModuleNotFoundError: No module named %r"
-
-expected_dynamicattribute_pattern = """
-Help on class DA in module %s:
-
-class DA(builtins.object)
- |  Data descriptors defined here:
- |
- |  __dict__%s
- |
- |  __weakref__%s
- |
- |  ham
- |
- |  ----------------------------------------------------------------------
- |  Data and other attributes inherited from Meta:
- |
- |  ham = 'spam'
-""".strip()
-
-expected_virtualattribute_pattern1 = """
-Help on class Class in module %s:
-
-class Class(builtins.object)
- |  Data and other attributes inherited from Meta:
- |
- |  LIFE = 42
-""".strip()
-
-expected_virtualattribute_pattern2 = """
-Help on class Class1 in module %s:
-
-class Class1(builtins.object)
- |  Data and other attributes inherited from Meta1:
- |
- |  one = 1
-""".strip()
-
-expected_virtualattribute_pattern3 = """
-Help on class Class2 in module %s:
-
-class Class2(Class1)
- |  Method resolution order:
- |      Class2
- |      Class1
- |      builtins.object
- |
- |  Data and other attributes inherited from Meta1:
- |
- |  one = 1
- |
- |  ----------------------------------------------------------------------
- |  Data and other attributes inherited from Meta3:
- |
- |  three = 3
- |
- |  ----------------------------------------------------------------------
- |  Data and other attributes inherited from Meta2:
- |
- |  two = 2
-""".strip()
-
-expected_missingattribute_pattern = """
-Help on class C in module %s:
-
-class C(builtins.object)
- |  Data and other attributes defined here:
- |
- |  here = 'present!'
-""".strip()
-
-def run_pydoc(module_name, *args, **env):
-    """
-    Runs pydoc on the specified module. Returns the stripped
-    output of pydoc.
-    """
-    args = args + (module_name,)
-    # do not write bytecode files to avoid caching errors
-    rc, out, err = assert_python_ok('-B', pydoc.__file__, *args, **env)
-    return out.strip()
-
-def run_pydoc_fail(module_name, *args, **env):
-    """
-    Runs pydoc on the specified module expecting a failure.
-    """
-    args = args + (module_name,)
-    rc, out, err = assert_python_failure('-B', pydoc.__file__, *args, **env)
-    return out.strip()
-
-def get_pydoc_html(module):
-    "Returns pydoc generated output as html"
-    doc = pydoc.HTMLDoc()
-    output = doc.docmodule(module)
-    loc = doc.getdocloc(pydoc_mod) or ""
-    if loc:
-        loc = "<br><a href=\"" + loc + "\">Module Docs</a>"
-    return output.strip(), loc
-
-def get_pydoc_link(module):
-    "Returns a documentation web link of a module"
-    abspath = os.path.abspath
-    dirname = os.path.dirname
-    basedir = dirname(dirname(abspath(__file__)))
-    doc = pydoc.TextDoc()
-    loc = doc.getdocloc(module, basedir=basedir)
-    return loc
-
-def get_pydoc_text(module):
-    "Returns pydoc generated output as text"
-    doc = pydoc.TextDoc()
-    loc = doc.getdocloc(pydoc_mod) or ""
-    if loc:
-        loc = "\nMODULE DOCS\n    " + loc + "\n"
-
-    output = doc.docmodule(module)
-
-    # clean up the extra text formatting that pydoc performs
-    patt = re.compile('\b.')
-    output = patt.sub('', output)
-    return output.strip(), loc
-
-def get_html_title(text):
-    # Bit of hack, but good enough for test purposes
-    header, _, _ = text.partition("</head>")
-    _, _, title = header.partition("<title>")
-    title, _, _ = title.partition("</title>")
-    return title
-
-
-def html2text(html):
-    """A quick and dirty implementation of html2text.
-
-    Tailored for pydoc tests only.
-    """
-    html = html.replace("<dd>", "\n")
-    html = re.sub("<.*?>", "", html)
-    html = pydoc.replace(html, "&nbsp;", " ", "&gt;", ">", "&lt;", "<")
-    return html
-
-
-class PydocBaseTest(unittest.TestCase):
-
-    def _restricted_walk_packages(self, walk_packages, path=None):
-        """
-        A version of pkgutil.walk_packages() that will restrict itself to
-        a given path.
-        """
-        default_path = path or [os.path.dirname(__file__)]
-        def wrapper(path=None, prefix='', onerror=None):
-            return walk_packages(path or default_path, prefix, onerror)
-        return wrapper
-
-    @contextlib.contextmanager
-    def restrict_walk_packages(self, path=None):
-        walk_packages = pkgutil.walk_packages
-        pkgutil.walk_packages = self._restricted_walk_packages(walk_packages,
-                                                               path)
-        try:
-            yield
-        finally:
-            pkgutil.walk_packages = walk_packages
-
-    def call_url_handler(self, url, expected_title):
-        text = pydoc._url_handler(url, "text/html")
-        result = get_html_title(text)
-        # Check the title to ensure an unexpected error page was not returned
-        self.assertEqual(result, expected_title, text)
-        return text
-
-
-class PydocDocTest(unittest.TestCase):
-    maxDiff = None
-
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_html_doc(self):
-        result, doc_loc = get_pydoc_html(pydoc_mod)
-        text_result = html2text(result)
-        text_lines = [line.strip() for line in text_result.splitlines()]
-        text_lines = [line for line in text_lines if line]
-        del text_lines[1]
-        expected_lines = html2text_of_expected.splitlines()
-        expected_lines = [line.strip() for line in expected_lines if line]
-        self.assertEqual(text_lines, expected_lines)
-        mod_file = inspect.getabsfile(pydoc_mod)
-        mod_url = urllib.parse.quote(mod_file)
-        self.assertIn(mod_url, result)
-        self.assertIn(mod_file, result)
-        self.assertIn(doc_loc, result)
-
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_text_doc(self):
-        result, doc_loc = get_pydoc_text(pydoc_mod)
-        expected_text = expected_text_pattern % (
-                        (doc_loc,) +
-                        expected_text_data_docstrings +
-                        (inspect.getabsfile(pydoc_mod),))
-        self.assertEqual(expected_text, result)
-
-    def test_text_enum_member_with_value_zero(self):
-        # Test issue #20654 to ensure enum member with value 0 can be
-        # displayed. It used to throw KeyError: 'zero'.
-        import enum
-        class BinaryInteger(enum.IntEnum):
-            zero = 0
-            one = 1
-        doc = pydoc.render_doc(BinaryInteger)
-        self.assertIn('BinaryInteger.zero', doc)
-
-    def test_mixed_case_module_names_are_lower_cased(self):
-        # issue16484
-        doc_link = get_pydoc_link(xml.etree.ElementTree)
-        self.assertIn('xml.etree.elementtree', doc_link)
-
-    def test_issue8225(self):
-        # Test issue8225 to ensure no doc link appears for xml.etree
-        result, doc_loc = get_pydoc_text(xml.etree)
-        self.assertEqual(doc_loc, "", "MODULE DOCS incorrectly includes a link")
-
-    def test_getpager_with_stdin_none(self):
-        previous_stdin = sys.stdin
-        try:
-            sys.stdin = None
-            pydoc.getpager() # Shouldn't fail.
-        finally:
-            sys.stdin = previous_stdin
-
-    def test_non_str_name(self):
-        # issue14638
-        # Treat illegal (non-str) name like no name
-
-        class A:
-            __name__ = 42
-        class B:
-            pass
-        adoc = pydoc.render_doc(A())
-        bdoc = pydoc.render_doc(B())
-        self.assertEqual(adoc.replace("A", "B"), bdoc)
-
-    def test_not_here(self):
-        missing_module = "test.i_am_not_here"
-        result = str(run_pydoc_fail(missing_module), 'ascii')
-        expected = missing_pattern % missing_module
-        self.assertEqual(expected, result,
-            "documentation for missing module found")
-
-    @requires_docstrings
-    def test_not_ascii(self):
-        result = run_pydoc('test.test_pydoc.nonascii', PYTHONIOENCODING='ascii')
-        encoded = nonascii.__doc__.encode('ascii', 'backslashreplace')
-        self.assertIn(encoded, result)
-
-    def test_input_strip(self):
-        missing_module = " test.i_am_not_here "
-        result = str(run_pydoc_fail(missing_module), 'ascii')
-        expected = missing_pattern % missing_module.strip()
-        self.assertEqual(expected, result)
-
-    def test_stripid(self):
-        # test with strings, other implementations might have different repr()
-        stripid = pydoc.stripid
-        # strip the id
-        self.assertEqual(stripid('<function stripid at 0x88dcee4>'),
-                         '<function stripid>')
-        self.assertEqual(stripid('<function stripid at 0x01F65390>'),
-                         '<function stripid>')
-        # nothing to strip, return the same text
-        self.assertEqual(stripid('42'), '42')
-        self.assertEqual(stripid("<type 'exceptions.Exception'>"),
-                         "<type 'exceptions.Exception'>")
-
-    def test_builtin_with_more_than_four_children(self):
-        """Tests help on builtin object which have more than four child classes.
-
-        When running help() on a builtin class which has child classes, it
-        should contain a "Built-in subclasses" section and only 4 classes
-        should be displayed with a hint on how many more subclasses are present.
-        For example:
-
-        >>> help(object)
-        Help on class object in module builtins:
-
-        class object
-         |  The most base type
-         |
-         |  Built-in subclasses:
-         |      async_generator
-         |      BaseException
-         |      builtin_function_or_method
-         |      bytearray
-         |      ... and 82 other subclasses
-        """
-        doc = pydoc.TextDoc()
-        text = doc.docclass(object)
-        snip = (" |  Built-in subclasses:\n"
-                " |      async_generator\n"
-                " |      BaseException\n"
-                " |      builtin_function_or_method\n"
-                " |      bytearray\n"
-                " |      ... and \\d+ other subclasses")
-        self.assertRegex(text, snip)
-
-    def test_builtin_with_child(self):
-        """Tests help on builtin object which have only child classes.
-
-        When running help() on a builtin class which has child classes, it
-        should contain a "Built-in subclasses" section. For example:
-
-        >>> help(ArithmeticError)
-        Help on class ArithmeticError in module builtins:
-
-        class ArithmeticError(Exception)
-         |  Base class for arithmetic errors.
-         |
-         ...
-         |
-         |  Built-in subclasses:
-         |      FloatingPointError
-         |      OverflowError
-         |      ZeroDivisionError
-        """
-        doc = pydoc.TextDoc()
-        text = doc.docclass(ArithmeticError)
-        snip = (" |  Built-in subclasses:\n"
-                " |      FloatingPointError\n"
-                " |      OverflowError\n"
-                " |      ZeroDivisionError")
-        self.assertIn(snip, text)
-
-    def test_builtin_with_grandchild(self):
-        """Tests help on builtin classes which have grandchild classes.
-
-        When running help() on a builtin class which has child classes, it
-        should contain a "Built-in subclasses" section. However, if it also has
-        grandchildren, these should not show up on the subclasses section.
-        For example:
-
-        >>> help(Exception)
-        Help on class Exception in module builtins:
-
-        class Exception(BaseException)
-         |  Common base class for all non-exit exceptions.
-         |
-         ...
-         |
-         |  Built-in subclasses:
-         |      ArithmeticError
-         |      AssertionError
-         |      AttributeError
-         ...
-        """
-        doc = pydoc.TextDoc()
-        text = doc.docclass(Exception)
-        snip = (" |  Built-in subclasses:\n"
-                " |      ArithmeticError\n"
-                " |      AssertionError\n"
-                " |      AttributeError")
-        self.assertIn(snip, text)
-        # Testing that the grandchild ZeroDivisionError does not show up
-        self.assertNotIn('ZeroDivisionError', text)
-
-    def test_builtin_no_child(self):
-        """Tests help on builtin object which have no child classes.
-
-        When running help() on a builtin class which has no child classes, it
-        should not contain any "Built-in subclasses" section. For example:
-
-        >>> help(ZeroDivisionError)
-
-        Help on class ZeroDivisionError in module builtins:
-
-        class ZeroDivisionError(ArithmeticError)
-         |  Second argument to a division or modulo operation was zero.
-         |
-         |  Method resolution order:
-         |      ZeroDivisionError
-         |      ArithmeticError
-         |      Exception
-         |      BaseException
-         |      object
-         |
-         |  Methods defined here:
-         ...
-        """
-        doc = pydoc.TextDoc()
-        text = doc.docclass(ZeroDivisionError)
-        # Testing that the subclasses section does not appear
-        self.assertNotIn('Built-in subclasses', text)
-
-    def test_builtin_on_metaclasses(self):
-        """Tests help on metaclasses.
-
-        When running help() on a metaclasses such as type, it
-        should not contain any "Built-in subclasses" section.
-        """
-        doc = pydoc.TextDoc()
-        text = doc.docclass(type)
-        # Testing that the subclasses section does not appear
-        self.assertNotIn('Built-in subclasses', text)
-
-    def test_fail_help_cli(self):
-        elines = (missing_pattern % 'abd').splitlines()
-        with spawn_python("-c" "help()") as proc:
-            out, _ = proc.communicate(b"abd")
-            olines = out.decode().splitlines()[-9:-6]
-            olines[0] = olines[0].removeprefix('help> ')
-            self.assertEqual(elines, olines)
-
-    def test_fail_help_output_redirect(self):
-        with StringIO() as buf:
-            helper = pydoc.Helper(output=buf)
-            helper.help("abd")
-            expected = missing_pattern % "abd"
-            self.assertEqual(expected, buf.getvalue().strip().replace('\n', os.linesep))
-
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_help_output_redirect(self):
-        # issue 940286, if output is set in Helper, then all output from
-        # Helper.help should be redirected
-        getpager_old = pydoc.getpager
-        getpager_new = lambda: (lambda x: x)
-        self.maxDiff = None
-
-        buf = StringIO()
-        helper = pydoc.Helper(output=buf)
-        unused, doc_loc = get_pydoc_text(pydoc_mod)
-        module = "test.pydoc_mod"
-        help_header = """
-        Help on module test.pydoc_mod in test:
-
-        """.lstrip()
-        help_header = textwrap.dedent(help_header)
-        expected_help_pattern = help_header + expected_text_pattern
-
-        pydoc.getpager = getpager_new
-        try:
-            with captured_output('stdout') as output, \
-                 captured_output('stderr') as err:
-                helper.help(module)
-                result = buf.getvalue().strip()
-                expected_text = expected_help_pattern % (
-                                (doc_loc,) +
-                                expected_text_data_docstrings +
-                                (inspect.getabsfile(pydoc_mod),))
-                self.assertEqual('', output.getvalue())
-                self.assertEqual('', err.getvalue())
-                self.assertEqual(expected_text, result)
-        finally:
-            pydoc.getpager = getpager_old
-
-    def test_namedtuple_fields(self):
-        Person = namedtuple('Person', ['nickname', 'firstname'])
-        with captured_stdout() as help_io:
-            pydoc.help(Person)
-        helptext = help_io.getvalue()
-        self.assertIn("nickname", helptext)
-        self.assertIn("firstname", helptext)
-        self.assertIn("Alias for field number 0", helptext)
-        self.assertIn("Alias for field number 1", helptext)
-
-    def test_namedtuple_public_underscore(self):
-        NT = namedtuple('NT', ['abc', 'def'], rename=True)
-        with captured_stdout() as help_io:
-            pydoc.help(NT)
-        helptext = help_io.getvalue()
-        self.assertIn('_1', helptext)
-        self.assertIn('_replace', helptext)
-        self.assertIn('_asdict', helptext)
-
-    def test_synopsis(self):
-        self.addCleanup(unlink, TESTFN)
-        for encoding in ('ISO-8859-1', 'UTF-8'):
-            with open(TESTFN, 'w', encoding=encoding) as script:
-                if encoding != 'UTF-8':
-                    print('#coding: {}'.format(encoding), file=script)
-                print('"""line 1: h\xe9', file=script)
-                print('line 2: hi"""', file=script)
-            synopsis = pydoc.synopsis(TESTFN, {})
-            self.assertEqual(synopsis, 'line 1: h\xe9')
-
-    @requires_docstrings
-    def test_synopsis_sourceless(self):
-        os = import_helper.import_fresh_module('os')
-        expected = os.__doc__.splitlines()[0]
-        filename = os.__spec__.cached
-        synopsis = pydoc.synopsis(filename)
-
-        self.assertEqual(synopsis, expected)
-
-    def test_synopsis_sourceless_empty_doc(self):
-        with os_helper.temp_cwd() as test_dir:
-            init_path = os.path.join(test_dir, 'foomod42.py')
-            cached_path = importlib.util.cache_from_source(init_path)
-            with open(init_path, 'w') as fobj:
-                fobj.write("foo = 1")
-            py_compile.compile(init_path)
-            synopsis = pydoc.synopsis(init_path, {})
-            self.assertIsNone(synopsis)
-            synopsis_cached = pydoc.synopsis(cached_path, {})
-            self.assertIsNone(synopsis_cached)
-
-    def test_splitdoc_with_description(self):
-        example_string = "I Am A Doc\n\n\nHere is my description"
-        self.assertEqual(pydoc.splitdoc(example_string),
-                         ('I Am A Doc', '\nHere is my description'))
-
-    def test_is_package_when_not_package(self):
-        with os_helper.temp_cwd() as test_dir:
-            self.assertFalse(pydoc.ispackage(test_dir))
-
-    def test_is_package_when_is_package(self):
-        with os_helper.temp_cwd() as test_dir:
-            init_path = os.path.join(test_dir, '__init__.py')
-            open(init_path, 'w').close()
-            self.assertTrue(pydoc.ispackage(test_dir))
-            os.remove(init_path)
-
-    def test_allmethods(self):
-        # issue 17476: allmethods was no longer returning unbound methods.
-        # This test is a bit fragile in the face of changes to object and type,
-        # but I can't think of a better way to do it without duplicating the
-        # logic of the function under test.
-
-        class TestClass(object):
-            def method_returning_true(self):
-                return True
-
-        # What we expect to get back: everything on object...
-        expected = dict(vars(object))
-        # ...plus our unbound method...
-        expected['method_returning_true'] = TestClass.method_returning_true
-        # ...but not the non-methods on object.
-        del expected['__doc__']
-        del expected['__class__']
-        # inspect resolves descriptors on type into methods, but vars doesn't,
-        # so we need to update __subclasshook__ and __init_subclass__.
-        expected['__subclasshook__'] = TestClass.__subclasshook__
-        expected['__init_subclass__'] = TestClass.__init_subclass__
-
-        methods = pydoc.allmethods(TestClass)
-        self.assertDictEqual(methods, expected)
-
-    @requires_docstrings
-    def test_method_aliases(self):
-        class A:
-            def tkraise(self, aboveThis=None):
-                """Raise this widget in the stacking order."""
-            lift = tkraise
-            def a_size(self):
-                """Return size"""
-        class B(A):
-            def itemconfigure(self, tagOrId, cnf=None, **kw):
-                """Configure resources of an item TAGORID."""
-            itemconfig = itemconfigure
-            b_size = A.a_size
-
-        doc = pydoc.render_doc(B)
-        # clean up the extra text formatting that pydoc performs
-        doc = re.sub('\b.', '', doc)
-        self.assertEqual(doc, '''\
-Python Library Documentation: class B in module %s
-
-class B(A)
- |  Method resolution order:
- |      B
- |      A
- |      builtins.object
- |
- |  Methods defined here:
- |
- |  b_size = a_size(self)
- |
- |  itemconfig = itemconfigure(self, tagOrId, cnf=None, **kw)
- |
- |  itemconfigure(self, tagOrId, cnf=None, **kw)
- |      Configure resources of an item TAGORID.
- |
- |  ----------------------------------------------------------------------
- |  Methods inherited from A:
- |
- |  a_size(self)
- |      Return size
- |
- |  lift = tkraise(self, aboveThis=None)
- |
- |  tkraise(self, aboveThis=None)
- |      Raise this widget in the stacking order.
- |
- |  ----------------------------------------------------------------------
- |  Data descriptors inherited from A:
- |
- |  __dict__
- |      dictionary for instance variables
- |
- |  __weakref__
- |      list of weak references to the object
-''' % __name__)
-
-        doc = pydoc.render_doc(B, renderer=pydoc.HTMLDoc())
-        expected_text = f"""
-Python Library Documentation
-
-class B in module {__name__}
-class B(A)
-    Method resolution order:
-        B
-        A
-        builtins.object
-
-    Methods defined here:
-        b_size = a_size(self)
-        itemconfig = itemconfigure(self, tagOrId, cnf=None, **kw)
-        itemconfigure(self, tagOrId, cnf=None, **kw)
-            Configure resources of an item TAGORID.
-
-    Methods inherited from A:
-        a_size(self)
-            Return size
-        lift = tkraise(self, aboveThis=None)
-        tkraise(self, aboveThis=None)
-            Raise this widget in the stacking order.
-
-    Data descriptors inherited from A:
-        __dict__
-            dictionary for instance variables
-        __weakref__
-            list of weak references to the object
-"""
-        as_text = html2text(doc)
-        expected_lines = [line.strip() for line in expected_text.split("\n") if line]
-        for expected_line in expected_lines:
-            self.assertIn(expected_line, as_text)
-
-    def test__future__imports(self):
-        # __future__ features are excluded from module help,
-        # except when it's the __future__ module itself
-        import __future__
-        future_text, _ = get_pydoc_text(__future__)
-        future_html, _ = get_pydoc_html(__future__)
-        pydoc_mod_text, _ = get_pydoc_text(pydoc_mod)
-        pydoc_mod_html, _ = get_pydoc_html(pydoc_mod)
-
-        for feature in __future__.all_feature_names:
-            txt = f"{feature} = _Feature"
-            html = f"<strong>{feature}</strong> = _Feature"
-            self.assertIn(txt, future_text)
-            self.assertIn(html, future_html)
-            self.assertNotIn(txt, pydoc_mod_text)
-            self.assertNotIn(html, pydoc_mod_html)
-
-
-class PydocImportTest(PydocBaseTest):
-
-    def setUp(self):
-        self.test_dir = os.mkdir(TESTFN)
-        self.addCleanup(rmtree, TESTFN)
-        importlib.invalidate_caches()
-
-    def test_badimport(self):
-        # This tests the fix for issue 5230, where if pydoc found the module
-        # but the module had an internal import error pydoc would report no doc
-        # found.
-        modname = 'testmod_xyzzy'
-        testpairs = (
-            ('i_am_not_here', 'i_am_not_here'),
-            ('test.i_am_not_here_either', 'test.i_am_not_here_either'),
-            ('test.i_am_not_here.neither_am_i', 'test.i_am_not_here'),
-            ('i_am_not_here.{}'.format(modname), 'i_am_not_here'),
-            ('test.{}'.format(modname), 'test.{}'.format(modname)),
-            )
-
-        sourcefn = os.path.join(TESTFN, modname) + os.extsep + "py"
-        for importstring, expectedinmsg in testpairs:
-            with open(sourcefn, 'w') as f:
-                f.write("import {}\n".format(importstring))
-            result = run_pydoc_fail(modname, PYTHONPATH=TESTFN).decode("ascii")
-            expected = badimport_pattern % (modname, expectedinmsg)
-            self.assertEqual(expected, result)
-
-    def test_apropos_with_bad_package(self):
-        # Issue 7425 - pydoc -k failed when bad package on path
-        pkgdir = os.path.join(TESTFN, "syntaxerr")
-        os.mkdir(pkgdir)
-        badsyntax = os.path.join(pkgdir, "__init__") + os.extsep + "py"
-        with open(badsyntax, 'w') as f:
-            f.write("invalid python syntax = $1\n")
-        with self.restrict_walk_packages(path=[TESTFN]):
-            with captured_stdout() as out:
-                with captured_stderr() as err:
-                    pydoc.apropos('xyzzy')
-            # No result, no error
-            self.assertEqual(out.getvalue(), '')
-            self.assertEqual(err.getvalue(), '')
-            # The package name is still matched
-            with captured_stdout() as out:
-                with captured_stderr() as err:
-                    pydoc.apropos('syntaxerr')
-            self.assertEqual(out.getvalue().strip(), 'syntaxerr')
-            self.assertEqual(err.getvalue(), '')
-
-    def test_apropos_with_unreadable_dir(self):
-        # Issue 7367 - pydoc -k failed when unreadable dir on path
-        self.unreadable_dir = os.path.join(TESTFN, "unreadable")
-        os.mkdir(self.unreadable_dir, 0)
-        self.addCleanup(os.rmdir, self.unreadable_dir)
-        # Note, on Windows the directory appears to be still
-        #   readable so this is not really testing the issue there
-        with self.restrict_walk_packages(path=[TESTFN]):
-            with captured_stdout() as out:
-                with captured_stderr() as err:
-                    pydoc.apropos('SOMEKEY')
-        # No result, no error
-        self.assertEqual(out.getvalue(), '')
-        self.assertEqual(err.getvalue(), '')
-
-    @os_helper.skip_unless_working_chmod
-    @unittest.skipIf(is_emscripten, "cannot remove x bit")
-    def test_apropos_empty_doc(self):
-        pkgdir = os.path.join(TESTFN, 'walkpkg')
-        os.mkdir(pkgdir)
-        self.addCleanup(rmtree, pkgdir)
-        init_path = os.path.join(pkgdir, '__init__.py')
-        with open(init_path, 'w') as fobj:
-            fobj.write("foo = 1")
-        current_mode = stat.S_IMODE(os.stat(pkgdir).st_mode)
-        try:
-            os.chmod(pkgdir, current_mode & ~stat.S_IEXEC)
-            with self.restrict_walk_packages(path=[TESTFN]), captured_stdout() as stdout:
-                pydoc.apropos('')
-            self.assertIn('walkpkg', stdout.getvalue())
-        finally:
-            os.chmod(pkgdir, current_mode)
-
-    def test_url_search_package_error(self):
-        # URL handler search should cope with packages that raise exceptions
-        pkgdir = os.path.join(TESTFN, "test_error_package")
-        os.mkdir(pkgdir)
-        init = os.path.join(pkgdir, "__init__.py")
-        with open(init, "wt", encoding="ascii") as f:
-            f.write("""raise ValueError("ouch")\n""")
-        with self.restrict_walk_packages(path=[TESTFN]):
-            # Package has to be importable for the error to have any effect
-            saved_paths = tuple(sys.path)
-            sys.path.insert(0, TESTFN)
-            try:
-                with self.assertRaisesRegex(ValueError, "ouch"):
-                    import test_error_package  # Sanity check
-
-                text = self.call_url_handler("search?key=test_error_package",
-                    "Pydoc: Search Results")
-                found = ('<a href="test_error_package.html">'
-                    'test_error_package</a>')
-                self.assertIn(found, text)
-            finally:
-                sys.path[:] = saved_paths
-
-    @unittest.skip('causes undesirable side-effects (#20128)')
-    def test_modules(self):
-        # See Helper.listmodules().
-        num_header_lines = 2
-        num_module_lines_min = 5  # Playing it safe.
-        num_footer_lines = 3
-        expected = num_header_lines + num_module_lines_min + num_footer_lines
-
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        helper('modules')
-        result = output.getvalue().strip()
-        num_lines = len(result.splitlines())
-
-        self.assertGreaterEqual(num_lines, expected)
-
-    @unittest.skip('causes undesirable side-effects (#20128)')
-    def test_modules_search(self):
-        # See Helper.listmodules().
-        expected = 'pydoc - '
-
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        with captured_stdout() as help_io:
-            helper('modules pydoc')
-        result = help_io.getvalue()
-
-        self.assertIn(expected, result)
-
-    @unittest.skip('some buildbots are not cooperating (#20128)')
-    def test_modules_search_builtin(self):
-        expected = 'gc - '
-
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        with captured_stdout() as help_io:
-            helper('modules garbage')
-        result = help_io.getvalue()
-
-        self.assertTrue(result.startswith(expected))
-
-    def test_importfile(self):
-        loaded_pydoc = pydoc.importfile(pydoc.__file__)
-
-        self.assertIsNot(loaded_pydoc, pydoc)
-        self.assertEqual(loaded_pydoc.__name__, 'pydoc')
-        self.assertEqual(loaded_pydoc.__file__, pydoc.__file__)
-        self.assertEqual(loaded_pydoc.__spec__, pydoc.__spec__)
-
-
-class TestDescriptions(unittest.TestCase):
-
-    def test_module(self):
-        # Check that pydocfodder module can be described
-        from test import pydocfodder
-        doc = pydoc.render_doc(pydocfodder)
-        self.assertIn("pydocfodder", doc)
-
-    def test_class(self):
-        class C: "New-style class"
-        c = C()
-
-        self.assertEqual(pydoc.describe(C), 'class C')
-        self.assertEqual(pydoc.describe(c), 'C')
-        expected = 'C in module %s object' % __name__
-        self.assertIn(expected, pydoc.render_doc(c))
-
-    def test_generic_alias(self):
-        self.assertEqual(pydoc.describe(typing.List[int]), '_GenericAlias')
-        doc = pydoc.render_doc(typing.List[int], renderer=pydoc.plaintext)
-        self.assertIn('_GenericAlias in module typing', doc)
-        self.assertIn('List = class list(object)', doc)
-        if not MISSING_C_DOCSTRINGS:
-            self.assertIn(list.__doc__.strip().splitlines()[0], doc)
-
-        self.assertEqual(pydoc.describe(list[int]), 'GenericAlias')
-        doc = pydoc.render_doc(list[int], renderer=pydoc.plaintext)
-        self.assertIn('GenericAlias in module builtins', doc)
-        self.assertIn('\nclass list(object)', doc)
-        if not MISSING_C_DOCSTRINGS:
-            self.assertIn(list.__doc__.strip().splitlines()[0], doc)
-
-    def test_union_type(self):
-        self.assertEqual(pydoc.describe(typing.Union[int, str]), '_UnionGenericAlias')
-        doc = pydoc.render_doc(typing.Union[int, str], renderer=pydoc.plaintext)
-        self.assertIn('_UnionGenericAlias in module typing', doc)
-        self.assertIn('Union = typing.Union', doc)
-        if typing.Union.__doc__:
-            self.assertIn(typing.Union.__doc__.strip().splitlines()[0], doc)
-
-        self.assertEqual(pydoc.describe(int | str), 'UnionType')
-        doc = pydoc.render_doc(int | str, renderer=pydoc.plaintext)
-        self.assertIn('UnionType in module types object', doc)
-        self.assertIn('\nclass UnionType(builtins.object)', doc)
-        if not MISSING_C_DOCSTRINGS:
-            self.assertIn(types.UnionType.__doc__.strip().splitlines()[0], doc)
-
-    def test_special_form(self):
-        self.assertEqual(pydoc.describe(typing.NoReturn), '_SpecialForm')
-        doc = pydoc.render_doc(typing.NoReturn, renderer=pydoc.plaintext)
-        self.assertIn('_SpecialForm in module typing', doc)
-        if typing.NoReturn.__doc__:
-            self.assertIn('NoReturn = typing.NoReturn', doc)
-            self.assertIn(typing.NoReturn.__doc__.strip().splitlines()[0], doc)
-        else:
-            self.assertIn('NoReturn = class _SpecialForm(_Final)', doc)
-
-    def test_typing_pydoc(self):
-        def foo(data: typing.List[typing.Any],
-                x: int) -> typing.Iterator[typing.Tuple[int, typing.Any]]:
-            ...
-        T = typing.TypeVar('T')
-        class C(typing.Generic[T], typing.Mapping[int, str]): ...
-        self.assertEqual(pydoc.render_doc(foo).splitlines()[-1],
-                         'f\x08fo\x08oo\x08o(data: List[Any], x: int)'
-                         ' -> Iterator[Tuple[int, Any]]')
-        self.assertEqual(pydoc.render_doc(C).splitlines()[2],
-                         'class C\x08C(collections.abc.Mapping, typing.Generic)')
-
-    def test_builtin(self):
-        for name in ('str', 'str.translate', 'builtins.str',
-                     'builtins.str.translate'):
-            # test low-level function
-            self.assertIsNotNone(pydoc.locate(name))
-            # test high-level function
-            try:
-                pydoc.render_doc(name)
-            except ImportError:
-                self.fail('finding the doc of {!r} failed'.format(name))
-
-        for name in ('notbuiltins', 'strrr', 'strr.translate',
-                     'str.trrrranslate', 'builtins.strrr',
-                     'builtins.str.trrranslate'):
-            self.assertIsNone(pydoc.locate(name))
-            self.assertRaises(ImportError, pydoc.render_doc, name)
-
-    @staticmethod
-    def _get_summary_line(o):
-        text = pydoc.plain(pydoc.render_doc(o))
-        lines = text.split('\n')
-        assert len(lines) >= 2
-        return lines[2]
-
-    @staticmethod
-    def _get_summary_lines(o):
-        text = pydoc.plain(pydoc.render_doc(o))
-        lines = text.split('\n')
-        return '\n'.join(lines[2:])
-
-    # these should include "self"
-    def test_unbound_python_method(self):
-        self.assertEqual(self._get_summary_line(textwrap.TextWrapper.wrap),
-            "wrap(self, text)")
-
-    @requires_docstrings
-    def test_unbound_builtin_method(self):
-        self.assertEqual(self._get_summary_line(_pickle.Pickler.dump),
-            "dump(self, obj, /)")
-
-    # these no longer include "self"
-    def test_bound_python_method(self):
-        t = textwrap.TextWrapper()
-        self.assertEqual(self._get_summary_line(t.wrap),
-            "wrap(text) method of textwrap.TextWrapper instance")
-    def test_field_order_for_named_tuples(self):
-        Person = namedtuple('Person', ['nickname', 'firstname', 'agegroup'])
-        s = pydoc.render_doc(Person)
-        self.assertLess(s.index('nickname'), s.index('firstname'))
-        self.assertLess(s.index('firstname'), s.index('agegroup'))
-
-        class NonIterableFields:
-            _fields = None
-
-        class NonHashableFields:
-            _fields = [[]]
-
-        # Make sure these doesn't fail
-        pydoc.render_doc(NonIterableFields)
-        pydoc.render_doc(NonHashableFields)
-
-    @requires_docstrings
-    def test_bound_builtin_method(self):
-        s = StringIO()
-        p = _pickle.Pickler(s)
-        self.assertEqual(self._get_summary_line(p.dump),
-            "dump(obj, /) method of _pickle.Pickler instance")
-
-    # this should *never* include self!
-    @requires_docstrings
-    def test_module_level_callable(self):
-        self.assertEqual(self._get_summary_line(os.stat),
-            "stat(path, *, dir_fd=None, follow_symlinks=True)")
-
-    @requires_docstrings
-    def test_staticmethod(self):
-        class X:
-            @staticmethod
-            def sm(x, y):
-                '''A static method'''
-                ...
-        self.assertEqual(self._get_summary_lines(X.__dict__['sm']),
-                         'sm(x, y)\n'
-                         '    A static method\n')
-        self.assertEqual(self._get_summary_lines(X.sm), """\
-sm(x, y)
-    A static method
-""")
-        self.assertIn("""
- |  Static methods defined here:
- |
- |  sm(x, y)
- |      A static method
-""", pydoc.plain(pydoc.render_doc(X)))
-
-    @requires_docstrings
-    def test_classmethod(self):
-        class X:
-            @classmethod
-            def cm(cls, x):
-                '''A class method'''
-                ...
-        self.assertEqual(self._get_summary_lines(X.__dict__['cm']),
-                         'cm(...)\n'
-                         '    A class method\n')
-        self.assertEqual(self._get_summary_lines(X.cm), """\
-cm(x) method of builtins.type instance
-    A class method
-""")
-        self.assertIn("""
- |  Class methods defined here:
- |
- |  cm(x) from builtins.type
- |      A class method
-""", pydoc.plain(pydoc.render_doc(X)))
-
-    @requires_docstrings
-    def test_getset_descriptor(self):
-        # Currently these attributes are implemented as getset descriptors
-        # in CPython.
-        self.assertEqual(self._get_summary_line(int.numerator), "numerator")
-        self.assertEqual(self._get_summary_line(float.real), "real")
-        self.assertEqual(self._get_summary_line(Exception.args), "args")
-        self.assertEqual(self._get_summary_line(memoryview.obj), "obj")
-
-    @requires_docstrings
-    def test_member_descriptor(self):
-        # Currently these attributes are implemented as member descriptors
-        # in CPython.
-        self.assertEqual(self._get_summary_line(complex.real), "real")
-        self.assertEqual(self._get_summary_line(range.start), "start")
-        self.assertEqual(self._get_summary_line(slice.start), "start")
-        self.assertEqual(self._get_summary_line(property.fget), "fget")
-        self.assertEqual(self._get_summary_line(StopIteration.value), "value")
-
-    @requires_docstrings
-    def test_slot_descriptor(self):
-        class Point:
-            __slots__ = 'x', 'y'
-        self.assertEqual(self._get_summary_line(Point.x), "x")
-
-    @requires_docstrings
-    def test_dict_attr_descriptor(self):
-        class NS:
-            pass
-        self.assertEqual(self._get_summary_line(NS.__dict__['__dict__']),
-                         "__dict__")
-
-    @requires_docstrings
-    def test_structseq_member_descriptor(self):
-        self.assertEqual(self._get_summary_line(type(sys.hash_info).width),
-                         "width")
-        self.assertEqual(self._get_summary_line(type(sys.flags).debug),
-                         "debug")
-        self.assertEqual(self._get_summary_line(type(sys.version_info).major),
-                         "major")
-        self.assertEqual(self._get_summary_line(type(sys.float_info).max),
-                         "max")
-
-    @requires_docstrings
-    def test_namedtuple_field_descriptor(self):
-        Box = namedtuple('Box', ('width', 'height'))
-        self.assertEqual(self._get_summary_lines(Box.width), """\
-    Alias for field number 0
-""")
-
-    @requires_docstrings
-    def test_property(self):
-        class Rect:
-            @property
-            def area(self):
-                '''Area of the rect'''
-                return self.w * self.h
-
-        self.assertEqual(self._get_summary_lines(Rect.area), """\
-    Area of the rect
-""")
-        self.assertIn("""
- |  area
- |      Area of the rect
-""", pydoc.plain(pydoc.render_doc(Rect)))
-
-    @requires_docstrings
-    def test_custom_non_data_descriptor(self):
-        class Descr:
-            def __get__(self, obj, cls):
-                if obj is None:
-                    return self
-                return 42
-        class X:
-            attr = Descr()
-
-        self.assertEqual(self._get_summary_lines(X.attr), f"""\
-<{__name__}.TestDescriptions.test_custom_non_data_descriptor.<locals>.Descr object>""")
-
-        X.attr.__doc__ = 'Custom descriptor'
-        self.assertEqual(self._get_summary_lines(X.attr), f"""\
-<{__name__}.TestDescriptions.test_custom_non_data_descriptor.<locals>.Descr object>
-    Custom descriptor
-""")
-
-        X.attr.__name__ = 'foo'
-        self.assertEqual(self._get_summary_lines(X.attr), """\
-foo(...)
-    Custom descriptor
-""")
-
-    @requires_docstrings
-    def test_custom_data_descriptor(self):
-        class Descr:
-            def __get__(self, obj, cls):
-                if obj is None:
-                    return self
-                return 42
-            def __set__(self, obj, cls):
-                1/0
-        class X:
-            attr = Descr()
-
-        self.assertEqual(self._get_summary_lines(X.attr), "")
-
-        X.attr.__doc__ = 'Custom descriptor'
-        self.assertEqual(self._get_summary_lines(X.attr), """\
-    Custom descriptor
-""")
-
-        X.attr.__name__ = 'foo'
-        self.assertEqual(self._get_summary_lines(X.attr), """\
-foo
-    Custom descriptor
-""")
-
-    def test_async_annotation(self):
-        async def coro_function(ign) -> int:
-            return 1
-
-        text = pydoc.plain(pydoc.plaintext.document(coro_function))
-        self.assertIn('async coro_function', text)
-
-        html = pydoc.HTMLDoc().document(coro_function)
-        self.assertIn(
-            'async <a name="-coro_function"><strong>coro_function',
-            html)
-
-    def test_async_generator_annotation(self):
-        async def an_async_generator():
-            yield 1
-
-        text = pydoc.plain(pydoc.plaintext.document(an_async_generator))
-        self.assertIn('async an_async_generator', text)
-
-        html = pydoc.HTMLDoc().document(an_async_generator)
-        self.assertIn(
-            'async <a name="-an_async_generator"><strong>an_async_generator',
-            html)
-
-    @requires_docstrings
-    def test_html_for_https_links(self):
-        def a_fn_with_https_link():
-            """a link https://localhost/"""
-            pass
-
-        html = pydoc.HTMLDoc().document(a_fn_with_https_link)
-        self.assertIn(
-            '<a href="https://localhost/">https://localhost/</a>',
-            html
-        )
-
-
-@unittest.skipIf(
-    is_emscripten or is_wasi,
-    "Socket server not available on Emscripten/WASI."
-)
-class PydocServerTest(unittest.TestCase):
-    """Tests for pydoc._start_server"""
-
-    def test_server(self):
-        # Minimal test that starts the server, checks that it works, then stops
-        # it and checks its cleanup.
-        def my_url_handler(url, content_type):
-            text = 'the URL sent was: (%s, %s)' % (url, content_type)
-            return text
-
-        serverthread = pydoc._start_server(
-            my_url_handler,
-            hostname='localhost',
-            port=0,
-            )
-        self.assertEqual(serverthread.error, None)
-        self.assertTrue(serverthread.serving)
-        self.addCleanup(
-            lambda: serverthread.stop() if serverthread.serving else None
-            )
-        self.assertIn('localhost', serverthread.url)
-
-        self.addCleanup(urlcleanup)
-        self.assertEqual(
-            b'the URL sent was: (/test, text/html)',
-            urlopen(urllib.parse.urljoin(serverthread.url, '/test')).read(),
-            )
-        self.assertEqual(
-            b'the URL sent was: (/test.css, text/css)',
-            urlopen(urllib.parse.urljoin(serverthread.url, '/test.css')).read(),
-            )
-
-        serverthread.stop()
-        self.assertFalse(serverthread.serving)
-        self.assertIsNone(serverthread.docserver)
-        self.assertIsNone(serverthread.url)
-
-
-class PydocUrlHandlerTest(PydocBaseTest):
-    """Tests for pydoc._url_handler"""
-
-    def test_content_type_err(self):
-        f = pydoc._url_handler
-        self.assertRaises(TypeError, f, 'A', '')
-        self.assertRaises(TypeError, f, 'B', 'foobar')
-
-    def test_url_requests(self):
-        # Test for the correct title in the html pages returned.
-        # This tests the different parts of the URL handler without
-        # getting too picky about the exact html.
-        requests = [
-            ("", "Pydoc: Index of Modules"),
-            ("get?key=", "Pydoc: Index of Modules"),
-            ("index", "Pydoc: Index of Modules"),
-            ("topics", "Pydoc: Topics"),
-            ("keywords", "Pydoc: Keywords"),
-            ("pydoc", "Pydoc: module pydoc"),
-            ("get?key=pydoc", "Pydoc: module pydoc"),
-            ("search?key=pydoc", "Pydoc: Search Results"),
-            ("topic?key=def", "Pydoc: KEYWORD def"),
-            ("topic?key=STRINGS", "Pydoc: TOPIC STRINGS"),
-            ("foobar", "Pydoc: Error - foobar"),
-            ]
-
-        with self.restrict_walk_packages():
-            for url, title in requests:
-                self.call_url_handler(url, title)
-
-
-class TestHelper(unittest.TestCase):
-    def test_keywords(self):
-        self.assertEqual(sorted(pydoc.Helper.keywords),
-                         sorted(keyword.kwlist))
-
-
-class PydocWithMetaClasses(unittest.TestCase):
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_DynamicClassAttribute(self):
-        class Meta(type):
-            def __getattr__(self, name):
-                if name == 'ham':
-                    return 'spam'
-                return super().__getattr__(name)
-        class DA(metaclass=Meta):
-            @types.DynamicClassAttribute
-            def ham(self):
-                return 'eggs'
-        expected_text_data_docstrings = tuple('\n |      ' + s if s else ''
-                                      for s in expected_data_docstrings)
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        helper(DA)
-        expected_text = expected_dynamicattribute_pattern % (
-                (__name__,) + expected_text_data_docstrings[:2])
-        result = output.getvalue().strip()
-        self.assertEqual(expected_text, result)
-
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_virtualClassAttributeWithOneMeta(self):
-        class Meta(type):
-            def __dir__(cls):
-                return ['__class__', '__module__', '__name__', 'LIFE']
-            def __getattr__(self, name):
-                if name =='LIFE':
-                    return 42
-                return super().__getattr(name)
-        class Class(metaclass=Meta):
-            pass
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        helper(Class)
-        expected_text = expected_virtualattribute_pattern1 % __name__
-        result = output.getvalue().strip()
-        self.assertEqual(expected_text, result)
-
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_virtualClassAttributeWithTwoMeta(self):
-        class Meta1(type):
-            def __dir__(cls):
-                return ['__class__', '__module__', '__name__', 'one']
-            def __getattr__(self, name):
-                if name =='one':
-                    return 1
-                return super().__getattr__(name)
-        class Meta2(type):
-            def __dir__(cls):
-                return ['__class__', '__module__', '__name__', 'two']
-            def __getattr__(self, name):
-                if name =='two':
-                    return 2
-                return super().__getattr__(name)
-        class Meta3(Meta1, Meta2):
-            def __dir__(cls):
-                return list(sorted(set(
-                    ['__class__', '__module__', '__name__', 'three'] +
-                    Meta1.__dir__(cls) + Meta2.__dir__(cls))))
-            def __getattr__(self, name):
-                if name =='three':
-                    return 3
-                return super().__getattr__(name)
-        class Class1(metaclass=Meta1):
-            pass
-        class Class2(Class1, metaclass=Meta3):
-            pass
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        helper(Class1)
-        expected_text1 = expected_virtualattribute_pattern2 % __name__
-        result1 = output.getvalue().strip()
-        self.assertEqual(expected_text1, result1)
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        helper(Class2)
-        expected_text2 = expected_virtualattribute_pattern3 % __name__
-        result2 = output.getvalue().strip()
-        self.assertEqual(expected_text2, result2)
-
-    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
-                     'trace function introduces __locals__ unexpectedly')
-    @requires_docstrings
-    def test_buggy_dir(self):
-        class M(type):
-            def __dir__(cls):
-                return ['__class__', '__name__', 'missing', 'here']
-        class C(metaclass=M):
-            here = 'present!'
-        output = StringIO()
-        helper = pydoc.Helper(output=output)
-        helper(C)
-        expected_text = expected_missingattribute_pattern % __name__
-        result = output.getvalue().strip()
-        self.assertEqual(expected_text, result)
-
-    def test_resolve_false(self):
-        # Issue #23008: pydoc enum.{,Int}Enum failed
-        # because bool(enum.Enum) is False.
-        with captured_stdout() as help_io:
-            pydoc.help('enum.Enum')
-        helptext = help_io.getvalue()
-        self.assertIn('class Enum', helptext)
-
-
-class TestInternalUtilities(unittest.TestCase):
-
-    def setUp(self):
-        tmpdir = tempfile.TemporaryDirectory()
-        self.argv0dir = tmpdir.name
-        self.argv0 = os.path.join(tmpdir.name, "nonexistent")
-        self.addCleanup(tmpdir.cleanup)
-        self.abs_curdir = abs_curdir = os.getcwd()
-        self.curdir_spellings = ["", os.curdir, abs_curdir]
-
-    def _get_revised_path(self, given_path, argv0=None):
-        # Checking that pydoc.cli() actually calls pydoc._get_revised_path()
-        # is handled via code review (at least for now).
-        if argv0 is None:
-            argv0 = self.argv0
-        return pydoc._get_revised_path(given_path, argv0)
-
-    def _get_starting_path(self):
-        # Get a copy of sys.path without the current directory.
-        clean_path = sys.path.copy()
-        for spelling in self.curdir_spellings:
-            for __ in range(clean_path.count(spelling)):
-                clean_path.remove(spelling)
-        return clean_path
-
-    def test_sys_path_adjustment_adds_missing_curdir(self):
-        clean_path = self._get_starting_path()
-        expected_path = [self.abs_curdir] + clean_path
-        self.assertEqual(self._get_revised_path(clean_path), expected_path)
-
-    def test_sys_path_adjustment_removes_argv0_dir(self):
-        clean_path = self._get_starting_path()
-        expected_path = [self.abs_curdir] + clean_path
-        leading_argv0dir = [self.argv0dir] + clean_path
-        self.assertEqual(self._get_revised_path(leading_argv0dir), expected_path)
-        trailing_argv0dir = clean_path + [self.argv0dir]
-        self.assertEqual(self._get_revised_path(trailing_argv0dir), expected_path)
-
-    def test_sys_path_adjustment_protects_pydoc_dir(self):
-        def _get_revised_path(given_path):
-            return self._get_revised_path(given_path, argv0=pydoc.__file__)
-        clean_path = self._get_starting_path()
-        leading_argv0dir = [self.argv0dir] + clean_path
-        expected_path = [self.abs_curdir] + leading_argv0dir
-        self.assertEqual(_get_revised_path(leading_argv0dir), expected_path)
-        trailing_argv0dir = clean_path + [self.argv0dir]
-        expected_path = [self.abs_curdir] + trailing_argv0dir
-        self.assertEqual(_get_revised_path(trailing_argv0dir), expected_path)
-
-    def test_sys_path_adjustment_when_curdir_already_included(self):
-        clean_path = self._get_starting_path()
-        for spelling in self.curdir_spellings:
-            with self.subTest(curdir_spelling=spelling):
-                # If curdir is already present, no alterations are made at all
-                leading_curdir = [spelling] + clean_path
-                self.assertIsNone(self._get_revised_path(leading_curdir))
-                trailing_curdir = clean_path + [spelling]
-                self.assertIsNone(self._get_revised_path(trailing_curdir))
-                leading_argv0dir = [self.argv0dir] + leading_curdir
-                self.assertIsNone(self._get_revised_path(leading_argv0dir))
-                trailing_argv0dir = trailing_curdir + [self.argv0dir]
-                self.assertIsNone(self._get_revised_path(trailing_argv0dir))
-
-
-def setUpModule():
-    thread_info = threading_helper.threading_setup()
-    unittest.addModuleCleanup(threading_helper.threading_cleanup, *thread_info)
-    unittest.addModuleCleanup(reap_children)
-
-
-if __name__ == "__main__":
-    unittest.main()
diff --git a/Lib/test/test_pydoc/__init__.py b/Lib/test/test_pydoc/__init__.py
new file mode 100644
index 0000000000..f2a39a3fe2
--- /dev/null
+++ b/Lib/test/test_pydoc/__init__.py
@@ -0,0 +1,6 @@
+import os
+from test import support
+
+
+def load_tests(*args):
+    return support.load_package_tests(os.path.dirname(__file__), *args)
diff --git a/Lib/test/test_pydoc/pydoc_mod.py b/Lib/test/test_pydoc/pydoc_mod.py
new file mode 100644
index 0000000000..80c287fb10
--- /dev/null
+++ b/Lib/test/test_pydoc/pydoc_mod.py
@@ -0,0 +1,51 @@
+"""This is a test module for test_pydoc"""
+
+from __future__ import print_function
+
+import types
+import typing
+
+__author__ = "Benjamin Peterson"
+__credits__ = "Nobody"
+__version__ = "1.2.3.4"
+__xyz__ = "X, Y and Z"
+
+class A:
+    """Hello and goodbye"""
+    def __init__():
+        """Wow, I have no function!"""
+        pass
+
+class B(object):
+    NO_MEANING: str = "eggs"
+    pass
+
+class C(object):
+    def say_no(self):
+        return "no"
+    def get_answer(self):
+        """ Return say_no() """
+        return self.say_no()
+    def is_it_true(self):
+        """ Return self.get_answer() """
+        return self.get_answer()
+    def __class_getitem__(self, item):
+        return types.GenericAlias(self, item)
+
+def doc_func():
+    """
+    This function solves all of the world's problems:
+    hunger
+    lack of Python
+    war
+    """
+
+def nodoc_func():
+    pass
+
+
+list_alias1 = typing.List[int]
+list_alias2 = list[int]
+c_alias = C[int]
+type_union1 = typing.Union[int, str]
+type_union2 = int | str
diff --git a/Lib/test/test_pydoc/pydocfodder.py b/Lib/test/test_pydoc/pydocfodder.py
new file mode 100644
index 0000000000..27037e048d
--- /dev/null
+++ b/Lib/test/test_pydoc/pydocfodder.py
@@ -0,0 +1,184 @@
+"""Something just to look at via pydoc."""
+
+import types
+
+def global_func(x, y):
+    """Module global function"""
+
+def global_func2(x, y):
+    """Module global function 2"""
+
+class A:
+    "A class."
+
+    def A_method(self):
+        "Method defined in A."
+    def AB_method(self):
+        "Method defined in A and B."
+    def AC_method(self):
+        "Method defined in A and C."
+    def AD_method(self):
+        "Method defined in A and D."
+    def ABC_method(self):
+        "Method defined in A, B and C."
+    def ABD_method(self):
+        "Method defined in A, B and D."
+    def ACD_method(self):
+        "Method defined in A, C and D."
+    def ABCD_method(self):
+        "Method defined in A, B, C and D."
+
+    def A_classmethod(cls, x):
+        "A class method defined in A."
+    A_classmethod = classmethod(A_classmethod)
+
+    def A_staticmethod(x, y):
+        "A static method defined in A."
+    A_staticmethod = staticmethod(A_staticmethod)
+
+    def _getx(self):
+        "A property getter function."
+    def _setx(self, value):
+        "A property setter function."
+    def _delx(self):
+        "A property deleter function."
+    A_property = property(fdel=_delx, fget=_getx, fset=_setx,
+                          doc="A sample property defined in A.")
+
+    A_int_alias = int
+
+class B(A):
+    "A class, derived from A."
+
+    def AB_method(self):
+        "Method defined in A and B."
+    def ABC_method(self):
+        "Method defined in A, B and C."
+    def ABD_method(self):
+        "Method defined in A, B and D."
+    def ABCD_method(self):
+        "Method defined in A, B, C and D."
+    def B_method(self):
+        "Method defined in B."
+    def BC_method(self):
+        "Method defined in B and C."
+    def BD_method(self):
+        "Method defined in B and D."
+    def BCD_method(self):
+        "Method defined in B, C and D."
+
+    @classmethod
+    def B_classmethod(cls, x):
+        "A class method defined in B."
+
+    global_func = global_func  # same name
+    global_func_alias = global_func
+    global_func2_alias = global_func2
+    B_classmethod_alias = B_classmethod
+    A_classmethod_ref = A.A_classmethod
+    A_staticmethod = A.A_staticmethod  # same name
+    A_staticmethod_alias = A.A_staticmethod
+    A_method_ref = A().A_method
+    A_method_alias = A.A_method
+    B_method_alias = B_method
+    __repr__ = object.__repr__  # same name
+    object_repr = object.__repr__
+    get = {}.get  # same name
+    dict_get = {}.get
+
+B.B_classmethod_ref = B.B_classmethod
+
+
+class C(A):
+    "A class, derived from A."
+
+    def AC_method(self):
+        "Method defined in A and C."
+    def ABC_method(self):
+        "Method defined in A, B and C."
+    def ACD_method(self):
+        "Method defined in A, C and D."
+    def ABCD_method(self):
+        "Method defined in A, B, C and D."
+    def BC_method(self):
+        "Method defined in B and C."
+    def BCD_method(self):
+        "Method defined in B, C and D."
+    def C_method(self):
+        "Method defined in C."
+    def CD_method(self):
+        "Method defined in C and D."
+
+class D(B, C):
+    """A class, derived from B and C.
+    """
+
+    def AD_method(self):
+        "Method defined in A and D."
+    def ABD_method(self):
+        "Method defined in A, B and D."
+    def ACD_method(self):
+        "Method defined in A, C and D."
+    def ABCD_method(self):
+        "Method defined in A, B, C and D."
+    def BD_method(self):
+        "Method defined in B and D."
+    def BCD_method(self):
+        "Method defined in B, C and D."
+    def CD_method(self):
+        "Method defined in C and D."
+    def D_method(self):
+        "Method defined in D."
+
+class FunkyProperties(object):
+    """From SF bug 472347, by Roeland Rengelink.
+
+    Property getters etc may not be vanilla functions or methods,
+    and this used to make GUI pydoc blow up.
+    """
+
+    def __init__(self):
+        self.desc = {'x':0}
+
+    class get_desc:
+        def __init__(self, attr):
+            self.attr = attr
+        def __call__(self, inst):
+            print('Get called', self, inst)
+            return inst.desc[self.attr]
+    class set_desc:
+        def __init__(self, attr):
+            self.attr = attr
+        def __call__(self, inst, val):
+            print('Set called', self, inst, val)
+            inst.desc[self.attr] = val
+    class del_desc:
+        def __init__(self, attr):
+            self.attr = attr
+        def __call__(self, inst):
+            print('Del called', self, inst)
+            del inst.desc[self.attr]
+
+    x = property(get_desc('x'), set_desc('x'), del_desc('x'), 'prop x')
+
+
+submodule = types.ModuleType(__name__ + '.submodule',
+    """A submodule, which should appear in its parent's summary""")
+
+global_func_alias = global_func
+A_classmethod = A.A_classmethod  # same name
+A_classmethod2 = A.A_classmethod
+A_classmethod3 = B.A_classmethod
+A_staticmethod = A.A_staticmethod  # same name
+A_staticmethod_alias = A.A_staticmethod
+A_staticmethod_ref = A().A_staticmethod
+A_staticmethod_ref2 = B().A_staticmethod
+A_method = A().A_method  # same name
+A_method2 = A().A_method
+A_method3 = B().A_method
+B_method = B.B_method  # same name
+B_method2 = B.B_method
+count = list.count  # same name
+list_count = list.count
+get = {}.get  # same name
+dict_get = {}.get
diff --git a/Lib/test/test_pydoc/test_pydoc.py b/Lib/test/test_pydoc/test_pydoc.py
new file mode 100644
index 0000000000..a35257c8ff
--- /dev/null
+++ b/Lib/test/test_pydoc/test_pydoc.py
@@ -0,0 +1,1803 @@
+import os
+import sys
+import contextlib
+import importlib.util
+import inspect
+import pydoc
+import py_compile
+import keyword
+import _pickle
+import pkgutil
+import re
+import stat
+import tempfile
+import test.support
+import types
+import typing
+import unittest
+import urllib.parse
+import xml.etree
+import xml.etree.ElementTree
+import textwrap
+from io import StringIO
+from collections import namedtuple
+from urllib.request import urlopen, urlcleanup
+from test import support
+from test.support import import_helper
+from test.support import os_helper
+from test.support.script_helper import (assert_python_ok,
+                                        assert_python_failure, spawn_python)
+from test.support import threading_helper
+from test.support import (reap_children, captured_output, captured_stdout,
+                          captured_stderr, is_emscripten, is_wasi,
+                          requires_docstrings, MISSING_C_DOCSTRINGS)
+from test.support.os_helper import (TESTFN, rmtree, unlink)
+from test.test_pydoc import pydoc_mod
+from test.test_pydoc import pydocfodder
+
+
+class nonascii:
+    '  '
+    pass
+
+if test.support.HAVE_DOCSTRINGS:
+    expected_data_docstrings = (
+        'dictionary for instance variables',
+        'list of weak references to the object',
+        ) * 2
+else:
+    expected_data_docstrings = ('', '', '', '')
+
+expected_text_pattern = """
+NAME
+    test.test_pydoc.pydoc_mod - This is a test module for test_pydoc
+%s
+CLASSES
+    builtins.object
+        A
+        B
+        C
+
+    class A(builtins.object)
+     |  Hello and goodbye
+     |
+     |  Methods defined here:
+     |
+     |  __init__()
+     |      Wow, I have no function!
+     |
+     |  ----------------------------------------------------------------------
+     |  Data descriptors defined here:
+     |
+     |  __dict__%s
+     |
+     |  __weakref__%s
+
+    class B(builtins.object)
+     |  Data descriptors defined here:
+     |
+     |  __dict__%s
+     |
+     |  __weakref__%s
+     |
+     |  ----------------------------------------------------------------------
+     |  Data and other attributes defined here:
+     |
+     |  NO_MEANING = 'eggs'
+     |
+     |  __annotations__ = {'NO_MEANING': <class 'str'>}
+
+    class C(builtins.object)
+     |  Methods defined here:
+     |
+     |  get_answer(self)
+     |      Return say_no()
+     |
+     |  is_it_true(self)
+     |      Return self.get_answer()
+     |
+     |  say_no(self)
+     |
+     |  ----------------------------------------------------------------------
+     |  Class methods defined here:
+     |
+     |  __class_getitem__(item)
+     |
+     |  ----------------------------------------------------------------------
+     |  Data descriptors defined here:
+     |
+     |  __dict__
+     |      dictionary for instance variables
+     |
+     |  __weakref__
+     |      list of weak references to the object
+
+FUNCTIONS
+    doc_func()
+        This function solves all of the world's problems:
+        hunger
+        lack of Python
+        war
+
+    nodoc_func()
+
+DATA
+    __xyz__ = 'X, Y and Z'
+    c_alias = test.test_pydoc.pydoc_mod.C[int]
+    list_alias1 = typing.List[int]
+    list_alias2 = list[int]
+    type_union1 = typing.Union[int, str]
+    type_union2 = int | str
+
+VERSION
+    1.2.3.4
+
+AUTHOR
+    Benjamin Peterson
+
+CREDITS
+    Nobody
+
+FILE
+    %s
+""".strip()
+
+expected_text_data_docstrings = tuple('\n     |      ' + s if s else ''
+                                      for s in expected_data_docstrings)
+
+html2text_of_expected = """
+test.test_pydoc.pydoc_mod (version 1.2.3.4)
+This is a test module for test_pydoc
+
+Modules
+    types
+    typing
+
+Classes
+    builtins.object
+    A
+    B
+    C
+
+class A(builtins.object)
+    Hello and goodbye
+
+    Methods defined here:
+        __init__()
+            Wow, I have no function!
+    ----------------------------------------------------------------------
+    Data descriptors defined here:
+        __dict__
+            dictionary for instance variables
+        __weakref__
+            list of weak references to the object
+
+class B(builtins.object)
+    Data descriptors defined here:
+        __dict__
+            dictionary for instance variables
+        __weakref__
+            list of weak references to the object
+    ----------------------------------------------------------------------
+    Data and other attributes defined here:
+        NO_MEANING = 'eggs'
+        __annotations__ = {'NO_MEANING': <class 'str'>}
+
+
+class C(builtins.object)
+    Methods defined here:
+        get_answer(self)
+            Return say_no()
+        is_it_true(self)
+            Return self.get_answer()
+        say_no(self)
+    ----------------------------------------------------------------------
+    Class methods defined here:
+        __class_getitem__(item)
+    ----------------------------------------------------------------------
+    Data descriptors defined here:
+        __dict__
+            dictionary for instance variables
+        __weakref__
+             list of weak references to the object
+
+Functions
+    doc_func()
+        This function solves all of the world's problems:
+        hunger
+        lack of Python
+        war
+    nodoc_func()
+
+Data
+    __xyz__ = 'X, Y and Z'
+    c_alias = test.test_pydoc.pydoc_mod.C[int]
+    list_alias1 = typing.List[int]
+    list_alias2 = list[int]
+    type_union1 = typing.Union[int, str]
+    type_union2 = int | str
+
+Author
+    Benjamin Peterson
+
+Credits
+    Nobody
+"""
+
+expected_html_data_docstrings = tuple(s.replace(' ', '&nbsp;')
+                                      for s in expected_data_docstrings)
+
+# output pattern for missing module
+missing_pattern = '''\
+No Python documentation found for %r.
+Use help() to get the interactive help utility.
+Use help(str) for help on the str class.'''.replace('\n', os.linesep)
+
+# output pattern for module with bad imports
+badimport_pattern = "problem in %s - ModuleNotFoundError: No module named %r"
+
+expected_dynamicattribute_pattern = """
+Help on class DA in module %s:
+
+class DA(builtins.object)
+ |  Data descriptors defined here:
+ |
+ |  __dict__%s
+ |
+ |  __weakref__%s
+ |
+ |  ham
+ |
+ |  ----------------------------------------------------------------------
+ |  Data and other attributes inherited from Meta:
+ |
+ |  ham = 'spam'
+""".strip()
+
+expected_virtualattribute_pattern1 = """
+Help on class Class in module %s:
+
+class Class(builtins.object)
+ |  Data and other attributes inherited from Meta:
+ |
+ |  LIFE = 42
+""".strip()
+
+expected_virtualattribute_pattern2 = """
+Help on class Class1 in module %s:
+
+class Class1(builtins.object)
+ |  Data and other attributes inherited from Meta1:
+ |
+ |  one = 1
+""".strip()
+
+expected_virtualattribute_pattern3 = """
+Help on class Class2 in module %s:
+
+class Class2(Class1)
+ |  Method resolution order:
+ |      Class2
+ |      Class1
+ |      builtins.object
+ |
+ |  Data and other attributes inherited from Meta1:
+ |
+ |  one = 1
+ |
+ |  ----------------------------------------------------------------------
+ |  Data and other attributes inherited from Meta3:
+ |
+ |  three = 3
+ |
+ |  ----------------------------------------------------------------------
+ |  Data and other attributes inherited from Meta2:
+ |
+ |  two = 2
+""".strip()
+
+expected_missingattribute_pattern = """
+Help on class C in module %s:
+
+class C(builtins.object)
+ |  Data and other attributes defined here:
+ |
+ |  here = 'present!'
+""".strip()
+
+def run_pydoc(module_name, *args, **env):
+    """
+    Runs pydoc on the specified module. Returns the stripped
+    output of pydoc.
+    """
+    args = args + (module_name,)
+    # do not write bytecode files to avoid caching errors
+    rc, out, err = assert_python_ok('-B', pydoc.__file__, *args, **env)
+    return out.strip()
+
+def run_pydoc_fail(module_name, *args, **env):
+    """
+    Runs pydoc on the specified module expecting a failure.
+    """
+    args = args + (module_name,)
+    rc, out, err = assert_python_failure('-B', pydoc.__file__, *args, **env)
+    return out.strip()
+
+def get_pydoc_html(module):
+    "Returns pydoc generated output as html"
+    doc = pydoc.HTMLDoc()
+    output = doc.docmodule(module)
+    loc = doc.getdocloc(pydoc_mod) or ""
+    if loc:
+        loc = "<br><a href=\"" + loc + "\">Module Docs</a>"
+    return output.strip(), loc
+
+def clean_text(doc):
+    # clean up the extra text formatting that pydoc performs
+    return re.sub('\b.', '', doc)
+
+def get_pydoc_link(module):
+    "Returns a documentation web link of a module"
+    abspath = os.path.abspath
+    dirname = os.path.dirname
+    basedir = dirname(dirname(dirname(abspath(__file__))))
+    doc = pydoc.TextDoc()
+    loc = doc.getdocloc(module, basedir=basedir)
+    return loc
+
+def get_pydoc_text(module):
+    "Returns pydoc generated output as text"
+    doc = pydoc.TextDoc()
+    loc = doc.getdocloc(pydoc_mod) or ""
+    if loc:
+        loc = "\nMODULE DOCS\n    " + loc + "\n"
+
+    output = doc.docmodule(module)
+    output = clean_text(output)
+    return output.strip(), loc
+
+def get_html_title(text):
+    # Bit of hack, but good enough for test purposes
+    header, _, _ = text.partition("</head>")
+    _, _, title = header.partition("<title>")
+    title, _, _ = title.partition("</title>")
+    return title
+
+
+def html2text(html):
+    """A quick and dirty implementation of html2text.
+
+    Tailored for pydoc tests only.
+    """
+    html = html.replace("<dd>", "\n")
+    html = html.replace("<hr>", "-"*70)
+    html = re.sub("<.*?>", "", html)
+    html = pydoc.replace(html, "&nbsp;", " ", "&gt;", ">", "&lt;", "<")
+    return html
+
+
+class PydocBaseTest(unittest.TestCase):
+
+    def _restricted_walk_packages(self, walk_packages, path=None):
+        """
+        A version of pkgutil.walk_packages() that will restrict itself to
+        a given path.
+        """
+        default_path = path or [os.path.dirname(__file__)]
+        def wrapper(path=None, prefix='', onerror=None):
+            return walk_packages(path or default_path, prefix, onerror)
+        return wrapper
+
+    @contextlib.contextmanager
+    def restrict_walk_packages(self, path=None):
+        walk_packages = pkgutil.walk_packages
+        pkgutil.walk_packages = self._restricted_walk_packages(walk_packages,
+                                                               path)
+        try:
+            yield
+        finally:
+            pkgutil.walk_packages = walk_packages
+
+    def call_url_handler(self, url, expected_title):
+        text = pydoc._url_handler(url, "text/html")
+        result = get_html_title(text)
+        # Check the title to ensure an unexpected error page was not returned
+        self.assertEqual(result, expected_title, text)
+        return text
+
+
+class PydocDocTest(unittest.TestCase):
+    maxDiff = None
+
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_html_doc(self):
+        result, doc_loc = get_pydoc_html(pydoc_mod)
+        text_result = html2text(result)
+        text_lines = [line.strip() for line in text_result.splitlines()]
+        text_lines = [line for line in text_lines if line]
+        del text_lines[1]
+        expected_lines = html2text_of_expected.splitlines()
+        expected_lines = [line.strip() for line in expected_lines if line]
+        self.assertEqual(text_lines, expected_lines)
+        mod_file = inspect.getabsfile(pydoc_mod)
+        mod_url = urllib.parse.quote(mod_file)
+        self.assertIn(mod_url, result)
+        self.assertIn(mod_file, result)
+        self.assertIn(doc_loc, result)
+
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_text_doc(self):
+        result, doc_loc = get_pydoc_text(pydoc_mod)
+        expected_text = expected_text_pattern % (
+                        (doc_loc,) +
+                        expected_text_data_docstrings +
+                        (inspect.getabsfile(pydoc_mod),))
+        self.assertEqual(expected_text, result)
+
+    def test_text_enum_member_with_value_zero(self):
+        # Test issue #20654 to ensure enum member with value 0 can be
+        # displayed. It used to throw KeyError: 'zero'.
+        import enum
+        class BinaryInteger(enum.IntEnum):
+            zero = 0
+            one = 1
+        doc = pydoc.render_doc(BinaryInteger)
+        self.assertIn('BinaryInteger.zero', doc)
+
+    def test_mixed_case_module_names_are_lower_cased(self):
+        # issue16484
+        doc_link = get_pydoc_link(xml.etree.ElementTree)
+        self.assertIn('xml.etree.elementtree', doc_link)
+
+    def test_issue8225(self):
+        # Test issue8225 to ensure no doc link appears for xml.etree
+        result, doc_loc = get_pydoc_text(xml.etree)
+        self.assertEqual(doc_loc, "", "MODULE DOCS incorrectly includes a link")
+
+    def test_getpager_with_stdin_none(self):
+        previous_stdin = sys.stdin
+        try:
+            sys.stdin = None
+            pydoc.getpager() # Shouldn't fail.
+        finally:
+            sys.stdin = previous_stdin
+
+    def test_non_str_name(self):
+        # issue14638
+        # Treat illegal (non-str) name like no name
+
+        class A:
+            __name__ = 42
+        class B:
+            pass
+        adoc = pydoc.render_doc(A())
+        bdoc = pydoc.render_doc(B())
+        self.assertEqual(adoc.replace("A", "B"), bdoc)
+
+    def test_not_here(self):
+        missing_module = "test.i_am_not_here"
+        result = str(run_pydoc_fail(missing_module), 'ascii')
+        expected = missing_pattern % missing_module
+        self.assertEqual(expected, result,
+            "documentation for missing module found")
+
+    @requires_docstrings
+    def test_not_ascii(self):
+        result = run_pydoc('test.test_pydoc.test_pydoc.nonascii', PYTHONIOENCODING='ascii')
+        encoded = nonascii.__doc__.encode('ascii', 'backslashreplace')
+        self.assertIn(encoded, result)
+
+    def test_input_strip(self):
+        missing_module = " test.i_am_not_here "
+        result = str(run_pydoc_fail(missing_module), 'ascii')
+        expected = missing_pattern % missing_module.strip()
+        self.assertEqual(expected, result)
+
+    def test_stripid(self):
+        # test with strings, other implementations might have different repr()
+        stripid = pydoc.stripid
+        # strip the id
+        self.assertEqual(stripid('<function stripid at 0x88dcee4>'),
+                         '<function stripid>')
+        self.assertEqual(stripid('<function stripid at 0x01F65390>'),
+                         '<function stripid>')
+        # nothing to strip, return the same text
+        self.assertEqual(stripid('42'), '42')
+        self.assertEqual(stripid("<type 'exceptions.Exception'>"),
+                         "<type 'exceptions.Exception'>")
+
+    def test_builtin_with_more_than_four_children(self):
+        """Tests help on builtin object which have more than four child classes.
+
+        When running help() on a builtin class which has child classes, it
+        should contain a "Built-in subclasses" section and only 4 classes
+        should be displayed with a hint on how many more subclasses are present.
+        For example:
+
+        >>> help(object)
+        Help on class object in module builtins:
+
+        class object
+         |  The most base type
+         |
+         |  Built-in subclasses:
+         |      async_generator
+         |      BaseException
+         |      builtin_function_or_method
+         |      bytearray
+         |      ... and 82 other subclasses
+        """
+        doc = pydoc.TextDoc()
+        text = doc.docclass(object)
+        snip = (" |  Built-in subclasses:\n"
+                " |      async_generator\n"
+                " |      BaseException\n"
+                " |      builtin_function_or_method\n"
+                " |      bytearray\n"
+                " |      ... and \\d+ other subclasses")
+        self.assertRegex(text, snip)
+
+    def test_builtin_with_child(self):
+        """Tests help on builtin object which have only child classes.
+
+        When running help() on a builtin class which has child classes, it
+        should contain a "Built-in subclasses" section. For example:
+
+        >>> help(ArithmeticError)
+        Help on class ArithmeticError in module builtins:
+
+        class ArithmeticError(Exception)
+         |  Base class for arithmetic errors.
+         |
+         ...
+         |
+         |  Built-in subclasses:
+         |      FloatingPointError
+         |      OverflowError
+         |      ZeroDivisionError
+        """
+        doc = pydoc.TextDoc()
+        text = doc.docclass(ArithmeticError)
+        snip = (" |  Built-in subclasses:\n"
+                " |      FloatingPointError\n"
+                " |      OverflowError\n"
+                " |      ZeroDivisionError")
+        self.assertIn(snip, text)
+
+    def test_builtin_with_grandchild(self):
+        """Tests help on builtin classes which have grandchild classes.
+
+        When running help() on a builtin class which has child classes, it
+        should contain a "Built-in subclasses" section. However, if it also has
+        grandchildren, these should not show up on the subclasses section.
+        For example:
+
+        >>> help(Exception)
+        Help on class Exception in module builtins:
+
+        class Exception(BaseException)
+         |  Common base class for all non-exit exceptions.
+         |
+         ...
+         |
+         |  Built-in subclasses:
+         |      ArithmeticError
+         |      AssertionError
+         |      AttributeError
+         ...
+        """
+        doc = pydoc.TextDoc()
+        text = doc.docclass(Exception)
+        snip = (" |  Built-in subclasses:\n"
+                " |      ArithmeticError\n"
+                " |      AssertionError\n"
+                " |      AttributeError")
+        self.assertIn(snip, text)
+        # Testing that the grandchild ZeroDivisionError does not show up
+        self.assertNotIn('ZeroDivisionError', text)
+
+    def test_builtin_no_child(self):
+        """Tests help on builtin object which have no child classes.
+
+        When running help() on a builtin class which has no child classes, it
+        should not contain any "Built-in subclasses" section. For example:
+
+        >>> help(ZeroDivisionError)
+
+        Help on class ZeroDivisionError in module builtins:
+
+        class ZeroDivisionError(ArithmeticError)
+         |  Second argument to a division or modulo operation was zero.
+         |
+         |  Method resolution order:
+         |      ZeroDivisionError
+         |      ArithmeticError
+         |      Exception
+         |      BaseException
+         |      object
+         |
+         |  Methods defined here:
+         ...
+        """
+        doc = pydoc.TextDoc()
+        text = doc.docclass(ZeroDivisionError)
+        # Testing that the subclasses section does not appear
+        self.assertNotIn('Built-in subclasses', text)
+
+    def test_builtin_on_metaclasses(self):
+        """Tests help on metaclasses.
+
+        When running help() on a metaclasses such as type, it
+        should not contain any "Built-in subclasses" section.
+        """
+        doc = pydoc.TextDoc()
+        text = doc.docclass(type)
+        # Testing that the subclasses section does not appear
+        self.assertNotIn('Built-in subclasses', text)
+
+    def test_fail_help_cli(self):
+        elines = (missing_pattern % 'abd').splitlines()
+        with spawn_python("-c" "help()") as proc:
+            out, _ = proc.communicate(b"abd")
+            olines = out.decode().splitlines()[-9:-6]
+            olines[0] = olines[0].removeprefix('help> ')
+            self.assertEqual(elines, olines)
+
+    def test_fail_help_output_redirect(self):
+        with StringIO() as buf:
+            helper = pydoc.Helper(output=buf)
+            helper.help("abd")
+            expected = missing_pattern % "abd"
+            self.assertEqual(expected, buf.getvalue().strip().replace('\n', os.linesep))
+
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_help_output_redirect(self):
+        # issue 940286, if output is set in Helper, then all output from
+        # Helper.help should be redirected
+        getpager_old = pydoc.getpager
+        getpager_new = lambda: (lambda x: x)
+        self.maxDiff = None
+
+        buf = StringIO()
+        helper = pydoc.Helper(output=buf)
+        unused, doc_loc = get_pydoc_text(pydoc_mod)
+        module = "test.test_pydoc.pydoc_mod"
+        help_header = """
+        Help on module test.test_pydoc.pydoc_mod in test.test_pydoc:
+
+        """.lstrip()
+        help_header = textwrap.dedent(help_header)
+        expected_help_pattern = help_header + expected_text_pattern
+
+        pydoc.getpager = getpager_new
+        try:
+            with captured_output('stdout') as output, \
+                 captured_output('stderr') as err:
+                helper.help(module)
+                result = buf.getvalue().strip()
+                expected_text = expected_help_pattern % (
+                                (doc_loc,) +
+                                expected_text_data_docstrings +
+                                (inspect.getabsfile(pydoc_mod),))
+                self.assertEqual('', output.getvalue())
+                self.assertEqual('', err.getvalue())
+                self.assertEqual(expected_text, result)
+        finally:
+            pydoc.getpager = getpager_old
+
+    def test_lambda_with_return_annotation(self):
+        func = lambda a, b, c: 1
+        func.__annotations__ = {"return": int}
+        with captured_output('stdout') as help_io:
+            pydoc.help(func)
+        helptext = help_io.getvalue()
+        self.assertIn("lambda (a, b, c) -> int", helptext)
+
+    def test_lambda_without_return_annotation(self):
+        func = lambda a, b, c: 1
+        func.__annotations__ = {"a": int, "b": int, "c": int}
+        with captured_output('stdout') as help_io:
+            pydoc.help(func)
+        helptext = help_io.getvalue()
+        self.assertIn("lambda (a: int, b: int, c: int)", helptext)
+
+    def test_lambda_with_return_and_params_annotation(self):
+        func = lambda a, b, c: 1
+        func.__annotations__ = {"a": int, "b": int, "c": int, "return": int}
+        with captured_output('stdout') as help_io:
+            pydoc.help(func)
+        helptext = help_io.getvalue()
+        self.assertIn("lambda (a: int, b: int, c: int) -> int", helptext)
+
+    def test_namedtuple_fields(self):
+        Person = namedtuple('Person', ['nickname', 'firstname'])
+        with captured_stdout() as help_io:
+            pydoc.help(Person)
+        helptext = help_io.getvalue()
+        self.assertIn("nickname", helptext)
+        self.assertIn("firstname", helptext)
+        self.assertIn("Alias for field number 0", helptext)
+        self.assertIn("Alias for field number 1", helptext)
+
+    def test_namedtuple_public_underscore(self):
+        NT = namedtuple('NT', ['abc', 'def'], rename=True)
+        with captured_stdout() as help_io:
+            pydoc.help(NT)
+        helptext = help_io.getvalue()
+        self.assertIn('_1', helptext)
+        self.assertIn('_replace', helptext)
+        self.assertIn('_asdict', helptext)
+
+    def test_synopsis(self):
+        self.addCleanup(unlink, TESTFN)
+        for encoding in ('ISO-8859-1', 'UTF-8'):
+            with open(TESTFN, 'w', encoding=encoding) as script:
+                if encoding != 'UTF-8':
+                    print('#coding: {}'.format(encoding), file=script)
+                print('"""line 1: h\xe9', file=script)
+                print('line 2: hi"""', file=script)
+            synopsis = pydoc.synopsis(TESTFN, {})
+            self.assertEqual(synopsis, 'line 1: h\xe9')
+
+    @requires_docstrings
+    def test_synopsis_sourceless(self):
+        os = import_helper.import_fresh_module('os')
+        expected = os.__doc__.splitlines()[0]
+        filename = os.__spec__.cached
+        synopsis = pydoc.synopsis(filename)
+
+        self.assertEqual(synopsis, expected)
+
+    def test_synopsis_sourceless_empty_doc(self):
+        with os_helper.temp_cwd() as test_dir:
+            init_path = os.path.join(test_dir, 'foomod42.py')
+            cached_path = importlib.util.cache_from_source(init_path)
+            with open(init_path, 'w') as fobj:
+                fobj.write("foo = 1")
+            py_compile.compile(init_path)
+            synopsis = pydoc.synopsis(init_path, {})
+            self.assertIsNone(synopsis)
+            synopsis_cached = pydoc.synopsis(cached_path, {})
+            self.assertIsNone(synopsis_cached)
+
+    def test_splitdoc_with_description(self):
+        example_string = "I Am A Doc\n\n\nHere is my description"
+        self.assertEqual(pydoc.splitdoc(example_string),
+                         ('I Am A Doc', '\nHere is my description'))
+
+    def test_is_package_when_not_package(self):
+        with os_helper.temp_cwd() as test_dir:
+            self.assertFalse(pydoc.ispackage(test_dir))
+
+    def test_is_package_when_is_package(self):
+        with os_helper.temp_cwd() as test_dir:
+            init_path = os.path.join(test_dir, '__init__.py')
+            open(init_path, 'w').close()
+            self.assertTrue(pydoc.ispackage(test_dir))
+            os.remove(init_path)
+
+    def test_allmethods(self):
+        # issue 17476: allmethods was no longer returning unbound methods.
+        # This test is a bit fragile in the face of changes to object and type,
+        # but I can't think of a better way to do it without duplicating the
+        # logic of the function under test.
+
+        class TestClass(object):
+            def method_returning_true(self):
+                return True
+
+        # What we expect to get back: everything on object...
+        expected = dict(vars(object))
+        # ...plus our unbound method...
+        expected['method_returning_true'] = TestClass.method_returning_true
+        # ...but not the non-methods on object.
+        del expected['__doc__']
+        del expected['__class__']
+        # inspect resolves descriptors on type into methods, but vars doesn't,
+        # so we need to update __subclasshook__ and __init_subclass__.
+        expected['__subclasshook__'] = TestClass.__subclasshook__
+        expected['__init_subclass__'] = TestClass.__init_subclass__
+
+        methods = pydoc.allmethods(TestClass)
+        self.assertDictEqual(methods, expected)
+
+    @requires_docstrings
+    def test_method_aliases(self):
+        class A:
+            def tkraise(self, aboveThis=None):
+                """Raise this widget in the stacking order."""
+            lift = tkraise
+            def a_size(self):
+                """Return size"""
+        class B(A):
+            def itemconfigure(self, tagOrId, cnf=None, **kw):
+                """Configure resources of an item TAGORID."""
+            itemconfig = itemconfigure
+            b_size = A.a_size
+
+        doc = pydoc.render_doc(B)
+        doc = clean_text(doc)
+        self.assertEqual(doc, '''\
+Python Library Documentation: class B in module %s
+
+class B(A)
+ |  Method resolution order:
+ |      B
+ |      A
+ |      builtins.object
+ |
+ |  Methods defined here:
+ |
+ |  b_size = a_size(self)
+ |
+ |  itemconfig = itemconfigure(self, tagOrId, cnf=None, **kw)
+ |
+ |  itemconfigure(self, tagOrId, cnf=None, **kw)
+ |      Configure resources of an item TAGORID.
+ |
+ |  ----------------------------------------------------------------------
+ |  Methods inherited from A:
+ |
+ |  a_size(self)
+ |      Return size
+ |
+ |  lift = tkraise(self, aboveThis=None)
+ |
+ |  tkraise(self, aboveThis=None)
+ |      Raise this widget in the stacking order.
+ |
+ |  ----------------------------------------------------------------------
+ |  Data descriptors inherited from A:
+ |
+ |  __dict__
+ |      dictionary for instance variables
+ |
+ |  __weakref__
+ |      list of weak references to the object
+''' % __name__)
+
+        doc = pydoc.render_doc(B, renderer=pydoc.HTMLDoc())
+        expected_text = f"""
+Python Library Documentation
+
+class B in module {__name__}
+class B(A)
+    Method resolution order:
+        B
+        A
+        builtins.object
+
+    Methods defined here:
+        b_size = a_size(self)
+        itemconfig = itemconfigure(self, tagOrId, cnf=None, **kw)
+        itemconfigure(self, tagOrId, cnf=None, **kw)
+            Configure resources of an item TAGORID.
+
+    Methods inherited from A:
+        a_size(self)
+            Return size
+        lift = tkraise(self, aboveThis=None)
+        tkraise(self, aboveThis=None)
+            Raise this widget in the stacking order.
+
+    Data descriptors inherited from A:
+        __dict__
+            dictionary for instance variables
+        __weakref__
+            list of weak references to the object
+"""
+        as_text = html2text(doc)
+        expected_lines = [line.strip() for line in expected_text.split("\n") if line]
+        for expected_line in expected_lines:
+            self.assertIn(expected_line, as_text)
+
+    def test__future__imports(self):
+        # __future__ features are excluded from module help,
+        # except when it's the __future__ module itself
+        import __future__
+        future_text, _ = get_pydoc_text(__future__)
+        future_html, _ = get_pydoc_html(__future__)
+        pydoc_mod_text, _ = get_pydoc_text(pydoc_mod)
+        pydoc_mod_html, _ = get_pydoc_html(pydoc_mod)
+
+        for feature in __future__.all_feature_names:
+            txt = f"{feature} = _Feature"
+            html = f"<strong>{feature}</strong> = _Feature"
+            self.assertIn(txt, future_text)
+            self.assertIn(html, future_html)
+            self.assertNotIn(txt, pydoc_mod_text)
+            self.assertNotIn(html, pydoc_mod_html)
+
+
+class PydocImportTest(PydocBaseTest):
+
+    def setUp(self):
+        self.test_dir = os.mkdir(TESTFN)
+        self.addCleanup(rmtree, TESTFN)
+        importlib.invalidate_caches()
+
+    def test_badimport(self):
+        # This tests the fix for issue 5230, where if pydoc found the module
+        # but the module had an internal import error pydoc would report no doc
+        # found.
+        modname = 'testmod_xyzzy'
+        testpairs = (
+            ('i_am_not_here', 'i_am_not_here'),
+            ('test.i_am_not_here_either', 'test.i_am_not_here_either'),
+            ('test.i_am_not_here.neither_am_i', 'test.i_am_not_here'),
+            ('i_am_not_here.{}'.format(modname), 'i_am_not_here'),
+            ('test.{}'.format(modname), 'test.{}'.format(modname)),
+            )
+
+        sourcefn = os.path.join(TESTFN, modname) + os.extsep + "py"
+        for importstring, expectedinmsg in testpairs:
+            with open(sourcefn, 'w') as f:
+                f.write("import {}\n".format(importstring))
+            result = run_pydoc_fail(modname, PYTHONPATH=TESTFN).decode("ascii")
+            expected = badimport_pattern % (modname, expectedinmsg)
+            self.assertEqual(expected, result)
+
+    def test_apropos_with_bad_package(self):
+        # Issue 7425 - pydoc -k failed when bad package on path
+        pkgdir = os.path.join(TESTFN, "syntaxerr")
+        os.mkdir(pkgdir)
+        badsyntax = os.path.join(pkgdir, "__init__") + os.extsep + "py"
+        with open(badsyntax, 'w') as f:
+            f.write("invalid python syntax = $1\n")
+        with self.restrict_walk_packages(path=[TESTFN]):
+            with captured_stdout() as out:
+                with captured_stderr() as err:
+                    pydoc.apropos('xyzzy')
+            # No result, no error
+            self.assertEqual(out.getvalue(), '')
+            self.assertEqual(err.getvalue(), '')
+            # The package name is still matched
+            with captured_stdout() as out:
+                with captured_stderr() as err:
+                    pydoc.apropos('syntaxerr')
+            self.assertEqual(out.getvalue().strip(), 'syntaxerr')
+            self.assertEqual(err.getvalue(), '')
+
+    def test_apropos_with_unreadable_dir(self):
+        # Issue 7367 - pydoc -k failed when unreadable dir on path
+        self.unreadable_dir = os.path.join(TESTFN, "unreadable")
+        os.mkdir(self.unreadable_dir, 0)
+        self.addCleanup(os.rmdir, self.unreadable_dir)
+        # Note, on Windows the directory appears to be still
+        #   readable so this is not really testing the issue there
+        with self.restrict_walk_packages(path=[TESTFN]):
+            with captured_stdout() as out:
+                with captured_stderr() as err:
+                    pydoc.apropos('SOMEKEY')
+        # No result, no error
+        self.assertEqual(out.getvalue(), '')
+        self.assertEqual(err.getvalue(), '')
+
+    @os_helper.skip_unless_working_chmod
+    @unittest.skipIf(is_emscripten, "cannot remove x bit")
+    def test_apropos_empty_doc(self):
+        pkgdir = os.path.join(TESTFN, 'walkpkg')
+        os.mkdir(pkgdir)
+        self.addCleanup(rmtree, pkgdir)
+        init_path = os.path.join(pkgdir, '__init__.py')
+        with open(init_path, 'w') as fobj:
+            fobj.write("foo = 1")
+        current_mode = stat.S_IMODE(os.stat(pkgdir).st_mode)
+        try:
+            os.chmod(pkgdir, current_mode & ~stat.S_IEXEC)
+            with self.restrict_walk_packages(path=[TESTFN]), captured_stdout() as stdout:
+                pydoc.apropos('')
+            self.assertIn('walkpkg', stdout.getvalue())
+        finally:
+            os.chmod(pkgdir, current_mode)
+
+    def test_url_search_package_error(self):
+        # URL handler search should cope with packages that raise exceptions
+        pkgdir = os.path.join(TESTFN, "test_error_package")
+        os.mkdir(pkgdir)
+        init = os.path.join(pkgdir, "__init__.py")
+        with open(init, "wt", encoding="ascii") as f:
+            f.write("""raise ValueError("ouch")\n""")
+        with self.restrict_walk_packages(path=[TESTFN]):
+            # Package has to be importable for the error to have any effect
+            saved_paths = tuple(sys.path)
+            sys.path.insert(0, TESTFN)
+            try:
+                with self.assertRaisesRegex(ValueError, "ouch"):
+                    import test_error_package  # Sanity check
+
+                text = self.call_url_handler("search?key=test_error_package",
+                    "Pydoc: Search Results")
+                found = ('<a href="test_error_package.html">'
+                    'test_error_package</a>')
+                self.assertIn(found, text)
+            finally:
+                sys.path[:] = saved_paths
+
+    @unittest.skip('causes undesirable side-effects (#20128)')
+    def test_modules(self):
+        # See Helper.listmodules().
+        num_header_lines = 2
+        num_module_lines_min = 5  # Playing it safe.
+        num_footer_lines = 3
+        expected = num_header_lines + num_module_lines_min + num_footer_lines
+
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        helper('modules')
+        result = output.getvalue().strip()
+        num_lines = len(result.splitlines())
+
+        self.assertGreaterEqual(num_lines, expected)
+
+    @unittest.skip('causes undesirable side-effects (#20128)')
+    def test_modules_search(self):
+        # See Helper.listmodules().
+        expected = 'pydoc - '
+
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        with captured_stdout() as help_io:
+            helper('modules pydoc')
+        result = help_io.getvalue()
+
+        self.assertIn(expected, result)
+
+    @unittest.skip('some buildbots are not cooperating (#20128)')
+    def test_modules_search_builtin(self):
+        expected = 'gc - '
+
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        with captured_stdout() as help_io:
+            helper('modules garbage')
+        result = help_io.getvalue()
+
+        self.assertTrue(result.startswith(expected))
+
+    def test_importfile(self):
+        loaded_pydoc = pydoc.importfile(pydoc.__file__)
+
+        self.assertIsNot(loaded_pydoc, pydoc)
+        self.assertEqual(loaded_pydoc.__name__, 'pydoc')
+        self.assertEqual(loaded_pydoc.__file__, pydoc.__file__)
+        self.assertEqual(loaded_pydoc.__spec__, pydoc.__spec__)
+
+
+class TestDescriptions(unittest.TestCase):
+
+    def test_module(self):
+        # Check that pydocfodder module can be described
+        doc = pydoc.render_doc(pydocfodder)
+        self.assertIn("pydocfodder", doc)
+
+    def test_class(self):
+        class C: "New-style class"
+        c = C()
+
+        self.assertEqual(pydoc.describe(C), 'class C')
+        self.assertEqual(pydoc.describe(c), 'C')
+        expected = 'C in module %s object' % __name__
+        self.assertIn(expected, pydoc.render_doc(c))
+
+    def test_generic_alias(self):
+        self.assertEqual(pydoc.describe(typing.List[int]), '_GenericAlias')
+        doc = pydoc.render_doc(typing.List[int], renderer=pydoc.plaintext)
+        self.assertIn('_GenericAlias in module typing', doc)
+        self.assertIn('List = class list(object)', doc)
+        if not MISSING_C_DOCSTRINGS:
+            self.assertIn(list.__doc__.strip().splitlines()[0], doc)
+
+        self.assertEqual(pydoc.describe(list[int]), 'GenericAlias')
+        doc = pydoc.render_doc(list[int], renderer=pydoc.plaintext)
+        self.assertIn('GenericAlias in module builtins', doc)
+        self.assertIn('\nclass list(object)', doc)
+        if not MISSING_C_DOCSTRINGS:
+            self.assertIn(list.__doc__.strip().splitlines()[0], doc)
+
+    def test_union_type(self):
+        self.assertEqual(pydoc.describe(typing.Union[int, str]), '_UnionGenericAlias')
+        doc = pydoc.render_doc(typing.Union[int, str], renderer=pydoc.plaintext)
+        self.assertIn('_UnionGenericAlias in module typing', doc)
+        self.assertIn('Union = typing.Union', doc)
+        if typing.Union.__doc__:
+            self.assertIn(typing.Union.__doc__.strip().splitlines()[0], doc)
+
+        self.assertEqual(pydoc.describe(int | str), 'UnionType')
+        doc = pydoc.render_doc(int | str, renderer=pydoc.plaintext)
+        self.assertIn('UnionType in module types object', doc)
+        self.assertIn('\nclass UnionType(builtins.object)', doc)
+        if not MISSING_C_DOCSTRINGS:
+            self.assertIn(types.UnionType.__doc__.strip().splitlines()[0], doc)
+
+    def test_special_form(self):
+        self.assertEqual(pydoc.describe(typing.NoReturn), '_SpecialForm')
+        doc = pydoc.render_doc(typing.NoReturn, renderer=pydoc.plaintext)
+        self.assertIn('_SpecialForm in module typing', doc)
+        if typing.NoReturn.__doc__:
+            self.assertIn('NoReturn = typing.NoReturn', doc)
+            self.assertIn(typing.NoReturn.__doc__.strip().splitlines()[0], doc)
+        else:
+            self.assertIn('NoReturn = class _SpecialForm(_Final)', doc)
+
+    def test_typing_pydoc(self):
+        def foo(data: typing.List[typing.Any],
+                x: int) -> typing.Iterator[typing.Tuple[int, typing.Any]]:
+            ...
+        T = typing.TypeVar('T')
+        class C(typing.Generic[T], typing.Mapping[int, str]): ...
+        self.assertEqual(pydoc.render_doc(foo).splitlines()[-1],
+                         'f\x08fo\x08oo\x08o(data: List[Any], x: int)'
+                         ' -> Iterator[Tuple[int, Any]]')
+        self.assertEqual(pydoc.render_doc(C).splitlines()[2],
+                         'class C\x08C(collections.abc.Mapping, typing.Generic)')
+
+    def test_builtin(self):
+        for name in ('str', 'str.translate', 'builtins.str',
+                     'builtins.str.translate'):
+            # test low-level function
+            self.assertIsNotNone(pydoc.locate(name))
+            # test high-level function
+            try:
+                pydoc.render_doc(name)
+            except ImportError:
+                self.fail('finding the doc of {!r} failed'.format(name))
+
+        for name in ('notbuiltins', 'strrr', 'strr.translate',
+                     'str.trrrranslate', 'builtins.strrr',
+                     'builtins.str.trrranslate'):
+            self.assertIsNone(pydoc.locate(name))
+            self.assertRaises(ImportError, pydoc.render_doc, name)
+
+    @staticmethod
+    def _get_summary_line(o):
+        text = pydoc.plain(pydoc.render_doc(o))
+        lines = text.split('\n')
+        assert len(lines) >= 2
+        return lines[2]
+
+    @staticmethod
+    def _get_summary_lines(o):
+        text = pydoc.plain(pydoc.render_doc(o))
+        lines = text.split('\n')
+        return '\n'.join(lines[2:])
+
+    # these should include "self"
+    def test_unbound_python_method(self):
+        self.assertEqual(self._get_summary_line(textwrap.TextWrapper.wrap),
+            "wrap(self, text)")
+
+    @requires_docstrings
+    def test_unbound_builtin_method(self):
+        self.assertEqual(self._get_summary_line(_pickle.Pickler.dump),
+            "dump(self, obj, /) unbound _pickle.Pickler method")
+
+    # these no longer include "self"
+    def test_bound_python_method(self):
+        t = textwrap.TextWrapper()
+        self.assertEqual(self._get_summary_line(t.wrap),
+            "wrap(text) method of textwrap.TextWrapper instance")
+    def test_field_order_for_named_tuples(self):
+        Person = namedtuple('Person', ['nickname', 'firstname', 'agegroup'])
+        s = pydoc.render_doc(Person)
+        self.assertLess(s.index('nickname'), s.index('firstname'))
+        self.assertLess(s.index('firstname'), s.index('agegroup'))
+
+        class NonIterableFields:
+            _fields = None
+
+        class NonHashableFields:
+            _fields = [[]]
+
+        # Make sure these doesn't fail
+        pydoc.render_doc(NonIterableFields)
+        pydoc.render_doc(NonHashableFields)
+
+    @requires_docstrings
+    def test_bound_builtin_method(self):
+        s = StringIO()
+        p = _pickle.Pickler(s)
+        self.assertEqual(self._get_summary_line(p.dump),
+            "dump(obj, /) method of _pickle.Pickler instance")
+
+    # this should *never* include self!
+    @requires_docstrings
+    def test_module_level_callable(self):
+        self.assertEqual(self._get_summary_line(os.stat),
+            "stat(path, *, dir_fd=None, follow_symlinks=True)")
+
+    def test_unbound_builtin_method_noargs(self):
+        self.assertEqual(self._get_summary_line(str.lower),
+            "lower(self, /) unbound builtins.str method")
+
+    def test_bound_builtin_method_noargs(self):
+        self.assertEqual(self._get_summary_line(''.lower),
+            "lower() method of builtins.str instance")
+
+    @requires_docstrings
+    def test_staticmethod(self):
+        class X:
+            @staticmethod
+            def sm(x, y):
+                '''A static method'''
+                ...
+        self.assertEqual(self._get_summary_lines(X.__dict__['sm']),
+                         'sm(x, y)\n'
+                         '    A static method\n')
+        self.assertEqual(self._get_summary_lines(X.sm), """\
+sm(x, y)
+    A static method
+""")
+        self.assertIn("""
+ |  Static methods defined here:
+ |
+ |  sm(x, y)
+ |      A static method
+""", pydoc.plain(pydoc.render_doc(X)))
+
+    @requires_docstrings
+    def test_classmethod(self):
+        class X:
+            @classmethod
+            def cm(cls, x):
+                '''A class method'''
+                ...
+        self.assertEqual(self._get_summary_lines(X.__dict__['cm']),
+                         'cm(...)\n'
+                         '    A class method\n')
+        self.assertEqual(self._get_summary_lines(X.cm), """\
+cm(x) class method of test.test_pydoc.test_pydoc.X
+    A class method
+""")
+        self.assertIn("""
+ |  Class methods defined here:
+ |
+ |  cm(x)
+ |      A class method
+""", pydoc.plain(pydoc.render_doc(X)))
+
+    @requires_docstrings
+    def test_getset_descriptor(self):
+        # Currently these attributes are implemented as getset descriptors
+        # in CPython.
+        self.assertEqual(self._get_summary_line(int.numerator), "numerator")
+        self.assertEqual(self._get_summary_line(float.real), "real")
+        self.assertEqual(self._get_summary_line(Exception.args), "args")
+        self.assertEqual(self._get_summary_line(memoryview.obj), "obj")
+
+    @requires_docstrings
+    def test_member_descriptor(self):
+        # Currently these attributes are implemented as member descriptors
+        # in CPython.
+        self.assertEqual(self._get_summary_line(complex.real), "real")
+        self.assertEqual(self._get_summary_line(range.start), "start")
+        self.assertEqual(self._get_summary_line(slice.start), "start")
+        self.assertEqual(self._get_summary_line(property.fget), "fget")
+        self.assertEqual(self._get_summary_line(StopIteration.value), "value")
+
+    @requires_docstrings
+    def test_slot_descriptor(self):
+        class Point:
+            __slots__ = 'x', 'y'
+        self.assertEqual(self._get_summary_line(Point.x), "x")
+
+    @requires_docstrings
+    def test_dict_attr_descriptor(self):
+        class NS:
+            pass
+        self.assertEqual(self._get_summary_line(NS.__dict__['__dict__']),
+                         "__dict__")
+
+    @requires_docstrings
+    def test_structseq_member_descriptor(self):
+        self.assertEqual(self._get_summary_line(type(sys.hash_info).width),
+                         "width")
+        self.assertEqual(self._get_summary_line(type(sys.flags).debug),
+                         "debug")
+        self.assertEqual(self._get_summary_line(type(sys.version_info).major),
+                         "major")
+        self.assertEqual(self._get_summary_line(type(sys.float_info).max),
+                         "max")
+
+    @requires_docstrings
+    def test_namedtuple_field_descriptor(self):
+        Box = namedtuple('Box', ('width', 'height'))
+        self.assertEqual(self._get_summary_lines(Box.width), """\
+    Alias for field number 0
+""")
+
+    @requires_docstrings
+    def test_property(self):
+        class Rect:
+            @property
+            def area(self):
+                '''Area of the rect'''
+                return self.w * self.h
+
+        self.assertEqual(self._get_summary_lines(Rect.area), """\
+    Area of the rect
+""")
+        self.assertIn("""
+ |  area
+ |      Area of the rect
+""", pydoc.plain(pydoc.render_doc(Rect)))
+
+    @requires_docstrings
+    def test_custom_non_data_descriptor(self):
+        class Descr:
+            def __get__(self, obj, cls):
+                if obj is None:
+                    return self
+                return 42
+        class X:
+            attr = Descr()
+
+        self.assertEqual(self._get_summary_lines(X.attr), f"""\
+<{__name__}.TestDescriptions.test_custom_non_data_descriptor.<locals>.Descr object>""")
+
+        X.attr.__doc__ = 'Custom descriptor'
+        self.assertEqual(self._get_summary_lines(X.attr), f"""\
+<{__name__}.TestDescriptions.test_custom_non_data_descriptor.<locals>.Descr object>
+    Custom descriptor
+""")
+
+        X.attr.__name__ = 'foo'
+        self.assertEqual(self._get_summary_lines(X.attr), """\
+foo(...)
+    Custom descriptor
+""")
+
+    @requires_docstrings
+    def test_custom_data_descriptor(self):
+        class Descr:
+            def __get__(self, obj, cls):
+                if obj is None:
+                    return self
+                return 42
+            def __set__(self, obj, cls):
+                1/0
+        class X:
+            attr = Descr()
+
+        self.assertEqual(self._get_summary_lines(X.attr), "")
+
+        X.attr.__doc__ = 'Custom descriptor'
+        self.assertEqual(self._get_summary_lines(X.attr), """\
+    Custom descriptor
+""")
+
+        X.attr.__name__ = 'foo'
+        self.assertEqual(self._get_summary_lines(X.attr), """\
+foo
+    Custom descriptor
+""")
+
+    def test_async_annotation(self):
+        async def coro_function(ign) -> int:
+            return 1
+
+        text = pydoc.plain(pydoc.plaintext.document(coro_function))
+        self.assertIn('async coro_function', text)
+
+        html = pydoc.HTMLDoc().document(coro_function)
+        self.assertIn(
+            'async <a name="-coro_function"><strong>coro_function',
+            html)
+
+    def test_async_generator_annotation(self):
+        async def an_async_generator():
+            yield 1
+
+        text = pydoc.plain(pydoc.plaintext.document(an_async_generator))
+        self.assertIn('async an_async_generator', text)
+
+        html = pydoc.HTMLDoc().document(an_async_generator)
+        self.assertIn(
+            'async <a name="-an_async_generator"><strong>an_async_generator',
+            html)
+
+    @requires_docstrings
+    def test_html_for_https_links(self):
+        def a_fn_with_https_link():
+            """a link https://localhost/"""
+            pass
+
+        html = pydoc.HTMLDoc().document(a_fn_with_https_link)
+        self.assertIn(
+            '<a href="https://localhost/">https://localhost/</a>',
+            html
+        )
+
+
+class PydocFodderTest(unittest.TestCase):
+
+    def getsection(self, text, beginline, endline):
+        lines = text.splitlines()
+        beginindex, endindex = 0, None
+        if beginline is not None:
+            beginindex = lines.index(beginline)
+        if endline is not None:
+            endindex = lines.index(endline, beginindex)
+        return lines[beginindex:endindex]
+
+    def test_text_doc_routines_in_class(self, cls=pydocfodder.B):
+        doc = pydoc.TextDoc()
+        result = doc.docclass(cls)
+        result = clean_text(result)
+        where = 'defined here' if cls is pydocfodder.B else 'inherited from B'
+        lines = self.getsection(result, f' |  Methods {where}:', ' |  ' + '-'*70)
+        self.assertIn(' |  A_method_alias = A_method(self)', lines)
+        self.assertIn(' |  B_method_alias = B_method(self)', lines)
+        self.assertIn(' |  A_staticmethod(x, y) from test.test_pydoc.pydocfodder.A', lines)
+        self.assertIn(' |  A_staticmethod_alias = A_staticmethod(x, y)', lines)
+        self.assertIn(' |  global_func(x, y) from test.test_pydoc.pydocfodder', lines)
+        self.assertIn(' |  global_func_alias = global_func(x, y)', lines)
+        self.assertIn(' |  global_func2_alias = global_func2(x, y) from test.test_pydoc.pydocfodder', lines)
+        self.assertIn(' |  __repr__(self, /) from builtins.object', lines)
+        self.assertIn(' |  object_repr = __repr__(self, /)', lines)
+
+        lines = self.getsection(result, f' |  Static methods {where}:', ' |  ' + '-'*70)
+        self.assertIn(' |  A_classmethod_ref = A_classmethod(x) class method of test.test_pydoc.pydocfodder.A', lines)
+        note = '' if cls is pydocfodder.B else ' class method of test.test_pydoc.pydocfodder.B'
+        self.assertIn(' |  B_classmethod_ref = B_classmethod(x)' + note, lines)
+        self.assertIn(' |  A_method_ref = A_method() method of test.test_pydoc.pydocfodder.A instance', lines)
+        self.assertIn(' |  get(key, default=None, /) method of builtins.dict instance', lines)
+        self.assertIn(' |  dict_get = get(key, default=None, /) method of builtins.dict instance', lines)
+
+        lines = self.getsection(result, f' |  Class methods {where}:', ' |  ' + '-'*70)
+        self.assertIn(' |  B_classmethod(x)', lines)
+        self.assertIn(' |  B_classmethod_alias = B_classmethod(x)', lines)
+
+    def test_html_doc_routines_in_class(self, cls=pydocfodder.B):
+        doc = pydoc.HTMLDoc()
+        result = doc.docclass(cls)
+        result = html2text(result)
+        where = 'defined here' if cls is pydocfodder.B else 'inherited from B'
+        lines = self.getsection(result, f'Methods {where}:', '-'*70)
+        self.assertIn('A_method_alias = A_method(self)', lines)
+        self.assertIn('B_method_alias = B_method(self)', lines)
+        self.assertIn('A_staticmethod(x, y) from test.test_pydoc.pydocfodder.A', lines)
+        self.assertIn('A_staticmethod_alias = A_staticmethod(x, y)', lines)
+        self.assertIn('global_func(x, y) from test.test_pydoc.pydocfodder', lines)
+        self.assertIn('global_func_alias = global_func(x, y)', lines)
+        self.assertIn('global_func2_alias = global_func2(x, y) from test.test_pydoc.pydocfodder', lines)
+        self.assertIn('__repr__(self, /) from builtins.object', lines)
+        self.assertIn('object_repr = __repr__(self, /)', lines)
+
+        lines = self.getsection(result, f'Static methods {where}:', '-'*70)
+        self.assertIn('A_classmethod_ref = A_classmethod(x) class method of test.test_pydoc.pydocfodder.A', lines)
+        note = '' if cls is pydocfodder.B else ' class method of test.test_pydoc.pydocfodder.B'
+        self.assertIn('B_classmethod_ref = B_classmethod(x)' + note, lines)
+        self.assertIn('A_method_ref = A_method() method of test.test_pydoc.pydocfodder.A instance', lines)
+
+        lines = self.getsection(result, f'Class methods {where}:', '-'*70)
+        self.assertIn('B_classmethod(x)', lines)
+        self.assertIn('B_classmethod_alias = B_classmethod(x)', lines)
+
+    def test_text_doc_inherited_routines_in_class(self):
+        self.test_text_doc_routines_in_class(pydocfodder.D)
+
+    def test_html_doc_inherited_routines_in_class(self):
+        self.test_html_doc_routines_in_class(pydocfodder.D)
+
+    def test_text_doc_routines_in_module(self):
+        doc = pydoc.TextDoc()
+        result = doc.docmodule(pydocfodder)
+        result = clean_text(result)
+        lines = self.getsection(result, 'FUNCTIONS', 'FILE')
+        # function alias
+        self.assertIn('    global_func_alias = global_func(x, y)', lines)
+        self.assertIn('    A_staticmethod(x, y)', lines)
+        self.assertIn('    A_staticmethod_alias = A_staticmethod(x, y)', lines)
+        # bound class methods
+        self.assertIn('    A_classmethod(x) class method of A', lines)
+        self.assertIn('    A_classmethod2 = A_classmethod(x) class method of A', lines)
+        self.assertIn('    A_classmethod3 = A_classmethod(x) class method of B', lines)
+        # bound methods
+        self.assertIn('    A_method() method of A instance', lines)
+        self.assertIn('    A_method2 = A_method() method of A instance', lines)
+        self.assertIn('    A_method3 = A_method() method of B instance', lines)
+        self.assertIn('    A_staticmethod_ref = A_staticmethod(x, y)', lines)
+        self.assertIn('    A_staticmethod_ref2 = A_staticmethod(y) method of B instance', lines)
+        self.assertIn('    get(key, default=None, /) method of builtins.dict instance', lines)
+        self.assertIn('    dict_get = get(key, default=None, /) method of builtins.dict instance', lines)
+        # unbound methods
+        self.assertIn('    B_method(self)', lines)
+        self.assertIn('    B_method2 = B_method(self)', lines)
+
+    def test_html_doc_routines_in_module(self):
+        doc = pydoc.HTMLDoc()
+        result = doc.docmodule(pydocfodder)
+        result = html2text(result)
+        lines = self.getsection(result, ' Functions', None)
+        # function alias
+        self.assertIn(' global_func_alias = global_func(x, y)', lines)
+        self.assertIn(' A_staticmethod(x, y)', lines)
+        self.assertIn(' A_staticmethod_alias = A_staticmethod(x, y)', lines)
+        # bound class methods
+        self.assertIn('A_classmethod(x) class method of A', lines)
+        self.assertIn(' A_classmethod2 = A_classmethod(x) class method of A', lines)
+        self.assertIn(' A_classmethod3 = A_classmethod(x) class method of B', lines)
+        # bound methods
+        self.assertIn(' A_method() method of A instance', lines)
+        self.assertIn(' A_method2 = A_method() method of A instance', lines)
+        self.assertIn(' A_method3 = A_method() method of B instance', lines)
+        self.assertIn(' A_staticmethod_ref = A_staticmethod(x, y)', lines)
+        self.assertIn(' A_staticmethod_ref2 = A_staticmethod(y) method of B instance', lines)
+        self.assertIn(' get(key, default=None, /) method of builtins.dict instance', lines)
+        self.assertIn(' dict_get = get(key, default=None, /) method of builtins.dict instance', lines)
+        # unbound methods
+        self.assertIn(' B_method(self)', lines)
+        self.assertIn(' B_method2 = B_method(self)', lines)
+
+
+@unittest.skipIf(
+    is_emscripten or is_wasi,
+    "Socket server not available on Emscripten/WASI."
+)
+class PydocServerTest(unittest.TestCase):
+    """Tests for pydoc._start_server"""
+
+    def test_server(self):
+        # Minimal test that starts the server, checks that it works, then stops
+        # it and checks its cleanup.
+        def my_url_handler(url, content_type):
+            text = 'the URL sent was: (%s, %s)' % (url, content_type)
+            return text
+
+        serverthread = pydoc._start_server(
+            my_url_handler,
+            hostname='localhost',
+            port=0,
+            )
+        self.assertEqual(serverthread.error, None)
+        self.assertTrue(serverthread.serving)
+        self.addCleanup(
+            lambda: serverthread.stop() if serverthread.serving else None
+            )
+        self.assertIn('localhost', serverthread.url)
+
+        self.addCleanup(urlcleanup)
+        self.assertEqual(
+            b'the URL sent was: (/test, text/html)',
+            urlopen(urllib.parse.urljoin(serverthread.url, '/test')).read(),
+            )
+        self.assertEqual(
+            b'the URL sent was: (/test.css, text/css)',
+            urlopen(urllib.parse.urljoin(serverthread.url, '/test.css')).read(),
+            )
+
+        serverthread.stop()
+        self.assertFalse(serverthread.serving)
+        self.assertIsNone(serverthread.docserver)
+        self.assertIsNone(serverthread.url)
+
+
+class PydocUrlHandlerTest(PydocBaseTest):
+    """Tests for pydoc._url_handler"""
+
+    def test_content_type_err(self):
+        f = pydoc._url_handler
+        self.assertRaises(TypeError, f, 'A', '')
+        self.assertRaises(TypeError, f, 'B', 'foobar')
+
+    def test_url_requests(self):
+        # Test for the correct title in the html pages returned.
+        # This tests the different parts of the URL handler without
+        # getting too picky about the exact html.
+        requests = [
+            ("", "Pydoc: Index of Modules"),
+            ("get?key=", "Pydoc: Index of Modules"),
+            ("index", "Pydoc: Index of Modules"),
+            ("topics", "Pydoc: Topics"),
+            ("keywords", "Pydoc: Keywords"),
+            ("pydoc", "Pydoc: module pydoc"),
+            ("get?key=pydoc", "Pydoc: module pydoc"),
+            ("search?key=pydoc", "Pydoc: Search Results"),
+            ("topic?key=def", "Pydoc: KEYWORD def"),
+            ("topic?key=STRINGS", "Pydoc: TOPIC STRINGS"),
+            ("foobar", "Pydoc: Error - foobar"),
+            ]
+
+        with self.restrict_walk_packages():
+            for url, title in requests:
+                self.call_url_handler(url, title)
+
+
+class TestHelper(unittest.TestCase):
+    def test_keywords(self):
+        self.assertEqual(sorted(pydoc.Helper.keywords),
+                         sorted(keyword.kwlist))
+
+
+class PydocWithMetaClasses(unittest.TestCase):
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_DynamicClassAttribute(self):
+        class Meta(type):
+            def __getattr__(self, name):
+                if name == 'ham':
+                    return 'spam'
+                return super().__getattr__(name)
+        class DA(metaclass=Meta):
+            @types.DynamicClassAttribute
+            def ham(self):
+                return 'eggs'
+        expected_text_data_docstrings = tuple('\n |      ' + s if s else ''
+                                      for s in expected_data_docstrings)
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        helper(DA)
+        expected_text = expected_dynamicattribute_pattern % (
+                (__name__,) + expected_text_data_docstrings[:2])
+        result = output.getvalue().strip()
+        self.assertEqual(expected_text, result)
+
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_virtualClassAttributeWithOneMeta(self):
+        class Meta(type):
+            def __dir__(cls):
+                return ['__class__', '__module__', '__name__', 'LIFE']
+            def __getattr__(self, name):
+                if name =='LIFE':
+                    return 42
+                return super().__getattr(name)
+        class Class(metaclass=Meta):
+            pass
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        helper(Class)
+        expected_text = expected_virtualattribute_pattern1 % __name__
+        result = output.getvalue().strip()
+        self.assertEqual(expected_text, result)
+
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_virtualClassAttributeWithTwoMeta(self):
+        class Meta1(type):
+            def __dir__(cls):
+                return ['__class__', '__module__', '__name__', 'one']
+            def __getattr__(self, name):
+                if name =='one':
+                    return 1
+                return super().__getattr__(name)
+        class Meta2(type):
+            def __dir__(cls):
+                return ['__class__', '__module__', '__name__', 'two']
+            def __getattr__(self, name):
+                if name =='two':
+                    return 2
+                return super().__getattr__(name)
+        class Meta3(Meta1, Meta2):
+            def __dir__(cls):
+                return list(sorted(set(
+                    ['__class__', '__module__', '__name__', 'three'] +
+                    Meta1.__dir__(cls) + Meta2.__dir__(cls))))
+            def __getattr__(self, name):
+                if name =='three':
+                    return 3
+                return super().__getattr__(name)
+        class Class1(metaclass=Meta1):
+            pass
+        class Class2(Class1, metaclass=Meta3):
+            pass
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        helper(Class1)
+        expected_text1 = expected_virtualattribute_pattern2 % __name__
+        result1 = output.getvalue().strip()
+        self.assertEqual(expected_text1, result1)
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        helper(Class2)
+        expected_text2 = expected_virtualattribute_pattern3 % __name__
+        result2 = output.getvalue().strip()
+        self.assertEqual(expected_text2, result2)
+
+    @unittest.skipIf(hasattr(sys, 'gettrace') and sys.gettrace(),
+                     'trace function introduces __locals__ unexpectedly')
+    @requires_docstrings
+    def test_buggy_dir(self):
+        class M(type):
+            def __dir__(cls):
+                return ['__class__', '__name__', 'missing', 'here']
+        class C(metaclass=M):
+            here = 'present!'
+        output = StringIO()
+        helper = pydoc.Helper(output=output)
+        helper(C)
+        expected_text = expected_missingattribute_pattern % __name__
+        result = output.getvalue().strip()
+        self.assertEqual(expected_text, result)
+
+    def test_resolve_false(self):
+        # Issue #23008: pydoc enum.{,Int}Enum failed
+        # because bool(enum.Enum) is False.
+        with captured_stdout() as help_io:
+            pydoc.help('enum.Enum')
+        helptext = help_io.getvalue()
+        self.assertIn('class Enum', helptext)
+
+
+class TestInternalUtilities(unittest.TestCase):
+
+    def setUp(self):
+        tmpdir = tempfile.TemporaryDirectory()
+        self.argv0dir = tmpdir.name
+        self.argv0 = os.path.join(tmpdir.name, "nonexistent")
+        self.addCleanup(tmpdir.cleanup)
+        self.abs_curdir = abs_curdir = os.getcwd()
+        self.curdir_spellings = ["", os.curdir, abs_curdir]
+
+    def _get_revised_path(self, given_path, argv0=None):
+        # Checking that pydoc.cli() actually calls pydoc._get_revised_path()
+        # is handled via code review (at least for now).
+        if argv0 is None:
+            argv0 = self.argv0
+        return pydoc._get_revised_path(given_path, argv0)
+
+    def _get_starting_path(self):
+        # Get a copy of sys.path without the current directory.
+        clean_path = sys.path.copy()
+        for spelling in self.curdir_spellings:
+            for __ in range(clean_path.count(spelling)):
+                clean_path.remove(spelling)
+        return clean_path
+
+    def test_sys_path_adjustment_adds_missing_curdir(self):
+        clean_path = self._get_starting_path()
+        expected_path = [self.abs_curdir] + clean_path
+        self.assertEqual(self._get_revised_path(clean_path), expected_path)
+
+    def test_sys_path_adjustment_removes_argv0_dir(self):
+        clean_path = self._get_starting_path()
+        expected_path = [self.abs_curdir] + clean_path
+        leading_argv0dir = [self.argv0dir] + clean_path
+        self.assertEqual(self._get_revised_path(leading_argv0dir), expected_path)
+        trailing_argv0dir = clean_path + [self.argv0dir]
+        self.assertEqual(self._get_revised_path(trailing_argv0dir), expected_path)
+
+    def test_sys_path_adjustment_protects_pydoc_dir(self):
+        def _get_revised_path(given_path):
+            return self._get_revised_path(given_path, argv0=pydoc.__file__)
+        clean_path = self._get_starting_path()
+        leading_argv0dir = [self.argv0dir] + clean_path
+        expected_path = [self.abs_curdir] + leading_argv0dir
+        self.assertEqual(_get_revised_path(leading_argv0dir), expected_path)
+        trailing_argv0dir = clean_path + [self.argv0dir]
+        expected_path = [self.abs_curdir] + trailing_argv0dir
+        self.assertEqual(_get_revised_path(trailing_argv0dir), expected_path)
+
+    def test_sys_path_adjustment_when_curdir_already_included(self):
+        clean_path = self._get_starting_path()
+        for spelling in self.curdir_spellings:
+            with self.subTest(curdir_spelling=spelling):
+                # If curdir is already present, no alterations are made at all
+                leading_curdir = [spelling] + clean_path
+                self.assertIsNone(self._get_revised_path(leading_curdir))
+                trailing_curdir = clean_path + [spelling]
+                self.assertIsNone(self._get_revised_path(trailing_curdir))
+                leading_argv0dir = [self.argv0dir] + leading_curdir
+                self.assertIsNone(self._get_revised_path(leading_argv0dir))
+                trailing_argv0dir = trailing_curdir + [self.argv0dir]
+                self.assertIsNone(self._get_revised_path(trailing_argv0dir))
+
+
+def setUpModule():
+    thread_info = threading_helper.threading_setup()
+    unittest.addModuleCleanup(threading_helper.threading_cleanup, *thread_info)
+    unittest.addModuleCleanup(reap_children)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/Lib/test/test_pyexpat.py b/Lib/test/test_pyexpat.py
index 95698c0b23..43cbd27151 100644
--- a/Lib/test/test_pyexpat.py
+++ b/Lib/test/test_pyexpat.py
@@ -758,5 +758,59 @@ def resolve_entity(context, base, system_id, public_id):
         self.assertEqual(handler_call_args, [("bar", "baz")])
 
 
+class ReparseDeferralTest(unittest.TestCase):
+    def test_getter_setter_round_trip(self):
+        parser = expat.ParserCreate()
+        enabled = (expat.version_info >= (2, 6, 0))
+
+        self.assertIs(parser.GetReparseDeferralEnabled(), enabled)
+        parser.SetReparseDeferralEnabled(False)
+        self.assertIs(parser.GetReparseDeferralEnabled(), False)
+        parser.SetReparseDeferralEnabled(True)
+        self.assertIs(parser.GetReparseDeferralEnabled(), enabled)
+
+    def test_reparse_deferral_enabled(self):
+        if expat.version_info < (2, 6, 0):
+            self.skipTest(f'Expat {expat.version_info} does not '
+                          'support reparse deferral')
+
+        started = []
+
+        def start_element(name, _):
+            started.append(name)
+
+        parser = expat.ParserCreate()
+        parser.StartElementHandler = start_element
+        self.assertTrue(parser.GetReparseDeferralEnabled())
+
+        for chunk in (b'<doc', b'/>'):
+            parser.Parse(chunk, False)
+
+        # The key test: Have handlers already fired?  Expecting: no.
+        self.assertEqual(started, [])
+
+        parser.Parse(b'', True)
+
+        self.assertEqual(started, ['doc'])
+
+    def test_reparse_deferral_disabled(self):
+        started = []
+
+        def start_element(name, _):
+            started.append(name)
+
+        parser = expat.ParserCreate()
+        parser.StartElementHandler = start_element
+        if expat.version_info >= (2, 6, 0):
+            parser.SetReparseDeferralEnabled(False)
+        self.assertFalse(parser.GetReparseDeferralEnabled())
+
+        for chunk in (b'<doc', b'/>'):
+            parser.Parse(chunk, False)
+
+        # The key test: Have handlers already fired?  Expecting: yes.
+        self.assertEqual(started, ['doc'])
+
+
 if __name__ == "__main__":
     unittest.main()
diff --git a/Lib/test/test_regrtest.py b/Lib/test/test_regrtest.py
index 2ab6f6a986..0a0c371836 100644
--- a/Lib/test/test_regrtest.py
+++ b/Lib/test/test_regrtest.py
@@ -27,7 +27,7 @@
 from test.libregrtest import main
 from test.libregrtest import setup
 from test.libregrtest import utils
-from test.libregrtest.filter import set_match_tests, match_test
+from test.libregrtest.filter import get_match_tests, set_match_tests, match_test
 from test.libregrtest.result import TestStats
 from test.libregrtest.utils import normalize_test_name
 
@@ -389,7 +389,7 @@ def test_unknown_option(self):
         self.checkError(['--unknown-option'],
                         'unrecognized arguments: --unknown-option')
 
-    def check_ci_mode(self, args, use_resources, rerun=True):
+    def create_regrtest(self, args):
         ns = cmdline._parse_args(args)
 
         # Check Regrtest attributes which are more reliable than Namespace
@@ -401,6 +401,10 @@ def check_ci_mode(self, args, use_resources, rerun=True):
 
             regrtest = main.Regrtest(ns)
 
+        return regrtest
+
+    def check_ci_mode(self, args, use_resources, rerun=True):
+        regrtest = self.create_regrtest(args)
         self.assertEqual(regrtest.num_workers, -1)
         self.assertEqual(regrtest.want_rerun, rerun)
         self.assertTrue(regrtest.randomize)
@@ -446,6 +450,29 @@ def test_dont_add_python_opts(self):
         ns = cmdline._parse_args(args)
         self.assertFalse(ns._add_python_opts)
 
+    def test_bisect(self):
+        args = ['--bisect']
+        regrtest = self.create_regrtest(args)
+        self.assertTrue(regrtest.want_bisect)
+
+    def test_verbose3_huntrleaks(self):
+        args = ['-R', '3:10', '--verbose3']
+        with support.captured_stderr():
+            regrtest = self.create_regrtest(args)
+        self.assertIsNotNone(regrtest.hunt_refleak)
+        self.assertEqual(regrtest.hunt_refleak.warmups, 3)
+        self.assertEqual(regrtest.hunt_refleak.runs, 10)
+        self.assertFalse(regrtest.output_on_failure)
+
+    def test_xml_huntrleaks(self):
+        args = ['-R', '3:12', '--junit-xml', 'output.xml']
+        with support.captured_stderr():
+            regrtest = self.create_regrtest(args)
+        self.assertIsNotNone(regrtest.hunt_refleak)
+        self.assertEqual(regrtest.hunt_refleak.warmups, 3)
+        self.assertEqual(regrtest.hunt_refleak.runs, 12)
+        self.assertIsNone(regrtest.junit_filename)
+
 
 @dataclasses.dataclass(slots=True)
 class Rerun:
@@ -1148,8 +1175,8 @@ def check_leak(self, code, what, *, run_workers=False):
                                 stderr=subprocess.STDOUT)
         self.check_executed_tests(output, [test], failed=test, stats=1)
 
-        line = 'beginning 6 repetitions\n123456\n......\n'
-        self.check_line(output, re.escape(line))
+        line = r'beginning 6 repetitions. .*\n123:456\n[.0-9X]{3} 111\n'
+        self.check_line(output, line)
 
         line2 = '%s leaked [1, 1, 1] %s, sum=3\n' % (test, what)
         self.assertIn(line2, output)
@@ -1178,6 +1205,47 @@ def test_huntrleaks(self):
     def test_huntrleaks_mp(self):
         self.check_huntrleaks(run_workers=True)
 
+    @unittest.skipUnless(support.Py_DEBUG, 'need a debug build')
+    def test_huntrleaks_bisect(self):
+        # test --huntrleaks --bisect
+        code = textwrap.dedent("""
+            import unittest
+
+            GLOBAL_LIST = []
+
+            class RefLeakTest(unittest.TestCase):
+                def test1(self):
+                    pass
+
+                def test2(self):
+                    pass
+
+                def test3(self):
+                    GLOBAL_LIST.append(object())
+
+                def test4(self):
+                    pass
+        """)
+
+        test = self.create_test('huntrleaks', code=code)
+
+        filename = 'reflog.txt'
+        self.addCleanup(os_helper.unlink, filename)
+        cmd = ['--huntrleaks', '3:3:', '--bisect', test]
+        output = self.run_tests(*cmd,
+                                exitcode=EXITCODE_BAD_TEST,
+                                stderr=subprocess.STDOUT)
+
+        self.assertIn(f"Bisect {test}", output)
+        self.assertIn(f"Bisect {test}: exit code 0", output)
+
+        # test3 is the one which leaks
+        self.assertIn("Bisection completed in", output)
+        self.assertIn(
+            "Tests (1):\n"
+            f"* {test}.RefLeakTest.test3\n",
+            output)
+
     @unittest.skipUnless(support.Py_DEBUG, 'need a debug build')
     def test_huntrleaks_fd_leak(self):
         # test --huntrleaks for file descriptor leak
@@ -2234,6 +2302,10 @@ def __init__(self, test_id):
             def id(self):
                 return self.test_id
 
+        # Restore patterns once the test completes
+        patterns = get_match_tests()
+        self.addCleanup(set_match_tests, patterns)
+
         test_access = Test('test.test_os.FileTests.test_access')
         test_chdir = Test('test.test_os.Win32ErrorTests.test_chdir')
         test_copy = Test('test.test_shutil.TestCopy.test_copy')
diff --git a/Lib/test/test_sax.py b/Lib/test/test_sax.py
index eda4e6a46d..9b3014a94a 100644
--- a/Lib/test/test_sax.py
+++ b/Lib/test/test_sax.py
@@ -19,6 +19,7 @@
 from io import BytesIO, StringIO
 import codecs
 import os.path
+import pyexpat
 import shutil
 import sys
 from urllib.error import URLError
@@ -1214,6 +1215,56 @@ def test_expat_incremental_reset(self):
 
         self.assertEqual(result.getvalue(), start + b"<doc>text</doc>")
 
+    @unittest.skipIf(pyexpat.version_info < (2, 6, 0),
+                     f'Expat {pyexpat.version_info} does not '
+                     'support reparse deferral')
+    def test_flush_reparse_deferral_enabled(self):
+        result = BytesIO()
+        xmlgen = XMLGenerator(result)
+        parser = create_parser()
+        parser.setContentHandler(xmlgen)
+
+        for chunk in ("<doc", ">"):
+            parser.feed(chunk)
+
+        self.assertEqual(result.getvalue(), start)  # i.e. no elements started
+        self.assertTrue(parser._parser.GetReparseDeferralEnabled())
+
+        parser.flush()
+
+        self.assertTrue(parser._parser.GetReparseDeferralEnabled())
+        self.assertEqual(result.getvalue(), start + b"<doc>")
+
+        parser.feed("</doc>")
+        parser.close()
+
+        self.assertEqual(result.getvalue(), start + b"<doc></doc>")
+
+    def test_flush_reparse_deferral_disabled(self):
+        result = BytesIO()
+        xmlgen = XMLGenerator(result)
+        parser = create_parser()
+        parser.setContentHandler(xmlgen)
+
+        for chunk in ("<doc", ">"):
+            parser.feed(chunk)
+
+        if pyexpat.version_info >= (2, 6, 0):
+            parser._parser.SetReparseDeferralEnabled(False)
+            self.assertEqual(result.getvalue(), start)  # i.e. no elements started
+
+        self.assertFalse(parser._parser.GetReparseDeferralEnabled())
+
+        parser.flush()
+
+        self.assertFalse(parser._parser.GetReparseDeferralEnabled())
+        self.assertEqual(result.getvalue(), start + b"<doc>")
+
+        parser.feed("</doc>")
+        parser.close()
+
+        self.assertEqual(result.getvalue(), start + b"<doc></doc>")
+
     # ===== Locator support
 
     def test_expat_locator_noinfo(self):
diff --git a/Lib/test/test_shutil.py b/Lib/test/test_shutil.py
index bf60f37934..49fcd78fd2 100644
--- a/Lib/test/test_shutil.py
+++ b/Lib/test/test_shutil.py
@@ -669,6 +669,23 @@ def test_rmtree_on_junction(self):
         finally:
             shutil.rmtree(TESTFN, ignore_errors=True)
 
+    @unittest.skipUnless(hasattr(os, "mkfifo"), 'requires os.mkfifo()')
+    @unittest.skipIf(sys.platform == "vxworks",
+                    "fifo requires special path on VxWorks")
+    def test_rmtree_on_named_pipe(self):
+        os.mkfifo(TESTFN)
+        try:
+            with self.assertRaises(NotADirectoryError):
+                shutil.rmtree(TESTFN)
+            self.assertTrue(os.path.exists(TESTFN))
+        finally:
+            os.unlink(TESTFN)
+
+        os.mkdir(TESTFN)
+        os.mkfifo(os.path.join(TESTFN, 'mypipe'))
+        shutil.rmtree(TESTFN)
+        self.assertFalse(os.path.exists(TESTFN))
+
 
 class TestCopyTree(BaseTest, unittest.TestCase):
 
diff --git a/Lib/test/test_socket.py b/Lib/test/test_socket.py
index 4eb5af99d6..37f7fd5a04 100644
--- a/Lib/test/test_socket.py
+++ b/Lib/test/test_socket.py
@@ -46,6 +46,7 @@
 
 VSOCKPORT = 1234
 AIX = platform.system() == "AIX"
+WSL = "microsoft-standard-WSL" in platform.release()
 
 try:
     import _socket
@@ -481,6 +482,7 @@ def clientTearDown(self):
         ThreadableTest.clientTearDown(self)
 
 @unittest.skipIf(fcntl is None, "need fcntl")
+@unittest.skipIf(WSL, 'VSOCK does not work on Microsoft WSL')
 @unittest.skipUnless(HAVE_SOCKET_VSOCK,
           'VSOCK sockets required for this test.')
 @unittest.skipUnless(get_cid() != 2,
@@ -497,6 +499,7 @@ def setUp(self):
         self.serv.bind((socket.VMADDR_CID_ANY, VSOCKPORT))
         self.serv.listen()
         self.serverExplicitReady()
+        self.serv.settimeout(support.LOOPBACK_TIMEOUT)
         self.conn, self.connaddr = self.serv.accept()
         self.addCleanup(self.conn.close)
 
diff --git a/Lib/test/test_ssl.py b/Lib/test/test_ssl.py
index 5648ebdec8..9b59ddd887 100644
--- a/Lib/test/test_ssl.py
+++ b/Lib/test/test_ssl.py
@@ -544,7 +544,7 @@ def test_openssl_version(self):
         else:
             openssl_ver = f"OpenSSL {major:d}.{minor:d}.{fix:d}"
         self.assertTrue(
-            s.startswith((openssl_ver, libressl_ver)),
+            s.startswith((openssl_ver, libressl_ver, "AWS-LC")),
             (s, t, hex(n))
         )
 
@@ -1162,24 +1162,30 @@ def test_load_cert_chain(self):
         with self.assertRaises(OSError) as cm:
             ctx.load_cert_chain(NONEXISTINGCERT)
         self.assertEqual(cm.exception.errno, errno.ENOENT)
-        with self.assertRaisesRegex(ssl.SSLError, "PEM lib"):
+        with self.assertRaisesRegex(ssl.SSLError, "PEM (lib|routines)"):
             ctx.load_cert_chain(BADCERT)
-        with self.assertRaisesRegex(ssl.SSLError, "PEM lib"):
+        with self.assertRaisesRegex(ssl.SSLError, "PEM (lib|routines)"):
             ctx.load_cert_chain(EMPTYCERT)
         # Separate key and cert
         ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
         ctx.load_cert_chain(ONLYCERT, ONLYKEY)
         ctx.load_cert_chain(certfile=ONLYCERT, keyfile=ONLYKEY)
         ctx.load_cert_chain(certfile=BYTES_ONLYCERT, keyfile=BYTES_ONLYKEY)
-        with self.assertRaisesRegex(ssl.SSLError, "PEM lib"):
+        with self.assertRaisesRegex(ssl.SSLError, "PEM (lib|routines)"):
             ctx.load_cert_chain(ONLYCERT)
-        with self.assertRaisesRegex(ssl.SSLError, "PEM lib"):
+        with self.assertRaisesRegex(ssl.SSLError, "PEM (lib|routines)"):
             ctx.load_cert_chain(ONLYKEY)
-        with self.assertRaisesRegex(ssl.SSLError, "PEM lib"):
+        with self.assertRaisesRegex(ssl.SSLError, "PEM (lib|routines)"):
             ctx.load_cert_chain(certfile=ONLYKEY, keyfile=ONLYCERT)
         # Mismatching key and cert
         ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
-        with self.assertRaisesRegex(ssl.SSLError, "key values mismatch"):
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            key values mismatch         # OpenSSL
+            |
+            KEY_VALUES_MISMATCH         # AWS-LC
+        )""", re.X)
+        with self.assertRaisesRegex(ssl.SSLError, regex):
             ctx.load_cert_chain(CAFILE_CACERT, ONLYKEY)
         # Password protected key and cert
         ctx.load_cert_chain(CERTFILE_PROTECTED, password=KEY_PASSWORD)
@@ -1247,7 +1253,7 @@ def test_load_verify_locations(self):
         with self.assertRaises(OSError) as cm:
             ctx.load_verify_locations(NONEXISTINGCERT)
         self.assertEqual(cm.exception.errno, errno.ENOENT)
-        with self.assertRaisesRegex(ssl.SSLError, "PEM lib"):
+        with self.assertRaisesRegex(ssl.SSLError, "PEM (lib|routines)"):
             ctx.load_verify_locations(BADCERT)
         ctx.load_verify_locations(CERTFILE, CAPATH)
         ctx.load_verify_locations(CERTFILE, capath=BYTES_CAPATH)
@@ -1651,9 +1657,10 @@ def test_lib_reason(self):
         with self.assertRaises(ssl.SSLError) as cm:
             ctx.load_dh_params(CERTFILE)
         self.assertEqual(cm.exception.library, 'PEM')
-        self.assertEqual(cm.exception.reason, 'NO_START_LINE')
+        regex = "(NO_START_LINE|UNSUPPORTED_PUBLIC_KEY_TYPE)"
+        self.assertRegex(cm.exception.reason, regex)
         s = str(cm.exception)
-        self.assertTrue(s.startswith("[PEM: NO_START_LINE] no start line"), s)
+        self.assertTrue("NO_START_LINE" in s, s)
 
     def test_subclass(self):
         # Check that the appropriate SSLError subclass is raised
@@ -1833,7 +1840,13 @@ def test_connect_fail(self):
         s = test_wrap_socket(socket.socket(socket.AF_INET),
                             cert_reqs=ssl.CERT_REQUIRED)
         self.addCleanup(s.close)
-        self.assertRaisesRegex(ssl.SSLError, "certificate verify failed",
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            certificate verify failed   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED   # AWS-LC
+        )""", re.X)
+        self.assertRaisesRegex(ssl.SSLError, regex,
                                s.connect, self.server_addr)
 
     def test_connect_ex(self):
@@ -1901,7 +1914,13 @@ def test_connect_with_context_fail(self):
             server_hostname=SIGNED_CERTFILE_HOSTNAME
         )
         self.addCleanup(s.close)
-        self.assertRaisesRegex(ssl.SSLError, "certificate verify failed",
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            certificate verify failed   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED   # AWS-LC
+        )""", re.X)
+        self.assertRaisesRegex(ssl.SSLError, regex,
                                 s.connect, self.server_addr)
 
     def test_connect_capath(self):
@@ -2118,14 +2137,16 @@ def test_bio_handshake(self):
         self.assertIsNone(sslobj.version())
         self.assertIsNone(sslobj.shared_ciphers())
         self.assertRaises(ValueError, sslobj.getpeercert)
-        if 'tls-unique' in ssl.CHANNEL_BINDING_TYPES:
+        # tls-unique is not defined for TLSv1.3
+        # https://datatracker.ietf.org/doc/html/rfc8446#appendix-C.5
+        if 'tls-unique' in ssl.CHANNEL_BINDING_TYPES and sslobj.version() != "TLSv1.3":
             self.assertIsNone(sslobj.get_channel_binding('tls-unique'))
         self.ssl_io_loop(sock, incoming, outgoing, sslobj.do_handshake)
         self.assertTrue(sslobj.cipher())
         self.assertIsNone(sslobj.shared_ciphers())
         self.assertIsNotNone(sslobj.version())
         self.assertTrue(sslobj.getpeercert())
-        if 'tls-unique' in ssl.CHANNEL_BINDING_TYPES:
+        if 'tls-unique' in ssl.CHANNEL_BINDING_TYPES and sslobj.version() != "TLSv1.3":
             self.assertTrue(sslobj.get_channel_binding('tls-unique'))
         try:
             self.ssl_io_loop(sock, incoming, outgoing, sslobj.unwrap)
@@ -2850,11 +2871,16 @@ def test_crl_check(self):
         client_context.verify_flags |= ssl.VERIFY_CRL_CHECK_LEAF
 
         server = ThreadedEchoServer(context=server_context, chatty=True)
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            certificate verify failed   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED   # AWS-LC
+        )""", re.X)
         with server:
             with client_context.wrap_socket(socket.socket(),
                                             server_hostname=hostname) as s:
-                with self.assertRaisesRegex(ssl.SSLError,
-                                            "certificate verify failed"):
+                with self.assertRaisesRegex(ssl.SSLError, regex):
                     s.connect((HOST, server.port))
 
         # now load a CRL file. The CRL file is signed by the CA.
@@ -2885,12 +2911,16 @@ def test_check_hostname(self):
 
         # incorrect hostname should raise an exception
         server = ThreadedEchoServer(context=server_context, chatty=True)
+        # Allow for flexible libssl error messages.
+        regex = re.compile(r"""(
+            certificate verify failed   # OpenSSL
+            |
+            CERTIFICATE_VERIFY_FAILED   # AWS-LC
+        )""", re.X)
         with server:
             with client_context.wrap_socket(socket.socket(),
                                             server_hostname="invalid") as s:
-                with self.assertRaisesRegex(
-                        ssl.CertificateError,
-                        "Hostname mismatch, certificate is not valid for 'invalid'."):
+                with self.assertRaisesRegex(ssl.CertificateError, regex):
                     s.connect((HOST, server.port))
 
         # missing server_hostname arg should cause an exception, too
@@ -3094,7 +3124,7 @@ def test_wrong_cert_tls13(self):
             s.connect((HOST, server.port))
             with self.assertRaisesRegex(
                 ssl.SSLError,
-                'alert unknown ca|EOF occurred'
+                'alert unknown ca|EOF occurred|TLSV1_ALERT_UNKNOWN_CA'
             ):
                 # TLS 1.3 perform client cert exchange after handshake
                 s.write(b'data')
@@ -3158,13 +3188,21 @@ def test_ssl_cert_verify_error(self):
                                      server_hostname=SIGNED_CERTFILE_HOSTNAME) as s:
                 try:
                     s.connect((HOST, server.port))
+                    self.fail("Expected connection failure")
                 except ssl.SSLError as e:
                     msg = 'unable to get local issuer certificate'
                     self.assertIsInstance(e, ssl.SSLCertVerificationError)
                     self.assertEqual(e.verify_code, 20)
                     self.assertEqual(e.verify_message, msg)
-                    self.assertIn(msg, repr(e))
-                    self.assertIn('certificate verify failed', repr(e))
+                    # Allow for flexible libssl error messages.
+                    regex = f"({msg}|CERTIFICATE_VERIFY_FAILED)"
+                    self.assertRegex(repr(e), regex)
+                    regex = re.compile(r"""(
+                        certificate verify failed   # OpenSSL
+                        |
+                        CERTIFICATE_VERIFY_FAILED   # AWS-LC
+                    )""", re.X)
+                    self.assertRegex(repr(e), regex)
 
     def test_PROTOCOL_TLS(self):
         """Connecting to an SSLv23 server with various client options"""
@@ -3696,7 +3734,7 @@ def test_no_shared_ciphers(self):
                                             server_hostname=hostname) as s:
                 with self.assertRaises(OSError):
                     s.connect((HOST, server.port))
-        self.assertIn("no shared cipher", server.conn_errors[0])
+        self.assertIn("NO_SHARED_CIPHER", server.conn_errors[0])
 
     def test_version_basic(self):
         """
@@ -3784,7 +3822,7 @@ def test_min_max_version_mismatch(self):
                                             server_hostname=hostname) as s:
                 with self.assertRaises(ssl.SSLError) as e:
                     s.connect((HOST, server.port))
-                self.assertIn("alert", str(e.exception))
+                self.assertRegex(str(e.exception), "(alert|ALERT)")
 
     @requires_tls_version('SSLv3')
     def test_min_max_version_sslv3(self):
@@ -3826,6 +3864,10 @@ def test_tls_unique_channel_binding(self):
 
         client_context, server_context, hostname = testing_context()
 
+        # tls-unique is not defined for TLSv1.3
+        # https://datatracker.ietf.org/doc/html/rfc8446#appendix-C.5
+        client_context.maximum_version = ssl.TLSVersion.TLSv1_2
+
         server = ThreadedEchoServer(context=server_context,
                                     chatty=True,
                                     connectionchatty=False)
@@ -3926,7 +3968,7 @@ def test_dh_params(self):
         cipher = stats["cipher"][0]
         parts = cipher.split("-")
         if "ADH" not in parts and "EDH" not in parts and "DHE" not in parts:
-            self.fail("Non-DH cipher: " + cipher[0])
+            self.fail("Non-DH key exchange: " + cipher[0])
 
     def test_ecdh_curve(self):
         # server secp384r1, client auto
@@ -4093,8 +4135,9 @@ def cb_raising(ssl_sock, server_name, initial_context):
                                            chatty=False,
                                            sni_name='supermessage')
 
-            self.assertEqual(cm.exception.reason,
-                             'SSLV3_ALERT_HANDSHAKE_FAILURE')
+            # Allow for flexible libssl error messages.
+            regex = "(SSLV3_ALERT_HANDSHAKE_FAILURE|NO_PRIVATE_VALUE)"
+            self.assertRegex(cm.exception.reason, regex)
             self.assertEqual(catch.unraisable.exc_type, ZeroDivisionError)
 
     def test_sni_callback_wrong_return_type(self):
diff --git a/Lib/test/test_subprocess.py b/Lib/test/test_subprocess.py
index b2ebfbee80..79efa42791 100644
--- a/Lib/test/test_subprocess.py
+++ b/Lib/test/test_subprocess.py
@@ -1622,6 +1622,22 @@ def test__use_vfork(self, mock_fork_exec):
                 subprocess.run([sys.executable, "-c", "pass"])
             self.assertFalse(mock_fork_exec.call_args_list[-1].args[-1])
 
+    @unittest.skipUnless(hasattr(subprocess, '_winapi'),
+                         'need subprocess._winapi')
+    def test_wait_negative_timeout(self):
+        proc = subprocess.Popen(ZERO_RETURN_CMD)
+        with proc:
+            patch = mock.patch.object(
+                subprocess._winapi,
+                'WaitForSingleObject',
+                return_value=subprocess._winapi.WAIT_OBJECT_0)
+            with patch as mock_wait:
+                proc.wait(-1)  # negative timeout
+                mock_wait.assert_called_once_with(proc._handle, 0)
+                proc.returncode = None
+
+            self.assertEqual(proc.wait(), 0)
+
 
 class RunFuncTestCase(BaseTestCase):
     def run_python(self, code, **kwargs):
@@ -3397,14 +3413,15 @@ def test_preexec_at_exit(self):
         def dummy():
             pass
 
-        def exit_handler():
-            subprocess.Popen({ZERO_RETURN_CMD}, preexec_fn=dummy)
-            print("shouldn't be printed")
-
-        atexit.register(exit_handler)
+        class AtFinalization:
+            def __del__(self):
+                print("OK")
+                subprocess.Popen({ZERO_RETURN_CMD}, preexec_fn=dummy)
+                print("shouldn't be printed")
+        at_finalization = AtFinalization()
         """
         _, out, err = assert_python_ok("-c", code)
-        self.assertEqual(out, b'')
+        self.assertEqual(out.strip(), b"OK")
         self.assertIn(b"preexec_fn not supported at interpreter shutdown", err)
 
 
diff --git a/Lib/test/test_sys_setprofile.py b/Lib/test/test_sys_setprofile.py
index 9e8936630d..bb8adc8b55 100644
--- a/Lib/test/test_sys_setprofile.py
+++ b/Lib/test/test_sys_setprofile.py
@@ -265,10 +265,6 @@ def g(p):
         f_ident = ident(f)
         g_ident = ident(g)
         self.check_events(g, [(1, 'call', g_ident),
-                              (2, 'call', f_ident),
-                              (2, 'return', f_ident),
-                              # once more; the generator is being garbage collected
-                              # and it will do a PY_THROW
                               (2, 'call', f_ident),
                               (2, 'return', f_ident),
                               (1, 'return', g_ident),
diff --git a/Lib/test/test_sys_settrace.py b/Lib/test/test_sys_settrace.py
index 7e16e94aa1..196fd60d19 100644
--- a/Lib/test/test_sys_settrace.py
+++ b/Lib/test/test_sys_settrace.py
@@ -2965,16 +2965,18 @@ def test_trace_unpack_long_sequence(self):
         self.assertEqual(counts, {'call': 1, 'line': 301, 'return': 1})
 
     def test_trace_lots_of_globals(self):
+        count = min(1000, int(support.C_RECURSION_LIMIT * 0.8))
+
         code = """if 1:
             def f():
                 return (
                     {}
                 )
-        """.format("\n+\n".join(f"var{i}\n" for i in range(1000)))
-        ns = {f"var{i}": i for i in range(1000)}
+        """.format("\n+\n".join(f"var{i}\n" for i in range(count)))
+        ns = {f"var{i}": i for i in range(count)}
         exec(code, ns)
         counts = self.count_traces(ns["f"])
-        self.assertEqual(counts, {'call': 1, 'line': 2000, 'return': 1})
+        self.assertEqual(counts, {'call': 1, 'line': count * 2, 'return': 1})
 
 
 class TestEdgeCases(unittest.TestCase):
diff --git a/Lib/test/test_sysconfig.py b/Lib/test/test_sysconfig.py
index b6dbf3d52c..1137c2032b 100644
--- a/Lib/test/test_sysconfig.py
+++ b/Lib/test/test_sysconfig.py
@@ -149,17 +149,21 @@ def test_posix_venv_scheme(self):
                                'python%d.%d' % sys.version_info[:2],
                                'site-packages')
 
-        # Resolve the paths in prefix
-        binpath = os.path.join(sys.prefix, binpath)
-        incpath = os.path.join(sys.prefix, incpath)
-        libpath = os.path.join(sys.prefix, libpath)
+        # Resolve the paths in an imaginary venv/ directory
+        binpath = os.path.join('venv', binpath)
+        incpath = os.path.join('venv', incpath)
+        libpath = os.path.join('venv', libpath)
 
-        self.assertEqual(binpath, sysconfig.get_path('scripts', scheme='posix_venv'))
-        self.assertEqual(libpath, sysconfig.get_path('purelib', scheme='posix_venv'))
+        # Mimic the venv module, set all bases to the venv directory
+        bases = ('base', 'platbase', 'installed_base', 'installed_platbase')
+        vars = {base: 'venv' for base in bases}
+
+        self.assertEqual(binpath, sysconfig.get_path('scripts', scheme='posix_venv', vars=vars))
+        self.assertEqual(libpath, sysconfig.get_path('purelib', scheme='posix_venv', vars=vars))
 
         # The include directory on POSIX isn't exactly the same as before,
         # but it is "within"
-        sysconfig_includedir = sysconfig.get_path('include', scheme='posix_venv')
+        sysconfig_includedir = sysconfig.get_path('include', scheme='posix_venv', vars=vars)
         self.assertTrue(sysconfig_includedir.startswith(incpath + os.sep))
 
     def test_nt_venv_scheme(self):
@@ -169,14 +173,19 @@ def test_nt_venv_scheme(self):
         incpath = 'Include'
         libpath = os.path.join('Lib', 'site-packages')
 
-        # Resolve the paths in prefix
-        binpath = os.path.join(sys.prefix, binpath)
-        incpath = os.path.join(sys.prefix, incpath)
-        libpath = os.path.join(sys.prefix, libpath)
+        # Resolve the paths in an imaginary venv\ directory
+        venv = 'venv'
+        binpath = os.path.join(venv, binpath)
+        incpath = os.path.join(venv, incpath)
+        libpath = os.path.join(venv, libpath)
+
+        # Mimic the venv module, set all bases to the venv directory
+        bases = ('base', 'platbase', 'installed_base', 'installed_platbase')
+        vars = {base: 'venv' for base in bases}
 
-        self.assertEqual(binpath, sysconfig.get_path('scripts', scheme='nt_venv'))
-        self.assertEqual(incpath, sysconfig.get_path('include', scheme='nt_venv'))
-        self.assertEqual(libpath, sysconfig.get_path('purelib', scheme='nt_venv'))
+        self.assertEqual(binpath, sysconfig.get_path('scripts', scheme='nt_venv', vars=vars))
+        self.assertEqual(incpath, sysconfig.get_path('include', scheme='nt_venv', vars=vars))
+        self.assertEqual(libpath, sysconfig.get_path('purelib', scheme='nt_venv', vars=vars))
 
     def test_venv_scheme(self):
         if sys.platform == 'win32':
diff --git a/Lib/test/test_tarfile.py b/Lib/test/test_tarfile.py
index 71489ea493..9aa1726749 100644
--- a/Lib/test/test_tarfile.py
+++ b/Lib/test/test_tarfile.py
@@ -487,14 +487,32 @@ def test_length_zero_header(self):
             with tarfile.open(support.findfile('recursion.tar')) as tar:
                 pass
 
-    def test_extractfile_name(self):
+    def test_extractfile_attrs(self):
         # gh-74468: TarFile.name must name a file, not a parent archive.
         file = self.tar.getmember('ustar/regtype')
         with self.tar.extractfile(file) as fobj:
             self.assertEqual(fobj.name, 'ustar/regtype')
+            self.assertRaises(AttributeError, fobj.fileno)
+            self.assertIs(fobj.readable(), True)
+            self.assertIs(fobj.writable(), False)
+            if self.is_stream:
+                self.assertRaises(AttributeError, fobj.seekable)
+            else:
+                self.assertIs(fobj.seekable(), True)
+            self.assertIs(fobj.closed, False)
+        self.assertIs(fobj.closed, True)
+        self.assertEqual(fobj.name, 'ustar/regtype')
+        self.assertRaises(AttributeError, fobj.fileno)
+        self.assertIs(fobj.readable(), True)
+        self.assertIs(fobj.writable(), False)
+        if self.is_stream:
+            self.assertRaises(AttributeError, fobj.seekable)
+        else:
+            self.assertIs(fobj.seekable(), True)
 
 
 class MiscReadTestBase(CommonReadTest):
+    is_stream = False
     def requires_name_attribute(self):
         pass
 
@@ -787,6 +805,7 @@ def requires_name_attribute(self):
 class StreamReadTest(CommonReadTest, unittest.TestCase):
 
     prefix="r|"
+    is_stream = True
 
     def test_read_through(self):
         # Issue #11224: A poorly designed _FileInFile.read() method
diff --git a/Lib/test/test_threading.py b/Lib/test/test_threading.py
index 00d9e591c7..2e4b860b97 100644
--- a/Lib/test/test_threading.py
+++ b/Lib/test/test_threading.py
@@ -47,6 +47,8 @@ def skip_unless_reliable_fork(test):
         return unittest.skip("due to known OS bug related to thread+fork")(test)
     if support.HAVE_ASAN_FORK_BUG:
         return unittest.skip("libasan has a pthread_create() dead lock related to thread+fork")(test)
+    if support.check_sanitizer(thread=True):
+        return unittest.skip("TSAN doesn't support threads after fork")
     return test
 
 
@@ -384,6 +386,10 @@ def test_finalize_running_thread(self):
         # Issue 1402: the PyGILState_Ensure / _Release functions may be called
         # very late on python exit: on deallocation of a running thread for
         # example.
+        if support.check_sanitizer(thread=True):
+            # the thread running `time.sleep(100)` below will still be alive
+            # at process exit
+            self.skipTest("TSAN would report thread leak")
         import_module("ctypes")
 
         rc, out, err = assert_python_failure("-c", """if 1:
@@ -416,6 +422,11 @@ def waitingThread():
     def test_finalize_with_trace(self):
         # Issue1733757
         # Avoid a deadlock when sys.settrace steps into threading._shutdown
+        if support.check_sanitizer(thread=True):
+            # the thread running `time.sleep(2)` below will still be alive
+            # at process exit
+            self.skipTest("TSAN would report thread leak")
+
         assert_python_ok("-c", """if 1:
             import sys, threading
 
@@ -1122,21 +1133,21 @@ def import_threading():
         self.assertEqual(out, b'')
         self.assertEqual(err, b'')
 
-    def test_start_new_thread_at_exit(self):
+    def test_start_new_thread_at_finalization(self):
         code = """if 1:
-            import atexit
             import _thread
 
             def f():
                 print("shouldn't be printed")
 
-            def exit_handler():
-                _thread.start_new_thread(f, ())
-
-            atexit.register(exit_handler)
+            class AtFinalization:
+                def __del__(self):
+                    print("OK")
+                    _thread.start_new_thread(f, ())
+            at_finalization = AtFinalization()
         """
         _, out, err = assert_python_ok("-c", code)
-        self.assertEqual(out, b'')
+        self.assertEqual(out.strip(), b"OK")
         self.assertIn(b"can't create new thread at interpreter shutdown", err)
 
 class ThreadJoinOnShutdown(BaseTestCase):
@@ -1223,6 +1234,11 @@ def test_4_daemon_threads(self):
         # Check that a daemon thread cannot crash the interpreter on shutdown
         # by manipulating internal structures that are being disposed of in
         # the main thread.
+        if support.check_sanitizer(thread=True):
+            # some of the threads running `random_io` below will still be alive
+            # at process exit
+            self.skipTest("TSAN would report thread leak")
+
         script = """if True:
             import os
             import random
@@ -1260,6 +1276,30 @@ def main():
         rc, out, err = assert_python_ok('-c', script)
         self.assertFalse(err)
 
+    def test_thread_from_thread(self):
+        script = """if True:
+            import threading
+            import time
+
+            def thread2():
+                time.sleep(0.05)
+                print("OK")
+
+            def thread1():
+                time.sleep(0.05)
+                t2 = threading.Thread(target=thread2)
+                t2.start()
+
+            t = threading.Thread(target=thread1)
+            t.start()
+            # do not join() -- the interpreter waits for non-daemon threads to
+            # finish.
+            """
+        rc, out, err = assert_python_ok('-c', script)
+        self.assertEqual(err, b"")
+        self.assertEqual(out.strip(), b"OK")
+        self.assertEqual(rc, 0)
+
     @skip_unless_reliable_fork
     def test_reinit_tls_after_fork(self):
         # Issue #13817: fork() would deadlock in a multithreaded program with
diff --git a/Lib/test/test_threadsignals.py b/Lib/test/test_threadsignals.py
index 6a53d65501..bf241ada90 100644
--- a/Lib/test/test_threadsignals.py
+++ b/Lib/test/test_threadsignals.py
@@ -32,39 +32,28 @@ def handle_signals(sig,frame):
 
 # a function that will be spawned as a separate thread.
 def send_signals():
-    os.kill(process_pid, signal.SIGUSR1)
-    os.kill(process_pid, signal.SIGUSR2)
+    # We use `raise_signal` rather than `kill` because:
+    #   * It verifies that a signal delivered to a background thread still has
+    #     its Python-level handler called on the main thread.
+    #   * It ensures the signal is handled before the thread exits.
+    signal.raise_signal(signal.SIGUSR1)
+    signal.raise_signal(signal.SIGUSR2)
     signalled_all.release()
 
 
 @threading_helper.requires_working_threading()
-@unittest.skipUnless(hasattr(signal, "alarm"), "test requires signal.alarm")
 class ThreadSignals(unittest.TestCase):
 
     def test_signals(self):
         with threading_helper.wait_threads_exit():
             # Test signal handling semantics of threads.
-            # We spawn a thread, have the thread send two signals, and
+            # We spawn a thread, have the thread send itself two signals, and
             # wait for it to finish. Check that we got both signals
             # and that they were run by the main thread.
             signalled_all.acquire()
             self.spawnSignallingThread()
             signalled_all.acquire()
 
-        # the signals that we asked the kernel to send
-        # will come back, but we don't know when.
-        # (it might even be after the thread exits
-        # and might be out of order.)  If we haven't seen
-        # the signals yet, send yet another signal and
-        # wait for it return.
-        if signal_blackboard[signal.SIGUSR1]['tripped'] == 0 \
-           or signal_blackboard[signal.SIGUSR2]['tripped'] == 0:
-            try:
-                signal.alarm(1)
-                signal.pause()
-            finally:
-                signal.alarm(0)
-
         self.assertEqual( signal_blackboard[signal.SIGUSR1]['tripped'], 1)
         self.assertEqual( signal_blackboard[signal.SIGUSR1]['tripped_by'],
                            thread.get_ident())
diff --git a/Lib/test/test_tokenize.py b/Lib/test/test_tokenize.py
index 2886bceb7b..c52b58b4ff 100644
--- a/Lib/test/test_tokenize.py
+++ b/Lib/test/test_tokenize.py
@@ -1874,6 +1874,43 @@ def test_roundtrip(self):
                              "    print('Can not import' # comment2\n)"
                              "else:   print('Loaded')\n")
 
+        self.check_roundtrip("f'\\N{EXCLAMATION MARK}'")
+        self.check_roundtrip(r"f'\\N{SNAKE}'")
+        self.check_roundtrip(r"f'\\N{{SNAKE}}'")
+        self.check_roundtrip(r"f'\N{SNAKE}'")
+        self.check_roundtrip(r"f'\\\N{SNAKE}'")
+        self.check_roundtrip(r"f'\\\\\N{SNAKE}'")
+        self.check_roundtrip(r"f'\\\\\\\N{SNAKE}'")
+
+        self.check_roundtrip(r"f'\\N{1}'")
+        self.check_roundtrip(r"f'\\\\N{2}'")
+        self.check_roundtrip(r"f'\\\\\\N{3}'")
+        self.check_roundtrip(r"f'\\\\\\\\N{4}'")
+
+        self.check_roundtrip(r"f'\\N{{'")
+        self.check_roundtrip(r"f'\\\\N{{'")
+        self.check_roundtrip(r"f'\\\\\\N{{'")
+        self.check_roundtrip(r"f'\\\\\\\\N{{'")
+        cases = [
+    """
+if 1:
+    "foo"
+"bar"
+""",
+    """
+if 1:
+    ("foo"
+     "bar")
+""",
+    """
+if 1:
+    "foo"
+    "bar"
+""" ]
+        for case in cases:
+            self.check_roundtrip(case)
+
+
     def test_continuation(self):
         # Balancing continuation
         self.check_roundtrip("a = (3,4, \n"
@@ -1908,9 +1945,6 @@ def test_random_files(self):
         tempdir = os.path.dirname(__file__) or os.curdir
         testfiles = glob.glob(os.path.join(glob.escape(tempdir), "test*.py"))
 
-        # TODO: Remove this once we can untokenize PEP 701 syntax
-        testfiles.remove(os.path.join(tempdir, "test_fstring.py"))
-
         if not support.is_resource_enabled("cpu"):
             testfiles = random.sample(testfiles, 10)
 
diff --git a/Lib/test/test_tools/test_makefile.py b/Lib/test/test_tools/test_makefile.py
new file mode 100644
index 0000000000..7222a054dc
--- /dev/null
+++ b/Lib/test/test_tools/test_makefile.py
@@ -0,0 +1,64 @@
+"""
+Tests for `Makefile`.
+"""
+
+import os
+import unittest
+from test import support
+import sysconfig
+
+MAKEFILE = sysconfig.get_makefile_filename()
+
+if not support.check_impl_detail(cpython=True):
+    raise unittest.SkipTest('cpython only')
+if not os.path.exists(MAKEFILE) or not os.path.isfile(MAKEFILE):
+    raise unittest.SkipTest('Makefile could not be found')
+
+
+class TestMakefile(unittest.TestCase):
+    def list_test_dirs(self):
+        result = []
+        found_testsubdirs = False
+        with open(MAKEFILE, 'r', encoding='utf-8') as f:
+            for line in f:
+                if line.startswith('TESTSUBDIRS='):
+                    found_testsubdirs = True
+                    result.append(
+                        line.removeprefix('TESTSUBDIRS=').replace(
+                            '\\', '',
+                        ).strip(),
+                    )
+                    continue
+                if found_testsubdirs:
+                    if '\t' not in line:
+                        break
+                    result.append(line.replace('\\', '').strip())
+        return result
+
+    def test_makefile_test_folders(self):
+        test_dirs = self.list_test_dirs()
+        idle_test = 'idlelib/idle_test'
+        self.assertIn(idle_test, test_dirs)
+
+        used = [idle_test]
+        for dirpath, _, _ in os.walk(support.TEST_HOME_DIR):
+            dirname = os.path.basename(dirpath)
+            if dirname == '__pycache__':
+                continue
+
+            relpath = os.path.relpath(dirpath, support.STDLIB_DIR)
+            with self.subTest(relpath=relpath):
+                self.assertIn(
+                    relpath,
+                    test_dirs,
+                    msg=(
+                        f"{relpath!r} is not included in the Makefile's list "
+                        "of test directories to install"
+                    )
+                )
+                used.append(relpath)
+
+        # Check that there are no extra entries:
+        unique_test_dirs = set(test_dirs)
+        self.assertSetEqual(unique_test_dirs, set(used))
+        self.assertEqual(len(test_dirs), len(unique_test_dirs))
diff --git a/Lib/test/test_traceback.py b/Lib/test/test_traceback.py
index 61eb0a7ef9..d12b559cf0 100644
--- a/Lib/test/test_traceback.py
+++ b/Lib/test/test_traceback.py
@@ -666,6 +666,23 @@ def f_with_binary_operator():
         result_lines = self.get_exception(f_with_binary_operator)
         self.assertEqual(result_lines, expected_error.splitlines())
 
+    def test_caret_for_failed_assertion(self):
+        def f_assert():
+            test = 3
+            assert test == 1 and test == 2, "Bug found?"
+
+        lineno_f = f_assert.__code__.co_firstlineno
+        expected_error = (
+            'Traceback (most recent call last):\n'
+            f'  File "{__file__}", line {self.callable_line}, in get_exception\n'
+            '    callable()\n'
+            f'  File "{__file__}", line {lineno_f+2}, in f_assert\n'
+            '    assert test == 1 and test == 2, "Bug found?"\n'
+            '           ^^^^^^^^^^^^^^^^^^^^^^^\n'
+        )
+        result_lines = self.get_exception(f_assert)
+        self.assertEqual(result_lines, expected_error.splitlines())
+
     def test_traceback_specialization_with_syntax_error(self):
         bytecode = compile("1 / 0 / 1 / 2\n", TESTFN, "exec")
 
diff --git a/Lib/test/test_ttk/test_widgets.py b/Lib/test/test_ttk/test_widgets.py
index fd1a748a49..e3e440c458 100644
--- a/Lib/test/test_ttk/test_widgets.py
+++ b/Lib/test/test_ttk/test_widgets.py
@@ -285,9 +285,29 @@ def test_unique_variables(self):
                 b.pack()
                 buttons.append(b)
         variables = [str(b['variable']) for b in buttons]
-        print(variables)
         self.assertEqual(len(set(variables)), 4, variables)
 
+    def test_unique_variables2(self):
+        buttons = []
+        f = ttk.Frame(self.root)
+        f.pack()
+        f = ttk.Frame(self.root)
+        f.pack()
+        for j in 'AB':
+            b = tkinter.Checkbutton(f, text=j)
+            b.pack()
+            buttons.append(b)
+        # Should be larger than the number of all previously created
+        # tkinter.Checkbutton widgets:
+        for j in range(100):
+            b = ttk.Checkbutton(f, text=str(j))
+            b.pack()
+            buttons.append(b)
+        names = [str(b) for b in buttons]
+        self.assertEqual(len(set(names)), len(buttons), names)
+        variables = [str(b['variable']) for b in buttons]
+        self.assertEqual(len(set(variables)), len(buttons), variables)
+
 
 @add_standard_options(IntegerSizeTests, StandardTtkOptionsTests)
 class EntryTest(AbstractWidgetTest, unittest.TestCase):
diff --git a/Lib/test/test_types.py b/Lib/test/test_types.py
index b86392f43c..5ffe4085f0 100644
--- a/Lib/test/test_types.py
+++ b/Lib/test/test_types.py
@@ -709,6 +709,26 @@ def test_hash(self):
         self.assertEqual(hash(int | str), hash(str | int))
         self.assertEqual(hash(int | str), hash(typing.Union[int, str]))
 
+    def test_union_of_unhashable(self):
+        class UnhashableMeta(type):
+            __hash__ = None
+
+        class A(metaclass=UnhashableMeta): ...
+        class B(metaclass=UnhashableMeta): ...
+
+        self.assertEqual((A | B).__args__, (A, B))
+        union1 = A | B
+        with self.assertRaises(TypeError):
+            hash(union1)
+
+        union2 = int | B
+        with self.assertRaises(TypeError):
+            hash(union2)
+
+        union3 = A | int
+        with self.assertRaises(TypeError):
+            hash(union3)
+
     def test_instancecheck_and_subclasscheck(self):
         for x in (int | str, typing.Union[int, str]):
             with self.subTest(x=x):
diff --git a/Lib/test/test_typing.py b/Lib/test/test_typing.py
index 05bc6c47bb..dc117b3482 100644
--- a/Lib/test/test_typing.py
+++ b/Lib/test/test_typing.py
@@ -2,10 +2,11 @@
 import collections
 import collections.abc
 from collections import defaultdict
-from functools import lru_cache, wraps
+from functools import lru_cache, wraps, reduce
 import gc
 import inspect
 import itertools
+import operator
 import pickle
 import re
 import sys
@@ -140,6 +141,26 @@ class MockSomething(Something, Mock): pass
         self.assertIsInstance(ms, Something)
         self.assertIsInstance(ms, Mock)
 
+    def test_subclassing_with_custom_constructor(self):
+        class Sub(Any):
+            def __init__(self, *args, **kwargs): pass
+        # The instantiation must not fail.
+        Sub(0, s="")
+
+    def test_multiple_inheritance_with_custom_constructors(self):
+        class Foo:
+            def __init__(self, x):
+                self.x = x
+
+        class Bar(Any, Foo):
+            def __init__(self, x, y):
+                self.y = y
+                super().__init__(x)
+
+        b = Bar(1, 2)
+        self.assertEqual(b.x, 1)
+        self.assertEqual(b.y, 2)
+
     def test_cannot_instantiate(self):
         with self.assertRaises(TypeError):
             Any()
@@ -1770,6 +1791,26 @@ def test_union_union(self):
         v = Union[u, Employee]
         self.assertEqual(v, Union[int, float, Employee])
 
+    def test_union_of_unhashable(self):
+        class UnhashableMeta(type):
+            __hash__ = None
+
+        class A(metaclass=UnhashableMeta): ...
+        class B(metaclass=UnhashableMeta): ...
+
+        self.assertEqual(Union[A, B].__args__, (A, B))
+        union1 = Union[A, B]
+        with self.assertRaises(TypeError):
+            hash(union1)
+
+        union2 = Union[int, B]
+        with self.assertRaises(TypeError):
+            hash(union2)
+
+        union3 = Union[A, int]
+        with self.assertRaises(TypeError):
+            hash(union3)
+
     def test_repr(self):
         self.assertEqual(repr(Union), 'typing.Union')
         u = Union[Employee, int]
@@ -4181,6 +4222,16 @@ class C(B[int]):
         c.bar = 'abc'
         self.assertEqual(c.__dict__, {'bar': 'abc'})
 
+    def test_setattr_exceptions(self):
+        class Immutable[T]:
+            def __setattr__(self, key, value):
+                raise RuntimeError("immutable")
+
+        # gh-115165: This used to cause RuntimeError to be raised
+        # when we tried to set `__orig_class__` on the `Immutable` instance
+        # returned by the `Immutable[int]()` call
+        self.assertIsInstance(Immutable[int](), Immutable)
+
     def test_subscripted_generics_as_proxies(self):
         T = TypeVar('T')
         class C(Generic[T]):
@@ -5285,10 +5336,8 @@ def some(self):
         self.assertFalse(hasattr(WithOverride.some, "__override__"))
 
     def test_multiple_decorators(self):
-        import functools
-
         def with_wraps(f):  # similar to `lru_cache` definition
-            @functools.wraps(f)
+            @wraps(f)
             def wrapper(*args, **kwargs):
                 return f(*args, **kwargs)
             return wrapper
@@ -5626,6 +5675,12 @@ def foo(a: 'Node[T'):
         with self.assertRaises(SyntaxError):
             get_type_hints(foo)
 
+    def test_syntax_error_empty_string(self):
+        for form in [typing.List, typing.Set, typing.Type, typing.Deque]:
+            with self.subTest(form=form):
+                with self.assertRaises(SyntaxError):
+                    form['']
+
     def test_name_error(self):
 
         def foo(a: 'Noode[T]'):
@@ -8113,6 +8168,17 @@ def test_re_submodule(self):
             self.assertEqual(__name__, 'typing.re')
             self.assertEqual(len(w), 1)
 
+    def test_re_submodule_access_basics(self):
+        with warnings.catch_warnings():
+            warnings.filterwarnings("error", category=DeprecationWarning)
+            from typing import re
+            self.assertIsInstance(re.__doc__, str)
+            self.assertEqual(re.__name__, "typing.re")
+            self.assertIsInstance(re.__dict__, types.MappingProxyType)
+
+        with self.assertWarns(DeprecationWarning):
+            re.Match
+
     def test_cannot_subclass(self):
         with self.assertRaisesRegex(
             TypeError,
@@ -8162,6 +8228,76 @@ def test_flatten(self):
         self.assertEqual(A.__metadata__, (4, 5))
         self.assertEqual(A.__origin__, int)
 
+    def test_deduplicate_from_union(self):
+        # Regular:
+        self.assertEqual(get_args(Annotated[int, 1] | int),
+                         (Annotated[int, 1], int))
+        self.assertEqual(get_args(Union[Annotated[int, 1], int]),
+                         (Annotated[int, 1], int))
+        self.assertEqual(get_args(Annotated[int, 1] | Annotated[int, 2] | int),
+                         (Annotated[int, 1], Annotated[int, 2], int))
+        self.assertEqual(get_args(Union[Annotated[int, 1], Annotated[int, 2], int]),
+                         (Annotated[int, 1], Annotated[int, 2], int))
+        self.assertEqual(get_args(Annotated[int, 1] | Annotated[str, 1] | int),
+                         (Annotated[int, 1], Annotated[str, 1], int))
+        self.assertEqual(get_args(Union[Annotated[int, 1], Annotated[str, 1], int]),
+                         (Annotated[int, 1], Annotated[str, 1], int))
+
+        # Duplicates:
+        self.assertEqual(Annotated[int, 1] | Annotated[int, 1] | int,
+                         Annotated[int, 1] | int)
+        self.assertEqual(Union[Annotated[int, 1], Annotated[int, 1], int],
+                         Union[Annotated[int, 1], int])
+
+        # Unhashable metadata:
+        self.assertEqual(get_args(str | Annotated[int, {}] | Annotated[int, set()] | int),
+                         (str, Annotated[int, {}], Annotated[int, set()], int))
+        self.assertEqual(get_args(Union[str, Annotated[int, {}], Annotated[int, set()], int]),
+                         (str, Annotated[int, {}], Annotated[int, set()], int))
+        self.assertEqual(get_args(str | Annotated[int, {}] | Annotated[str, {}] | int),
+                         (str, Annotated[int, {}], Annotated[str, {}], int))
+        self.assertEqual(get_args(Union[str, Annotated[int, {}], Annotated[str, {}], int]),
+                         (str, Annotated[int, {}], Annotated[str, {}], int))
+
+        self.assertEqual(get_args(Annotated[int, 1] | str | Annotated[str, {}] | int),
+                         (Annotated[int, 1], str, Annotated[str, {}], int))
+        self.assertEqual(get_args(Union[Annotated[int, 1], str, Annotated[str, {}], int]),
+                         (Annotated[int, 1], str, Annotated[str, {}], int))
+
+        import dataclasses
+        @dataclasses.dataclass
+        class ValueRange:
+            lo: int
+            hi: int
+        v = ValueRange(1, 2)
+        self.assertEqual(get_args(Annotated[int, v] | None),
+                         (Annotated[int, v], types.NoneType))
+        self.assertEqual(get_args(Union[Annotated[int, v], None]),
+                         (Annotated[int, v], types.NoneType))
+        self.assertEqual(get_args(Optional[Annotated[int, v]]),
+                         (Annotated[int, v], types.NoneType))
+
+        # Unhashable metadata duplicated:
+        self.assertEqual(Annotated[int, {}] | Annotated[int, {}] | int,
+                         Annotated[int, {}] | int)
+        self.assertEqual(Annotated[int, {}] | Annotated[int, {}] | int,
+                         int | Annotated[int, {}])
+        self.assertEqual(Union[Annotated[int, {}], Annotated[int, {}], int],
+                         Union[Annotated[int, {}], int])
+        self.assertEqual(Union[Annotated[int, {}], Annotated[int, {}], int],
+                         Union[int, Annotated[int, {}]])
+
+    def test_order_in_union(self):
+        expr1 = Annotated[int, 1] | str | Annotated[str, {}] | int
+        for args in itertools.permutations(get_args(expr1)):
+            with self.subTest(args=args):
+                self.assertEqual(expr1, reduce(operator.or_, args))
+
+        expr2 = Union[Annotated[int, 1], str, Annotated[str, {}], int]
+        for args in itertools.permutations(get_args(expr2)):
+            with self.subTest(args=args):
+                self.assertEqual(expr2, Union[args])
+
     def test_specialize(self):
         L = Annotated[List[T], "my decoration"]
         LI = Annotated[List[int], "my decoration"]
@@ -8182,6 +8318,16 @@ def test_hash_eq(self):
             {Annotated[int, 4, 5], Annotated[int, 4, 5], Annotated[T, 4, 5]},
             {Annotated[int, 4, 5], Annotated[T, 4, 5]}
         )
+        # Unhashable `metadata` raises `TypeError`:
+        a1 = Annotated[int, []]
+        with self.assertRaises(TypeError):
+            hash(a1)
+
+        class A:
+            __hash__ = None
+        a2 = Annotated[int, A()]
+        with self.assertRaises(TypeError):
+            hash(a2)
 
     def test_instantiate(self):
         class C:
@@ -8207,6 +8353,17 @@ def test_instantiate_generic(self):
         self.assertEqual(MyCount([4, 4, 5]), {4: 2, 5: 1})
         self.assertEqual(MyCount[int]([4, 4, 5]), {4: 2, 5: 1})
 
+    def test_instantiate_immutable(self):
+        class C:
+            def __setattr__(self, key, value):
+                raise Exception("should be ignored")
+
+        A = Annotated[C, "a decoration"]
+        # gh-115165: This used to cause RuntimeError to be raised
+        # when we tried to set `__orig_class__` on the `C` instance
+        # returned by the `A()` call
+        self.assertIsInstance(A(), C)
+
     def test_cannot_instantiate_forward(self):
         A = Annotated["int", (5, 6)]
         with self.assertRaises(TypeError):
diff --git a/Lib/test/test_unittest/testmock/testmock.py b/Lib/test/test_unittest/testmock/testmock.py
index 34d76ba0ad..3fb4f1f866 100644
--- a/Lib/test/test_unittest/testmock/testmock.py
+++ b/Lib/test/test_unittest/testmock/testmock.py
@@ -234,6 +234,64 @@ class B(object):
             with mock.patch('builtins.open', mock.mock_open()):
                 mock.mock_open()  # should still be valid with open() mocked
 
+    def test_create_autospec_wraps_class(self):
+        """Autospec a class with wraps & test if the call is passed to the
+        wrapped object."""
+        result = "real result"
+
+        class Result:
+            def get_result(self):
+                return result
+        class_mock = create_autospec(spec=Result, wraps=Result)
+        # Have to reassign the return_value to DEFAULT to return the real
+        # result (actual instance of "Result") when the mock is called.
+        class_mock.return_value = mock.DEFAULT
+        self.assertEqual(class_mock().get_result(), result)
+        # Autospec should also wrap child attributes of parent.
+        self.assertEqual(class_mock.get_result._mock_wraps, Result.get_result)
+
+    def test_create_autospec_instance_wraps_class(self):
+        """Autospec a class instance with wraps & test if the call is passed
+        to the wrapped object."""
+        result = "real result"
+
+        class Result:
+            @staticmethod
+            def get_result():
+                """This is a static method because when the mocked instance of
+                'Result' will call this method, it won't be able to consume
+                'self' argument."""
+                return result
+        instance_mock = create_autospec(spec=Result, instance=True, wraps=Result)
+        # Have to reassign the return_value to DEFAULT to return the real
+        # result from "Result.get_result" when the mocked instance of "Result"
+        # calls "get_result".
+        instance_mock.get_result.return_value = mock.DEFAULT
+        self.assertEqual(instance_mock.get_result(), result)
+        # Autospec should also wrap child attributes of the instance.
+        self.assertEqual(instance_mock.get_result._mock_wraps, Result.get_result)
+
+    def test_create_autospec_wraps_function_type(self):
+        """Autospec a function or a method with wraps & test if the call is
+        passed to the wrapped object."""
+        result = "real result"
+
+        class Result:
+            def get_result(self):
+                return result
+        func_mock = create_autospec(spec=Result.get_result, wraps=Result.get_result)
+        self.assertEqual(func_mock(Result()), result)
+
+    def test_explicit_return_value_even_if_mock_wraps_object(self):
+        """If the mock has an explicit return_value set then calls are not
+        passed to the wrapped object and the return_value is returned instead.
+        """
+        def my_func():
+            return None
+        func_mock = create_autospec(spec=my_func, wraps=my_func)
+        return_value = "explicit return value"
+        func_mock.return_value = return_value
+        self.assertEqual(func_mock(), return_value)
 
     def test_reset_mock(self):
         parent = Mock()
@@ -603,6 +661,14 @@ def test_wraps_calls(self):
         real = Mock()
 
         mock = Mock(wraps=real)
+        # If "Mock" wraps an object, just accessing its
+        # "return_value" ("NonCallableMock.__get_return_value") should not
+        # trigger its descriptor ("NonCallableMock.__set_return_value") so
+        # the default "return_value" should always be "sentinel.DEFAULT".
+        self.assertEqual(mock.return_value, DEFAULT)
+        # It will not be "sentinel.DEFAULT" if the mock is not wrapping any
+        # object.
+        self.assertNotEqual(real.return_value, DEFAULT)
         self.assertEqual(mock(), real())
 
         real.reset_mock()
diff --git a/Lib/test/test_unittest/testmock/testpatch.py b/Lib/test/test_unittest/testmock/testpatch.py
index 833d7da1f3..d0046d702a 100644
--- a/Lib/test/test_unittest/testmock/testpatch.py
+++ b/Lib/test/test_unittest/testmock/testpatch.py
@@ -1912,7 +1912,7 @@ def foo(x=0):
 
         with patch.object(foo, '__module__', "testpatch2"):
             self.assertEqual(foo.__module__, "testpatch2")
-        self.assertEqual(foo.__module__, 'test.test_unittest.testmock.testpatch')
+        self.assertEqual(foo.__module__, __name__)
 
         with patch.object(foo, '__annotations__', dict([('s', 1, )])):
             self.assertEqual(foo.__annotations__, dict([('s', 1, )]))
diff --git a/Lib/test/test_unparse.py b/Lib/test/test_unparse.py
index 6f698a8d89..106704ba8c 100644
--- a/Lib/test/test_unparse.py
+++ b/Lib/test/test_unparse.py
@@ -649,6 +649,30 @@ def test_multiquote_joined_string(self):
         self.check_ast_roundtrip("""f'''""\"''\\'{"\\n\\"'"}''' """)
         self.check_ast_roundtrip("""f'''""\"''\\'{""\"\\n\\"'''""\" '''\\n'''}''' """)
 
+    def test_backslash_in_format_spec(self):
+        import re
+        msg = re.escape("invalid escape sequence '\\ '")
+        with self.assertWarnsRegex(SyntaxWarning, msg):
+            self.check_ast_roundtrip("""f"{x:\\ }" """)
+        self.check_ast_roundtrip("""f"{x:\\n}" """)
+
+        self.check_ast_roundtrip("""f"{x:\\\\ }" """)
+
+        with self.assertWarnsRegex(SyntaxWarning, msg):
+            self.check_ast_roundtrip("""f"{x:\\\\\\ }" """)
+        self.check_ast_roundtrip("""f"{x:\\\\\\n}" """)
+
+        self.check_ast_roundtrip("""f"{x:\\\\\\\\ }" """)
+
+    def test_quote_in_format_spec(self):
+        self.check_ast_roundtrip("""f"{x:'}" """)
+        self.check_ast_roundtrip("""f"{x:\\'}" """)
+        self.check_ast_roundtrip("""f"{x:\\\\'}" """)
+
+        self.check_ast_roundtrip("""f'\\'{x:"}' """)
+        self.check_ast_roundtrip("""f'\\'{x:\\"}' """)
+        self.check_ast_roundtrip("""f'\\'{x:\\\\"}' """)
+
 
 class ManualASTCreationTestCase(unittest.TestCase):
     """Test that AST nodes created without a type_params field unparse correctly."""
diff --git a/Lib/test/test_urllib2.py b/Lib/test/test_urllib2.py
index 99c9e24994..69cf1dc7ae 100644
--- a/Lib/test/test_urllib2.py
+++ b/Lib/test/test_urllib2.py
@@ -14,10 +14,11 @@
 import subprocess
 
 import urllib.request
-# The proxy bypass method imported below has logic specific to the OSX
-# proxy config data structure but is testable on all platforms.
+# The proxy bypass method imported below has logic specific to the
+# corresponding system but is testable on all platforms.
 from urllib.request import (Request, OpenerDirector, HTTPBasicAuthHandler,
                             HTTPPasswordMgrWithPriorAuth, _parse_proxy,
+                            _proxy_bypass_winreg_override,
                             _proxy_bypass_macosx_sysconf,
                             AbstractDigestAuthHandler)
 from urllib.parse import urlparse
@@ -775,7 +776,7 @@ def connect_ftp(self, user, passwd, host, port, dirs,
              ["foo", "bar"], "", None),
             ("ftp://localhost/baz.gif;type=a",
              "localhost", ftplib.FTP_PORT, "", "", "A",
-             [], "baz.gif", None),  # XXX really this should guess image/gif
+             [], "baz.gif", "image/gif"),
             ]:
             req = Request(url)
             req.timeout = None
@@ -1483,6 +1484,30 @@ def test_proxy_https_proxy_authorization(self):
         self.assertEqual(req.host, "proxy.example.com:3128")
         self.assertEqual(req.get_header("Proxy-authorization"), "FooBar")
 
+    @unittest.skipUnless(os.name == "nt", "only relevant for Windows")
+    def test_winreg_proxy_bypass(self):
+        proxy_override = "www.example.com;*.example.net; 192.168.0.1"
+        proxy_bypass = _proxy_bypass_winreg_override
+        for host in ("www.example.com", "www.example.net", "192.168.0.1"):
+            self.assertTrue(proxy_bypass(host, proxy_override),
+                            "expected bypass of %s to be true" % host)
+
+        for host in ("example.com", "www.example.org", "example.net",
+                     "192.168.0.2"):
+            self.assertFalse(proxy_bypass(host, proxy_override),
+                             "expected bypass of %s to be False" % host)
+
+        # check intranet address bypass
+        proxy_override = "example.com; <local>"
+        self.assertTrue(proxy_bypass("example.com", proxy_override),
+                        "expected bypass of %s to be true" % host)
+        self.assertFalse(proxy_bypass("example.net", proxy_override),
+                         "expected bypass of %s to be False" % host)
+        for host in ("test", "localhost"):
+            self.assertTrue(proxy_bypass(host, proxy_override),
+                            "expect <local> to bypass intranet address '%s'"
+                            % host)
+
     @unittest.skipUnless(sys.platform == 'darwin', "only relevant for OSX")
     def test_osx_proxy_bypass(self):
         bypass = {
diff --git a/Lib/test/test_urlparse.py b/Lib/test/test_urlparse.py
index 625c6dc887..236b6e4516 100644
--- a/Lib/test/test_urlparse.py
+++ b/Lib/test/test_urlparse.py
@@ -19,6 +19,10 @@
     ("=a", [('', 'a')]),
     ("a", [('a', '')]),
     ("a=", [('a', '')]),
+    ("a=b=c", [('a', 'b=c')]),
+    ("a%3Db=c", [('a=b', 'c')]),
+    ("a=b&c=d", [('a', 'b'), ('c', 'd')]),
+    ("a=b%26c=d", [('a', 'b&c=d')]),
     ("&a=b", [('a', 'b')]),
     ("a=a+b&b=b+c", [('a', 'a b'), ('b', 'b c')]),
     ("a=1&a=2", [('a', '1'), ('a', '2')]),
@@ -29,6 +33,10 @@
     (b"=a", [(b'', b'a')]),
     (b"a", [(b'a', b'')]),
     (b"a=", [(b'a', b'')]),
+    (b"a=b=c", [(b'a', b'b=c')]),
+    (b"a%3Db=c", [(b'a=b', b'c')]),
+    (b"a=b&c=d", [(b'a', b'b'), (b'c', b'd')]),
+    (b"a=b%26c=d", [(b'a', b'b&c=d')]),
     (b"&a=b", [(b'a', b'b')]),
     (b"a=a+b&b=b+c", [(b'a', b'a b'), (b'b', b'b c')]),
     (b"a=1&a=2", [(b'a', b'1'), (b'a', b'2')]),
@@ -36,6 +44,14 @@
     ("a=a+b;b=b+c", [('a', 'a b;b=b c')]),
     (b";a=b", [(b';a', b'b')]),
     (b"a=a+b;b=b+c", [(b'a', b'a b;b=b c')]),
+
+    ("\u0141=\xE9", [('\u0141', '\xE9')]),
+    ("%C5%81=%C3%A9", [('\u0141', '\xE9')]),
+    ("%81=%A9", [('\ufffd', '\ufffd')]),
+    (b"\xc5\x81=\xc3\xa9", [(b'\xc5\x81', b'\xc3\xa9')]),
+    (b"%C5%81=%C3%A9", [(b'\xc5\x81', b'\xc3\xa9')]),
+    (b"\x81=\xA9", [(b'\x81', b'\xa9')]),
+    (b"%81=%A9", [(b'\x81', b'\xa9')]),
 ]
 
 # Each parse_qs testcase is a two-tuple that contains
@@ -49,6 +65,10 @@
     ("=a", {'': ['a']}),
     ("a", {'a': ['']}),
     ("a=", {'a': ['']}),
+    ("a=b=c", {'a': ['b=c']}),
+    ("a%3Db=c", {'a=b': ['c']}),
+    ("a=b&c=d", {'a': ['b'], 'c': ['d']}),
+    ("a=b%26c=d", {'a': ['b&c=d']}),
     ("&a=b", {'a': ['b']}),
     ("a=a+b&b=b+c", {'a': ['a b'], 'b': ['b c']}),
     ("a=1&a=2", {'a': ['1', '2']}),
@@ -59,6 +79,10 @@
     (b"=a", {b'': [b'a']}),
     (b"a", {b'a': [b'']}),
     (b"a=", {b'a': [b'']}),
+    (b"a=b=c", {b'a': [b'b=c']}),
+    (b"a%3Db=c", {b'a=b': [b'c']}),
+    (b"a=b&c=d", {b'a': [b'b'], b'c': [b'd']}),
+    (b"a=b%26c=d", {b'a': [b'b&c=d']}),
     (b"&a=b", {b'a': [b'b']}),
     (b"a=a+b&b=b+c", {b'a': [b'a b'], b'b': [b'b c']}),
     (b"a=1&a=2", {b'a': [b'1', b'2']}),
@@ -66,6 +90,15 @@
     ("a=a+b;b=b+c", {'a': ['a b;b=b c']}),
     (b";a=b", {b';a': [b'b']}),
     (b"a=a+b;b=b+c", {b'a':[ b'a b;b=b c']}),
+    (b"a=a%E2%80%99b", {b'a': [b'a\xe2\x80\x99b']}),
+
+    ("\u0141=\xE9", {'\u0141': ['\xE9']}),
+    ("%C5%81=%C3%A9", {'\u0141': ['\xE9']}),
+    ("%81=%A9", {'\ufffd': ['\ufffd']}),
+    (b"\xc5\x81=\xc3\xa9", {b'\xc5\x81': [b'\xc3\xa9']}),
+    (b"%C5%81=%C3%A9", {b'\xc5\x81': [b'\xc3\xa9']}),
+    (b"\x81=\xA9", {b'\x81': [b'\xa9']}),
+    (b"%81=%A9", {b'\x81': [b'\xa9']}),
 ]
 
 class UrlParseTestCase(unittest.TestCase):
@@ -995,8 +1028,8 @@ def test_parse_qsl_encoding(self):
 
     def test_parse_qsl_max_num_fields(self):
         with self.assertRaises(ValueError):
-            urllib.parse.parse_qs('&'.join(['a=a']*11), max_num_fields=10)
-        urllib.parse.parse_qs('&'.join(['a=a']*10), max_num_fields=10)
+            urllib.parse.parse_qsl('&'.join(['a=a']*11), max_num_fields=10)
+        urllib.parse.parse_qsl('&'.join(['a=a']*10), max_num_fields=10)
 
     def test_parse_qs_separator(self):
         parse_qs_semicolon_cases = [
@@ -1039,6 +1072,30 @@ def test_parse_qsl_separator(self):
                 result_bytes = urllib.parse.parse_qsl(orig, separator=b';')
                 self.assertEqual(result_bytes, expect, "Error parsing %r" % orig)
 
+    def test_parse_qsl_bytes(self):
+        self.assertEqual(urllib.parse.parse_qsl(b'a=b'), [(b'a', b'b')])
+        self.assertEqual(urllib.parse.parse_qsl(bytearray(b'a=b')), [(b'a', b'b')])
+        self.assertEqual(urllib.parse.parse_qsl(memoryview(b'a=b')), [(b'a', b'b')])
+
+    def test_parse_qsl_false_value(self):
+        kwargs = dict(keep_blank_values=True, strict_parsing=True)
+        for x in '', b'', None, 0, 0.0, [], {}, memoryview(b''):
+            self.assertEqual(urllib.parse.parse_qsl(x, **kwargs), [])
+            self.assertRaises(ValueError, urllib.parse.parse_qsl, x, separator=1)
+
+    def test_parse_qsl_errors(self):
+        self.assertRaises(TypeError, urllib.parse.parse_qsl, list(b'a=b'))
+        self.assertRaises(TypeError, urllib.parse.parse_qsl, iter(b'a=b'))
+        self.assertRaises(TypeError, urllib.parse.parse_qsl, 1)
+        self.assertRaises(TypeError, urllib.parse.parse_qsl, object())
+
+        for separator in '', b'', None, 0, 1, 0.0, 1.5:
+            with self.assertRaises(ValueError):
+                urllib.parse.parse_qsl('a=b', separator=separator)
+        with self.assertRaises(UnicodeEncodeError):
+            urllib.parse.parse_qsl(b'a=b', separator='\xa6')
+        with self.assertRaises(UnicodeDecodeError):
+            urllib.parse.parse_qsl('a=b', separator=b'\xa6')
 
     def test_urlencode_sequences(self):
         # Other tests incidentally urlencode things; test non-covered cases:
diff --git a/Lib/test/test_venv.py b/Lib/test/test_venv.py
index fea16568af..7540be2c10 100644
--- a/Lib/test/test_venv.py
+++ b/Lib/test/test_venv.py
@@ -494,7 +494,7 @@ def test_multiprocessing_recursion(self):
         envpy = os.path.join(os.path.realpath(self.env_dir),
                              self.bindir, self.exe)
         script = os.path.join(TEST_HOME_DIR, '_test_venv_multiprocessing.py')
-        subprocess.check_call([envpy, script])
+        subprocess.check_call([envpy, "-I", script])
 
     @unittest.skipIf(os.name == 'nt', 'not relevant on Windows')
     def test_deactivate_with_strict_bash_opts(self):
diff --git a/Lib/test/test_xml_etree.py b/Lib/test/test_xml_etree.py
index b50898f1d1..9c382d14f5 100644
--- a/Lib/test/test_xml_etree.py
+++ b/Lib/test/test_xml_etree.py
@@ -13,6 +13,7 @@
 import operator
 import os
 import pickle
+import pyexpat
 import sys
 import textwrap
 import types
@@ -1377,12 +1378,14 @@ def test_attlist_default(self):
 
 class XMLPullParserTest(unittest.TestCase):
 
-    def _feed(self, parser, data, chunk_size=None):
+    def _feed(self, parser, data, chunk_size=None, flush=False):
         if chunk_size is None:
             parser.feed(data)
         else:
             for i in range(0, len(data), chunk_size):
                 parser.feed(data[i:i+chunk_size])
+        if flush:
+            parser.flush()
 
     def assert_events(self, parser, expected, max_events=None):
         self.assertEqual(
@@ -1400,28 +1403,35 @@ def assert_event_tags(self, parser, expected, max_events=None):
         self.assertEqual([(action, elem.tag) for action, elem in events],
                          expected)
 
-    def test_simple_xml(self):
-        for chunk_size in (None, 1, 5):
-            with self.subTest(chunk_size=chunk_size):
-                parser = ET.XMLPullParser()
-                self.assert_event_tags(parser, [])
-                self._feed(parser, "<!-- comment -->\n", chunk_size)
-                self.assert_event_tags(parser, [])
-                self._feed(parser,
-                           "<root>\n  <element key='value'>text</element",
-                           chunk_size)
-                self.assert_event_tags(parser, [])
-                self._feed(parser, ">\n", chunk_size)
-                self.assert_event_tags(parser, [('end', 'element')])
-                self._feed(parser, "<element>text</element>tail\n", chunk_size)
-                self._feed(parser, "<empty-element/>\n", chunk_size)
-                self.assert_event_tags(parser, [
-                    ('end', 'element'),
-                    ('end', 'empty-element'),
-                    ])
-                self._feed(parser, "</root>\n", chunk_size)
-                self.assert_event_tags(parser, [('end', 'root')])
-                self.assertIsNone(parser.close())
+    def test_simple_xml(self, chunk_size=None, flush=False):
+        parser = ET.XMLPullParser()
+        self.assert_event_tags(parser, [])
+        self._feed(parser, "<!-- comment -->\n", chunk_size, flush)
+        self.assert_event_tags(parser, [])
+        self._feed(parser,
+                   "<root>\n  <element key='value'>text</element",
+                   chunk_size, flush)
+        self.assert_event_tags(parser, [])
+        self._feed(parser, ">\n", chunk_size, flush)
+        self.assert_event_tags(parser, [('end', 'element')])
+        self._feed(parser, "<element>text</element>tail\n", chunk_size, flush)
+        self._feed(parser, "<empty-element/>\n", chunk_size, flush)
+        self.assert_event_tags(parser, [
+            ('end', 'element'),
+            ('end', 'empty-element'),
+            ])
+        self._feed(parser, "</root>\n", chunk_size, flush)
+        self.assert_event_tags(parser, [('end', 'root')])
+        self.assertIsNone(parser.close())
+
+    def test_simple_xml_chunk_1(self):
+        self.test_simple_xml(chunk_size=1, flush=True)
+
+    def test_simple_xml_chunk_5(self):
+        self.test_simple_xml(chunk_size=5, flush=True)
+
+    def test_simple_xml_chunk_22(self):
+        self.test_simple_xml(chunk_size=22)
 
     def test_feed_while_iterating(self):
         parser = ET.XMLPullParser()
@@ -1617,6 +1627,56 @@ def test_unknown_event(self):
         with self.assertRaises(ValueError):
             ET.XMLPullParser(events=('start', 'end', 'bogus'))
 
+    @unittest.skipIf(pyexpat.version_info < (2, 6, 0),
+                     f'Expat {pyexpat.version_info} does not '
+                     'support reparse deferral')
+    def test_flush_reparse_deferral_enabled(self):
+        parser = ET.XMLPullParser(events=('start', 'end'))
+
+        for chunk in ("<doc", ">"):
+            parser.feed(chunk)
+
+        self.assert_event_tags(parser, [])  # i.e. no elements started
+        if ET is pyET:
+            self.assertTrue(parser._parser._parser.GetReparseDeferralEnabled())
+
+        parser.flush()
+
+        self.assert_event_tags(parser, [('start', 'doc')])
+        if ET is pyET:
+            self.assertTrue(parser._parser._parser.GetReparseDeferralEnabled())
+
+        parser.feed("</doc>")
+        parser.close()
+
+        self.assert_event_tags(parser, [('end', 'doc')])
+
+    def test_flush_reparse_deferral_disabled(self):
+        parser = ET.XMLPullParser(events=('start', 'end'))
+
+        for chunk in ("<doc", ">"):
+            parser.feed(chunk)
+
+        if pyexpat.version_info >= (2, 6, 0):
+            if not ET is pyET:
+                self.skipTest(f'XMLParser.(Get|Set)ReparseDeferralEnabled '
+                              'methods not available in C')
+            parser._parser._parser.SetReparseDeferralEnabled(False)
+            self.assert_event_tags(parser, [])  # i.e. no elements started
+
+        if ET is pyET:
+            self.assertFalse(parser._parser._parser.GetReparseDeferralEnabled())
+
+        parser.flush()
+
+        self.assert_event_tags(parser, [('start', 'doc')])
+        if ET is pyET:
+            self.assertFalse(parser._parser._parser.GetReparseDeferralEnabled())
+
+        parser.feed("</doc>")
+        parser.close()
+
+        self.assert_event_tags(parser, [('end', 'doc')])
 
 #
 # xinclude tests (samples from appendix C of the xinclude specification)
diff --git a/Lib/test/test_zipfile/_path/test_path.py b/Lib/test/test_zipfile/_path/test_path.py
index 171ab6fdb5..c66cb3cba6 100644
--- a/Lib/test/test_zipfile/_path/test_path.py
+++ b/Lib/test/test_zipfile/_path/test_path.py
@@ -577,15 +577,3 @@ def test_getinfo_missing(self, alpharep):
         zipfile.Path(alpharep)
         with self.assertRaises(KeyError):
             alpharep.getinfo('does-not-exist')
-
-    def test_root_folder_in_zipfile(self):
-        """
-        gh-112795: Some tools or self constructed codes will add '/' folder to
-        the zip file, this is a strange behavior, but we should support it.
-        """
-        in_memory_file = io.BytesIO()
-        zf = zipfile.ZipFile(in_memory_file, "w")
-        zf.mkdir('/')
-        zf.writestr('./a.txt', 'aaa')
-        tmpdir = pathlib.Path(self.fixtures.enter_context(temp_dir()))
-        zf.extractall(tmpdir)
diff --git a/Lib/test/test_zipfile/test_core.py b/Lib/test/test_zipfile/test_core.py
index ecc3dd6d0b..5b32f80d80 100644
--- a/Lib/test/test_zipfile/test_core.py
+++ b/Lib/test/test_zipfile/test_core.py
@@ -4,7 +4,6 @@
 import io
 import itertools
 import os
-import pathlib
 import posixpath
 import struct
 import subprocess
@@ -25,7 +24,7 @@
     captured_stdout, captured_stderr, requires_subprocess
 )
 from test.support.os_helper import (
-    TESTFN, unlink, rmtree, temp_dir, temp_cwd, fd_count
+    TESTFN, unlink, rmtree, temp_dir, temp_cwd, fd_count, FakePath
 )
 
 
@@ -160,7 +159,7 @@ def test_open(self):
             self.zip_open_test(f, self.compression)
 
     def test_open_with_pathlike(self):
-        path = pathlib.Path(TESTFN2)
+        path = FakePath(TESTFN2)
         self.zip_open_test(path, self.compression)
         with zipfile.ZipFile(path, "r", self.compression) as zipfp:
             self.assertIsInstance(zipfp.filename, str)
@@ -447,6 +446,27 @@ def write(self, data):
             self.assertEqual(zipfp.read('file1'), b'data1')
             self.assertEqual(zipfp.read('file2'), b'data2')
 
+    def test_zipextfile_attrs(self):
+        fname = "somefile.txt"
+        with zipfile.ZipFile(TESTFN2, mode="w") as zipfp:
+            zipfp.writestr(fname, "bogus")
+
+        with zipfile.ZipFile(TESTFN2, mode="r") as zipfp:
+            with zipfp.open(fname) as fid:
+                self.assertEqual(fid.name, fname)
+                self.assertRaises(io.UnsupportedOperation, fid.fileno)
+                self.assertEqual(fid.mode, 'r')
+                self.assertIs(fid.readable(), True)
+                self.assertIs(fid.writable(), False)
+                self.assertIs(fid.seekable(), True)
+                self.assertIs(fid.closed, False)
+            self.assertIs(fid.closed, True)
+            self.assertEqual(fid.name, fname)
+            self.assertEqual(fid.mode, 'r')
+            self.assertRaises(io.UnsupportedOperation, fid.fileno)
+            self.assertRaises(ValueError, fid.readable)
+            self.assertIs(fid.writable(), False)
+            self.assertRaises(ValueError, fid.seekable)
 
     def tearDown(self):
         unlink(TESTFN)
@@ -578,17 +598,16 @@ def test_write_default_name(self):
 
     def test_io_on_closed_zipextfile(self):
         fname = "somefile.txt"
-        with zipfile.ZipFile(TESTFN2, mode="w") as zipfp:
+        with zipfile.ZipFile(TESTFN2, mode="w", compression=self.compression) as zipfp:
             zipfp.writestr(fname, "bogus")
 
         with zipfile.ZipFile(TESTFN2, mode="r") as zipfp:
             with zipfp.open(fname) as fid:
                 fid.close()
+                self.assertIs(fid.closed, True)
                 self.assertRaises(ValueError, fid.read)
                 self.assertRaises(ValueError, fid.seek, 0)
                 self.assertRaises(ValueError, fid.tell)
-                self.assertRaises(ValueError, fid.readable)
-                self.assertRaises(ValueError, fid.seekable)
 
     def test_write_to_readonly(self):
         """Check that trying to call write() on a readonly ZipFile object
@@ -1285,6 +1304,21 @@ def test_issue44439(self):
                 self.assertEqual(data.write(q), LENGTH)
             self.assertEqual(zip.getinfo('data').file_size, LENGTH)
 
+    def test_zipwritefile_attrs(self):
+        fname = "somefile.txt"
+        with zipfile.ZipFile(TESTFN2, mode="w", compression=self.compression) as zipfp:
+            with zipfp.open(fname, 'w') as fid:
+                self.assertRaises(io.UnsupportedOperation, fid.fileno)
+                self.assertIs(fid.readable(), False)
+                self.assertIs(fid.writable(), True)
+                self.assertIs(fid.seekable(), False)
+                self.assertIs(fid.closed, False)
+            self.assertIs(fid.closed, True)
+            self.assertRaises(io.UnsupportedOperation, fid.fileno)
+            self.assertIs(fid.readable(), False)
+            self.assertIs(fid.writable(), True)
+            self.assertIs(fid.seekable(), False)
+
 class StoredWriterTests(AbstractWriterTests, unittest.TestCase):
     compression = zipfile.ZIP_STORED
 
@@ -1487,7 +1521,7 @@ def test_write_pathlike(self):
                 fp.write("print(42)\n")
 
             with TemporaryFile() as t, zipfile.PyZipFile(t, "w") as zipfp:
-                zipfp.writepy(pathlib.Path(TESTFN2) / "mod1.py")
+                zipfp.writepy(FakePath(os.path.join(TESTFN2, "mod1.py")))
                 names = zipfp.namelist()
                 self.assertCompiledIn('mod1.py', names)
         finally:
@@ -1545,7 +1579,7 @@ def test_extract_with_target(self):
 
     def test_extract_with_target_pathlike(self):
         with temp_dir() as extdir:
-            self._test_extract_with_target(pathlib.Path(extdir))
+            self._test_extract_with_target(FakePath(extdir))
 
     def test_extract_all(self):
         with temp_cwd():
@@ -1580,7 +1614,7 @@ def test_extract_all_with_target(self):
 
     def test_extract_all_with_target_pathlike(self):
         with temp_dir() as extdir:
-            self._test_extract_all_with_target(pathlib.Path(extdir))
+            self._test_extract_all_with_target(FakePath(extdir))
 
     def check_file(self, filename, content):
         self.assertTrue(os.path.isfile(filename))
@@ -1893,7 +1927,7 @@ def test_is_zip_erroneous_file(self):
             fp.write("this is not a legal zip file\n")
         self.assertFalse(zipfile.is_zipfile(TESTFN))
         # - passing a path-like object
-        self.assertFalse(zipfile.is_zipfile(pathlib.Path(TESTFN)))
+        self.assertFalse(zipfile.is_zipfile(FakePath(TESTFN)))
         # - passing a file object
         with open(TESTFN, "rb") as fp:
             self.assertFalse(zipfile.is_zipfile(fp))
@@ -2903,6 +2937,22 @@ def test_bug_6050(self):
         os.mkdir(os.path.join(TESTFN2, "a"))
         self.test_extract_dir()
 
+    def test_extract_dir_backslash(self):
+        zfname = findfile("zipdir_backslash.zip")
+        with zipfile.ZipFile(zfname) as zipf:
+            zipf.extractall(TESTFN2)
+        if os.name == 'nt':
+            self.assertTrue(os.path.isdir(os.path.join(TESTFN2, "a")))
+            self.assertTrue(os.path.isdir(os.path.join(TESTFN2, "a", "b")))
+            self.assertTrue(os.path.isfile(os.path.join(TESTFN2, "a", "b", "c")))
+            self.assertTrue(os.path.isdir(os.path.join(TESTFN2, "d")))
+            self.assertTrue(os.path.isdir(os.path.join(TESTFN2, "d", "e")))
+        else:
+            self.assertTrue(os.path.isfile(os.path.join(TESTFN2, "a\\b\\c")))
+            self.assertTrue(os.path.isfile(os.path.join(TESTFN2, "d\\e\\")))
+            self.assertFalse(os.path.exists(os.path.join(TESTFN2, "a")))
+            self.assertFalse(os.path.exists(os.path.join(TESTFN2, "d")))
+
     def test_write_dir(self):
         dirpath = os.path.join(TESTFN2, "x")
         os.mkdir(dirpath)
@@ -2999,6 +3049,17 @@ def test_create_directory_with_write(self):
 
             self.assertEqual(set(os.listdir(target)), {"directory", "directory2"})
 
+    def test_root_folder_in_zipfile(self):
+        """
+        gh-112795: Some tools or self constructed codes will add '/' folder to
+        the zip file, this is a strange behavior, but we should support it.
+        """
+        in_memory_file = io.BytesIO()
+        zf = zipfile.ZipFile(in_memory_file, "w")
+        zf.mkdir('/')
+        zf.writestr('./a.txt', 'aaa')
+        zf.extractall(TESTFN2)
+
     def tearDown(self):
         rmtree(TESTFN2)
         if os.path.exists(TESTFN):
@@ -3013,7 +3074,7 @@ def test_from_file(self):
         self.assertEqual(zi.file_size, os.path.getsize(__file__))
 
     def test_from_file_pathlike(self):
-        zi = zipfile.ZipInfo.from_file(pathlib.Path(__file__))
+        zi = zipfile.ZipInfo.from_file(FakePath(__file__))
         self.assertEqual(posixpath.basename(zi.filename), 'test_core.py')
         self.assertFalse(zi.is_dir())
         self.assertEqual(zi.file_size, os.path.getsize(__file__))
diff --git a/Lib/test/zipdir_backslash.zip b/Lib/test/zipdir_backslash.zip
new file mode 100644
index 0000000000..979126ef5e
Binary files /dev/null and b/Lib/test/zipdir_backslash.zip differ
diff --git a/Lib/tkinter/__init__.py b/Lib/tkinter/__init__.py
index 8b8fdfe3fb..43b0cbec7f 100644
--- a/Lib/tkinter/__init__.py
+++ b/Lib/tkinter/__init__.py
@@ -3074,11 +3074,16 @@ def __init__(self, master=None, cnf={}, **kw):
         Widget.__init__(self, master, 'checkbutton', cnf, kw)
 
     def _setup(self, master, cnf):
+        # Because Checkbutton defaults to a variable with the same name as
+        # the widget, Checkbutton default names must be globally unique,
+        # not just unique within the parent widget.
         if not cnf.get('name'):
             global _checkbutton_count
             name = self.__class__.__name__.lower()
             _checkbutton_count += 1
-            cnf['name'] = f'!{name}{_checkbutton_count}'
+            # To avoid collisions with ttk.Checkbutton, use the different
+            # name template.
+            cnf['name'] = f'!{name}-{_checkbutton_count}'
         super()._setup(master, cnf)
 
     def deselect(self):
diff --git a/Lib/tokenize.py b/Lib/tokenize.py
index 49e8144edd..7af7a5cc1c 100644
--- a/Lib/tokenize.py
+++ b/Lib/tokenize.py
@@ -170,6 +170,7 @@ def __init__(self):
         self.tokens = []
         self.prev_row = 1
         self.prev_col = 0
+        self.prev_type = None
         self.encoding = None
 
     def add_whitespace(self, start):
@@ -185,6 +186,29 @@ def add_whitespace(self, start):
         if col_offset:
             self.tokens.append(" " * col_offset)
 
+    def escape_brackets(self, token):
+        characters = []
+        consume_until_next_bracket = False
+        for character in token:
+            if character == "}":
+                if consume_until_next_bracket:
+                    consume_until_next_bracket = False
+                else:
+                    characters.append(character)
+            if character == "{":
+                n_backslashes = sum(
+                    1 for char in _itertools.takewhile(
+                        "\\".__eq__,
+                        characters[-2::-1]
+                    )
+                )
+                if n_backslashes % 2 == 0:
+                    characters.append(character)
+                else:
+                    consume_until_next_bracket = True
+            characters.append(character)
+        return "".join(characters)
+
     def untokenize(self, iterable):
         it = iter(iterable)
         indents = []
@@ -216,11 +240,13 @@ def untokenize(self, iterable):
                 startline = False
             elif tok_type == FSTRING_MIDDLE:
                 if '{' in token or '}' in token:
+                    token = self.escape_brackets(token)
+                    last_line = token.splitlines()[-1]
                     end_line, end_col = end
-                    end = (end_line, end_col + token.count('{') + token.count('}'))
-                    token = re.sub('{', '{{', token)
-                    token = re.sub('}', '}}', token)
-
+                    extra_chars = last_line.count("{{") + last_line.count("}}")
+                    end = (end_line, end_col + extra_chars)
+            elif tok_type in (STRING, FSTRING_START) and self.prev_type in (STRING, FSTRING_END):
+                self.tokens.append(" ")
 
             self.add_whitespace(start)
             self.tokens.append(token)
@@ -228,6 +254,7 @@ def untokenize(self, iterable):
             if tok_type in (NEWLINE, NL):
                 self.prev_row += 1
                 self.prev_col = 0
+            self.prev_type = tok_type
         return "".join(self.tokens)
 
     def compat(self, token, iterable):
@@ -235,6 +262,7 @@ def compat(self, token, iterable):
         toks_append = self.tokens.append
         startline = token[0] in (NEWLINE, NL)
         prevstring = False
+        in_fstring = 0
 
         for tok in _itertools.chain([token], iterable):
             toknum, tokval = tok[:2]
@@ -253,6 +281,10 @@ def compat(self, token, iterable):
             else:
                 prevstring = False
 
+            if toknum == FSTRING_START:
+                in_fstring += 1
+            elif toknum == FSTRING_END:
+                in_fstring -= 1
             if toknum == INDENT:
                 indents.append(tokval)
                 continue
@@ -265,11 +297,18 @@ def compat(self, token, iterable):
                 toks_append(indents[-1])
                 startline = False
             elif toknum == FSTRING_MIDDLE:
-                if '{' in tokval or '}' in tokval:
-                    tokval = re.sub('{', '{{', tokval)
-                    tokval = re.sub('}', '}}', tokval)
+                tokval = self.escape_brackets(tokval)
+
+            # Insert a space between two consecutive brackets if we are in an f-string
+            if tokval in {"{", "}"} and self.tokens and self.tokens[-1] == tokval and in_fstring:
+                tokval = ' ' + tokval
+
+            # Insert a space between two consecutive f-strings
+            if toknum in (STRING, FSTRING_START) and self.prev_type in (STRING, FSTRING_END):
+                self.tokens.append(" ")
 
             toks_append(tokval)
+            self.prev_type = toknum
 
 
 def untokenize(iterable):
diff --git a/Lib/typing.py b/Lib/typing.py
index ffe7ce8d8a..c9962b9c9b 100644
--- a/Lib/typing.py
+++ b/Lib/typing.py
@@ -314,19 +314,33 @@ def _unpack_args(args):
             newargs.append(arg)
     return newargs
 
-def _deduplicate(params):
+def _deduplicate(params, *, unhashable_fallback=False):
     # Weed out strict duplicates, preserving the first of each occurrence.
-    all_params = set(params)
-    if len(all_params) < len(params):
-        new_params = []
-        for t in params:
-            if t in all_params:
-                new_params.append(t)
-                all_params.remove(t)
-        params = new_params
-        assert not all_params, all_params
-    return params
-
+    try:
+        return dict.fromkeys(params)
+    except TypeError:
+        if not unhashable_fallback:
+            raise
+        # Happens for cases like `Annotated[dict, {'x': IntValidator()}]`
+        return _deduplicate_unhashable(params)
+
+def _deduplicate_unhashable(unhashable_params):
+    new_unhashable = []
+    for t in unhashable_params:
+        if t not in new_unhashable:
+            new_unhashable.append(t)
+    return new_unhashable
+
+def _compare_args_orderless(first_args, second_args):
+    first_unhashable = _deduplicate_unhashable(first_args)
+    second_unhashable = _deduplicate_unhashable(second_args)
+    t = list(second_unhashable)
+    try:
+        for elem in first_unhashable:
+            t.remove(elem)
+    except ValueError:
+        return False
+    return not t
 
 def _remove_dups_flatten(parameters):
     """Internal helper for Union creation and substitution.
@@ -341,7 +355,7 @@ def _remove_dups_flatten(parameters):
         else:
             params.append(p)
 
-    return tuple(_deduplicate(params))
+    return tuple(_deduplicate(params, unhashable_fallback=True))
 
 
 def _flatten_literal_params(parameters):
@@ -530,7 +544,7 @@ class Any(metaclass=_AnyMeta):
     def __new__(cls, *args, **kwargs):
         if cls is Any:
             raise TypeError("Any cannot be instantiated")
-        return super().__new__(cls, *args, **kwargs)
+        return super().__new__(cls)
 
 
 @_SpecialForm
@@ -872,7 +886,7 @@ def __init__(self, arg, is_argument=True, module=None, *, is_class=False):
         # If we do `def f(*args: *Ts)`, then we'll have `arg = '*Ts'`.
         # Unfortunately, this isn't a valid expression on its own, so we
         # do the unpacking manually.
-        if arg[0] == '*':
+        if arg.startswith('*'):
             arg_to_compile = f'({arg},)[0]'  # E.g. (*Ts,)[0] or (*tuple[int, int],)[0]
         else:
             arg_to_compile = arg
@@ -1140,7 +1154,9 @@ def __call__(self, *args, **kwargs):
         result = self.__origin__(*args, **kwargs)
         try:
             result.__orig_class__ = self
-        except AttributeError:
+        # Some objects raise TypeError (or something even more exotic)
+        # if you try to set attributes on them; we guard against that here
+        except Exception:
             pass
         return result
 
@@ -1546,7 +1562,10 @@ def copy_with(self, params):
     def __eq__(self, other):
         if not isinstance(other, (_UnionGenericAlias, types.UnionType)):
             return NotImplemented
-        return set(self.__args__) == set(other.__args__)
+        try:  # fast path
+            return set(self.__args__) == set(other.__args__)
+        except TypeError:  # not hashable, slow path
+            return _compare_args_orderless(self.__args__, other.__args__)
 
     def __hash__(self):
         return hash(frozenset(self.__args__))
@@ -3254,11 +3273,11 @@ def __enter__(self) -> 'TextIO':
 
 class _DeprecatedType(type):
     def __getattribute__(cls, name):
-        if name not in ("__dict__", "__module__") and name in cls.__dict__:
+        if name not in {"__dict__", "__module__", "__doc__"} and name in cls.__dict__:
             warnings.warn(
                 f"{cls.__name__} is deprecated, import directly "
                 f"from typing instead. {cls.__name__} will be removed "
-                "in Python 3.12.",
+                "in Python 3.13.",
                 DeprecationWarning,
                 stacklevel=2,
             )
diff --git a/Lib/unittest/mock.py b/Lib/unittest/mock.py
index a2187580af..0e1b9ace7b 100644
--- a/Lib/unittest/mock.py
+++ b/Lib/unittest/mock.py
@@ -543,7 +543,7 @@ def __get_return_value(self):
         if self._mock_delegate is not None:
             ret = self._mock_delegate.return_value
 
-        if ret is DEFAULT:
+        if ret is DEFAULT and self._mock_wraps is None:
             ret = self._get_child_mock(
                 _new_parent=self, _new_name='()'
             )
@@ -1204,6 +1204,9 @@ def _execute_mock_call(self, /, *args, **kwargs):
         if self._mock_return_value is not DEFAULT:
             return self.return_value
 
+        if self._mock_delegate and self._mock_delegate.return_value is not DEFAULT:
+            return self.return_value
+
         if self._mock_wraps is not None:
             return self._mock_wraps(*args, **kwargs)
 
@@ -2754,9 +2757,12 @@ def create_autospec(spec, spec_set=False, instance=False, _parent=None,
     if _parent is not None and not instance:
         _parent._mock_children[_name] = mock
 
+    wrapped = kwargs.get('wraps')
+
     if is_type and not instance and 'return_value' not in kwargs:
         mock.return_value = create_autospec(spec, spec_set, instance=True,
-                                            _name='()', _parent=mock)
+                                            _name='()', _parent=mock,
+                                            wraps=wrapped)
 
     for entry in dir(spec):
         if _is_magic(entry):
@@ -2778,6 +2784,9 @@ def create_autospec(spec, spec_set=False, instance=False, _parent=None,
             continue
 
         kwargs = {'spec': original}
+        # Wrap child attributes also.
+        if wrapped and hasattr(wrapped, entry):
+            kwargs.update(wraps=original)
         if spec_set:
             kwargs = {'spec_set': original}
 
diff --git a/Lib/urllib/parse.py b/Lib/urllib/parse.py
index c129b0d797..fc9e7c99f2 100644
--- a/Lib/urllib/parse.py
+++ b/Lib/urllib/parse.py
@@ -763,42 +763,48 @@ def parse_qsl(qs, keep_blank_values=False, strict_parsing=False,
 
         Returns a list, as G-d intended.
     """
-    qs, _coerce_result = _coerce_args(qs)
-    separator, _ = _coerce_args(separator)
 
-    if not separator or (not isinstance(separator, (str, bytes))):
+    if not separator or not isinstance(separator, (str, bytes)):
         raise ValueError("Separator must be of type string or bytes.")
+    if isinstance(qs, str):
+        if not isinstance(separator, str):
+            separator = str(separator, 'ascii')
+        eq = '='
+        def _unquote(s):
+            return unquote_plus(s, encoding=encoding, errors=errors)
+    else:
+        if not qs:
+            return []
+        # Use memoryview() to reject integers and iterables,
+        # acceptable by the bytes constructor.
+        qs = bytes(memoryview(qs))
+        if isinstance(separator, str):
+            separator = bytes(separator, 'ascii')
+        eq = b'='
+        def _unquote(s):
+            return unquote_to_bytes(s.replace(b'+', b' '))
+
+    if not qs:
+        return []
 
     # If max_num_fields is defined then check that the number of fields
     # is less than max_num_fields. This prevents a memory exhaustion DOS
     # attack via post bodies with many fields.
     if max_num_fields is not None:
-        num_fields = 1 + qs.count(separator) if qs else 0
+        num_fields = 1 + qs.count(separator)
         if max_num_fields < num_fields:
             raise ValueError('Max number of fields exceeded')
 
     r = []
-    query_args = qs.split(separator) if qs else []
-    for name_value in query_args:
-        if not name_value and not strict_parsing:
-            continue
-        nv = name_value.split('=', 1)
-        if len(nv) != 2:
-            if strict_parsing:
+    for name_value in qs.split(separator):
+        if name_value or strict_parsing:
+            name, has_eq, value = name_value.partition(eq)
+            if not has_eq and strict_parsing:
                 raise ValueError("bad query field: %r" % (name_value,))
-            # Handle case of a control-name with no equal sign
-            if keep_blank_values:
-                nv.append('')
-            else:
-                continue
-        if len(nv[1]) or keep_blank_values:
-            name = nv[0].replace('+', ' ')
-            name = unquote(name, encoding=encoding, errors=errors)
-            name = _coerce_result(name)
-            value = nv[1].replace('+', ' ')
-            value = unquote(value, encoding=encoding, errors=errors)
-            value = _coerce_result(value)
-            r.append((name, value))
+            if value or keep_blank_values:
+                name = _unquote(name)
+                value = _unquote(value)
+                r.append((name, value))
     return r
 
 def unquote_plus(string, encoding='utf-8', errors='replace'):
diff --git a/Lib/urllib/request.py b/Lib/urllib/request.py
index 5314b3f260..7228a35534 100644
--- a/Lib/urllib/request.py
+++ b/Lib/urllib/request.py
@@ -2589,6 +2589,7 @@ def _proxy_bypass_macosx_sysconf(host, proxy_settings):
     }
     """
     from fnmatch import fnmatch
+    from ipaddress import AddressValueError, IPv4Address
 
     hostonly, port = _splitport(host)
 
@@ -2605,20 +2606,17 @@ def ip2num(ipAddr):
             return True
 
     hostIP = None
+    try:
+        hostIP = int(IPv4Address(hostonly))
+    except AddressValueError:
+        pass
 
     for value in proxy_settings.get('exceptions', ()):
         # Items in the list are strings like these: *.local, 169.254/16
         if not value: continue
 
         m = re.match(r"(\d+(?:\.\d+)*)(/\d+)?", value)
-        if m is not None:
-            if hostIP is None:
-                try:
-                    hostIP = socket.gethostbyname(hostonly)
-                    hostIP = ip2num(hostIP)
-                except OSError:
-                    continue
-
+        if m is not None and hostIP is not None:
             base = ip2num(m.group(1))
             mask = m.group(2)
             if mask is None:
@@ -2641,6 +2639,31 @@ def ip2num(ipAddr):
     return False
 
 
+# Same as _proxy_bypass_macosx_sysconf, testable on all platforms
+def _proxy_bypass_winreg_override(host, override):
+    """Return True if the host should bypass the proxy server.
+
+    The proxy override list is obtained from the Windows
+    Internet settings proxy override registry value.
+
+    An example of a proxy override value is:
+    "www.example.com;*.example.net; 192.168.0.1"
+    """
+    from fnmatch import fnmatch
+
+    host, _ = _splitport(host)
+    proxy_override = override.split(';')
+    for test in proxy_override:
+        test = test.strip()
+        # "<local>" should bypass the proxy server for all intranet addresses
+        if test == '<local>':
+            if '.' not in host:
+                return True
+        elif fnmatch(host, test):
+            return True
+    return False
+
+
 if sys.platform == 'darwin':
     from _scproxy import _get_proxy_settings, _get_proxies
 
@@ -2739,7 +2762,7 @@ def proxy_bypass_registry(host):
             import winreg
         except ImportError:
             # Std modules, so should be around - but you never know!
-            return 0
+            return False
         try:
             internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,
                 r'Software\Microsoft\Windows\CurrentVersion\Internet Settings')
@@ -2749,40 +2772,10 @@ def proxy_bypass_registry(host):
                                                      'ProxyOverride')[0])
             # ^^^^ Returned as Unicode but problems if not converted to ASCII
         except OSError:
-            return 0
+            return False
         if not proxyEnable or not proxyOverride:
-            return 0
-        # try to make a host list from name and IP address.
-        rawHost, port = _splitport(host)
-        host = [rawHost]
-        try:
-            addr = socket.gethostbyname(rawHost)
-            if addr != rawHost:
-                host.append(addr)
-        except OSError:
-            pass
-        try:
-            fqdn = socket.getfqdn(rawHost)
-            if fqdn != rawHost:
-                host.append(fqdn)
-        except OSError:
-            pass
-        # make a check value list from the registry entry: replace the
-        # '<local>' string by the localhost entry and the corresponding
-        # canonical entry.
-        proxyOverride = proxyOverride.split(';')
-        # now check if we match one of the registry values.
-        for test in proxyOverride:
-            if test == '<local>':
-                if '.' not in rawHost:
-                    return 1
-            test = test.replace(".", r"\.")     # mask dots
-            test = test.replace("*", r".*")     # change glob sequence
-            test = test.replace("?", r".")      # change glob char
-            for val in host:
-                if re.match(test, val, re.I):
-                    return 1
-        return 0
+            return False
+        return _proxy_bypass_winreg_override(host, proxyOverride)
 
     def proxy_bypass(host):
         """Return True, if host should be bypassed.
diff --git a/Lib/xml/etree/ElementTree.py b/Lib/xml/etree/ElementTree.py
index bb7362d163..fd2cc8704e 100644
--- a/Lib/xml/etree/ElementTree.py
+++ b/Lib/xml/etree/ElementTree.py
@@ -1313,6 +1313,11 @@ def read_events(self):
             else:
                 yield event
 
+    def flush(self):
+        if self._parser is None:
+            raise ValueError("flush() called after end of stream")
+        self._parser.flush()
+
 
 def XML(text, parser=None):
     """Parse XML document from string constant.
@@ -1719,6 +1724,15 @@ def close(self):
             del self.parser, self._parser
             del self.target, self._target
 
+    def flush(self):
+        was_enabled = self.parser.GetReparseDeferralEnabled()
+        try:
+            self.parser.SetReparseDeferralEnabled(False)
+            self.parser.Parse(b"", False)
+        except self._error as v:
+            self._raiseerror(v)
+        finally:
+            self.parser.SetReparseDeferralEnabled(was_enabled)
 
 # --------------------------------------------------------------------
 # C14N 2.0
diff --git a/Lib/xml/sax/expatreader.py b/Lib/xml/sax/expatreader.py
index b9ad52692d..ba3c1e9851 100644
--- a/Lib/xml/sax/expatreader.py
+++ b/Lib/xml/sax/expatreader.py
@@ -214,6 +214,20 @@ def feed(self, data, isFinal=False):
             # FIXME: when to invoke error()?
             self._err_handler.fatalError(exc)
 
+    def flush(self):
+        if self._parser is None:
+            return
+
+        was_enabled = self._parser.GetReparseDeferralEnabled()
+        try:
+            self._parser.SetReparseDeferralEnabled(False)
+            self._parser.Parse(b"", False)
+        except expat.error as e:
+            exc = SAXParseException(expat.ErrorString(e.code), e, self)
+            self._err_handler.fatalError(exc)
+        finally:
+            self._parser.SetReparseDeferralEnabled(was_enabled)
+
     def _close_source(self):
         source = self._source
         try:
diff --git a/Lib/zipfile/__init__.py b/Lib/zipfile/__init__.py
index 8918484207..91358156bc 100644
--- a/Lib/zipfile/__init__.py
+++ b/Lib/zipfile/__init__.py
@@ -582,7 +582,15 @@ def from_file(cls, filename, arcname=None, *, strict_timestamps=True):
 
     def is_dir(self):
         """Return True if this archive member is a directory."""
-        return self.filename.endswith('/')
+        if self.filename.endswith('/'):
+            return True
+        # The ZIP format specification requires to use forward slashes
+        # as the directory separator, but in practice some ZIP files
+        # created on Windows can use backward slashes.  For compatibility
+        # with the extraction code which already handles this:
+        if os.path.altsep:
+            return self.filename.endswith((os.path.sep, os.path.altsep))
+        return False
 
 
 # ZIP encryption uses the CRC32 one-byte primitive for scrambling some
@@ -1554,7 +1562,8 @@ def comment(self, comment):
         self._didModify = True
 
     def read(self, name, pwd=None):
-        """Return file bytes for name."""
+        """Return file bytes for name. 'pwd' is the password to decrypt
+        encrypted files."""
         with self.open(name, "r", pwd) as fp:
             return fp.read()
 
@@ -1706,7 +1715,8 @@ def extract(self, member, path=None, pwd=None):
         """Extract a member from the archive to the current working directory,
            using its full name. Its file information is extracted as accurately
            as possible. `member' may be a filename or a ZipInfo object. You can
-           specify a different directory using `path'.
+           specify a different directory using `path'. You can specify the
+           password to decrypt the file using 'pwd'.
         """
         if path is None:
             path = os.getcwd()
@@ -1719,7 +1729,8 @@ def extractall(self, path=None, members=None, pwd=None):
         """Extract all members from the archive to the current working
            directory. `path' specifies a different directory to extract to.
            `members' is optional and must be a subset of the list returned
-           by namelist().
+           by namelist(). You can specify the password to decrypt all files
+           using 'pwd'.
         """
         if members is None:
             members = self.namelist()
diff --git a/Makefile.pre.in b/Makefile.pre.in
index dd5e69f7ab..27a26c2252 100644
--- a/Makefile.pre.in
+++ b/Makefile.pre.in
@@ -1320,9 +1320,9 @@ regen-limited-abi: all
 regen-all: regen-cases regen-opcode regen-opcode-targets regen-typeslots \
 	regen-token regen-ast regen-keyword regen-sre regen-frozen \
 	regen-pegen-metaparser regen-pegen regen-test-frozenmain \
-	regen-test-levenshtein regen-global-objects regen-sbom
+	regen-test-levenshtein regen-global-objects
 	@echo
-	@echo "Note: make regen-stdlib-module-names and make regen-configure should be run manually"
+	@echo "Note: make regen-stdlib-module-names, make-regen-sbom, and make regen-configure should be run manually"
 
 ############################################################################
 # Special rules for object files
@@ -2208,6 +2208,7 @@ TESTSUBDIRS=	idlelib/idle_test \
 		test/test_lib2to3/data/fixers/myfixes \
 		test/test_module \
 		test/test_peg_generator \
+		test/test_pydoc \
 		test/test_sqlite3 \
 		test/test_tkinter \
 		test/test_tomllib \
@@ -2244,7 +2245,11 @@ TESTSUBDIRS=	idlelib/idle_test \
 		test/wheeldata \
 		test/xmltestdata \
 		test/xmltestdata/c14n-20 \
-		test/ziptestdata
+		test/ziptestdata \
+		test/test_concurrent_futures \
+		test/test_multiprocessing_fork \
+		test/test_multiprocessing_forkserver \
+		test/test_multiprocessing_spawn
 
 COMPILEALL_OPTS=-j0
 
diff --git a/Misc/ACKS b/Misc/ACKS
index 2693c3c593..371e937658 100644
--- a/Misc/ACKS
+++ b/Misc/ACKS
@@ -752,6 +752,7 @@ Raymond Hettinger
 Lisa Hewus Fresh
 Kevan Heydon
 Wouter van Heyst
+Derek Higgins
 Kelsey Hightower
 Jason Hildebrand
 Ryan Hileman
diff --git a/Misc/externals.spdx.json b/Misc/externals.spdx.json
new file mode 100644
index 0000000000..12cbc54c75
--- /dev/null
+++ b/Misc/externals.spdx.json
@@ -0,0 +1,195 @@
+{
+  "SPDXID": "SPDXRef-DOCUMENT",
+  "packages": [
+    {
+      "SPDXID": "SPDXRef-PACKAGE-bzip2",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "ab8d1b0cc087c20d4c32c0e4fcf7d0c733a95da12cedc6d63b3f0a9af07427e2"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/bzip2-1.0.8.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:bzip:bzip2:1.0.8:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "bzip2",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "1.0.8"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-libffi",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "9d802681adfea27d84cae0487a785fb9caa925bdad44c401b364c59ab2b8edda"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/libffi-3.4.4.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:libffi_project:libffi:3.4.4:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "libffi",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "3.4.4"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-openssl",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "e6a77c273ebb284fedd8ea19b081fce74a9455936ffd47215f7c24713e2614b2"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/openssl-3.0.13.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:openssl:openssl:3.0.13:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "openssl",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "3.0.13"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-sqlite",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "6f0364a27375435a34137b138ca4fedef8d23eec6493ca1dfff33bfc0c34fda4"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/sqlite-3.45.1.0.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:sqlite:sqlite:3.45.1.0:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "sqlite",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "3.45.1.0"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-tcl-core",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "6e33a88f116822167734cd72b693b5d30ced130a3cae6dc2ff696042f993bb42"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/tcl-core-8.6.13.0.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:tcl_tk:tcl_tk:8.6.13.0:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "tcl-core",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "8.6.13.0"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-tk",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "896c1f488bdd0159091bd5cce124b756dfdffa4a5350b7fd4d7d8e48421089a4"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/tk-8.6.13.0.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:tcl_tk:tcl_tk:8.6.13.0:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "tk",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "8.6.13.0"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-tix",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "f7b21d115867a41ae5fd7c635a4c234d3ca25126c3661eb36028c6e25601f85e"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/tix-8.4.3.6.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:tcl_tk:tcl_tk:8.4.3.6:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "tix",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "8.4.3.6"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-xz",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "a15c168e39e87d750c3dc766edc7f19bdda57dacf01e509678467eace91ad282"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/xz-5.2.5.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:xz_project:xz:5.2.5:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "xz",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "5.2.5"
+    },
+    {
+      "SPDXID": "SPDXRef-PACKAGE-zlib",
+      "checksums": [
+        {
+          "algorithm": "SHA256",
+          "checksumValue": "e3f3fb32564952006eb18b091ca8464740e5eca29d328cfb0b2da22768e0b638"
+        }
+      ],
+      "downloadLocation": "https://github.com/python/cpython-source-deps/archive/refs/tags/zlib-1.3.1.tar.gz",
+      "externalRefs": [
+        {
+          "referenceCategory": "SECURITY",
+          "referenceLocator": "cpe:2.3:a:zlib:zlib:1.3.1:*:*:*:*:*:*:*",
+          "referenceType": "cpe23Type"
+        }
+      ],
+      "licenseConcluded": "NOASSERTION",
+      "name": "zlib",
+      "primaryPackagePurpose": "SOURCE",
+      "versionInfo": "1.3.1"
+    }
+  ],
+  "spdxVersion": "SPDX-2.3"
+}
\ No newline at end of file
diff --git a/Misc/sbom.spdx.json b/Misc/sbom.spdx.json
index d783d14255..5612c9cae3 100644
--- a/Misc/sbom.spdx.json
+++ b/Misc/sbom.spdx.json
@@ -48,29 +48,15 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "ab7bb32514d170592dfb3f76e41bbdc075a4e7e0"
+          "checksumValue": "90c06411f131e777e2b5c3d22b7ccf50bc46f617"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "f521acdad222644365b0e81a33bcd6939a98c91b225c47582cc84bd73d96febc"
+          "checksumValue": "3045f9176950aa13a54e53fa096385670c676c492705d636e977f888e4c72d48"
         }
       ],
       "fileName": "Modules/expat/expat.h"
     },
-    {
-      "SPDXID": "SPDXRef-FILE-Modules-expat-expat-config.h",
-      "checksums": [
-        {
-          "algorithm": "SHA1",
-          "checksumValue": "73627287302ee3e84347c4fe21f37a9cb828bc3b"
-        },
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "f17e59f9d95eeb05694c02508aa284d332616c22cbe2e6a802d8a0710310eaab"
-        }
-      ],
-      "fileName": "Modules/expat/expat_config.h"
-    },
     {
       "SPDXID": "SPDXRef-FILE-Modules-expat-expat-external.h",
       "checksums": [
@@ -104,11 +90,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "2790d37e7de2f13dccc4f4fb352cbdf9ed6abaa2"
+          "checksumValue": "9f6d9211a7b627785d5c48d10cc8eda66255113f"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "d2efe5a1018449968a689f444cca432e3d5875aba6ad08ee18ca235d64f41bb9"
+          "checksumValue": "9f0bdd346dd94ac4359c636a4e60bc768f4ae53ce0e836eb05fb9246ee36c7f2"
         }
       ],
       "fileName": "Modules/expat/internal.h"
@@ -146,11 +132,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "baa44fe4581895d42e8d5e83d8ce6a69b1c34dbe"
+          "checksumValue": "f50c899172acd93fc539007bfb43315b83d407e4"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "33a7b9ac8bf4571e23272cdf644c6f9808bd44c66b149e3c41ab3870d1888609"
+          "checksumValue": "d571b8258cfaa067a20adef553e5fcedd6671ca4a8841483496de031bd904567"
         }
       ],
       "fileName": "Modules/expat/pyexpatns.h"
@@ -160,11 +146,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "2b984f806f10fbfbf72d8d1b7ba2992413c15299"
+          "checksumValue": "4c49b5df2bc702f663ba3b5a52d1940ec363226b"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "fbce56cd680e690043bbf572188cc2d0a25dbfc0d47ac8cb98eb3de768d4e694"
+          "checksumValue": "b5ec29f6560acc183f1ee8ab92bb3aea17b87b4c2120cd2e3f78deba7a12491e"
         }
       ],
       "fileName": "Modules/expat/siphash.h"
@@ -188,11 +174,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "e774ae6ee9391aa6ffb8f775fb74e48f4b428959"
+          "checksumValue": "a3a8c44efd55dbf2cfea8fcee009ec63120ec0a3"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "3c71cea9a6174718542331971a35db317902b2433be9d8dd1cb24239b635c0cc"
+          "checksumValue": "e70948500d34dfcba4e9f0b305319dfe2a937c7cbfb687905128b56e1a6f8b33"
         }
       ],
       "fileName": "Modules/expat/winconfig.h"
@@ -202,11 +188,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "b580e827e16baa6b035586ffcd4d90301e5a353f"
+          "checksumValue": "3b5de0ed1de33cad85b46230707403247f2851df"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "483518bbd69338eefc706cd7fc0b6039df2d3e347f64097989059ed6d2385a1e"
+          "checksumValue": "a03abd531601eef61a87e06113d218ff139b6969e15a3d4668cd85d65fc6f79b"
         }
       ],
       "fileName": "Modules/expat/xmlparse.c"
@@ -216,11 +202,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "5ef21312af73deb2428be3fe97a65244608e76de"
+          "checksumValue": "ef767128d2dda99436712dcf3465dde5dbaab876"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "6fcf8c72ac0112c1b98bd2039c632a66b4c3dc516ce7c1f981390951121ef3c0"
+          "checksumValue": "71fb52aa302cf6f56e41943009965804f49ff2210d9bd15b258f70aaf70db772"
         }
       ],
       "fileName": "Modules/expat/xmlrole.c"
@@ -230,11 +216,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "c1a4ea6356643d0820edb9c024c20ad2aaf562dc"
+          "checksumValue": "c961fb1a80f7b0601a63e69fba793fe5f6dff157"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "2b5d674be6ef20c7e3f69295176d75e68c5616e4dfce0a186fdd5e2ed8315f7a"
+          "checksumValue": "228470eb9181a9a7575b63137edcb61b817ee4e0923faffdbeba29e07c939713"
         }
       ],
       "fileName": "Modules/expat/xmlrole.h"
@@ -244,11 +230,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "e6d66ae9fd61d7950c62c5d87693c30a707e8577"
+          "checksumValue": "8394790c0199c8f88108542ad78f23095d28a3fe"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "1110f651bdccfa765ad3d6f3857a35887ab35fc0fe7f3f3488fde2b238b482e3"
+          "checksumValue": "5b16c671ccc42496374762768e4bf48f614aecfd2025a07925b8d94244aec645"
         }
       ],
       "fileName": "Modules/expat/xmltok.c"
@@ -258,11 +244,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "9c2a544875fd08ba9c2397296c97263518a410aa"
+          "checksumValue": "7d2943a0128094455004b1a98007b98734221bae"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "4299a03828b98bfe47ec6809f6e279252954a9a911dc7e0f19551bd74e3af971"
+          "checksumValue": "6b8919dc951606dc6f2b0175f8955a9ced901ce8bd08db47f291b6c04227ae7f"
         }
       ],
       "fileName": "Modules/expat/xmltok.h"
@@ -272,11 +258,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "aa96882de8e3d1d3083124b595aa911efe44e5ad"
+          "checksumValue": "7756f7c0d3625ae7dde6cf7d386685ffacb57c7e"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "0fbcba7931707c60301305dab78d2298d96447d0a5513926d8b18135228c0818"
+          "checksumValue": "a3fe18ff32b21fbcb7c190895c68158404e1b9fb449db6431bc08b261dc03938"
         }
       ],
       "fileName": "Modules/expat/xmltok_impl.c"
@@ -314,11 +300,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "f77449b2b4eb99f1da0938633cc558baf9c444fb"
+          "checksumValue": "f8ba39b46ebdfa7d031d9c33130c6ded680a8120"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "0f252967debca5b35362ca53951ea16ca8bb97a19a1d24f6695f44d50010859e"
+          "checksumValue": "f71cf6a0e8f09354c2af2c785a1d36e0cba7613a589be01ca8a3d8478f4c8874"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_MD5.c"
@@ -328,11 +314,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "c24e6779a91c840f3d65d24abbce225b608b676e"
+          "checksumValue": "eaaab54cea2b0bb8ec0eedf0b373d42f1a0f8f6c"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "9cd062e782801013e3cacaba583e44e1b5e682e217d20208d5323354d42011f1"
+          "checksumValue": "9a02e2a6e163515ea0228a859d5e55c1f57b11fae5908c42f9f9814ce9bca230"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_MD5.h"
@@ -342,11 +328,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "560f6ff541b5eff480ea047b147f4212bb0db7ed"
+          "checksumValue": "f4f42faf8da78a230199f649c0f2a1b865799a31"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "0ade3ab264e912d7b4e5cdcf773db8c63e4440540d295922d74b06bcfc74c77a"
+          "checksumValue": "5b29bd9951646861e0e19427be5d923a5bab7a4516824ccc068f696469195eec"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_SHA1.c"
@@ -356,11 +342,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "853b77d45379146faaeac5fe899b28db386ad13c"
+          "checksumValue": "722b57139737ceeb88e41d3839e6f7d70578741b"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "b13eb14f91582703819235ea7c8f807bb93e4f1e6b695499dc1d86021dc39e72"
+          "checksumValue": "5640295c790d56b1b4df147d6a6c58803b1845cd7d93365bf7cc7b75ba3cacd5"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_SHA1.h"
@@ -370,11 +356,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "667120b6100c946cdaa442f1173c723339923071"
+          "checksumValue": "f2aa3ed6acce621c162bc3a0592780ce5aa3bc4d"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "b189459b863341a3a9c5c78c0208b6554a2f2ac26e0748fbd4432a91db21fae6"
+          "checksumValue": "30638efb75c8b185bb09c3df6977e3f3c5d21a1e696218cf7ade6bc4d5201b31"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_SHA2.c"
@@ -384,11 +370,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "81db38b0b920e63ec33c7109d1144c35cf091da0"
+          "checksumValue": "4903e10291d07367be3bc283935bc52926e57ba1"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "631c9ba19c1c2c835bb63d3f2f22b8d76fb535edfed3c254ff2a52f12af3fe61"
+          "checksumValue": "093d7693084af0999d2a13d207311d74b5bdfdc9c08447ed4a979e3f7505ae6b"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_SHA2.h"
@@ -398,11 +384,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "9c832b98a2f2a68202d2da016fb718965d7b7602"
+          "checksumValue": "66644fd3325c414fef7d985536bb477c849c8f9a"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "38d350d1184238966cfa821a59ae00343f362182b6c2fbea7f2651763d757fb7"
+          "checksumValue": "17c0db96d40d1849f02546d5f55428fa89b61b07748d5b5df45cec25c5f29c0f"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_SHA3.c"
@@ -412,11 +398,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "ecc766fb6f7ee85e902b593b61b41e5a728fca34"
+          "checksumValue": "580e9a73813281e99a98871380b3726576295a96"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "bae290a94366a2460f51e8468144baaade91d9048db111e10d2e2ffddc3f98cf"
+          "checksumValue": "d8d4d14bbc3a561a4e590d9b18b326e6a8095efb12423edbd949cf3c00953621"
         }
       ],
       "fileName": "Modules/_hacl/Hacl_Hash_SHA3.h"
@@ -440,11 +426,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "2ea61d6a236147462045f65c20311819d74db80c"
+          "checksumValue": "12c0c680c93b8112b97cc575faacbb3cbbd315b1"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "2c22b4d49ba06d6a3053cdc66405bd5ae953a28fcfed1ab164e8f5e0f6e2fb8b"
+          "checksumValue": "455e94f24a0900deda7e6e36f4714e4253d32cea077f97e23f90c569a717bc48"
         }
       ],
       "fileName": "Modules/_hacl/include/krml/FStar_UInt128_Verified.h"
@@ -454,11 +440,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "1a647d841180ac8ca667afa968c353425e81ad0d"
+          "checksumValue": "62b44acbbdc77b749c36c242cda027bacf7679f8"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "e5d1c5854833bec7ea02e227ec35bd7b49c5fb9e0f339efa0dd83e1595f722d4"
+          "checksumValue": "65decdb74c24049aa19430462a51219250cfc65d8c162778e42df88b3142fa42"
         }
       ],
       "fileName": "Modules/_hacl/include/krml/FStar_UInt_8_16_32_64.h"
@@ -482,11 +468,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "903c9eb76b01f3a95c04c3bc841c2fb71dea5403"
+          "checksumValue": "ba64394679643c6d4ceaf6bd2616d48d12f996a7"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "08ec602c7f90a1540389c0cfc95769fa7fec251e7ca143ef83c0b9f7afcf89a7"
+          "checksumValue": "d16a59f37a1d4982626870e370889eb9d332a9ad035661b8062f549fc734d061"
         }
       ],
       "fileName": "Modules/_hacl/include/krml/internal/target.h"
@@ -524,11 +510,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "5dd4ee3c835a0d176a6e9fecbe9752fd1474ff41"
+          "checksumValue": "60f02d21f045c8a4c2b6b84a8f7e023d9490c8e5"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "d82ef594cba44203576d67b047240316bb3c542912ebb7034afa1e07888cec56"
+          "checksumValue": "370d8ef9c48cb55472ece11e12eaf94c58118de3f5515b6df1c130b696597828"
         }
       ],
       "fileName": "Modules/_hacl/internal/Hacl_Hash_MD5.h"
@@ -538,11 +524,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "515b3082eb7c30597773e1c63ec46688f6da3634"
+          "checksumValue": "6346c30a140e7d3010c98fe19d14fa229a54eb16"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "10aacf847006b8e0dfb64d5c327443f954db6718b4aec712fb3268230df6a752"
+          "checksumValue": "ab52c6092bdbbfc9884f841bf4824016792ffa96167577cbe0df00dd96f56a34"
         }
       ],
       "fileName": "Modules/_hacl/internal/Hacl_Hash_SHA1.h"
@@ -552,11 +538,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "a044ec12b70ba97b67e9a312827d6270452a20ca"
+          "checksumValue": "0018e084339058dd454b4e49d10d236b4f896bf8"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "a1426b54fa7273ba5b50817c25b2b26fc85c4d1befb14092cd27dc4c99439463"
+          "checksumValue": "10e959a92b3288a6165a404c8fae2bbcd7fb00a9abbae2b7809fa55d6fe9068d"
         }
       ],
       "fileName": "Modules/_hacl/internal/Hacl_Hash_SHA2.h"
@@ -566,11 +552,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "cfb7b520c39a73cb84c541d370455f92b998781f"
+          "checksumValue": "eae8a5226bf993f07584cf4c0d269022328cf3d4"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "fd41997f9e96b3c9a3337b1b51fab965a1e21b0c16f353d156f1a1fa00709fbf"
+          "checksumValue": "6853125de10d0f605e9bc3a3dbbd7254713709e9893cc3f69929ea8d3f254934"
         }
       ],
       "fileName": "Modules/_hacl/internal/Hacl_Hash_SHA3.h"
@@ -580,11 +566,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "f5c7b3ed911af6c8d582e8b3714b0c36195dc994"
+          "checksumValue": "d8063060cc707a7ac70108a15934d33e7b448db6"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "07de72398b12957e014e97b9ac197bceef12d6d6505c2bfe8b23ee17b94ec5fa"
+          "checksumValue": "347dfdf856ed1e584d124d6709b51267598ea5b37c1a2e03beeb358c978beada"
         }
       ],
       "fileName": "Modules/_hacl/python_hacl_namespaces.h"
@@ -692,11 +678,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "6fa074693aa7305018dfa8db48010a8ef1050ad4"
+          "checksumValue": "f935d64cc633c38e09fc2d89281c95edfbc1fb05"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "c8c6dd861ac193d4a0e836242ff44900f83423f86d2c2940c8c4c1e41fbd5812"
+          "checksumValue": "b932aa273b2504606a48895a50ff08c883f7a68a7e4aced5daa909c43348605a"
         }
       ],
       "fileName": "Modules/_blake2/impl/blake2b.c"
@@ -776,11 +762,11 @@
       "checksums": [
         {
           "algorithm": "SHA1",
-          "checksumValue": "d2691353fa54ac6ffcd7c0a294984dc9d7968ef7"
+          "checksumValue": "13ac5bb93578a7ee8f815b4e247e82c849992bbe"
         },
         {
           "algorithm": "SHA256",
-          "checksumValue": "cfd7948c9fd50e9f9c62f8a93b20a254d1d510a862d1092af4f187b7c1a859a3"
+          "checksumValue": "25ec5dd5c79f916307358059fe9f633781f27df1c0e0962c4fcccdda1feb93a7"
         }
       ],
       "fileName": "Modules/_blake2/impl/blake2s.c"
@@ -1568,20 +1554,6 @@
         }
       ],
       "fileName": "Modules/_decimal/libmpdec/vcdiv64.asm"
-    },
-    {
-      "SPDXID": "SPDXRef-FILE-Lib-ensurepip-bundled-pip-24.0-py3-none-any.whl",
-      "checksums": [
-        {
-          "algorithm": "SHA1",
-          "checksumValue": "e44313ae1e6af3c2bd3b60ab2fa8c34308d00555"
-        },
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "ba0d021a166865d2265246961bec0152ff124de910c5cc39f1156ce3fa7c69dc"
-        }
-      ],
-      "fileName": "Lib/ensurepip/_bundled/pip-24.0-py3-none-any.whl"
     }
   ],
   "packages": [
@@ -1590,14 +1562,14 @@
       "checksums": [
         {
           "algorithm": "SHA256",
-          "checksumValue": "6b902ab103843592be5e99504f846ec109c1abb692e85347587f237a4ffa1033"
+          "checksumValue": "a13447b9aa67d7c860783fdf6820f33ebdea996900d6d8bbc50a628f55f099f7"
         }
       ],
-      "downloadLocation": "https://github.com/libexpat/libexpat/releases/download/R_2_5_0/expat-2.5.0.tar.gz",
+      "downloadLocation": "https://github.com/libexpat/libexpat/releases/download/R_2_6_0/expat-2.6.0.tar.gz",
       "externalRefs": [
         {
           "referenceCategory": "SECURITY",
-          "referenceLocator": "cpe:2.3:a:libexpat_project:libexpat:2.5.0:*:*:*:*:*:*:*",
+          "referenceLocator": "cpe:2.3:a:libexpat_project:libexpat:2.6.0:*:*:*:*:*:*:*",
           "referenceType": "cpe23Type"
         }
       ],
@@ -1605,21 +1577,21 @@
       "name": "expat",
       "originator": "Organization: Expat development team",
       "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "2.5.0"
+      "versionInfo": "2.6.0"
     },
     {
       "SPDXID": "SPDXRef-PACKAGE-hacl-star",
       "checksums": [
         {
           "algorithm": "SHA256",
-          "checksumValue": "c23ac158b238c368389dc86bfc315263e5c0e57785da74144aea2cab9a3d51a2"
+          "checksumValue": "e31e4ca10da91c585793c0eaf1b98aee3cb43e3a58d3d8d478593e5a6bd82927"
         }
       ],
-      "downloadLocation": "https://github.com/hacl-star/hacl-star/archive/521af282fdf6d60227335120f18ae9309a4b8e8c.zip",
+      "downloadLocation": "https://github.com/hacl-star/hacl-star/archive/bb3d0dc8d9d15a5cd51094d5b69e70aa09005ff0.zip",
       "externalRefs": [
         {
           "referenceCategory": "SECURITY",
-          "referenceLocator": "cpe:2.3:a:hacl-star:hacl-star:521af282fdf6d60227335120f18ae9309a4b8e8c:*:*:*:*:*:*:*",
+          "referenceLocator": "cpe:2.3:a:hacl-star:hacl-star:bb3d0dc8d9d15a5cd51094d5b69e70aa09005ff0:*:*:*:*:*:*:*",
           "referenceType": "cpe23Type"
         }
       ],
@@ -1627,7 +1599,7 @@
       "name": "hacl-star",
       "originator": "Organization: HACL* Developers",
       "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "521af282fdf6d60227335120f18ae9309a4b8e8c"
+      "versionInfo": "bb3d0dc8d9d15a5cd51094d5b69e70aa09005ff0"
     },
     {
       "SPDXID": "SPDXRef-PACKAGE-libb2",
@@ -1694,660 +1666,9 @@
       "originator": "Organization: bytereef.org",
       "primaryPackagePurpose": "SOURCE",
       "versionInfo": "2.5.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-cachecontrol",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "95dedbec849f46dda3137866dc28b9d133fc9af55f5b805ab1291833e4457aa4"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/1d/e3/a22348e6226dcd585d5a4b5f0175b3a16dabfd3912cbeb02f321d00e56c7/cachecontrol-0.13.1-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/cachecontrol@0.13.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "cachecontrol",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "0.13.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-colorama",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/colorama@0.4.6",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "colorama",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "0.4.6"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-distlib",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "034db59a0b96f8ca18035f36290806a9a6e6bd9d1ff91e45a7f172eb17e51784"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/8e/41/9307e4f5f9976bc8b7fea0b66367734e8faf3ec84bc0d412d8cfabbb66cd/distlib-0.3.8-py2.py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/distlib@0.3.8",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "distlib",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "0.3.8"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-distro",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "99522ca3e365cac527b44bde033f64c6945d90eb9f769703caaec52b09bbd3ff"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/f4/2c/c90a3adaf0ddb70afe193f5ebfb539612af57cffe677c3126be533df3098/distro-1.8.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/distro@1.8.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "distro",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "1.8.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-msgpack",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "525228efd79bb831cf6830a732e2e80bc1b05436b086d4264814b4b2955b2fa9"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/9f/4a/36d936e54cf71e23ad276564465f6a54fb129e3d61520b76e13e0bb29167/msgpack-1.0.5-cp310-cp310-macosx_10_9_universal2.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/msgpack@1.0.5",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "msgpack",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "1.0.5"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-packaging",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "ef103e05f519cdc783ae24ea4e2e0f508a9c99b2d4969652eed6a2e1ea5bd522"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/05/8e/8de486cbd03baba4deef4142bd643a3e7bbe954a784dc1bb17142572d127/packaging-21.3-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/packaging@21.3",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "packaging",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "21.3"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-platformdirs",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "cec7b889196b9144d088e4c57d9ceef7374f6c39694ad1577a0aab50d27ea28c"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/9e/d8/563a9fc17153c588c8c2042d2f0f84a89057cdb1c30270f589c88b42d62c/platformdirs-3.8.1-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/platformdirs@3.8.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "platformdirs",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "3.8.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-pyparsing",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "d554a96d1a7d3ddaf7183104485bc19fd80543ad6ac5bdb6426719d766fb06c1"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/a4/24/6ae4c9c45cf99d96b06b5d99e25526c060303171fb0aea9da2bfd7dbde93/pyparsing-3.1.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/pyparsing@3.1.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "pyparsing",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "3.1.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-pyproject-hooks",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "283c11acd6b928d2f6a7c73fa0d01cb2bdc5f07c57a2eeb6e83d5e56b97976f8"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/d5/ea/9ae603de7fbb3df820b23a70f6aff92bf8c7770043254ad8d2dc9d6bcba4/pyproject_hooks-1.0.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/pyproject-hooks@1.0.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "pyproject-hooks",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "1.0.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-requests",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "58cd2187c01e70e6e26505bca751777aa9f2ee0b7f4300988b709f44e013003f"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/requests@2.31.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "requests",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "2.31.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-certifi",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "92d6037539857d8206b8f6ae472e8b77db8058fec5937a1ef3f54304089edbb9"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/certifi@2023.7.22",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "certifi",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "2023.7.22"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-chardet",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "362777fb014af596ad31334fde1e8c327dfdb076e1960d1694662d46a6917ab9"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/74/8f/8fc49109009e8d2169d94d72e6b1f4cd45c13d147ba7d6170fb41f22b08f/chardet-5.1.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/chardet@5.1.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "chardet",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "5.1.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-idna",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "90b77e79eaa3eba6de819a0c442c0b4ceefc341a7a2ab77d7562bf49f425c5c2"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/idna@3.4",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "idna",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "3.4"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-rich",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "8f87bc7ee54675732fa66a05ebfe489e27264caeeff3728c945d25971b6485ec"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/fc/1e/482e5eec0b89b593e81d78f819a9412849814e22225842b598908e7ac560/rich-13.4.2-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/rich@13.4.2",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "rich",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "13.4.2"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-pygments",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "db2db3deb4b4179f399a09054b023b6a586b76499d36965813c71aa8ed7b5fd1"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/34/a7/37c8d68532ba71549db4212cb036dbd6161b40e463aba336770e80c72f84/Pygments-2.15.1-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/pygments@2.15.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "pygments",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "2.15.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-typing-extensions",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "440d5dd3af93b060174bf433bccd69b0babc3b15b1a8dca43789fd7f61514b36"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/typing_extensions@4.7.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "typing_extensions",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "4.7.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-resolvelib",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "d2da45d1a8dfee81bdd591647783e340ef3bcb104b54c383f70d422ef5cc7dbf"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/d2/fc/e9ccf0521607bcd244aa0b3fbd574f71b65e9ce6a112c83af988bbbe2e23/resolvelib-1.0.1-py2.py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/resolvelib@1.0.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "resolvelib",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "1.0.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-setuptools",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "11e52c67415a381d10d6b462ced9cfb97066179f0e871399e006c4ab101fc85f"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/setuptools@68.0.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "setuptools",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "68.0.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-six",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/six@1.16.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "six",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "1.16.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-tenacity",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "2f277afb21b851637e8f52e6a613ff08734c347dc19ade928e519d7d2d8569b0"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/e7/b0/c23bd61e1b32c9b96fbca996c87784e196a812da8d621d8d04851f6c8181/tenacity-8.2.2-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/tenacity@8.2.2",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "tenacity",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "8.2.2"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-tomli",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "939de3e7a6161af0c887ef91b7d41a53e7c5a1ca976325f429cb46ea9bc30ecc"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/97/75/10a9ebee3fd790d20926a90a2547f0bf78f371b2f13aa822c759680ca7b9/tomli-2.0.1-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/tomli@2.0.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "tomli",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "2.0.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-truststore",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "e37a5642ae9fc48caa8f120b6283d77225d600d224965a672c9e8ef49ce4bb4c"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/20/56/7811d5439b6a56374f274a8672d8f18b4deadadeb3a9f0c86424b98b6f96/truststore-0.8.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/truststore@0.8.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "truststore",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "0.8.0"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-webencodings",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "a0af1213f3c2226497a97e2b3aa01a7e4bee4f403f95be16fc9acd2947514a78"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/webencodings@0.5.1",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "webencodings",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "0.5.1"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-urllib3",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "94a757d178c9be92ef5539b8840d48dc9cf1b2709c9d6b588232a055c524458b"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/48/fe/a5c6cc46e9fe9171d7ecf0f33ee7aae14642f8d74baa7af4d7840f9358be/urllib3-1.26.17-py2.py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/urllib3@1.26.17",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "urllib3",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "1.26.17"
-    },
-    {
-      "SPDXID": "SPDXRef-PACKAGE-pip",
-      "checksums": [
-        {
-          "algorithm": "SHA256",
-          "checksumValue": "ba0d021a166865d2265246961bec0152ff124de910c5cc39f1156ce3fa7c69dc"
-        }
-      ],
-      "downloadLocation": "https://files.pythonhosted.org/packages/8a/6a/19e9fe04fca059ccf770861c7d5721ab4c2aebc539889e97c7977528a53b/pip-24.0-py3-none-any.whl",
-      "externalRefs": [
-        {
-          "referenceCategory": "SECURITY",
-          "referenceLocator": "cpe:2.3:a:pypa:pip:24.0:*:*:*:*:*:*:*",
-          "referenceType": "cpe23Type"
-        },
-        {
-          "referenceCategory": "PACKAGE_MANAGER",
-          "referenceLocator": "pkg:pypi/pip@24.0",
-          "referenceType": "purl"
-        }
-      ],
-      "licenseConcluded": "NOASSERTION",
-      "name": "pip",
-      "originator": "Organization: Python Packaging Authority",
-      "primaryPackagePurpose": "SOURCE",
-      "versionInfo": "24.0"
     }
   ],
   "relationships": [
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-cachecontrol",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-certifi",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-chardet",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-colorama",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-distlib",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-distro",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-idna",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-msgpack",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-packaging",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-platformdirs",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-pygments",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-pyparsing",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-pyproject-hooks",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-requests",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-resolvelib",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-rich",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-setuptools",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-six",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-tenacity",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-tomli",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-truststore",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-typing-extensions",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-urllib3",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-PACKAGE-webencodings",
-      "relationshipType": "DEPENDS_ON",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
-    },
     {
       "relatedSpdxElement": "SPDXRef-FILE-Modules-expat-COPYING",
       "relationshipType": "CONTAINS",
@@ -2368,11 +1689,6 @@
       "relationshipType": "CONTAINS",
       "spdxElementId": "SPDXRef-PACKAGE-expat"
     },
-    {
-      "relatedSpdxElement": "SPDXRef-FILE-Modules-expat-expat-config.h",
-      "relationshipType": "CONTAINS",
-      "spdxElementId": "SPDXRef-PACKAGE-expat"
-    },
     {
       "relatedSpdxElement": "SPDXRef-FILE-Modules-expat-expat-external.h",
       "relationshipType": "CONTAINS",
@@ -2907,11 +2223,6 @@
       "relatedSpdxElement": "SPDXRef-FILE-Modules-decimal-libmpdec-vcdiv64.asm",
       "relationshipType": "CONTAINS",
       "spdxElementId": "SPDXRef-PACKAGE-mpdecimal"
-    },
-    {
-      "relatedSpdxElement": "SPDXRef-FILE-Lib-ensurepip-bundled-pip-24.0-py3-none-any.whl",
-      "relationshipType": "CONTAINS",
-      "spdxElementId": "SPDXRef-PACKAGE-pip"
     }
   ],
   "spdxVersion": "SPDX-2.3"
diff --git a/Modules/_blake2/impl/blake2b.c b/Modules/_blake2/impl/blake2b.c
index c1068e8640..cef2283891 100644
--- a/Modules/_blake2/impl/blake2b.c
+++ b/Modules/_blake2/impl/blake2b.c
@@ -27,7 +27,7 @@
 #if defined(HAVE_SSE2)
 #include <emmintrin.h>
 // MSVC only defines  _mm_set_epi64x for x86_64...
-#if defined(_MSC_VER) && !defined(_M_X64)
+#if defined(_MSC_VER) && !defined(_M_X64) && !defined(__clang__)
 static inline __m128i _mm_set_epi64x( const uint64_t u1, const uint64_t u0 )
 {
   return _mm_set_epi32( u1 >> 32, u1, u0 >> 32, u0 );
diff --git a/Modules/_blake2/impl/blake2s.c b/Modules/_blake2/impl/blake2s.c
index 47514685b8..e7f63fd274 100644
--- a/Modules/_blake2/impl/blake2s.c
+++ b/Modules/_blake2/impl/blake2s.c
@@ -27,7 +27,7 @@
 #if defined(HAVE_SSE2)
 #include <emmintrin.h>
 // MSVC only defines  _mm_set_epi64x for x86_64...
-#if defined(_MSC_VER) && !defined(_M_X64)
+#if defined(_MSC_VER) && !defined(_M_X64) && !defined(__clang__)
 static inline __m128i _mm_set_epi64x( const uint64_t u1, const uint64_t u0 )
 {
   return _mm_set_epi32( u1 >> 32, u1, u0 >> 32, u0 );
diff --git a/Modules/_collectionsmodule.c b/Modules/_collectionsmodule.c
index 9a81531bdf..4e195f0d5f 100644
--- a/Modules/_collectionsmodule.c
+++ b/Modules/_collectionsmodule.c
@@ -1116,8 +1116,9 @@ deque_index(dequeobject *deque, PyObject *const *args, Py_ssize_t nargs)
     n = stop - i;
     while (--n >= 0) {
         CHECK_NOT_END(b);
-        item = b->data[index];
+        item = Py_NewRef(b->data[index]);
         cmp = PyObject_RichCompareBool(item, v, Py_EQ);
+        Py_DECREF(item);
         if (cmp > 0)
             return PyLong_FromSsize_t(stop - n - 1);
         if (cmp < 0)
diff --git a/Modules/_csv.c b/Modules/_csv.c
index 91cb63628a..d63eac1bf7 100644
--- a/Modules/_csv.c
+++ b/Modules/_csv.c
@@ -1109,6 +1109,8 @@ join_append_data(WriterObj *self, int field_kind, const void *field_data,
         if (c == dialect->delimiter ||
             c == dialect->escapechar ||
             c == dialect->quotechar  ||
+            c == '\n'  ||
+            c == '\r'  ||
             PyUnicode_FindChar(
                 dialect->lineterminator, c, 0,
                 PyUnicode_GET_LENGTH(dialect->lineterminator), 1) >= 0) {
@@ -1180,6 +1182,7 @@ join_check_rec_size(WriterObj *self, Py_ssize_t rec_len)
 static int
 join_append(WriterObj *self, PyObject *field, int quoted)
 {
+    DialectObj *dialect = self->dialect;
     int field_kind = -1;
     const void *field_data = NULL;
     Py_ssize_t field_len = 0;
@@ -1192,6 +1195,19 @@ join_append(WriterObj *self, PyObject *field, int quoted)
         field_data = PyUnicode_DATA(field);
         field_len = PyUnicode_GET_LENGTH(field);
     }
+    if (!field_len && dialect->delimiter == ' ' && dialect->skipinitialspace) {
+        if (dialect->quoting == QUOTE_NONE ||
+            (field == NULL &&
+             (dialect->quoting == QUOTE_STRINGS ||
+              dialect->quoting == QUOTE_NOTNULL)))
+        {
+            PyErr_Format(self->error_obj,
+                         "empty field must be quoted if delimiter is a space "
+                         "and skipinitialspace is true");
+            return 0;
+        }
+        quoted = 1;
+    }
     rec_len = join_append_data(self, field_kind, field_data, field_len,
                                &quoted, 0);
     if (rec_len < 0)
@@ -1243,6 +1259,7 @@ csv_writerow(WriterObj *self, PyObject *seq)
 {
     DialectObj *dialect = self->dialect;
     PyObject *iter, *field, *line, *result;
+    bool null_field = false;
 
     iter = PyObject_GetIter(seq);
     if (iter == NULL) {
@@ -1279,11 +1296,12 @@ csv_writerow(WriterObj *self, PyObject *seq)
             break;
         }
 
+        null_field = (field == Py_None);
         if (PyUnicode_Check(field)) {
             append_ok = join_append(self, field, quoted);
             Py_DECREF(field);
         }
-        else if (field == Py_None) {
+        else if (null_field) {
             append_ok = join_append(self, NULL, quoted);
             Py_DECREF(field);
         }
@@ -1309,7 +1327,11 @@ csv_writerow(WriterObj *self, PyObject *seq)
         return NULL;
 
     if (self->num_fields > 0 && self->rec_len == 0) {
-        if (dialect->quoting == QUOTE_NONE) {
+        if (dialect->quoting == QUOTE_NONE ||
+            (null_field &&
+             (dialect->quoting == QUOTE_STRINGS ||
+              dialect->quoting == QUOTE_NOTNULL)))
+        {
             PyErr_Format(self->error_obj,
                 "single empty field record must be quoted");
             return NULL;
diff --git a/Modules/_decimal/_decimal.c b/Modules/_decimal/_decimal.c
index 70b13982bb..1a195816fe 100644
--- a/Modules/_decimal/_decimal.c
+++ b/Modules/_decimal/_decimal.c
@@ -143,6 +143,8 @@ static PyObject *default_context_template = NULL;
 static PyObject *basic_context_template = NULL;
 static PyObject *extended_context_template = NULL;
 
+/* Invariant: NULL or pointer to _pydecimal.Decimal */
+static PyObject *PyDecimal = NULL;
 
 /* Error codes for functions that return signals or conditions */
 #define DEC_INVALID_SIGNALS (MPD_Max_status+1U)
@@ -3219,56 +3221,6 @@ dotsep_as_utf8(const char *s)
     return utf8;
 }
 
-/* copy of libmpdec _mpd_round() */
-static void
-_mpd_round(mpd_t *result, const mpd_t *a, mpd_ssize_t prec,
-           const mpd_context_t *ctx, uint32_t *status)
-{
-    mpd_ssize_t exp = a->exp + a->digits - prec;
-
-    if (prec <= 0) {
-        mpd_seterror(result, MPD_Invalid_operation, status);
-        return;
-    }
-    if (mpd_isspecial(a) || mpd_iszero(a)) {
-        mpd_qcopy(result, a, status);
-        return;
-    }
-
-    mpd_qrescale_fmt(result, a, exp, ctx, status);
-    if (result->digits > prec) {
-        mpd_qrescale_fmt(result, result, exp+1, ctx, status);
-    }
-}
-
-/* Locate negative zero "z" option within a UTF-8 format spec string.
- * Returns pointer to "z", else NULL.
- * The portion of the spec we're working with is [[fill]align][sign][z] */
-static const char *
-format_spec_z_search(char const *fmt, Py_ssize_t size) {
-    char const *pos = fmt;
-    char const *fmt_end = fmt + size;
-    /* skip over [[fill]align] (fill may be multi-byte character) */
-    pos += 1;
-    while (pos < fmt_end && *pos & 0x80) {
-        pos += 1;
-    }
-    if (pos < fmt_end && strchr("<>=^", *pos) != NULL) {
-        pos += 1;
-    } else {
-        /* fill not present-- skip over [align] */
-        pos = fmt;
-        if (pos < fmt_end && strchr("<>=^", *pos) != NULL) {
-            pos += 1;
-        }
-    }
-    /* skip over [sign] */
-    if (pos < fmt_end && strchr("+- ", *pos) != NULL) {
-        pos += 1;
-    }
-    return pos < fmt_end && *pos == 'z' ? pos : NULL;
-}
-
 static int
 dict_get_item_string(PyObject *dict, const char *key, PyObject **valueobj, const char **valuestr)
 {
@@ -3294,6 +3246,48 @@ dict_get_item_string(PyObject *dict, const char *key, PyObject **valueobj, const
     return 0;
 }
 
+/*
+ * Fallback _pydecimal formatting for new format specifiers that mpdecimal does
+ * not yet support. As documented, libmpdec follows the PEP-3101 format language:
+ * https://www.bytereef.org/mpdecimal/doc/libmpdec/assign-convert.html#to-string
+ */
+static PyObject *
+pydec_format(PyObject *dec, PyObject *context, PyObject *fmt)
+{
+    PyObject *result;
+    PyObject *pydec;
+    PyObject *u;
+
+    if (PyDecimal == NULL) {
+        PyDecimal = _PyImport_GetModuleAttrString("_pydecimal", "Decimal");
+        if (PyDecimal == NULL) {
+            return NULL;
+        }
+    }
+
+    u = dec_str(dec);
+    if (u == NULL) {
+        return NULL;
+    }
+
+    pydec = PyObject_CallOneArg(PyDecimal, u);
+    Py_DECREF(u);
+    if (pydec == NULL) {
+        return NULL;
+    }
+
+    result = PyObject_CallMethod(pydec, "__format__", "(OO)", fmt, context);
+    Py_DECREF(pydec);
+
+    if (result == NULL && PyErr_ExceptionMatches(PyExc_ValueError)) {
+        /* Do not confuse users with the _pydecimal exception */
+        PyErr_Clear();
+        PyErr_SetString(PyExc_ValueError, "invalid format string");
+    }
+
+    return result;
+}
+
 /* Formatted representation of a PyDecObject. */
 static PyObject *
 dec_format(PyObject *dec, PyObject *args)
@@ -3306,16 +3300,11 @@ dec_format(PyObject *dec, PyObject *args)
     PyObject *fmtarg;
     PyObject *context;
     mpd_spec_t spec;
-    char const *fmt;
-    char *fmt_copy = NULL;
+    char *fmt;
     char *decstring = NULL;
     uint32_t status = 0;
     int replace_fillchar = 0;
-    int no_neg_0 = 0;
     Py_ssize_t size;
-    mpd_t *mpd = MPD(dec);
-    mpd_uint_t dt[MPD_MINALLOC_MAX];
-    mpd_t tmp = {MPD_STATIC|MPD_STATIC_DATA,0,0,0,MPD_MINALLOC_MAX,dt};
 
 
     CURRENT_CONTEXT(context);
@@ -3324,39 +3313,20 @@ dec_format(PyObject *dec, PyObject *args)
     }
 
     if (PyUnicode_Check(fmtarg)) {
-        fmt = PyUnicode_AsUTF8AndSize(fmtarg, &size);
+        fmt = (char *)PyUnicode_AsUTF8AndSize(fmtarg, &size);
         if (fmt == NULL) {
             return NULL;
         }
-        /* NOTE: If https://github.com/python/cpython/pull/29438 lands, the
-         *   format string manipulation below can be eliminated by enhancing
-         *   the forked mpd_parse_fmt_str(). */
+
         if (size > 0 && fmt[0] == '\0') {
             /* NUL fill character: must be replaced with a valid UTF-8 char
                before calling mpd_parse_fmt_str(). */
             replace_fillchar = 1;
-            fmt = fmt_copy = dec_strdup(fmt, size);
-            if (fmt_copy == NULL) {
+            fmt = dec_strdup(fmt, size);
+            if (fmt == NULL) {
                 return NULL;
             }
-            fmt_copy[0] = '_';
-        }
-        /* Strip 'z' option, which isn't understood by mpd_parse_fmt_str().
-         * NOTE: fmt is always null terminated by PyUnicode_AsUTF8AndSize() */
-        char const *z_position = format_spec_z_search(fmt, size);
-        if (z_position != NULL) {
-            no_neg_0 = 1;
-            size_t z_index = z_position - fmt;
-            if (fmt_copy == NULL) {
-                fmt = fmt_copy = dec_strdup(fmt, size);
-                if (fmt_copy == NULL) {
-                    return NULL;
-                }
-            }
-            /* Shift characters (including null terminator) left,
-               overwriting the 'z' option. */
-            memmove(fmt_copy + z_index, fmt_copy + z_index + 1, size - z_index);
-            size -= 1;
+            fmt[0] = '_';
         }
     }
     else {
@@ -3366,10 +3336,13 @@ dec_format(PyObject *dec, PyObject *args)
     }
 
     if (!mpd_parse_fmt_str(&spec, fmt, CtxCaps(context))) {
-        PyErr_SetString(PyExc_ValueError,
-            "invalid format string");
-        goto finish;
+        if (replace_fillchar) {
+            PyMem_Free(fmt);
+        }
+
+        return pydec_format(dec, context, fmtarg);
     }
+
     if (replace_fillchar) {
         /* In order to avoid clobbering parts of UTF-8 thousands separators or
            decimal points when the substitution is reversed later, the actual
@@ -3422,45 +3395,8 @@ dec_format(PyObject *dec, PyObject *args)
         }
     }
 
-    if (no_neg_0 && mpd_isnegative(mpd) && !mpd_isspecial(mpd)) {
-        /* Round into a temporary (carefully mirroring the rounding
-           of mpd_qformat_spec()), and check if the result is negative zero.
-           If so, clear the sign and format the resulting positive zero. */
-        mpd_ssize_t prec;
-        mpd_qcopy(&tmp, mpd, &status);
-        if (spec.prec >= 0) {
-            switch (spec.type) {
-              case 'f':
-                  mpd_qrescale(&tmp, &tmp, -spec.prec, CTX(context), &status);
-                  break;
-              case '%':
-                  tmp.exp += 2;
-                  mpd_qrescale(&tmp, &tmp, -spec.prec, CTX(context), &status);
-                  break;
-              case 'g':
-                  prec = (spec.prec == 0) ? 1 : spec.prec;
-                  if (tmp.digits > prec) {
-                      _mpd_round(&tmp, &tmp, prec, CTX(context), &status);
-                  }
-                  break;
-              case 'e':
-                  if (!mpd_iszero(&tmp)) {
-                      _mpd_round(&tmp, &tmp, spec.prec+1, CTX(context), &status);
-                  }
-                  break;
-            }
-        }
-        if (status & MPD_Errors) {
-            PyErr_SetString(PyExc_ValueError, "unexpected error when rounding");
-            goto finish;
-        }
-        if (mpd_iszero(&tmp)) {
-            mpd_set_positive(&tmp);
-            mpd = &tmp;
-        }
-    }
 
-    decstring = mpd_qformat_spec(mpd, &spec, CTX(context), &status);
+    decstring = mpd_qformat_spec(MPD(dec), &spec, CTX(context), &status);
     if (decstring == NULL) {
         if (status & MPD_Malloc_error) {
             PyErr_NoMemory();
@@ -3483,7 +3419,7 @@ dec_format(PyObject *dec, PyObject *args)
     Py_XDECREF(grouping);
     Py_XDECREF(sep);
     Py_XDECREF(dot);
-    if (fmt_copy) PyMem_Free(fmt_copy);
+    if (replace_fillchar) PyMem_Free(fmt);
     if (decstring) mpd_free(decstring);
     return result;
 }
@@ -5893,6 +5829,9 @@ PyInit__decimal(void)
     /* Create the module */
     ASSIGN_PTR(m, PyModule_Create(&_decimal_module));
 
+    /* For format specifiers not yet supported by libmpdec */
+    PyDecimal = NULL;
+
     /* Add types to the module */
     CHECK_INT(PyModule_AddObjectRef(m, "Decimal", (PyObject *)&PyDec_Type));
     CHECK_INT(PyModule_AddObjectRef(m, "Context", (PyObject *)&PyDecContext_Type));
diff --git a/Modules/_elementtree.c b/Modules/_elementtree.c
index 620de8bb4c..fcd4be9338 100644
--- a/Modules/_elementtree.c
+++ b/Modules/_elementtree.c
@@ -3895,6 +3895,40 @@ _elementtree_XMLParser_close_impl(XMLParserObject *self)
     }
 }
 
+/*[clinic input]
+_elementtree.XMLParser.flush
+
+[clinic start generated code]*/
+
+static PyObject *
+_elementtree_XMLParser_flush_impl(XMLParserObject *self)
+/*[clinic end generated code: output=42fdb8795ca24509 input=effbecdb28715949]*/
+{
+    if (!_check_xmlparser(self)) {
+        return NULL;
+    }
+
+    elementtreestate *st = self->state;
+
+    if (EXPAT(st, SetReparseDeferralEnabled) == NULL) {
+        Py_RETURN_NONE;
+    }
+
+    // NOTE: The Expat parser in the C implementation of ElementTree is not
+    //       exposed to the outside; as a result we known that reparse deferral
+    //       is currently enabled, or we would not even have access to function
+    //       XML_SetReparseDeferralEnabled in the first place (which we checked
+    //       for, a few lines up).
+
+    EXPAT(st, SetReparseDeferralEnabled)(self->parser, XML_FALSE);
+
+    PyObject *res = expat_parse(st, self, "", 0, XML_FALSE);
+
+    EXPAT(st, SetReparseDeferralEnabled)(self->parser, XML_TRUE);
+
+    return res;
+}
+
 /*[clinic input]
 _elementtree.XMLParser.feed
 
@@ -4289,6 +4323,7 @@ static PyType_Spec treebuilder_spec = {
 static PyMethodDef xmlparser_methods[] = {
     _ELEMENTTREE_XMLPARSER_FEED_METHODDEF
     _ELEMENTTREE_XMLPARSER_CLOSE_METHODDEF
+    _ELEMENTTREE_XMLPARSER_FLUSH_METHODDEF
     _ELEMENTTREE_XMLPARSER__PARSE_WHOLE_METHODDEF
     _ELEMENTTREE_XMLPARSER__SETEVENTS_METHODDEF
     {NULL, NULL}
diff --git a/Modules/_hacl/Hacl_Hash_MD5.c b/Modules/_hacl/Hacl_Hash_MD5.c
index 222ac824f0..ed294839ed 100644
--- a/Modules/_hacl/Hacl_Hash_MD5.c
+++ b/Modules/_hacl/Hacl_Hash_MD5.c
@@ -25,37 +25,29 @@
 
 #include "internal/Hacl_Hash_MD5.h"
 
-static uint32_t
-_h0[4U] =
-  { (uint32_t)0x67452301U, (uint32_t)0xefcdab89U, (uint32_t)0x98badcfeU, (uint32_t)0x10325476U };
+static uint32_t _h0[4U] = { 0x67452301U, 0xefcdab89U, 0x98badcfeU, 0x10325476U };
 
 static uint32_t
 _t[64U] =
   {
-    (uint32_t)0xd76aa478U, (uint32_t)0xe8c7b756U, (uint32_t)0x242070dbU, (uint32_t)0xc1bdceeeU,
-    (uint32_t)0xf57c0fafU, (uint32_t)0x4787c62aU, (uint32_t)0xa8304613U, (uint32_t)0xfd469501U,
-    (uint32_t)0x698098d8U, (uint32_t)0x8b44f7afU, (uint32_t)0xffff5bb1U, (uint32_t)0x895cd7beU,
-    (uint32_t)0x6b901122U, (uint32_t)0xfd987193U, (uint32_t)0xa679438eU, (uint32_t)0x49b40821U,
-    (uint32_t)0xf61e2562U, (uint32_t)0xc040b340U, (uint32_t)0x265e5a51U, (uint32_t)0xe9b6c7aaU,
-    (uint32_t)0xd62f105dU, (uint32_t)0x02441453U, (uint32_t)0xd8a1e681U, (uint32_t)0xe7d3fbc8U,
-    (uint32_t)0x21e1cde6U, (uint32_t)0xc33707d6U, (uint32_t)0xf4d50d87U, (uint32_t)0x455a14edU,
-    (uint32_t)0xa9e3e905U, (uint32_t)0xfcefa3f8U, (uint32_t)0x676f02d9U, (uint32_t)0x8d2a4c8aU,
-    (uint32_t)0xfffa3942U, (uint32_t)0x8771f681U, (uint32_t)0x6d9d6122U, (uint32_t)0xfde5380cU,
-    (uint32_t)0xa4beea44U, (uint32_t)0x4bdecfa9U, (uint32_t)0xf6bb4b60U, (uint32_t)0xbebfbc70U,
-    (uint32_t)0x289b7ec6U, (uint32_t)0xeaa127faU, (uint32_t)0xd4ef3085U, (uint32_t)0x4881d05U,
-    (uint32_t)0xd9d4d039U, (uint32_t)0xe6db99e5U, (uint32_t)0x1fa27cf8U, (uint32_t)0xc4ac5665U,
-    (uint32_t)0xf4292244U, (uint32_t)0x432aff97U, (uint32_t)0xab9423a7U, (uint32_t)0xfc93a039U,
-    (uint32_t)0x655b59c3U, (uint32_t)0x8f0ccc92U, (uint32_t)0xffeff47dU, (uint32_t)0x85845dd1U,
-    (uint32_t)0x6fa87e4fU, (uint32_t)0xfe2ce6e0U, (uint32_t)0xa3014314U, (uint32_t)0x4e0811a1U,
-    (uint32_t)0xf7537e82U, (uint32_t)0xbd3af235U, (uint32_t)0x2ad7d2bbU, (uint32_t)0xeb86d391U
+    0xd76aa478U, 0xe8c7b756U, 0x242070dbU, 0xc1bdceeeU, 0xf57c0fafU, 0x4787c62aU, 0xa8304613U,
+    0xfd469501U, 0x698098d8U, 0x8b44f7afU, 0xffff5bb1U, 0x895cd7beU, 0x6b901122U, 0xfd987193U,
+    0xa679438eU, 0x49b40821U, 0xf61e2562U, 0xc040b340U, 0x265e5a51U, 0xe9b6c7aaU, 0xd62f105dU,
+    0x02441453U, 0xd8a1e681U, 0xe7d3fbc8U, 0x21e1cde6U, 0xc33707d6U, 0xf4d50d87U, 0x455a14edU,
+    0xa9e3e905U, 0xfcefa3f8U, 0x676f02d9U, 0x8d2a4c8aU, 0xfffa3942U, 0x8771f681U, 0x6d9d6122U,
+    0xfde5380cU, 0xa4beea44U, 0x4bdecfa9U, 0xf6bb4b60U, 0xbebfbc70U, 0x289b7ec6U, 0xeaa127faU,
+    0xd4ef3085U, 0x4881d05U, 0xd9d4d039U, 0xe6db99e5U, 0x1fa27cf8U, 0xc4ac5665U, 0xf4292244U,
+    0x432aff97U, 0xab9423a7U, 0xfc93a039U, 0x655b59c3U, 0x8f0ccc92U, 0xffeff47dU, 0x85845dd1U,
+    0x6fa87e4fU, 0xfe2ce6e0U, 0xa3014314U, 0x4e0811a1U, 0xf7537e82U, 0xbd3af235U, 0x2ad7d2bbU,
+    0xeb86d391U
   };
 
-void Hacl_Hash_Core_MD5_legacy_init(uint32_t *s)
+void Hacl_Hash_MD5_init(uint32_t *s)
 {
-  KRML_MAYBE_FOR4(i, (uint32_t)0U, (uint32_t)4U, (uint32_t)1U, s[i] = _h0[i];);
+  KRML_MAYBE_FOR4(i, 0U, 4U, 1U, s[i] = _h0[i];);
 }
 
-static void legacy_update(uint32_t *abcd, uint8_t *x)
+static void update(uint32_t *abcd, uint8_t *x)
 {
   uint32_t aa = abcd[0U];
   uint32_t bb = abcd[1U];
@@ -74,14 +66,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb0
     +
       ((va + ((vb0 & vc0) | (~vb0 & vd0)) + xk + ti0)
-      << (uint32_t)7U
-      | (va + ((vb0 & vc0) | (~vb0 & vd0)) + xk + ti0) >> (uint32_t)25U);
+      << 7U
+      | (va + ((vb0 & vc0) | (~vb0 & vd0)) + xk + ti0) >> 25U);
   abcd[0U] = v;
   uint32_t va0 = abcd[3U];
   uint32_t vb1 = abcd[0U];
   uint32_t vc1 = abcd[1U];
   uint32_t vd1 = abcd[2U];
-  uint8_t *b1 = x + (uint32_t)4U;
+  uint8_t *b1 = x + 4U;
   uint32_t u0 = load32_le(b1);
   uint32_t xk0 = u0;
   uint32_t ti1 = _t[1U];
@@ -90,14 +82,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb1
     +
       ((va0 + ((vb1 & vc1) | (~vb1 & vd1)) + xk0 + ti1)
-      << (uint32_t)12U
-      | (va0 + ((vb1 & vc1) | (~vb1 & vd1)) + xk0 + ti1) >> (uint32_t)20U);
+      << 12U
+      | (va0 + ((vb1 & vc1) | (~vb1 & vd1)) + xk0 + ti1) >> 20U);
   abcd[3U] = v0;
   uint32_t va1 = abcd[2U];
   uint32_t vb2 = abcd[3U];
   uint32_t vc2 = abcd[0U];
   uint32_t vd2 = abcd[1U];
-  uint8_t *b2 = x + (uint32_t)8U;
+  uint8_t *b2 = x + 8U;
   uint32_t u1 = load32_le(b2);
   uint32_t xk1 = u1;
   uint32_t ti2 = _t[2U];
@@ -106,14 +98,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb2
     +
       ((va1 + ((vb2 & vc2) | (~vb2 & vd2)) + xk1 + ti2)
-      << (uint32_t)17U
-      | (va1 + ((vb2 & vc2) | (~vb2 & vd2)) + xk1 + ti2) >> (uint32_t)15U);
+      << 17U
+      | (va1 + ((vb2 & vc2) | (~vb2 & vd2)) + xk1 + ti2) >> 15U);
   abcd[2U] = v1;
   uint32_t va2 = abcd[1U];
   uint32_t vb3 = abcd[2U];
   uint32_t vc3 = abcd[3U];
   uint32_t vd3 = abcd[0U];
-  uint8_t *b3 = x + (uint32_t)12U;
+  uint8_t *b3 = x + 12U;
   uint32_t u2 = load32_le(b3);
   uint32_t xk2 = u2;
   uint32_t ti3 = _t[3U];
@@ -122,14 +114,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb3
     +
       ((va2 + ((vb3 & vc3) | (~vb3 & vd3)) + xk2 + ti3)
-      << (uint32_t)22U
-      | (va2 + ((vb3 & vc3) | (~vb3 & vd3)) + xk2 + ti3) >> (uint32_t)10U);
+      << 22U
+      | (va2 + ((vb3 & vc3) | (~vb3 & vd3)) + xk2 + ti3) >> 10U);
   abcd[1U] = v2;
   uint32_t va3 = abcd[0U];
   uint32_t vb4 = abcd[1U];
   uint32_t vc4 = abcd[2U];
   uint32_t vd4 = abcd[3U];
-  uint8_t *b4 = x + (uint32_t)16U;
+  uint8_t *b4 = x + 16U;
   uint32_t u3 = load32_le(b4);
   uint32_t xk3 = u3;
   uint32_t ti4 = _t[4U];
@@ -138,14 +130,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb4
     +
       ((va3 + ((vb4 & vc4) | (~vb4 & vd4)) + xk3 + ti4)
-      << (uint32_t)7U
-      | (va3 + ((vb4 & vc4) | (~vb4 & vd4)) + xk3 + ti4) >> (uint32_t)25U);
+      << 7U
+      | (va3 + ((vb4 & vc4) | (~vb4 & vd4)) + xk3 + ti4) >> 25U);
   abcd[0U] = v3;
   uint32_t va4 = abcd[3U];
   uint32_t vb5 = abcd[0U];
   uint32_t vc5 = abcd[1U];
   uint32_t vd5 = abcd[2U];
-  uint8_t *b5 = x + (uint32_t)20U;
+  uint8_t *b5 = x + 20U;
   uint32_t u4 = load32_le(b5);
   uint32_t xk4 = u4;
   uint32_t ti5 = _t[5U];
@@ -154,14 +146,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb5
     +
       ((va4 + ((vb5 & vc5) | (~vb5 & vd5)) + xk4 + ti5)
-      << (uint32_t)12U
-      | (va4 + ((vb5 & vc5) | (~vb5 & vd5)) + xk4 + ti5) >> (uint32_t)20U);
+      << 12U
+      | (va4 + ((vb5 & vc5) | (~vb5 & vd5)) + xk4 + ti5) >> 20U);
   abcd[3U] = v4;
   uint32_t va5 = abcd[2U];
   uint32_t vb6 = abcd[3U];
   uint32_t vc6 = abcd[0U];
   uint32_t vd6 = abcd[1U];
-  uint8_t *b6 = x + (uint32_t)24U;
+  uint8_t *b6 = x + 24U;
   uint32_t u5 = load32_le(b6);
   uint32_t xk5 = u5;
   uint32_t ti6 = _t[6U];
@@ -170,14 +162,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb6
     +
       ((va5 + ((vb6 & vc6) | (~vb6 & vd6)) + xk5 + ti6)
-      << (uint32_t)17U
-      | (va5 + ((vb6 & vc6) | (~vb6 & vd6)) + xk5 + ti6) >> (uint32_t)15U);
+      << 17U
+      | (va5 + ((vb6 & vc6) | (~vb6 & vd6)) + xk5 + ti6) >> 15U);
   abcd[2U] = v5;
   uint32_t va6 = abcd[1U];
   uint32_t vb7 = abcd[2U];
   uint32_t vc7 = abcd[3U];
   uint32_t vd7 = abcd[0U];
-  uint8_t *b7 = x + (uint32_t)28U;
+  uint8_t *b7 = x + 28U;
   uint32_t u6 = load32_le(b7);
   uint32_t xk6 = u6;
   uint32_t ti7 = _t[7U];
@@ -186,14 +178,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb7
     +
       ((va6 + ((vb7 & vc7) | (~vb7 & vd7)) + xk6 + ti7)
-      << (uint32_t)22U
-      | (va6 + ((vb7 & vc7) | (~vb7 & vd7)) + xk6 + ti7) >> (uint32_t)10U);
+      << 22U
+      | (va6 + ((vb7 & vc7) | (~vb7 & vd7)) + xk6 + ti7) >> 10U);
   abcd[1U] = v6;
   uint32_t va7 = abcd[0U];
   uint32_t vb8 = abcd[1U];
   uint32_t vc8 = abcd[2U];
   uint32_t vd8 = abcd[3U];
-  uint8_t *b8 = x + (uint32_t)32U;
+  uint8_t *b8 = x + 32U;
   uint32_t u7 = load32_le(b8);
   uint32_t xk7 = u7;
   uint32_t ti8 = _t[8U];
@@ -202,14 +194,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb8
     +
       ((va7 + ((vb8 & vc8) | (~vb8 & vd8)) + xk7 + ti8)
-      << (uint32_t)7U
-      | (va7 + ((vb8 & vc8) | (~vb8 & vd8)) + xk7 + ti8) >> (uint32_t)25U);
+      << 7U
+      | (va7 + ((vb8 & vc8) | (~vb8 & vd8)) + xk7 + ti8) >> 25U);
   abcd[0U] = v7;
   uint32_t va8 = abcd[3U];
   uint32_t vb9 = abcd[0U];
   uint32_t vc9 = abcd[1U];
   uint32_t vd9 = abcd[2U];
-  uint8_t *b9 = x + (uint32_t)36U;
+  uint8_t *b9 = x + 36U;
   uint32_t u8 = load32_le(b9);
   uint32_t xk8 = u8;
   uint32_t ti9 = _t[9U];
@@ -218,14 +210,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb9
     +
       ((va8 + ((vb9 & vc9) | (~vb9 & vd9)) + xk8 + ti9)
-      << (uint32_t)12U
-      | (va8 + ((vb9 & vc9) | (~vb9 & vd9)) + xk8 + ti9) >> (uint32_t)20U);
+      << 12U
+      | (va8 + ((vb9 & vc9) | (~vb9 & vd9)) + xk8 + ti9) >> 20U);
   abcd[3U] = v8;
   uint32_t va9 = abcd[2U];
   uint32_t vb10 = abcd[3U];
   uint32_t vc10 = abcd[0U];
   uint32_t vd10 = abcd[1U];
-  uint8_t *b10 = x + (uint32_t)40U;
+  uint8_t *b10 = x + 40U;
   uint32_t u9 = load32_le(b10);
   uint32_t xk9 = u9;
   uint32_t ti10 = _t[10U];
@@ -234,14 +226,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb10
     +
       ((va9 + ((vb10 & vc10) | (~vb10 & vd10)) + xk9 + ti10)
-      << (uint32_t)17U
-      | (va9 + ((vb10 & vc10) | (~vb10 & vd10)) + xk9 + ti10) >> (uint32_t)15U);
+      << 17U
+      | (va9 + ((vb10 & vc10) | (~vb10 & vd10)) + xk9 + ti10) >> 15U);
   abcd[2U] = v9;
   uint32_t va10 = abcd[1U];
   uint32_t vb11 = abcd[2U];
   uint32_t vc11 = abcd[3U];
   uint32_t vd11 = abcd[0U];
-  uint8_t *b11 = x + (uint32_t)44U;
+  uint8_t *b11 = x + 44U;
   uint32_t u10 = load32_le(b11);
   uint32_t xk10 = u10;
   uint32_t ti11 = _t[11U];
@@ -250,14 +242,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb11
     +
       ((va10 + ((vb11 & vc11) | (~vb11 & vd11)) + xk10 + ti11)
-      << (uint32_t)22U
-      | (va10 + ((vb11 & vc11) | (~vb11 & vd11)) + xk10 + ti11) >> (uint32_t)10U);
+      << 22U
+      | (va10 + ((vb11 & vc11) | (~vb11 & vd11)) + xk10 + ti11) >> 10U);
   abcd[1U] = v10;
   uint32_t va11 = abcd[0U];
   uint32_t vb12 = abcd[1U];
   uint32_t vc12 = abcd[2U];
   uint32_t vd12 = abcd[3U];
-  uint8_t *b12 = x + (uint32_t)48U;
+  uint8_t *b12 = x + 48U;
   uint32_t u11 = load32_le(b12);
   uint32_t xk11 = u11;
   uint32_t ti12 = _t[12U];
@@ -266,14 +258,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb12
     +
       ((va11 + ((vb12 & vc12) | (~vb12 & vd12)) + xk11 + ti12)
-      << (uint32_t)7U
-      | (va11 + ((vb12 & vc12) | (~vb12 & vd12)) + xk11 + ti12) >> (uint32_t)25U);
+      << 7U
+      | (va11 + ((vb12 & vc12) | (~vb12 & vd12)) + xk11 + ti12) >> 25U);
   abcd[0U] = v11;
   uint32_t va12 = abcd[3U];
   uint32_t vb13 = abcd[0U];
   uint32_t vc13 = abcd[1U];
   uint32_t vd13 = abcd[2U];
-  uint8_t *b13 = x + (uint32_t)52U;
+  uint8_t *b13 = x + 52U;
   uint32_t u12 = load32_le(b13);
   uint32_t xk12 = u12;
   uint32_t ti13 = _t[13U];
@@ -282,14 +274,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb13
     +
       ((va12 + ((vb13 & vc13) | (~vb13 & vd13)) + xk12 + ti13)
-      << (uint32_t)12U
-      | (va12 + ((vb13 & vc13) | (~vb13 & vd13)) + xk12 + ti13) >> (uint32_t)20U);
+      << 12U
+      | (va12 + ((vb13 & vc13) | (~vb13 & vd13)) + xk12 + ti13) >> 20U);
   abcd[3U] = v12;
   uint32_t va13 = abcd[2U];
   uint32_t vb14 = abcd[3U];
   uint32_t vc14 = abcd[0U];
   uint32_t vd14 = abcd[1U];
-  uint8_t *b14 = x + (uint32_t)56U;
+  uint8_t *b14 = x + 56U;
   uint32_t u13 = load32_le(b14);
   uint32_t xk13 = u13;
   uint32_t ti14 = _t[14U];
@@ -298,14 +290,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb14
     +
       ((va13 + ((vb14 & vc14) | (~vb14 & vd14)) + xk13 + ti14)
-      << (uint32_t)17U
-      | (va13 + ((vb14 & vc14) | (~vb14 & vd14)) + xk13 + ti14) >> (uint32_t)15U);
+      << 17U
+      | (va13 + ((vb14 & vc14) | (~vb14 & vd14)) + xk13 + ti14) >> 15U);
   abcd[2U] = v13;
   uint32_t va14 = abcd[1U];
   uint32_t vb15 = abcd[2U];
   uint32_t vc15 = abcd[3U];
   uint32_t vd15 = abcd[0U];
-  uint8_t *b15 = x + (uint32_t)60U;
+  uint8_t *b15 = x + 60U;
   uint32_t u14 = load32_le(b15);
   uint32_t xk14 = u14;
   uint32_t ti15 = _t[15U];
@@ -314,14 +306,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb15
     +
       ((va14 + ((vb15 & vc15) | (~vb15 & vd15)) + xk14 + ti15)
-      << (uint32_t)22U
-      | (va14 + ((vb15 & vc15) | (~vb15 & vd15)) + xk14 + ti15) >> (uint32_t)10U);
+      << 22U
+      | (va14 + ((vb15 & vc15) | (~vb15 & vd15)) + xk14 + ti15) >> 10U);
   abcd[1U] = v14;
   uint32_t va15 = abcd[0U];
   uint32_t vb16 = abcd[1U];
   uint32_t vc16 = abcd[2U];
   uint32_t vd16 = abcd[3U];
-  uint8_t *b16 = x + (uint32_t)4U;
+  uint8_t *b16 = x + 4U;
   uint32_t u15 = load32_le(b16);
   uint32_t xk15 = u15;
   uint32_t ti16 = _t[16U];
@@ -330,14 +322,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb16
     +
       ((va15 + ((vb16 & vd16) | (vc16 & ~vd16)) + xk15 + ti16)
-      << (uint32_t)5U
-      | (va15 + ((vb16 & vd16) | (vc16 & ~vd16)) + xk15 + ti16) >> (uint32_t)27U);
+      << 5U
+      | (va15 + ((vb16 & vd16) | (vc16 & ~vd16)) + xk15 + ti16) >> 27U);
   abcd[0U] = v15;
   uint32_t va16 = abcd[3U];
   uint32_t vb17 = abcd[0U];
   uint32_t vc17 = abcd[1U];
   uint32_t vd17 = abcd[2U];
-  uint8_t *b17 = x + (uint32_t)24U;
+  uint8_t *b17 = x + 24U;
   uint32_t u16 = load32_le(b17);
   uint32_t xk16 = u16;
   uint32_t ti17 = _t[17U];
@@ -346,14 +338,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb17
     +
       ((va16 + ((vb17 & vd17) | (vc17 & ~vd17)) + xk16 + ti17)
-      << (uint32_t)9U
-      | (va16 + ((vb17 & vd17) | (vc17 & ~vd17)) + xk16 + ti17) >> (uint32_t)23U);
+      << 9U
+      | (va16 + ((vb17 & vd17) | (vc17 & ~vd17)) + xk16 + ti17) >> 23U);
   abcd[3U] = v16;
   uint32_t va17 = abcd[2U];
   uint32_t vb18 = abcd[3U];
   uint32_t vc18 = abcd[0U];
   uint32_t vd18 = abcd[1U];
-  uint8_t *b18 = x + (uint32_t)44U;
+  uint8_t *b18 = x + 44U;
   uint32_t u17 = load32_le(b18);
   uint32_t xk17 = u17;
   uint32_t ti18 = _t[18U];
@@ -362,8 +354,8 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb18
     +
       ((va17 + ((vb18 & vd18) | (vc18 & ~vd18)) + xk17 + ti18)
-      << (uint32_t)14U
-      | (va17 + ((vb18 & vd18) | (vc18 & ~vd18)) + xk17 + ti18) >> (uint32_t)18U);
+      << 14U
+      | (va17 + ((vb18 & vd18) | (vc18 & ~vd18)) + xk17 + ti18) >> 18U);
   abcd[2U] = v17;
   uint32_t va18 = abcd[1U];
   uint32_t vb19 = abcd[2U];
@@ -378,14 +370,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb19
     +
       ((va18 + ((vb19 & vd19) | (vc19 & ~vd19)) + xk18 + ti19)
-      << (uint32_t)20U
-      | (va18 + ((vb19 & vd19) | (vc19 & ~vd19)) + xk18 + ti19) >> (uint32_t)12U);
+      << 20U
+      | (va18 + ((vb19 & vd19) | (vc19 & ~vd19)) + xk18 + ti19) >> 12U);
   abcd[1U] = v18;
   uint32_t va19 = abcd[0U];
   uint32_t vb20 = abcd[1U];
   uint32_t vc20 = abcd[2U];
   uint32_t vd20 = abcd[3U];
-  uint8_t *b20 = x + (uint32_t)20U;
+  uint8_t *b20 = x + 20U;
   uint32_t u19 = load32_le(b20);
   uint32_t xk19 = u19;
   uint32_t ti20 = _t[20U];
@@ -394,14 +386,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb20
     +
       ((va19 + ((vb20 & vd20) | (vc20 & ~vd20)) + xk19 + ti20)
-      << (uint32_t)5U
-      | (va19 + ((vb20 & vd20) | (vc20 & ~vd20)) + xk19 + ti20) >> (uint32_t)27U);
+      << 5U
+      | (va19 + ((vb20 & vd20) | (vc20 & ~vd20)) + xk19 + ti20) >> 27U);
   abcd[0U] = v19;
   uint32_t va20 = abcd[3U];
   uint32_t vb21 = abcd[0U];
   uint32_t vc21 = abcd[1U];
   uint32_t vd21 = abcd[2U];
-  uint8_t *b21 = x + (uint32_t)40U;
+  uint8_t *b21 = x + 40U;
   uint32_t u20 = load32_le(b21);
   uint32_t xk20 = u20;
   uint32_t ti21 = _t[21U];
@@ -410,14 +402,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb21
     +
       ((va20 + ((vb21 & vd21) | (vc21 & ~vd21)) + xk20 + ti21)
-      << (uint32_t)9U
-      | (va20 + ((vb21 & vd21) | (vc21 & ~vd21)) + xk20 + ti21) >> (uint32_t)23U);
+      << 9U
+      | (va20 + ((vb21 & vd21) | (vc21 & ~vd21)) + xk20 + ti21) >> 23U);
   abcd[3U] = v20;
   uint32_t va21 = abcd[2U];
   uint32_t vb22 = abcd[3U];
   uint32_t vc22 = abcd[0U];
   uint32_t vd22 = abcd[1U];
-  uint8_t *b22 = x + (uint32_t)60U;
+  uint8_t *b22 = x + 60U;
   uint32_t u21 = load32_le(b22);
   uint32_t xk21 = u21;
   uint32_t ti22 = _t[22U];
@@ -426,14 +418,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb22
     +
       ((va21 + ((vb22 & vd22) | (vc22 & ~vd22)) + xk21 + ti22)
-      << (uint32_t)14U
-      | (va21 + ((vb22 & vd22) | (vc22 & ~vd22)) + xk21 + ti22) >> (uint32_t)18U);
+      << 14U
+      | (va21 + ((vb22 & vd22) | (vc22 & ~vd22)) + xk21 + ti22) >> 18U);
   abcd[2U] = v21;
   uint32_t va22 = abcd[1U];
   uint32_t vb23 = abcd[2U];
   uint32_t vc23 = abcd[3U];
   uint32_t vd23 = abcd[0U];
-  uint8_t *b23 = x + (uint32_t)16U;
+  uint8_t *b23 = x + 16U;
   uint32_t u22 = load32_le(b23);
   uint32_t xk22 = u22;
   uint32_t ti23 = _t[23U];
@@ -442,14 +434,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb23
     +
       ((va22 + ((vb23 & vd23) | (vc23 & ~vd23)) + xk22 + ti23)
-      << (uint32_t)20U
-      | (va22 + ((vb23 & vd23) | (vc23 & ~vd23)) + xk22 + ti23) >> (uint32_t)12U);
+      << 20U
+      | (va22 + ((vb23 & vd23) | (vc23 & ~vd23)) + xk22 + ti23) >> 12U);
   abcd[1U] = v22;
   uint32_t va23 = abcd[0U];
   uint32_t vb24 = abcd[1U];
   uint32_t vc24 = abcd[2U];
   uint32_t vd24 = abcd[3U];
-  uint8_t *b24 = x + (uint32_t)36U;
+  uint8_t *b24 = x + 36U;
   uint32_t u23 = load32_le(b24);
   uint32_t xk23 = u23;
   uint32_t ti24 = _t[24U];
@@ -458,14 +450,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb24
     +
       ((va23 + ((vb24 & vd24) | (vc24 & ~vd24)) + xk23 + ti24)
-      << (uint32_t)5U
-      | (va23 + ((vb24 & vd24) | (vc24 & ~vd24)) + xk23 + ti24) >> (uint32_t)27U);
+      << 5U
+      | (va23 + ((vb24 & vd24) | (vc24 & ~vd24)) + xk23 + ti24) >> 27U);
   abcd[0U] = v23;
   uint32_t va24 = abcd[3U];
   uint32_t vb25 = abcd[0U];
   uint32_t vc25 = abcd[1U];
   uint32_t vd25 = abcd[2U];
-  uint8_t *b25 = x + (uint32_t)56U;
+  uint8_t *b25 = x + 56U;
   uint32_t u24 = load32_le(b25);
   uint32_t xk24 = u24;
   uint32_t ti25 = _t[25U];
@@ -474,14 +466,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb25
     +
       ((va24 + ((vb25 & vd25) | (vc25 & ~vd25)) + xk24 + ti25)
-      << (uint32_t)9U
-      | (va24 + ((vb25 & vd25) | (vc25 & ~vd25)) + xk24 + ti25) >> (uint32_t)23U);
+      << 9U
+      | (va24 + ((vb25 & vd25) | (vc25 & ~vd25)) + xk24 + ti25) >> 23U);
   abcd[3U] = v24;
   uint32_t va25 = abcd[2U];
   uint32_t vb26 = abcd[3U];
   uint32_t vc26 = abcd[0U];
   uint32_t vd26 = abcd[1U];
-  uint8_t *b26 = x + (uint32_t)12U;
+  uint8_t *b26 = x + 12U;
   uint32_t u25 = load32_le(b26);
   uint32_t xk25 = u25;
   uint32_t ti26 = _t[26U];
@@ -490,14 +482,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb26
     +
       ((va25 + ((vb26 & vd26) | (vc26 & ~vd26)) + xk25 + ti26)
-      << (uint32_t)14U
-      | (va25 + ((vb26 & vd26) | (vc26 & ~vd26)) + xk25 + ti26) >> (uint32_t)18U);
+      << 14U
+      | (va25 + ((vb26 & vd26) | (vc26 & ~vd26)) + xk25 + ti26) >> 18U);
   abcd[2U] = v25;
   uint32_t va26 = abcd[1U];
   uint32_t vb27 = abcd[2U];
   uint32_t vc27 = abcd[3U];
   uint32_t vd27 = abcd[0U];
-  uint8_t *b27 = x + (uint32_t)32U;
+  uint8_t *b27 = x + 32U;
   uint32_t u26 = load32_le(b27);
   uint32_t xk26 = u26;
   uint32_t ti27 = _t[27U];
@@ -506,14 +498,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb27
     +
       ((va26 + ((vb27 & vd27) | (vc27 & ~vd27)) + xk26 + ti27)
-      << (uint32_t)20U
-      | (va26 + ((vb27 & vd27) | (vc27 & ~vd27)) + xk26 + ti27) >> (uint32_t)12U);
+      << 20U
+      | (va26 + ((vb27 & vd27) | (vc27 & ~vd27)) + xk26 + ti27) >> 12U);
   abcd[1U] = v26;
   uint32_t va27 = abcd[0U];
   uint32_t vb28 = abcd[1U];
   uint32_t vc28 = abcd[2U];
   uint32_t vd28 = abcd[3U];
-  uint8_t *b28 = x + (uint32_t)52U;
+  uint8_t *b28 = x + 52U;
   uint32_t u27 = load32_le(b28);
   uint32_t xk27 = u27;
   uint32_t ti28 = _t[28U];
@@ -522,14 +514,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb28
     +
       ((va27 + ((vb28 & vd28) | (vc28 & ~vd28)) + xk27 + ti28)
-      << (uint32_t)5U
-      | (va27 + ((vb28 & vd28) | (vc28 & ~vd28)) + xk27 + ti28) >> (uint32_t)27U);
+      << 5U
+      | (va27 + ((vb28 & vd28) | (vc28 & ~vd28)) + xk27 + ti28) >> 27U);
   abcd[0U] = v27;
   uint32_t va28 = abcd[3U];
   uint32_t vb29 = abcd[0U];
   uint32_t vc29 = abcd[1U];
   uint32_t vd29 = abcd[2U];
-  uint8_t *b29 = x + (uint32_t)8U;
+  uint8_t *b29 = x + 8U;
   uint32_t u28 = load32_le(b29);
   uint32_t xk28 = u28;
   uint32_t ti29 = _t[29U];
@@ -538,14 +530,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb29
     +
       ((va28 + ((vb29 & vd29) | (vc29 & ~vd29)) + xk28 + ti29)
-      << (uint32_t)9U
-      | (va28 + ((vb29 & vd29) | (vc29 & ~vd29)) + xk28 + ti29) >> (uint32_t)23U);
+      << 9U
+      | (va28 + ((vb29 & vd29) | (vc29 & ~vd29)) + xk28 + ti29) >> 23U);
   abcd[3U] = v28;
   uint32_t va29 = abcd[2U];
   uint32_t vb30 = abcd[3U];
   uint32_t vc30 = abcd[0U];
   uint32_t vd30 = abcd[1U];
-  uint8_t *b30 = x + (uint32_t)28U;
+  uint8_t *b30 = x + 28U;
   uint32_t u29 = load32_le(b30);
   uint32_t xk29 = u29;
   uint32_t ti30 = _t[30U];
@@ -554,14 +546,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb30
     +
       ((va29 + ((vb30 & vd30) | (vc30 & ~vd30)) + xk29 + ti30)
-      << (uint32_t)14U
-      | (va29 + ((vb30 & vd30) | (vc30 & ~vd30)) + xk29 + ti30) >> (uint32_t)18U);
+      << 14U
+      | (va29 + ((vb30 & vd30) | (vc30 & ~vd30)) + xk29 + ti30) >> 18U);
   abcd[2U] = v29;
   uint32_t va30 = abcd[1U];
   uint32_t vb31 = abcd[2U];
   uint32_t vc31 = abcd[3U];
   uint32_t vd31 = abcd[0U];
-  uint8_t *b31 = x + (uint32_t)48U;
+  uint8_t *b31 = x + 48U;
   uint32_t u30 = load32_le(b31);
   uint32_t xk30 = u30;
   uint32_t ti31 = _t[31U];
@@ -570,14 +562,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb31
     +
       ((va30 + ((vb31 & vd31) | (vc31 & ~vd31)) + xk30 + ti31)
-      << (uint32_t)20U
-      | (va30 + ((vb31 & vd31) | (vc31 & ~vd31)) + xk30 + ti31) >> (uint32_t)12U);
+      << 20U
+      | (va30 + ((vb31 & vd31) | (vc31 & ~vd31)) + xk30 + ti31) >> 12U);
   abcd[1U] = v30;
   uint32_t va31 = abcd[0U];
   uint32_t vb32 = abcd[1U];
   uint32_t vc32 = abcd[2U];
   uint32_t vd32 = abcd[3U];
-  uint8_t *b32 = x + (uint32_t)20U;
+  uint8_t *b32 = x + 20U;
   uint32_t u31 = load32_le(b32);
   uint32_t xk31 = u31;
   uint32_t ti32 = _t[32U];
@@ -586,14 +578,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb32
     +
       ((va31 + (vb32 ^ (vc32 ^ vd32)) + xk31 + ti32)
-      << (uint32_t)4U
-      | (va31 + (vb32 ^ (vc32 ^ vd32)) + xk31 + ti32) >> (uint32_t)28U);
+      << 4U
+      | (va31 + (vb32 ^ (vc32 ^ vd32)) + xk31 + ti32) >> 28U);
   abcd[0U] = v31;
   uint32_t va32 = abcd[3U];
   uint32_t vb33 = abcd[0U];
   uint32_t vc33 = abcd[1U];
   uint32_t vd33 = abcd[2U];
-  uint8_t *b33 = x + (uint32_t)32U;
+  uint8_t *b33 = x + 32U;
   uint32_t u32 = load32_le(b33);
   uint32_t xk32 = u32;
   uint32_t ti33 = _t[33U];
@@ -602,14 +594,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb33
     +
       ((va32 + (vb33 ^ (vc33 ^ vd33)) + xk32 + ti33)
-      << (uint32_t)11U
-      | (va32 + (vb33 ^ (vc33 ^ vd33)) + xk32 + ti33) >> (uint32_t)21U);
+      << 11U
+      | (va32 + (vb33 ^ (vc33 ^ vd33)) + xk32 + ti33) >> 21U);
   abcd[3U] = v32;
   uint32_t va33 = abcd[2U];
   uint32_t vb34 = abcd[3U];
   uint32_t vc34 = abcd[0U];
   uint32_t vd34 = abcd[1U];
-  uint8_t *b34 = x + (uint32_t)44U;
+  uint8_t *b34 = x + 44U;
   uint32_t u33 = load32_le(b34);
   uint32_t xk33 = u33;
   uint32_t ti34 = _t[34U];
@@ -618,14 +610,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb34
     +
       ((va33 + (vb34 ^ (vc34 ^ vd34)) + xk33 + ti34)
-      << (uint32_t)16U
-      | (va33 + (vb34 ^ (vc34 ^ vd34)) + xk33 + ti34) >> (uint32_t)16U);
+      << 16U
+      | (va33 + (vb34 ^ (vc34 ^ vd34)) + xk33 + ti34) >> 16U);
   abcd[2U] = v33;
   uint32_t va34 = abcd[1U];
   uint32_t vb35 = abcd[2U];
   uint32_t vc35 = abcd[3U];
   uint32_t vd35 = abcd[0U];
-  uint8_t *b35 = x + (uint32_t)56U;
+  uint8_t *b35 = x + 56U;
   uint32_t u34 = load32_le(b35);
   uint32_t xk34 = u34;
   uint32_t ti35 = _t[35U];
@@ -634,14 +626,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb35
     +
       ((va34 + (vb35 ^ (vc35 ^ vd35)) + xk34 + ti35)
-      << (uint32_t)23U
-      | (va34 + (vb35 ^ (vc35 ^ vd35)) + xk34 + ti35) >> (uint32_t)9U);
+      << 23U
+      | (va34 + (vb35 ^ (vc35 ^ vd35)) + xk34 + ti35) >> 9U);
   abcd[1U] = v34;
   uint32_t va35 = abcd[0U];
   uint32_t vb36 = abcd[1U];
   uint32_t vc36 = abcd[2U];
   uint32_t vd36 = abcd[3U];
-  uint8_t *b36 = x + (uint32_t)4U;
+  uint8_t *b36 = x + 4U;
   uint32_t u35 = load32_le(b36);
   uint32_t xk35 = u35;
   uint32_t ti36 = _t[36U];
@@ -650,14 +642,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb36
     +
       ((va35 + (vb36 ^ (vc36 ^ vd36)) + xk35 + ti36)
-      << (uint32_t)4U
-      | (va35 + (vb36 ^ (vc36 ^ vd36)) + xk35 + ti36) >> (uint32_t)28U);
+      << 4U
+      | (va35 + (vb36 ^ (vc36 ^ vd36)) + xk35 + ti36) >> 28U);
   abcd[0U] = v35;
   uint32_t va36 = abcd[3U];
   uint32_t vb37 = abcd[0U];
   uint32_t vc37 = abcd[1U];
   uint32_t vd37 = abcd[2U];
-  uint8_t *b37 = x + (uint32_t)16U;
+  uint8_t *b37 = x + 16U;
   uint32_t u36 = load32_le(b37);
   uint32_t xk36 = u36;
   uint32_t ti37 = _t[37U];
@@ -666,14 +658,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb37
     +
       ((va36 + (vb37 ^ (vc37 ^ vd37)) + xk36 + ti37)
-      << (uint32_t)11U
-      | (va36 + (vb37 ^ (vc37 ^ vd37)) + xk36 + ti37) >> (uint32_t)21U);
+      << 11U
+      | (va36 + (vb37 ^ (vc37 ^ vd37)) + xk36 + ti37) >> 21U);
   abcd[3U] = v36;
   uint32_t va37 = abcd[2U];
   uint32_t vb38 = abcd[3U];
   uint32_t vc38 = abcd[0U];
   uint32_t vd38 = abcd[1U];
-  uint8_t *b38 = x + (uint32_t)28U;
+  uint8_t *b38 = x + 28U;
   uint32_t u37 = load32_le(b38);
   uint32_t xk37 = u37;
   uint32_t ti38 = _t[38U];
@@ -682,14 +674,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb38
     +
       ((va37 + (vb38 ^ (vc38 ^ vd38)) + xk37 + ti38)
-      << (uint32_t)16U
-      | (va37 + (vb38 ^ (vc38 ^ vd38)) + xk37 + ti38) >> (uint32_t)16U);
+      << 16U
+      | (va37 + (vb38 ^ (vc38 ^ vd38)) + xk37 + ti38) >> 16U);
   abcd[2U] = v37;
   uint32_t va38 = abcd[1U];
   uint32_t vb39 = abcd[2U];
   uint32_t vc39 = abcd[3U];
   uint32_t vd39 = abcd[0U];
-  uint8_t *b39 = x + (uint32_t)40U;
+  uint8_t *b39 = x + 40U;
   uint32_t u38 = load32_le(b39);
   uint32_t xk38 = u38;
   uint32_t ti39 = _t[39U];
@@ -698,14 +690,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb39
     +
       ((va38 + (vb39 ^ (vc39 ^ vd39)) + xk38 + ti39)
-      << (uint32_t)23U
-      | (va38 + (vb39 ^ (vc39 ^ vd39)) + xk38 + ti39) >> (uint32_t)9U);
+      << 23U
+      | (va38 + (vb39 ^ (vc39 ^ vd39)) + xk38 + ti39) >> 9U);
   abcd[1U] = v38;
   uint32_t va39 = abcd[0U];
   uint32_t vb40 = abcd[1U];
   uint32_t vc40 = abcd[2U];
   uint32_t vd40 = abcd[3U];
-  uint8_t *b40 = x + (uint32_t)52U;
+  uint8_t *b40 = x + 52U;
   uint32_t u39 = load32_le(b40);
   uint32_t xk39 = u39;
   uint32_t ti40 = _t[40U];
@@ -714,8 +706,8 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb40
     +
       ((va39 + (vb40 ^ (vc40 ^ vd40)) + xk39 + ti40)
-      << (uint32_t)4U
-      | (va39 + (vb40 ^ (vc40 ^ vd40)) + xk39 + ti40) >> (uint32_t)28U);
+      << 4U
+      | (va39 + (vb40 ^ (vc40 ^ vd40)) + xk39 + ti40) >> 28U);
   abcd[0U] = v39;
   uint32_t va40 = abcd[3U];
   uint32_t vb41 = abcd[0U];
@@ -730,14 +722,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb41
     +
       ((va40 + (vb41 ^ (vc41 ^ vd41)) + xk40 + ti41)
-      << (uint32_t)11U
-      | (va40 + (vb41 ^ (vc41 ^ vd41)) + xk40 + ti41) >> (uint32_t)21U);
+      << 11U
+      | (va40 + (vb41 ^ (vc41 ^ vd41)) + xk40 + ti41) >> 21U);
   abcd[3U] = v40;
   uint32_t va41 = abcd[2U];
   uint32_t vb42 = abcd[3U];
   uint32_t vc42 = abcd[0U];
   uint32_t vd42 = abcd[1U];
-  uint8_t *b42 = x + (uint32_t)12U;
+  uint8_t *b42 = x + 12U;
   uint32_t u41 = load32_le(b42);
   uint32_t xk41 = u41;
   uint32_t ti42 = _t[42U];
@@ -746,14 +738,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb42
     +
       ((va41 + (vb42 ^ (vc42 ^ vd42)) + xk41 + ti42)
-      << (uint32_t)16U
-      | (va41 + (vb42 ^ (vc42 ^ vd42)) + xk41 + ti42) >> (uint32_t)16U);
+      << 16U
+      | (va41 + (vb42 ^ (vc42 ^ vd42)) + xk41 + ti42) >> 16U);
   abcd[2U] = v41;
   uint32_t va42 = abcd[1U];
   uint32_t vb43 = abcd[2U];
   uint32_t vc43 = abcd[3U];
   uint32_t vd43 = abcd[0U];
-  uint8_t *b43 = x + (uint32_t)24U;
+  uint8_t *b43 = x + 24U;
   uint32_t u42 = load32_le(b43);
   uint32_t xk42 = u42;
   uint32_t ti43 = _t[43U];
@@ -762,14 +754,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb43
     +
       ((va42 + (vb43 ^ (vc43 ^ vd43)) + xk42 + ti43)
-      << (uint32_t)23U
-      | (va42 + (vb43 ^ (vc43 ^ vd43)) + xk42 + ti43) >> (uint32_t)9U);
+      << 23U
+      | (va42 + (vb43 ^ (vc43 ^ vd43)) + xk42 + ti43) >> 9U);
   abcd[1U] = v42;
   uint32_t va43 = abcd[0U];
   uint32_t vb44 = abcd[1U];
   uint32_t vc44 = abcd[2U];
   uint32_t vd44 = abcd[3U];
-  uint8_t *b44 = x + (uint32_t)36U;
+  uint8_t *b44 = x + 36U;
   uint32_t u43 = load32_le(b44);
   uint32_t xk43 = u43;
   uint32_t ti44 = _t[44U];
@@ -778,14 +770,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb44
     +
       ((va43 + (vb44 ^ (vc44 ^ vd44)) + xk43 + ti44)
-      << (uint32_t)4U
-      | (va43 + (vb44 ^ (vc44 ^ vd44)) + xk43 + ti44) >> (uint32_t)28U);
+      << 4U
+      | (va43 + (vb44 ^ (vc44 ^ vd44)) + xk43 + ti44) >> 28U);
   abcd[0U] = v43;
   uint32_t va44 = abcd[3U];
   uint32_t vb45 = abcd[0U];
   uint32_t vc45 = abcd[1U];
   uint32_t vd45 = abcd[2U];
-  uint8_t *b45 = x + (uint32_t)48U;
+  uint8_t *b45 = x + 48U;
   uint32_t u44 = load32_le(b45);
   uint32_t xk44 = u44;
   uint32_t ti45 = _t[45U];
@@ -794,14 +786,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb45
     +
       ((va44 + (vb45 ^ (vc45 ^ vd45)) + xk44 + ti45)
-      << (uint32_t)11U
-      | (va44 + (vb45 ^ (vc45 ^ vd45)) + xk44 + ti45) >> (uint32_t)21U);
+      << 11U
+      | (va44 + (vb45 ^ (vc45 ^ vd45)) + xk44 + ti45) >> 21U);
   abcd[3U] = v44;
   uint32_t va45 = abcd[2U];
   uint32_t vb46 = abcd[3U];
   uint32_t vc46 = abcd[0U];
   uint32_t vd46 = abcd[1U];
-  uint8_t *b46 = x + (uint32_t)60U;
+  uint8_t *b46 = x + 60U;
   uint32_t u45 = load32_le(b46);
   uint32_t xk45 = u45;
   uint32_t ti46 = _t[46U];
@@ -810,14 +802,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb46
     +
       ((va45 + (vb46 ^ (vc46 ^ vd46)) + xk45 + ti46)
-      << (uint32_t)16U
-      | (va45 + (vb46 ^ (vc46 ^ vd46)) + xk45 + ti46) >> (uint32_t)16U);
+      << 16U
+      | (va45 + (vb46 ^ (vc46 ^ vd46)) + xk45 + ti46) >> 16U);
   abcd[2U] = v45;
   uint32_t va46 = abcd[1U];
   uint32_t vb47 = abcd[2U];
   uint32_t vc47 = abcd[3U];
   uint32_t vd47 = abcd[0U];
-  uint8_t *b47 = x + (uint32_t)8U;
+  uint8_t *b47 = x + 8U;
   uint32_t u46 = load32_le(b47);
   uint32_t xk46 = u46;
   uint32_t ti47 = _t[47U];
@@ -826,8 +818,8 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb47
     +
       ((va46 + (vb47 ^ (vc47 ^ vd47)) + xk46 + ti47)
-      << (uint32_t)23U
-      | (va46 + (vb47 ^ (vc47 ^ vd47)) + xk46 + ti47) >> (uint32_t)9U);
+      << 23U
+      | (va46 + (vb47 ^ (vc47 ^ vd47)) + xk46 + ti47) >> 9U);
   abcd[1U] = v46;
   uint32_t va47 = abcd[0U];
   uint32_t vb48 = abcd[1U];
@@ -842,14 +834,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb48
     +
       ((va47 + (vc48 ^ (vb48 | ~vd48)) + xk47 + ti48)
-      << (uint32_t)6U
-      | (va47 + (vc48 ^ (vb48 | ~vd48)) + xk47 + ti48) >> (uint32_t)26U);
+      << 6U
+      | (va47 + (vc48 ^ (vb48 | ~vd48)) + xk47 + ti48) >> 26U);
   abcd[0U] = v47;
   uint32_t va48 = abcd[3U];
   uint32_t vb49 = abcd[0U];
   uint32_t vc49 = abcd[1U];
   uint32_t vd49 = abcd[2U];
-  uint8_t *b49 = x + (uint32_t)28U;
+  uint8_t *b49 = x + 28U;
   uint32_t u48 = load32_le(b49);
   uint32_t xk48 = u48;
   uint32_t ti49 = _t[49U];
@@ -858,14 +850,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb49
     +
       ((va48 + (vc49 ^ (vb49 | ~vd49)) + xk48 + ti49)
-      << (uint32_t)10U
-      | (va48 + (vc49 ^ (vb49 | ~vd49)) + xk48 + ti49) >> (uint32_t)22U);
+      << 10U
+      | (va48 + (vc49 ^ (vb49 | ~vd49)) + xk48 + ti49) >> 22U);
   abcd[3U] = v48;
   uint32_t va49 = abcd[2U];
   uint32_t vb50 = abcd[3U];
   uint32_t vc50 = abcd[0U];
   uint32_t vd50 = abcd[1U];
-  uint8_t *b50 = x + (uint32_t)56U;
+  uint8_t *b50 = x + 56U;
   uint32_t u49 = load32_le(b50);
   uint32_t xk49 = u49;
   uint32_t ti50 = _t[50U];
@@ -874,14 +866,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb50
     +
       ((va49 + (vc50 ^ (vb50 | ~vd50)) + xk49 + ti50)
-      << (uint32_t)15U
-      | (va49 + (vc50 ^ (vb50 | ~vd50)) + xk49 + ti50) >> (uint32_t)17U);
+      << 15U
+      | (va49 + (vc50 ^ (vb50 | ~vd50)) + xk49 + ti50) >> 17U);
   abcd[2U] = v49;
   uint32_t va50 = abcd[1U];
   uint32_t vb51 = abcd[2U];
   uint32_t vc51 = abcd[3U];
   uint32_t vd51 = abcd[0U];
-  uint8_t *b51 = x + (uint32_t)20U;
+  uint8_t *b51 = x + 20U;
   uint32_t u50 = load32_le(b51);
   uint32_t xk50 = u50;
   uint32_t ti51 = _t[51U];
@@ -890,14 +882,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb51
     +
       ((va50 + (vc51 ^ (vb51 | ~vd51)) + xk50 + ti51)
-      << (uint32_t)21U
-      | (va50 + (vc51 ^ (vb51 | ~vd51)) + xk50 + ti51) >> (uint32_t)11U);
+      << 21U
+      | (va50 + (vc51 ^ (vb51 | ~vd51)) + xk50 + ti51) >> 11U);
   abcd[1U] = v50;
   uint32_t va51 = abcd[0U];
   uint32_t vb52 = abcd[1U];
   uint32_t vc52 = abcd[2U];
   uint32_t vd52 = abcd[3U];
-  uint8_t *b52 = x + (uint32_t)48U;
+  uint8_t *b52 = x + 48U;
   uint32_t u51 = load32_le(b52);
   uint32_t xk51 = u51;
   uint32_t ti52 = _t[52U];
@@ -906,14 +898,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb52
     +
       ((va51 + (vc52 ^ (vb52 | ~vd52)) + xk51 + ti52)
-      << (uint32_t)6U
-      | (va51 + (vc52 ^ (vb52 | ~vd52)) + xk51 + ti52) >> (uint32_t)26U);
+      << 6U
+      | (va51 + (vc52 ^ (vb52 | ~vd52)) + xk51 + ti52) >> 26U);
   abcd[0U] = v51;
   uint32_t va52 = abcd[3U];
   uint32_t vb53 = abcd[0U];
   uint32_t vc53 = abcd[1U];
   uint32_t vd53 = abcd[2U];
-  uint8_t *b53 = x + (uint32_t)12U;
+  uint8_t *b53 = x + 12U;
   uint32_t u52 = load32_le(b53);
   uint32_t xk52 = u52;
   uint32_t ti53 = _t[53U];
@@ -922,14 +914,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb53
     +
       ((va52 + (vc53 ^ (vb53 | ~vd53)) + xk52 + ti53)
-      << (uint32_t)10U
-      | (va52 + (vc53 ^ (vb53 | ~vd53)) + xk52 + ti53) >> (uint32_t)22U);
+      << 10U
+      | (va52 + (vc53 ^ (vb53 | ~vd53)) + xk52 + ti53) >> 22U);
   abcd[3U] = v52;
   uint32_t va53 = abcd[2U];
   uint32_t vb54 = abcd[3U];
   uint32_t vc54 = abcd[0U];
   uint32_t vd54 = abcd[1U];
-  uint8_t *b54 = x + (uint32_t)40U;
+  uint8_t *b54 = x + 40U;
   uint32_t u53 = load32_le(b54);
   uint32_t xk53 = u53;
   uint32_t ti54 = _t[54U];
@@ -938,14 +930,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb54
     +
       ((va53 + (vc54 ^ (vb54 | ~vd54)) + xk53 + ti54)
-      << (uint32_t)15U
-      | (va53 + (vc54 ^ (vb54 | ~vd54)) + xk53 + ti54) >> (uint32_t)17U);
+      << 15U
+      | (va53 + (vc54 ^ (vb54 | ~vd54)) + xk53 + ti54) >> 17U);
   abcd[2U] = v53;
   uint32_t va54 = abcd[1U];
   uint32_t vb55 = abcd[2U];
   uint32_t vc55 = abcd[3U];
   uint32_t vd55 = abcd[0U];
-  uint8_t *b55 = x + (uint32_t)4U;
+  uint8_t *b55 = x + 4U;
   uint32_t u54 = load32_le(b55);
   uint32_t xk54 = u54;
   uint32_t ti55 = _t[55U];
@@ -954,14 +946,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb55
     +
       ((va54 + (vc55 ^ (vb55 | ~vd55)) + xk54 + ti55)
-      << (uint32_t)21U
-      | (va54 + (vc55 ^ (vb55 | ~vd55)) + xk54 + ti55) >> (uint32_t)11U);
+      << 21U
+      | (va54 + (vc55 ^ (vb55 | ~vd55)) + xk54 + ti55) >> 11U);
   abcd[1U] = v54;
   uint32_t va55 = abcd[0U];
   uint32_t vb56 = abcd[1U];
   uint32_t vc56 = abcd[2U];
   uint32_t vd56 = abcd[3U];
-  uint8_t *b56 = x + (uint32_t)32U;
+  uint8_t *b56 = x + 32U;
   uint32_t u55 = load32_le(b56);
   uint32_t xk55 = u55;
   uint32_t ti56 = _t[56U];
@@ -970,14 +962,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb56
     +
       ((va55 + (vc56 ^ (vb56 | ~vd56)) + xk55 + ti56)
-      << (uint32_t)6U
-      | (va55 + (vc56 ^ (vb56 | ~vd56)) + xk55 + ti56) >> (uint32_t)26U);
+      << 6U
+      | (va55 + (vc56 ^ (vb56 | ~vd56)) + xk55 + ti56) >> 26U);
   abcd[0U] = v55;
   uint32_t va56 = abcd[3U];
   uint32_t vb57 = abcd[0U];
   uint32_t vc57 = abcd[1U];
   uint32_t vd57 = abcd[2U];
-  uint8_t *b57 = x + (uint32_t)60U;
+  uint8_t *b57 = x + 60U;
   uint32_t u56 = load32_le(b57);
   uint32_t xk56 = u56;
   uint32_t ti57 = _t[57U];
@@ -986,14 +978,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb57
     +
       ((va56 + (vc57 ^ (vb57 | ~vd57)) + xk56 + ti57)
-      << (uint32_t)10U
-      | (va56 + (vc57 ^ (vb57 | ~vd57)) + xk56 + ti57) >> (uint32_t)22U);
+      << 10U
+      | (va56 + (vc57 ^ (vb57 | ~vd57)) + xk56 + ti57) >> 22U);
   abcd[3U] = v56;
   uint32_t va57 = abcd[2U];
   uint32_t vb58 = abcd[3U];
   uint32_t vc58 = abcd[0U];
   uint32_t vd58 = abcd[1U];
-  uint8_t *b58 = x + (uint32_t)24U;
+  uint8_t *b58 = x + 24U;
   uint32_t u57 = load32_le(b58);
   uint32_t xk57 = u57;
   uint32_t ti58 = _t[58U];
@@ -1002,14 +994,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb58
     +
       ((va57 + (vc58 ^ (vb58 | ~vd58)) + xk57 + ti58)
-      << (uint32_t)15U
-      | (va57 + (vc58 ^ (vb58 | ~vd58)) + xk57 + ti58) >> (uint32_t)17U);
+      << 15U
+      | (va57 + (vc58 ^ (vb58 | ~vd58)) + xk57 + ti58) >> 17U);
   abcd[2U] = v57;
   uint32_t va58 = abcd[1U];
   uint32_t vb59 = abcd[2U];
   uint32_t vc59 = abcd[3U];
   uint32_t vd59 = abcd[0U];
-  uint8_t *b59 = x + (uint32_t)52U;
+  uint8_t *b59 = x + 52U;
   uint32_t u58 = load32_le(b59);
   uint32_t xk58 = u58;
   uint32_t ti59 = _t[59U];
@@ -1018,14 +1010,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb59
     +
       ((va58 + (vc59 ^ (vb59 | ~vd59)) + xk58 + ti59)
-      << (uint32_t)21U
-      | (va58 + (vc59 ^ (vb59 | ~vd59)) + xk58 + ti59) >> (uint32_t)11U);
+      << 21U
+      | (va58 + (vc59 ^ (vb59 | ~vd59)) + xk58 + ti59) >> 11U);
   abcd[1U] = v58;
   uint32_t va59 = abcd[0U];
   uint32_t vb60 = abcd[1U];
   uint32_t vc60 = abcd[2U];
   uint32_t vd60 = abcd[3U];
-  uint8_t *b60 = x + (uint32_t)16U;
+  uint8_t *b60 = x + 16U;
   uint32_t u59 = load32_le(b60);
   uint32_t xk59 = u59;
   uint32_t ti60 = _t[60U];
@@ -1034,14 +1026,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb60
     +
       ((va59 + (vc60 ^ (vb60 | ~vd60)) + xk59 + ti60)
-      << (uint32_t)6U
-      | (va59 + (vc60 ^ (vb60 | ~vd60)) + xk59 + ti60) >> (uint32_t)26U);
+      << 6U
+      | (va59 + (vc60 ^ (vb60 | ~vd60)) + xk59 + ti60) >> 26U);
   abcd[0U] = v59;
   uint32_t va60 = abcd[3U];
   uint32_t vb61 = abcd[0U];
   uint32_t vc61 = abcd[1U];
   uint32_t vd61 = abcd[2U];
-  uint8_t *b61 = x + (uint32_t)44U;
+  uint8_t *b61 = x + 44U;
   uint32_t u60 = load32_le(b61);
   uint32_t xk60 = u60;
   uint32_t ti61 = _t[61U];
@@ -1050,14 +1042,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb61
     +
       ((va60 + (vc61 ^ (vb61 | ~vd61)) + xk60 + ti61)
-      << (uint32_t)10U
-      | (va60 + (vc61 ^ (vb61 | ~vd61)) + xk60 + ti61) >> (uint32_t)22U);
+      << 10U
+      | (va60 + (vc61 ^ (vb61 | ~vd61)) + xk60 + ti61) >> 22U);
   abcd[3U] = v60;
   uint32_t va61 = abcd[2U];
   uint32_t vb62 = abcd[3U];
   uint32_t vc62 = abcd[0U];
   uint32_t vd62 = abcd[1U];
-  uint8_t *b62 = x + (uint32_t)8U;
+  uint8_t *b62 = x + 8U;
   uint32_t u61 = load32_le(b62);
   uint32_t xk61 = u61;
   uint32_t ti62 = _t[62U];
@@ -1066,14 +1058,14 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb62
     +
       ((va61 + (vc62 ^ (vb62 | ~vd62)) + xk61 + ti62)
-      << (uint32_t)15U
-      | (va61 + (vc62 ^ (vb62 | ~vd62)) + xk61 + ti62) >> (uint32_t)17U);
+      << 15U
+      | (va61 + (vc62 ^ (vb62 | ~vd62)) + xk61 + ti62) >> 17U);
   abcd[2U] = v61;
   uint32_t va62 = abcd[1U];
   uint32_t vb = abcd[2U];
   uint32_t vc = abcd[3U];
   uint32_t vd = abcd[0U];
-  uint8_t *b63 = x + (uint32_t)36U;
+  uint8_t *b63 = x + 36U;
   uint32_t u62 = load32_le(b63);
   uint32_t xk62 = u62;
   uint32_t ti = _t[63U];
@@ -1082,8 +1074,8 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
     vb
     +
       ((va62 + (vc ^ (vb | ~vd)) + xk62 + ti)
-      << (uint32_t)21U
-      | (va62 + (vc ^ (vb | ~vd)) + xk62 + ti) >> (uint32_t)11U);
+      << 21U
+      | (va62 + (vc ^ (vb | ~vd)) + xk62 + ti) >> 11U);
   abcd[1U] = v62;
   uint32_t a = abcd[0U];
   uint32_t b = abcd[1U];
@@ -1095,98 +1087,69 @@ static void legacy_update(uint32_t *abcd, uint8_t *x)
   abcd[3U] = d + dd;
 }
 
-static void legacy_pad(uint64_t len, uint8_t *dst)
+static void pad(uint64_t len, uint8_t *dst)
 {
   uint8_t *dst1 = dst;
-  dst1[0U] = (uint8_t)0x80U;
-  uint8_t *dst2 = dst + (uint32_t)1U;
-  for
-  (uint32_t
-    i = (uint32_t)0U;
-    i
-    < ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(len % (uint64_t)(uint32_t)64U))) % (uint32_t)64U;
-    i++)
+  dst1[0U] = 0x80U;
+  uint8_t *dst2 = dst + 1U;
+  for (uint32_t i = 0U; i < (128U - (9U + (uint32_t)(len % (uint64_t)64U))) % 64U; i++)
   {
-    dst2[i] = (uint8_t)0U;
+    dst2[i] = 0U;
   }
-  uint8_t
-  *dst3 =
-    dst
-    +
-      (uint32_t)1U
-      +
-        ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(len % (uint64_t)(uint32_t)64U)))
-        % (uint32_t)64U;
-  store64_le(dst3, len << (uint32_t)3U);
+  uint8_t *dst3 = dst + 1U + (128U - (9U + (uint32_t)(len % (uint64_t)64U))) % 64U;
+  store64_le(dst3, len << 3U);
 }
 
-void Hacl_Hash_Core_MD5_legacy_finish(uint32_t *s, uint8_t *dst)
+void Hacl_Hash_MD5_finish(uint32_t *s, uint8_t *dst)
 {
-  KRML_MAYBE_FOR4(i,
-    (uint32_t)0U,
-    (uint32_t)4U,
-    (uint32_t)1U,
-    store32_le(dst + i * (uint32_t)4U, s[i]););
+  KRML_MAYBE_FOR4(i, 0U, 4U, 1U, store32_le(dst + i * 4U, s[i]););
 }
 
-void Hacl_Hash_MD5_legacy_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks)
+void Hacl_Hash_MD5_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks)
 {
-  for (uint32_t i = (uint32_t)0U; i < n_blocks; i++)
+  for (uint32_t i = 0U; i < n_blocks; i++)
   {
-    uint32_t sz = (uint32_t)64U;
+    uint32_t sz = 64U;
     uint8_t *block = blocks + sz * i;
-    legacy_update(s, block);
+    update(s, block);
   }
 }
 
 void
-Hacl_Hash_MD5_legacy_update_last(
-  uint32_t *s,
-  uint64_t prev_len,
-  uint8_t *input,
-  uint32_t input_len
-)
+Hacl_Hash_MD5_update_last(uint32_t *s, uint64_t prev_len, uint8_t *input, uint32_t input_len)
 {
-  uint32_t blocks_n = input_len / (uint32_t)64U;
-  uint32_t blocks_len = blocks_n * (uint32_t)64U;
+  uint32_t blocks_n = input_len / 64U;
+  uint32_t blocks_len = blocks_n * 64U;
   uint8_t *blocks = input;
   uint32_t rest_len = input_len - blocks_len;
   uint8_t *rest = input + blocks_len;
-  Hacl_Hash_MD5_legacy_update_multi(s, blocks, blocks_n);
+  Hacl_Hash_MD5_update_multi(s, blocks, blocks_n);
   uint64_t total_input_len = prev_len + (uint64_t)input_len;
-  uint32_t
-  pad_len =
-    (uint32_t)1U
-    +
-      ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(total_input_len % (uint64_t)(uint32_t)64U)))
-      % (uint32_t)64U
-    + (uint32_t)8U;
+  uint32_t pad_len = 1U + (128U - (9U + (uint32_t)(total_input_len % (uint64_t)64U))) % 64U + 8U;
   uint32_t tmp_len = rest_len + pad_len;
   uint8_t tmp_twoblocks[128U] = { 0U };
   uint8_t *tmp = tmp_twoblocks;
   uint8_t *tmp_rest = tmp;
   uint8_t *tmp_pad = tmp + rest_len;
   memcpy(tmp_rest, rest, rest_len * sizeof (uint8_t));
-  legacy_pad(total_input_len, tmp_pad);
-  Hacl_Hash_MD5_legacy_update_multi(s, tmp, tmp_len / (uint32_t)64U);
+  pad(total_input_len, tmp_pad);
+  Hacl_Hash_MD5_update_multi(s, tmp, tmp_len / 64U);
 }
 
-void Hacl_Hash_MD5_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_MD5_hash_oneshot(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  uint32_t
-  s[4U] =
-    { (uint32_t)0x67452301U, (uint32_t)0xefcdab89U, (uint32_t)0x98badcfeU, (uint32_t)0x10325476U };
-  uint32_t blocks_n0 = input_len / (uint32_t)64U;
+  uint32_t s[4U] = { 0x67452301U, 0xefcdab89U, 0x98badcfeU, 0x10325476U };
+  uint32_t blocks_n0 = input_len / 64U;
   uint32_t blocks_n1;
-  if (input_len % (uint32_t)64U == (uint32_t)0U && blocks_n0 > (uint32_t)0U)
+  if (input_len % 64U == 0U && blocks_n0 > 0U)
   {
-    blocks_n1 = blocks_n0 - (uint32_t)1U;
+    blocks_n1 = blocks_n0 - 1U;
   }
   else
   {
     blocks_n1 = blocks_n0;
   }
-  uint32_t blocks_len0 = blocks_n1 * (uint32_t)64U;
+  uint32_t blocks_len0 = blocks_n1 * 64U;
   uint8_t *blocks0 = input;
   uint32_t rest_len0 = input_len - blocks_len0;
   uint8_t *rest0 = input + blocks_len0;
@@ -1195,75 +1158,75 @@ void Hacl_Hash_MD5_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst)
   uint8_t *blocks = blocks0;
   uint32_t rest_len = rest_len0;
   uint8_t *rest = rest0;
-  Hacl_Hash_MD5_legacy_update_multi(s, blocks, blocks_n);
-  Hacl_Hash_MD5_legacy_update_last(s, (uint64_t)blocks_len, rest, rest_len);
-  Hacl_Hash_Core_MD5_legacy_finish(s, dst);
+  Hacl_Hash_MD5_update_multi(s, blocks, blocks_n);
+  Hacl_Hash_MD5_update_last(s, (uint64_t)blocks_len, rest, rest_len);
+  Hacl_Hash_MD5_finish(s, output);
 }
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_MD5_legacy_create_in(void)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_MD5_malloc(void)
 {
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)4U, sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(4U, sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
-  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
+  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
   Hacl_Streaming_MD_state_32
   *p = (Hacl_Streaming_MD_state_32 *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_MD_state_32));
   p[0U] = s;
-  Hacl_Hash_Core_MD5_legacy_init(block_state);
+  Hacl_Hash_MD5_init(block_state);
   return p;
 }
 
-void Hacl_Streaming_MD5_legacy_init(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_MD5_reset(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
-  Hacl_Hash_Core_MD5_legacy_init(block_state);
+  Hacl_Hash_MD5_init(block_state);
   Hacl_Streaming_MD_state_32
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 /**
 0 = success, 1 = max length exceeded
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_MD5_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len)
+Hacl_Hash_MD5_update(Hacl_Streaming_MD_state_32 *state, uint8_t *chunk, uint32_t chunk_len)
 {
-  Hacl_Streaming_MD_state_32 s = *p;
+  Hacl_Streaming_MD_state_32 s = *state;
   uint64_t total_len = s.total_len;
-  if ((uint64_t)len > (uint64_t)2305843009213693951U - total_len)
+  if ((uint64_t)chunk_len > 2305843009213693951ULL - total_len)
   {
     return Hacl_Streaming_Types_MaximumLengthExceeded;
   }
   uint32_t sz;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    sz = (uint32_t)64U;
+    sz = 64U;
   }
   else
   {
-    sz = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    sz = (uint32_t)(total_len % (uint64_t)64U);
   }
-  if (len <= (uint32_t)64U - sz)
+  if (chunk_len <= 64U - sz)
   {
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
     uint8_t *buf2 = buf + sz1;
-    memcpy(buf2, data, len * sizeof (uint8_t));
-    uint64_t total_len2 = total_len1 + (uint64_t)len;
-    *p
+    memcpy(buf2, chunk, chunk_len * sizeof (uint8_t));
+    uint64_t total_len2 = total_len1 + (uint64_t)chunk_len;
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
@@ -1273,74 +1236,74 @@ Hacl_Streaming_MD5_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data, u
         }
       );
   }
-  else if (sz == (uint32_t)0U)
+  else if (sz == 0U)
   {
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_Hash_MD5_legacy_update_multi(block_state1, buf, (uint32_t)1U);
+      Hacl_Hash_MD5_update_multi(block_state1, buf, 1U);
     }
     uint32_t ite;
-    if ((uint64_t)len % (uint64_t)(uint32_t)64U == (uint64_t)0U && (uint64_t)len > (uint64_t)0U)
+    if ((uint64_t)chunk_len % (uint64_t)64U == 0ULL && (uint64_t)chunk_len > 0ULL)
     {
-      ite = (uint32_t)64U;
+      ite = 64U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)len % (uint64_t)(uint32_t)64U);
+      ite = (uint32_t)((uint64_t)chunk_len % (uint64_t)64U);
     }
-    uint32_t n_blocks = (len - ite) / (uint32_t)64U;
-    uint32_t data1_len = n_blocks * (uint32_t)64U;
-    uint32_t data2_len = len - data1_len;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + data1_len;
-    Hacl_Hash_MD5_legacy_update_multi(block_state1, data1, data1_len / (uint32_t)64U);
+    uint32_t n_blocks = (chunk_len - ite) / 64U;
+    uint32_t data1_len = n_blocks * 64U;
+    uint32_t data2_len = chunk_len - data1_len;
+    uint8_t *data1 = chunk;
+    uint8_t *data2 = chunk + data1_len;
+    Hacl_Hash_MD5_update_multi(block_state1, data1, data1_len / 64U);
     uint8_t *dst = buf;
     memcpy(dst, data2, data2_len * sizeof (uint8_t));
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)len
+          .total_len = total_len1 + (uint64_t)chunk_len
         }
       );
   }
   else
   {
-    uint32_t diff = (uint32_t)64U - sz;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + diff;
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    uint32_t diff = 64U - sz;
+    uint8_t *chunk1 = chunk;
+    uint8_t *chunk2 = chunk + diff;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state10 = s1.block_state;
     uint8_t *buf0 = s1.buf;
     uint64_t total_len10 = s1.total_len;
     uint32_t sz10;
-    if (total_len10 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len10 > (uint64_t)0U)
+    if (total_len10 % (uint64_t)64U == 0ULL && total_len10 > 0ULL)
     {
-      sz10 = (uint32_t)64U;
+      sz10 = 64U;
     }
     else
     {
-      sz10 = (uint32_t)(total_len10 % (uint64_t)(uint32_t)64U);
+      sz10 = (uint32_t)(total_len10 % (uint64_t)64U);
     }
     uint8_t *buf2 = buf0 + sz10;
-    memcpy(buf2, data1, diff * sizeof (uint8_t));
+    memcpy(buf2, chunk1, diff * sizeof (uint8_t));
     uint64_t total_len2 = total_len10 + (uint64_t)diff;
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
@@ -1349,114 +1312,109 @@ Hacl_Streaming_MD5_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data, u
           .total_len = total_len2
         }
       );
-    Hacl_Streaming_MD_state_32 s10 = *p;
+    Hacl_Streaming_MD_state_32 s10 = *state;
     uint32_t *block_state1 = s10.block_state;
     uint8_t *buf = s10.buf;
     uint64_t total_len1 = s10.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_Hash_MD5_legacy_update_multi(block_state1, buf, (uint32_t)1U);
+      Hacl_Hash_MD5_update_multi(block_state1, buf, 1U);
     }
     uint32_t ite;
     if
-    (
-      (uint64_t)(len - diff)
-      % (uint64_t)(uint32_t)64U
-      == (uint64_t)0U
-      && (uint64_t)(len - diff) > (uint64_t)0U
-    )
+    ((uint64_t)(chunk_len - diff) % (uint64_t)64U == 0ULL && (uint64_t)(chunk_len - diff) > 0ULL)
     {
-      ite = (uint32_t)64U;
+      ite = 64U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)(len - diff) % (uint64_t)(uint32_t)64U);
+      ite = (uint32_t)((uint64_t)(chunk_len - diff) % (uint64_t)64U);
     }
-    uint32_t n_blocks = (len - diff - ite) / (uint32_t)64U;
-    uint32_t data1_len = n_blocks * (uint32_t)64U;
-    uint32_t data2_len = len - diff - data1_len;
-    uint8_t *data11 = data2;
-    uint8_t *data21 = data2 + data1_len;
-    Hacl_Hash_MD5_legacy_update_multi(block_state1, data11, data1_len / (uint32_t)64U);
+    uint32_t n_blocks = (chunk_len - diff - ite) / 64U;
+    uint32_t data1_len = n_blocks * 64U;
+    uint32_t data2_len = chunk_len - diff - data1_len;
+    uint8_t *data1 = chunk2;
+    uint8_t *data2 = chunk2 + data1_len;
+    Hacl_Hash_MD5_update_multi(block_state1, data1, data1_len / 64U);
     uint8_t *dst = buf;
-    memcpy(dst, data21, data2_len * sizeof (uint8_t));
-    *p
+    memcpy(dst, data2, data2_len * sizeof (uint8_t));
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)(len - diff)
+          .total_len = total_len1 + (uint64_t)(chunk_len - diff)
         }
       );
   }
   return Hacl_Streaming_Types_Success;
 }
 
-void Hacl_Streaming_MD5_legacy_finish(Hacl_Streaming_MD_state_32 *p, uint8_t *dst)
+void Hacl_Hash_MD5_digest(Hacl_Streaming_MD_state_32 *state, uint8_t *output)
 {
-  Hacl_Streaming_MD_state_32 scrut = *p;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state = scrut.block_state;
   uint8_t *buf_ = scrut.buf;
   uint64_t total_len = scrut.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    r = (uint32_t)64U;
+    r = 64U;
   }
   else
   {
-    r = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    r = (uint32_t)(total_len % (uint64_t)64U);
   }
   uint8_t *buf_1 = buf_;
   uint32_t tmp_block_state[4U] = { 0U };
-  memcpy(tmp_block_state, block_state, (uint32_t)4U * sizeof (uint32_t));
+  memcpy(tmp_block_state, block_state, 4U * sizeof (uint32_t));
   uint32_t ite;
-  if (r % (uint32_t)64U == (uint32_t)0U && r > (uint32_t)0U)
+  if (r % 64U == 0U && r > 0U)
   {
-    ite = (uint32_t)64U;
+    ite = 64U;
   }
   else
   {
-    ite = r % (uint32_t)64U;
+    ite = r % 64U;
   }
   uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
-  Hacl_Hash_MD5_legacy_update_multi(tmp_block_state, buf_multi, (uint32_t)0U);
+  Hacl_Hash_MD5_update_multi(tmp_block_state, buf_multi, 0U);
   uint64_t prev_len_last = total_len - (uint64_t)r;
-  Hacl_Hash_MD5_legacy_update_last(tmp_block_state, prev_len_last, buf_last, r);
-  Hacl_Hash_Core_MD5_legacy_finish(tmp_block_state, dst);
+  Hacl_Hash_MD5_update_last(tmp_block_state, prev_len_last, buf_last, r);
+  Hacl_Hash_MD5_finish(tmp_block_state, output);
 }
 
-void Hacl_Streaming_MD5_legacy_free(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_MD5_free(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
   KRML_HOST_FREE(block_state);
   KRML_HOST_FREE(buf);
-  KRML_HOST_FREE(s);
+  KRML_HOST_FREE(state);
 }
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_MD5_legacy_copy(Hacl_Streaming_MD_state_32 *s0)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_MD5_copy(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s0;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state0 = scrut.block_state;
   uint8_t *buf0 = scrut.buf;
   uint64_t total_len0 = scrut.total_len;
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  memcpy(buf, buf0, (uint32_t)64U * sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)4U, sizeof (uint32_t));
-  memcpy(block_state, block_state0, (uint32_t)4U * sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  memcpy(buf, buf0, 64U * sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(4U, sizeof (uint32_t));
+  memcpy(block_state, block_state0, 4U * sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
   s = { .block_state = block_state, .buf = buf, .total_len = total_len0 };
   Hacl_Streaming_MD_state_32
@@ -1465,8 +1423,8 @@ Hacl_Streaming_MD_state_32 *Hacl_Streaming_MD5_legacy_copy(Hacl_Streaming_MD_sta
   return p;
 }
 
-void Hacl_Streaming_MD5_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_MD5_hash(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  Hacl_Hash_MD5_legacy_hash(input, input_len, dst);
+  Hacl_Hash_MD5_hash_oneshot(output, input, input_len);
 }
 
diff --git a/Modules/_hacl/Hacl_Hash_MD5.h b/Modules/_hacl/Hacl_Hash_MD5.h
index 13c19fd40f..f69d6e5a81 100644
--- a/Modules/_hacl/Hacl_Hash_MD5.h
+++ b/Modules/_hacl/Hacl_Hash_MD5.h
@@ -31,31 +31,32 @@ extern "C" {
 #endif
 
 #include <string.h>
+#include "python_hacl_namespaces.h"
 #include "krml/types.h"
 #include "krml/lowstar_endianness.h"
 #include "krml/internal/target.h"
 
 #include "Hacl_Streaming_Types.h"
 
-typedef Hacl_Streaming_MD_state_32 Hacl_Streaming_MD5_state;
+typedef Hacl_Streaming_MD_state_32 Hacl_Hash_MD5_state_t;
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_MD5_legacy_create_in(void);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_MD5_malloc(void);
 
-void Hacl_Streaming_MD5_legacy_init(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_MD5_reset(Hacl_Streaming_MD_state_32 *state);
 
 /**
 0 = success, 1 = max length exceeded
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_MD5_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len);
+Hacl_Hash_MD5_update(Hacl_Streaming_MD_state_32 *state, uint8_t *chunk, uint32_t chunk_len);
 
-void Hacl_Streaming_MD5_legacy_finish(Hacl_Streaming_MD_state_32 *p, uint8_t *dst);
+void Hacl_Hash_MD5_digest(Hacl_Streaming_MD_state_32 *state, uint8_t *output);
 
-void Hacl_Streaming_MD5_legacy_free(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_MD5_free(Hacl_Streaming_MD_state_32 *state);
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_MD5_legacy_copy(Hacl_Streaming_MD_state_32 *s0);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_MD5_copy(Hacl_Streaming_MD_state_32 *state);
 
-void Hacl_Streaming_MD5_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst);
+void Hacl_Hash_MD5_hash(uint8_t *output, uint8_t *input, uint32_t input_len);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/Hacl_Hash_SHA1.c b/Modules/_hacl/Hacl_Hash_SHA1.c
index 5ecb3c0b3a..1a8b09b171 100644
--- a/Modules/_hacl/Hacl_Hash_SHA1.c
+++ b/Modules/_hacl/Hacl_Hash_SHA1.c
@@ -25,19 +25,14 @@
 
 #include "internal/Hacl_Hash_SHA1.h"
 
-static uint32_t
-_h0[5U] =
-  {
-    (uint32_t)0x67452301U, (uint32_t)0xefcdab89U, (uint32_t)0x98badcfeU, (uint32_t)0x10325476U,
-    (uint32_t)0xc3d2e1f0U
-  };
+static uint32_t _h0[5U] = { 0x67452301U, 0xefcdab89U, 0x98badcfeU, 0x10325476U, 0xc3d2e1f0U };
 
-void Hacl_Hash_Core_SHA1_legacy_init(uint32_t *s)
+void Hacl_Hash_SHA1_init(uint32_t *s)
 {
-  KRML_MAYBE_FOR5(i, (uint32_t)0U, (uint32_t)5U, (uint32_t)1U, s[i] = _h0[i];);
+  KRML_MAYBE_FOR5(i, 0U, 5U, 1U, s[i] = _h0[i];);
 }
 
-static void legacy_update(uint32_t *h, uint8_t *l)
+static void update(uint32_t *h, uint8_t *l)
 {
   uint32_t ha = h[0U];
   uint32_t hb = h[1U];
@@ -45,29 +40,26 @@ static void legacy_update(uint32_t *h, uint8_t *l)
   uint32_t hd = h[3U];
   uint32_t he = h[4U];
   uint32_t _w[80U] = { 0U };
-  for (uint32_t i = (uint32_t)0U; i < (uint32_t)80U; i++)
+  for (uint32_t i = 0U; i < 80U; i++)
   {
     uint32_t v;
-    if (i < (uint32_t)16U)
+    if (i < 16U)
     {
-      uint8_t *b = l + i * (uint32_t)4U;
+      uint8_t *b = l + i * 4U;
       uint32_t u = load32_be(b);
       v = u;
     }
     else
     {
-      uint32_t wmit3 = _w[i - (uint32_t)3U];
-      uint32_t wmit8 = _w[i - (uint32_t)8U];
-      uint32_t wmit14 = _w[i - (uint32_t)14U];
-      uint32_t wmit16 = _w[i - (uint32_t)16U];
-      v =
-        (wmit3 ^ (wmit8 ^ (wmit14 ^ wmit16)))
-        << (uint32_t)1U
-        | (wmit3 ^ (wmit8 ^ (wmit14 ^ wmit16))) >> (uint32_t)31U;
+      uint32_t wmit3 = _w[i - 3U];
+      uint32_t wmit8 = _w[i - 8U];
+      uint32_t wmit14 = _w[i - 14U];
+      uint32_t wmit16 = _w[i - 16U];
+      v = (wmit3 ^ (wmit8 ^ (wmit14 ^ wmit16))) << 1U | (wmit3 ^ (wmit8 ^ (wmit14 ^ wmit16))) >> 31U;
     }
     _w[i] = v;
   }
-  for (uint32_t i = (uint32_t)0U; i < (uint32_t)80U; i++)
+  for (uint32_t i = 0U; i < 80U; i++)
   {
     uint32_t _a = h[0U];
     uint32_t _b = h[1U];
@@ -76,11 +68,11 @@ static void legacy_update(uint32_t *h, uint8_t *l)
     uint32_t _e = h[4U];
     uint32_t wmit = _w[i];
     uint32_t ite0;
-    if (i < (uint32_t)20U)
+    if (i < 20U)
     {
       ite0 = (_b & _c) ^ (~_b & _d);
     }
-    else if ((uint32_t)39U < i && i < (uint32_t)60U)
+    else if (39U < i && i < 60U)
     {
       ite0 = (_b & _c) ^ ((_b & _d) ^ (_c & _d));
     }
@@ -89,32 +81,32 @@ static void legacy_update(uint32_t *h, uint8_t *l)
       ite0 = _b ^ (_c ^ _d);
     }
     uint32_t ite;
-    if (i < (uint32_t)20U)
+    if (i < 20U)
     {
-      ite = (uint32_t)0x5a827999U;
+      ite = 0x5a827999U;
     }
-    else if (i < (uint32_t)40U)
+    else if (i < 40U)
     {
-      ite = (uint32_t)0x6ed9eba1U;
+      ite = 0x6ed9eba1U;
     }
-    else if (i < (uint32_t)60U)
+    else if (i < 60U)
     {
-      ite = (uint32_t)0x8f1bbcdcU;
+      ite = 0x8f1bbcdcU;
     }
     else
     {
-      ite = (uint32_t)0xca62c1d6U;
+      ite = 0xca62c1d6U;
     }
-    uint32_t _T = (_a << (uint32_t)5U | _a >> (uint32_t)27U) + ite0 + _e + ite + wmit;
+    uint32_t _T = (_a << 5U | _a >> 27U) + ite0 + _e + ite + wmit;
     h[0U] = _T;
     h[1U] = _a;
-    h[2U] = _b << (uint32_t)30U | _b >> (uint32_t)2U;
+    h[2U] = _b << 30U | _b >> 2U;
     h[3U] = _c;
     h[4U] = _d;
   }
-  for (uint32_t i = (uint32_t)0U; i < (uint32_t)80U; i++)
+  for (uint32_t i = 0U; i < 80U; i++)
   {
-    _w[i] = (uint32_t)0U;
+    _w[i] = 0U;
   }
   uint32_t sta = h[0U];
   uint32_t stb = h[1U];
@@ -128,101 +120,69 @@ static void legacy_update(uint32_t *h, uint8_t *l)
   h[4U] = ste + he;
 }
 
-static void legacy_pad(uint64_t len, uint8_t *dst)
+static void pad(uint64_t len, uint8_t *dst)
 {
   uint8_t *dst1 = dst;
-  dst1[0U] = (uint8_t)0x80U;
-  uint8_t *dst2 = dst + (uint32_t)1U;
-  for
-  (uint32_t
-    i = (uint32_t)0U;
-    i
-    < ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(len % (uint64_t)(uint32_t)64U))) % (uint32_t)64U;
-    i++)
+  dst1[0U] = 0x80U;
+  uint8_t *dst2 = dst + 1U;
+  for (uint32_t i = 0U; i < (128U - (9U + (uint32_t)(len % (uint64_t)64U))) % 64U; i++)
   {
-    dst2[i] = (uint8_t)0U;
+    dst2[i] = 0U;
   }
-  uint8_t
-  *dst3 =
-    dst
-    +
-      (uint32_t)1U
-      +
-        ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(len % (uint64_t)(uint32_t)64U)))
-        % (uint32_t)64U;
-  store64_be(dst3, len << (uint32_t)3U);
+  uint8_t *dst3 = dst + 1U + (128U - (9U + (uint32_t)(len % (uint64_t)64U))) % 64U;
+  store64_be(dst3, len << 3U);
 }
 
-void Hacl_Hash_Core_SHA1_legacy_finish(uint32_t *s, uint8_t *dst)
+void Hacl_Hash_SHA1_finish(uint32_t *s, uint8_t *dst)
 {
-  KRML_MAYBE_FOR5(i,
-    (uint32_t)0U,
-    (uint32_t)5U,
-    (uint32_t)1U,
-    store32_be(dst + i * (uint32_t)4U, s[i]););
+  KRML_MAYBE_FOR5(i, 0U, 5U, 1U, store32_be(dst + i * 4U, s[i]););
 }
 
-void Hacl_Hash_SHA1_legacy_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks)
+void Hacl_Hash_SHA1_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks)
 {
-  for (uint32_t i = (uint32_t)0U; i < n_blocks; i++)
+  for (uint32_t i = 0U; i < n_blocks; i++)
   {
-    uint32_t sz = (uint32_t)64U;
+    uint32_t sz = 64U;
     uint8_t *block = blocks + sz * i;
-    legacy_update(s, block);
+    update(s, block);
   }
 }
 
 void
-Hacl_Hash_SHA1_legacy_update_last(
-  uint32_t *s,
-  uint64_t prev_len,
-  uint8_t *input,
-  uint32_t input_len
-)
+Hacl_Hash_SHA1_update_last(uint32_t *s, uint64_t prev_len, uint8_t *input, uint32_t input_len)
 {
-  uint32_t blocks_n = input_len / (uint32_t)64U;
-  uint32_t blocks_len = blocks_n * (uint32_t)64U;
+  uint32_t blocks_n = input_len / 64U;
+  uint32_t blocks_len = blocks_n * 64U;
   uint8_t *blocks = input;
   uint32_t rest_len = input_len - blocks_len;
   uint8_t *rest = input + blocks_len;
-  Hacl_Hash_SHA1_legacy_update_multi(s, blocks, blocks_n);
+  Hacl_Hash_SHA1_update_multi(s, blocks, blocks_n);
   uint64_t total_input_len = prev_len + (uint64_t)input_len;
-  uint32_t
-  pad_len =
-    (uint32_t)1U
-    +
-      ((uint32_t)128U - ((uint32_t)9U + (uint32_t)(total_input_len % (uint64_t)(uint32_t)64U)))
-      % (uint32_t)64U
-    + (uint32_t)8U;
+  uint32_t pad_len = 1U + (128U - (9U + (uint32_t)(total_input_len % (uint64_t)64U))) % 64U + 8U;
   uint32_t tmp_len = rest_len + pad_len;
   uint8_t tmp_twoblocks[128U] = { 0U };
   uint8_t *tmp = tmp_twoblocks;
   uint8_t *tmp_rest = tmp;
   uint8_t *tmp_pad = tmp + rest_len;
   memcpy(tmp_rest, rest, rest_len * sizeof (uint8_t));
-  legacy_pad(total_input_len, tmp_pad);
-  Hacl_Hash_SHA1_legacy_update_multi(s, tmp, tmp_len / (uint32_t)64U);
+  pad(total_input_len, tmp_pad);
+  Hacl_Hash_SHA1_update_multi(s, tmp, tmp_len / 64U);
 }
 
-void Hacl_Hash_SHA1_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_SHA1_hash_oneshot(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  uint32_t
-  s[5U] =
-    {
-      (uint32_t)0x67452301U, (uint32_t)0xefcdab89U, (uint32_t)0x98badcfeU, (uint32_t)0x10325476U,
-      (uint32_t)0xc3d2e1f0U
-    };
-  uint32_t blocks_n0 = input_len / (uint32_t)64U;
+  uint32_t s[5U] = { 0x67452301U, 0xefcdab89U, 0x98badcfeU, 0x10325476U, 0xc3d2e1f0U };
+  uint32_t blocks_n0 = input_len / 64U;
   uint32_t blocks_n1;
-  if (input_len % (uint32_t)64U == (uint32_t)0U && blocks_n0 > (uint32_t)0U)
+  if (input_len % 64U == 0U && blocks_n0 > 0U)
   {
-    blocks_n1 = blocks_n0 - (uint32_t)1U;
+    blocks_n1 = blocks_n0 - 1U;
   }
   else
   {
     blocks_n1 = blocks_n0;
   }
-  uint32_t blocks_len0 = blocks_n1 * (uint32_t)64U;
+  uint32_t blocks_len0 = blocks_n1 * 64U;
   uint8_t *blocks0 = input;
   uint32_t rest_len0 = input_len - blocks_len0;
   uint8_t *rest0 = input + blocks_len0;
@@ -231,75 +191,75 @@ void Hacl_Hash_SHA1_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst
   uint8_t *blocks = blocks0;
   uint32_t rest_len = rest_len0;
   uint8_t *rest = rest0;
-  Hacl_Hash_SHA1_legacy_update_multi(s, blocks, blocks_n);
-  Hacl_Hash_SHA1_legacy_update_last(s, (uint64_t)blocks_len, rest, rest_len);
-  Hacl_Hash_Core_SHA1_legacy_finish(s, dst);
+  Hacl_Hash_SHA1_update_multi(s, blocks, blocks_n);
+  Hacl_Hash_SHA1_update_last(s, (uint64_t)blocks_len, rest, rest_len);
+  Hacl_Hash_SHA1_finish(s, output);
 }
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA1_legacy_create_in(void)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA1_malloc(void)
 {
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)5U, sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(5U, sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
-  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
+  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
   Hacl_Streaming_MD_state_32
   *p = (Hacl_Streaming_MD_state_32 *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_MD_state_32));
   p[0U] = s;
-  Hacl_Hash_Core_SHA1_legacy_init(block_state);
+  Hacl_Hash_SHA1_init(block_state);
   return p;
 }
 
-void Hacl_Streaming_SHA1_legacy_init(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_SHA1_reset(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
-  Hacl_Hash_Core_SHA1_legacy_init(block_state);
+  Hacl_Hash_SHA1_init(block_state);
   Hacl_Streaming_MD_state_32
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 /**
 0 = success, 1 = max length exceeded
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA1_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len)
+Hacl_Hash_SHA1_update(Hacl_Streaming_MD_state_32 *state, uint8_t *chunk, uint32_t chunk_len)
 {
-  Hacl_Streaming_MD_state_32 s = *p;
+  Hacl_Streaming_MD_state_32 s = *state;
   uint64_t total_len = s.total_len;
-  if ((uint64_t)len > (uint64_t)2305843009213693951U - total_len)
+  if ((uint64_t)chunk_len > 2305843009213693951ULL - total_len)
   {
     return Hacl_Streaming_Types_MaximumLengthExceeded;
   }
   uint32_t sz;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    sz = (uint32_t)64U;
+    sz = 64U;
   }
   else
   {
-    sz = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    sz = (uint32_t)(total_len % (uint64_t)64U);
   }
-  if (len <= (uint32_t)64U - sz)
+  if (chunk_len <= 64U - sz)
   {
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
     uint8_t *buf2 = buf + sz1;
-    memcpy(buf2, data, len * sizeof (uint8_t));
-    uint64_t total_len2 = total_len1 + (uint64_t)len;
-    *p
+    memcpy(buf2, chunk, chunk_len * sizeof (uint8_t));
+    uint64_t total_len2 = total_len1 + (uint64_t)chunk_len;
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
@@ -309,74 +269,74 @@ Hacl_Streaming_SHA1_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data,
         }
       );
   }
-  else if (sz == (uint32_t)0U)
+  else if (sz == 0U)
   {
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_Hash_SHA1_legacy_update_multi(block_state1, buf, (uint32_t)1U);
+      Hacl_Hash_SHA1_update_multi(block_state1, buf, 1U);
     }
     uint32_t ite;
-    if ((uint64_t)len % (uint64_t)(uint32_t)64U == (uint64_t)0U && (uint64_t)len > (uint64_t)0U)
+    if ((uint64_t)chunk_len % (uint64_t)64U == 0ULL && (uint64_t)chunk_len > 0ULL)
     {
-      ite = (uint32_t)64U;
+      ite = 64U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)len % (uint64_t)(uint32_t)64U);
+      ite = (uint32_t)((uint64_t)chunk_len % (uint64_t)64U);
     }
-    uint32_t n_blocks = (len - ite) / (uint32_t)64U;
-    uint32_t data1_len = n_blocks * (uint32_t)64U;
-    uint32_t data2_len = len - data1_len;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + data1_len;
-    Hacl_Hash_SHA1_legacy_update_multi(block_state1, data1, data1_len / (uint32_t)64U);
+    uint32_t n_blocks = (chunk_len - ite) / 64U;
+    uint32_t data1_len = n_blocks * 64U;
+    uint32_t data2_len = chunk_len - data1_len;
+    uint8_t *data1 = chunk;
+    uint8_t *data2 = chunk + data1_len;
+    Hacl_Hash_SHA1_update_multi(block_state1, data1, data1_len / 64U);
     uint8_t *dst = buf;
     memcpy(dst, data2, data2_len * sizeof (uint8_t));
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)len
+          .total_len = total_len1 + (uint64_t)chunk_len
         }
       );
   }
   else
   {
-    uint32_t diff = (uint32_t)64U - sz;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + diff;
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    uint32_t diff = 64U - sz;
+    uint8_t *chunk1 = chunk;
+    uint8_t *chunk2 = chunk + diff;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state10 = s1.block_state;
     uint8_t *buf0 = s1.buf;
     uint64_t total_len10 = s1.total_len;
     uint32_t sz10;
-    if (total_len10 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len10 > (uint64_t)0U)
+    if (total_len10 % (uint64_t)64U == 0ULL && total_len10 > 0ULL)
     {
-      sz10 = (uint32_t)64U;
+      sz10 = 64U;
     }
     else
     {
-      sz10 = (uint32_t)(total_len10 % (uint64_t)(uint32_t)64U);
+      sz10 = (uint32_t)(total_len10 % (uint64_t)64U);
     }
     uint8_t *buf2 = buf0 + sz10;
-    memcpy(buf2, data1, diff * sizeof (uint8_t));
+    memcpy(buf2, chunk1, diff * sizeof (uint8_t));
     uint64_t total_len2 = total_len10 + (uint64_t)diff;
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
@@ -385,114 +345,109 @@ Hacl_Streaming_SHA1_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data,
           .total_len = total_len2
         }
       );
-    Hacl_Streaming_MD_state_32 s10 = *p;
+    Hacl_Streaming_MD_state_32 s10 = *state;
     uint32_t *block_state1 = s10.block_state;
     uint8_t *buf = s10.buf;
     uint64_t total_len1 = s10.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_Hash_SHA1_legacy_update_multi(block_state1, buf, (uint32_t)1U);
+      Hacl_Hash_SHA1_update_multi(block_state1, buf, 1U);
     }
     uint32_t ite;
     if
-    (
-      (uint64_t)(len - diff)
-      % (uint64_t)(uint32_t)64U
-      == (uint64_t)0U
-      && (uint64_t)(len - diff) > (uint64_t)0U
-    )
+    ((uint64_t)(chunk_len - diff) % (uint64_t)64U == 0ULL && (uint64_t)(chunk_len - diff) > 0ULL)
     {
-      ite = (uint32_t)64U;
+      ite = 64U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)(len - diff) % (uint64_t)(uint32_t)64U);
+      ite = (uint32_t)((uint64_t)(chunk_len - diff) % (uint64_t)64U);
     }
-    uint32_t n_blocks = (len - diff - ite) / (uint32_t)64U;
-    uint32_t data1_len = n_blocks * (uint32_t)64U;
-    uint32_t data2_len = len - diff - data1_len;
-    uint8_t *data11 = data2;
-    uint8_t *data21 = data2 + data1_len;
-    Hacl_Hash_SHA1_legacy_update_multi(block_state1, data11, data1_len / (uint32_t)64U);
+    uint32_t n_blocks = (chunk_len - diff - ite) / 64U;
+    uint32_t data1_len = n_blocks * 64U;
+    uint32_t data2_len = chunk_len - diff - data1_len;
+    uint8_t *data1 = chunk2;
+    uint8_t *data2 = chunk2 + data1_len;
+    Hacl_Hash_SHA1_update_multi(block_state1, data1, data1_len / 64U);
     uint8_t *dst = buf;
-    memcpy(dst, data21, data2_len * sizeof (uint8_t));
-    *p
+    memcpy(dst, data2, data2_len * sizeof (uint8_t));
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)(len - diff)
+          .total_len = total_len1 + (uint64_t)(chunk_len - diff)
         }
       );
   }
   return Hacl_Streaming_Types_Success;
 }
 
-void Hacl_Streaming_SHA1_legacy_finish(Hacl_Streaming_MD_state_32 *p, uint8_t *dst)
+void Hacl_Hash_SHA1_digest(Hacl_Streaming_MD_state_32 *state, uint8_t *output)
 {
-  Hacl_Streaming_MD_state_32 scrut = *p;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state = scrut.block_state;
   uint8_t *buf_ = scrut.buf;
   uint64_t total_len = scrut.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    r = (uint32_t)64U;
+    r = 64U;
   }
   else
   {
-    r = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    r = (uint32_t)(total_len % (uint64_t)64U);
   }
   uint8_t *buf_1 = buf_;
   uint32_t tmp_block_state[5U] = { 0U };
-  memcpy(tmp_block_state, block_state, (uint32_t)5U * sizeof (uint32_t));
+  memcpy(tmp_block_state, block_state, 5U * sizeof (uint32_t));
   uint32_t ite;
-  if (r % (uint32_t)64U == (uint32_t)0U && r > (uint32_t)0U)
+  if (r % 64U == 0U && r > 0U)
   {
-    ite = (uint32_t)64U;
+    ite = 64U;
   }
   else
   {
-    ite = r % (uint32_t)64U;
+    ite = r % 64U;
   }
   uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
-  Hacl_Hash_SHA1_legacy_update_multi(tmp_block_state, buf_multi, (uint32_t)0U);
+  Hacl_Hash_SHA1_update_multi(tmp_block_state, buf_multi, 0U);
   uint64_t prev_len_last = total_len - (uint64_t)r;
-  Hacl_Hash_SHA1_legacy_update_last(tmp_block_state, prev_len_last, buf_last, r);
-  Hacl_Hash_Core_SHA1_legacy_finish(tmp_block_state, dst);
+  Hacl_Hash_SHA1_update_last(tmp_block_state, prev_len_last, buf_last, r);
+  Hacl_Hash_SHA1_finish(tmp_block_state, output);
 }
 
-void Hacl_Streaming_SHA1_legacy_free(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_SHA1_free(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
   KRML_HOST_FREE(block_state);
   KRML_HOST_FREE(buf);
-  KRML_HOST_FREE(s);
+  KRML_HOST_FREE(state);
 }
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA1_legacy_copy(Hacl_Streaming_MD_state_32 *s0)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA1_copy(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s0;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state0 = scrut.block_state;
   uint8_t *buf0 = scrut.buf;
   uint64_t total_len0 = scrut.total_len;
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  memcpy(buf, buf0, (uint32_t)64U * sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)5U, sizeof (uint32_t));
-  memcpy(block_state, block_state0, (uint32_t)5U * sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  memcpy(buf, buf0, 64U * sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(5U, sizeof (uint32_t));
+  memcpy(block_state, block_state0, 5U * sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
   s = { .block_state = block_state, .buf = buf, .total_len = total_len0 };
   Hacl_Streaming_MD_state_32
@@ -501,8 +456,8 @@ Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA1_legacy_copy(Hacl_Streaming_MD_st
   return p;
 }
 
-void Hacl_Streaming_SHA1_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_SHA1_hash(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  Hacl_Hash_SHA1_legacy_hash(input, input_len, dst);
+  Hacl_Hash_SHA1_hash_oneshot(output, input, input_len);
 }
 
diff --git a/Modules/_hacl/Hacl_Hash_SHA1.h b/Modules/_hacl/Hacl_Hash_SHA1.h
index dc50aa6f6d..ad1e8e72a7 100644
--- a/Modules/_hacl/Hacl_Hash_SHA1.h
+++ b/Modules/_hacl/Hacl_Hash_SHA1.h
@@ -31,31 +31,32 @@ extern "C" {
 #endif
 
 #include <string.h>
+#include "python_hacl_namespaces.h"
 #include "krml/types.h"
 #include "krml/lowstar_endianness.h"
 #include "krml/internal/target.h"
 
 #include "Hacl_Streaming_Types.h"
 
-typedef Hacl_Streaming_MD_state_32 Hacl_Streaming_SHA1_state;
+typedef Hacl_Streaming_MD_state_32 Hacl_Hash_SHA1_state_t;
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA1_legacy_create_in(void);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA1_malloc(void);
 
-void Hacl_Streaming_SHA1_legacy_init(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_SHA1_reset(Hacl_Streaming_MD_state_32 *state);
 
 /**
 0 = success, 1 = max length exceeded
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA1_legacy_update(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len);
+Hacl_Hash_SHA1_update(Hacl_Streaming_MD_state_32 *state, uint8_t *chunk, uint32_t chunk_len);
 
-void Hacl_Streaming_SHA1_legacy_finish(Hacl_Streaming_MD_state_32 *p, uint8_t *dst);
+void Hacl_Hash_SHA1_digest(Hacl_Streaming_MD_state_32 *state, uint8_t *output);
 
-void Hacl_Streaming_SHA1_legacy_free(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_SHA1_free(Hacl_Streaming_MD_state_32 *state);
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA1_legacy_copy(Hacl_Streaming_MD_state_32 *s0);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA1_copy(Hacl_Streaming_MD_state_32 *state);
 
-void Hacl_Streaming_SHA1_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst);
+void Hacl_Hash_SHA1_hash(uint8_t *output, uint8_t *input, uint32_t input_len);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/Hacl_Hash_SHA2.c b/Modules/_hacl/Hacl_Hash_SHA2.c
index 08e3f7edbf..4b6af5fc78 100644
--- a/Modules/_hacl/Hacl_Hash_SHA2.c
+++ b/Modules/_hacl/Hacl_Hash_SHA2.c
@@ -27,14 +27,14 @@
 
 
 
-void Hacl_SHA2_Scalar32_sha256_init(uint32_t *hash)
+void Hacl_Hash_SHA2_sha256_init(uint32_t *hash)
 {
   KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
+    0U,
+    8U,
+    1U,
     uint32_t *os = hash;
-    uint32_t x = Hacl_Impl_SHA2_Generic_h256[i];
+    uint32_t x = Hacl_Hash_SHA2_h256[i];
     os[i] = x;);
 }
 
@@ -42,49 +42,49 @@ static inline void sha256_update(uint8_t *b, uint32_t *hash)
 {
   uint32_t hash_old[8U] = { 0U };
   uint32_t ws[16U] = { 0U };
-  memcpy(hash_old, hash, (uint32_t)8U * sizeof (uint32_t));
+  memcpy(hash_old, hash, 8U * sizeof (uint32_t));
   uint8_t *b10 = b;
   uint32_t u = load32_be(b10);
   ws[0U] = u;
-  uint32_t u0 = load32_be(b10 + (uint32_t)4U);
+  uint32_t u0 = load32_be(b10 + 4U);
   ws[1U] = u0;
-  uint32_t u1 = load32_be(b10 + (uint32_t)8U);
+  uint32_t u1 = load32_be(b10 + 8U);
   ws[2U] = u1;
-  uint32_t u2 = load32_be(b10 + (uint32_t)12U);
+  uint32_t u2 = load32_be(b10 + 12U);
   ws[3U] = u2;
-  uint32_t u3 = load32_be(b10 + (uint32_t)16U);
+  uint32_t u3 = load32_be(b10 + 16U);
   ws[4U] = u3;
-  uint32_t u4 = load32_be(b10 + (uint32_t)20U);
+  uint32_t u4 = load32_be(b10 + 20U);
   ws[5U] = u4;
-  uint32_t u5 = load32_be(b10 + (uint32_t)24U);
+  uint32_t u5 = load32_be(b10 + 24U);
   ws[6U] = u5;
-  uint32_t u6 = load32_be(b10 + (uint32_t)28U);
+  uint32_t u6 = load32_be(b10 + 28U);
   ws[7U] = u6;
-  uint32_t u7 = load32_be(b10 + (uint32_t)32U);
+  uint32_t u7 = load32_be(b10 + 32U);
   ws[8U] = u7;
-  uint32_t u8 = load32_be(b10 + (uint32_t)36U);
+  uint32_t u8 = load32_be(b10 + 36U);
   ws[9U] = u8;
-  uint32_t u9 = load32_be(b10 + (uint32_t)40U);
+  uint32_t u9 = load32_be(b10 + 40U);
   ws[10U] = u9;
-  uint32_t u10 = load32_be(b10 + (uint32_t)44U);
+  uint32_t u10 = load32_be(b10 + 44U);
   ws[11U] = u10;
-  uint32_t u11 = load32_be(b10 + (uint32_t)48U);
+  uint32_t u11 = load32_be(b10 + 48U);
   ws[12U] = u11;
-  uint32_t u12 = load32_be(b10 + (uint32_t)52U);
+  uint32_t u12 = load32_be(b10 + 52U);
   ws[13U] = u12;
-  uint32_t u13 = load32_be(b10 + (uint32_t)56U);
+  uint32_t u13 = load32_be(b10 + 56U);
   ws[14U] = u13;
-  uint32_t u14 = load32_be(b10 + (uint32_t)60U);
+  uint32_t u14 = load32_be(b10 + 60U);
   ws[15U] = u14;
   KRML_MAYBE_FOR4(i0,
-    (uint32_t)0U,
-    (uint32_t)4U,
-    (uint32_t)1U,
+    0U,
+    4U,
+    1U,
     KRML_MAYBE_FOR16(i,
-      (uint32_t)0U,
-      (uint32_t)16U,
-      (uint32_t)1U,
-      uint32_t k_t = Hacl_Impl_SHA2_Generic_k224_256[(uint32_t)16U * i0 + i];
+      0U,
+      16U,
+      1U,
+      uint32_t k_t = Hacl_Hash_SHA2_k224_256[16U * i0 + i];
       uint32_t ws_t = ws[i];
       uint32_t a0 = hash[0U];
       uint32_t b0 = hash[1U];
@@ -98,20 +98,13 @@ static inline void sha256_update(uint8_t *b, uint32_t *hash)
       uint32_t
       t1 =
         h02
-        +
-          ((e0 << (uint32_t)26U | e0 >> (uint32_t)6U)
-          ^
-            ((e0 << (uint32_t)21U | e0 >> (uint32_t)11U)
-            ^ (e0 << (uint32_t)7U | e0 >> (uint32_t)25U)))
+        + ((e0 << 26U | e0 >> 6U) ^ ((e0 << 21U | e0 >> 11U) ^ (e0 << 7U | e0 >> 25U)))
         + ((e0 & f0) ^ (~e0 & g0))
         + k_e_t
         + ws_t;
       uint32_t
       t2 =
-        ((a0 << (uint32_t)30U | a0 >> (uint32_t)2U)
-        ^
-          ((a0 << (uint32_t)19U | a0 >> (uint32_t)13U)
-          ^ (a0 << (uint32_t)10U | a0 >> (uint32_t)22U)))
+        ((a0 << 30U | a0 >> 2U) ^ ((a0 << 19U | a0 >> 13U) ^ (a0 << 10U | a0 >> 22U)))
         + ((a0 & b0) ^ ((a0 & c0) ^ (b0 & c0)));
       uint32_t a1 = t1 + t2;
       uint32_t b1 = a0;
@@ -129,74 +122,63 @@ static inline void sha256_update(uint8_t *b, uint32_t *hash)
       hash[5U] = f1;
       hash[6U] = g1;
       hash[7U] = h12;);
-    if (i0 < (uint32_t)3U)
+    if (i0 < 3U)
     {
       KRML_MAYBE_FOR16(i,
-        (uint32_t)0U,
-        (uint32_t)16U,
-        (uint32_t)1U,
+        0U,
+        16U,
+        1U,
         uint32_t t16 = ws[i];
-        uint32_t t15 = ws[(i + (uint32_t)1U) % (uint32_t)16U];
-        uint32_t t7 = ws[(i + (uint32_t)9U) % (uint32_t)16U];
-        uint32_t t2 = ws[(i + (uint32_t)14U) % (uint32_t)16U];
-        uint32_t
-        s1 =
-          (t2 << (uint32_t)15U | t2 >> (uint32_t)17U)
-          ^ ((t2 << (uint32_t)13U | t2 >> (uint32_t)19U) ^ t2 >> (uint32_t)10U);
-        uint32_t
-        s0 =
-          (t15 << (uint32_t)25U | t15 >> (uint32_t)7U)
-          ^ ((t15 << (uint32_t)14U | t15 >> (uint32_t)18U) ^ t15 >> (uint32_t)3U);
+        uint32_t t15 = ws[(i + 1U) % 16U];
+        uint32_t t7 = ws[(i + 9U) % 16U];
+        uint32_t t2 = ws[(i + 14U) % 16U];
+        uint32_t s1 = (t2 << 15U | t2 >> 17U) ^ ((t2 << 13U | t2 >> 19U) ^ t2 >> 10U);
+        uint32_t s0 = (t15 << 25U | t15 >> 7U) ^ ((t15 << 14U | t15 >> 18U) ^ t15 >> 3U);
         ws[i] = s1 + t7 + s0 + t16;);
     });
   KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
+    0U,
+    8U,
+    1U,
     uint32_t *os = hash;
     uint32_t x = hash[i] + hash_old[i];
     os[i] = x;);
 }
 
-void Hacl_SHA2_Scalar32_sha256_update_nblocks(uint32_t len, uint8_t *b, uint32_t *st)
+void Hacl_Hash_SHA2_sha256_update_nblocks(uint32_t len, uint8_t *b, uint32_t *st)
 {
-  uint32_t blocks = len / (uint32_t)64U;
-  for (uint32_t i = (uint32_t)0U; i < blocks; i++)
+  uint32_t blocks = len / 64U;
+  for (uint32_t i = 0U; i < blocks; i++)
   {
     uint8_t *b0 = b;
-    uint8_t *mb = b0 + i * (uint32_t)64U;
+    uint8_t *mb = b0 + i * 64U;
     sha256_update(mb, st);
   }
 }
 
 void
-Hacl_SHA2_Scalar32_sha256_update_last(
-  uint64_t totlen,
-  uint32_t len,
-  uint8_t *b,
-  uint32_t *hash
-)
+Hacl_Hash_SHA2_sha256_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *hash)
 {
   uint32_t blocks;
-  if (len + (uint32_t)8U + (uint32_t)1U <= (uint32_t)64U)
+  if (len + 8U + 1U <= 64U)
   {
-    blocks = (uint32_t)1U;
+    blocks = 1U;
   }
   else
   {
-    blocks = (uint32_t)2U;
+    blocks = 2U;
   }
-  uint32_t fin = blocks * (uint32_t)64U;
+  uint32_t fin = blocks * 64U;
   uint8_t last[128U] = { 0U };
   uint8_t totlen_buf[8U] = { 0U };
-  uint64_t total_len_bits = totlen << (uint32_t)3U;
+  uint64_t total_len_bits = totlen << 3U;
   store64_be(totlen_buf, total_len_bits);
   uint8_t *b0 = b;
   memcpy(last, b0, len * sizeof (uint8_t));
-  last[len] = (uint8_t)0x80U;
-  memcpy(last + fin - (uint32_t)8U, totlen_buf, (uint32_t)8U * sizeof (uint8_t));
+  last[len] = 0x80U;
+  memcpy(last + fin - 8U, totlen_buf, 8U * sizeof (uint8_t));
   uint8_t *last00 = last;
-  uint8_t *last10 = last + (uint32_t)64U;
+  uint8_t *last10 = last + 64U;
   uint8_t *l0 = last00;
   uint8_t *l1 = last10;
   uint8_t *lb0 = l0;
@@ -204,65 +186,56 @@ Hacl_SHA2_Scalar32_sha256_update_last(
   uint8_t *last0 = lb0;
   uint8_t *last1 = lb1;
   sha256_update(last0, hash);
-  if (blocks > (uint32_t)1U)
+  if (blocks > 1U)
   {
     sha256_update(last1, hash);
     return;
   }
 }
 
-void Hacl_SHA2_Scalar32_sha256_finish(uint32_t *st, uint8_t *h)
+void Hacl_Hash_SHA2_sha256_finish(uint32_t *st, uint8_t *h)
 {
   uint8_t hbuf[32U] = { 0U };
-  KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
-    store32_be(hbuf + i * (uint32_t)4U, st[i]););
-  memcpy(h, hbuf, (uint32_t)32U * sizeof (uint8_t));
+  KRML_MAYBE_FOR8(i, 0U, 8U, 1U, store32_be(hbuf + i * 4U, st[i]););
+  memcpy(h, hbuf, 32U * sizeof (uint8_t));
 }
 
-void Hacl_SHA2_Scalar32_sha224_init(uint32_t *hash)
+void Hacl_Hash_SHA2_sha224_init(uint32_t *hash)
 {
   KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
+    0U,
+    8U,
+    1U,
     uint32_t *os = hash;
-    uint32_t x = Hacl_Impl_SHA2_Generic_h224[i];
+    uint32_t x = Hacl_Hash_SHA2_h224[i];
     os[i] = x;);
 }
 
 static inline void sha224_update_nblocks(uint32_t len, uint8_t *b, uint32_t *st)
 {
-  Hacl_SHA2_Scalar32_sha256_update_nblocks(len, b, st);
+  Hacl_Hash_SHA2_sha256_update_nblocks(len, b, st);
 }
 
-void
-Hacl_SHA2_Scalar32_sha224_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *st)
+void Hacl_Hash_SHA2_sha224_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *st)
 {
-  Hacl_SHA2_Scalar32_sha256_update_last(totlen, len, b, st);
+  Hacl_Hash_SHA2_sha256_update_last(totlen, len, b, st);
 }
 
-void Hacl_SHA2_Scalar32_sha224_finish(uint32_t *st, uint8_t *h)
+void Hacl_Hash_SHA2_sha224_finish(uint32_t *st, uint8_t *h)
 {
   uint8_t hbuf[32U] = { 0U };
-  KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
-    store32_be(hbuf + i * (uint32_t)4U, st[i]););
-  memcpy(h, hbuf, (uint32_t)28U * sizeof (uint8_t));
+  KRML_MAYBE_FOR8(i, 0U, 8U, 1U, store32_be(hbuf + i * 4U, st[i]););
+  memcpy(h, hbuf, 28U * sizeof (uint8_t));
 }
 
-void Hacl_SHA2_Scalar32_sha512_init(uint64_t *hash)
+void Hacl_Hash_SHA2_sha512_init(uint64_t *hash)
 {
   KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
+    0U,
+    8U,
+    1U,
     uint64_t *os = hash;
-    uint64_t x = Hacl_Impl_SHA2_Generic_h512[i];
+    uint64_t x = Hacl_Hash_SHA2_h512[i];
     os[i] = x;);
 }
 
@@ -270,49 +243,49 @@ static inline void sha512_update(uint8_t *b, uint64_t *hash)
 {
   uint64_t hash_old[8U] = { 0U };
   uint64_t ws[16U] = { 0U };
-  memcpy(hash_old, hash, (uint32_t)8U * sizeof (uint64_t));
+  memcpy(hash_old, hash, 8U * sizeof (uint64_t));
   uint8_t *b10 = b;
   uint64_t u = load64_be(b10);
   ws[0U] = u;
-  uint64_t u0 = load64_be(b10 + (uint32_t)8U);
+  uint64_t u0 = load64_be(b10 + 8U);
   ws[1U] = u0;
-  uint64_t u1 = load64_be(b10 + (uint32_t)16U);
+  uint64_t u1 = load64_be(b10 + 16U);
   ws[2U] = u1;
-  uint64_t u2 = load64_be(b10 + (uint32_t)24U);
+  uint64_t u2 = load64_be(b10 + 24U);
   ws[3U] = u2;
-  uint64_t u3 = load64_be(b10 + (uint32_t)32U);
+  uint64_t u3 = load64_be(b10 + 32U);
   ws[4U] = u3;
-  uint64_t u4 = load64_be(b10 + (uint32_t)40U);
+  uint64_t u4 = load64_be(b10 + 40U);
   ws[5U] = u4;
-  uint64_t u5 = load64_be(b10 + (uint32_t)48U);
+  uint64_t u5 = load64_be(b10 + 48U);
   ws[6U] = u5;
-  uint64_t u6 = load64_be(b10 + (uint32_t)56U);
+  uint64_t u6 = load64_be(b10 + 56U);
   ws[7U] = u6;
-  uint64_t u7 = load64_be(b10 + (uint32_t)64U);
+  uint64_t u7 = load64_be(b10 + 64U);
   ws[8U] = u7;
-  uint64_t u8 = load64_be(b10 + (uint32_t)72U);
+  uint64_t u8 = load64_be(b10 + 72U);
   ws[9U] = u8;
-  uint64_t u9 = load64_be(b10 + (uint32_t)80U);
+  uint64_t u9 = load64_be(b10 + 80U);
   ws[10U] = u9;
-  uint64_t u10 = load64_be(b10 + (uint32_t)88U);
+  uint64_t u10 = load64_be(b10 + 88U);
   ws[11U] = u10;
-  uint64_t u11 = load64_be(b10 + (uint32_t)96U);
+  uint64_t u11 = load64_be(b10 + 96U);
   ws[12U] = u11;
-  uint64_t u12 = load64_be(b10 + (uint32_t)104U);
+  uint64_t u12 = load64_be(b10 + 104U);
   ws[13U] = u12;
-  uint64_t u13 = load64_be(b10 + (uint32_t)112U);
+  uint64_t u13 = load64_be(b10 + 112U);
   ws[14U] = u13;
-  uint64_t u14 = load64_be(b10 + (uint32_t)120U);
+  uint64_t u14 = load64_be(b10 + 120U);
   ws[15U] = u14;
   KRML_MAYBE_FOR5(i0,
-    (uint32_t)0U,
-    (uint32_t)5U,
-    (uint32_t)1U,
+    0U,
+    5U,
+    1U,
     KRML_MAYBE_FOR16(i,
-      (uint32_t)0U,
-      (uint32_t)16U,
-      (uint32_t)1U,
-      uint64_t k_t = Hacl_Impl_SHA2_Generic_k384_512[(uint32_t)16U * i0 + i];
+      0U,
+      16U,
+      1U,
+      uint64_t k_t = Hacl_Hash_SHA2_k384_512[16U * i0 + i];
       uint64_t ws_t = ws[i];
       uint64_t a0 = hash[0U];
       uint64_t b0 = hash[1U];
@@ -326,20 +299,13 @@ static inline void sha512_update(uint8_t *b, uint64_t *hash)
       uint64_t
       t1 =
         h02
-        +
-          ((e0 << (uint32_t)50U | e0 >> (uint32_t)14U)
-          ^
-            ((e0 << (uint32_t)46U | e0 >> (uint32_t)18U)
-            ^ (e0 << (uint32_t)23U | e0 >> (uint32_t)41U)))
+        + ((e0 << 50U | e0 >> 14U) ^ ((e0 << 46U | e0 >> 18U) ^ (e0 << 23U | e0 >> 41U)))
         + ((e0 & f0) ^ (~e0 & g0))
         + k_e_t
         + ws_t;
       uint64_t
       t2 =
-        ((a0 << (uint32_t)36U | a0 >> (uint32_t)28U)
-        ^
-          ((a0 << (uint32_t)30U | a0 >> (uint32_t)34U)
-          ^ (a0 << (uint32_t)25U | a0 >> (uint32_t)39U)))
+        ((a0 << 36U | a0 >> 28U) ^ ((a0 << 30U | a0 >> 34U) ^ (a0 << 25U | a0 >> 39U)))
         + ((a0 & b0) ^ ((a0 & c0) ^ (b0 & c0)));
       uint64_t a1 = t1 + t2;
       uint64_t b1 = a0;
@@ -357,48 +323,42 @@ static inline void sha512_update(uint8_t *b, uint64_t *hash)
       hash[5U] = f1;
       hash[6U] = g1;
       hash[7U] = h12;);
-    if (i0 < (uint32_t)4U)
+    if (i0 < 4U)
     {
       KRML_MAYBE_FOR16(i,
-        (uint32_t)0U,
-        (uint32_t)16U,
-        (uint32_t)1U,
+        0U,
+        16U,
+        1U,
         uint64_t t16 = ws[i];
-        uint64_t t15 = ws[(i + (uint32_t)1U) % (uint32_t)16U];
-        uint64_t t7 = ws[(i + (uint32_t)9U) % (uint32_t)16U];
-        uint64_t t2 = ws[(i + (uint32_t)14U) % (uint32_t)16U];
-        uint64_t
-        s1 =
-          (t2 << (uint32_t)45U | t2 >> (uint32_t)19U)
-          ^ ((t2 << (uint32_t)3U | t2 >> (uint32_t)61U) ^ t2 >> (uint32_t)6U);
-        uint64_t
-        s0 =
-          (t15 << (uint32_t)63U | t15 >> (uint32_t)1U)
-          ^ ((t15 << (uint32_t)56U | t15 >> (uint32_t)8U) ^ t15 >> (uint32_t)7U);
+        uint64_t t15 = ws[(i + 1U) % 16U];
+        uint64_t t7 = ws[(i + 9U) % 16U];
+        uint64_t t2 = ws[(i + 14U) % 16U];
+        uint64_t s1 = (t2 << 45U | t2 >> 19U) ^ ((t2 << 3U | t2 >> 61U) ^ t2 >> 6U);
+        uint64_t s0 = (t15 << 63U | t15 >> 1U) ^ ((t15 << 56U | t15 >> 8U) ^ t15 >> 7U);
         ws[i] = s1 + t7 + s0 + t16;);
     });
   KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
+    0U,
+    8U,
+    1U,
     uint64_t *os = hash;
     uint64_t x = hash[i] + hash_old[i];
     os[i] = x;);
 }
 
-void Hacl_SHA2_Scalar32_sha512_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st)
+void Hacl_Hash_SHA2_sha512_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st)
 {
-  uint32_t blocks = len / (uint32_t)128U;
-  for (uint32_t i = (uint32_t)0U; i < blocks; i++)
+  uint32_t blocks = len / 128U;
+  for (uint32_t i = 0U; i < blocks; i++)
   {
     uint8_t *b0 = b;
-    uint8_t *mb = b0 + i * (uint32_t)128U;
+    uint8_t *mb = b0 + i * 128U;
     sha512_update(mb, st);
   }
 }
 
 void
-Hacl_SHA2_Scalar32_sha512_update_last(
+Hacl_Hash_SHA2_sha512_update_last(
   FStar_UInt128_uint128 totlen,
   uint32_t len,
   uint8_t *b,
@@ -406,25 +366,25 @@ Hacl_SHA2_Scalar32_sha512_update_last(
 )
 {
   uint32_t blocks;
-  if (len + (uint32_t)16U + (uint32_t)1U <= (uint32_t)128U)
+  if (len + 16U + 1U <= 128U)
   {
-    blocks = (uint32_t)1U;
+    blocks = 1U;
   }
   else
   {
-    blocks = (uint32_t)2U;
+    blocks = 2U;
   }
-  uint32_t fin = blocks * (uint32_t)128U;
+  uint32_t fin = blocks * 128U;
   uint8_t last[256U] = { 0U };
   uint8_t totlen_buf[16U] = { 0U };
-  FStar_UInt128_uint128 total_len_bits = FStar_UInt128_shift_left(totlen, (uint32_t)3U);
+  FStar_UInt128_uint128 total_len_bits = FStar_UInt128_shift_left(totlen, 3U);
   store128_be(totlen_buf, total_len_bits);
   uint8_t *b0 = b;
   memcpy(last, b0, len * sizeof (uint8_t));
-  last[len] = (uint8_t)0x80U;
-  memcpy(last + fin - (uint32_t)16U, totlen_buf, (uint32_t)16U * sizeof (uint8_t));
+  last[len] = 0x80U;
+  memcpy(last + fin - 16U, totlen_buf, 16U * sizeof (uint8_t));
   uint8_t *last00 = last;
-  uint8_t *last10 = last + (uint32_t)128U;
+  uint8_t *last10 = last + 128U;
   uint8_t *l0 = last00;
   uint8_t *l1 = last10;
   uint8_t *lb0 = l0;
@@ -432,76 +392,68 @@ Hacl_SHA2_Scalar32_sha512_update_last(
   uint8_t *last0 = lb0;
   uint8_t *last1 = lb1;
   sha512_update(last0, hash);
-  if (blocks > (uint32_t)1U)
+  if (blocks > 1U)
   {
     sha512_update(last1, hash);
     return;
   }
 }
 
-void Hacl_SHA2_Scalar32_sha512_finish(uint64_t *st, uint8_t *h)
+void Hacl_Hash_SHA2_sha512_finish(uint64_t *st, uint8_t *h)
 {
   uint8_t hbuf[64U] = { 0U };
-  KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
-    store64_be(hbuf + i * (uint32_t)8U, st[i]););
-  memcpy(h, hbuf, (uint32_t)64U * sizeof (uint8_t));
+  KRML_MAYBE_FOR8(i, 0U, 8U, 1U, store64_be(hbuf + i * 8U, st[i]););
+  memcpy(h, hbuf, 64U * sizeof (uint8_t));
 }
 
-void Hacl_SHA2_Scalar32_sha384_init(uint64_t *hash)
+void Hacl_Hash_SHA2_sha384_init(uint64_t *hash)
 {
   KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
+    0U,
+    8U,
+    1U,
     uint64_t *os = hash;
-    uint64_t x = Hacl_Impl_SHA2_Generic_h384[i];
+    uint64_t x = Hacl_Hash_SHA2_h384[i];
     os[i] = x;);
 }
 
-void Hacl_SHA2_Scalar32_sha384_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st)
+void Hacl_Hash_SHA2_sha384_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st)
 {
-  Hacl_SHA2_Scalar32_sha512_update_nblocks(len, b, st);
+  Hacl_Hash_SHA2_sha512_update_nblocks(len, b, st);
 }
 
 void
-Hacl_SHA2_Scalar32_sha384_update_last(
+Hacl_Hash_SHA2_sha384_update_last(
   FStar_UInt128_uint128 totlen,
   uint32_t len,
   uint8_t *b,
   uint64_t *st
 )
 {
-  Hacl_SHA2_Scalar32_sha512_update_last(totlen, len, b, st);
+  Hacl_Hash_SHA2_sha512_update_last(totlen, len, b, st);
 }
 
-void Hacl_SHA2_Scalar32_sha384_finish(uint64_t *st, uint8_t *h)
+void Hacl_Hash_SHA2_sha384_finish(uint64_t *st, uint8_t *h)
 {
   uint8_t hbuf[64U] = { 0U };
-  KRML_MAYBE_FOR8(i,
-    (uint32_t)0U,
-    (uint32_t)8U,
-    (uint32_t)1U,
-    store64_be(hbuf + i * (uint32_t)8U, st[i]););
-  memcpy(h, hbuf, (uint32_t)48U * sizeof (uint8_t));
+  KRML_MAYBE_FOR8(i, 0U, 8U, 1U, store64_be(hbuf + i * 8U, st[i]););
+  memcpy(h, hbuf, 48U * sizeof (uint8_t));
 }
 
 /**
 Allocate initial state for the SHA2_256 hash. The state is to be freed by
 calling `free_256`.
 */
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_create_in_256(void)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA2_malloc_256(void)
 {
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(8U, sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
-  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
+  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
   Hacl_Streaming_MD_state_32
   *p = (Hacl_Streaming_MD_state_32 *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_MD_state_32));
   p[0U] = s;
-  Hacl_SHA2_Scalar32_sha256_init(block_state);
+  Hacl_Hash_SHA2_sha256_init(block_state);
   return p;
 }
 
@@ -511,16 +463,16 @@ The state is to be freed by calling `free_256`. Cloning the state this way is
 useful, for instance, if your control-flow diverges and you need to feed
 more (different) data into the hash in each branch.
 */
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_copy_256(Hacl_Streaming_MD_state_32 *s0)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA2_copy_256(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s0;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state0 = scrut.block_state;
   uint8_t *buf0 = scrut.buf;
   uint64_t total_len0 = scrut.total_len;
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  memcpy(buf, buf0, (uint32_t)64U * sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint32_t));
-  memcpy(block_state, block_state0, (uint32_t)8U * sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  memcpy(buf, buf0, 64U * sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(8U, sizeof (uint32_t));
+  memcpy(block_state, block_state0, 8U * sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
   s = { .block_state = block_state, .buf = buf, .total_len = total_len0 };
   Hacl_Streaming_MD_state_32
@@ -532,54 +484,54 @@ Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_copy_256(Hacl_Streaming_MD_state
 /**
 Reset an existing state to the initial hash state with empty data.
 */
-void Hacl_Streaming_SHA2_init_256(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_SHA2_reset_256(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
-  Hacl_SHA2_Scalar32_sha256_init(block_state);
+  Hacl_Hash_SHA2_sha256_init(block_state);
   Hacl_Streaming_MD_state_32
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 static inline Hacl_Streaming_Types_error_code
-update_224_256(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len)
+update_224_256(Hacl_Streaming_MD_state_32 *state, uint8_t *chunk, uint32_t chunk_len)
 {
-  Hacl_Streaming_MD_state_32 s = *p;
+  Hacl_Streaming_MD_state_32 s = *state;
   uint64_t total_len = s.total_len;
-  if ((uint64_t)len > (uint64_t)2305843009213693951U - total_len)
+  if ((uint64_t)chunk_len > 2305843009213693951ULL - total_len)
   {
     return Hacl_Streaming_Types_MaximumLengthExceeded;
   }
   uint32_t sz;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    sz = (uint32_t)64U;
+    sz = 64U;
   }
   else
   {
-    sz = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    sz = (uint32_t)(total_len % (uint64_t)64U);
   }
-  if (len <= (uint32_t)64U - sz)
+  if (chunk_len <= 64U - sz)
   {
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
     uint8_t *buf2 = buf + sz1;
-    memcpy(buf2, data, len * sizeof (uint8_t));
-    uint64_t total_len2 = total_len1 + (uint64_t)len;
-    *p
+    memcpy(buf2, chunk, chunk_len * sizeof (uint8_t));
+    uint64_t total_len2 = total_len1 + (uint64_t)chunk_len;
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
@@ -589,76 +541,74 @@ update_224_256(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len)
         }
       );
   }
-  else if (sz == (uint32_t)0U)
+  else if (sz == 0U)
   {
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_SHA2_Scalar32_sha256_update_nblocks((uint32_t)64U, buf, block_state1);
+      Hacl_Hash_SHA2_sha256_update_nblocks(64U, buf, block_state1);
     }
     uint32_t ite;
-    if ((uint64_t)len % (uint64_t)(uint32_t)64U == (uint64_t)0U && (uint64_t)len > (uint64_t)0U)
+    if ((uint64_t)chunk_len % (uint64_t)64U == 0ULL && (uint64_t)chunk_len > 0ULL)
     {
-      ite = (uint32_t)64U;
+      ite = 64U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)len % (uint64_t)(uint32_t)64U);
+      ite = (uint32_t)((uint64_t)chunk_len % (uint64_t)64U);
     }
-    uint32_t n_blocks = (len - ite) / (uint32_t)64U;
-    uint32_t data1_len = n_blocks * (uint32_t)64U;
-    uint32_t data2_len = len - data1_len;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + data1_len;
-    Hacl_SHA2_Scalar32_sha256_update_nblocks(data1_len / (uint32_t)64U * (uint32_t)64U,
-      data1,
-      block_state1);
+    uint32_t n_blocks = (chunk_len - ite) / 64U;
+    uint32_t data1_len = n_blocks * 64U;
+    uint32_t data2_len = chunk_len - data1_len;
+    uint8_t *data1 = chunk;
+    uint8_t *data2 = chunk + data1_len;
+    Hacl_Hash_SHA2_sha256_update_nblocks(data1_len / 64U * 64U, data1, block_state1);
     uint8_t *dst = buf;
     memcpy(dst, data2, data2_len * sizeof (uint8_t));
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)len
+          .total_len = total_len1 + (uint64_t)chunk_len
         }
       );
   }
   else
   {
-    uint32_t diff = (uint32_t)64U - sz;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + diff;
-    Hacl_Streaming_MD_state_32 s1 = *p;
+    uint32_t diff = 64U - sz;
+    uint8_t *chunk1 = chunk;
+    uint8_t *chunk2 = chunk + diff;
+    Hacl_Streaming_MD_state_32 s1 = *state;
     uint32_t *block_state10 = s1.block_state;
     uint8_t *buf0 = s1.buf;
     uint64_t total_len10 = s1.total_len;
     uint32_t sz10;
-    if (total_len10 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len10 > (uint64_t)0U)
+    if (total_len10 % (uint64_t)64U == 0ULL && total_len10 > 0ULL)
     {
-      sz10 = (uint32_t)64U;
+      sz10 = 64U;
     }
     else
     {
-      sz10 = (uint32_t)(total_len10 % (uint64_t)(uint32_t)64U);
+      sz10 = (uint32_t)(total_len10 % (uint64_t)64U);
     }
     uint8_t *buf2 = buf0 + sz10;
-    memcpy(buf2, data1, diff * sizeof (uint8_t));
+    memcpy(buf2, chunk1, diff * sizeof (uint8_t));
     uint64_t total_len2 = total_len10 + (uint64_t)diff;
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
@@ -667,55 +617,48 @@ update_224_256(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len)
           .total_len = total_len2
         }
       );
-    Hacl_Streaming_MD_state_32 s10 = *p;
+    Hacl_Streaming_MD_state_32 s10 = *state;
     uint32_t *block_state1 = s10.block_state;
     uint8_t *buf = s10.buf;
     uint64_t total_len1 = s10.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)64U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)64U;
+      sz1 = 64U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)64U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)64U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_SHA2_Scalar32_sha256_update_nblocks((uint32_t)64U, buf, block_state1);
+      Hacl_Hash_SHA2_sha256_update_nblocks(64U, buf, block_state1);
     }
     uint32_t ite;
     if
-    (
-      (uint64_t)(len - diff)
-      % (uint64_t)(uint32_t)64U
-      == (uint64_t)0U
-      && (uint64_t)(len - diff) > (uint64_t)0U
-    )
+    ((uint64_t)(chunk_len - diff) % (uint64_t)64U == 0ULL && (uint64_t)(chunk_len - diff) > 0ULL)
     {
-      ite = (uint32_t)64U;
+      ite = 64U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)(len - diff) % (uint64_t)(uint32_t)64U);
+      ite = (uint32_t)((uint64_t)(chunk_len - diff) % (uint64_t)64U);
     }
-    uint32_t n_blocks = (len - diff - ite) / (uint32_t)64U;
-    uint32_t data1_len = n_blocks * (uint32_t)64U;
-    uint32_t data2_len = len - diff - data1_len;
-    uint8_t *data11 = data2;
-    uint8_t *data21 = data2 + data1_len;
-    Hacl_SHA2_Scalar32_sha256_update_nblocks(data1_len / (uint32_t)64U * (uint32_t)64U,
-      data11,
-      block_state1);
+    uint32_t n_blocks = (chunk_len - diff - ite) / 64U;
+    uint32_t data1_len = n_blocks * 64U;
+    uint32_t data2_len = chunk_len - diff - data1_len;
+    uint8_t *data1 = chunk2;
+    uint8_t *data2 = chunk2 + data1_len;
+    Hacl_Hash_SHA2_sha256_update_nblocks(data1_len / 64U * 64U, data1, block_state1);
     uint8_t *dst = buf;
-    memcpy(dst, data21, data2_len * sizeof (uint8_t));
-    *p
+    memcpy(dst, data2, data2_len * sizeof (uint8_t));
+    *state
     =
       (
         (Hacl_Streaming_MD_state_32){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)(len - diff)
+          .total_len = total_len1 + (uint64_t)(chunk_len - diff)
         }
       );
   }
@@ -725,209 +668,203 @@ update_224_256(Hacl_Streaming_MD_state_32 *p, uint8_t *data, uint32_t len)
 /**
 Feed an arbitrary amount of data into the hash. This function returns 0 for
 success, or 1 if the combined length of all of the data passed to `update_256`
-(since the last call to `init_256`) exceeds 2^61-1 bytes.
+(since the last call to `reset_256`) exceeds 2^61-1 bytes.
 
 This function is identical to the update function for SHA2_224.
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_256(
-  Hacl_Streaming_MD_state_32 *p,
+Hacl_Hash_SHA2_update_256(
+  Hacl_Streaming_MD_state_32 *state,
   uint8_t *input,
   uint32_t input_len
 )
 {
-  return update_224_256(p, input, input_len);
+  return update_224_256(state, input, input_len);
 }
 
 /**
-Write the resulting hash into `dst`, an array of 32 bytes. The state remains
-valid after a call to `finish_256`, meaning the user may feed more data into
-the hash via `update_256`. (The finish_256 function operates on an internal copy of
+Write the resulting hash into `output`, an array of 32 bytes. The state remains
+valid after a call to `digest_256`, meaning the user may feed more data into
+the hash via `update_256`. (The digest_256 function operates on an internal copy of
 the state and therefore does not invalidate the client-held state `p`.)
 */
-void Hacl_Streaming_SHA2_finish_256(Hacl_Streaming_MD_state_32 *p, uint8_t *dst)
+void Hacl_Hash_SHA2_digest_256(Hacl_Streaming_MD_state_32 *state, uint8_t *output)
 {
-  Hacl_Streaming_MD_state_32 scrut = *p;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state = scrut.block_state;
   uint8_t *buf_ = scrut.buf;
   uint64_t total_len = scrut.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    r = (uint32_t)64U;
+    r = 64U;
   }
   else
   {
-    r = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    r = (uint32_t)(total_len % (uint64_t)64U);
   }
   uint8_t *buf_1 = buf_;
   uint32_t tmp_block_state[8U] = { 0U };
-  memcpy(tmp_block_state, block_state, (uint32_t)8U * sizeof (uint32_t));
+  memcpy(tmp_block_state, block_state, 8U * sizeof (uint32_t));
   uint32_t ite;
-  if (r % (uint32_t)64U == (uint32_t)0U && r > (uint32_t)0U)
+  if (r % 64U == 0U && r > 0U)
   {
-    ite = (uint32_t)64U;
+    ite = 64U;
   }
   else
   {
-    ite = r % (uint32_t)64U;
+    ite = r % 64U;
   }
   uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
-  Hacl_SHA2_Scalar32_sha256_update_nblocks((uint32_t)0U, buf_multi, tmp_block_state);
+  Hacl_Hash_SHA2_sha256_update_nblocks(0U, buf_multi, tmp_block_state);
   uint64_t prev_len_last = total_len - (uint64_t)r;
-  Hacl_SHA2_Scalar32_sha256_update_last(prev_len_last + (uint64_t)r,
-    r,
-    buf_last,
-    tmp_block_state);
-  Hacl_SHA2_Scalar32_sha256_finish(tmp_block_state, dst);
+  Hacl_Hash_SHA2_sha256_update_last(prev_len_last + (uint64_t)r, r, buf_last, tmp_block_state);
+  Hacl_Hash_SHA2_sha256_finish(tmp_block_state, output);
 }
 
 /**
-Free a state allocated with `create_in_256`.
+Free a state allocated with `malloc_256`.
 
 This function is identical to the free function for SHA2_224.
 */
-void Hacl_Streaming_SHA2_free_256(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_SHA2_free_256(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
   KRML_HOST_FREE(block_state);
   KRML_HOST_FREE(buf);
-  KRML_HOST_FREE(s);
+  KRML_HOST_FREE(state);
 }
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 32 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 32 bytes.
 */
-void Hacl_Streaming_SHA2_hash_256(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_SHA2_hash_256(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
   uint8_t *ib = input;
-  uint8_t *rb = dst;
+  uint8_t *rb = output;
   uint32_t st[8U] = { 0U };
-  Hacl_SHA2_Scalar32_sha256_init(st);
-  uint32_t rem = input_len % (uint32_t)64U;
+  Hacl_Hash_SHA2_sha256_init(st);
+  uint32_t rem = input_len % 64U;
   uint64_t len_ = (uint64_t)input_len;
-  Hacl_SHA2_Scalar32_sha256_update_nblocks(input_len, ib, st);
-  uint32_t rem1 = input_len % (uint32_t)64U;
+  Hacl_Hash_SHA2_sha256_update_nblocks(input_len, ib, st);
+  uint32_t rem1 = input_len % 64U;
   uint8_t *b0 = ib;
   uint8_t *lb = b0 + input_len - rem1;
-  Hacl_SHA2_Scalar32_sha256_update_last(len_, rem, lb, st);
-  Hacl_SHA2_Scalar32_sha256_finish(st, rb);
+  Hacl_Hash_SHA2_sha256_update_last(len_, rem, lb, st);
+  Hacl_Hash_SHA2_sha256_finish(st, rb);
 }
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_create_in_224(void)
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA2_malloc_224(void)
 {
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)64U, sizeof (uint8_t));
-  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint32_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(64U, sizeof (uint8_t));
+  uint32_t *block_state = (uint32_t *)KRML_HOST_CALLOC(8U, sizeof (uint32_t));
   Hacl_Streaming_MD_state_32
-  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
+  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
   Hacl_Streaming_MD_state_32
   *p = (Hacl_Streaming_MD_state_32 *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_MD_state_32));
   p[0U] = s;
-  Hacl_SHA2_Scalar32_sha224_init(block_state);
+  Hacl_Hash_SHA2_sha224_init(block_state);
   return p;
 }
 
-void Hacl_Streaming_SHA2_init_224(Hacl_Streaming_MD_state_32 *s)
+void Hacl_Hash_SHA2_reset_224(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_MD_state_32 scrut = *s;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint32_t *block_state = scrut.block_state;
-  Hacl_SHA2_Scalar32_sha224_init(block_state);
+  Hacl_Hash_SHA2_sha224_init(block_state);
   Hacl_Streaming_MD_state_32
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_224(
-  Hacl_Streaming_MD_state_32 *p,
+Hacl_Hash_SHA2_update_224(
+  Hacl_Streaming_MD_state_32 *state,
   uint8_t *input,
   uint32_t input_len
 )
 {
-  return update_224_256(p, input, input_len);
+  return update_224_256(state, input, input_len);
 }
 
 /**
-Write the resulting hash into `dst`, an array of 28 bytes. The state remains
-valid after a call to `finish_224`, meaning the user may feed more data into
+Write the resulting hash into `output`, an array of 28 bytes. The state remains
+valid after a call to `digest_224`, meaning the user may feed more data into
 the hash via `update_224`.
 */
-void Hacl_Streaming_SHA2_finish_224(Hacl_Streaming_MD_state_32 *p, uint8_t *dst)
+void Hacl_Hash_SHA2_digest_224(Hacl_Streaming_MD_state_32 *state, uint8_t *output)
 {
-  Hacl_Streaming_MD_state_32 scrut = *p;
+  Hacl_Streaming_MD_state_32 scrut = *state;
   uint32_t *block_state = scrut.block_state;
   uint8_t *buf_ = scrut.buf;
   uint64_t total_len = scrut.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)(uint32_t)64U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)64U == 0ULL && total_len > 0ULL)
   {
-    r = (uint32_t)64U;
+    r = 64U;
   }
   else
   {
-    r = (uint32_t)(total_len % (uint64_t)(uint32_t)64U);
+    r = (uint32_t)(total_len % (uint64_t)64U);
   }
   uint8_t *buf_1 = buf_;
   uint32_t tmp_block_state[8U] = { 0U };
-  memcpy(tmp_block_state, block_state, (uint32_t)8U * sizeof (uint32_t));
+  memcpy(tmp_block_state, block_state, 8U * sizeof (uint32_t));
   uint32_t ite;
-  if (r % (uint32_t)64U == (uint32_t)0U && r > (uint32_t)0U)
+  if (r % 64U == 0U && r > 0U)
   {
-    ite = (uint32_t)64U;
+    ite = 64U;
   }
   else
   {
-    ite = r % (uint32_t)64U;
+    ite = r % 64U;
   }
   uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
-  sha224_update_nblocks((uint32_t)0U, buf_multi, tmp_block_state);
+  sha224_update_nblocks(0U, buf_multi, tmp_block_state);
   uint64_t prev_len_last = total_len - (uint64_t)r;
-  Hacl_SHA2_Scalar32_sha224_update_last(prev_len_last + (uint64_t)r,
-    r,
-    buf_last,
-    tmp_block_state);
-  Hacl_SHA2_Scalar32_sha224_finish(tmp_block_state, dst);
+  Hacl_Hash_SHA2_sha224_update_last(prev_len_last + (uint64_t)r, r, buf_last, tmp_block_state);
+  Hacl_Hash_SHA2_sha224_finish(tmp_block_state, output);
 }
 
-void Hacl_Streaming_SHA2_free_224(Hacl_Streaming_MD_state_32 *p)
+void Hacl_Hash_SHA2_free_224(Hacl_Streaming_MD_state_32 *state)
 {
-  Hacl_Streaming_SHA2_free_256(p);
+  Hacl_Hash_SHA2_free_256(state);
 }
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 28 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 28 bytes.
 */
-void Hacl_Streaming_SHA2_hash_224(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_SHA2_hash_224(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
   uint8_t *ib = input;
-  uint8_t *rb = dst;
+  uint8_t *rb = output;
   uint32_t st[8U] = { 0U };
-  Hacl_SHA2_Scalar32_sha224_init(st);
-  uint32_t rem = input_len % (uint32_t)64U;
+  Hacl_Hash_SHA2_sha224_init(st);
+  uint32_t rem = input_len % 64U;
   uint64_t len_ = (uint64_t)input_len;
   sha224_update_nblocks(input_len, ib, st);
-  uint32_t rem1 = input_len % (uint32_t)64U;
+  uint32_t rem1 = input_len % 64U;
   uint8_t *b0 = ib;
   uint8_t *lb = b0 + input_len - rem1;
-  Hacl_SHA2_Scalar32_sha224_update_last(len_, rem, lb, st);
-  Hacl_SHA2_Scalar32_sha224_finish(st, rb);
+  Hacl_Hash_SHA2_sha224_update_last(len_, rem, lb, st);
+  Hacl_Hash_SHA2_sha224_finish(st, rb);
 }
 
-Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_create_in_512(void)
+Hacl_Streaming_MD_state_64 *Hacl_Hash_SHA2_malloc_512(void)
 {
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)128U, sizeof (uint8_t));
-  uint64_t *block_state = (uint64_t *)KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint64_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(128U, sizeof (uint8_t));
+  uint64_t *block_state = (uint64_t *)KRML_HOST_CALLOC(8U, sizeof (uint64_t));
   Hacl_Streaming_MD_state_64
-  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
+  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
   Hacl_Streaming_MD_state_64
   *p = (Hacl_Streaming_MD_state_64 *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_MD_state_64));
   p[0U] = s;
-  Hacl_SHA2_Scalar32_sha512_init(block_state);
+  Hacl_Hash_SHA2_sha512_init(block_state);
   return p;
 }
 
@@ -937,16 +874,16 @@ The state is to be freed by calling `free_512`. Cloning the state this way is
 useful, for instance, if your control-flow diverges and you need to feed
 more (different) data into the hash in each branch.
 */
-Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_copy_512(Hacl_Streaming_MD_state_64 *s0)
+Hacl_Streaming_MD_state_64 *Hacl_Hash_SHA2_copy_512(Hacl_Streaming_MD_state_64 *state)
 {
-  Hacl_Streaming_MD_state_64 scrut = *s0;
+  Hacl_Streaming_MD_state_64 scrut = *state;
   uint64_t *block_state0 = scrut.block_state;
   uint8_t *buf0 = scrut.buf;
   uint64_t total_len0 = scrut.total_len;
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)128U, sizeof (uint8_t));
-  memcpy(buf, buf0, (uint32_t)128U * sizeof (uint8_t));
-  uint64_t *block_state = (uint64_t *)KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint64_t));
-  memcpy(block_state, block_state0, (uint32_t)8U * sizeof (uint64_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(128U, sizeof (uint8_t));
+  memcpy(buf, buf0, 128U * sizeof (uint8_t));
+  uint64_t *block_state = (uint64_t *)KRML_HOST_CALLOC(8U, sizeof (uint64_t));
+  memcpy(block_state, block_state0, 8U * sizeof (uint64_t));
   Hacl_Streaming_MD_state_64
   s = { .block_state = block_state, .buf = buf, .total_len = total_len0 };
   Hacl_Streaming_MD_state_64
@@ -955,54 +892,54 @@ Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_copy_512(Hacl_Streaming_MD_state
   return p;
 }
 
-void Hacl_Streaming_SHA2_init_512(Hacl_Streaming_MD_state_64 *s)
+void Hacl_Hash_SHA2_reset_512(Hacl_Streaming_MD_state_64 *state)
 {
-  Hacl_Streaming_MD_state_64 scrut = *s;
+  Hacl_Streaming_MD_state_64 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint64_t *block_state = scrut.block_state;
-  Hacl_SHA2_Scalar32_sha512_init(block_state);
+  Hacl_Hash_SHA2_sha512_init(block_state);
   Hacl_Streaming_MD_state_64
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 static inline Hacl_Streaming_Types_error_code
-update_384_512(Hacl_Streaming_MD_state_64 *p, uint8_t *data, uint32_t len)
+update_384_512(Hacl_Streaming_MD_state_64 *state, uint8_t *chunk, uint32_t chunk_len)
 {
-  Hacl_Streaming_MD_state_64 s = *p;
+  Hacl_Streaming_MD_state_64 s = *state;
   uint64_t total_len = s.total_len;
-  if ((uint64_t)len > (uint64_t)18446744073709551615U - total_len)
+  if ((uint64_t)chunk_len > 18446744073709551615ULL - total_len)
   {
     return Hacl_Streaming_Types_MaximumLengthExceeded;
   }
   uint32_t sz;
-  if (total_len % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)128U == 0ULL && total_len > 0ULL)
   {
-    sz = (uint32_t)128U;
+    sz = 128U;
   }
   else
   {
-    sz = (uint32_t)(total_len % (uint64_t)(uint32_t)128U);
+    sz = (uint32_t)(total_len % (uint64_t)128U);
   }
-  if (len <= (uint32_t)128U - sz)
+  if (chunk_len <= 128U - sz)
   {
-    Hacl_Streaming_MD_state_64 s1 = *p;
+    Hacl_Streaming_MD_state_64 s1 = *state;
     uint64_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)128U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)128U;
+      sz1 = 128U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)128U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)128U);
     }
     uint8_t *buf2 = buf + sz1;
-    memcpy(buf2, data, len * sizeof (uint8_t));
-    uint64_t total_len2 = total_len1 + (uint64_t)len;
-    *p
+    memcpy(buf2, chunk, chunk_len * sizeof (uint8_t));
+    uint64_t total_len2 = total_len1 + (uint64_t)chunk_len;
+    *state
     =
       (
         (Hacl_Streaming_MD_state_64){
@@ -1012,76 +949,74 @@ update_384_512(Hacl_Streaming_MD_state_64 *p, uint8_t *data, uint32_t len)
         }
       );
   }
-  else if (sz == (uint32_t)0U)
+  else if (sz == 0U)
   {
-    Hacl_Streaming_MD_state_64 s1 = *p;
+    Hacl_Streaming_MD_state_64 s1 = *state;
     uint64_t *block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)128U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)128U;
+      sz1 = 128U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)128U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)128U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_SHA2_Scalar32_sha512_update_nblocks((uint32_t)128U, buf, block_state1);
+      Hacl_Hash_SHA2_sha512_update_nblocks(128U, buf, block_state1);
     }
     uint32_t ite;
-    if ((uint64_t)len % (uint64_t)(uint32_t)128U == (uint64_t)0U && (uint64_t)len > (uint64_t)0U)
+    if ((uint64_t)chunk_len % (uint64_t)128U == 0ULL && (uint64_t)chunk_len > 0ULL)
     {
-      ite = (uint32_t)128U;
+      ite = 128U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)len % (uint64_t)(uint32_t)128U);
+      ite = (uint32_t)((uint64_t)chunk_len % (uint64_t)128U);
     }
-    uint32_t n_blocks = (len - ite) / (uint32_t)128U;
-    uint32_t data1_len = n_blocks * (uint32_t)128U;
-    uint32_t data2_len = len - data1_len;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + data1_len;
-    Hacl_SHA2_Scalar32_sha512_update_nblocks(data1_len / (uint32_t)128U * (uint32_t)128U,
-      data1,
-      block_state1);
+    uint32_t n_blocks = (chunk_len - ite) / 128U;
+    uint32_t data1_len = n_blocks * 128U;
+    uint32_t data2_len = chunk_len - data1_len;
+    uint8_t *data1 = chunk;
+    uint8_t *data2 = chunk + data1_len;
+    Hacl_Hash_SHA2_sha512_update_nblocks(data1_len / 128U * 128U, data1, block_state1);
     uint8_t *dst = buf;
     memcpy(dst, data2, data2_len * sizeof (uint8_t));
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_64){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)len
+          .total_len = total_len1 + (uint64_t)chunk_len
         }
       );
   }
   else
   {
-    uint32_t diff = (uint32_t)128U - sz;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + diff;
-    Hacl_Streaming_MD_state_64 s1 = *p;
+    uint32_t diff = 128U - sz;
+    uint8_t *chunk1 = chunk;
+    uint8_t *chunk2 = chunk + diff;
+    Hacl_Streaming_MD_state_64 s1 = *state;
     uint64_t *block_state10 = s1.block_state;
     uint8_t *buf0 = s1.buf;
     uint64_t total_len10 = s1.total_len;
     uint32_t sz10;
-    if (total_len10 % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len10 > (uint64_t)0U)
+    if (total_len10 % (uint64_t)128U == 0ULL && total_len10 > 0ULL)
     {
-      sz10 = (uint32_t)128U;
+      sz10 = 128U;
     }
     else
     {
-      sz10 = (uint32_t)(total_len10 % (uint64_t)(uint32_t)128U);
+      sz10 = (uint32_t)(total_len10 % (uint64_t)128U);
     }
     uint8_t *buf2 = buf0 + sz10;
-    memcpy(buf2, data1, diff * sizeof (uint8_t));
+    memcpy(buf2, chunk1, diff * sizeof (uint8_t));
     uint64_t total_len2 = total_len10 + (uint64_t)diff;
-    *p
+    *state
     =
       (
         (Hacl_Streaming_MD_state_64){
@@ -1090,55 +1025,48 @@ update_384_512(Hacl_Streaming_MD_state_64 *p, uint8_t *data, uint32_t len)
           .total_len = total_len2
         }
       );
-    Hacl_Streaming_MD_state_64 s10 = *p;
+    Hacl_Streaming_MD_state_64 s10 = *state;
     uint64_t *block_state1 = s10.block_state;
     uint8_t *buf = s10.buf;
     uint64_t total_len1 = s10.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)128U == 0ULL && total_len1 > 0ULL)
     {
-      sz1 = (uint32_t)128U;
+      sz1 = 128U;
     }
     else
     {
-      sz1 = (uint32_t)(total_len1 % (uint64_t)(uint32_t)128U);
+      sz1 = (uint32_t)(total_len1 % (uint64_t)128U);
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
-      Hacl_SHA2_Scalar32_sha512_update_nblocks((uint32_t)128U, buf, block_state1);
+      Hacl_Hash_SHA2_sha512_update_nblocks(128U, buf, block_state1);
     }
     uint32_t ite;
     if
-    (
-      (uint64_t)(len - diff)
-      % (uint64_t)(uint32_t)128U
-      == (uint64_t)0U
-      && (uint64_t)(len - diff) > (uint64_t)0U
-    )
+    ((uint64_t)(chunk_len - diff) % (uint64_t)128U == 0ULL && (uint64_t)(chunk_len - diff) > 0ULL)
     {
-      ite = (uint32_t)128U;
+      ite = 128U;
     }
     else
     {
-      ite = (uint32_t)((uint64_t)(len - diff) % (uint64_t)(uint32_t)128U);
+      ite = (uint32_t)((uint64_t)(chunk_len - diff) % (uint64_t)128U);
     }
-    uint32_t n_blocks = (len - diff - ite) / (uint32_t)128U;
-    uint32_t data1_len = n_blocks * (uint32_t)128U;
-    uint32_t data2_len = len - diff - data1_len;
-    uint8_t *data11 = data2;
-    uint8_t *data21 = data2 + data1_len;
-    Hacl_SHA2_Scalar32_sha512_update_nblocks(data1_len / (uint32_t)128U * (uint32_t)128U,
-      data11,
-      block_state1);
+    uint32_t n_blocks = (chunk_len - diff - ite) / 128U;
+    uint32_t data1_len = n_blocks * 128U;
+    uint32_t data2_len = chunk_len - diff - data1_len;
+    uint8_t *data1 = chunk2;
+    uint8_t *data2 = chunk2 + data1_len;
+    Hacl_Hash_SHA2_sha512_update_nblocks(data1_len / 128U * 128U, data1, block_state1);
     uint8_t *dst = buf;
-    memcpy(dst, data21, data2_len * sizeof (uint8_t));
-    *p
+    memcpy(dst, data2, data2_len * sizeof (uint8_t));
+    *state
     =
       (
         (Hacl_Streaming_MD_state_64){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)(len - diff)
+          .total_len = total_len1 + (uint64_t)(chunk_len - diff)
         }
       );
   }
@@ -1148,198 +1076,198 @@ update_384_512(Hacl_Streaming_MD_state_64 *p, uint8_t *data, uint32_t len)
 /**
 Feed an arbitrary amount of data into the hash. This function returns 0 for
 success, or 1 if the combined length of all of the data passed to `update_512`
-(since the last call to `init_512`) exceeds 2^125-1 bytes.
+(since the last call to `reset_512`) exceeds 2^125-1 bytes.
 
 This function is identical to the update function for SHA2_384.
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_512(
-  Hacl_Streaming_MD_state_64 *p,
+Hacl_Hash_SHA2_update_512(
+  Hacl_Streaming_MD_state_64 *state,
   uint8_t *input,
   uint32_t input_len
 )
 {
-  return update_384_512(p, input, input_len);
+  return update_384_512(state, input, input_len);
 }
 
 /**
-Write the resulting hash into `dst`, an array of 64 bytes. The state remains
-valid after a call to `finish_512`, meaning the user may feed more data into
-the hash via `update_512`. (The finish_512 function operates on an internal copy of
+Write the resulting hash into `output`, an array of 64 bytes. The state remains
+valid after a call to `digest_512`, meaning the user may feed more data into
+the hash via `update_512`. (The digest_512 function operates on an internal copy of
 the state and therefore does not invalidate the client-held state `p`.)
 */
-void Hacl_Streaming_SHA2_finish_512(Hacl_Streaming_MD_state_64 *p, uint8_t *dst)
+void Hacl_Hash_SHA2_digest_512(Hacl_Streaming_MD_state_64 *state, uint8_t *output)
 {
-  Hacl_Streaming_MD_state_64 scrut = *p;
+  Hacl_Streaming_MD_state_64 scrut = *state;
   uint64_t *block_state = scrut.block_state;
   uint8_t *buf_ = scrut.buf;
   uint64_t total_len = scrut.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)128U == 0ULL && total_len > 0ULL)
   {
-    r = (uint32_t)128U;
+    r = 128U;
   }
   else
   {
-    r = (uint32_t)(total_len % (uint64_t)(uint32_t)128U);
+    r = (uint32_t)(total_len % (uint64_t)128U);
   }
   uint8_t *buf_1 = buf_;
   uint64_t tmp_block_state[8U] = { 0U };
-  memcpy(tmp_block_state, block_state, (uint32_t)8U * sizeof (uint64_t));
+  memcpy(tmp_block_state, block_state, 8U * sizeof (uint64_t));
   uint32_t ite;
-  if (r % (uint32_t)128U == (uint32_t)0U && r > (uint32_t)0U)
+  if (r % 128U == 0U && r > 0U)
   {
-    ite = (uint32_t)128U;
+    ite = 128U;
   }
   else
   {
-    ite = r % (uint32_t)128U;
+    ite = r % 128U;
   }
   uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
-  Hacl_SHA2_Scalar32_sha512_update_nblocks((uint32_t)0U, buf_multi, tmp_block_state);
+  Hacl_Hash_SHA2_sha512_update_nblocks(0U, buf_multi, tmp_block_state);
   uint64_t prev_len_last = total_len - (uint64_t)r;
-  Hacl_SHA2_Scalar32_sha512_update_last(FStar_UInt128_add(FStar_UInt128_uint64_to_uint128(prev_len_last),
+  Hacl_Hash_SHA2_sha512_update_last(FStar_UInt128_add(FStar_UInt128_uint64_to_uint128(prev_len_last),
       FStar_UInt128_uint64_to_uint128((uint64_t)r)),
     r,
     buf_last,
     tmp_block_state);
-  Hacl_SHA2_Scalar32_sha512_finish(tmp_block_state, dst);
+  Hacl_Hash_SHA2_sha512_finish(tmp_block_state, output);
 }
 
 /**
-Free a state allocated with `create_in_512`.
+Free a state allocated with `malloc_512`.
 
 This function is identical to the free function for SHA2_384.
 */
-void Hacl_Streaming_SHA2_free_512(Hacl_Streaming_MD_state_64 *s)
+void Hacl_Hash_SHA2_free_512(Hacl_Streaming_MD_state_64 *state)
 {
-  Hacl_Streaming_MD_state_64 scrut = *s;
+  Hacl_Streaming_MD_state_64 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint64_t *block_state = scrut.block_state;
   KRML_HOST_FREE(block_state);
   KRML_HOST_FREE(buf);
-  KRML_HOST_FREE(s);
+  KRML_HOST_FREE(state);
 }
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 64 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 64 bytes.
 */
-void Hacl_Streaming_SHA2_hash_512(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_SHA2_hash_512(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
   uint8_t *ib = input;
-  uint8_t *rb = dst;
+  uint8_t *rb = output;
   uint64_t st[8U] = { 0U };
-  Hacl_SHA2_Scalar32_sha512_init(st);
-  uint32_t rem = input_len % (uint32_t)128U;
+  Hacl_Hash_SHA2_sha512_init(st);
+  uint32_t rem = input_len % 128U;
   FStar_UInt128_uint128 len_ = FStar_UInt128_uint64_to_uint128((uint64_t)input_len);
-  Hacl_SHA2_Scalar32_sha512_update_nblocks(input_len, ib, st);
-  uint32_t rem1 = input_len % (uint32_t)128U;
+  Hacl_Hash_SHA2_sha512_update_nblocks(input_len, ib, st);
+  uint32_t rem1 = input_len % 128U;
   uint8_t *b0 = ib;
   uint8_t *lb = b0 + input_len - rem1;
-  Hacl_SHA2_Scalar32_sha512_update_last(len_, rem, lb, st);
-  Hacl_SHA2_Scalar32_sha512_finish(st, rb);
+  Hacl_Hash_SHA2_sha512_update_last(len_, rem, lb, st);
+  Hacl_Hash_SHA2_sha512_finish(st, rb);
 }
 
-Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_create_in_384(void)
+Hacl_Streaming_MD_state_64 *Hacl_Hash_SHA2_malloc_384(void)
 {
-  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC((uint32_t)128U, sizeof (uint8_t));
-  uint64_t *block_state = (uint64_t *)KRML_HOST_CALLOC((uint32_t)8U, sizeof (uint64_t));
+  uint8_t *buf = (uint8_t *)KRML_HOST_CALLOC(128U, sizeof (uint8_t));
+  uint64_t *block_state = (uint64_t *)KRML_HOST_CALLOC(8U, sizeof (uint64_t));
   Hacl_Streaming_MD_state_64
-  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
+  s = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
   Hacl_Streaming_MD_state_64
   *p = (Hacl_Streaming_MD_state_64 *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_MD_state_64));
   p[0U] = s;
-  Hacl_SHA2_Scalar32_sha384_init(block_state);
+  Hacl_Hash_SHA2_sha384_init(block_state);
   return p;
 }
 
-void Hacl_Streaming_SHA2_init_384(Hacl_Streaming_MD_state_64 *s)
+void Hacl_Hash_SHA2_reset_384(Hacl_Streaming_MD_state_64 *state)
 {
-  Hacl_Streaming_MD_state_64 scrut = *s;
+  Hacl_Streaming_MD_state_64 scrut = *state;
   uint8_t *buf = scrut.buf;
   uint64_t *block_state = scrut.block_state;
-  Hacl_SHA2_Scalar32_sha384_init(block_state);
+  Hacl_Hash_SHA2_sha384_init(block_state);
   Hacl_Streaming_MD_state_64
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_384(
-  Hacl_Streaming_MD_state_64 *p,
+Hacl_Hash_SHA2_update_384(
+  Hacl_Streaming_MD_state_64 *state,
   uint8_t *input,
   uint32_t input_len
 )
 {
-  return update_384_512(p, input, input_len);
+  return update_384_512(state, input, input_len);
 }
 
 /**
-Write the resulting hash into `dst`, an array of 48 bytes. The state remains
-valid after a call to `finish_384`, meaning the user may feed more data into
+Write the resulting hash into `output`, an array of 48 bytes. The state remains
+valid after a call to `digest_384`, meaning the user may feed more data into
 the hash via `update_384`.
 */
-void Hacl_Streaming_SHA2_finish_384(Hacl_Streaming_MD_state_64 *p, uint8_t *dst)
+void Hacl_Hash_SHA2_digest_384(Hacl_Streaming_MD_state_64 *state, uint8_t *output)
 {
-  Hacl_Streaming_MD_state_64 scrut = *p;
+  Hacl_Streaming_MD_state_64 scrut = *state;
   uint64_t *block_state = scrut.block_state;
   uint8_t *buf_ = scrut.buf;
   uint64_t total_len = scrut.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)(uint32_t)128U == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)128U == 0ULL && total_len > 0ULL)
   {
-    r = (uint32_t)128U;
+    r = 128U;
   }
   else
   {
-    r = (uint32_t)(total_len % (uint64_t)(uint32_t)128U);
+    r = (uint32_t)(total_len % (uint64_t)128U);
   }
   uint8_t *buf_1 = buf_;
   uint64_t tmp_block_state[8U] = { 0U };
-  memcpy(tmp_block_state, block_state, (uint32_t)8U * sizeof (uint64_t));
+  memcpy(tmp_block_state, block_state, 8U * sizeof (uint64_t));
   uint32_t ite;
-  if (r % (uint32_t)128U == (uint32_t)0U && r > (uint32_t)0U)
+  if (r % 128U == 0U && r > 0U)
   {
-    ite = (uint32_t)128U;
+    ite = 128U;
   }
   else
   {
-    ite = r % (uint32_t)128U;
+    ite = r % 128U;
   }
   uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
-  Hacl_SHA2_Scalar32_sha384_update_nblocks((uint32_t)0U, buf_multi, tmp_block_state);
+  Hacl_Hash_SHA2_sha384_update_nblocks(0U, buf_multi, tmp_block_state);
   uint64_t prev_len_last = total_len - (uint64_t)r;
-  Hacl_SHA2_Scalar32_sha384_update_last(FStar_UInt128_add(FStar_UInt128_uint64_to_uint128(prev_len_last),
+  Hacl_Hash_SHA2_sha384_update_last(FStar_UInt128_add(FStar_UInt128_uint64_to_uint128(prev_len_last),
       FStar_UInt128_uint64_to_uint128((uint64_t)r)),
     r,
     buf_last,
     tmp_block_state);
-  Hacl_SHA2_Scalar32_sha384_finish(tmp_block_state, dst);
+  Hacl_Hash_SHA2_sha384_finish(tmp_block_state, output);
 }
 
-void Hacl_Streaming_SHA2_free_384(Hacl_Streaming_MD_state_64 *p)
+void Hacl_Hash_SHA2_free_384(Hacl_Streaming_MD_state_64 *state)
 {
-  Hacl_Streaming_SHA2_free_512(p);
+  Hacl_Hash_SHA2_free_512(state);
 }
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 48 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 48 bytes.
 */
-void Hacl_Streaming_SHA2_hash_384(uint8_t *input, uint32_t input_len, uint8_t *dst)
+void Hacl_Hash_SHA2_hash_384(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
   uint8_t *ib = input;
-  uint8_t *rb = dst;
+  uint8_t *rb = output;
   uint64_t st[8U] = { 0U };
-  Hacl_SHA2_Scalar32_sha384_init(st);
-  uint32_t rem = input_len % (uint32_t)128U;
+  Hacl_Hash_SHA2_sha384_init(st);
+  uint32_t rem = input_len % 128U;
   FStar_UInt128_uint128 len_ = FStar_UInt128_uint64_to_uint128((uint64_t)input_len);
-  Hacl_SHA2_Scalar32_sha384_update_nblocks(input_len, ib, st);
-  uint32_t rem1 = input_len % (uint32_t)128U;
+  Hacl_Hash_SHA2_sha384_update_nblocks(input_len, ib, st);
+  uint32_t rem1 = input_len % 128U;
   uint8_t *b0 = ib;
   uint8_t *lb = b0 + input_len - rem1;
-  Hacl_SHA2_Scalar32_sha384_update_last(len_, rem, lb, st);
-  Hacl_SHA2_Scalar32_sha384_finish(st, rb);
+  Hacl_Hash_SHA2_sha384_update_last(len_, rem, lb, st);
+  Hacl_Hash_SHA2_sha384_finish(st, rb);
 }
 
diff --git a/Modules/_hacl/Hacl_Hash_SHA2.h b/Modules/_hacl/Hacl_Hash_SHA2.h
index a0e731094d..d8204b504b 100644
--- a/Modules/_hacl/Hacl_Hash_SHA2.h
+++ b/Modules/_hacl/Hacl_Hash_SHA2.h
@@ -39,19 +39,19 @@ extern "C" {
 #include "Hacl_Streaming_Types.h"
 
 
-typedef Hacl_Streaming_MD_state_32 Hacl_Streaming_SHA2_state_sha2_224;
+typedef Hacl_Streaming_MD_state_32 Hacl_Hash_SHA2_state_t_224;
 
-typedef Hacl_Streaming_MD_state_32 Hacl_Streaming_SHA2_state_sha2_256;
+typedef Hacl_Streaming_MD_state_32 Hacl_Hash_SHA2_state_t_256;
 
-typedef Hacl_Streaming_MD_state_64 Hacl_Streaming_SHA2_state_sha2_384;
+typedef Hacl_Streaming_MD_state_64 Hacl_Hash_SHA2_state_t_384;
 
-typedef Hacl_Streaming_MD_state_64 Hacl_Streaming_SHA2_state_sha2_512;
+typedef Hacl_Streaming_MD_state_64 Hacl_Hash_SHA2_state_t_512;
 
 /**
 Allocate initial state for the SHA2_256 hash. The state is to be freed by
 calling `free_256`.
 */
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_create_in_256(void);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA2_malloc_256(void);
 
 /**
 Copies the state passed as argument into a newly allocated state (deep copy).
@@ -59,73 +59,73 @@ The state is to be freed by calling `free_256`. Cloning the state this way is
 useful, for instance, if your control-flow diverges and you need to feed
 more (different) data into the hash in each branch.
 */
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_copy_256(Hacl_Streaming_MD_state_32 *s0);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA2_copy_256(Hacl_Streaming_MD_state_32 *state);
 
 /**
 Reset an existing state to the initial hash state with empty data.
 */
-void Hacl_Streaming_SHA2_init_256(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_SHA2_reset_256(Hacl_Streaming_MD_state_32 *state);
 
 /**
 Feed an arbitrary amount of data into the hash. This function returns 0 for
 success, or 1 if the combined length of all of the data passed to `update_256`
-(since the last call to `init_256`) exceeds 2^61-1 bytes.
+(since the last call to `reset_256`) exceeds 2^61-1 bytes.
 
 This function is identical to the update function for SHA2_224.
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_256(
-  Hacl_Streaming_MD_state_32 *p,
+Hacl_Hash_SHA2_update_256(
+  Hacl_Streaming_MD_state_32 *state,
   uint8_t *input,
   uint32_t input_len
 );
 
 /**
-Write the resulting hash into `dst`, an array of 32 bytes. The state remains
-valid after a call to `finish_256`, meaning the user may feed more data into
-the hash via `update_256`. (The finish_256 function operates on an internal copy of
+Write the resulting hash into `output`, an array of 32 bytes. The state remains
+valid after a call to `digest_256`, meaning the user may feed more data into
+the hash via `update_256`. (The digest_256 function operates on an internal copy of
 the state and therefore does not invalidate the client-held state `p`.)
 */
-void Hacl_Streaming_SHA2_finish_256(Hacl_Streaming_MD_state_32 *p, uint8_t *dst);
+void Hacl_Hash_SHA2_digest_256(Hacl_Streaming_MD_state_32 *state, uint8_t *output);
 
 /**
-Free a state allocated with `create_in_256`.
+Free a state allocated with `malloc_256`.
 
 This function is identical to the free function for SHA2_224.
 */
-void Hacl_Streaming_SHA2_free_256(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_SHA2_free_256(Hacl_Streaming_MD_state_32 *state);
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 32 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 32 bytes.
 */
-void Hacl_Streaming_SHA2_hash_256(uint8_t *input, uint32_t input_len, uint8_t *dst);
+void Hacl_Hash_SHA2_hash_256(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-Hacl_Streaming_MD_state_32 *Hacl_Streaming_SHA2_create_in_224(void);
+Hacl_Streaming_MD_state_32 *Hacl_Hash_SHA2_malloc_224(void);
 
-void Hacl_Streaming_SHA2_init_224(Hacl_Streaming_MD_state_32 *s);
+void Hacl_Hash_SHA2_reset_224(Hacl_Streaming_MD_state_32 *state);
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_224(
-  Hacl_Streaming_MD_state_32 *p,
+Hacl_Hash_SHA2_update_224(
+  Hacl_Streaming_MD_state_32 *state,
   uint8_t *input,
   uint32_t input_len
 );
 
 /**
-Write the resulting hash into `dst`, an array of 28 bytes. The state remains
-valid after a call to `finish_224`, meaning the user may feed more data into
+Write the resulting hash into `output`, an array of 28 bytes. The state remains
+valid after a call to `digest_224`, meaning the user may feed more data into
 the hash via `update_224`.
 */
-void Hacl_Streaming_SHA2_finish_224(Hacl_Streaming_MD_state_32 *p, uint8_t *dst);
+void Hacl_Hash_SHA2_digest_224(Hacl_Streaming_MD_state_32 *state, uint8_t *output);
 
-void Hacl_Streaming_SHA2_free_224(Hacl_Streaming_MD_state_32 *p);
+void Hacl_Hash_SHA2_free_224(Hacl_Streaming_MD_state_32 *state);
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 28 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 28 bytes.
 */
-void Hacl_Streaming_SHA2_hash_224(uint8_t *input, uint32_t input_len, uint8_t *dst);
+void Hacl_Hash_SHA2_hash_224(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_create_in_512(void);
+Hacl_Streaming_MD_state_64 *Hacl_Hash_SHA2_malloc_512(void);
 
 /**
 Copies the state passed as argument into a newly allocated state (deep copy).
@@ -133,68 +133,68 @@ The state is to be freed by calling `free_512`. Cloning the state this way is
 useful, for instance, if your control-flow diverges and you need to feed
 more (different) data into the hash in each branch.
 */
-Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_copy_512(Hacl_Streaming_MD_state_64 *s0);
+Hacl_Streaming_MD_state_64 *Hacl_Hash_SHA2_copy_512(Hacl_Streaming_MD_state_64 *state);
 
-void Hacl_Streaming_SHA2_init_512(Hacl_Streaming_MD_state_64 *s);
+void Hacl_Hash_SHA2_reset_512(Hacl_Streaming_MD_state_64 *state);
 
 /**
 Feed an arbitrary amount of data into the hash. This function returns 0 for
 success, or 1 if the combined length of all of the data passed to `update_512`
-(since the last call to `init_512`) exceeds 2^125-1 bytes.
+(since the last call to `reset_512`) exceeds 2^125-1 bytes.
 
 This function is identical to the update function for SHA2_384.
 */
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_512(
-  Hacl_Streaming_MD_state_64 *p,
+Hacl_Hash_SHA2_update_512(
+  Hacl_Streaming_MD_state_64 *state,
   uint8_t *input,
   uint32_t input_len
 );
 
 /**
-Write the resulting hash into `dst`, an array of 64 bytes. The state remains
-valid after a call to `finish_512`, meaning the user may feed more data into
-the hash via `update_512`. (The finish_512 function operates on an internal copy of
+Write the resulting hash into `output`, an array of 64 bytes. The state remains
+valid after a call to `digest_512`, meaning the user may feed more data into
+the hash via `update_512`. (The digest_512 function operates on an internal copy of
 the state and therefore does not invalidate the client-held state `p`.)
 */
-void Hacl_Streaming_SHA2_finish_512(Hacl_Streaming_MD_state_64 *p, uint8_t *dst);
+void Hacl_Hash_SHA2_digest_512(Hacl_Streaming_MD_state_64 *state, uint8_t *output);
 
 /**
-Free a state allocated with `create_in_512`.
+Free a state allocated with `malloc_512`.
 
 This function is identical to the free function for SHA2_384.
 */
-void Hacl_Streaming_SHA2_free_512(Hacl_Streaming_MD_state_64 *s);
+void Hacl_Hash_SHA2_free_512(Hacl_Streaming_MD_state_64 *state);
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 64 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 64 bytes.
 */
-void Hacl_Streaming_SHA2_hash_512(uint8_t *input, uint32_t input_len, uint8_t *dst);
+void Hacl_Hash_SHA2_hash_512(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-Hacl_Streaming_MD_state_64 *Hacl_Streaming_SHA2_create_in_384(void);
+Hacl_Streaming_MD_state_64 *Hacl_Hash_SHA2_malloc_384(void);
 
-void Hacl_Streaming_SHA2_init_384(Hacl_Streaming_MD_state_64 *s);
+void Hacl_Hash_SHA2_reset_384(Hacl_Streaming_MD_state_64 *state);
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_SHA2_update_384(
-  Hacl_Streaming_MD_state_64 *p,
+Hacl_Hash_SHA2_update_384(
+  Hacl_Streaming_MD_state_64 *state,
   uint8_t *input,
   uint32_t input_len
 );
 
 /**
-Write the resulting hash into `dst`, an array of 48 bytes. The state remains
-valid after a call to `finish_384`, meaning the user may feed more data into
+Write the resulting hash into `output`, an array of 48 bytes. The state remains
+valid after a call to `digest_384`, meaning the user may feed more data into
 the hash via `update_384`.
 */
-void Hacl_Streaming_SHA2_finish_384(Hacl_Streaming_MD_state_64 *p, uint8_t *dst);
+void Hacl_Hash_SHA2_digest_384(Hacl_Streaming_MD_state_64 *state, uint8_t *output);
 
-void Hacl_Streaming_SHA2_free_384(Hacl_Streaming_MD_state_64 *p);
+void Hacl_Hash_SHA2_free_384(Hacl_Streaming_MD_state_64 *state);
 
 /**
-Hash `input`, of len `input_len`, into `dst`, an array of 48 bytes.
+Hash `input`, of len `input_len`, into `output`, an array of 48 bytes.
 */
-void Hacl_Streaming_SHA2_hash_384(uint8_t *input, uint32_t input_len, uint8_t *dst);
+void Hacl_Hash_SHA2_hash_384(uint8_t *output, uint8_t *input, uint32_t input_len);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/Hacl_Hash_SHA3.c b/Modules/_hacl/Hacl_Hash_SHA3.c
index b3febdfeb2..4f502866fe 100644
--- a/Modules/_hacl/Hacl_Hash_SHA3.c
+++ b/Modules/_hacl/Hacl_Hash_SHA3.c
@@ -31,27 +31,27 @@ static uint32_t block_len(Spec_Hash_Definitions_hash_alg a)
   {
     case Spec_Hash_Definitions_SHA3_224:
       {
-        return (uint32_t)144U;
+        return 144U;
       }
     case Spec_Hash_Definitions_SHA3_256:
       {
-        return (uint32_t)136U;
+        return 136U;
       }
     case Spec_Hash_Definitions_SHA3_384:
       {
-        return (uint32_t)104U;
+        return 104U;
       }
     case Spec_Hash_Definitions_SHA3_512:
       {
-        return (uint32_t)72U;
+        return 72U;
       }
     case Spec_Hash_Definitions_Shake128:
       {
-        return (uint32_t)168U;
+        return 168U;
       }
     case Spec_Hash_Definitions_Shake256:
       {
-        return (uint32_t)136U;
+        return 136U;
       }
     default:
       {
@@ -67,19 +67,19 @@ static uint32_t hash_len(Spec_Hash_Definitions_hash_alg a)
   {
     case Spec_Hash_Definitions_SHA3_224:
       {
-        return (uint32_t)28U;
+        return 28U;
       }
     case Spec_Hash_Definitions_SHA3_256:
       {
-        return (uint32_t)32U;
+        return 32U;
       }
     case Spec_Hash_Definitions_SHA3_384:
       {
-        return (uint32_t)48U;
+        return 48U;
       }
     case Spec_Hash_Definitions_SHA3_512:
       {
-        return (uint32_t)64U;
+        return 64U;
       }
     default:
       {
@@ -97,10 +97,10 @@ Hacl_Hash_SHA3_update_multi_sha3(
   uint32_t n_blocks
 )
 {
-  for (uint32_t i = (uint32_t)0U; i < n_blocks; i++)
+  for (uint32_t i = 0U; i < n_blocks; i++)
   {
     uint8_t *block = blocks + i * block_len(a);
-    Hacl_Impl_SHA3_absorb_inner(block_len(a), block, s);
+    Hacl_Hash_SHA3_absorb_inner(block_len(a), block, s);
   }
 }
 
@@ -115,139 +115,139 @@ Hacl_Hash_SHA3_update_last_sha3(
   uint8_t suffix;
   if (a == Spec_Hash_Definitions_Shake128 || a == Spec_Hash_Definitions_Shake256)
   {
-    suffix = (uint8_t)0x1fU;
+    suffix = 0x1fU;
   }
   else
   {
-    suffix = (uint8_t)0x06U;
+    suffix = 0x06U;
   }
   uint32_t len = block_len(a);
   if (input_len == len)
   {
-    Hacl_Impl_SHA3_absorb_inner(len, input, s);
-    uint8_t *uu____0 = input + input_len;
+    Hacl_Hash_SHA3_absorb_inner(len, input, s);
     uint8_t lastBlock_[200U] = { 0U };
     uint8_t *lastBlock = lastBlock_;
-    memcpy(lastBlock, uu____0, (uint32_t)0U * sizeof (uint8_t));
+    memcpy(lastBlock, input + input_len, 0U * sizeof (uint8_t));
     lastBlock[0U] = suffix;
-    Hacl_Impl_SHA3_loadState(len, lastBlock, s);
-    if (!((suffix & (uint8_t)0x80U) == (uint8_t)0U) && (uint32_t)0U == len - (uint32_t)1U)
+    Hacl_Hash_SHA3_loadState(len, lastBlock, s);
+    if (!(((uint32_t)suffix & 0x80U) == 0U) && 0U == len - 1U)
     {
-      Hacl_Impl_SHA3_state_permute(s);
+      Hacl_Hash_SHA3_state_permute(s);
     }
     uint8_t nextBlock_[200U] = { 0U };
     uint8_t *nextBlock = nextBlock_;
-    nextBlock[len - (uint32_t)1U] = (uint8_t)0x80U;
-    Hacl_Impl_SHA3_loadState(len, nextBlock, s);
-    Hacl_Impl_SHA3_state_permute(s);
+    nextBlock[len - 1U] = 0x80U;
+    Hacl_Hash_SHA3_loadState(len, nextBlock, s);
+    Hacl_Hash_SHA3_state_permute(s);
     return;
   }
   uint8_t lastBlock_[200U] = { 0U };
   uint8_t *lastBlock = lastBlock_;
   memcpy(lastBlock, input, input_len * sizeof (uint8_t));
   lastBlock[input_len] = suffix;
-  Hacl_Impl_SHA3_loadState(len, lastBlock, s);
-  if (!((suffix & (uint8_t)0x80U) == (uint8_t)0U) && input_len == len - (uint32_t)1U)
+  Hacl_Hash_SHA3_loadState(len, lastBlock, s);
+  if (!(((uint32_t)suffix & 0x80U) == 0U) && input_len == len - 1U)
   {
-    Hacl_Impl_SHA3_state_permute(s);
+    Hacl_Hash_SHA3_state_permute(s);
   }
   uint8_t nextBlock_[200U] = { 0U };
   uint8_t *nextBlock = nextBlock_;
-  nextBlock[len - (uint32_t)1U] = (uint8_t)0x80U;
-  Hacl_Impl_SHA3_loadState(len, nextBlock, s);
-  Hacl_Impl_SHA3_state_permute(s);
+  nextBlock[len - 1U] = 0x80U;
+  Hacl_Hash_SHA3_loadState(len, nextBlock, s);
+  Hacl_Hash_SHA3_state_permute(s);
 }
 
 typedef struct hash_buf2_s
 {
-  Hacl_Streaming_Keccak_hash_buf fst;
-  Hacl_Streaming_Keccak_hash_buf snd;
+  Hacl_Hash_SHA3_hash_buf fst;
+  Hacl_Hash_SHA3_hash_buf snd;
 }
 hash_buf2;
 
-Spec_Hash_Definitions_hash_alg Hacl_Streaming_Keccak_get_alg(Hacl_Streaming_Keccak_state *s)
+Spec_Hash_Definitions_hash_alg Hacl_Hash_SHA3_get_alg(Hacl_Hash_SHA3_state_t *s)
 {
-  Hacl_Streaming_Keccak_state scrut = *s;
-  Hacl_Streaming_Keccak_hash_buf block_state = scrut.block_state;
+  Hacl_Hash_SHA3_hash_buf block_state = (*s).block_state;
   return block_state.fst;
 }
 
-Hacl_Streaming_Keccak_state *Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_hash_alg a)
+Hacl_Hash_SHA3_state_t *Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_hash_alg a)
 {
   KRML_CHECK_SIZE(sizeof (uint8_t), block_len(a));
   uint8_t *buf0 = (uint8_t *)KRML_HOST_CALLOC(block_len(a), sizeof (uint8_t));
-  uint64_t *buf = (uint64_t *)KRML_HOST_CALLOC((uint32_t)25U, sizeof (uint64_t));
-  Hacl_Streaming_Keccak_hash_buf block_state = { .fst = a, .snd = buf };
-  Hacl_Streaming_Keccak_state
-  s = { .block_state = block_state, .buf = buf0, .total_len = (uint64_t)(uint32_t)0U };
-  Hacl_Streaming_Keccak_state
-  *p = (Hacl_Streaming_Keccak_state *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_Keccak_state));
+  uint64_t *buf = (uint64_t *)KRML_HOST_CALLOC(25U, sizeof (uint64_t));
+  Hacl_Hash_SHA3_hash_buf block_state = { .fst = a, .snd = buf };
+  Hacl_Hash_SHA3_state_t
+  s = { .block_state = block_state, .buf = buf0, .total_len = (uint64_t)0U };
+  Hacl_Hash_SHA3_state_t
+  *p = (Hacl_Hash_SHA3_state_t *)KRML_HOST_MALLOC(sizeof (Hacl_Hash_SHA3_state_t));
   p[0U] = s;
   uint64_t *s1 = block_state.snd;
-  memset(s1, 0U, (uint32_t)25U * sizeof (uint64_t));
+  memset(s1, 0U, 25U * sizeof (uint64_t));
   return p;
 }
 
-void Hacl_Streaming_Keccak_free(Hacl_Streaming_Keccak_state *s)
+void Hacl_Hash_SHA3_free(Hacl_Hash_SHA3_state_t *state)
 {
-  Hacl_Streaming_Keccak_state scrut = *s;
+  Hacl_Hash_SHA3_state_t scrut = *state;
   uint8_t *buf = scrut.buf;
-  Hacl_Streaming_Keccak_hash_buf block_state = scrut.block_state;
-  uint64_t *s1 = block_state.snd;
-  KRML_HOST_FREE(s1);
-  KRML_HOST_FREE(buf);
+  Hacl_Hash_SHA3_hash_buf block_state = scrut.block_state;
+  uint64_t *s = block_state.snd;
   KRML_HOST_FREE(s);
+  KRML_HOST_FREE(buf);
+  KRML_HOST_FREE(state);
 }
 
-Hacl_Streaming_Keccak_state *Hacl_Streaming_Keccak_copy(Hacl_Streaming_Keccak_state *s0)
+Hacl_Hash_SHA3_state_t *Hacl_Hash_SHA3_copy(Hacl_Hash_SHA3_state_t *state)
 {
-  Hacl_Streaming_Keccak_state scrut0 = *s0;
-  Hacl_Streaming_Keccak_hash_buf block_state0 = scrut0.block_state;
+  Hacl_Hash_SHA3_state_t scrut0 = *state;
+  Hacl_Hash_SHA3_hash_buf block_state0 = scrut0.block_state;
   uint8_t *buf0 = scrut0.buf;
   uint64_t total_len0 = scrut0.total_len;
   Spec_Hash_Definitions_hash_alg i = block_state0.fst;
   KRML_CHECK_SIZE(sizeof (uint8_t), block_len(i));
   uint8_t *buf1 = (uint8_t *)KRML_HOST_CALLOC(block_len(i), sizeof (uint8_t));
   memcpy(buf1, buf0, block_len(i) * sizeof (uint8_t));
-  uint64_t *buf = (uint64_t *)KRML_HOST_CALLOC((uint32_t)25U, sizeof (uint64_t));
-  Hacl_Streaming_Keccak_hash_buf block_state = { .fst = i, .snd = buf };
+  uint64_t *buf = (uint64_t *)KRML_HOST_CALLOC(25U, sizeof (uint64_t));
+  Hacl_Hash_SHA3_hash_buf block_state = { .fst = i, .snd = buf };
   hash_buf2 scrut = { .fst = block_state0, .snd = block_state };
   uint64_t *s_dst = scrut.snd.snd;
   uint64_t *s_src = scrut.fst.snd;
-  memcpy(s_dst, s_src, (uint32_t)25U * sizeof (uint64_t));
-  Hacl_Streaming_Keccak_state
+  memcpy(s_dst, s_src, 25U * sizeof (uint64_t));
+  Hacl_Hash_SHA3_state_t
   s = { .block_state = block_state, .buf = buf1, .total_len = total_len0 };
-  Hacl_Streaming_Keccak_state
-  *p = (Hacl_Streaming_Keccak_state *)KRML_HOST_MALLOC(sizeof (Hacl_Streaming_Keccak_state));
+  Hacl_Hash_SHA3_state_t
+  *p = (Hacl_Hash_SHA3_state_t *)KRML_HOST_MALLOC(sizeof (Hacl_Hash_SHA3_state_t));
   p[0U] = s;
   return p;
 }
 
-void Hacl_Streaming_Keccak_reset(Hacl_Streaming_Keccak_state *s)
+void Hacl_Hash_SHA3_reset(Hacl_Hash_SHA3_state_t *state)
 {
-  Hacl_Streaming_Keccak_state scrut = *s;
+  Hacl_Hash_SHA3_state_t scrut = *state;
   uint8_t *buf = scrut.buf;
-  Hacl_Streaming_Keccak_hash_buf block_state = scrut.block_state;
-  uint64_t *s1 = block_state.snd;
-  memset(s1, 0U, (uint32_t)25U * sizeof (uint64_t));
-  Hacl_Streaming_Keccak_state
-  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)(uint32_t)0U };
-  s[0U] = tmp;
+  Hacl_Hash_SHA3_hash_buf block_state = scrut.block_state;
+  Spec_Hash_Definitions_hash_alg i = block_state.fst;
+  KRML_MAYBE_UNUSED_VAR(i);
+  uint64_t *s = block_state.snd;
+  memset(s, 0U, 25U * sizeof (uint64_t));
+  Hacl_Hash_SHA3_state_t
+  tmp = { .block_state = block_state, .buf = buf, .total_len = (uint64_t)0U };
+  state[0U] = tmp;
 }
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint32_t len)
+Hacl_Hash_SHA3_update(Hacl_Hash_SHA3_state_t *state, uint8_t *chunk, uint32_t chunk_len)
 {
-  Hacl_Streaming_Keccak_state s = *p;
-  Hacl_Streaming_Keccak_hash_buf block_state = s.block_state;
+  Hacl_Hash_SHA3_state_t s = *state;
+  Hacl_Hash_SHA3_hash_buf block_state = s.block_state;
   uint64_t total_len = s.total_len;
   Spec_Hash_Definitions_hash_alg i = block_state.fst;
-  if ((uint64_t)len > (uint64_t)0xFFFFFFFFFFFFFFFFU - total_len)
+  if ((uint64_t)chunk_len > 0xFFFFFFFFFFFFFFFFULL - total_len)
   {
     return Hacl_Streaming_Types_MaximumLengthExceeded;
   }
   uint32_t sz;
-  if (total_len % (uint64_t)block_len(i) == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)block_len(i) == 0ULL && total_len > 0ULL)
   {
     sz = block_len(i);
   }
@@ -255,14 +255,14 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
   {
     sz = (uint32_t)(total_len % (uint64_t)block_len(i));
   }
-  if (len <= block_len(i) - sz)
+  if (chunk_len <= block_len(i) - sz)
   {
-    Hacl_Streaming_Keccak_state s1 = *p;
-    Hacl_Streaming_Keccak_hash_buf block_state1 = s1.block_state;
+    Hacl_Hash_SHA3_state_t s1 = *state;
+    Hacl_Hash_SHA3_hash_buf block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)block_len(i) == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)block_len(i) == 0ULL && total_len1 > 0ULL)
     {
       sz1 = block_len(i);
     }
@@ -271,26 +271,20 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
       sz1 = (uint32_t)(total_len1 % (uint64_t)block_len(i));
     }
     uint8_t *buf2 = buf + sz1;
-    memcpy(buf2, data, len * sizeof (uint8_t));
-    uint64_t total_len2 = total_len1 + (uint64_t)len;
-    *p
+    memcpy(buf2, chunk, chunk_len * sizeof (uint8_t));
+    uint64_t total_len2 = total_len1 + (uint64_t)chunk_len;
+    *state
     =
-      (
-        (Hacl_Streaming_Keccak_state){
-          .block_state = block_state1,
-          .buf = buf,
-          .total_len = total_len2
-        }
-      );
+      ((Hacl_Hash_SHA3_state_t){ .block_state = block_state1, .buf = buf, .total_len = total_len2 });
   }
-  else if (sz == (uint32_t)0U)
+  else if (sz == 0U)
   {
-    Hacl_Streaming_Keccak_state s1 = *p;
-    Hacl_Streaming_Keccak_hash_buf block_state1 = s1.block_state;
+    Hacl_Hash_SHA3_state_t s1 = *state;
+    Hacl_Hash_SHA3_hash_buf block_state1 = s1.block_state;
     uint8_t *buf = s1.buf;
     uint64_t total_len1 = s1.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)block_len(i) == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)block_len(i) == 0ULL && total_len1 > 0ULL)
     {
       sz1 = block_len(i);
     }
@@ -298,52 +292,52 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
     {
       sz1 = (uint32_t)(total_len1 % (uint64_t)block_len(i));
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
       Spec_Hash_Definitions_hash_alg a1 = block_state1.fst;
       uint64_t *s2 = block_state1.snd;
       Hacl_Hash_SHA3_update_multi_sha3(a1, s2, buf, block_len(i) / block_len(a1));
     }
     uint32_t ite;
-    if ((uint64_t)len % (uint64_t)block_len(i) == (uint64_t)0U && (uint64_t)len > (uint64_t)0U)
+    if ((uint64_t)chunk_len % (uint64_t)block_len(i) == 0ULL && (uint64_t)chunk_len > 0ULL)
     {
       ite = block_len(i);
     }
     else
     {
-      ite = (uint32_t)((uint64_t)len % (uint64_t)block_len(i));
+      ite = (uint32_t)((uint64_t)chunk_len % (uint64_t)block_len(i));
     }
-    uint32_t n_blocks = (len - ite) / block_len(i);
+    uint32_t n_blocks = (chunk_len - ite) / block_len(i);
     uint32_t data1_len = n_blocks * block_len(i);
-    uint32_t data2_len = len - data1_len;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + data1_len;
+    uint32_t data2_len = chunk_len - data1_len;
+    uint8_t *data1 = chunk;
+    uint8_t *data2 = chunk + data1_len;
     Spec_Hash_Definitions_hash_alg a1 = block_state1.fst;
     uint64_t *s2 = block_state1.snd;
     Hacl_Hash_SHA3_update_multi_sha3(a1, s2, data1, data1_len / block_len(a1));
     uint8_t *dst = buf;
     memcpy(dst, data2, data2_len * sizeof (uint8_t));
-    *p
+    *state
     =
       (
-        (Hacl_Streaming_Keccak_state){
+        (Hacl_Hash_SHA3_state_t){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)len
+          .total_len = total_len1 + (uint64_t)chunk_len
         }
       );
   }
   else
   {
     uint32_t diff = block_len(i) - sz;
-    uint8_t *data1 = data;
-    uint8_t *data2 = data + diff;
-    Hacl_Streaming_Keccak_state s1 = *p;
-    Hacl_Streaming_Keccak_hash_buf block_state10 = s1.block_state;
+    uint8_t *chunk1 = chunk;
+    uint8_t *chunk2 = chunk + diff;
+    Hacl_Hash_SHA3_state_t s1 = *state;
+    Hacl_Hash_SHA3_hash_buf block_state10 = s1.block_state;
     uint8_t *buf0 = s1.buf;
     uint64_t total_len10 = s1.total_len;
     uint32_t sz10;
-    if (total_len10 % (uint64_t)block_len(i) == (uint64_t)0U && total_len10 > (uint64_t)0U)
+    if (total_len10 % (uint64_t)block_len(i) == 0ULL && total_len10 > 0ULL)
     {
       sz10 = block_len(i);
     }
@@ -352,23 +346,23 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
       sz10 = (uint32_t)(total_len10 % (uint64_t)block_len(i));
     }
     uint8_t *buf2 = buf0 + sz10;
-    memcpy(buf2, data1, diff * sizeof (uint8_t));
+    memcpy(buf2, chunk1, diff * sizeof (uint8_t));
     uint64_t total_len2 = total_len10 + (uint64_t)diff;
-    *p
+    *state
     =
       (
-        (Hacl_Streaming_Keccak_state){
+        (Hacl_Hash_SHA3_state_t){
           .block_state = block_state10,
           .buf = buf0,
           .total_len = total_len2
         }
       );
-    Hacl_Streaming_Keccak_state s10 = *p;
-    Hacl_Streaming_Keccak_hash_buf block_state1 = s10.block_state;
+    Hacl_Hash_SHA3_state_t s10 = *state;
+    Hacl_Hash_SHA3_hash_buf block_state1 = s10.block_state;
     uint8_t *buf = s10.buf;
     uint64_t total_len1 = s10.total_len;
     uint32_t sz1;
-    if (total_len1 % (uint64_t)block_len(i) == (uint64_t)0U && total_len1 > (uint64_t)0U)
+    if (total_len1 % (uint64_t)block_len(i) == 0ULL && total_len1 > 0ULL)
     {
       sz1 = block_len(i);
     }
@@ -376,7 +370,7 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
     {
       sz1 = (uint32_t)(total_len1 % (uint64_t)block_len(i));
     }
-    if (!(sz1 == (uint32_t)0U))
+    if (!(sz1 == 0U))
     {
       Spec_Hash_Definitions_hash_alg a1 = block_state1.fst;
       uint64_t *s2 = block_state1.snd;
@@ -385,35 +379,35 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
     uint32_t ite;
     if
     (
-      (uint64_t)(len - diff)
+      (uint64_t)(chunk_len - diff)
       % (uint64_t)block_len(i)
-      == (uint64_t)0U
-      && (uint64_t)(len - diff) > (uint64_t)0U
+      == 0ULL
+      && (uint64_t)(chunk_len - diff) > 0ULL
     )
     {
       ite = block_len(i);
     }
     else
     {
-      ite = (uint32_t)((uint64_t)(len - diff) % (uint64_t)block_len(i));
+      ite = (uint32_t)((uint64_t)(chunk_len - diff) % (uint64_t)block_len(i));
     }
-    uint32_t n_blocks = (len - diff - ite) / block_len(i);
+    uint32_t n_blocks = (chunk_len - diff - ite) / block_len(i);
     uint32_t data1_len = n_blocks * block_len(i);
-    uint32_t data2_len = len - diff - data1_len;
-    uint8_t *data11 = data2;
-    uint8_t *data21 = data2 + data1_len;
+    uint32_t data2_len = chunk_len - diff - data1_len;
+    uint8_t *data1 = chunk2;
+    uint8_t *data2 = chunk2 + data1_len;
     Spec_Hash_Definitions_hash_alg a1 = block_state1.fst;
     uint64_t *s2 = block_state1.snd;
-    Hacl_Hash_SHA3_update_multi_sha3(a1, s2, data11, data1_len / block_len(a1));
+    Hacl_Hash_SHA3_update_multi_sha3(a1, s2, data1, data1_len / block_len(a1));
     uint8_t *dst = buf;
-    memcpy(dst, data21, data2_len * sizeof (uint8_t));
-    *p
+    memcpy(dst, data2, data2_len * sizeof (uint8_t));
+    *state
     =
       (
-        (Hacl_Streaming_Keccak_state){
+        (Hacl_Hash_SHA3_state_t){
           .block_state = block_state1,
           .buf = buf,
-          .total_len = total_len1 + (uint64_t)(len - diff)
+          .total_len = total_len1 + (uint64_t)(chunk_len - diff)
         }
       );
   }
@@ -421,19 +415,19 @@ Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint
 }
 
 static void
-finish_(
+digest_(
   Spec_Hash_Definitions_hash_alg a,
-  Hacl_Streaming_Keccak_state *p,
-  uint8_t *dst,
+  Hacl_Hash_SHA3_state_t *state,
+  uint8_t *output,
   uint32_t l
 )
 {
-  Hacl_Streaming_Keccak_state scrut0 = *p;
-  Hacl_Streaming_Keccak_hash_buf block_state = scrut0.block_state;
+  Hacl_Hash_SHA3_state_t scrut0 = *state;
+  Hacl_Hash_SHA3_hash_buf block_state = scrut0.block_state;
   uint8_t *buf_ = scrut0.buf;
   uint64_t total_len = scrut0.total_len;
   uint32_t r;
-  if (total_len % (uint64_t)block_len(a) == (uint64_t)0U && total_len > (uint64_t)0U)
+  if (total_len % (uint64_t)block_len(a) == 0ULL && total_len > 0ULL)
   {
     r = block_len(a);
   }
@@ -443,25 +437,25 @@ finish_(
   }
   uint8_t *buf_1 = buf_;
   uint64_t buf[25U] = { 0U };
-  Hacl_Streaming_Keccak_hash_buf tmp_block_state = { .fst = a, .snd = buf };
+  Hacl_Hash_SHA3_hash_buf tmp_block_state = { .fst = a, .snd = buf };
   hash_buf2 scrut = { .fst = block_state, .snd = tmp_block_state };
   uint64_t *s_dst = scrut.snd.snd;
   uint64_t *s_src = scrut.fst.snd;
-  memcpy(s_dst, s_src, (uint32_t)25U * sizeof (uint64_t));
-  uint32_t ite0;
-  if (r % block_len(a) == (uint32_t)0U && r > (uint32_t)0U)
+  memcpy(s_dst, s_src, 25U * sizeof (uint64_t));
+  uint32_t ite;
+  if (r % block_len(a) == 0U && r > 0U)
   {
-    ite0 = block_len(a);
+    ite = block_len(a);
   }
   else
   {
-    ite0 = r % block_len(a);
+    ite = r % block_len(a);
   }
-  uint8_t *buf_last = buf_1 + r - ite0;
+  uint8_t *buf_last = buf_1 + r - ite;
   uint8_t *buf_multi = buf_1;
   Spec_Hash_Definitions_hash_alg a1 = tmp_block_state.fst;
   uint64_t *s0 = tmp_block_state.snd;
-  Hacl_Hash_SHA3_update_multi_sha3(a1, s0, buf_multi, (uint32_t)0U / block_len(a1));
+  Hacl_Hash_SHA3_update_multi_sha3(a1, s0, buf_multi, 0U / block_len(a1));
   Spec_Hash_Definitions_hash_alg a10 = tmp_block_state.fst;
   uint64_t *s1 = tmp_block_state.snd;
   Hacl_Hash_SHA3_update_last_sha3(a10, s1, buf_last, r);
@@ -469,267 +463,182 @@ finish_(
   uint64_t *s = tmp_block_state.snd;
   if (a11 == Spec_Hash_Definitions_Shake128 || a11 == Spec_Hash_Definitions_Shake256)
   {
-    uint32_t ite;
-    if (a11 == Spec_Hash_Definitions_Shake128 || a11 == Spec_Hash_Definitions_Shake256)
-    {
-      ite = l;
-    }
-    else
-    {
-      ite = hash_len(a11);
-    }
-    Hacl_Impl_SHA3_squeeze(s, block_len(a11), ite, dst);
+    Hacl_Hash_SHA3_squeeze0(s, block_len(a11), l, output);
     return;
   }
-  Hacl_Impl_SHA3_squeeze(s, block_len(a11), hash_len(a11), dst);
+  Hacl_Hash_SHA3_squeeze0(s, block_len(a11), hash_len(a11), output);
 }
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_Keccak_finish(Hacl_Streaming_Keccak_state *s, uint8_t *dst)
+Hacl_Hash_SHA3_digest(Hacl_Hash_SHA3_state_t *state, uint8_t *output)
 {
-  Spec_Hash_Definitions_hash_alg a1 = Hacl_Streaming_Keccak_get_alg(s);
+  Spec_Hash_Definitions_hash_alg a1 = Hacl_Hash_SHA3_get_alg(state);
   if (a1 == Spec_Hash_Definitions_Shake128 || a1 == Spec_Hash_Definitions_Shake256)
   {
     return Hacl_Streaming_Types_InvalidAlgorithm;
   }
-  finish_(a1, s, dst, hash_len(a1));
+  digest_(a1, state, output, hash_len(a1));
   return Hacl_Streaming_Types_Success;
 }
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_Keccak_squeeze(Hacl_Streaming_Keccak_state *s, uint8_t *dst, uint32_t l)
+Hacl_Hash_SHA3_squeeze(Hacl_Hash_SHA3_state_t *s, uint8_t *dst, uint32_t l)
 {
-  Spec_Hash_Definitions_hash_alg a1 = Hacl_Streaming_Keccak_get_alg(s);
+  Spec_Hash_Definitions_hash_alg a1 = Hacl_Hash_SHA3_get_alg(s);
   if (!(a1 == Spec_Hash_Definitions_Shake128 || a1 == Spec_Hash_Definitions_Shake256))
   {
     return Hacl_Streaming_Types_InvalidAlgorithm;
   }
-  if (l == (uint32_t)0U)
+  if (l == 0U)
   {
     return Hacl_Streaming_Types_InvalidLength;
   }
-  finish_(a1, s, dst, l);
+  digest_(a1, s, dst, l);
   return Hacl_Streaming_Types_Success;
 }
 
-uint32_t Hacl_Streaming_Keccak_block_len(Hacl_Streaming_Keccak_state *s)
+uint32_t Hacl_Hash_SHA3_block_len(Hacl_Hash_SHA3_state_t *s)
 {
-  Spec_Hash_Definitions_hash_alg a1 = Hacl_Streaming_Keccak_get_alg(s);
+  Spec_Hash_Definitions_hash_alg a1 = Hacl_Hash_SHA3_get_alg(s);
   return block_len(a1);
 }
 
-uint32_t Hacl_Streaming_Keccak_hash_len(Hacl_Streaming_Keccak_state *s)
+uint32_t Hacl_Hash_SHA3_hash_len(Hacl_Hash_SHA3_state_t *s)
 {
-  Spec_Hash_Definitions_hash_alg a1 = Hacl_Streaming_Keccak_get_alg(s);
+  Spec_Hash_Definitions_hash_alg a1 = Hacl_Hash_SHA3_get_alg(s);
   return hash_len(a1);
 }
 
-bool Hacl_Streaming_Keccak_is_shake(Hacl_Streaming_Keccak_state *s)
+bool Hacl_Hash_SHA3_is_shake(Hacl_Hash_SHA3_state_t *s)
 {
-  Spec_Hash_Definitions_hash_alg uu____0 = Hacl_Streaming_Keccak_get_alg(s);
+  Spec_Hash_Definitions_hash_alg uu____0 = Hacl_Hash_SHA3_get_alg(s);
   return uu____0 == Spec_Hash_Definitions_Shake128 || uu____0 == Spec_Hash_Definitions_Shake256;
 }
 
 void
-Hacl_SHA3_shake128_hacl(
+Hacl_Hash_SHA3_shake128_hacl(
   uint32_t inputByteLen,
   uint8_t *input,
   uint32_t outputByteLen,
   uint8_t *output
 )
 {
-  Hacl_Impl_SHA3_keccak((uint32_t)1344U,
-    (uint32_t)256U,
-    inputByteLen,
-    input,
-    (uint8_t)0x1FU,
-    outputByteLen,
-    output);
+  Hacl_Hash_SHA3_keccak(1344U, 256U, inputByteLen, input, 0x1FU, outputByteLen, output);
 }
 
 void
-Hacl_SHA3_shake256_hacl(
+Hacl_Hash_SHA3_shake256_hacl(
   uint32_t inputByteLen,
   uint8_t *input,
   uint32_t outputByteLen,
   uint8_t *output
 )
 {
-  Hacl_Impl_SHA3_keccak((uint32_t)1088U,
-    (uint32_t)512U,
-    inputByteLen,
-    input,
-    (uint8_t)0x1FU,
-    outputByteLen,
-    output);
+  Hacl_Hash_SHA3_keccak(1088U, 512U, inputByteLen, input, 0x1FU, outputByteLen, output);
 }
 
-void Hacl_SHA3_sha3_224(uint32_t inputByteLen, uint8_t *input, uint8_t *output)
+void Hacl_Hash_SHA3_sha3_224(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  Hacl_Impl_SHA3_keccak((uint32_t)1152U,
-    (uint32_t)448U,
-    inputByteLen,
-    input,
-    (uint8_t)0x06U,
-    (uint32_t)28U,
-    output);
+  Hacl_Hash_SHA3_keccak(1152U, 448U, input_len, input, 0x06U, 28U, output);
 }
 
-void Hacl_SHA3_sha3_256(uint32_t inputByteLen, uint8_t *input, uint8_t *output)
+void Hacl_Hash_SHA3_sha3_256(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  Hacl_Impl_SHA3_keccak((uint32_t)1088U,
-    (uint32_t)512U,
-    inputByteLen,
-    input,
-    (uint8_t)0x06U,
-    (uint32_t)32U,
-    output);
+  Hacl_Hash_SHA3_keccak(1088U, 512U, input_len, input, 0x06U, 32U, output);
 }
 
-void Hacl_SHA3_sha3_384(uint32_t inputByteLen, uint8_t *input, uint8_t *output)
+void Hacl_Hash_SHA3_sha3_384(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  Hacl_Impl_SHA3_keccak((uint32_t)832U,
-    (uint32_t)768U,
-    inputByteLen,
-    input,
-    (uint8_t)0x06U,
-    (uint32_t)48U,
-    output);
+  Hacl_Hash_SHA3_keccak(832U, 768U, input_len, input, 0x06U, 48U, output);
 }
 
-void Hacl_SHA3_sha3_512(uint32_t inputByteLen, uint8_t *input, uint8_t *output)
+void Hacl_Hash_SHA3_sha3_512(uint8_t *output, uint8_t *input, uint32_t input_len)
 {
-  Hacl_Impl_SHA3_keccak((uint32_t)576U,
-    (uint32_t)1024U,
-    inputByteLen,
-    input,
-    (uint8_t)0x06U,
-    (uint32_t)64U,
-    output);
+  Hacl_Hash_SHA3_keccak(576U, 1024U, input_len, input, 0x06U, 64U, output);
 }
 
 static const
 uint32_t
 keccak_rotc[24U] =
   {
-    (uint32_t)1U, (uint32_t)3U, (uint32_t)6U, (uint32_t)10U, (uint32_t)15U, (uint32_t)21U,
-    (uint32_t)28U, (uint32_t)36U, (uint32_t)45U, (uint32_t)55U, (uint32_t)2U, (uint32_t)14U,
-    (uint32_t)27U, (uint32_t)41U, (uint32_t)56U, (uint32_t)8U, (uint32_t)25U, (uint32_t)43U,
-    (uint32_t)62U, (uint32_t)18U, (uint32_t)39U, (uint32_t)61U, (uint32_t)20U, (uint32_t)44U
+    1U, 3U, 6U, 10U, 15U, 21U, 28U, 36U, 45U, 55U, 2U, 14U, 27U, 41U, 56U, 8U, 25U, 43U, 62U, 18U,
+    39U, 61U, 20U, 44U
   };
 
 static const
 uint32_t
 keccak_piln[24U] =
   {
-    (uint32_t)10U, (uint32_t)7U, (uint32_t)11U, (uint32_t)17U, (uint32_t)18U, (uint32_t)3U,
-    (uint32_t)5U, (uint32_t)16U, (uint32_t)8U, (uint32_t)21U, (uint32_t)24U, (uint32_t)4U,
-    (uint32_t)15U, (uint32_t)23U, (uint32_t)19U, (uint32_t)13U, (uint32_t)12U, (uint32_t)2U,
-    (uint32_t)20U, (uint32_t)14U, (uint32_t)22U, (uint32_t)9U, (uint32_t)6U, (uint32_t)1U
+    10U, 7U, 11U, 17U, 18U, 3U, 5U, 16U, 8U, 21U, 24U, 4U, 15U, 23U, 19U, 13U, 12U, 2U, 20U, 14U,
+    22U, 9U, 6U, 1U
   };
 
 static const
 uint64_t
 keccak_rndc[24U] =
   {
-    (uint64_t)0x0000000000000001U, (uint64_t)0x0000000000008082U, (uint64_t)0x800000000000808aU,
-    (uint64_t)0x8000000080008000U, (uint64_t)0x000000000000808bU, (uint64_t)0x0000000080000001U,
-    (uint64_t)0x8000000080008081U, (uint64_t)0x8000000000008009U, (uint64_t)0x000000000000008aU,
-    (uint64_t)0x0000000000000088U, (uint64_t)0x0000000080008009U, (uint64_t)0x000000008000000aU,
-    (uint64_t)0x000000008000808bU, (uint64_t)0x800000000000008bU, (uint64_t)0x8000000000008089U,
-    (uint64_t)0x8000000000008003U, (uint64_t)0x8000000000008002U, (uint64_t)0x8000000000000080U,
-    (uint64_t)0x000000000000800aU, (uint64_t)0x800000008000000aU, (uint64_t)0x8000000080008081U,
-    (uint64_t)0x8000000000008080U, (uint64_t)0x0000000080000001U, (uint64_t)0x8000000080008008U
+    0x0000000000000001ULL, 0x0000000000008082ULL, 0x800000000000808aULL, 0x8000000080008000ULL,
+    0x000000000000808bULL, 0x0000000080000001ULL, 0x8000000080008081ULL, 0x8000000000008009ULL,
+    0x000000000000008aULL, 0x0000000000000088ULL, 0x0000000080008009ULL, 0x000000008000000aULL,
+    0x000000008000808bULL, 0x800000000000008bULL, 0x8000000000008089ULL, 0x8000000000008003ULL,
+    0x8000000000008002ULL, 0x8000000000000080ULL, 0x000000000000800aULL, 0x800000008000000aULL,
+    0x8000000080008081ULL, 0x8000000000008080ULL, 0x0000000080000001ULL, 0x8000000080008008ULL
   };
 
-void Hacl_Impl_SHA3_state_permute(uint64_t *s)
+void Hacl_Hash_SHA3_state_permute(uint64_t *s)
 {
-  for (uint32_t i0 = (uint32_t)0U; i0 < (uint32_t)24U; i0++)
+  for (uint32_t i0 = 0U; i0 < 24U; i0++)
   {
     uint64_t _C[5U] = { 0U };
     KRML_MAYBE_FOR5(i,
-      (uint32_t)0U,
-      (uint32_t)5U,
-      (uint32_t)1U,
-      _C[i] =
-        s[i
-        + (uint32_t)0U]
-        ^
-          (s[i
-          + (uint32_t)5U]
-          ^ (s[i + (uint32_t)10U] ^ (s[i + (uint32_t)15U] ^ s[i + (uint32_t)20U]))););
+      0U,
+      5U,
+      1U,
+      _C[i] = s[i + 0U] ^ (s[i + 5U] ^ (s[i + 10U] ^ (s[i + 15U] ^ s[i + 20U]))););
     KRML_MAYBE_FOR5(i1,
-      (uint32_t)0U,
-      (uint32_t)5U,
-      (uint32_t)1U,
-      uint64_t uu____0 = _C[(i1 + (uint32_t)1U) % (uint32_t)5U];
-      uint64_t
-      _D =
-        _C[(i1 + (uint32_t)4U)
-        % (uint32_t)5U]
-        ^ (uu____0 << (uint32_t)1U | uu____0 >> (uint32_t)63U);
-      KRML_MAYBE_FOR5(i,
-        (uint32_t)0U,
-        (uint32_t)5U,
-        (uint32_t)1U,
-        s[i1 + (uint32_t)5U * i] = s[i1 + (uint32_t)5U * i] ^ _D;););
+      0U,
+      5U,
+      1U,
+      uint64_t uu____0 = _C[(i1 + 1U) % 5U];
+      uint64_t _D = _C[(i1 + 4U) % 5U] ^ (uu____0 << 1U | uu____0 >> 63U);
+      KRML_MAYBE_FOR5(i, 0U, 5U, 1U, s[i1 + 5U * i] = s[i1 + 5U * i] ^ _D;););
     uint64_t x = s[1U];
     uint64_t current = x;
-    for (uint32_t i = (uint32_t)0U; i < (uint32_t)24U; i++)
+    for (uint32_t i = 0U; i < 24U; i++)
     {
       uint32_t _Y = keccak_piln[i];
       uint32_t r = keccak_rotc[i];
       uint64_t temp = s[_Y];
       uint64_t uu____1 = current;
-      s[_Y] = uu____1 << r | uu____1 >> ((uint32_t)64U - r);
+      s[_Y] = uu____1 << r | uu____1 >> (64U - r);
       current = temp;
     }
     KRML_MAYBE_FOR5(i,
-      (uint32_t)0U,
-      (uint32_t)5U,
-      (uint32_t)1U,
-      uint64_t
-      v0 =
-        s[(uint32_t)0U
-        + (uint32_t)5U * i]
-        ^ (~s[(uint32_t)1U + (uint32_t)5U * i] & s[(uint32_t)2U + (uint32_t)5U * i]);
-      uint64_t
-      v1 =
-        s[(uint32_t)1U
-        + (uint32_t)5U * i]
-        ^ (~s[(uint32_t)2U + (uint32_t)5U * i] & s[(uint32_t)3U + (uint32_t)5U * i]);
-      uint64_t
-      v2 =
-        s[(uint32_t)2U
-        + (uint32_t)5U * i]
-        ^ (~s[(uint32_t)3U + (uint32_t)5U * i] & s[(uint32_t)4U + (uint32_t)5U * i]);
-      uint64_t
-      v3 =
-        s[(uint32_t)3U
-        + (uint32_t)5U * i]
-        ^ (~s[(uint32_t)4U + (uint32_t)5U * i] & s[(uint32_t)0U + (uint32_t)5U * i]);
-      uint64_t
-      v4 =
-        s[(uint32_t)4U
-        + (uint32_t)5U * i]
-        ^ (~s[(uint32_t)0U + (uint32_t)5U * i] & s[(uint32_t)1U + (uint32_t)5U * i]);
-      s[(uint32_t)0U + (uint32_t)5U * i] = v0;
-      s[(uint32_t)1U + (uint32_t)5U * i] = v1;
-      s[(uint32_t)2U + (uint32_t)5U * i] = v2;
-      s[(uint32_t)3U + (uint32_t)5U * i] = v3;
-      s[(uint32_t)4U + (uint32_t)5U * i] = v4;);
+      0U,
+      5U,
+      1U,
+      uint64_t v0 = s[0U + 5U * i] ^ (~s[1U + 5U * i] & s[2U + 5U * i]);
+      uint64_t v1 = s[1U + 5U * i] ^ (~s[2U + 5U * i] & s[3U + 5U * i]);
+      uint64_t v2 = s[2U + 5U * i] ^ (~s[3U + 5U * i] & s[4U + 5U * i]);
+      uint64_t v3 = s[3U + 5U * i] ^ (~s[4U + 5U * i] & s[0U + 5U * i]);
+      uint64_t v4 = s[4U + 5U * i] ^ (~s[0U + 5U * i] & s[1U + 5U * i]);
+      s[0U + 5U * i] = v0;
+      s[1U + 5U * i] = v1;
+      s[2U + 5U * i] = v2;
+      s[3U + 5U * i] = v3;
+      s[4U + 5U * i] = v4;);
     uint64_t c = keccak_rndc[i0];
     s[0U] = s[0U] ^ c;
   }
 }
 
-void Hacl_Impl_SHA3_loadState(uint32_t rateInBytes, uint8_t *input, uint64_t *s)
+void Hacl_Hash_SHA3_loadState(uint32_t rateInBytes, uint8_t *input, uint64_t *s)
 {
   uint8_t block[200U] = { 0U };
   memcpy(block, input, rateInBytes * sizeof (uint8_t));
-  for (uint32_t i = (uint32_t)0U; i < (uint32_t)25U; i++)
+  for (uint32_t i = 0U; i < 25U; i++)
   {
-    uint64_t u = load64_le(block + i * (uint32_t)8U);
+    uint64_t u = load64_le(block + i * 8U);
     uint64_t x = u;
     s[i] = s[i] ^ x;
   }
@@ -738,18 +647,18 @@ void Hacl_Impl_SHA3_loadState(uint32_t rateInBytes, uint8_t *input, uint64_t *s)
 static void storeState(uint32_t rateInBytes, uint64_t *s, uint8_t *res)
 {
   uint8_t block[200U] = { 0U };
-  for (uint32_t i = (uint32_t)0U; i < (uint32_t)25U; i++)
+  for (uint32_t i = 0U; i < 25U; i++)
   {
     uint64_t sj = s[i];
-    store64_le(block + i * (uint32_t)8U, sj);
+    store64_le(block + i * 8U, sj);
   }
   memcpy(res, block, rateInBytes * sizeof (uint8_t));
 }
 
-void Hacl_Impl_SHA3_absorb_inner(uint32_t rateInBytes, uint8_t *block, uint64_t *s)
+void Hacl_Hash_SHA3_absorb_inner(uint32_t rateInBytes, uint8_t *block, uint64_t *s)
 {
-  Hacl_Impl_SHA3_loadState(rateInBytes, block, s);
-  Hacl_Impl_SHA3_state_permute(s);
+  Hacl_Hash_SHA3_loadState(rateInBytes, block, s);
+  Hacl_Hash_SHA3_state_permute(s);
 }
 
 static void
@@ -763,30 +672,30 @@ absorb(
 {
   uint32_t n_blocks = inputByteLen / rateInBytes;
   uint32_t rem = inputByteLen % rateInBytes;
-  for (uint32_t i = (uint32_t)0U; i < n_blocks; i++)
+  for (uint32_t i = 0U; i < n_blocks; i++)
   {
     uint8_t *block = input + i * rateInBytes;
-    Hacl_Impl_SHA3_absorb_inner(rateInBytes, block, s);
+    Hacl_Hash_SHA3_absorb_inner(rateInBytes, block, s);
   }
   uint8_t *last = input + n_blocks * rateInBytes;
   uint8_t lastBlock_[200U] = { 0U };
   uint8_t *lastBlock = lastBlock_;
   memcpy(lastBlock, last, rem * sizeof (uint8_t));
   lastBlock[rem] = delimitedSuffix;
-  Hacl_Impl_SHA3_loadState(rateInBytes, lastBlock, s);
-  if (!((delimitedSuffix & (uint8_t)0x80U) == (uint8_t)0U) && rem == rateInBytes - (uint32_t)1U)
+  Hacl_Hash_SHA3_loadState(rateInBytes, lastBlock, s);
+  if (!(((uint32_t)delimitedSuffix & 0x80U) == 0U) && rem == rateInBytes - 1U)
   {
-    Hacl_Impl_SHA3_state_permute(s);
+    Hacl_Hash_SHA3_state_permute(s);
   }
   uint8_t nextBlock_[200U] = { 0U };
   uint8_t *nextBlock = nextBlock_;
-  nextBlock[rateInBytes - (uint32_t)1U] = (uint8_t)0x80U;
-  Hacl_Impl_SHA3_loadState(rateInBytes, nextBlock, s);
-  Hacl_Impl_SHA3_state_permute(s);
+  nextBlock[rateInBytes - 1U] = 0x80U;
+  Hacl_Hash_SHA3_loadState(rateInBytes, nextBlock, s);
+  Hacl_Hash_SHA3_state_permute(s);
 }
 
 void
-Hacl_Impl_SHA3_squeeze(
+Hacl_Hash_SHA3_squeeze0(
   uint64_t *s,
   uint32_t rateInBytes,
   uint32_t outputByteLen,
@@ -797,16 +706,16 @@ Hacl_Impl_SHA3_squeeze(
   uint32_t remOut = outputByteLen % rateInBytes;
   uint8_t *last = output + outputByteLen - remOut;
   uint8_t *blocks = output;
-  for (uint32_t i = (uint32_t)0U; i < outBlocks; i++)
+  for (uint32_t i = 0U; i < outBlocks; i++)
   {
     storeState(rateInBytes, s, blocks + i * rateInBytes);
-    Hacl_Impl_SHA3_state_permute(s);
+    Hacl_Hash_SHA3_state_permute(s);
   }
   storeState(remOut, s, last);
 }
 
 void
-Hacl_Impl_SHA3_keccak(
+Hacl_Hash_SHA3_keccak(
   uint32_t rate,
   uint32_t capacity,
   uint32_t inputByteLen,
@@ -816,9 +725,10 @@ Hacl_Impl_SHA3_keccak(
   uint8_t *output
 )
 {
-  uint32_t rateInBytes = rate / (uint32_t)8U;
+  KRML_MAYBE_UNUSED_VAR(capacity);
+  uint32_t rateInBytes = rate / 8U;
   uint64_t s[25U] = { 0U };
   absorb(s, rateInBytes, inputByteLen, input, delimitedSuffix);
-  Hacl_Impl_SHA3_squeeze(s, rateInBytes, outputByteLen, output);
+  Hacl_Hash_SHA3_squeeze0(s, rateInBytes, outputByteLen, output);
 }
 
diff --git a/Modules/_hacl/Hacl_Hash_SHA3.h b/Modules/_hacl/Hacl_Hash_SHA3.h
index 681b6af4a8..678e9f2fbe 100644
--- a/Modules/_hacl/Hacl_Hash_SHA3.h
+++ b/Modules/_hacl/Hacl_Hash_SHA3.h
@@ -31,54 +31,55 @@ extern "C" {
 #endif
 
 #include <string.h>
+#include "python_hacl_namespaces.h"
 #include "krml/types.h"
 #include "krml/lowstar_endianness.h"
 #include "krml/internal/target.h"
 
 #include "Hacl_Streaming_Types.h"
 
-typedef struct Hacl_Streaming_Keccak_hash_buf_s
+typedef struct Hacl_Hash_SHA3_hash_buf_s
 {
   Spec_Hash_Definitions_hash_alg fst;
   uint64_t *snd;
 }
-Hacl_Streaming_Keccak_hash_buf;
+Hacl_Hash_SHA3_hash_buf;
 
-typedef struct Hacl_Streaming_Keccak_state_s
+typedef struct Hacl_Hash_SHA3_state_t_s
 {
-  Hacl_Streaming_Keccak_hash_buf block_state;
+  Hacl_Hash_SHA3_hash_buf block_state;
   uint8_t *buf;
   uint64_t total_len;
 }
-Hacl_Streaming_Keccak_state;
+Hacl_Hash_SHA3_state_t;
 
-Spec_Hash_Definitions_hash_alg Hacl_Streaming_Keccak_get_alg(Hacl_Streaming_Keccak_state *s);
+Spec_Hash_Definitions_hash_alg Hacl_Hash_SHA3_get_alg(Hacl_Hash_SHA3_state_t *s);
 
-Hacl_Streaming_Keccak_state *Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_hash_alg a);
+Hacl_Hash_SHA3_state_t *Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_hash_alg a);
 
-void Hacl_Streaming_Keccak_free(Hacl_Streaming_Keccak_state *s);
+void Hacl_Hash_SHA3_free(Hacl_Hash_SHA3_state_t *state);
 
-Hacl_Streaming_Keccak_state *Hacl_Streaming_Keccak_copy(Hacl_Streaming_Keccak_state *s0);
+Hacl_Hash_SHA3_state_t *Hacl_Hash_SHA3_copy(Hacl_Hash_SHA3_state_t *state);
 
-void Hacl_Streaming_Keccak_reset(Hacl_Streaming_Keccak_state *s);
+void Hacl_Hash_SHA3_reset(Hacl_Hash_SHA3_state_t *state);
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_Keccak_update(Hacl_Streaming_Keccak_state *p, uint8_t *data, uint32_t len);
+Hacl_Hash_SHA3_update(Hacl_Hash_SHA3_state_t *state, uint8_t *chunk, uint32_t chunk_len);
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_Keccak_finish(Hacl_Streaming_Keccak_state *s, uint8_t *dst);
+Hacl_Hash_SHA3_digest(Hacl_Hash_SHA3_state_t *state, uint8_t *output);
 
 Hacl_Streaming_Types_error_code
-Hacl_Streaming_Keccak_squeeze(Hacl_Streaming_Keccak_state *s, uint8_t *dst, uint32_t l);
+Hacl_Hash_SHA3_squeeze(Hacl_Hash_SHA3_state_t *s, uint8_t *dst, uint32_t l);
 
-uint32_t Hacl_Streaming_Keccak_block_len(Hacl_Streaming_Keccak_state *s);
+uint32_t Hacl_Hash_SHA3_block_len(Hacl_Hash_SHA3_state_t *s);
 
-uint32_t Hacl_Streaming_Keccak_hash_len(Hacl_Streaming_Keccak_state *s);
+uint32_t Hacl_Hash_SHA3_hash_len(Hacl_Hash_SHA3_state_t *s);
 
-bool Hacl_Streaming_Keccak_is_shake(Hacl_Streaming_Keccak_state *s);
+bool Hacl_Hash_SHA3_is_shake(Hacl_Hash_SHA3_state_t *s);
 
 void
-Hacl_SHA3_shake128_hacl(
+Hacl_Hash_SHA3_shake128_hacl(
   uint32_t inputByteLen,
   uint8_t *input,
   uint32_t outputByteLen,
@@ -86,25 +87,25 @@ Hacl_SHA3_shake128_hacl(
 );
 
 void
-Hacl_SHA3_shake256_hacl(
+Hacl_Hash_SHA3_shake256_hacl(
   uint32_t inputByteLen,
   uint8_t *input,
   uint32_t outputByteLen,
   uint8_t *output
 );
 
-void Hacl_SHA3_sha3_224(uint32_t inputByteLen, uint8_t *input, uint8_t *output);
+void Hacl_Hash_SHA3_sha3_224(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-void Hacl_SHA3_sha3_256(uint32_t inputByteLen, uint8_t *input, uint8_t *output);
+void Hacl_Hash_SHA3_sha3_256(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-void Hacl_SHA3_sha3_384(uint32_t inputByteLen, uint8_t *input, uint8_t *output);
+void Hacl_Hash_SHA3_sha3_384(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-void Hacl_SHA3_sha3_512(uint32_t inputByteLen, uint8_t *input, uint8_t *output);
+void Hacl_Hash_SHA3_sha3_512(uint8_t *output, uint8_t *input, uint32_t input_len);
 
-void Hacl_Impl_SHA3_absorb_inner(uint32_t rateInBytes, uint8_t *block, uint64_t *s);
+void Hacl_Hash_SHA3_absorb_inner(uint32_t rateInBytes, uint8_t *block, uint64_t *s);
 
 void
-Hacl_Impl_SHA3_squeeze(
+Hacl_Hash_SHA3_squeeze0(
   uint64_t *s,
   uint32_t rateInBytes,
   uint32_t outputByteLen,
@@ -112,7 +113,7 @@ Hacl_Impl_SHA3_squeeze(
 );
 
 void
-Hacl_Impl_SHA3_keccak(
+Hacl_Hash_SHA3_keccak(
   uint32_t rate,
   uint32_t capacity,
   uint32_t inputByteLen,
diff --git a/Modules/_hacl/include/krml/FStar_UInt128_Verified.h b/Modules/_hacl/include/krml/FStar_UInt128_Verified.h
index 3d36d44073..bdf25898f2 100644
--- a/Modules/_hacl/include/krml/FStar_UInt128_Verified.h
+++ b/Modules/_hacl/include/krml/FStar_UInt128_Verified.h
@@ -15,7 +15,7 @@
 
 static inline uint64_t FStar_UInt128_constant_time_carry(uint64_t a, uint64_t b)
 {
-  return (a ^ ((a ^ b) | ((a - b) ^ b))) >> (uint32_t)63U;
+  return (a ^ ((a ^ b) | ((a - b) ^ b))) >> 63U;
 }
 
 static inline uint64_t FStar_UInt128_carry(uint64_t a, uint64_t b)
@@ -118,7 +118,7 @@ static inline FStar_UInt128_uint128 FStar_UInt128_lognot(FStar_UInt128_uint128 a
   return lit;
 }
 
-static uint32_t FStar_UInt128_u32_64 = (uint32_t)64U;
+static uint32_t FStar_UInt128_u32_64 = 64U;
 
 static inline uint64_t FStar_UInt128_add_u64_shift_left(uint64_t hi, uint64_t lo, uint32_t s)
 {
@@ -134,7 +134,7 @@ FStar_UInt128_add_u64_shift_left_respec(uint64_t hi, uint64_t lo, uint32_t s)
 static inline FStar_UInt128_uint128
 FStar_UInt128_shift_left_small(FStar_UInt128_uint128 a, uint32_t s)
 {
-  if (s == (uint32_t)0U)
+  if (s == 0U)
   {
     return a;
   }
@@ -151,7 +151,7 @@ static inline FStar_UInt128_uint128
 FStar_UInt128_shift_left_large(FStar_UInt128_uint128 a, uint32_t s)
 {
   FStar_UInt128_uint128 lit;
-  lit.low = (uint64_t)0U;
+  lit.low = 0ULL;
   lit.high = a.low << (s - FStar_UInt128_u32_64);
   return lit;
 }
@@ -183,7 +183,7 @@ FStar_UInt128_add_u64_shift_right_respec(uint64_t hi, uint64_t lo, uint32_t s)
 static inline FStar_UInt128_uint128
 FStar_UInt128_shift_right_small(FStar_UInt128_uint128 a, uint32_t s)
 {
-  if (s == (uint32_t)0U)
+  if (s == 0U)
   {
     return a;
   }
@@ -201,7 +201,7 @@ FStar_UInt128_shift_right_large(FStar_UInt128_uint128 a, uint32_t s)
 {
   FStar_UInt128_uint128 lit;
   lit.low = a.high >> (s - FStar_UInt128_u32_64);
-  lit.high = (uint64_t)0U;
+  lit.high = 0ULL;
   return lit;
 }
 
@@ -269,7 +269,7 @@ static inline FStar_UInt128_uint128 FStar_UInt128_uint64_to_uint128(uint64_t a)
 {
   FStar_UInt128_uint128 lit;
   lit.low = a;
-  lit.high = (uint64_t)0U;
+  lit.high = 0ULL;
   return lit;
 }
 
@@ -280,10 +280,10 @@ static inline uint64_t FStar_UInt128_uint128_to_uint64(FStar_UInt128_uint128 a)
 
 static inline uint64_t FStar_UInt128_u64_mod_32(uint64_t a)
 {
-  return a & (uint64_t)0xffffffffU;
+  return a & 0xffffffffULL;
 }
 
-static uint32_t FStar_UInt128_u32_32 = (uint32_t)32U;
+static uint32_t FStar_UInt128_u32_32 = 32U;
 
 static inline uint64_t FStar_UInt128_u32_combine(uint64_t hi, uint64_t lo)
 {
diff --git a/Modules/_hacl/include/krml/FStar_UInt_8_16_32_64.h b/Modules/_hacl/include/krml/FStar_UInt_8_16_32_64.h
index a56c7d6134..1bdec972a2 100644
--- a/Modules/_hacl/include/krml/FStar_UInt_8_16_32_64.h
+++ b/Modules/_hacl/include/krml/FStar_UInt_8_16_32_64.h
@@ -14,16 +14,16 @@
 #include "krml/types.h"
 #include "krml/internal/target.h"
 
-static inline uint64_t FStar_UInt64_eq_mask(uint64_t a, uint64_t b)
+static KRML_NOINLINE uint64_t FStar_UInt64_eq_mask(uint64_t a, uint64_t b)
 {
   uint64_t x = a ^ b;
-  uint64_t minus_x = ~x + (uint64_t)1U;
+  uint64_t minus_x = ~x + 1ULL;
   uint64_t x_or_minus_x = x | minus_x;
-  uint64_t xnx = x_or_minus_x >> (uint32_t)63U;
-  return xnx - (uint64_t)1U;
+  uint64_t xnx = x_or_minus_x >> 63U;
+  return xnx - 1ULL;
 }
 
-static inline uint64_t FStar_UInt64_gte_mask(uint64_t a, uint64_t b)
+static KRML_NOINLINE uint64_t FStar_UInt64_gte_mask(uint64_t a, uint64_t b)
 {
   uint64_t x = a;
   uint64_t y = b;
@@ -32,20 +32,20 @@ static inline uint64_t FStar_UInt64_gte_mask(uint64_t a, uint64_t b)
   uint64_t x_sub_y_xor_y = x_sub_y ^ y;
   uint64_t q = x_xor_y | x_sub_y_xor_y;
   uint64_t x_xor_q = x ^ q;
-  uint64_t x_xor_q_ = x_xor_q >> (uint32_t)63U;
-  return x_xor_q_ - (uint64_t)1U;
+  uint64_t x_xor_q_ = x_xor_q >> 63U;
+  return x_xor_q_ - 1ULL;
 }
 
-static inline uint32_t FStar_UInt32_eq_mask(uint32_t a, uint32_t b)
+static KRML_NOINLINE uint32_t FStar_UInt32_eq_mask(uint32_t a, uint32_t b)
 {
   uint32_t x = a ^ b;
-  uint32_t minus_x = ~x + (uint32_t)1U;
+  uint32_t minus_x = ~x + 1U;
   uint32_t x_or_minus_x = x | minus_x;
-  uint32_t xnx = x_or_minus_x >> (uint32_t)31U;
-  return xnx - (uint32_t)1U;
+  uint32_t xnx = x_or_minus_x >> 31U;
+  return xnx - 1U;
 }
 
-static inline uint32_t FStar_UInt32_gte_mask(uint32_t a, uint32_t b)
+static KRML_NOINLINE uint32_t FStar_UInt32_gte_mask(uint32_t a, uint32_t b)
 {
   uint32_t x = a;
   uint32_t y = b;
@@ -54,52 +54,52 @@ static inline uint32_t FStar_UInt32_gte_mask(uint32_t a, uint32_t b)
   uint32_t x_sub_y_xor_y = x_sub_y ^ y;
   uint32_t q = x_xor_y | x_sub_y_xor_y;
   uint32_t x_xor_q = x ^ q;
-  uint32_t x_xor_q_ = x_xor_q >> (uint32_t)31U;
-  return x_xor_q_ - (uint32_t)1U;
+  uint32_t x_xor_q_ = x_xor_q >> 31U;
+  return x_xor_q_ - 1U;
 }
 
-static inline uint16_t FStar_UInt16_eq_mask(uint16_t a, uint16_t b)
+static KRML_NOINLINE uint16_t FStar_UInt16_eq_mask(uint16_t a, uint16_t b)
 {
-  uint16_t x = a ^ b;
-  uint16_t minus_x = ~x + (uint16_t)1U;
-  uint16_t x_or_minus_x = x | minus_x;
-  uint16_t xnx = x_or_minus_x >> (uint32_t)15U;
-  return xnx - (uint16_t)1U;
+  uint16_t x = (uint32_t)a ^ (uint32_t)b;
+  uint16_t minus_x = (uint32_t)~x + 1U;
+  uint16_t x_or_minus_x = (uint32_t)x | (uint32_t)minus_x;
+  uint16_t xnx = (uint32_t)x_or_minus_x >> 15U;
+  return (uint32_t)xnx - 1U;
 }
 
-static inline uint16_t FStar_UInt16_gte_mask(uint16_t a, uint16_t b)
+static KRML_NOINLINE uint16_t FStar_UInt16_gte_mask(uint16_t a, uint16_t b)
 {
   uint16_t x = a;
   uint16_t y = b;
-  uint16_t x_xor_y = x ^ y;
-  uint16_t x_sub_y = x - y;
-  uint16_t x_sub_y_xor_y = x_sub_y ^ y;
-  uint16_t q = x_xor_y | x_sub_y_xor_y;
-  uint16_t x_xor_q = x ^ q;
-  uint16_t x_xor_q_ = x_xor_q >> (uint32_t)15U;
-  return x_xor_q_ - (uint16_t)1U;
+  uint16_t x_xor_y = (uint32_t)x ^ (uint32_t)y;
+  uint16_t x_sub_y = (uint32_t)x - (uint32_t)y;
+  uint16_t x_sub_y_xor_y = (uint32_t)x_sub_y ^ (uint32_t)y;
+  uint16_t q = (uint32_t)x_xor_y | (uint32_t)x_sub_y_xor_y;
+  uint16_t x_xor_q = (uint32_t)x ^ (uint32_t)q;
+  uint16_t x_xor_q_ = (uint32_t)x_xor_q >> 15U;
+  return (uint32_t)x_xor_q_ - 1U;
 }
 
-static inline uint8_t FStar_UInt8_eq_mask(uint8_t a, uint8_t b)
+static KRML_NOINLINE uint8_t FStar_UInt8_eq_mask(uint8_t a, uint8_t b)
 {
-  uint8_t x = a ^ b;
-  uint8_t minus_x = ~x + (uint8_t)1U;
-  uint8_t x_or_minus_x = x | minus_x;
-  uint8_t xnx = x_or_minus_x >> (uint32_t)7U;
-  return xnx - (uint8_t)1U;
+  uint8_t x = (uint32_t)a ^ (uint32_t)b;
+  uint8_t minus_x = (uint32_t)~x + 1U;
+  uint8_t x_or_minus_x = (uint32_t)x | (uint32_t)minus_x;
+  uint8_t xnx = (uint32_t)x_or_minus_x >> 7U;
+  return (uint32_t)xnx - 1U;
 }
 
-static inline uint8_t FStar_UInt8_gte_mask(uint8_t a, uint8_t b)
+static KRML_NOINLINE uint8_t FStar_UInt8_gte_mask(uint8_t a, uint8_t b)
 {
   uint8_t x = a;
   uint8_t y = b;
-  uint8_t x_xor_y = x ^ y;
-  uint8_t x_sub_y = x - y;
-  uint8_t x_sub_y_xor_y = x_sub_y ^ y;
-  uint8_t q = x_xor_y | x_sub_y_xor_y;
-  uint8_t x_xor_q = x ^ q;
-  uint8_t x_xor_q_ = x_xor_q >> (uint32_t)7U;
-  return x_xor_q_ - (uint8_t)1U;
+  uint8_t x_xor_y = (uint32_t)x ^ (uint32_t)y;
+  uint8_t x_sub_y = (uint32_t)x - (uint32_t)y;
+  uint8_t x_sub_y_xor_y = (uint32_t)x_sub_y ^ (uint32_t)y;
+  uint8_t q = (uint32_t)x_xor_y | (uint32_t)x_sub_y_xor_y;
+  uint8_t x_xor_q = (uint32_t)x ^ (uint32_t)q;
+  uint8_t x_xor_q_ = (uint32_t)x_xor_q >> 7U;
+  return (uint32_t)x_xor_q_ - 1U;
 }
 
 
diff --git a/Modules/_hacl/include/krml/internal/target.h b/Modules/_hacl/include/krml/internal/target.h
index 5a2f94eb2e..c7fcc0151e 100644
--- a/Modules/_hacl/include/krml/internal/target.h
+++ b/Modules/_hacl/include/krml/internal/target.h
@@ -4,13 +4,13 @@
 #ifndef __KRML_TARGET_H
 #define __KRML_TARGET_H
 
-#include <stdlib.h>
-#include <stddef.h>
-#include <stdio.h>
-#include <stdbool.h>
+#include <assert.h>
 #include <inttypes.h>
 #include <limits.h>
-#include <assert.h>
+#include <stdbool.h>
+#include <stddef.h>
+#include <stdio.h>
+#include <stdlib.h>
 
 /* Since KaRaMeL emits the inline keyword unconditionally, we follow the
  * guidelines at https://gcc.gnu.org/onlinedocs/gcc/Inline.html and make this
@@ -57,6 +57,31 @@
 #  define KRML_HOST_IGNORE(x) (void)(x)
 #endif
 
+#ifndef KRML_MAYBE_UNUSED_VAR
+#  define KRML_MAYBE_UNUSED_VAR(x) KRML_HOST_IGNORE(x)
+#endif
+
+#ifndef KRML_MAYBE_UNUSED
+#  if defined(__GNUC__)
+#    define KRML_MAYBE_UNUSED __attribute__((unused))
+#  else
+#    define KRML_MAYBE_UNUSED
+#  endif
+#endif
+
+#ifndef KRML_NOINLINE
+#  if defined(_MSC_VER)
+#    define KRML_NOINLINE __declspec(noinline)
+#  elif defined (__GNUC__)
+#    define KRML_NOINLINE __attribute__((noinline,unused))
+#  else
+#    define KRML_NOINLINE
+#    warning "The KRML_NOINLINE macro is not defined for this toolchain!"
+#    warning "The compiler may defeat side-channel resistance with optimizations."
+#    warning "Please locate target.h and try to fill it out with a suitable definition for this compiler."
+#  endif
+#endif
+
 /* In FStar.Buffer.fst, the size of arrays is uint32_t, but it's a number of
  * *elements*. Do an ugly, run-time check (some of which KaRaMeL can eliminate).
  */
@@ -83,184 +108,186 @@
 #define KRML_LOOP1(i, n, x) { \
   x \
   i += n; \
+  (void) i; \
 }
 
-#define KRML_LOOP2(i, n, x) \
-  KRML_LOOP1(i, n, x) \
+#define KRML_LOOP2(i, n, x)                                                    \
+  KRML_LOOP1(i, n, x)                                                          \
   KRML_LOOP1(i, n, x)
 
-#define KRML_LOOP3(i, n, x) \
-  KRML_LOOP2(i, n, x) \
+#define KRML_LOOP3(i, n, x)                                                    \
+  KRML_LOOP2(i, n, x)                                                          \
   KRML_LOOP1(i, n, x)
 
-#define KRML_LOOP4(i, n, x) \
-  KRML_LOOP2(i, n, x) \
+#define KRML_LOOP4(i, n, x)                                                    \
+  KRML_LOOP2(i, n, x)                                                          \
   KRML_LOOP2(i, n, x)
 
-#define KRML_LOOP5(i, n, x) \
-  KRML_LOOP4(i, n, x) \
+#define KRML_LOOP5(i, n, x)                                                    \
+  KRML_LOOP4(i, n, x)                                                          \
   KRML_LOOP1(i, n, x)
 
-#define KRML_LOOP6(i, n, x) \
-  KRML_LOOP4(i, n, x) \
+#define KRML_LOOP6(i, n, x)                                                    \
+  KRML_LOOP4(i, n, x)                                                          \
   KRML_LOOP2(i, n, x)
 
-#define KRML_LOOP7(i, n, x) \
-  KRML_LOOP4(i, n, x) \
+#define KRML_LOOP7(i, n, x)                                                    \
+  KRML_LOOP4(i, n, x)                                                          \
   KRML_LOOP3(i, n, x)
 
-#define KRML_LOOP8(i, n, x) \
-  KRML_LOOP4(i, n, x) \
+#define KRML_LOOP8(i, n, x)                                                    \
+  KRML_LOOP4(i, n, x)                                                          \
   KRML_LOOP4(i, n, x)
 
-#define KRML_LOOP9(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP9(i, n, x)                                                    \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP1(i, n, x)
 
-#define KRML_LOOP10(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP10(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP2(i, n, x)
 
-#define KRML_LOOP11(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP11(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP3(i, n, x)
 
-#define KRML_LOOP12(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP12(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP4(i, n, x)
 
-#define KRML_LOOP13(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP13(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP5(i, n, x)
 
-#define KRML_LOOP14(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP14(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP6(i, n, x)
 
-#define KRML_LOOP15(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP15(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP7(i, n, x)
 
-#define KRML_LOOP16(i, n, x) \
-  KRML_LOOP8(i, n, x) \
+#define KRML_LOOP16(i, n, x)                                                   \
+  KRML_LOOP8(i, n, x)                                                          \
   KRML_LOOP8(i, n, x)
 
-#define KRML_UNROLL_FOR(i, z, n, k, x) do { \
-  uint32_t i = z; \
-  KRML_LOOP##n(i, k, x) \
-} while (0)
+#define KRML_UNROLL_FOR(i, z, n, k, x)                                         \
+  do {                                                                         \
+    uint32_t i = z;                                                            \
+    KRML_LOOP##n(i, k, x)                                                      \
+  } while (0)
 
-#define KRML_ACTUAL_FOR(i, z, n, k, x) \
-  do { \
-    for (uint32_t i = z; i < n; i += k) { \
-      x \
-    } \
+#define KRML_ACTUAL_FOR(i, z, n, k, x)                                         \
+  do {                                                                         \
+    for (uint32_t i = z; i < n; i += k) {                                      \
+      x                                                                        \
+    }                                                                          \
   } while (0)
 
 #ifndef KRML_UNROLL_MAX
-#define KRML_UNROLL_MAX 16
+#  define KRML_UNROLL_MAX 16
 #endif
 
 /* 1 is the number of loop iterations, i.e. (n - z)/k as evaluated by krml */
 #if 0 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR0(i, z, n, k, x)
+#  define KRML_MAYBE_FOR0(i, z, n, k, x)
 #else
-#define KRML_MAYBE_FOR0(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR0(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 1 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR1(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 1, k, x)
+#  define KRML_MAYBE_FOR1(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 1, k, x)
 #else
-#define KRML_MAYBE_FOR1(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR1(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 2 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR2(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 2, k, x)
+#  define KRML_MAYBE_FOR2(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 2, k, x)
 #else
-#define KRML_MAYBE_FOR2(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR2(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 3 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR3(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 3, k, x)
+#  define KRML_MAYBE_FOR3(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 3, k, x)
 #else
-#define KRML_MAYBE_FOR3(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR3(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 4 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR4(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 4, k, x)
+#  define KRML_MAYBE_FOR4(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 4, k, x)
 #else
-#define KRML_MAYBE_FOR4(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR4(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 5 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR5(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 5, k, x)
+#  define KRML_MAYBE_FOR5(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 5, k, x)
 #else
-#define KRML_MAYBE_FOR5(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR5(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 6 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR6(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 6, k, x)
+#  define KRML_MAYBE_FOR6(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 6, k, x)
 #else
-#define KRML_MAYBE_FOR6(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR6(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 7 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR7(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 7, k, x)
+#  define KRML_MAYBE_FOR7(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 7, k, x)
 #else
-#define KRML_MAYBE_FOR7(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR7(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 8 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR8(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 8, k, x)
+#  define KRML_MAYBE_FOR8(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 8, k, x)
 #else
-#define KRML_MAYBE_FOR8(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR8(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 9 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR9(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 9, k, x)
+#  define KRML_MAYBE_FOR9(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 9, k, x)
 #else
-#define KRML_MAYBE_FOR9(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR9(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 10 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR10(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 10, k, x)
+#  define KRML_MAYBE_FOR10(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 10, k, x)
 #else
-#define KRML_MAYBE_FOR10(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR10(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 11 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR11(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 11, k, x)
+#  define KRML_MAYBE_FOR11(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 11, k, x)
 #else
-#define KRML_MAYBE_FOR11(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR11(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 12 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR12(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 12, k, x)
+#  define KRML_MAYBE_FOR12(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 12, k, x)
 #else
-#define KRML_MAYBE_FOR12(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR12(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 13 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR13(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 13, k, x)
+#  define KRML_MAYBE_FOR13(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 13, k, x)
 #else
-#define KRML_MAYBE_FOR13(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR13(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 14 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR14(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 14, k, x)
+#  define KRML_MAYBE_FOR14(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 14, k, x)
 #else
-#define KRML_MAYBE_FOR14(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR14(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 15 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR15(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 15, k, x)
+#  define KRML_MAYBE_FOR15(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 15, k, x)
 #else
-#define KRML_MAYBE_FOR15(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR15(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 
 #if 16 <= KRML_UNROLL_MAX
-#define KRML_MAYBE_FOR16(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 16, k, x)
+#  define KRML_MAYBE_FOR16(i, z, n, k, x) KRML_UNROLL_FOR(i, z, 16, k, x)
 #else
-#define KRML_MAYBE_FOR16(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
+#  define KRML_MAYBE_FOR16(i, z, n, k, x) KRML_ACTUAL_FOR(i, z, n, k, x)
 #endif
 #endif
diff --git a/Modules/_hacl/internal/Hacl_Hash_MD5.h b/Modules/_hacl/internal/Hacl_Hash_MD5.h
index 87ad4cf228..a50ec407f5 100644
--- a/Modules/_hacl/internal/Hacl_Hash_MD5.h
+++ b/Modules/_hacl/internal/Hacl_Hash_MD5.h
@@ -37,21 +37,16 @@ extern "C" {
 
 #include "../Hacl_Hash_MD5.h"
 
-void Hacl_Hash_Core_MD5_legacy_init(uint32_t *s);
+void Hacl_Hash_MD5_init(uint32_t *s);
 
-void Hacl_Hash_Core_MD5_legacy_finish(uint32_t *s, uint8_t *dst);
+void Hacl_Hash_MD5_finish(uint32_t *s, uint8_t *dst);
 
-void Hacl_Hash_MD5_legacy_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks);
+void Hacl_Hash_MD5_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks);
 
 void
-Hacl_Hash_MD5_legacy_update_last(
-  uint32_t *s,
-  uint64_t prev_len,
-  uint8_t *input,
-  uint32_t input_len
-);
-
-void Hacl_Hash_MD5_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst);
+Hacl_Hash_MD5_update_last(uint32_t *s, uint64_t prev_len, uint8_t *input, uint32_t input_len);
+
+void Hacl_Hash_MD5_hash_oneshot(uint8_t *output, uint8_t *input, uint32_t input_len);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/internal/Hacl_Hash_SHA1.h b/Modules/_hacl/internal/Hacl_Hash_SHA1.h
index d2d9df44c6..b39bad3f3b 100644
--- a/Modules/_hacl/internal/Hacl_Hash_SHA1.h
+++ b/Modules/_hacl/internal/Hacl_Hash_SHA1.h
@@ -37,21 +37,16 @@ extern "C" {
 
 #include "../Hacl_Hash_SHA1.h"
 
-void Hacl_Hash_Core_SHA1_legacy_init(uint32_t *s);
+void Hacl_Hash_SHA1_init(uint32_t *s);
 
-void Hacl_Hash_Core_SHA1_legacy_finish(uint32_t *s, uint8_t *dst);
+void Hacl_Hash_SHA1_finish(uint32_t *s, uint8_t *dst);
 
-void Hacl_Hash_SHA1_legacy_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks);
+void Hacl_Hash_SHA1_update_multi(uint32_t *s, uint8_t *blocks, uint32_t n_blocks);
 
 void
-Hacl_Hash_SHA1_legacy_update_last(
-  uint32_t *s,
-  uint64_t prev_len,
-  uint8_t *input,
-  uint32_t input_len
-);
-
-void Hacl_Hash_SHA1_legacy_hash(uint8_t *input, uint32_t input_len, uint8_t *dst);
+Hacl_Hash_SHA1_update_last(uint32_t *s, uint64_t prev_len, uint8_t *input, uint32_t input_len);
+
+void Hacl_Hash_SHA1_hash_oneshot(uint8_t *output, uint8_t *input, uint32_t input_len);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/internal/Hacl_Hash_SHA2.h b/Modules/_hacl/internal/Hacl_Hash_SHA2.h
index 851f7dc60c..0127f4373f 100644
--- a/Modules/_hacl/internal/Hacl_Hash_SHA2.h
+++ b/Modules/_hacl/internal/Hacl_Hash_SHA2.h
@@ -40,141 +40,121 @@ extern "C" {
 
 static const
 uint32_t
-Hacl_Impl_SHA2_Generic_h224[8U] =
+Hacl_Hash_SHA2_h224[8U] =
   {
-    (uint32_t)0xc1059ed8U, (uint32_t)0x367cd507U, (uint32_t)0x3070dd17U, (uint32_t)0xf70e5939U,
-    (uint32_t)0xffc00b31U, (uint32_t)0x68581511U, (uint32_t)0x64f98fa7U, (uint32_t)0xbefa4fa4U
+    0xc1059ed8U, 0x367cd507U, 0x3070dd17U, 0xf70e5939U, 0xffc00b31U, 0x68581511U, 0x64f98fa7U,
+    0xbefa4fa4U
   };
 
 static const
 uint32_t
-Hacl_Impl_SHA2_Generic_h256[8U] =
+Hacl_Hash_SHA2_h256[8U] =
   {
-    (uint32_t)0x6a09e667U, (uint32_t)0xbb67ae85U, (uint32_t)0x3c6ef372U, (uint32_t)0xa54ff53aU,
-    (uint32_t)0x510e527fU, (uint32_t)0x9b05688cU, (uint32_t)0x1f83d9abU, (uint32_t)0x5be0cd19U
+    0x6a09e667U, 0xbb67ae85U, 0x3c6ef372U, 0xa54ff53aU, 0x510e527fU, 0x9b05688cU, 0x1f83d9abU,
+    0x5be0cd19U
   };
 
 static const
 uint64_t
-Hacl_Impl_SHA2_Generic_h384[8U] =
+Hacl_Hash_SHA2_h384[8U] =
   {
-    (uint64_t)0xcbbb9d5dc1059ed8U, (uint64_t)0x629a292a367cd507U, (uint64_t)0x9159015a3070dd17U,
-    (uint64_t)0x152fecd8f70e5939U, (uint64_t)0x67332667ffc00b31U, (uint64_t)0x8eb44a8768581511U,
-    (uint64_t)0xdb0c2e0d64f98fa7U, (uint64_t)0x47b5481dbefa4fa4U
+    0xcbbb9d5dc1059ed8ULL, 0x629a292a367cd507ULL, 0x9159015a3070dd17ULL, 0x152fecd8f70e5939ULL,
+    0x67332667ffc00b31ULL, 0x8eb44a8768581511ULL, 0xdb0c2e0d64f98fa7ULL, 0x47b5481dbefa4fa4ULL
   };
 
 static const
 uint64_t
-Hacl_Impl_SHA2_Generic_h512[8U] =
+Hacl_Hash_SHA2_h512[8U] =
   {
-    (uint64_t)0x6a09e667f3bcc908U, (uint64_t)0xbb67ae8584caa73bU, (uint64_t)0x3c6ef372fe94f82bU,
-    (uint64_t)0xa54ff53a5f1d36f1U, (uint64_t)0x510e527fade682d1U, (uint64_t)0x9b05688c2b3e6c1fU,
-    (uint64_t)0x1f83d9abfb41bd6bU, (uint64_t)0x5be0cd19137e2179U
+    0x6a09e667f3bcc908ULL, 0xbb67ae8584caa73bULL, 0x3c6ef372fe94f82bULL, 0xa54ff53a5f1d36f1ULL,
+    0x510e527fade682d1ULL, 0x9b05688c2b3e6c1fULL, 0x1f83d9abfb41bd6bULL, 0x5be0cd19137e2179ULL
   };
 
 static const
 uint32_t
-Hacl_Impl_SHA2_Generic_k224_256[64U] =
+Hacl_Hash_SHA2_k224_256[64U] =
   {
-    (uint32_t)0x428a2f98U, (uint32_t)0x71374491U, (uint32_t)0xb5c0fbcfU, (uint32_t)0xe9b5dba5U,
-    (uint32_t)0x3956c25bU, (uint32_t)0x59f111f1U, (uint32_t)0x923f82a4U, (uint32_t)0xab1c5ed5U,
-    (uint32_t)0xd807aa98U, (uint32_t)0x12835b01U, (uint32_t)0x243185beU, (uint32_t)0x550c7dc3U,
-    (uint32_t)0x72be5d74U, (uint32_t)0x80deb1feU, (uint32_t)0x9bdc06a7U, (uint32_t)0xc19bf174U,
-    (uint32_t)0xe49b69c1U, (uint32_t)0xefbe4786U, (uint32_t)0x0fc19dc6U, (uint32_t)0x240ca1ccU,
-    (uint32_t)0x2de92c6fU, (uint32_t)0x4a7484aaU, (uint32_t)0x5cb0a9dcU, (uint32_t)0x76f988daU,
-    (uint32_t)0x983e5152U, (uint32_t)0xa831c66dU, (uint32_t)0xb00327c8U, (uint32_t)0xbf597fc7U,
-    (uint32_t)0xc6e00bf3U, (uint32_t)0xd5a79147U, (uint32_t)0x06ca6351U, (uint32_t)0x14292967U,
-    (uint32_t)0x27b70a85U, (uint32_t)0x2e1b2138U, (uint32_t)0x4d2c6dfcU, (uint32_t)0x53380d13U,
-    (uint32_t)0x650a7354U, (uint32_t)0x766a0abbU, (uint32_t)0x81c2c92eU, (uint32_t)0x92722c85U,
-    (uint32_t)0xa2bfe8a1U, (uint32_t)0xa81a664bU, (uint32_t)0xc24b8b70U, (uint32_t)0xc76c51a3U,
-    (uint32_t)0xd192e819U, (uint32_t)0xd6990624U, (uint32_t)0xf40e3585U, (uint32_t)0x106aa070U,
-    (uint32_t)0x19a4c116U, (uint32_t)0x1e376c08U, (uint32_t)0x2748774cU, (uint32_t)0x34b0bcb5U,
-    (uint32_t)0x391c0cb3U, (uint32_t)0x4ed8aa4aU, (uint32_t)0x5b9cca4fU, (uint32_t)0x682e6ff3U,
-    (uint32_t)0x748f82eeU, (uint32_t)0x78a5636fU, (uint32_t)0x84c87814U, (uint32_t)0x8cc70208U,
-    (uint32_t)0x90befffaU, (uint32_t)0xa4506cebU, (uint32_t)0xbef9a3f7U, (uint32_t)0xc67178f2U
+    0x428a2f98U, 0x71374491U, 0xb5c0fbcfU, 0xe9b5dba5U, 0x3956c25bU, 0x59f111f1U, 0x923f82a4U,
+    0xab1c5ed5U, 0xd807aa98U, 0x12835b01U, 0x243185beU, 0x550c7dc3U, 0x72be5d74U, 0x80deb1feU,
+    0x9bdc06a7U, 0xc19bf174U, 0xe49b69c1U, 0xefbe4786U, 0x0fc19dc6U, 0x240ca1ccU, 0x2de92c6fU,
+    0x4a7484aaU, 0x5cb0a9dcU, 0x76f988daU, 0x983e5152U, 0xa831c66dU, 0xb00327c8U, 0xbf597fc7U,
+    0xc6e00bf3U, 0xd5a79147U, 0x06ca6351U, 0x14292967U, 0x27b70a85U, 0x2e1b2138U, 0x4d2c6dfcU,
+    0x53380d13U, 0x650a7354U, 0x766a0abbU, 0x81c2c92eU, 0x92722c85U, 0xa2bfe8a1U, 0xa81a664bU,
+    0xc24b8b70U, 0xc76c51a3U, 0xd192e819U, 0xd6990624U, 0xf40e3585U, 0x106aa070U, 0x19a4c116U,
+    0x1e376c08U, 0x2748774cU, 0x34b0bcb5U, 0x391c0cb3U, 0x4ed8aa4aU, 0x5b9cca4fU, 0x682e6ff3U,
+    0x748f82eeU, 0x78a5636fU, 0x84c87814U, 0x8cc70208U, 0x90befffaU, 0xa4506cebU, 0xbef9a3f7U,
+    0xc67178f2U
   };
 
 static const
 uint64_t
-Hacl_Impl_SHA2_Generic_k384_512[80U] =
+Hacl_Hash_SHA2_k384_512[80U] =
   {
-    (uint64_t)0x428a2f98d728ae22U, (uint64_t)0x7137449123ef65cdU, (uint64_t)0xb5c0fbcfec4d3b2fU,
-    (uint64_t)0xe9b5dba58189dbbcU, (uint64_t)0x3956c25bf348b538U, (uint64_t)0x59f111f1b605d019U,
-    (uint64_t)0x923f82a4af194f9bU, (uint64_t)0xab1c5ed5da6d8118U, (uint64_t)0xd807aa98a3030242U,
-    (uint64_t)0x12835b0145706fbeU, (uint64_t)0x243185be4ee4b28cU, (uint64_t)0x550c7dc3d5ffb4e2U,
-    (uint64_t)0x72be5d74f27b896fU, (uint64_t)0x80deb1fe3b1696b1U, (uint64_t)0x9bdc06a725c71235U,
-    (uint64_t)0xc19bf174cf692694U, (uint64_t)0xe49b69c19ef14ad2U, (uint64_t)0xefbe4786384f25e3U,
-    (uint64_t)0x0fc19dc68b8cd5b5U, (uint64_t)0x240ca1cc77ac9c65U, (uint64_t)0x2de92c6f592b0275U,
-    (uint64_t)0x4a7484aa6ea6e483U, (uint64_t)0x5cb0a9dcbd41fbd4U, (uint64_t)0x76f988da831153b5U,
-    (uint64_t)0x983e5152ee66dfabU, (uint64_t)0xa831c66d2db43210U, (uint64_t)0xb00327c898fb213fU,
-    (uint64_t)0xbf597fc7beef0ee4U, (uint64_t)0xc6e00bf33da88fc2U, (uint64_t)0xd5a79147930aa725U,
-    (uint64_t)0x06ca6351e003826fU, (uint64_t)0x142929670a0e6e70U, (uint64_t)0x27b70a8546d22ffcU,
-    (uint64_t)0x2e1b21385c26c926U, (uint64_t)0x4d2c6dfc5ac42aedU, (uint64_t)0x53380d139d95b3dfU,
-    (uint64_t)0x650a73548baf63deU, (uint64_t)0x766a0abb3c77b2a8U, (uint64_t)0x81c2c92e47edaee6U,
-    (uint64_t)0x92722c851482353bU, (uint64_t)0xa2bfe8a14cf10364U, (uint64_t)0xa81a664bbc423001U,
-    (uint64_t)0xc24b8b70d0f89791U, (uint64_t)0xc76c51a30654be30U, (uint64_t)0xd192e819d6ef5218U,
-    (uint64_t)0xd69906245565a910U, (uint64_t)0xf40e35855771202aU, (uint64_t)0x106aa07032bbd1b8U,
-    (uint64_t)0x19a4c116b8d2d0c8U, (uint64_t)0x1e376c085141ab53U, (uint64_t)0x2748774cdf8eeb99U,
-    (uint64_t)0x34b0bcb5e19b48a8U, (uint64_t)0x391c0cb3c5c95a63U, (uint64_t)0x4ed8aa4ae3418acbU,
-    (uint64_t)0x5b9cca4f7763e373U, (uint64_t)0x682e6ff3d6b2b8a3U, (uint64_t)0x748f82ee5defb2fcU,
-    (uint64_t)0x78a5636f43172f60U, (uint64_t)0x84c87814a1f0ab72U, (uint64_t)0x8cc702081a6439ecU,
-    (uint64_t)0x90befffa23631e28U, (uint64_t)0xa4506cebde82bde9U, (uint64_t)0xbef9a3f7b2c67915U,
-    (uint64_t)0xc67178f2e372532bU, (uint64_t)0xca273eceea26619cU, (uint64_t)0xd186b8c721c0c207U,
-    (uint64_t)0xeada7dd6cde0eb1eU, (uint64_t)0xf57d4f7fee6ed178U, (uint64_t)0x06f067aa72176fbaU,
-    (uint64_t)0x0a637dc5a2c898a6U, (uint64_t)0x113f9804bef90daeU, (uint64_t)0x1b710b35131c471bU,
-    (uint64_t)0x28db77f523047d84U, (uint64_t)0x32caab7b40c72493U, (uint64_t)0x3c9ebe0a15c9bebcU,
-    (uint64_t)0x431d67c49c100d4cU, (uint64_t)0x4cc5d4becb3e42b6U, (uint64_t)0x597f299cfc657e2aU,
-    (uint64_t)0x5fcb6fab3ad6faecU, (uint64_t)0x6c44198c4a475817U
+    0x428a2f98d728ae22ULL, 0x7137449123ef65cdULL, 0xb5c0fbcfec4d3b2fULL, 0xe9b5dba58189dbbcULL,
+    0x3956c25bf348b538ULL, 0x59f111f1b605d019ULL, 0x923f82a4af194f9bULL, 0xab1c5ed5da6d8118ULL,
+    0xd807aa98a3030242ULL, 0x12835b0145706fbeULL, 0x243185be4ee4b28cULL, 0x550c7dc3d5ffb4e2ULL,
+    0x72be5d74f27b896fULL, 0x80deb1fe3b1696b1ULL, 0x9bdc06a725c71235ULL, 0xc19bf174cf692694ULL,
+    0xe49b69c19ef14ad2ULL, 0xefbe4786384f25e3ULL, 0x0fc19dc68b8cd5b5ULL, 0x240ca1cc77ac9c65ULL,
+    0x2de92c6f592b0275ULL, 0x4a7484aa6ea6e483ULL, 0x5cb0a9dcbd41fbd4ULL, 0x76f988da831153b5ULL,
+    0x983e5152ee66dfabULL, 0xa831c66d2db43210ULL, 0xb00327c898fb213fULL, 0xbf597fc7beef0ee4ULL,
+    0xc6e00bf33da88fc2ULL, 0xd5a79147930aa725ULL, 0x06ca6351e003826fULL, 0x142929670a0e6e70ULL,
+    0x27b70a8546d22ffcULL, 0x2e1b21385c26c926ULL, 0x4d2c6dfc5ac42aedULL, 0x53380d139d95b3dfULL,
+    0x650a73548baf63deULL, 0x766a0abb3c77b2a8ULL, 0x81c2c92e47edaee6ULL, 0x92722c851482353bULL,
+    0xa2bfe8a14cf10364ULL, 0xa81a664bbc423001ULL, 0xc24b8b70d0f89791ULL, 0xc76c51a30654be30ULL,
+    0xd192e819d6ef5218ULL, 0xd69906245565a910ULL, 0xf40e35855771202aULL, 0x106aa07032bbd1b8ULL,
+    0x19a4c116b8d2d0c8ULL, 0x1e376c085141ab53ULL, 0x2748774cdf8eeb99ULL, 0x34b0bcb5e19b48a8ULL,
+    0x391c0cb3c5c95a63ULL, 0x4ed8aa4ae3418acbULL, 0x5b9cca4f7763e373ULL, 0x682e6ff3d6b2b8a3ULL,
+    0x748f82ee5defb2fcULL, 0x78a5636f43172f60ULL, 0x84c87814a1f0ab72ULL, 0x8cc702081a6439ecULL,
+    0x90befffa23631e28ULL, 0xa4506cebde82bde9ULL, 0xbef9a3f7b2c67915ULL, 0xc67178f2e372532bULL,
+    0xca273eceea26619cULL, 0xd186b8c721c0c207ULL, 0xeada7dd6cde0eb1eULL, 0xf57d4f7fee6ed178ULL,
+    0x06f067aa72176fbaULL, 0x0a637dc5a2c898a6ULL, 0x113f9804bef90daeULL, 0x1b710b35131c471bULL,
+    0x28db77f523047d84ULL, 0x32caab7b40c72493ULL, 0x3c9ebe0a15c9bebcULL, 0x431d67c49c100d4cULL,
+    0x4cc5d4becb3e42b6ULL, 0x597f299cfc657e2aULL, 0x5fcb6fab3ad6faecULL, 0x6c44198c4a475817ULL
   };
 
-void Hacl_SHA2_Scalar32_sha256_init(uint32_t *hash);
+void Hacl_Hash_SHA2_sha256_init(uint32_t *hash);
 
-void Hacl_SHA2_Scalar32_sha256_update_nblocks(uint32_t len, uint8_t *b, uint32_t *st);
+void Hacl_Hash_SHA2_sha256_update_nblocks(uint32_t len, uint8_t *b, uint32_t *st);
 
 void
-Hacl_SHA2_Scalar32_sha256_update_last(
-  uint64_t totlen,
-  uint32_t len,
-  uint8_t *b,
-  uint32_t *hash
-);
+Hacl_Hash_SHA2_sha256_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *hash);
 
-void Hacl_SHA2_Scalar32_sha256_finish(uint32_t *st, uint8_t *h);
+void Hacl_Hash_SHA2_sha256_finish(uint32_t *st, uint8_t *h);
 
-void Hacl_SHA2_Scalar32_sha224_init(uint32_t *hash);
+void Hacl_Hash_SHA2_sha224_init(uint32_t *hash);
 
 void
-Hacl_SHA2_Scalar32_sha224_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *st);
+Hacl_Hash_SHA2_sha224_update_last(uint64_t totlen, uint32_t len, uint8_t *b, uint32_t *st);
 
-void Hacl_SHA2_Scalar32_sha224_finish(uint32_t *st, uint8_t *h);
+void Hacl_Hash_SHA2_sha224_finish(uint32_t *st, uint8_t *h);
 
-void Hacl_SHA2_Scalar32_sha512_init(uint64_t *hash);
+void Hacl_Hash_SHA2_sha512_init(uint64_t *hash);
 
-void Hacl_SHA2_Scalar32_sha512_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st);
+void Hacl_Hash_SHA2_sha512_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st);
 
 void
-Hacl_SHA2_Scalar32_sha512_update_last(
+Hacl_Hash_SHA2_sha512_update_last(
   FStar_UInt128_uint128 totlen,
   uint32_t len,
   uint8_t *b,
   uint64_t *hash
 );
 
-void Hacl_SHA2_Scalar32_sha512_finish(uint64_t *st, uint8_t *h);
+void Hacl_Hash_SHA2_sha512_finish(uint64_t *st, uint8_t *h);
 
-void Hacl_SHA2_Scalar32_sha384_init(uint64_t *hash);
+void Hacl_Hash_SHA2_sha384_init(uint64_t *hash);
 
-void Hacl_SHA2_Scalar32_sha384_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st);
+void Hacl_Hash_SHA2_sha384_update_nblocks(uint32_t len, uint8_t *b, uint64_t *st);
 
 void
-Hacl_SHA2_Scalar32_sha384_update_last(
+Hacl_Hash_SHA2_sha384_update_last(
   FStar_UInt128_uint128 totlen,
   uint32_t len,
   uint8_t *b,
   uint64_t *st
 );
 
-void Hacl_SHA2_Scalar32_sha384_finish(uint64_t *st, uint8_t *h);
+void Hacl_Hash_SHA2_sha384_finish(uint64_t *st, uint8_t *h);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/internal/Hacl_Hash_SHA3.h b/Modules/_hacl/internal/Hacl_Hash_SHA3.h
index 1c9808b8dd..b80e81fafb 100644
--- a/Modules/_hacl/internal/Hacl_Hash_SHA3.h
+++ b/Modules/_hacl/internal/Hacl_Hash_SHA3.h
@@ -53,9 +53,9 @@ Hacl_Hash_SHA3_update_last_sha3(
   uint32_t input_len
 );
 
-void Hacl_Impl_SHA3_state_permute(uint64_t *s);
+void Hacl_Hash_SHA3_state_permute(uint64_t *s);
 
-void Hacl_Impl_SHA3_loadState(uint32_t rateInBytes, uint8_t *input, uint64_t *s);
+void Hacl_Hash_SHA3_loadState(uint32_t rateInBytes, uint8_t *input, uint64_t *s);
 
 #if defined(__cplusplus)
 }
diff --git a/Modules/_hacl/python_hacl_namespaces.h b/Modules/_hacl/python_hacl_namespaces.h
index 0df236282a..684e7fd2fb 100644
--- a/Modules/_hacl/python_hacl_namespaces.h
+++ b/Modules/_hacl/python_hacl_namespaces.h
@@ -5,59 +5,61 @@
  * C's excuse for namespaces: Use globally unique names to avoid linkage
  * conflicts with builds linking or dynamically loading other code potentially
  * using HACL* libraries.
+ *
+ * To make sure this is effective: cd Modules && nm -a *.o | grep Hacl
  */
 
-#define Hacl_Streaming_SHA2_state_sha2_224_s python_hashlib_Hacl_Streaming_SHA2_state_sha2_224_s
-#define Hacl_Streaming_SHA2_state_sha2_224 python_hashlib_Hacl_Streaming_SHA2_state_sha2_224
-#define Hacl_Streaming_SHA2_state_sha2_256 python_hashlib_Hacl_Streaming_SHA2_state_sha2_256
-#define Hacl_Streaming_SHA2_state_sha2_384_s python_hashlib_Hacl_Streaming_SHA2_state_sha2_384_s
-#define Hacl_Streaming_SHA2_state_sha2_384 python_hashlib_Hacl_Streaming_SHA2_state_sha2_384
-#define Hacl_Streaming_SHA2_state_sha2_512 python_hashlib_Hacl_Streaming_SHA2_state_sha2_512
-#define Hacl_Streaming_SHA2_create_in_256 python_hashlib_Hacl_Streaming_SHA2_create_in_256
-#define Hacl_Streaming_SHA2_create_in_224 python_hashlib_Hacl_Streaming_SHA2_create_in_224
-#define Hacl_Streaming_SHA2_create_in_512 python_hashlib_Hacl_Streaming_SHA2_create_in_512
-#define Hacl_Streaming_SHA2_create_in_384 python_hashlib_Hacl_Streaming_SHA2_create_in_384
-#define Hacl_Streaming_SHA2_copy_256 python_hashlib_Hacl_Streaming_SHA2_copy_256
-#define Hacl_Streaming_SHA2_copy_224 python_hashlib_Hacl_Streaming_SHA2_copy_224
-#define Hacl_Streaming_SHA2_copy_512 python_hashlib_Hacl_Streaming_SHA2_copy_512
-#define Hacl_Streaming_SHA2_copy_384 python_hashlib_Hacl_Streaming_SHA2_copy_384
-#define Hacl_Streaming_SHA2_init_256 python_hashlib_Hacl_Streaming_SHA2_init_256
-#define Hacl_Streaming_SHA2_init_224 python_hashlib_Hacl_Streaming_SHA2_init_224
-#define Hacl_Streaming_SHA2_init_512 python_hashlib_Hacl_Streaming_SHA2_init_512
-#define Hacl_Streaming_SHA2_init_384 python_hashlib_Hacl_Streaming_SHA2_init_384
+#define Hacl_Hash_SHA2_state_sha2_224_s python_hashlib_Hacl_Hash_SHA2_state_sha2_224_s
+#define Hacl_Hash_SHA2_state_sha2_224 python_hashlib_Hacl_Hash_SHA2_state_sha2_224
+#define Hacl_Hash_SHA2_state_sha2_256 python_hashlib_Hacl_Hash_SHA2_state_sha2_256
+#define Hacl_Hash_SHA2_state_sha2_384_s python_hashlib_Hacl_Hash_SHA2_state_sha2_384_s
+#define Hacl_Hash_SHA2_state_sha2_384 python_hashlib_Hacl_Hash_SHA2_state_sha2_384
+#define Hacl_Hash_SHA2_state_sha2_512 python_hashlib_Hacl_Hash_SHA2_state_sha2_512
+#define Hacl_Hash_SHA2_malloc_256 python_hashlib_Hacl_Hash_SHA2_malloc_256
+#define Hacl_Hash_SHA2_malloc_224 python_hashlib_Hacl_Hash_SHA2_malloc_224
+#define Hacl_Hash_SHA2_malloc_512 python_hashlib_Hacl_Hash_SHA2_malloc_512
+#define Hacl_Hash_SHA2_malloc_384 python_hashlib_Hacl_Hash_SHA2_malloc_384
+#define Hacl_Hash_SHA2_copy_256 python_hashlib_Hacl_Hash_SHA2_copy_256
+#define Hacl_Hash_SHA2_copy_224 python_hashlib_Hacl_Hash_SHA2_copy_224
+#define Hacl_Hash_SHA2_copy_512 python_hashlib_Hacl_Hash_SHA2_copy_512
+#define Hacl_Hash_SHA2_copy_384 python_hashlib_Hacl_Hash_SHA2_copy_384
+#define Hacl_Hash_SHA2_init_256 python_hashlib_Hacl_Hash_SHA2_init_256
+#define Hacl_Hash_SHA2_init_224 python_hashlib_Hacl_Hash_SHA2_init_224
+#define Hacl_Hash_SHA2_init_512 python_hashlib_Hacl_Hash_SHA2_init_512
+#define Hacl_Hash_SHA2_init_384 python_hashlib_Hacl_Hash_SHA2_init_384
 #define Hacl_SHA2_Scalar32_sha512_init python_hashlib_Hacl_SHA2_Scalar32_sha512_init
-#define Hacl_Streaming_SHA2_update_256 python_hashlib_Hacl_Streaming_SHA2_update_256
-#define Hacl_Streaming_SHA2_update_224 python_hashlib_Hacl_Streaming_SHA2_update_224
-#define Hacl_Streaming_SHA2_update_512 python_hashlib_Hacl_Streaming_SHA2_update_512
-#define Hacl_Streaming_SHA2_update_384 python_hashlib_Hacl_Streaming_SHA2_update_384
-#define Hacl_Streaming_SHA2_finish_256 python_hashlib_Hacl_Streaming_SHA2_finish_256
-#define Hacl_Streaming_SHA2_finish_224 python_hashlib_Hacl_Streaming_SHA2_finish_224
-#define Hacl_Streaming_SHA2_finish_512 python_hashlib_Hacl_Streaming_SHA2_finish_512
-#define Hacl_Streaming_SHA2_finish_384 python_hashlib_Hacl_Streaming_SHA2_finish_384
-#define Hacl_Streaming_SHA2_free_256 python_hashlib_Hacl_Streaming_SHA2_free_256
-#define Hacl_Streaming_SHA2_free_224 python_hashlib_Hacl_Streaming_SHA2_free_224
-#define Hacl_Streaming_SHA2_free_512 python_hashlib_Hacl_Streaming_SHA2_free_512
-#define Hacl_Streaming_SHA2_free_384 python_hashlib_Hacl_Streaming_SHA2_free_384
-#define Hacl_Streaming_SHA2_sha256 python_hashlib_Hacl_Streaming_SHA2_sha256
-#define Hacl_Streaming_SHA2_sha224 python_hashlib_Hacl_Streaming_SHA2_sha224
-#define Hacl_Streaming_SHA2_sha512 python_hashlib_Hacl_Streaming_SHA2_sha512
-#define Hacl_Streaming_SHA2_sha384 python_hashlib_Hacl_Streaming_SHA2_sha384
+#define Hacl_Hash_SHA2_update_256 python_hashlib_Hacl_Hash_SHA2_update_256
+#define Hacl_Hash_SHA2_update_224 python_hashlib_Hacl_Hash_SHA2_update_224
+#define Hacl_Hash_SHA2_update_512 python_hashlib_Hacl_Hash_SHA2_update_512
+#define Hacl_Hash_SHA2_update_384 python_hashlib_Hacl_Hash_SHA2_update_384
+#define Hacl_Hash_SHA2_digest_256 python_hashlib_Hacl_Hash_SHA2_digest_256
+#define Hacl_Hash_SHA2_digest_224 python_hashlib_Hacl_Hash_SHA2_digest_224
+#define Hacl_Hash_SHA2_digest_512 python_hashlib_Hacl_Hash_SHA2_digest_512
+#define Hacl_Hash_SHA2_digest_384 python_hashlib_Hacl_Hash_SHA2_digest_384
+#define Hacl_Hash_SHA2_free_256 python_hashlib_Hacl_Hash_SHA2_free_256
+#define Hacl_Hash_SHA2_free_224 python_hashlib_Hacl_Hash_SHA2_free_224
+#define Hacl_Hash_SHA2_free_512 python_hashlib_Hacl_Hash_SHA2_free_512
+#define Hacl_Hash_SHA2_free_384 python_hashlib_Hacl_Hash_SHA2_free_384
+#define Hacl_Hash_SHA2_sha256 python_hashlib_Hacl_Hash_SHA2_sha256
+#define Hacl_Hash_SHA2_sha224 python_hashlib_Hacl_Hash_SHA2_sha224
+#define Hacl_Hash_SHA2_sha512 python_hashlib_Hacl_Hash_SHA2_sha512
+#define Hacl_Hash_SHA2_sha384 python_hashlib_Hacl_Hash_SHA2_sha384
 
-#define Hacl_Streaming_MD5_legacy_create_in python_hashlib_Hacl_Streaming_MD5_legacy_create_in
-#define Hacl_Streaming_MD5_legacy_init python_hashlib_Hacl_Streaming_MD5_legacy_init
-#define Hacl_Streaming_MD5_legacy_update python_hashlib_Hacl_Streaming_MD5_legacy_update
-#define Hacl_Streaming_MD5_legacy_finish python_hashlib_Hacl_Streaming_MD5_legacy_finish
-#define Hacl_Streaming_MD5_legacy_free python_hashlib_Hacl_Streaming_MD5_legacy_free
-#define Hacl_Streaming_MD5_legacy_copy python_hashlib_Hacl_Streaming_MD5_legacy_copy
-#define Hacl_Streaming_MD5_legacy_hash python_hashlib_Hacl_Streaming_MD5_legacy_hash
+#define Hacl_Hash_MD5_malloc python_hashlib_Hacl_Hash_MD5_malloc
+#define Hacl_Hash_MD5_init python_hashlib_Hacl_Hash_MD5_init
+#define Hacl_Hash_MD5_update python_hashlib_Hacl_Hash_MD5_update
+#define Hacl_Hash_MD5_digest python_hashlib_Hacl_Hash_MD5_digest
+#define Hacl_Hash_MD5_free python_hashlib_Hacl_Hash_MD5_free
+#define Hacl_Hash_MD5_copy python_hashlib_Hacl_Hash_MD5_copy
+#define Hacl_Hash_MD5_hash python_hashlib_Hacl_Hash_MD5_hash
 
-#define Hacl_Streaming_SHA1_legacy_create_in python_hashlib_Hacl_Streaming_SHA1_legacy_create_in
-#define Hacl_Streaming_SHA1_legacy_init python_hashlib_Hacl_Streaming_SHA1_legacy_init
-#define Hacl_Streaming_SHA1_legacy_update python_hashlib_Hacl_Streaming_SHA1_legacy_update
-#define Hacl_Streaming_SHA1_legacy_finish python_hashlib_Hacl_Streaming_SHA1_legacy_finish
-#define Hacl_Streaming_SHA1_legacy_free python_hashlib_Hacl_Streaming_SHA1_legacy_free
-#define Hacl_Streaming_SHA1_legacy_copy python_hashlib_Hacl_Streaming_SHA1_legacy_copy
-#define Hacl_Streaming_SHA1_legacy_hash python_hashlib_Hacl_Streaming_SHA1_legacy_hash
+#define Hacl_Hash_SHA1_malloc python_hashlib_Hacl_Hash_SHA1_malloc
+#define Hacl_Hash_SHA1_init python_hashlib_Hacl_Hash_SHA1_init
+#define Hacl_Hash_SHA1_update python_hashlib_Hacl_Hash_SHA1_update
+#define Hacl_Hash_SHA1_digest python_hashlib_Hacl_Hash_SHA1_digest
+#define Hacl_Hash_SHA1_free python_hashlib_Hacl_Hash_SHA1_free
+#define Hacl_Hash_SHA1_copy python_hashlib_Hacl_Hash_SHA1_copy
+#define Hacl_Hash_SHA1_hash python_hashlib_Hacl_Hash_SHA1_hash
 
 #define Hacl_Hash_SHA3_update_last_sha3 python_hashlib_Hacl_Hash_SHA3_update_last_sha3
 #define Hacl_Hash_SHA3_update_multi_sha3 python_hashlib_Hacl_Hash_SHA3_update_multi_sha3
@@ -72,15 +74,16 @@
 #define Hacl_SHA3_sha3_512 python_hashlib_Hacl_SHA3_sha3_512
 #define Hacl_SHA3_shake128_hacl python_hashlib_Hacl_SHA3_shake128_hacl
 #define Hacl_SHA3_shake256_hacl python_hashlib_Hacl_SHA3_shake256_hacl
-#define Hacl_Streaming_Keccak_block_len python_hashlib_Hacl_Streaming_Keccak_block_len
-#define Hacl_Streaming_Keccak_copy python_hashlib_Hacl_Streaming_Keccak_copy
-#define Hacl_Streaming_Keccak_finish python_hashlib_Hacl_Streaming_Keccak_finish
-#define Hacl_Streaming_Keccak_free python_hashlib_Hacl_Streaming_Keccak_free
-#define Hacl_Streaming_Keccak_get_alg python_hashlib_Hacl_Streaming_Keccak_get_alg
-#define Hacl_Streaming_Keccak_hash_len python_hashlib_Hacl_Streaming_Keccak_hash_len
-#define Hacl_Streaming_Keccak_is_shake python_hashlib_Hacl_Streaming_Keccak_is_shake
-#define Hacl_Streaming_Keccak_malloc python_hashlib_Hacl_Streaming_Keccak_malloc
-#define Hacl_Streaming_Keccak_reset python_hashlib_Hacl_Streaming_Keccak_reset
-#define Hacl_Streaming_Keccak_update python_hashlib_Hacl_Streaming_Keccak_update
+#define Hacl_Hash_SHA3_block_len python_hashlib_Hacl_Hash_SHA3_block_len
+#define Hacl_Hash_SHA3_copy python_hashlib_Hacl_Hash_SHA3_copy
+#define Hacl_Hash_SHA3_digest python_hashlib_Hacl_Hash_SHA3_digest
+#define Hacl_Hash_SHA3_free python_hashlib_Hacl_Hash_SHA3_free
+#define Hacl_Hash_SHA3_get_alg python_hashlib_Hacl_Hash_SHA3_get_alg
+#define Hacl_Hash_SHA3_hash_len python_hashlib_Hacl_Hash_SHA3_hash_len
+#define Hacl_Hash_SHA3_is_shake python_hashlib_Hacl_Hash_SHA3_is_shake
+#define Hacl_Hash_SHA3_malloc python_hashlib_Hacl_Hash_SHA3_malloc
+#define Hacl_Hash_SHA3_reset python_hashlib_Hacl_Hash_SHA3_reset
+#define Hacl_Hash_SHA3_update python_hashlib_Hacl_Hash_SHA3_update
+#define Hacl_Hash_SHA3_squeeze python_hashlib_Hacl_Hash_SHA3_squeeze
 
 #endif  // _PYTHON_HACL_NAMESPACES_H
diff --git a/Modules/_hacl/refresh.sh b/Modules/_hacl/refresh.sh
index c1b3e37f3a..3878e02af3 100755
--- a/Modules/_hacl/refresh.sh
+++ b/Modules/_hacl/refresh.sh
@@ -22,7 +22,7 @@ fi
 
 # Update this when updating to a new version after verifying that the changes
 # the update brings in are good.
-expected_hacl_star_rev=521af282fdf6d60227335120f18ae9309a4b8e8c
+expected_hacl_star_rev=bb3d0dc8d9d15a5cd51094d5b69e70aa09005ff0
 
 hacl_dir="$(realpath "$1")"
 cd "$(dirname "$0")"
@@ -127,7 +127,7 @@ $sed -i -z 's!\(extern\|typedef\)[^;]*;\n\n!!g' include/krml/FStar_UInt_8_16_32_
 $sed -i 's!#include.*Hacl_Krmllib.h"!!g' "${all_files[@]}"
 
 # Use globally unique names for the Hacl_ C APIs to avoid linkage conflicts.
-$sed -i -z 's!#include <string.h>\n!#include <string.h>\n#include "python_hacl_namespaces.h"\n!' Hacl_Hash_SHA2.h
+$sed -i -z 's!#include <string.h>\n!#include <string.h>\n#include "python_hacl_namespaces.h"\n!' Hacl_Hash_*.h
 
 # Finally, we remove a bunch of ifdefs from target.h that are, again, useful in
 # the general case, but not exercised by the subset of HACL* that we vendor.
diff --git a/Modules/_io/bufferedio.c b/Modules/_io/bufferedio.c
index f30d54a5e1..e87d04bd07 100644
--- a/Modules/_io/bufferedio.c
+++ b/Modules/_io/bufferedio.c
@@ -1015,6 +1015,16 @@ _io__Buffered_read1_impl(buffered *self, Py_ssize_t n)
         Py_DECREF(res);
         return NULL;
     }
+    /* Flush the write buffer if necessary */
+    if (self->writable) {
+        PyObject *r = buffered_flush_and_rewind_unlocked(self);
+        if (r == NULL) {
+            LEAVE_BUFFERED(self)
+            Py_DECREF(res);
+            return NULL;
+        }
+        Py_DECREF(r);
+    }
     _bufferedreader_reset_buf(self);
     r = _bufferedreader_raw_read(self, PyBytes_AS_STRING(res), n);
     LEAVE_BUFFERED(self)
@@ -1276,7 +1286,11 @@ _io__Buffered_tell_impl(buffered *self)
     if (pos == -1)
         return NULL;
     pos -= RAW_OFFSET(self);
-    /* TODO: sanity check (pos >= 0) */
+
+    // GH-95782
+    if (pos < 0)
+        pos = 0;
+
     return PyLong_FromOff_t(pos);
 }
 
@@ -1345,6 +1359,11 @@ _io__Buffered_seek_impl(buffered *self, PyObject *targetobj, int whence)
                 offset = target;
             if (offset >= -self->pos && offset <= avail) {
                 self->pos += offset;
+
+                // GH-95782
+                if (current - avail + offset < 0)
+                    return PyLong_FromOff_t(0);
+
                 return PyLong_FromOff_t(current - avail + offset);
             }
         }
diff --git a/Modules/_multiprocessing/posixshmem.c b/Modules/_multiprocessing/posixshmem.c
index 88c93fe313..7af995b396 100644
--- a/Modules/_multiprocessing/posixshmem.c
+++ b/Modules/_multiprocessing/posixshmem.c
@@ -42,10 +42,15 @@ _posixshmem_shm_open_impl(PyObject *module, PyObject *path, int flags,
 {
     int fd;
     int async_err = 0;
-    const char *name = PyUnicode_AsUTF8(path);
+    Py_ssize_t name_size;
+    const char *name = PyUnicode_AsUTF8AndSize(path, &name_size);
     if (name == NULL) {
         return -1;
     }
+    if (strlen(name) != (size_t)name_size) {
+        PyErr_SetString(PyExc_ValueError, "embedded null character");
+        return -1;
+    }
     do {
         Py_BEGIN_ALLOW_THREADS
         fd = shm_open(name, flags, mode);
@@ -81,10 +86,15 @@ _posixshmem_shm_unlink_impl(PyObject *module, PyObject *path)
 {
     int rv;
     int async_err = 0;
-    const char *name = PyUnicode_AsUTF8(path);
+    Py_ssize_t name_size;
+    const char *name = PyUnicode_AsUTF8AndSize(path, &name_size);
     if (name == NULL) {
         return NULL;
     }
+    if (strlen(name) != (size_t)name_size) {
+        PyErr_SetString(PyExc_ValueError, "embedded null character");
+        return NULL;
+    }
     do {
         Py_BEGIN_ALLOW_THREADS
         rv = shm_unlink(name);
diff --git a/Modules/_posixsubprocess.c b/Modules/_posixsubprocess.c
index d75bb92757..35ea2ac306 100644
--- a/Modules/_posixsubprocess.c
+++ b/Modules/_posixsubprocess.c
@@ -946,7 +946,9 @@ subprocess_fork_exec_impl(PyObject *module, PyObject *process_args,
     Py_ssize_t fds_to_keep_len = PyTuple_GET_SIZE(py_fds_to_keep);
 
     PyInterpreterState *interp = PyInterpreterState_Get();
-    if ((preexec_fn != Py_None) && interp->finalizing) {
+    if ((preexec_fn != Py_None) &&
+        _PyInterpreterState_GetFinalizing(interp) != NULL)
+    {
         PyErr_SetString(PyExc_RuntimeError,
                         "preexec_fn not supported at interpreter shutdown");
         return NULL;
diff --git a/Modules/_ssl.c b/Modules/_ssl.c
index b602eb04c7..85fbc16282 100644
--- a/Modules/_ssl.c
+++ b/Modules/_ssl.c
@@ -3143,7 +3143,6 @@ _ssl__SSLContext_impl(PyTypeObject *type, int proto_version)
         result = SSL_CTX_set_cipher_list(ctx, "HIGH:!aNULL:!eNULL");
     }
     if (result == 0) {
-        Py_DECREF(self);
         ERR_clear_error();
         PyErr_SetString(get_state_ctx(self)->PySSLErrorObject,
                         "No cipher can be selected.");
@@ -4520,6 +4519,50 @@ set_sni_callback(PySSLContext *self, PyObject *arg, void *c)
     return 0;
 }
 
+#if OPENSSL_VERSION_NUMBER < 0x30300000L
+static X509_OBJECT *x509_object_dup(const X509_OBJECT *obj)
+{
+    int ok;
+    X509_OBJECT *ret = X509_OBJECT_new();
+    if (ret == NULL) {
+        return NULL;
+    }
+    switch (X509_OBJECT_get_type(obj)) {
+        case X509_LU_X509:
+            ok = X509_OBJECT_set1_X509(ret, X509_OBJECT_get0_X509(obj));
+            break;
+        case X509_LU_CRL:
+            /* X509_OBJECT_get0_X509_CRL was not const-correct prior to 3.0.*/
+            ok = X509_OBJECT_set1_X509_CRL(
+                ret, X509_OBJECT_get0_X509_CRL((X509_OBJECT *)obj));
+            break;
+        default:
+            /* We cannot duplicate unrecognized types in a polyfill, but it is
+             * safe to leave an empty object. The caller will ignore it. */
+            ok = 1;
+            break;
+    }
+    if (!ok) {
+        X509_OBJECT_free(ret);
+        return NULL;
+    }
+    return ret;
+}
+
+static STACK_OF(X509_OBJECT) *
+X509_STORE_get1_objects(X509_STORE *store)
+{
+    STACK_OF(X509_OBJECT) *ret;
+    if (!X509_STORE_lock(store)) {
+        return NULL;
+    }
+    ret = sk_X509_OBJECT_deep_copy(X509_STORE_get0_objects(store),
+                                   x509_object_dup, X509_OBJECT_free);
+    X509_STORE_unlock(store);
+    return ret;
+}
+#endif
+
 PyDoc_STRVAR(PySSLContext_sni_callback_doc,
 "Set a callback that will be called when a server name is provided by the SSL/TLS client in the SNI extension.\n\
 \n\
@@ -4549,7 +4592,12 @@ _ssl__SSLContext_cert_store_stats_impl(PySSLContext *self)
     int x509 = 0, crl = 0, ca = 0, i;
 
     store = SSL_CTX_get_cert_store(self->ctx);
-    objs = X509_STORE_get0_objects(store);
+    objs = X509_STORE_get1_objects(store);
+    if (objs == NULL) {
+        PyErr_SetString(PyExc_MemoryError, "failed to query cert store");
+        return NULL;
+    }
+
     for (i = 0; i < sk_X509_OBJECT_num(objs); i++) {
         obj = sk_X509_OBJECT_value(objs, i);
         switch (X509_OBJECT_get_type(obj)) {
@@ -4563,12 +4611,11 @@ _ssl__SSLContext_cert_store_stats_impl(PySSLContext *self)
                 crl++;
                 break;
             default:
-                /* Ignore X509_LU_FAIL, X509_LU_RETRY, X509_LU_PKEY.
-                 * As far as I can tell they are internal states and never
-                 * stored in a cert store */
+                /* Ignore unrecognized types. */
                 break;
         }
     }
+    sk_X509_OBJECT_pop_free(objs, X509_OBJECT_free);
     return Py_BuildValue("{sisisi}", "x509", x509, "crl", crl,
         "x509_ca", ca);
 }
@@ -4600,7 +4647,12 @@ _ssl__SSLContext_get_ca_certs_impl(PySSLContext *self, int binary_form)
     }
 
     store = SSL_CTX_get_cert_store(self->ctx);
-    objs = X509_STORE_get0_objects(store);
+    objs = X509_STORE_get1_objects(store);
+    if (objs == NULL) {
+        PyErr_SetString(PyExc_MemoryError, "failed to query cert store");
+        goto error;
+    }
+
     for (i = 0; i < sk_X509_OBJECT_num(objs); i++) {
         X509_OBJECT *obj;
         X509 *cert;
@@ -4628,9 +4680,11 @@ _ssl__SSLContext_get_ca_certs_impl(PySSLContext *self, int binary_form)
         }
         Py_CLEAR(ci);
     }
+    sk_X509_OBJECT_pop_free(objs, X509_OBJECT_free);
     return rlist;
 
   error:
+    sk_X509_OBJECT_pop_free(objs, X509_OBJECT_free);
     Py_XDECREF(ci);
     Py_XDECREF(rlist);
     return NULL;
diff --git a/Modules/_testbuffer.c b/Modules/_testbuffer.c
index 63ed4dc6ca..a2f23107c8 100644
--- a/Modules/_testbuffer.c
+++ b/Modules/_testbuffer.c
@@ -2819,70 +2819,91 @@ static struct PyModuleDef _testbuffermodule = {
     NULL
 };
 
-
-PyMODINIT_FUNC
-PyInit__testbuffer(void)
+static int
+_testbuffer_exec(PyObject *mod)
 {
-    PyObject *m;
-
-    m = PyModule_Create(&_testbuffermodule);
-    if (m == NULL)
-        return NULL;
-
     Py_SET_TYPE(&NDArray_Type, &PyType_Type);
-    Py_INCREF(&NDArray_Type);
-    PyModule_AddObject(m, "ndarray", (PyObject *)&NDArray_Type);
+    if (PyModule_AddType(mod, &NDArray_Type) < 0) {
+        return -1;
+    }
 
     Py_SET_TYPE(&StaticArray_Type, &PyType_Type);
-    Py_INCREF(&StaticArray_Type);
-    PyModule_AddObject(m, "staticarray", (PyObject *)&StaticArray_Type);
+    if (PyModule_AddType(mod, &StaticArray_Type) < 0) {
+        return -1;
+    }
 
     structmodule = PyImport_ImportModule("struct");
-    if (structmodule == NULL)
-        return NULL;
+    if (structmodule == NULL) {
+        return -1;
+    }
 
     Struct = PyObject_GetAttrString(structmodule, "Struct");
+    if (Struct == NULL) {
+        return -1;
+    }
     calcsize = PyObject_GetAttrString(structmodule, "calcsize");
-    if (Struct == NULL || calcsize == NULL)
-        return NULL;
+    if (calcsize == NULL) {
+        return -1;
+    }
 
     simple_format = PyUnicode_FromString(simple_fmt);
-    if (simple_format == NULL)
-        return NULL;
-
-    PyModule_AddIntMacro(m, ND_MAX_NDIM);
-    PyModule_AddIntMacro(m, ND_VAREXPORT);
-    PyModule_AddIntMacro(m, ND_WRITABLE);
-    PyModule_AddIntMacro(m, ND_FORTRAN);
-    PyModule_AddIntMacro(m, ND_SCALAR);
-    PyModule_AddIntMacro(m, ND_PIL);
-    PyModule_AddIntMacro(m, ND_GETBUF_FAIL);
-    PyModule_AddIntMacro(m, ND_GETBUF_UNDEFINED);
-    PyModule_AddIntMacro(m, ND_REDIRECT);
-
-    PyModule_AddIntMacro(m, PyBUF_SIMPLE);
-    PyModule_AddIntMacro(m, PyBUF_WRITABLE);
-    PyModule_AddIntMacro(m, PyBUF_FORMAT);
-    PyModule_AddIntMacro(m, PyBUF_ND);
-    PyModule_AddIntMacro(m, PyBUF_STRIDES);
-    PyModule_AddIntMacro(m, PyBUF_INDIRECT);
-    PyModule_AddIntMacro(m, PyBUF_C_CONTIGUOUS);
-    PyModule_AddIntMacro(m, PyBUF_F_CONTIGUOUS);
-    PyModule_AddIntMacro(m, PyBUF_ANY_CONTIGUOUS);
-    PyModule_AddIntMacro(m, PyBUF_FULL);
-    PyModule_AddIntMacro(m, PyBUF_FULL_RO);
-    PyModule_AddIntMacro(m, PyBUF_RECORDS);
-    PyModule_AddIntMacro(m, PyBUF_RECORDS_RO);
-    PyModule_AddIntMacro(m, PyBUF_STRIDED);
-    PyModule_AddIntMacro(m, PyBUF_STRIDED_RO);
-    PyModule_AddIntMacro(m, PyBUF_CONTIG);
-    PyModule_AddIntMacro(m, PyBUF_CONTIG_RO);
-
-    PyModule_AddIntMacro(m, PyBUF_READ);
-    PyModule_AddIntMacro(m, PyBUF_WRITE);
-
-    return m;
-}
+    if (simple_format == NULL) {
+        return -1;
+    }
 
+#define ADD_INT_MACRO(mod, macro)                                             \
+    do {                                                                    \
+        if (PyModule_AddIntConstant(mod, #macro, macro) < 0) {                \
+            return -1;                                                      \
+        }                                                                   \
+    } while (0)
+
+    ADD_INT_MACRO(mod, ND_MAX_NDIM);
+    ADD_INT_MACRO(mod, ND_VAREXPORT);
+    ADD_INT_MACRO(mod, ND_WRITABLE);
+    ADD_INT_MACRO(mod, ND_FORTRAN);
+    ADD_INT_MACRO(mod, ND_SCALAR);
+    ADD_INT_MACRO(mod, ND_PIL);
+    ADD_INT_MACRO(mod, ND_GETBUF_FAIL);
+    ADD_INT_MACRO(mod, ND_GETBUF_UNDEFINED);
+    ADD_INT_MACRO(mod, ND_REDIRECT);
+
+    ADD_INT_MACRO(mod, PyBUF_SIMPLE);
+    ADD_INT_MACRO(mod, PyBUF_WRITABLE);
+    ADD_INT_MACRO(mod, PyBUF_FORMAT);
+    ADD_INT_MACRO(mod, PyBUF_ND);
+    ADD_INT_MACRO(mod, PyBUF_STRIDES);
+    ADD_INT_MACRO(mod, PyBUF_INDIRECT);
+    ADD_INT_MACRO(mod, PyBUF_C_CONTIGUOUS);
+    ADD_INT_MACRO(mod, PyBUF_F_CONTIGUOUS);
+    ADD_INT_MACRO(mod, PyBUF_ANY_CONTIGUOUS);
+    ADD_INT_MACRO(mod, PyBUF_FULL);
+    ADD_INT_MACRO(mod, PyBUF_FULL_RO);
+    ADD_INT_MACRO(mod, PyBUF_RECORDS);
+    ADD_INT_MACRO(mod, PyBUF_RECORDS_RO);
+    ADD_INT_MACRO(mod, PyBUF_STRIDED);
+    ADD_INT_MACRO(mod, PyBUF_STRIDED_RO);
+    ADD_INT_MACRO(mod, PyBUF_CONTIG);
+    ADD_INT_MACRO(mod, PyBUF_CONTIG_RO);
+
+    ADD_INT_MACRO(mod, PyBUF_READ);
+    ADD_INT_MACRO(mod, PyBUF_WRITE);
+
+#undef ADD_INT_MACRO
 
+    return 0;
+}
 
+PyMODINIT_FUNC
+PyInit__testbuffer(void)
+{
+    PyObject *mod = PyModule_Create(&_testbuffermodule);
+    if (mod == NULL) {
+        return NULL;
+    }
+    if (_testbuffer_exec(mod) < 0) {
+        Py_DECREF(mod);
+        return NULL;
+    }
+    return mod;
+}
diff --git a/Modules/_testcapi/long.c b/Modules/_testcapi/long.c
index 213c676e5c..9c5a0e3867 100644
--- a/Modules/_testcapi/long.c
+++ b/Modules/_testcapi/long.c
@@ -750,6 +750,18 @@ pylong_asvoidptr(PyObject *module, PyObject *arg)
     return Py_NewRef((PyObject *)value);
 }
 
+static PyObject *
+pylong_aspid(PyObject *module, PyObject *arg)
+{
+    NULLABLE(arg);
+    pid_t value = PyLong_AsPid(arg);
+    if (value == -1 && PyErr_Occurred()) {
+        return NULL;
+    }
+    return PyLong_FromPid(value);
+}
+
+
 static PyMethodDef test_methods[] = {
     {"test_long_and_overflow",  test_long_and_overflow,          METH_NOARGS},
     {"test_long_api",           test_long_api,                   METH_NOARGS},
@@ -778,6 +790,7 @@ static PyMethodDef test_methods[] = {
     {"pylong_as_size_t",            pylong_as_size_t,           METH_O},
     {"pylong_asdouble",             pylong_asdouble,            METH_O},
     {"pylong_asvoidptr",            pylong_asvoidptr,           METH_O},
+    {"pylong_aspid",                pylong_aspid,               METH_O},
     {NULL},
 };
 
diff --git a/Modules/_testcapi/mem.c b/Modules/_testcapi/mem.c
index af32e9668d..545cc6b669 100644
--- a/Modules/_testcapi/mem.c
+++ b/Modules/_testcapi/mem.c
@@ -580,8 +580,8 @@ check_pyobject_forbidden_bytes_is_freed(PyObject *self,
 static PyObject *
 check_pyobject_freed_is_freed(PyObject *self, PyObject *Py_UNUSED(args))
 {
-    /* This test would fail if run with the address sanitizer */
-#ifdef _Py_ADDRESS_SANITIZER
+    /* ASan or TSan would report an use-after-free error */
+#if defined(_Py_ADDRESS_SANITIZER) || defined(_Py_THREAD_SANITIZER)
     Py_RETURN_NONE;
 #else
     PyObject *op = PyObject_CallNoArgs((PyObject *)&PyBaseObject_Type);
diff --git a/Modules/_testcapimodule.c b/Modules/_testcapimodule.c
index 48c8f92213..e9066581a9 100644
--- a/Modules/_testcapimodule.c
+++ b/Modules/_testcapimodule.c
@@ -3986,6 +3986,7 @@ PyInit__testcapi(void)
     PyModule_AddObject(m, "SIZEOF_WCHAR_T", PyLong_FromSsize_t(sizeof(wchar_t)));
     PyModule_AddObject(m, "SIZEOF_VOID_P", PyLong_FromSsize_t(sizeof(void*)));
     PyModule_AddObject(m, "SIZEOF_TIME_T", PyLong_FromSsize_t(sizeof(time_t)));
+    PyModule_AddObject(m, "SIZEOF_PID_T", PyLong_FromSsize_t(sizeof(pid_t)));
     PyModule_AddObject(m, "Py_Version", PyLong_FromUnsignedLong(Py_Version));
     Py_INCREF(&PyInstanceMethod_Type);
     PyModule_AddObject(m, "instancemethod", (PyObject *)&PyInstanceMethod_Type);
diff --git a/Modules/_threadmodule.c b/Modules/_threadmodule.c
index 568fe8375d..365f446008 100644
--- a/Modules/_threadmodule.c
+++ b/Modules/_threadmodule.c
@@ -1190,7 +1190,7 @@ thread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)
                         "thread is not supported for isolated subinterpreters");
         return NULL;
     }
-    if (interp->finalizing) {
+    if (_PyInterpreterState_GetFinalizing(interp) != NULL) {
         PyErr_SetString(PyExc_RuntimeError,
                         "can't create new thread at interpreter shutdown");
         return NULL;
diff --git a/Modules/arraymodule.c b/Modules/arraymodule.c
index 6680820d8e..19ee83d24c 100644
--- a/Modules/arraymodule.c
+++ b/Modules/arraymodule.c
@@ -244,7 +244,7 @@ BB_setitem(arrayobject *ap, Py_ssize_t i, PyObject *v)
     if (!PyArg_Parse(v, "b;array item must be integer", &x))
         return -1;
     if (i >= 0)
-        ((char *)ap->ob_item)[i] = x;
+        ((unsigned char *)ap->ob_item)[i] = x;
     return 0;
 }
 
diff --git a/Modules/clinic/_elementtree.c.h b/Modules/clinic/_elementtree.c.h
index 0b3a86159c..d635d33d85 100644
--- a/Modules/clinic/_elementtree.c.h
+++ b/Modules/clinic/_elementtree.c.h
@@ -1168,6 +1168,23 @@ _elementtree_XMLParser_close(XMLParserObject *self, PyObject *Py_UNUSED(ignored)
     return _elementtree_XMLParser_close_impl(self);
 }
 
+PyDoc_STRVAR(_elementtree_XMLParser_flush__doc__,
+"flush($self, /)\n"
+"--\n"
+"\n");
+
+#define _ELEMENTTREE_XMLPARSER_FLUSH_METHODDEF    \
+    {"flush", (PyCFunction)_elementtree_XMLParser_flush, METH_NOARGS, _elementtree_XMLParser_flush__doc__},
+
+static PyObject *
+_elementtree_XMLParser_flush_impl(XMLParserObject *self);
+
+static PyObject *
+_elementtree_XMLParser_flush(XMLParserObject *self, PyObject *Py_UNUSED(ignored))
+{
+    return _elementtree_XMLParser_flush_impl(self);
+}
+
 PyDoc_STRVAR(_elementtree_XMLParser_feed__doc__,
 "feed($self, data, /)\n"
 "--\n"
@@ -1218,4 +1235,4 @@ skip_optional:
 exit:
     return return_value;
 }
-/*[clinic end generated code: output=31c4780c4df68441 input=a9049054013a1b77]*/
+/*[clinic end generated code: output=ec30550fd83b2791 input=a9049054013a1b77]*/
diff --git a/Modules/clinic/pyexpat.c.h b/Modules/clinic/pyexpat.c.h
index 34937c5d59..20a28dc6a7 100644
--- a/Modules/clinic/pyexpat.c.h
+++ b/Modules/clinic/pyexpat.c.h
@@ -8,6 +8,53 @@ preserve
 #endif
 
 
+PyDoc_STRVAR(pyexpat_xmlparser_SetReparseDeferralEnabled__doc__,
+"SetReparseDeferralEnabled($self, enabled, /)\n"
+"--\n"
+"\n"
+"Enable/Disable reparse deferral; enabled by default with Expat >=2.6.0.");
+
+#define PYEXPAT_XMLPARSER_SETREPARSEDEFERRALENABLED_METHODDEF    \
+    {"SetReparseDeferralEnabled", (PyCFunction)pyexpat_xmlparser_SetReparseDeferralEnabled, METH_O, pyexpat_xmlparser_SetReparseDeferralEnabled__doc__},
+
+static PyObject *
+pyexpat_xmlparser_SetReparseDeferralEnabled_impl(xmlparseobject *self,
+                                                 int enabled);
+
+static PyObject *
+pyexpat_xmlparser_SetReparseDeferralEnabled(xmlparseobject *self, PyObject *arg)
+{
+    PyObject *return_value = NULL;
+    int enabled;
+
+    enabled = PyObject_IsTrue(arg);
+    if (enabled < 0) {
+        goto exit;
+    }
+    return_value = pyexpat_xmlparser_SetReparseDeferralEnabled_impl(self, enabled);
+
+exit:
+    return return_value;
+}
+
+PyDoc_STRVAR(pyexpat_xmlparser_GetReparseDeferralEnabled__doc__,
+"GetReparseDeferralEnabled($self, /)\n"
+"--\n"
+"\n"
+"Retrieve reparse deferral enabled status; always returns false with Expat <2.6.0.");
+
+#define PYEXPAT_XMLPARSER_GETREPARSEDEFERRALENABLED_METHODDEF    \
+    {"GetReparseDeferralEnabled", (PyCFunction)pyexpat_xmlparser_GetReparseDeferralEnabled, METH_NOARGS, pyexpat_xmlparser_GetReparseDeferralEnabled__doc__},
+
+static PyObject *
+pyexpat_xmlparser_GetReparseDeferralEnabled_impl(xmlparseobject *self);
+
+static PyObject *
+pyexpat_xmlparser_GetReparseDeferralEnabled(xmlparseobject *self, PyObject *Py_UNUSED(ignored))
+{
+    return pyexpat_xmlparser_GetReparseDeferralEnabled_impl(self);
+}
+
 PyDoc_STRVAR(pyexpat_xmlparser_Parse__doc__,
 "Parse($self, data, isfinal=False, /)\n"
 "--\n"
@@ -498,4 +545,4 @@ exit:
 #ifndef PYEXPAT_XMLPARSER_USEFOREIGNDTD_METHODDEF
     #define PYEXPAT_XMLPARSER_USEFOREIGNDTD_METHODDEF
 #endif /* !defined(PYEXPAT_XMLPARSER_USEFOREIGNDTD_METHODDEF) */
-/*[clinic end generated code: output=63efc62e24a7b5a7 input=a9049054013a1b77]*/
+/*[clinic end generated code: output=8625852bb44a5e56 input=a9049054013a1b77]*/
diff --git a/Modules/expat/expat.h b/Modules/expat/expat.h
index 1c83563cbf..95464b0dd1 100644
--- a/Modules/expat/expat.h
+++ b/Modules/expat/expat.h
@@ -11,11 +11,13 @@
    Copyright (c) 2000-2005 Fred L. Drake, Jr. <fdrake@users.sourceforge.net>
    Copyright (c) 2001-2002 Greg Stein <gstein@users.sourceforge.net>
    Copyright (c) 2002-2016 Karl Waclawek <karl@waclawek.net>
-   Copyright (c) 2016-2022 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2024 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2016      Cristian Rodrguez <crrodriguez@opensuse.org>
    Copyright (c) 2016      Thomas Beutlich <tc@tbeu.de>
    Copyright (c) 2017      Rhodri James <rhodri@wildebeest.org.uk>
    Copyright (c) 2022      Thijs Schreijer <thijs@thijsschreijer.nl>
+   Copyright (c) 2023      Hanno Bck <hanno@gentoo.org>
+   Copyright (c) 2023      Sony Corporation / Snild Dolkow <snild@sony.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -269,7 +271,7 @@ XML_ParserCreate_MM(const XML_Char *encoding,
                     const XML_Memory_Handling_Suite *memsuite,
                     const XML_Char *namespaceSeparator);
 
-/* Prepare a parser object to be re-used.  This is particularly
+/* Prepare a parser object to be reused.  This is particularly
    valuable when memory allocation overhead is disproportionately high,
    such as when a large number of small documnents need to be parsed.
    All handlers are cleared from the parser, except for the
@@ -951,7 +953,7 @@ XMLPARSEAPI(XML_Index) XML_GetCurrentByteIndex(XML_Parser parser);
 XMLPARSEAPI(int)
 XML_GetCurrentByteCount(XML_Parser parser);
 
-/* If XML_CONTEXT_BYTES is defined, returns the input buffer, sets
+/* If XML_CONTEXT_BYTES is >=1, returns the input buffer, sets
    the integer pointed to by offset to the offset within this buffer
    of the current parse position, and sets the integer pointed to by size
    to the size of this buffer (the number of input bytes). Otherwise
@@ -1025,7 +1027,9 @@ enum XML_FeatureEnum {
   XML_FEATURE_ATTR_INFO,
   /* Added in Expat 2.4.0. */
   XML_FEATURE_BILLION_LAUGHS_ATTACK_PROTECTION_MAXIMUM_AMPLIFICATION_DEFAULT,
-  XML_FEATURE_BILLION_LAUGHS_ATTACK_PROTECTION_ACTIVATION_THRESHOLD_DEFAULT
+  XML_FEATURE_BILLION_LAUGHS_ATTACK_PROTECTION_ACTIVATION_THRESHOLD_DEFAULT,
+  /* Added in Expat 2.6.0. */
+  XML_FEATURE_GE
   /* Additional features must be added to the end of this enum. */
 };
 
@@ -1038,23 +1042,29 @@ typedef struct {
 XMLPARSEAPI(const XML_Feature *)
 XML_GetFeatureList(void);
 
-#ifdef XML_DTD
-/* Added in Expat 2.4.0. */
+#if XML_GE == 1
+/* Added in Expat 2.4.0 for XML_DTD defined and
+ * added in Expat 2.6.0 for XML_GE == 1. */
 XMLPARSEAPI(XML_Bool)
 XML_SetBillionLaughsAttackProtectionMaximumAmplification(
     XML_Parser parser, float maximumAmplificationFactor);
 
-/* Added in Expat 2.4.0. */
+/* Added in Expat 2.4.0 for XML_DTD defined and
+ * added in Expat 2.6.0 for XML_GE == 1. */
 XMLPARSEAPI(XML_Bool)
 XML_SetBillionLaughsAttackProtectionActivationThreshold(
     XML_Parser parser, unsigned long long activationThresholdBytes);
 #endif
 
+/* Added in Expat 2.6.0. */
+XMLPARSEAPI(XML_Bool)
+XML_SetReparseDeferralEnabled(XML_Parser parser, XML_Bool enabled);
+
 /* Expat follows the semantic versioning convention.
-   See http://semver.org.
+   See https://semver.org
 */
 #define XML_MAJOR_VERSION 2
-#define XML_MINOR_VERSION 5
+#define XML_MINOR_VERSION 6
 #define XML_MICRO_VERSION 0
 
 #ifdef __cplusplus
diff --git a/Modules/expat/expat_config.h b/Modules/expat/expat_config.h
index 6671f7b689..e7d9499d90 100644
--- a/Modules/expat/expat_config.h
+++ b/Modules/expat/expat_config.h
@@ -16,6 +16,7 @@
 
 #define XML_NS 1
 #define XML_DTD 1
+#define XML_GE 1
 #define XML_CONTEXT_BYTES 1024
 
 // bpo-30947: Python uses best available entropy sources to
diff --git a/Modules/expat/internal.h b/Modules/expat/internal.h
index e09f533b23..cce71e4c51 100644
--- a/Modules/expat/internal.h
+++ b/Modules/expat/internal.h
@@ -28,9 +28,10 @@
    Copyright (c) 2002-2003 Fred L. Drake, Jr. <fdrake@users.sourceforge.net>
    Copyright (c) 2002-2006 Karl Waclawek <karl@waclawek.net>
    Copyright (c) 2003      Greg Stein <gstein@users.sourceforge.net>
-   Copyright (c) 2016-2022 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2023 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2018      Yury Gribov <tetra2005@gmail.com>
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
+   Copyright (c) 2023      Sony Corporation / Snild Dolkow <snild@sony.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -154,12 +155,15 @@ extern "C" {
 void _INTERNAL_trim_to_complete_utf8_characters(const char *from,
                                                 const char **fromLimRef);
 
-#if defined(XML_DTD)
+#if XML_GE == 1
 unsigned long long testingAccountingGetCountBytesDirect(XML_Parser parser);
 unsigned long long testingAccountingGetCountBytesIndirect(XML_Parser parser);
 const char *unsignedCharToPrintable(unsigned char c);
 #endif
 
+extern XML_Bool g_reparseDeferralEnabledDefault; // written ONLY in runtests.c
+extern unsigned int g_parseAttempts;             // used for testing only
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/Modules/expat/pyexpatns.h b/Modules/expat/pyexpatns.h
index d45d9b6c45..8ee03ef079 100644
--- a/Modules/expat/pyexpatns.h
+++ b/Modules/expat/pyexpatns.h
@@ -108,6 +108,7 @@
 #define XML_SetNotStandaloneHandler     PyExpat_XML_SetNotStandaloneHandler
 #define XML_SetParamEntityParsing       PyExpat_XML_SetParamEntityParsing
 #define XML_SetProcessingInstructionHandler PyExpat_XML_SetProcessingInstructionHandler
+#define XML_SetReparseDeferralEnabled   PyExpat_XML_SetReparseDeferralEnabled
 #define XML_SetReturnNSTriplet          PyExpat_XML_SetReturnNSTriplet
 #define XML_SetSkippedEntityHandler     PyExpat_XML_SetSkippedEntityHandler
 #define XML_SetStartCdataSectionHandler PyExpat_XML_SetStartCdataSectionHandler
diff --git a/Modules/expat/siphash.h b/Modules/expat/siphash.h
index 303283ad2d..a1ed99e687 100644
--- a/Modules/expat/siphash.h
+++ b/Modules/expat/siphash.h
@@ -106,7 +106,7 @@
  * if this code is included and compiled as C++; related GCC warning is:
  * warning: use of C++11 long long integer constant [-Wlong-long]
  */
-#define _SIP_ULL(high, low) ((((uint64_t)high) << 32) | (low))
+#define SIP_ULL(high, low) ((((uint64_t)high) << 32) | (low))
 
 #define SIP_ROTL(x, b) (uint64_t)(((x) << (b)) | ((x) >> (64 - (b))))
 
@@ -190,10 +190,10 @@ sip_round(struct siphash *H, const int rounds) {
 
 static struct siphash *
 sip24_init(struct siphash *H, const struct sipkey *key) {
-  H->v0 = _SIP_ULL(0x736f6d65U, 0x70736575U) ^ key->k[0];
-  H->v1 = _SIP_ULL(0x646f7261U, 0x6e646f6dU) ^ key->k[1];
-  H->v2 = _SIP_ULL(0x6c796765U, 0x6e657261U) ^ key->k[0];
-  H->v3 = _SIP_ULL(0x74656462U, 0x79746573U) ^ key->k[1];
+  H->v0 = SIP_ULL(0x736f6d65U, 0x70736575U) ^ key->k[0];
+  H->v1 = SIP_ULL(0x646f7261U, 0x6e646f6dU) ^ key->k[1];
+  H->v2 = SIP_ULL(0x6c796765U, 0x6e657261U) ^ key->k[0];
+  H->v3 = SIP_ULL(0x74656462U, 0x79746573U) ^ key->k[1];
 
   H->p = H->buf;
   H->c = 0;
diff --git a/Modules/expat/winconfig.h b/Modules/expat/winconfig.h
index 2ecd61b5b9..05805514ec 100644
--- a/Modules/expat/winconfig.h
+++ b/Modules/expat/winconfig.h
@@ -9,7 +9,8 @@
    Copyright (c) 2000      Clark Cooper <coopercc@users.sourceforge.net>
    Copyright (c) 2002      Greg Stein <gstein@users.sourceforge.net>
    Copyright (c) 2005      Karl Waclawek <karl@waclawek.net>
-   Copyright (c) 2017-2021 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2017-2023 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2023      Orgad Shaneh <orgad.shaneh@audiocodes.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -35,7 +36,9 @@
 #ifndef WINCONFIG_H
 #define WINCONFIG_H
 
-#define WIN32_LEAN_AND_MEAN
+#ifndef WIN32_LEAN_AND_MEAN
+#  define WIN32_LEAN_AND_MEAN
+#endif
 #include <windows.h>
 #undef WIN32_LEAN_AND_MEAN
 
diff --git a/Modules/expat/xmlparse.c b/Modules/expat/xmlparse.c
index b6c2eca975..aaf0fa9c8f 100644
--- a/Modules/expat/xmlparse.c
+++ b/Modules/expat/xmlparse.c
@@ -1,4 +1,4 @@
-/* 5ab094ffadd6edfc94c3eee53af44a86951f9f1f0933ada3114bbce2bfb02c99 (2.5.0+)
+/* 628e24d4966bedbd4800f6ed128d06d29703765b4bce12d3b7f099f90f842fc9 (2.6.0+)
                             __  __            _
                          ___\ \/ /_ __   __ _| |_
                         / _ \\  /| '_ \ / _` | __|
@@ -13,7 +13,7 @@
    Copyright (c) 2002-2016 Karl Waclawek <karl@waclawek.net>
    Copyright (c) 2005-2009 Steven Solie <steven@solie.ca>
    Copyright (c) 2016      Eric Rahm <erahm@mozilla.com>
-   Copyright (c) 2016-2022 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2024 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2016      Gaurav <g.gupta@samsung.com>
    Copyright (c) 2016      Thomas Beutlich <tc@tbeu.de>
    Copyright (c) 2016      Gustavo Grieco <gustavo.grieco@imag.fr>
@@ -32,10 +32,13 @@
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
    Copyright (c) 2019-2020 Ben Wagner <bungeman@chromium.org>
    Copyright (c) 2019      Vadim Zeitlin <vadim@zeitlins.org>
-   Copyright (c) 2021      Dong-hee Na <donghee.na@python.org>
+   Copyright (c) 2021      Donghee Na <donghee.na@python.org>
    Copyright (c) 2022      Samanta Navarro <ferivoz@riseup.net>
    Copyright (c) 2022      Jeffrey Walton <noloader@gmail.com>
    Copyright (c) 2022      Jann Horn <jannh@google.com>
+   Copyright (c) 2022      Sean McBride <sean@rogue-research.com>
+   Copyright (c) 2023      Owain Davies <owaind@bath.edu>
+   Copyright (c) 2023      Sony Corporation / Snild Dolkow <snild@sony.com>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -60,10 +63,25 @@
 
 #define XML_BUILDING_EXPAT 1
 
-#include <expat_config.h>
+#include "expat_config.h"
 
-#if ! defined(_GNU_SOURCE)
-#  define _GNU_SOURCE 1 /* syscall prototype */
+#if ! defined(XML_GE) || (1 - XML_GE - 1 == 2) || (XML_GE < 0) || (XML_GE > 1)
+#  error XML_GE (for general entities) must be defined, non-empty, either 1 or 0 (0 to disable, 1 to enable; 1 is a common default)
+#endif
+
+#if defined(XML_DTD) && XML_GE == 0
+#  error Either undefine XML_DTD or define XML_GE to 1.
+#endif
+
+#if ! defined(XML_CONTEXT_BYTES) || (1 - XML_CONTEXT_BYTES - 1 == 2)           \
+    || (XML_CONTEXT_BYTES + 0 < 0)
+#  error XML_CONTEXT_BYTES must be defined, non-empty and >=0 (0 to disable, >=1 to enable; 1024 is a common default)
+#endif
+
+#if defined(HAVE_SYSCALL_GETRANDOM)
+#  if ! defined(_GNU_SOURCE)
+#    define _GNU_SOURCE 1 /* syscall prototype */
+#  endif
 #endif
 
 #ifdef _WIN32
@@ -73,6 +91,7 @@
 #  endif
 #endif
 
+#include <stdbool.h>
 #include <stddef.h>
 #include <string.h> /* memset(), memcpy() */
 #include <assert.h>
@@ -131,8 +150,8 @@
     Your options include: \
       * Linux >=3.17 + glibc >=2.25 (getrandom): HAVE_GETRANDOM, \
       * Linux >=3.17 + glibc (including <2.25) (syscall SYS_getrandom): HAVE_SYSCALL_GETRANDOM, \
-      * BSD / macOS >=10.7 (arc4random_buf): HAVE_ARC4RANDOM_BUF, \
-      * BSD / macOS (including <10.7) (arc4random): HAVE_ARC4RANDOM, \
+      * BSD / macOS >=10.7 / glibc >=2.36 (arc4random_buf): HAVE_ARC4RANDOM_BUF, \
+      * BSD / macOS (including <10.7) / glibc >=2.36 (arc4random): HAVE_ARC4RANDOM, \
       * libbsd (arc4random_buf): HAVE_ARC4RANDOM_BUF + HAVE_LIBBSD, \
       * libbsd (arc4random): HAVE_ARC4RANDOM + HAVE_LIBBSD, \
       * Linux (including <3.17) / BSD / macOS (including <10.7) / Solaris >=8 (/dev/urandom): XML_DEV_URANDOM, \
@@ -196,6 +215,8 @@ typedef char ICHAR;
 /* Do safe (NULL-aware) pointer arithmetic */
 #define EXPAT_SAFE_PTR_DIFF(p, q) (((p) && (q)) ? ((p) - (q)) : 0)
 
+#define EXPAT_MIN(a, b) (((a) < (b)) ? (a) : (b))
+
 #include "internal.h"
 #include "xmltok.h"
 #include "xmlrole.h"
@@ -279,7 +300,7 @@ typedef struct {
    XML_Parse()/XML_ParseBuffer(), the buffer is re-allocated to
    contain the 'raw' name as well.
 
-   A parser re-uses these structures, maintaining a list of allocated
+   A parser reuses these structures, maintaining a list of allocated
    TAG objects in a free list.
 */
 typedef struct tag {
@@ -408,12 +429,12 @@ enum XML_Account {
   XML_ACCOUNT_NONE              /* i.e. do not account, was accounted already */
 };
 
-#ifdef XML_DTD
+#if XML_GE == 1
 typedef unsigned long long XmlBigCount;
 typedef struct accounting {
   XmlBigCount countBytesDirect;
   XmlBigCount countBytesIndirect;
-  int debugLevel;
+  unsigned long debugLevel;
   float maximumAmplificationFactor; // >=1.0
   unsigned long long activationThresholdBytes;
 } ACCOUNTING;
@@ -422,9 +443,9 @@ typedef struct entity_stats {
   unsigned int countEverOpened;
   unsigned int currentDepth;
   unsigned int maximumDepthSeen;
-  int debugLevel;
+  unsigned long debugLevel;
 } ENTITY_STATS;
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
 
 typedef enum XML_Error PTRCALL Processor(XML_Parser parser, const char *start,
                                          const char *end, const char **endPtr);
@@ -464,41 +485,47 @@ static enum XML_Error doContent(XML_Parser parser, int startTagLevel,
                                 const ENCODING *enc, const char *start,
                                 const char *end, const char **endPtr,
                                 XML_Bool haveMore, enum XML_Account account);
-static enum XML_Error doCdataSection(XML_Parser parser, const ENCODING *,
+static enum XML_Error doCdataSection(XML_Parser parser, const ENCODING *enc,
                                      const char **startPtr, const char *end,
                                      const char **nextPtr, XML_Bool haveMore,
                                      enum XML_Account account);
 #ifdef XML_DTD
-static enum XML_Error doIgnoreSection(XML_Parser parser, const ENCODING *,
+static enum XML_Error doIgnoreSection(XML_Parser parser, const ENCODING *enc,
                                       const char **startPtr, const char *end,
                                       const char **nextPtr, XML_Bool haveMore);
 #endif /* XML_DTD */
 
 static void freeBindings(XML_Parser parser, BINDING *bindings);
-static enum XML_Error storeAtts(XML_Parser parser, const ENCODING *,
-                                const char *s, TAG_NAME *tagNamePtr,
+static enum XML_Error storeAtts(XML_Parser parser, const ENCODING *enc,
+                                const char *attStr, TAG_NAME *tagNamePtr,
                                 BINDING **bindingsPtr,
                                 enum XML_Account account);
 static enum XML_Error addBinding(XML_Parser parser, PREFIX *prefix,
                                  const ATTRIBUTE_ID *attId, const XML_Char *uri,
                                  BINDING **bindingsPtr);
-static int defineAttribute(ELEMENT_TYPE *type, ATTRIBUTE_ID *, XML_Bool isCdata,
-                           XML_Bool isId, const XML_Char *dfltValue,
-                           XML_Parser parser);
-static enum XML_Error storeAttributeValue(XML_Parser parser, const ENCODING *,
-                                          XML_Bool isCdata, const char *,
-                                          const char *, STRING_POOL *,
+static int defineAttribute(ELEMENT_TYPE *type, ATTRIBUTE_ID *attId,
+                           XML_Bool isCdata, XML_Bool isId,
+                           const XML_Char *value, XML_Parser parser);
+static enum XML_Error storeAttributeValue(XML_Parser parser,
+                                          const ENCODING *enc, XML_Bool isCdata,
+                                          const char *ptr, const char *end,
+                                          STRING_POOL *pool,
                                           enum XML_Account account);
-static enum XML_Error appendAttributeValue(XML_Parser parser, const ENCODING *,
-                                           XML_Bool isCdata, const char *,
-                                           const char *, STRING_POOL *,
+static enum XML_Error appendAttributeValue(XML_Parser parser,
+                                           const ENCODING *enc,
+                                           XML_Bool isCdata, const char *ptr,
+                                           const char *end, STRING_POOL *pool,
                                            enum XML_Account account);
 static ATTRIBUTE_ID *getAttributeId(XML_Parser parser, const ENCODING *enc,
                                     const char *start, const char *end);
-static int setElementTypePrefix(XML_Parser parser, ELEMENT_TYPE *);
+static int setElementTypePrefix(XML_Parser parser, ELEMENT_TYPE *elementType);
+#if XML_GE == 1
 static enum XML_Error storeEntityValue(XML_Parser parser, const ENCODING *enc,
                                        const char *start, const char *end,
                                        enum XML_Account account);
+#else
+static enum XML_Error storeSelfEntityValue(XML_Parser parser, ENTITY *entity);
+#endif
 static int reportProcessingInstruction(XML_Parser parser, const ENCODING *enc,
                                        const char *start, const char *end);
 static int reportComment(XML_Parser parser, const ENCODING *enc,
@@ -518,21 +545,22 @@ static void dtdDestroy(DTD *p, XML_Bool isDocEntity,
                        const XML_Memory_Handling_Suite *ms);
 static int dtdCopy(XML_Parser oldParser, DTD *newDtd, const DTD *oldDtd,
                    const XML_Memory_Handling_Suite *ms);
-static int copyEntityTable(XML_Parser oldParser, HASH_TABLE *, STRING_POOL *,
-                           const HASH_TABLE *);
+static int copyEntityTable(XML_Parser oldParser, HASH_TABLE *newTable,
+                           STRING_POOL *newPool, const HASH_TABLE *oldTable);
 static NAMED *lookup(XML_Parser parser, HASH_TABLE *table, KEY name,
                      size_t createSize);
-static void FASTCALL hashTableInit(HASH_TABLE *,
+static void FASTCALL hashTableInit(HASH_TABLE *table,
                                    const XML_Memory_Handling_Suite *ms);
-static void FASTCALL hashTableClear(HASH_TABLE *);
-static void FASTCALL hashTableDestroy(HASH_TABLE *);
-static void FASTCALL hashTableIterInit(HASH_TABLE_ITER *, const HASH_TABLE *);
-static NAMED *FASTCALL hashTableIterNext(HASH_TABLE_ITER *);
+static void FASTCALL hashTableClear(HASH_TABLE *table);
+static void FASTCALL hashTableDestroy(HASH_TABLE *table);
+static void FASTCALL hashTableIterInit(HASH_TABLE_ITER *iter,
+                                       const HASH_TABLE *table);
+static NAMED *FASTCALL hashTableIterNext(HASH_TABLE_ITER *iter);
 
-static void FASTCALL poolInit(STRING_POOL *,
+static void FASTCALL poolInit(STRING_POOL *pool,
                               const XML_Memory_Handling_Suite *ms);
-static void FASTCALL poolClear(STRING_POOL *);
-static void FASTCALL poolDestroy(STRING_POOL *);
+static void FASTCALL poolClear(STRING_POOL *pool);
+static void FASTCALL poolDestroy(STRING_POOL *pool);
 static XML_Char *poolAppend(STRING_POOL *pool, const ENCODING *enc,
                             const char *ptr, const char *end);
 static XML_Char *poolStoreString(STRING_POOL *pool, const ENCODING *enc,
@@ -562,7 +590,7 @@ static XML_Parser parserCreate(const XML_Char *encodingName,
 
 static void parserInit(XML_Parser parser, const XML_Char *encodingName);
 
-#ifdef XML_DTD
+#if XML_GE == 1
 static float accountingGetCurrentAmplification(XML_Parser rootParser);
 static void accountingReportStats(XML_Parser originParser, const char *epilog);
 static void accountingOnAbort(XML_Parser originParser);
@@ -585,13 +613,12 @@ static void entityTrackingOnClose(XML_Parser parser, ENTITY *entity,
 
 static XML_Parser getRootParserOf(XML_Parser parser,
                                   unsigned int *outLevelDiff);
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
 
 static unsigned long getDebugLevel(const char *variableName,
                                    unsigned long defaultDebugLevel);
 
 #define poolStart(pool) ((pool)->start)
-#define poolEnd(pool) ((pool)->ptr)
 #define poolLength(pool) ((pool)->ptr - (pool)->start)
 #define poolChop(pool) ((void)--(pool->ptr))
 #define poolLastChar(pool) (((pool)->ptr)[-1])
@@ -602,21 +629,35 @@ static unsigned long getDebugLevel(const char *variableName,
        ? 0                                                                     \
        : ((*((pool)->ptr)++ = c), 1))
 
+XML_Bool g_reparseDeferralEnabledDefault = XML_TRUE; // write ONLY in runtests.c
+unsigned int g_parseAttempts = 0;                    // used for testing only
+
 struct XML_ParserStruct {
   /* The first member must be m_userData so that the XML_GetUserData
      macro works. */
   void *m_userData;
   void *m_handlerArg;
-  char *m_buffer;
+
+  // How the four parse buffer pointers below relate in time and space:
+  //
+  //   m_buffer <= m_bufferPtr <= m_bufferEnd  <= m_bufferLim
+  //   |           |              |               |
+  //   <--parsed-->|              |               |
+  //               <---parsing--->|               |
+  //                              <--unoccupied-->|
+  //   <---------total-malloced/realloced-------->|
+
+  char *m_buffer; // malloc/realloc base pointer of parse buffer
   const XML_Memory_Handling_Suite m_mem;
-  /* first character to be parsed */
-  const char *m_bufferPtr;
-  /* past last character to be parsed */
-  char *m_bufferEnd;
-  /* allocated end of m_buffer */
-  const char *m_bufferLim;
+  const char *m_bufferPtr; // first character to be parsed
+  char *m_bufferEnd;       // past last character to be parsed
+  const char *m_bufferLim; // allocated end of m_buffer
+
   XML_Index m_parseEndByteIndex;
   const char *m_parseEndPtr;
+  size_t m_partialTokenBytesBefore; /* used in heuristic to avoid O(n^2) */
+  XML_Bool m_reparseDeferralEnabled;
+  int m_lastBufferRequestSize;
   XML_Char *m_dataBuf;
   XML_Char *m_dataBufEnd;
   XML_StartElementHandler m_startElementHandler;
@@ -703,7 +744,7 @@ struct XML_ParserStruct {
   enum XML_ParamEntityParsing m_paramEntityParsing;
 #endif
   unsigned long m_hash_secret_salt;
-#ifdef XML_DTD
+#if XML_GE == 1
   ACCOUNTING m_accounting;
   ENTITY_STATS m_entity_stats;
 #endif
@@ -948,6 +989,47 @@ get_hash_secret_salt(XML_Parser parser) {
   return parser->m_hash_secret_salt;
 }
 
+static enum XML_Error
+callProcessor(XML_Parser parser, const char *start, const char *end,
+              const char **endPtr) {
+  const size_t have_now = EXPAT_SAFE_PTR_DIFF(end, start);
+
+  if (parser->m_reparseDeferralEnabled
+      && ! parser->m_parsingStatus.finalBuffer) {
+    // Heuristic: don't try to parse a partial token again until the amount of
+    // available data has increased significantly.
+    const size_t had_before = parser->m_partialTokenBytesBefore;
+    // ...but *do* try anyway if we're close to causing a reallocation.
+    size_t available_buffer
+        = EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer);
+#if XML_CONTEXT_BYTES > 0
+    available_buffer -= EXPAT_MIN(available_buffer, XML_CONTEXT_BYTES);
+#endif
+    available_buffer
+        += EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_bufferEnd);
+    // m_lastBufferRequestSize is never assigned a value < 0, so the cast is ok
+    const bool enough
+        = (have_now >= 2 * had_before)
+          || ((size_t)parser->m_lastBufferRequestSize > available_buffer);
+
+    if (! enough) {
+      *endPtr = start; // callers may expect this to be set
+      return XML_ERROR_NONE;
+    }
+  }
+  g_parseAttempts += 1;
+  const enum XML_Error ret = parser->m_processor(parser, start, end, endPtr);
+  if (ret == XML_ERROR_NONE) {
+    // if we consumed nothing, remember what we had on this parse attempt.
+    if (*endPtr == start) {
+      parser->m_partialTokenBytesBefore = have_now;
+    } else {
+      parser->m_partialTokenBytesBefore = 0;
+    }
+  }
+  return ret;
+}
+
 static XML_Bool /* only valid for root parser */
 startParsing(XML_Parser parser) {
   /* hash functions must be initialized before setContext() is called */
@@ -1129,6 +1211,9 @@ parserInit(XML_Parser parser, const XML_Char *encodingName) {
   parser->m_bufferEnd = parser->m_buffer;
   parser->m_parseEndByteIndex = 0;
   parser->m_parseEndPtr = NULL;
+  parser->m_partialTokenBytesBefore = 0;
+  parser->m_reparseDeferralEnabled = g_reparseDeferralEnabledDefault;
+  parser->m_lastBufferRequestSize = 0;
   parser->m_declElementType = NULL;
   parser->m_declAttributeId = NULL;
   parser->m_declEntity = NULL;
@@ -1163,7 +1248,7 @@ parserInit(XML_Parser parser, const XML_Char *encodingName) {
 #endif
   parser->m_hash_secret_salt = 0;
 
-#ifdef XML_DTD
+#if XML_GE == 1
   memset(&parser->m_accounting, 0, sizeof(ACCOUNTING));
   parser->m_accounting.debugLevel = getDebugLevel("EXPAT_ACCOUNTING_DEBUG", 0u);
   parser->m_accounting.maximumAmplificationFactor
@@ -1298,6 +1383,7 @@ XML_ExternalEntityParserCreate(XML_Parser oldParser, const XML_Char *context,
      to worry which hash secrets each table has.
   */
   unsigned long oldhash_secret_salt;
+  XML_Bool oldReparseDeferralEnabled;
 
   /* Validate the oldParser parameter before we pull everything out of it */
   if (oldParser == NULL)
@@ -1342,6 +1428,7 @@ XML_ExternalEntityParserCreate(XML_Parser oldParser, const XML_Char *context,
      to worry which hash secrets each table has.
   */
   oldhash_secret_salt = parser->m_hash_secret_salt;
+  oldReparseDeferralEnabled = parser->m_reparseDeferralEnabled;
 
 #ifdef XML_DTD
   if (! context)
@@ -1394,6 +1481,7 @@ XML_ExternalEntityParserCreate(XML_Parser oldParser, const XML_Char *context,
   parser->m_defaultExpandInternalEntities = oldDefaultExpandInternalEntities;
   parser->m_ns_triplets = oldns_triplets;
   parser->m_hash_secret_salt = oldhash_secret_salt;
+  parser->m_reparseDeferralEnabled = oldReparseDeferralEnabled;
   parser->m_parentParser = oldParser;
 #ifdef XML_DTD
   parser->m_paramEntityParsing = oldParamEntityParsing;
@@ -1848,55 +1936,8 @@ XML_Parse(XML_Parser parser, const char *s, int len, int isFinal) {
     parser->m_parsingStatus.parsing = XML_PARSING;
   }
 
-  if (len == 0) {
-    parser->m_parsingStatus.finalBuffer = (XML_Bool)isFinal;
-    if (! isFinal)
-      return XML_STATUS_OK;
-    parser->m_positionPtr = parser->m_bufferPtr;
-    parser->m_parseEndPtr = parser->m_bufferEnd;
-
-    /* If data are left over from last buffer, and we now know that these
-       data are the final chunk of input, then we have to check them again
-       to detect errors based on that fact.
-    */
-    parser->m_errorCode
-        = parser->m_processor(parser, parser->m_bufferPtr,
-                              parser->m_parseEndPtr, &parser->m_bufferPtr);
-
-    if (parser->m_errorCode == XML_ERROR_NONE) {
-      switch (parser->m_parsingStatus.parsing) {
-      case XML_SUSPENDED:
-        /* It is hard to be certain, but it seems that this case
-         * cannot occur.  This code is cleaning up a previous parse
-         * with no new data (since len == 0).  Changing the parsing
-         * state requires getting to execute a handler function, and
-         * there doesn't seem to be an opportunity for that while in
-         * this circumstance.
-         *
-         * Given the uncertainty, we retain the code but exclude it
-         * from coverage tests.
-         *
-         * LCOV_EXCL_START
-         */
-        XmlUpdatePosition(parser->m_encoding, parser->m_positionPtr,
-                          parser->m_bufferPtr, &parser->m_position);
-        parser->m_positionPtr = parser->m_bufferPtr;
-        return XML_STATUS_SUSPENDED;
-        /* LCOV_EXCL_STOP */
-      case XML_INITIALIZED:
-      case XML_PARSING:
-        parser->m_parsingStatus.parsing = XML_FINISHED;
-        /* fall through */
-      default:
-        return XML_STATUS_OK;
-      }
-    }
-    parser->m_eventEndPtr = parser->m_eventPtr;
-    parser->m_processor = errorProcessor;
-    return XML_STATUS_ERROR;
-  }
-#ifndef XML_CONTEXT_BYTES
-  else if (parser->m_bufferPtr == parser->m_bufferEnd) {
+#if XML_CONTEXT_BYTES == 0
+  if (parser->m_bufferPtr == parser->m_bufferEnd) {
     const char *end;
     int nLeftOver;
     enum XML_Status result;
@@ -1907,12 +1948,15 @@ XML_Parse(XML_Parser parser, const char *s, int len, int isFinal) {
       parser->m_processor = errorProcessor;
       return XML_STATUS_ERROR;
     }
+    // though this isn't a buffer request, we assume that `len` is the app's
+    // preferred buffer fill size, and therefore save it here.
+    parser->m_lastBufferRequestSize = len;
     parser->m_parseEndByteIndex += len;
     parser->m_positionPtr = s;
     parser->m_parsingStatus.finalBuffer = (XML_Bool)isFinal;
 
     parser->m_errorCode
-        = parser->m_processor(parser, s, parser->m_parseEndPtr = s + len, &end);
+        = callProcessor(parser, s, parser->m_parseEndPtr = s + len, &end);
 
     if (parser->m_errorCode != XML_ERROR_NONE) {
       parser->m_eventEndPtr = parser->m_eventPtr;
@@ -1939,23 +1983,25 @@ XML_Parse(XML_Parser parser, const char *s, int len, int isFinal) {
                       &parser->m_position);
     nLeftOver = s + len - end;
     if (nLeftOver) {
-      if (parser->m_buffer == NULL
-          || nLeftOver > parser->m_bufferLim - parser->m_buffer) {
-        /* avoid _signed_ integer overflow */
-        char *temp = NULL;
-        const int bytesToAllocate = (int)((unsigned)len * 2U);
-        if (bytesToAllocate > 0) {
-          temp = (char *)REALLOC(parser, parser->m_buffer, bytesToAllocate);
-        }
-        if (temp == NULL) {
-          parser->m_errorCode = XML_ERROR_NO_MEMORY;
-          parser->m_eventPtr = parser->m_eventEndPtr = NULL;
-          parser->m_processor = errorProcessor;
-          return XML_STATUS_ERROR;
-        }
-        parser->m_buffer = temp;
-        parser->m_bufferLim = parser->m_buffer + bytesToAllocate;
+      // Back up and restore the parsing status to avoid XML_ERROR_SUSPENDED
+      // (and XML_ERROR_FINISHED) from XML_GetBuffer.
+      const enum XML_Parsing originalStatus = parser->m_parsingStatus.parsing;
+      parser->m_parsingStatus.parsing = XML_PARSING;
+      void *const temp = XML_GetBuffer(parser, nLeftOver);
+      parser->m_parsingStatus.parsing = originalStatus;
+      // GetBuffer may have overwritten this, but we want to remember what the
+      // app requested, not how many bytes were left over after parsing.
+      parser->m_lastBufferRequestSize = len;
+      if (temp == NULL) {
+        // NOTE: parser->m_errorCode has already been set by XML_GetBuffer().
+        parser->m_eventPtr = parser->m_eventEndPtr = NULL;
+        parser->m_processor = errorProcessor;
+        return XML_STATUS_ERROR;
       }
+      // Since we know that the buffer was empty and XML_CONTEXT_BYTES is 0, we
+      // don't have any data to preserve, and can copy straight into the start
+      // of the buffer rather than the GetBuffer return pointer (which may be
+      // pointing further into the allocated buffer).
       memcpy(parser->m_buffer, end, nLeftOver);
     }
     parser->m_bufferPtr = parser->m_buffer;
@@ -1966,16 +2012,15 @@ XML_Parse(XML_Parser parser, const char *s, int len, int isFinal) {
     parser->m_eventEndPtr = parser->m_bufferPtr;
     return result;
   }
-#endif /* not defined XML_CONTEXT_BYTES */
-  else {
-    void *buff = XML_GetBuffer(parser, len);
-    if (buff == NULL)
-      return XML_STATUS_ERROR;
-    else {
-      memcpy(buff, s, len);
-      return XML_ParseBuffer(parser, len, isFinal);
-    }
+#endif /* XML_CONTEXT_BYTES == 0 */
+  void *buff = XML_GetBuffer(parser, len);
+  if (buff == NULL)
+    return XML_STATUS_ERROR;
+  if (len > 0) {
+    assert(s != NULL); // make sure s==NULL && len!=0 was rejected above
+    memcpy(buff, s, len);
   }
+  return XML_ParseBuffer(parser, len, isFinal);
 }
 
 enum XML_Status XMLCALL
@@ -2015,8 +2060,8 @@ XML_ParseBuffer(XML_Parser parser, int len, int isFinal) {
   parser->m_parseEndByteIndex += len;
   parser->m_parsingStatus.finalBuffer = (XML_Bool)isFinal;
 
-  parser->m_errorCode = parser->m_processor(
-      parser, start, parser->m_parseEndPtr, &parser->m_bufferPtr);
+  parser->m_errorCode = callProcessor(parser, start, parser->m_parseEndPtr,
+                                      &parser->m_bufferPtr);
 
   if (parser->m_errorCode != XML_ERROR_NONE) {
     parser->m_eventEndPtr = parser->m_eventPtr;
@@ -2061,10 +2106,14 @@ XML_GetBuffer(XML_Parser parser, int len) {
   default:;
   }
 
-  if (len > EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_bufferEnd)) {
-#ifdef XML_CONTEXT_BYTES
+  // whether or not the request succeeds, `len` seems to be the app's preferred
+  // buffer fill size; remember it.
+  parser->m_lastBufferRequestSize = len;
+  if (len > EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_bufferEnd)
+      || parser->m_buffer == NULL) {
+#if XML_CONTEXT_BYTES > 0
     int keep;
-#endif /* defined XML_CONTEXT_BYTES */
+#endif /* XML_CONTEXT_BYTES > 0 */
     /* Do not invoke signed arithmetic overflow: */
     int neededSize = (int)((unsigned)len
                            + (unsigned)EXPAT_SAFE_PTR_DIFF(
@@ -2073,7 +2122,7 @@ XML_GetBuffer(XML_Parser parser, int len) {
       parser->m_errorCode = XML_ERROR_NO_MEMORY;
       return NULL;
     }
-#ifdef XML_CONTEXT_BYTES
+#if XML_CONTEXT_BYTES > 0
     keep = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer);
     if (keep > XML_CONTEXT_BYTES)
       keep = XML_CONTEXT_BYTES;
@@ -2083,10 +2132,11 @@ XML_GetBuffer(XML_Parser parser, int len) {
       return NULL;
     }
     neededSize += keep;
-#endif /* defined XML_CONTEXT_BYTES */
-    if (neededSize
-        <= EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_buffer)) {
-#ifdef XML_CONTEXT_BYTES
+#endif /* XML_CONTEXT_BYTES > 0 */
+    if (parser->m_buffer && parser->m_bufferPtr
+        && neededSize
+               <= EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_buffer)) {
+#if XML_CONTEXT_BYTES > 0
       if (keep < EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer)) {
         int offset
             = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer)
@@ -2099,19 +2149,17 @@ XML_GetBuffer(XML_Parser parser, int len) {
         parser->m_bufferPtr -= offset;
       }
 #else
-      if (parser->m_buffer && parser->m_bufferPtr) {
-        memmove(parser->m_buffer, parser->m_bufferPtr,
-                EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr));
-        parser->m_bufferEnd
-            = parser->m_buffer
-              + EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr);
-        parser->m_bufferPtr = parser->m_buffer;
-      }
-#endif /* not defined XML_CONTEXT_BYTES */
+      memmove(parser->m_buffer, parser->m_bufferPtr,
+              EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr));
+      parser->m_bufferEnd
+          = parser->m_buffer
+            + EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr);
+      parser->m_bufferPtr = parser->m_buffer;
+#endif /* XML_CONTEXT_BYTES > 0 */
     } else {
       char *newBuf;
       int bufferSize
-          = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_bufferPtr);
+          = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_buffer);
       if (bufferSize == 0)
         bufferSize = INIT_BUFFER_SIZE;
       do {
@@ -2128,7 +2176,7 @@ XML_GetBuffer(XML_Parser parser, int len) {
         return NULL;
       }
       parser->m_bufferLim = newBuf + bufferSize;
-#ifdef XML_CONTEXT_BYTES
+#if XML_CONTEXT_BYTES > 0
       if (parser->m_bufferPtr) {
         memcpy(newBuf, &parser->m_bufferPtr[-keep],
                EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr)
@@ -2158,7 +2206,7 @@ XML_GetBuffer(XML_Parser parser, int len) {
         parser->m_bufferEnd = newBuf;
       }
       parser->m_bufferPtr = parser->m_buffer = newBuf;
-#endif /* not defined XML_CONTEXT_BYTES */
+#endif /* XML_CONTEXT_BYTES > 0 */
     }
     parser->m_eventPtr = parser->m_eventEndPtr = NULL;
     parser->m_positionPtr = NULL;
@@ -2208,7 +2256,7 @@ XML_ResumeParser(XML_Parser parser) {
   }
   parser->m_parsingStatus.parsing = XML_PARSING;
 
-  parser->m_errorCode = parser->m_processor(
+  parser->m_errorCode = callProcessor(
       parser, parser->m_bufferPtr, parser->m_parseEndPtr, &parser->m_bufferPtr);
 
   if (parser->m_errorCode != XML_ERROR_NONE) {
@@ -2272,7 +2320,7 @@ XML_GetCurrentByteCount(XML_Parser parser) {
 
 const char *XMLCALL
 XML_GetInputContext(XML_Parser parser, int *offset, int *size) {
-#ifdef XML_CONTEXT_BYTES
+#if XML_CONTEXT_BYTES > 0
   if (parser == NULL)
     return NULL;
   if (parser->m_eventPtr && parser->m_buffer) {
@@ -2286,7 +2334,7 @@ XML_GetInputContext(XML_Parser parser, int *offset, int *size) {
   (void)parser;
   (void)offset;
   (void)size;
-#endif /* defined XML_CONTEXT_BYTES */
+#endif /* XML_CONTEXT_BYTES > 0 */
   return (const char *)0;
 }
 
@@ -2506,7 +2554,7 @@ XML_GetFeatureList(void) {
 #ifdef XML_DTD
       {XML_FEATURE_DTD, XML_L("XML_DTD"), 0},
 #endif
-#ifdef XML_CONTEXT_BYTES
+#if XML_CONTEXT_BYTES > 0
       {XML_FEATURE_CONTEXT_BYTES, XML_L("XML_CONTEXT_BYTES"),
        XML_CONTEXT_BYTES},
 #endif
@@ -2522,8 +2570,9 @@ XML_GetFeatureList(void) {
 #ifdef XML_ATTR_INFO
       {XML_FEATURE_ATTR_INFO, XML_L("XML_ATTR_INFO"), 0},
 #endif
-#ifdef XML_DTD
-      /* Added in Expat 2.4.0. */
+#if XML_GE == 1
+      /* Added in Expat 2.4.0 for XML_DTD defined and
+       * added in Expat 2.6.0 for XML_GE == 1. */
       {XML_FEATURE_BILLION_LAUGHS_ATTACK_PROTECTION_MAXIMUM_AMPLIFICATION_DEFAULT,
        XML_L("XML_BLAP_MAX_AMP"),
        (long int)
@@ -2531,13 +2580,15 @@ XML_GetFeatureList(void) {
       {XML_FEATURE_BILLION_LAUGHS_ATTACK_PROTECTION_ACTIVATION_THRESHOLD_DEFAULT,
        XML_L("XML_BLAP_ACT_THRES"),
        EXPAT_BILLION_LAUGHS_ATTACK_PROTECTION_ACTIVATION_THRESHOLD_DEFAULT},
+      /* Added in Expat 2.6.0. */
+      {XML_FEATURE_GE, XML_L("XML_GE"), 0},
 #endif
       {XML_FEATURE_END, NULL, 0}};
 
   return features;
 }
 
-#ifdef XML_DTD
+#if XML_GE == 1
 XML_Bool XMLCALL
 XML_SetBillionLaughsAttackProtectionMaximumAmplification(
     XML_Parser parser, float maximumAmplificationFactor) {
@@ -2559,7 +2610,16 @@ XML_SetBillionLaughsAttackProtectionActivationThreshold(
   parser->m_accounting.activationThresholdBytes = activationThresholdBytes;
   return XML_TRUE;
 }
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
+
+XML_Bool XMLCALL
+XML_SetReparseDeferralEnabled(XML_Parser parser, XML_Bool enabled) {
+  if (parser != NULL && (enabled == XML_TRUE || enabled == XML_FALSE)) {
+    parser->m_reparseDeferralEnabled = enabled;
+    return XML_TRUE;
+  }
+  return XML_FALSE;
+}
 
 /* Initially tag->rawName always points into the parse buffer;
    for those TAG instances opened while the current parse buffer was
@@ -2581,7 +2641,7 @@ storeRawNames(XML_Parser parser) {
     */
     if (tag->rawName == rawNameBuf)
       break;
-    /* For re-use purposes we need to ensure that the
+    /* For reuse purposes we need to ensure that the
        size of tag->buf is a multiple of sizeof(XML_Char).
     */
     rawNameLen = ROUND_UP(tag->rawNameLength, sizeof(XML_Char));
@@ -2645,13 +2705,13 @@ externalEntityInitProcessor2(XML_Parser parser, const char *start,
   int tok = XmlContentTok(parser->m_encoding, start, end, &next);
   switch (tok) {
   case XML_TOK_BOM:
-#ifdef XML_DTD
+#if XML_GE == 1
     if (! accountingDiffTolerated(parser, tok, start, next, __LINE__,
                                   XML_ACCOUNT_DIRECT)) {
       accountingOnAbort(parser);
       return XML_ERROR_AMPLIFICATION_LIMIT_BREACH;
     }
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
 
     /* If we are at the end of the buffer, this would cause the next stage,
        i.e. externalEntityInitProcessor3, to pass control directly to
@@ -2765,7 +2825,7 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
   for (;;) {
     const char *next = s; /* XmlContentTok doesn't always set the last arg */
     int tok = XmlContentTok(enc, s, end, &next);
-#ifdef XML_DTD
+#if XML_GE == 1
     const char *accountAfter
         = ((tok == XML_TOK_TRAILING_RSQB) || (tok == XML_TOK_TRAILING_CR))
               ? (haveMore ? s /* i.e. 0 bytes */ : end)
@@ -2831,14 +2891,14 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
       XML_Char ch = (XML_Char)XmlPredefinedEntityName(
           enc, s + enc->minBytesPerChar, next - enc->minBytesPerChar);
       if (ch) {
-#ifdef XML_DTD
+#if XML_GE == 1
         /* NOTE: We are replacing 4-6 characters original input for 1 character
          *       so there is no amplification and hence recording without
          *       protection. */
         accountingDiffTolerated(parser, tok, (char *)&ch,
                                 ((char *)&ch) + sizeof(XML_Char), __LINE__,
                                 XML_ACCOUNT_ENTITY_EXPANSION);
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
         if (parser->m_characterDataHandler)
           parser->m_characterDataHandler(parser->m_handlerArg, &ch, 1);
         else if (parser->m_defaultHandler)
@@ -3039,13 +3099,13 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
           if (parser->m_ns && localPart) {
             /* localPart and prefix may have been overwritten in
                tag->name.str, since this points to the binding->uri
-               buffer which gets re-used; so we have to add them again
+               buffer which gets reused; so we have to add them again
             */
             uri = (XML_Char *)tag->name.str + tag->name.uriLen;
             /* don't need to check for space - already done in storeAtts() */
             while (*localPart)
               *uri++ = *localPart++;
-            prefix = (XML_Char *)tag->name.prefix;
+            prefix = tag->name.prefix;
             if (parser->m_ns_triplets && prefix) {
               *uri++ = parser->m_namespaceSeparator;
               while (*prefix)
@@ -3112,7 +3172,7 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
          However, now we have a start/endCdataSectionHandler, so it seems
          easier to let the user deal with this.
       */
-      else if (0 && parser->m_characterDataHandler)
+      else if ((0) && parser->m_characterDataHandler)
         parser->m_characterDataHandler(parser->m_handlerArg, parser->m_dataBuf,
                                        0);
       /* END disabled code */
@@ -3141,8 +3201,8 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
               (int)(dataPtr - (ICHAR *)parser->m_dataBuf));
         } else
           parser->m_characterDataHandler(
-              parser->m_handlerArg, (XML_Char *)s,
-              (int)((XML_Char *)end - (XML_Char *)s));
+              parser->m_handlerArg, (const XML_Char *)s,
+              (int)((const XML_Char *)end - (const XML_Char *)s));
       } else if (parser->m_defaultHandler)
         reportDefault(parser, enc, s, end);
       /* We are at the end of the final buffer, should we check for
@@ -3175,8 +3235,8 @@ doContent(XML_Parser parser, int startTagLevel, const ENCODING *enc,
             *eventPP = s;
           }
         } else
-          charDataHandler(parser->m_handlerArg, (XML_Char *)s,
-                          (int)((XML_Char *)next - (XML_Char *)s));
+          charDataHandler(parser->m_handlerArg, (const XML_Char *)s,
+                          (int)((const XML_Char *)next - (const XML_Char *)s));
       } else if (parser->m_defaultHandler)
         reportDefault(parser, enc, s, next);
     } break;
@@ -4040,7 +4100,7 @@ doCdataSection(XML_Parser parser, const ENCODING *enc, const char **startPtr,
   for (;;) {
     const char *next = s; /* in case of XML_TOK_NONE or XML_TOK_PARTIAL */
     int tok = XmlCdataSectionTok(enc, s, end, &next);
-#ifdef XML_DTD
+#if XML_GE == 1
     if (! accountingDiffTolerated(parser, tok, s, next, __LINE__, account)) {
       accountingOnAbort(parser);
       return XML_ERROR_AMPLIFICATION_LIMIT_BREACH;
@@ -4055,7 +4115,7 @@ doCdataSection(XML_Parser parser, const ENCODING *enc, const char **startPtr,
         parser->m_endCdataSectionHandler(parser->m_handlerArg);
       /* BEGIN disabled code */
       /* see comment under XML_TOK_CDATA_SECT_OPEN */
-      else if (0 && parser->m_characterDataHandler)
+      else if ((0) && parser->m_characterDataHandler)
         parser->m_characterDataHandler(parser->m_handlerArg, parser->m_dataBuf,
                                        0);
       /* END disabled code */
@@ -4091,8 +4151,8 @@ doCdataSection(XML_Parser parser, const ENCODING *enc, const char **startPtr,
             *eventPP = s;
           }
         } else
-          charDataHandler(parser->m_handlerArg, (XML_Char *)s,
-                          (int)((XML_Char *)next - (XML_Char *)s));
+          charDataHandler(parser->m_handlerArg, (const XML_Char *)s,
+                          (int)((const XML_Char *)next - (const XML_Char *)s));
       } else if (parser->m_defaultHandler)
         reportDefault(parser, enc, s, next);
     } break;
@@ -4192,7 +4252,7 @@ doIgnoreSection(XML_Parser parser, const ENCODING *enc, const char **startPtr,
   *eventPP = s;
   *startPtr = NULL;
   tok = XmlIgnoreSectionTok(enc, s, end, &next);
-#  ifdef XML_DTD
+#  if XML_GE == 1
   if (! accountingDiffTolerated(parser, tok, s, next, __LINE__,
                                 XML_ACCOUNT_DIRECT)) {
     accountingOnAbort(parser);
@@ -4284,7 +4344,7 @@ processXmlDecl(XML_Parser parser, int isGeneralTextEntity, const char *s,
   const XML_Char *storedversion = NULL;
   int standalone = -1;
 
-#ifdef XML_DTD
+#if XML_GE == 1
   if (! accountingDiffTolerated(parser, XML_TOK_XML_DECL, s, next, __LINE__,
                                 XML_ACCOUNT_DIRECT)) {
     accountingOnAbort(parser);
@@ -4482,16 +4542,16 @@ entityValueInitProcessor(XML_Parser parser, const char *s, const char *end,
       parser->m_processor = entityValueProcessor;
       return entityValueProcessor(parser, next, end, nextPtr);
     }
-    /* If we are at the end of the buffer, this would cause XmlPrologTok to
-       return XML_TOK_NONE on the next call, which would then cause the
-       function to exit with *nextPtr set to s - that is what we want for other
-       tokens, but not for the BOM - we would rather like to skip it;
-       then, when this routine is entered the next time, XmlPrologTok will
-       return XML_TOK_INVALID, since the BOM is still in the buffer
+    /* XmlPrologTok has now set the encoding based on the BOM it found, and we
+       must move s and nextPtr forward to consume the BOM.
+
+       If we didn't, and got XML_TOK_NONE from the next XmlPrologTok call, we
+       would leave the BOM in the buffer and return. On the next call to this
+       function, our XmlPrologTok call would return XML_TOK_INVALID, since it
+       is not valid to have multiple BOMs.
     */
-    else if (tok == XML_TOK_BOM && next == end
-             && ! parser->m_parsingStatus.finalBuffer) {
-#  ifdef XML_DTD
+    else if (tok == XML_TOK_BOM) {
+#  if XML_GE == 1
       if (! accountingDiffTolerated(parser, tok, s, next, __LINE__,
                                     XML_ACCOUNT_DIRECT)) {
         accountingOnAbort(parser);
@@ -4500,7 +4560,7 @@ entityValueInitProcessor(XML_Parser parser, const char *s, const char *end,
 #  endif
 
       *nextPtr = next;
-      return XML_ERROR_NONE;
+      s = next;
     }
     /* If we get this token, we have the start of what might be a
        normal tag, but not a declaration (i.e. it doesn't begin with
@@ -4707,11 +4767,13 @@ doProlog(XML_Parser parser, const ENCODING *enc, const char *s, const char *end,
       }
     }
     role = XmlTokenRole(&parser->m_prologState, tok, s, next, enc);
-#ifdef XML_DTD
+#if XML_GE == 1
     switch (role) {
     case XML_ROLE_INSTANCE_START: // bytes accounted in contentProcessor
     case XML_ROLE_XML_DECL:       // bytes accounted in processXmlDecl
-    case XML_ROLE_TEXT_DECL:      // bytes accounted in processXmlDecl
+#  ifdef XML_DTD
+    case XML_ROLE_TEXT_DECL: // bytes accounted in processXmlDecl
+#  endif
       break;
     default:
       if (! accountingDiffTolerated(parser, tok, s, next, __LINE__, account)) {
@@ -5029,6 +5091,9 @@ doProlog(XML_Parser parser, const ENCODING *enc, const char *s, const char *end,
       break;
     case XML_ROLE_ENTITY_VALUE:
       if (dtd->keepProcessing) {
+#if XML_GE == 1
+        // This will store the given replacement text in
+        // parser->m_declEntity->textPtr.
         enum XML_Error result
             = storeEntityValue(parser, enc, s + enc->minBytesPerChar,
                                next - enc->minBytesPerChar, XML_ACCOUNT_NONE);
@@ -5049,6 +5114,25 @@ doProlog(XML_Parser parser, const ENCODING *enc, const char *s, const char *end,
           poolDiscard(&dtd->entityValuePool);
         if (result != XML_ERROR_NONE)
           return result;
+#else
+        // This will store "&amp;entity123;" in parser->m_declEntity->textPtr
+        // to end up as "&entity123;" in the handler.
+        if (parser->m_declEntity != NULL) {
+          const enum XML_Error result
+              = storeSelfEntityValue(parser, parser->m_declEntity);
+          if (result != XML_ERROR_NONE)
+            return result;
+
+          if (parser->m_entityDeclHandler) {
+            *eventEndPP = s;
+            parser->m_entityDeclHandler(
+                parser->m_handlerArg, parser->m_declEntity->name,
+                parser->m_declEntity->is_param, parser->m_declEntity->textPtr,
+                parser->m_declEntity->textLen, parser->m_curBase, 0, 0, 0);
+            handleDefault = XML_FALSE;
+          }
+        }
+#endif
       }
       break;
     case XML_ROLE_DOCTYPE_SYSTEM_ID:
@@ -5107,6 +5191,16 @@ doProlog(XML_Parser parser, const ENCODING *enc, const char *s, const char *end,
       }
       break;
     case XML_ROLE_ENTITY_COMPLETE:
+#if XML_GE == 0
+      // This will store "&amp;entity123;" in entity->textPtr
+      // to end up as "&entity123;" in the handler.
+      if (parser->m_declEntity != NULL) {
+        const enum XML_Error result
+            = storeSelfEntityValue(parser, parser->m_declEntity);
+        if (result != XML_ERROR_NONE)
+          return result;
+      }
+#endif
       if (dtd->keepProcessing && parser->m_declEntity
           && parser->m_entityDeclHandler) {
         *eventEndPP = s;
@@ -5648,7 +5742,7 @@ epilogProcessor(XML_Parser parser, const char *s, const char *end,
   for (;;) {
     const char *next = NULL;
     int tok = XmlPrologTok(parser->m_encoding, s, end, &next);
-#ifdef XML_DTD
+#if XML_GE == 1
     if (! accountingDiffTolerated(parser, tok, s, next, __LINE__,
                                   XML_ACCOUNT_DIRECT)) {
       accountingOnAbort(parser);
@@ -5728,7 +5822,7 @@ processInternalEntity(XML_Parser parser, ENTITY *entity, XML_Bool betweenDecl) {
       return XML_ERROR_NO_MEMORY;
   }
   entity->open = XML_TRUE;
-#ifdef XML_DTD
+#if XML_GE == 1
   entityTrackingOnOpen(parser, entity, __LINE__);
 #endif
   entity->processed = 0;
@@ -5761,10 +5855,10 @@ processInternalEntity(XML_Parser parser, ENTITY *entity, XML_Bool betweenDecl) {
     if (textEnd != next && parser->m_parsingStatus.parsing == XML_SUSPENDED) {
       entity->processed = (int)(next - textStart);
       parser->m_processor = internalEntityProcessor;
-    } else {
-#ifdef XML_DTD
+    } else if (parser->m_openInternalEntities->entity == entity) {
+#if XML_GE == 1
       entityTrackingOnClose(parser, entity, __LINE__);
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
       entity->open = XML_FALSE;
       parser->m_openInternalEntities = openEntity->next;
       /* put openEntity back in list of free instances */
@@ -5813,7 +5907,7 @@ internalEntityProcessor(XML_Parser parser, const char *s, const char *end,
     return result;
   }
 
-#ifdef XML_DTD
+#if XML_GE == 1
   entityTrackingOnClose(parser, entity, __LINE__);
 #endif
   entity->open = XML_FALSE;
@@ -5892,7 +5986,7 @@ appendAttributeValue(XML_Parser parser, const ENCODING *enc, XML_Bool isCdata,
     const char *next
         = ptr; /* XmlAttributeValueTok doesn't always set the last arg */
     int tok = XmlAttributeValueTok(enc, ptr, end, &next);
-#ifdef XML_DTD
+#if XML_GE == 1
     if (! accountingDiffTolerated(parser, tok, ptr, next, __LINE__, account)) {
       accountingOnAbort(parser);
       return XML_ERROR_AMPLIFICATION_LIMIT_BREACH;
@@ -5957,14 +6051,14 @@ appendAttributeValue(XML_Parser parser, const ENCODING *enc, XML_Bool isCdata,
       XML_Char ch = (XML_Char)XmlPredefinedEntityName(
           enc, ptr + enc->minBytesPerChar, next - enc->minBytesPerChar);
       if (ch) {
-#ifdef XML_DTD
+#if XML_GE == 1
         /* NOTE: We are replacing 4-6 characters original input for 1 character
          *       so there is no amplification and hence recording without
          *       protection. */
         accountingDiffTolerated(parser, tok, (char *)&ch,
                                 ((char *)&ch) + sizeof(XML_Char), __LINE__,
                                 XML_ACCOUNT_ENTITY_EXPANSION);
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
         if (! poolAppendChar(pool, ch))
           return XML_ERROR_NO_MEMORY;
         break;
@@ -6042,14 +6136,14 @@ appendAttributeValue(XML_Parser parser, const ENCODING *enc, XML_Bool isCdata,
         enum XML_Error result;
         const XML_Char *textEnd = entity->textPtr + entity->textLen;
         entity->open = XML_TRUE;
-#ifdef XML_DTD
+#if XML_GE == 1
         entityTrackingOnOpen(parser, entity, __LINE__);
 #endif
         result = appendAttributeValue(parser, parser->m_internalEncoding,
                                       isCdata, (const char *)entity->textPtr,
                                       (const char *)textEnd, pool,
                                       XML_ACCOUNT_ENTITY_EXPANSION);
-#ifdef XML_DTD
+#if XML_GE == 1
         entityTrackingOnClose(parser, entity, __LINE__);
 #endif
         entity->open = XML_FALSE;
@@ -6079,6 +6173,7 @@ appendAttributeValue(XML_Parser parser, const ENCODING *enc, XML_Bool isCdata,
   /* not reached */
 }
 
+#if XML_GE == 1
 static enum XML_Error
 storeEntityValue(XML_Parser parser, const ENCODING *enc,
                  const char *entityTextPtr, const char *entityTextEnd,
@@ -6086,12 +6181,12 @@ storeEntityValue(XML_Parser parser, const ENCODING *enc,
   DTD *const dtd = parser->m_dtd; /* save one level of indirection */
   STRING_POOL *pool = &(dtd->entityValuePool);
   enum XML_Error result = XML_ERROR_NONE;
-#ifdef XML_DTD
+#  ifdef XML_DTD
   int oldInEntityValue = parser->m_prologState.inEntityValue;
   parser->m_prologState.inEntityValue = 1;
-#else
+#  else
   UNUSED_P(account);
-#endif /* XML_DTD */
+#  endif /* XML_DTD */
   /* never return Null for the value argument in EntityDeclHandler,
      since this would indicate an external entity; therefore we
      have to make sure that entityValuePool.start is not null */
@@ -6105,18 +6200,16 @@ storeEntityValue(XML_Parser parser, const ENCODING *enc,
         = entityTextPtr; /* XmlEntityValueTok doesn't always set the last arg */
     int tok = XmlEntityValueTok(enc, entityTextPtr, entityTextEnd, &next);
 
-#ifdef XML_DTD
     if (! accountingDiffTolerated(parser, tok, entityTextPtr, next, __LINE__,
                                   account)) {
       accountingOnAbort(parser);
       result = XML_ERROR_AMPLIFICATION_LIMIT_BREACH;
       goto endEntityValue;
     }
-#endif
 
     switch (tok) {
     case XML_TOK_PARAM_ENTITY_REF:
-#ifdef XML_DTD
+#  ifdef XML_DTD
       if (parser->m_isParamEntity || enc != parser->m_encoding) {
         const XML_Char *name;
         ENTITY *entity;
@@ -6178,7 +6271,7 @@ storeEntityValue(XML_Parser parser, const ENCODING *enc,
         }
         break;
       }
-#endif /* XML_DTD */
+#  endif /* XML_DTD */
       /* In the internal subset, PE references are not legal
          within markup declarations, e.g entity values in this case. */
       parser->m_eventPtr = entityTextPtr;
@@ -6259,12 +6352,38 @@ storeEntityValue(XML_Parser parser, const ENCODING *enc,
     entityTextPtr = next;
   }
 endEntityValue:
-#ifdef XML_DTD
+#  ifdef XML_DTD
   parser->m_prologState.inEntityValue = oldInEntityValue;
-#endif /* XML_DTD */
+#  endif /* XML_DTD */
   return result;
 }
 
+#else /* XML_GE == 0 */
+
+static enum XML_Error
+storeSelfEntityValue(XML_Parser parser, ENTITY *entity) {
+  // This will store "&amp;entity123;" in entity->textPtr
+  // to end up as "&entity123;" in the handler.
+  const char *const entity_start = "&amp;";
+  const char *const entity_end = ";";
+
+  STRING_POOL *const pool = &(parser->m_dtd->entityValuePool);
+  if (! poolAppendString(pool, entity_start)
+      || ! poolAppendString(pool, entity->name)
+      || ! poolAppendString(pool, entity_end)) {
+    poolDiscard(pool);
+    return XML_ERROR_NO_MEMORY;
+  }
+
+  entity->textPtr = poolStart(pool);
+  entity->textLen = (int)(poolLength(pool));
+  poolFinish(pool);
+
+  return XML_ERROR_NONE;
+}
+
+#endif /* XML_GE == 0 */
+
 static void FASTCALL
 normalizeLines(XML_Char *s) {
   XML_Char *p;
@@ -6375,8 +6494,9 @@ reportDefault(XML_Parser parser, const ENCODING *enc, const char *s,
     } while ((convert_res != XML_CONVERT_COMPLETED)
              && (convert_res != XML_CONVERT_INPUT_INCOMPLETE));
   } else
-    parser->m_defaultHandler(parser->m_handlerArg, (XML_Char *)s,
-                             (int)((XML_Char *)end - (XML_Char *)s));
+    parser->m_defaultHandler(
+        parser->m_handlerArg, (const XML_Char *)s,
+        (int)((const XML_Char *)end - (const XML_Char *)s));
 }
 
 static int
@@ -6480,7 +6600,7 @@ getAttributeId(XML_Parser parser, const ENCODING *enc, const char *start,
   name = poolStoreString(&dtd->pool, enc, start, end);
   if (! name)
     return NULL;
-  /* skip quotation mark - its storage will be re-used (like in name[-1]) */
+  /* skip quotation mark - its storage will be reused (like in name[-1]) */
   ++name;
   id = (ATTRIBUTE_ID *)lookup(parser, &dtd->attributeIds, name,
                               sizeof(ATTRIBUTE_ID));
@@ -6630,6 +6750,10 @@ getContext(XML_Parser parser) {
 
 static XML_Bool
 setContext(XML_Parser parser, const XML_Char *context) {
+  if (context == NULL) {
+    return XML_FALSE;
+  }
+
   DTD *const dtd = parser->m_dtd; /* save one level of indirection */
   const XML_Char *s = context;
 
@@ -7220,7 +7344,7 @@ poolAppend(STRING_POOL *pool, const ENCODING *enc, const char *ptr,
     return NULL;
   for (;;) {
     const enum XML_Convert_Result convert_res = XmlConvert(
-        enc, &ptr, end, (ICHAR **)&(pool->ptr), (ICHAR *)pool->end);
+        enc, &ptr, end, (ICHAR **)&(pool->ptr), (const ICHAR *)pool->end);
     if ((convert_res == XML_CONVERT_COMPLETED)
         || (convert_res == XML_CONVERT_INPUT_INCOMPLETE))
       break;
@@ -7651,7 +7775,7 @@ copyString(const XML_Char *s, const XML_Memory_Handling_Suite *memsuite) {
   return result;
 }
 
-#ifdef XML_DTD
+#if XML_GE == 1
 
 static float
 accountingGetCurrentAmplification(XML_Parser rootParser) {
@@ -7672,7 +7796,7 @@ accountingReportStats(XML_Parser originParser, const char *epilog) {
   const XML_Parser rootParser = getRootParserOf(originParser, NULL);
   assert(! rootParser->m_parentParser);
 
-  if (rootParser->m_accounting.debugLevel < 1) {
+  if (rootParser->m_accounting.debugLevel == 0u) {
     return;
   }
 
@@ -7709,7 +7833,7 @@ accountingReportDiff(XML_Parser rootParser,
 
   /* Note: Performance is of no concern here */
   const char *walker = before;
-  if ((rootParser->m_accounting.debugLevel >= 3)
+  if ((rootParser->m_accounting.debugLevel >= 3u)
       || (after - before)
              <= (ptrdiff_t)(contextLength + ellipsisLength + contextLength)) {
     for (; walker < after; walker++) {
@@ -7774,7 +7898,7 @@ accountingDiffTolerated(XML_Parser originParser, int tok, const char *before,
         || (amplificationFactor
             <= rootParser->m_accounting.maximumAmplificationFactor);
 
-  if (rootParser->m_accounting.debugLevel >= 2) {
+  if (rootParser->m_accounting.debugLevel >= 2u) {
     accountingReportStats(rootParser, "");
     accountingReportDiff(rootParser, levelsAwayFromRootParser, before, after,
                          bytesMore, source_line, account);
@@ -7801,7 +7925,7 @@ static void
 entityTrackingReportStats(XML_Parser rootParser, ENTITY *entity,
                           const char *action, int sourceLine) {
   assert(! rootParser->m_parentParser);
-  if (rootParser->m_entity_stats.debugLevel < 1)
+  if (rootParser->m_entity_stats.debugLevel == 0u)
     return;
 
 #  if defined(XML_UNICODE)
@@ -8382,7 +8506,7 @@ unsignedCharToPrintable(unsigned char c) {
   assert(0); /* never gets here */
 }
 
-#endif /* XML_DTD */
+#endif /* XML_GE == 1 */
 
 static unsigned long
 getDebugLevel(const char *variableName, unsigned long defaultDebugLevel) {
@@ -8393,9 +8517,9 @@ getDebugLevel(const char *variableName, unsigned long defaultDebugLevel) {
   const char *const value = valueOrNull;
 
   errno = 0;
-  char *afterValue = (char *)value;
+  char *afterValue = NULL;
   unsigned long debugLevel = strtoul(value, &afterValue, 10);
-  if ((errno != 0) || (afterValue[0] != '\0')) {
+  if ((errno != 0) || (afterValue == value) || (afterValue[0] != '\0')) {
     errno = 0;
     return defaultDebugLevel;
   }
diff --git a/Modules/expat/xmlrole.c b/Modules/expat/xmlrole.c
index 3f0f5c150c..2c48bf4086 100644
--- a/Modules/expat/xmlrole.c
+++ b/Modules/expat/xmlrole.c
@@ -12,10 +12,10 @@
    Copyright (c) 2002-2006 Karl Waclawek <karl@waclawek.net>
    Copyright (c) 2002-2003 Fred L. Drake, Jr. <fdrake@users.sourceforge.net>
    Copyright (c) 2005-2009 Steven Solie <steven@solie.ca>
-   Copyright (c) 2016-2021 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2023 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2017      Rhodri James <rhodri@wildebeest.org.uk>
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
-   Copyright (c) 2021      Dong-hee Na <donghee.na@python.org>
+   Copyright (c) 2021      Donghee Na <donghee.na@python.org>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -38,7 +38,7 @@
    USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
 
-#include <expat_config.h>
+#include "expat_config.h"
 
 #include <stddef.h>
 
diff --git a/Modules/expat/xmlrole.h b/Modules/expat/xmlrole.h
index d6e1fa150a..a7904274c9 100644
--- a/Modules/expat/xmlrole.h
+++ b/Modules/expat/xmlrole.h
@@ -10,7 +10,7 @@
    Copyright (c) 2000      Clark Cooper <coopercc@users.sourceforge.net>
    Copyright (c) 2002      Karl Waclawek <karl@waclawek.net>
    Copyright (c) 2002      Fred L. Drake, Jr. <fdrake@users.sourceforge.net>
-   Copyright (c) 2017      Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2017-2024 Sebastian Pipping <sebastian@pipping.org>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -127,9 +127,9 @@ typedef struct prolog_state {
 #endif /* XML_DTD */
 } PROLOG_STATE;
 
-void XmlPrologStateInit(PROLOG_STATE *);
+void XmlPrologStateInit(PROLOG_STATE *state);
 #ifdef XML_DTD
-void XmlPrologStateInitExternalEntity(PROLOG_STATE *);
+void XmlPrologStateInitExternalEntity(PROLOG_STATE *state);
 #endif /* XML_DTD */
 
 #define XmlTokenRole(state, tok, ptr, end, enc)                                \
diff --git a/Modules/expat/xmltok.c b/Modules/expat/xmltok.c
index 2b7012a58b..29a66d72ce 100644
--- a/Modules/expat/xmltok.c
+++ b/Modules/expat/xmltok.c
@@ -12,7 +12,7 @@
    Copyright (c) 2002      Greg Stein <gstein@users.sourceforge.net>
    Copyright (c) 2002-2016 Karl Waclawek <karl@waclawek.net>
    Copyright (c) 2005-2009 Steven Solie <steven@solie.ca>
-   Copyright (c) 2016-2022 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2024 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2016      Pascal Cuoq <cuoq@trust-in-soft.com>
    Copyright (c) 2016      Don Lewis <truckman@apache.org>
    Copyright (c) 2017      Rhodri James <rhodri@wildebeest.org.uk>
@@ -20,8 +20,10 @@
    Copyright (c) 2017      Benbuck Nason <bnason@netflix.com>
    Copyright (c) 2017      Jos Gutirrez de la Concha <jose@zeroc.com>
    Copyright (c) 2019      David Loffredo <loffredo@steptools.com>
-   Copyright (c) 2021      Dong-hee Na <donghee.na@python.org>
+   Copyright (c) 2021      Donghee Na <donghee.na@python.org>
    Copyright (c) 2022      Martin Ettl <ettl.martin78@googlemail.com>
+   Copyright (c) 2022      Sean McBride <sean@rogue-research.com>
+   Copyright (c) 2023      Hanno Bck <hanno@gentoo.org>
    Licensed under the MIT license:
 
    Permission is  hereby granted,  free of charge,  to any  person obtaining
@@ -44,7 +46,7 @@
    USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
 
-#include <expat_config.h>
+#include "expat_config.h"
 
 #include <stddef.h>
 #include <string.h> /* memcpy */
@@ -76,7 +78,7 @@
 #define VTABLE VTABLE1, PREFIX(toUtf8), PREFIX(toUtf16)
 
 #define UCS2_GET_NAMING(pages, hi, lo)                                         \
-  (namingBitmap[(pages[hi] << 3) + ((lo) >> 5)] & (1u << ((lo)&0x1F)))
+  (namingBitmap[(pages[hi] << 3) + ((lo) >> 5)] & (1u << ((lo) & 0x1F)))
 
 /* A 2 byte UTF-8 representation splits the characters 11 bits between
    the bottom 5 and 6 bits of the bytes.  We need 8 bits to index into
@@ -100,7 +102,7 @@
    & (1u << (((byte)[2]) & 0x1F)))
 
 /* Detection of invalid UTF-8 sequences is based on Table 3.1B
-   of Unicode 3.2: http://www.unicode.org/unicode/reports/tr28/
+   of Unicode 3.2: https://www.unicode.org/unicode/reports/tr28/
    with the additional restriction of not allowing the Unicode
    code points 0xFFFF and 0xFFFE (sequences EF,BF,BF and EF,BF,BE).
    Implementation details:
@@ -225,7 +227,7 @@ struct normal_encoding {
       /* isNmstrt2 */ NULL, /* isNmstrt3 */ NULL, /* isNmstrt4 */ NULL,        \
       /* isInvalid2 */ NULL, /* isInvalid3 */ NULL, /* isInvalid4 */ NULL
 
-static int FASTCALL checkCharRefNumber(int);
+static int FASTCALL checkCharRefNumber(int result);
 
 #include "xmltok_impl.h"
 #include "ascii.h"
@@ -243,7 +245,7 @@ static int FASTCALL checkCharRefNumber(int);
 #endif
 
 #define SB_BYTE_TYPE(enc, p)                                                   \
-  (((struct normal_encoding *)(enc))->type[(unsigned char)*(p)])
+  (((const struct normal_encoding *)(enc))->type[(unsigned char)*(p)])
 
 #ifdef XML_MIN_SIZE
 static int PTRFASTCALL
@@ -407,7 +409,7 @@ utf8_toUtf16(const ENCODING *enc, const char **fromP, const char *fromLim,
   unsigned short *to = *toP;
   const char *from = *fromP;
   while (from < fromLim && to < toLim) {
-    switch (((struct normal_encoding *)enc)->type[(unsigned char)*from]) {
+    switch (SB_BYTE_TYPE(enc, from)) {
     case BT_LEAD2:
       if (fromLim - from < 2) {
         res = XML_CONVERT_INPUT_INCOMPLETE;
@@ -715,31 +717,26 @@ unicode_byte_type(char hi, char lo) {
       return res;                                                              \
   }
 
-#define SET2(ptr, ch) (((ptr)[0] = ((ch)&0xff)), ((ptr)[1] = ((ch) >> 8)))
 #define GET_LO(ptr) ((unsigned char)(ptr)[0])
 #define GET_HI(ptr) ((unsigned char)(ptr)[1])
 
 DEFINE_UTF16_TO_UTF8(little2_)
 DEFINE_UTF16_TO_UTF16(little2_)
 
-#undef SET2
 #undef GET_LO
 #undef GET_HI
 
-#define SET2(ptr, ch) (((ptr)[0] = ((ch) >> 8)), ((ptr)[1] = ((ch)&0xFF)))
 #define GET_LO(ptr) ((unsigned char)(ptr)[1])
 #define GET_HI(ptr) ((unsigned char)(ptr)[0])
 
 DEFINE_UTF16_TO_UTF8(big2_)
 DEFINE_UTF16_TO_UTF16(big2_)
 
-#undef SET2
 #undef GET_LO
 #undef GET_HI
 
 #define LITTLE2_BYTE_TYPE(enc, p)                                              \
-  ((p)[1] == 0 ? ((struct normal_encoding *)(enc))->type[(unsigned char)*(p)]  \
-               : unicode_byte_type((p)[1], (p)[0]))
+  ((p)[1] == 0 ? SB_BYTE_TYPE(enc, p) : unicode_byte_type((p)[1], (p)[0]))
 #define LITTLE2_BYTE_TO_ASCII(p) ((p)[1] == 0 ? (p)[0] : -1)
 #define LITTLE2_CHAR_MATCHES(p, c) ((p)[1] == 0 && (p)[0] == (c))
 #define LITTLE2_IS_NAME_CHAR_MINBPC(p)                                         \
@@ -872,9 +869,7 @@ static const struct normal_encoding internal_little2_encoding
 #endif
 
 #define BIG2_BYTE_TYPE(enc, p)                                                 \
-  ((p)[0] == 0                                                                 \
-       ? ((struct normal_encoding *)(enc))->type[(unsigned char)(p)[1]]        \
-       : unicode_byte_type((p)[0], (p)[1]))
+  ((p)[0] == 0 ? SB_BYTE_TYPE(enc, p + 1) : unicode_byte_type((p)[0], (p)[1]))
 #define BIG2_BYTE_TO_ASCII(p) ((p)[0] == 0 ? (p)[1] : -1)
 #define BIG2_CHAR_MATCHES(p, c) ((p)[0] == 0 && (p)[1] == (c))
 #define BIG2_IS_NAME_CHAR_MINBPC(p)                                            \
diff --git a/Modules/expat/xmltok.h b/Modules/expat/xmltok.h
index 6f630c2f9b..c51fce1ec1 100644
--- a/Modules/expat/xmltok.h
+++ b/Modules/expat/xmltok.h
@@ -10,7 +10,7 @@
    Copyright (c) 2000      Clark Cooper <coopercc@users.sourceforge.net>
    Copyright (c) 2002      Fred L. Drake, Jr. <fdrake@users.sourceforge.net>
    Copyright (c) 2002-2005 Karl Waclawek <karl@waclawek.net>
-   Copyright (c) 2016-2017 Sebastian Pipping <sebastian@pipping.org>
+   Copyright (c) 2016-2024 Sebastian Pipping <sebastian@pipping.org>
    Copyright (c) 2017      Rhodri James <rhodri@wildebeest.org.uk>
    Licensed under the MIT license:
 
@@ -289,7 +289,8 @@ int XmlParseXmlDecl(int isGeneralTextEntity, const ENCODING *enc,
                     const char **encodingNamePtr,
                     const ENCODING **namedEncodingPtr, int *standalonePtr);
 
-int XmlInitEncoding(INIT_ENCODING *, const ENCODING **, const char *name);
+int XmlInitEncoding(INIT_ENCODING *p, const ENCODING **encPtr,
+                    const char *name);
 const ENCODING *XmlGetUtf8InternalEncoding(void);
 const ENCODING *XmlGetUtf16InternalEncoding(void);
 int FASTCALL XmlUtf8Encode(int charNumber, char *buf);
@@ -307,7 +308,8 @@ int XmlParseXmlDeclNS(int isGeneralTextEntity, const ENCODING *enc,
                       const char **encodingNamePtr,
                       const ENCODING **namedEncodingPtr, int *standalonePtr);
 
-int XmlInitEncodingNS(INIT_ENCODING *, const ENCODING **, const char *name);
+int XmlInitEncodingNS(INIT_ENCODING *p, const ENCODING **encPtr,
+                      const char *name);
 const ENCODING *XmlGetUtf8InternalEncodingNS(void);
 const ENCODING *XmlGetUtf16InternalEncodingNS(void);
 ENCODING *XmlInitUnknownEncodingNS(void *mem, int *table, CONVERTER convert,
diff --git a/Modules/expat/xmltok_impl.c b/Modules/expat/xmltok_impl.c
index 1971d74bf8..239a2d06c4 100644
--- a/Modules/expat/xmltok_impl.c
+++ b/Modules/expat/xmltok_impl.c
@@ -126,7 +126,7 @@
 #  endif
 
 #  define HAS_CHARS(enc, ptr, end, count)                                      \
-    ((end) - (ptr) >= ((count)*MINBPC(enc)))
+    ((end) - (ptr) >= ((count) * MINBPC(enc)))
 
 #  define HAS_CHAR(enc, ptr, end) HAS_CHARS(enc, ptr, end, 1)
 
diff --git a/Modules/gcmodule.c b/Modules/gcmodule.c
index 149a6a022d..f8c774cbb7 100644
--- a/Modules/gcmodule.c
+++ b/Modules/gcmodule.c
@@ -2288,6 +2288,9 @@ void
 _Py_RunGC(PyThreadState *tstate)
 {
     GCState *gcstate = &tstate->interp->gc;
+    if (!gcstate->enabled) {
+        return;
+    }
     gcstate->collecting = 1;
     gc_collect_generations(tstate);
     gcstate->collecting = 0;
diff --git a/Modules/getpath.c b/Modules/getpath.c
index b9914a0c8e..0a31000075 100644
--- a/Modules/getpath.c
+++ b/Modules/getpath.c
@@ -259,6 +259,10 @@ getpath_joinpath(PyObject *Py_UNUSED(self), PyObject *args)
     }
     /* Convert all parts to wchar and accumulate max final length */
     wchar_t **parts = (wchar_t **)PyMem_Malloc(n * sizeof(wchar_t *));
+    if (parts == NULL) {
+        PyErr_NoMemory();
+        return NULL;
+    }
     memset(parts, 0, n * sizeof(wchar_t *));
     Py_ssize_t cchFinal = 0;
     Py_ssize_t first = 0;
diff --git a/Modules/itertoolsmodule.c b/Modules/itertoolsmodule.c
index 24e77c485d..d42f9dd076 100644
--- a/Modules/itertoolsmodule.c
+++ b/Modules/itertoolsmodule.c
@@ -810,10 +810,9 @@ teedataobject_traverse(teedataobject *tdo, visitproc visit, void * arg)
 }
 
 static void
-teedataobject_safe_decref(PyObject *obj, PyTypeObject *tdo_type)
+teedataobject_safe_decref(PyObject *obj)
 {
-    while (obj && Py_IS_TYPE(obj, tdo_type) &&
-           Py_REFCNT(obj) == 1) {
+    while (obj && Py_REFCNT(obj) == 1) {
         PyObject *nextlink = ((teedataobject *)obj)->nextlink;
         ((teedataobject *)obj)->nextlink = NULL;
         Py_SETREF(obj, nextlink);
@@ -832,8 +831,7 @@ teedataobject_clear(teedataobject *tdo)
         Py_CLEAR(tdo->values[i]);
     tmp = tdo->nextlink;
     tdo->nextlink = NULL;
-    itertools_state *state = get_module_state_by_cls(Py_TYPE(tdo));
-    teedataobject_safe_decref(tmp, state->teedataobject_type);
+    teedataobject_safe_decref(tmp);
     return 0;
 }
 
@@ -4618,15 +4616,15 @@ batched(p, n) --> [p0, p1, ..., p_n-1], [p_n, p_n+1, ..., p_2n-1], ...\n\
 chain(p, q, ...) --> p0, p1, ... plast, q0, q1, ...\n\
 chain.from_iterable([p, q, ...]) --> p0, p1, ... plast, q0, q1, ...\n\
 compress(data, selectors) --> (d[0] if s[0]), (d[1] if s[1]), ...\n\
-dropwhile(pred, seq) --> seq[n], seq[n+1], starting when pred fails\n\
+dropwhile(predicate, seq) --> seq[n], seq[n+1], starting when predicate fails\n\
 groupby(iterable[, keyfunc]) --> sub-iterators grouped by value of keyfunc(v)\n\
-filterfalse(pred, seq) --> elements of seq where pred(elem) is False\n\
+filterfalse(predicate, seq) --> elements of seq where predicate(elem) is False\n\
 islice(seq, [start,] stop [, step]) --> elements from\n\
        seq[start:stop:step]\n\
 pairwise(s) --> (s[0],s[1]), (s[1],s[2]), (s[2], s[3]), ...\n\
 starmap(fun, seq) --> fun(*seq[0]), fun(*seq[1]), ...\n\
 tee(it, n=2) --> (it1, it2 , ... itn) splits one iterator into n\n\
-takewhile(pred, seq) --> seq[0], seq[1], until pred fails\n\
+takewhile(predicate, seq) --> seq[0], seq[1], until predicate fails\n\
 zip_longest(p, q, ...) --> (p[0], q[0]), (p[1], q[1]), ...\n\
 \n\
 Combinatoric generators:\n\
diff --git a/Modules/md5module.c b/Modules/md5module.c
index 2122f8b18b..dcc9da38d7 100644
--- a/Modules/md5module.c
+++ b/Modules/md5module.c
@@ -52,7 +52,7 @@ typedef struct {
     // Prevents undefined behavior via multiple threads entering the C API.
     // The lock will be NULL before threaded access has been enabled.
     PyThread_type_lock lock;
-    Hacl_Streaming_MD5_state *hash_state;
+    Hacl_Hash_MD5_state_t *hash_state;
 } MD5object;
 
 #include "clinic/md5module.c.h"
@@ -90,11 +90,11 @@ MD5_traverse(PyObject *ptr, visitproc visit, void *arg)
 static void
 MD5_dealloc(MD5object *ptr)
 {
-    Hacl_Streaming_MD5_legacy_free(ptr->hash_state);
+    Hacl_Hash_MD5_free(ptr->hash_state);
     if (ptr->lock != NULL) {
         PyThread_free_lock(ptr->lock);
     }
-    PyTypeObject *tp = Py_TYPE(ptr);
+    PyTypeObject *tp = Py_TYPE((PyObject*)ptr);
     PyObject_GC_UnTrack(ptr);
     PyObject_GC_Del(ptr);
     Py_DECREF(tp);
@@ -122,7 +122,7 @@ MD5Type_copy_impl(MD5object *self, PyTypeObject *cls)
         return NULL;
 
     ENTER_HASHLIB(self);
-    newobj->hash_state = Hacl_Streaming_MD5_legacy_copy(self->hash_state);
+    newobj->hash_state = Hacl_Hash_MD5_copy(self->hash_state);
     LEAVE_HASHLIB(self);
     return (PyObject *)newobj;
 }
@@ -139,7 +139,7 @@ MD5Type_digest_impl(MD5object *self)
 {
     unsigned char digest[MD5_DIGESTSIZE];
     ENTER_HASHLIB(self);
-    Hacl_Streaming_MD5_legacy_finish(self->hash_state, digest);
+    Hacl_Hash_MD5_digest(self->hash_state, digest);
     LEAVE_HASHLIB(self);
     return PyBytes_FromStringAndSize((const char *)digest, MD5_DIGESTSIZE);
 }
@@ -156,20 +156,20 @@ MD5Type_hexdigest_impl(MD5object *self)
 {
     unsigned char digest[MD5_DIGESTSIZE];
     ENTER_HASHLIB(self);
-    Hacl_Streaming_MD5_legacy_finish(self->hash_state, digest);
+    Hacl_Hash_MD5_digest(self->hash_state, digest);
     LEAVE_HASHLIB(self);
     return _Py_strhex((const char*)digest, MD5_DIGESTSIZE);
 }
 
-static void update(Hacl_Streaming_MD5_state *state, uint8_t *buf, Py_ssize_t len) {
+static void update(Hacl_Hash_MD5_state_t *state, uint8_t *buf, Py_ssize_t len) {
 #if PY_SSIZE_T_MAX > UINT32_MAX
   while (len > UINT32_MAX) {
-    Hacl_Streaming_MD5_legacy_update(state, buf, UINT32_MAX);
+    Hacl_Hash_MD5_update(state, buf, UINT32_MAX);
     len -= UINT32_MAX;
     buf += UINT32_MAX;
   }
 #endif
-  Hacl_Streaming_MD5_legacy_update(state, buf, (uint32_t) len);
+  Hacl_Hash_MD5_update(state, buf, (uint32_t) len);
 }
 
 /*[clinic input]
@@ -293,7 +293,7 @@ _md5_md5_impl(PyObject *module, PyObject *string, int usedforsecurity)
         return NULL;
     }
 
-    new->hash_state = Hacl_Streaming_MD5_legacy_create_in();
+    new->hash_state = Hacl_Hash_MD5_malloc();
 
     if (PyErr_Occurred()) {
         Py_DECREF(new);
diff --git a/Modules/overlapped.c b/Modules/overlapped.c
index afdd78d1bc..686ecf8b33 100644
--- a/Modules/overlapped.c
+++ b/Modules/overlapped.c
@@ -719,6 +719,24 @@ Overlapped_dealloc(OverlappedObject *self)
     if (!HasOverlappedIoCompleted(&self->overlapped) &&
         self->type != TYPE_NOT_STARTED)
     {
+        // NOTE: We should not get here, if we do then something is wrong in
+        // the IocpProactor or ProactorEventLoop. Since everything uses IOCP if
+        // the overlapped IO hasn't completed yet then we should not be
+        // deallocating!
+        //
+        // The problem is likely that this OverlappedObject was removed from
+        // the IocpProactor._cache before it was complete. The _cache holds a
+        // reference while IO is pending so that it does not get deallocated
+        // while the kernel has retained the OVERLAPPED structure.
+        //
+        // CancelIoEx (likely called from self.cancel()) may have successfully
+        // completed, but the OVERLAPPED is still in use until either
+        // HasOverlappedIoCompleted() is true or GetQueuedCompletionStatus has
+        // returned this OVERLAPPED object.
+        //
+        // NOTE: Waiting when IOCP is in use can hang indefinitely, but this
+        // CancelIoEx is superfluous in that self.cancel() was already called,
+        // so I've only ever seen this return FALSE with GLE=ERROR_NOT_FOUND
         Py_BEGIN_ALLOW_THREADS
         if (CancelIoEx(self->handle, &self->overlapped))
             wait = TRUE;
@@ -2039,6 +2057,7 @@ overlapped_exec(PyObject *module)
     WINAPI_CONSTANT(F_DWORD,  ERROR_OPERATION_ABORTED);
     WINAPI_CONSTANT(F_DWORD,  ERROR_SEM_TIMEOUT);
     WINAPI_CONSTANT(F_DWORD,  ERROR_PIPE_BUSY);
+    WINAPI_CONSTANT(F_DWORD,  ERROR_PORT_UNREACHABLE);
     WINAPI_CONSTANT(F_DWORD,  INFINITE);
     WINAPI_CONSTANT(F_HANDLE, INVALID_HANDLE_VALUE);
     WINAPI_CONSTANT(F_HANDLE, NULL);
diff --git a/Modules/posixmodule.c b/Modules/posixmodule.c
index 1c23061967..9f69c79261 100644
--- a/Modules/posixmodule.c
+++ b/Modules/posixmodule.c
@@ -7663,7 +7663,7 @@ os_fork1_impl(PyObject *module)
     pid_t pid;
 
     PyInterpreterState *interp = _PyInterpreterState_GET();
-    if (interp->finalizing) {
+    if (_PyInterpreterState_GetFinalizing(interp) != NULL) {
         PyErr_SetString(PyExc_RuntimeError,
                         "can't fork at interpreter shutdown");
         return NULL;
@@ -7707,7 +7707,7 @@ os_fork_impl(PyObject *module)
 {
     pid_t pid;
     PyInterpreterState *interp = _PyInterpreterState_GET();
-    if (interp->finalizing) {
+    if (_PyInterpreterState_GetFinalizing(interp) != NULL) {
         PyErr_SetString(PyExc_RuntimeError,
                         "can't fork at interpreter shutdown");
         return NULL;
@@ -8391,7 +8391,7 @@ os_forkpty_impl(PyObject *module)
     pid_t pid;
 
     PyInterpreterState *interp = _PyInterpreterState_GET();
-    if (interp->finalizing) {
+    if (_PyInterpreterState_GetFinalizing(interp) != NULL) {
         PyErr_SetString(PyExc_RuntimeError,
                         "can't fork at interpreter shutdown");
         return NULL;
@@ -9245,36 +9245,39 @@ wait_helper(PyObject *module, pid_t pid, int status, struct rusage *ru)
     if (!result)
         return NULL;
 
+    int pos = 0;
+
 #ifndef doubletime
 #define doubletime(TV) ((double)(TV).tv_sec + (TV).tv_usec * 0.000001)
 #endif
 
-    PyStructSequence_SET_ITEM(result, 0,
-                              PyFloat_FromDouble(doubletime(ru->ru_utime)));
-    PyStructSequence_SET_ITEM(result, 1,
-                              PyFloat_FromDouble(doubletime(ru->ru_stime)));
-#define SET_INT(result, index, value)\
-        PyStructSequence_SET_ITEM(result, index, PyLong_FromLong(value))
-    SET_INT(result, 2, ru->ru_maxrss);
-    SET_INT(result, 3, ru->ru_ixrss);
-    SET_INT(result, 4, ru->ru_idrss);
-    SET_INT(result, 5, ru->ru_isrss);
-    SET_INT(result, 6, ru->ru_minflt);
-    SET_INT(result, 7, ru->ru_majflt);
-    SET_INT(result, 8, ru->ru_nswap);
-    SET_INT(result, 9, ru->ru_inblock);
-    SET_INT(result, 10, ru->ru_oublock);
-    SET_INT(result, 11, ru->ru_msgsnd);
-    SET_INT(result, 12, ru->ru_msgrcv);
-    SET_INT(result, 13, ru->ru_nsignals);
-    SET_INT(result, 14, ru->ru_nvcsw);
-    SET_INT(result, 15, ru->ru_nivcsw);
-#undef SET_INT
-
-    if (PyErr_Occurred()) {
-        Py_DECREF(result);
-        return NULL;
-    }
+#define SET_RESULT(CALL)                                     \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            Py_DECREF(result);                               \
+            return NULL;                                     \
+        }                                                    \
+        PyStructSequence_SET_ITEM(result, pos++, item);      \
+    } while(0)
+
+    SET_RESULT(PyFloat_FromDouble(doubletime(ru->ru_utime)));
+    SET_RESULT(PyFloat_FromDouble(doubletime(ru->ru_stime)));
+    SET_RESULT(PyLong_FromLong(ru->ru_maxrss));
+    SET_RESULT(PyLong_FromLong(ru->ru_ixrss));
+    SET_RESULT(PyLong_FromLong(ru->ru_idrss));
+    SET_RESULT(PyLong_FromLong(ru->ru_isrss));
+    SET_RESULT(PyLong_FromLong(ru->ru_minflt));
+    SET_RESULT(PyLong_FromLong(ru->ru_majflt));
+    SET_RESULT(PyLong_FromLong(ru->ru_nswap));
+    SET_RESULT(PyLong_FromLong(ru->ru_inblock));
+    SET_RESULT(PyLong_FromLong(ru->ru_oublock));
+    SET_RESULT(PyLong_FromLong(ru->ru_msgsnd));
+    SET_RESULT(PyLong_FromLong(ru->ru_msgrcv));
+    SET_RESULT(PyLong_FromLong(ru->ru_nsignals));
+    SET_RESULT(PyLong_FromLong(ru->ru_nvcsw));
+    SET_RESULT(PyLong_FromLong(ru->ru_nivcsw));
+#undef SET_RESULT
 
     return Py_BuildValue("NiN", PyLong_FromPid(pid), status, result);
 }
@@ -9397,15 +9400,25 @@ os_waitid_impl(PyObject *module, idtype_t idtype, id_t id, int options)
     if (!result)
         return NULL;
 
-    PyStructSequence_SET_ITEM(result, 0, PyLong_FromPid(si.si_pid));
-    PyStructSequence_SET_ITEM(result, 1, _PyLong_FromUid(si.si_uid));
-    PyStructSequence_SET_ITEM(result, 2, PyLong_FromLong((long)(si.si_signo)));
-    PyStructSequence_SET_ITEM(result, 3, PyLong_FromLong((long)(si.si_status)));
-    PyStructSequence_SET_ITEM(result, 4, PyLong_FromLong((long)(si.si_code)));
-    if (PyErr_Occurred()) {
-        Py_DECREF(result);
-        return NULL;
-    }
+    int pos = 0;
+
+#define SET_RESULT(CALL)                                     \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            Py_DECREF(result);                               \
+            return NULL;                                     \
+        }                                                    \
+        PyStructSequence_SET_ITEM(result, pos++, item);      \
+    } while(0)
+
+    SET_RESULT(PyLong_FromPid(si.si_pid));
+    SET_RESULT(_PyLong_FromUid(si.si_uid));
+    SET_RESULT(PyLong_FromLong((long)(si.si_signo)));
+    SET_RESULT(PyLong_FromLong((long)(si.si_status)));
+    SET_RESULT(PyLong_FromLong((long)(si.si_code)));
+
+#undef SET_RESULT
 
     return result;
 }
@@ -12358,46 +12371,50 @@ _pystatvfs_fromstructstatvfs(PyObject *module, struct statvfs st) {
     if (v == NULL)
         return NULL;
 
+    int pos = 0;
+
+#define SET_RESULT(CALL)                                     \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            Py_DECREF(v);                                    \
+            return NULL;                                     \
+        }                                                    \
+        PyStructSequence_SET_ITEM(v, pos++, item);           \
+    } while(0)
+
 #if !defined(HAVE_LARGEFILE_SUPPORT)
-    PyStructSequence_SET_ITEM(v, 0, PyLong_FromLong((long) st.f_bsize));
-    PyStructSequence_SET_ITEM(v, 1, PyLong_FromLong((long) st.f_frsize));
-    PyStructSequence_SET_ITEM(v, 2, PyLong_FromLong((long) st.f_blocks));
-    PyStructSequence_SET_ITEM(v, 3, PyLong_FromLong((long) st.f_bfree));
-    PyStructSequence_SET_ITEM(v, 4, PyLong_FromLong((long) st.f_bavail));
-    PyStructSequence_SET_ITEM(v, 5, PyLong_FromLong((long) st.f_files));
-    PyStructSequence_SET_ITEM(v, 6, PyLong_FromLong((long) st.f_ffree));
-    PyStructSequence_SET_ITEM(v, 7, PyLong_FromLong((long) st.f_favail));
-    PyStructSequence_SET_ITEM(v, 8, PyLong_FromLong((long) st.f_flag));
-    PyStructSequence_SET_ITEM(v, 9, PyLong_FromLong((long) st.f_namemax));
+    SET_RESULT(PyLong_FromLong((long) st.f_bsize));
+    SET_RESULT(PyLong_FromLong((long) st.f_frsize));
+    SET_RESULT(PyLong_FromLong((long) st.f_blocks));
+    SET_RESULT(PyLong_FromLong((long) st.f_bfree));
+    SET_RESULT(PyLong_FromLong((long) st.f_bavail));
+    SET_RESULT(PyLong_FromLong((long) st.f_files));
+    SET_RESULT(PyLong_FromLong((long) st.f_ffree));
+    SET_RESULT(PyLong_FromLong((long) st.f_favail));
+    SET_RESULT(PyLong_FromLong((long) st.f_flag));
+    SET_RESULT(PyLong_FromLong((long) st.f_namemax));
 #else
-    PyStructSequence_SET_ITEM(v, 0, PyLong_FromLong((long) st.f_bsize));
-    PyStructSequence_SET_ITEM(v, 1, PyLong_FromLong((long) st.f_frsize));
-    PyStructSequence_SET_ITEM(v, 2,
-                              PyLong_FromLongLong((long long) st.f_blocks));
-    PyStructSequence_SET_ITEM(v, 3,
-                              PyLong_FromLongLong((long long) st.f_bfree));
-    PyStructSequence_SET_ITEM(v, 4,
-                              PyLong_FromLongLong((long long) st.f_bavail));
-    PyStructSequence_SET_ITEM(v, 5,
-                              PyLong_FromLongLong((long long) st.f_files));
-    PyStructSequence_SET_ITEM(v, 6,
-                              PyLong_FromLongLong((long long) st.f_ffree));
-    PyStructSequence_SET_ITEM(v, 7,
-                              PyLong_FromLongLong((long long) st.f_favail));
-    PyStructSequence_SET_ITEM(v, 8, PyLong_FromLong((long) st.f_flag));
-    PyStructSequence_SET_ITEM(v, 9, PyLong_FromLong((long) st.f_namemax));
+    SET_RESULT(PyLong_FromLong((long) st.f_bsize));
+    SET_RESULT(PyLong_FromLong((long) st.f_frsize));
+    SET_RESULT(PyLong_FromLongLong((long long) st.f_blocks));
+    SET_RESULT(PyLong_FromLongLong((long long) st.f_bfree));
+    SET_RESULT(PyLong_FromLongLong((long long) st.f_bavail));
+    SET_RESULT(PyLong_FromLongLong((long long) st.f_files));
+    SET_RESULT(PyLong_FromLongLong((long long) st.f_ffree));
+    SET_RESULT(PyLong_FromLongLong((long long) st.f_favail));
+    SET_RESULT(PyLong_FromLong((long) st.f_flag));
+    SET_RESULT(PyLong_FromLong((long) st.f_namemax));
 #endif
 /* The _ALL_SOURCE feature test macro defines f_fsid as a structure
  * (issue #32390). */
 #if defined(_AIX) && defined(_ALL_SOURCE)
-    PyStructSequence_SET_ITEM(v, 10, PyLong_FromUnsignedLong(st.f_fsid.val[0]));
+    SET_RESULT(PyLong_FromUnsignedLong(st.f_fsid.val[0]));
 #else
-    PyStructSequence_SET_ITEM(v, 10, PyLong_FromUnsignedLong(st.f_fsid));
+    SET_RESULT(PyLong_FromUnsignedLong(st.f_fsid));
 #endif
-    if (PyErr_Occurred()) {
-        Py_DECREF(v);
-        return NULL;
-    }
+
+#undef SET_RESULT
 
     return v;
 }
@@ -14327,12 +14344,23 @@ os_get_terminal_size_impl(PyObject *module, int fd)
     termsize = PyStructSequence_New((PyTypeObject *)TerminalSizeType);
     if (termsize == NULL)
         return NULL;
-    PyStructSequence_SET_ITEM(termsize, 0, PyLong_FromLong(columns));
-    PyStructSequence_SET_ITEM(termsize, 1, PyLong_FromLong(lines));
-    if (PyErr_Occurred()) {
-        Py_DECREF(termsize);
-        return NULL;
-    }
+
+    int pos = 0;
+
+#define SET_TERMSIZE(CALL)                                   \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            Py_DECREF(termsize);                             \
+            return NULL;                                     \
+        }                                                    \
+        PyStructSequence_SET_ITEM(termsize, pos++, item);    \
+    } while(0)
+
+    SET_TERMSIZE(PyLong_FromLong(columns));
+    SET_TERMSIZE(PyLong_FromLong(lines));
+#undef SET_TERMSIZE
+
     return termsize;
 }
 #endif /* defined(TERMSIZE_USE_CONIO) || defined(TERMSIZE_USE_IOCTL) */
diff --git a/Modules/pwdmodule.c b/Modules/pwdmodule.c
index cc2e2a4389..920259a62c 100644
--- a/Modules/pwdmodule.c
+++ b/Modules/pwdmodule.c
@@ -63,53 +63,52 @@ static struct PyModuleDef pwdmodule;
 
 #define DEFAULT_BUFFER_SIZE 1024
 
-static void
-sets(PyObject *v, int i, const char* val)
-{
-  if (val) {
-      PyObject *o = PyUnicode_DecodeFSDefault(val);
-      PyStructSequence_SET_ITEM(v, i, o);
-  }
-  else {
-      PyStructSequence_SET_ITEM(v, i, Py_None);
-      Py_INCREF(Py_None);
-  }
-}
-
 static PyObject *
 mkpwent(PyObject *module, struct passwd *p)
 {
-    int setIndex = 0;
     PyObject *v = PyStructSequence_New(get_pwd_state(module)->StructPwdType);
-    if (v == NULL)
+    if (v == NULL) {
         return NULL;
+    }
+
+    int setIndex = 0;
+
+#define SET_STRING(VAL) \
+    SET_RESULT((VAL) ? PyUnicode_DecodeFSDefault((VAL)) : Py_NewRef(Py_None))
 
-#define SETS(i,val) sets(v, i, val)
+#define SET_RESULT(CALL)                                     \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            goto error;                                      \
+        }                                                    \
+        PyStructSequence_SET_ITEM(v, setIndex++, item);      \
+    } while(0)
 
-    SETS(setIndex++, p->pw_name);
+    SET_STRING(p->pw_name);
 #if defined(HAVE_STRUCT_PASSWD_PW_PASSWD) && !defined(__ANDROID__)
-    SETS(setIndex++, p->pw_passwd);
+    SET_STRING(p->pw_passwd);
 #else
-    SETS(setIndex++, "");
+    SET_STRING("");
 #endif
-    PyStructSequence_SET_ITEM(v, setIndex++, _PyLong_FromUid(p->pw_uid));
-    PyStructSequence_SET_ITEM(v, setIndex++, _PyLong_FromGid(p->pw_gid));
+    SET_RESULT(_PyLong_FromUid(p->pw_uid));
+    SET_RESULT(_PyLong_FromGid(p->pw_gid));
 #if defined(HAVE_STRUCT_PASSWD_PW_GECOS)
-    SETS(setIndex++, p->pw_gecos);
+    SET_STRING(p->pw_gecos);
 #else
-    SETS(setIndex++, "");
+    SET_STRING("");
 #endif
-    SETS(setIndex++, p->pw_dir);
-    SETS(setIndex++, p->pw_shell);
-
-#undef SETS
+    SET_STRING(p->pw_dir);
+    SET_STRING(p->pw_shell);
 
-    if (PyErr_Occurred()) {
-        Py_XDECREF(v);
-        return NULL;
-    }
+#undef SET_STRING
+#undef SET_RESULT
 
     return v;
+
+error:
+    Py_DECREF(v);
+    return NULL;
 }
 
 /*[clinic input]
diff --git a/Modules/pyexpat.c b/Modules/pyexpat.c
index b21360419d..be31c637fc 100644
--- a/Modules/pyexpat.c
+++ b/Modules/pyexpat.c
@@ -1,6 +1,7 @@
 #include "Python.h"
 #include <ctype.h>
 
+#include <stdbool.h>
 #include "structmember.h"         // PyMemberDef
 #include "expat.h"
 
@@ -76,6 +77,12 @@ typedef struct {
                                 /* NULL if not enabled */
     int buffer_size;            /* Size of buffer, in XML_Char units */
     int buffer_used;            /* Buffer units in use */
+    bool reparse_deferral_enabled; /* Whether to defer reparsing of
+                                   unfinished XML tokens; a de-facto cache of
+                                   what Expat has the authority on, for lack
+                                   of a getter API function
+                                   "XML_GetReparseDeferralEnabled" in Expat
+                                   2.6.0 */
     PyObject *intern;           /* Dictionary to intern strings */
     PyObject **handlers;
 } xmlparseobject;
@@ -705,6 +712,40 @@ get_parse_result(pyexpat_state *state, xmlparseobject *self, int rv)
 
 #define MAX_CHUNK_SIZE (1 << 20)
 
+/*[clinic input]
+pyexpat.xmlparser.SetReparseDeferralEnabled
+
+    enabled: bool
+    /
+
+Enable/Disable reparse deferral; enabled by default with Expat >=2.6.0.
+[clinic start generated code]*/
+
+static PyObject *
+pyexpat_xmlparser_SetReparseDeferralEnabled_impl(xmlparseobject *self,
+                                                 int enabled)
+/*[clinic end generated code: output=5ec539e3b63c8c49 input=021eb9e0bafc32c5]*/
+{
+#if XML_COMBINED_VERSION >= 20600
+    XML_SetReparseDeferralEnabled(self->itself, enabled ? XML_TRUE : XML_FALSE);
+    self->reparse_deferral_enabled = (bool)enabled;
+#endif
+    Py_RETURN_NONE;
+}
+
+/*[clinic input]
+pyexpat.xmlparser.GetReparseDeferralEnabled
+
+Retrieve reparse deferral enabled status; always returns false with Expat <2.6.0.
+[clinic start generated code]*/
+
+static PyObject *
+pyexpat_xmlparser_GetReparseDeferralEnabled_impl(xmlparseobject *self)
+/*[clinic end generated code: output=4e91312e88a595a8 input=54b5f11d32b20f3e]*/
+{
+    return PyBool_FromLong(self->reparse_deferral_enabled);
+}
+
 /*[clinic input]
 pyexpat.xmlparser.Parse
 
@@ -1065,6 +1106,8 @@ static struct PyMethodDef xmlparse_methods[] = {
 #if XML_COMBINED_VERSION >= 19505
     PYEXPAT_XMLPARSER_USEFOREIGNDTD_METHODDEF
 #endif
+    PYEXPAT_XMLPARSER_SETREPARSEDEFERRALENABLED_METHODDEF
+    PYEXPAT_XMLPARSER_GETREPARSEDEFERRALENABLED_METHODDEF
     {NULL, NULL}  /* sentinel */
 };
 
@@ -1160,6 +1203,11 @@ newxmlparseobject(pyexpat_state *state, const char *encoding,
     self->ns_prefixes = 0;
     self->handlers = NULL;
     self->intern = Py_XNewRef(intern);
+#if XML_COMBINED_VERSION >= 20600
+    self->reparse_deferral_enabled = true;
+#else
+    self->reparse_deferral_enabled = false;
+#endif
 
     /* namespace_separator is either NULL or contains one char + \0 */
     self->itself = XML_ParserCreate_MM(encoding, &ExpatMemoryHandler,
@@ -2028,6 +2076,11 @@ pyexpat_exec(PyObject *mod)
 #else
     capi->SetHashSalt = NULL;
 #endif
+#if XML_COMBINED_VERSION >= 20600
+    capi->SetReparseDeferralEnabled = XML_SetReparseDeferralEnabled;
+#else
+    capi->SetReparseDeferralEnabled = NULL;
+#endif
 
     /* export using capsule */
     PyObject *capi_object = PyCapsule_New(capi, PyExpat_CAPSULE_NAME,
diff --git a/Modules/sha1module.c b/Modules/sha1module.c
index c66269b5f5..624dc57b0a 100644
--- a/Modules/sha1module.c
+++ b/Modules/sha1module.c
@@ -51,7 +51,7 @@ typedef struct {
     // Prevents undefined behavior via multiple threads entering the C API.
     // The lock will be NULL before threaded access has been enabled.
     PyThread_type_lock lock;
-    Hacl_Streaming_SHA1_state *hash_state;
+    Hacl_Hash_SHA1_state_t *hash_state;
 } SHA1object;
 
 #include "clinic/sha1module.c.h"
@@ -90,7 +90,7 @@ SHA1_traverse(PyObject *ptr, visitproc visit, void *arg)
 static void
 SHA1_dealloc(SHA1object *ptr)
 {
-    Hacl_Streaming_SHA1_legacy_free(ptr->hash_state);
+    Hacl_Hash_SHA1_free(ptr->hash_state);
     if (ptr->lock != NULL) {
         PyThread_free_lock(ptr->lock);
     }
@@ -122,7 +122,7 @@ SHA1Type_copy_impl(SHA1object *self, PyTypeObject *cls)
         return NULL;
 
     ENTER_HASHLIB(self);
-    newobj->hash_state = Hacl_Streaming_SHA1_legacy_copy(self->hash_state);
+    newobj->hash_state = Hacl_Hash_SHA1_copy(self->hash_state);
     LEAVE_HASHLIB(self);
     return (PyObject *)newobj;
 }
@@ -139,7 +139,7 @@ SHA1Type_digest_impl(SHA1object *self)
 {
     unsigned char digest[SHA1_DIGESTSIZE];
     ENTER_HASHLIB(self);
-    Hacl_Streaming_SHA1_legacy_finish(self->hash_state, digest);
+    Hacl_Hash_SHA1_digest(self->hash_state, digest);
     LEAVE_HASHLIB(self);
     return PyBytes_FromStringAndSize((const char *)digest, SHA1_DIGESTSIZE);
 }
@@ -156,20 +156,20 @@ SHA1Type_hexdigest_impl(SHA1object *self)
 {
     unsigned char digest[SHA1_DIGESTSIZE];
     ENTER_HASHLIB(self);
-    Hacl_Streaming_SHA1_legacy_finish(self->hash_state, digest);
+    Hacl_Hash_SHA1_digest(self->hash_state, digest);
     LEAVE_HASHLIB(self);
     return _Py_strhex((const char *)digest, SHA1_DIGESTSIZE);
 }
 
-static void update(Hacl_Streaming_SHA1_state *state, uint8_t *buf, Py_ssize_t len) {
+static void update(Hacl_Hash_SHA1_state_t *state, uint8_t *buf, Py_ssize_t len) {
 #if PY_SSIZE_T_MAX > UINT32_MAX
   while (len > UINT32_MAX) {
-    Hacl_Streaming_SHA1_legacy_update(state, buf, UINT32_MAX);
+    Hacl_Hash_SHA1_update(state, buf, UINT32_MAX);
     len -= UINT32_MAX;
     buf += UINT32_MAX;
   }
 #endif
-  Hacl_Streaming_SHA1_legacy_update(state, buf, (uint32_t) len);
+  Hacl_Hash_SHA1_update(state, buf, (uint32_t) len);
 }
 
 /*[clinic input]
@@ -293,7 +293,7 @@ _sha1_sha1_impl(PyObject *module, PyObject *string, int usedforsecurity)
         return NULL;
     }
 
-    new->hash_state = Hacl_Streaming_SHA1_legacy_create_in();
+    new->hash_state = Hacl_Hash_SHA1_malloc();
 
     if (PyErr_Occurred()) {
         Py_DECREF(new);
diff --git a/Modules/sha2module.c b/Modules/sha2module.c
index db3774c81e..f5dab39a8c 100644
--- a/Modules/sha2module.c
+++ b/Modules/sha2module.c
@@ -55,7 +55,7 @@ typedef struct {
     // Prevents undefined behavior via multiple threads entering the C API.
     // The lock will be NULL before threaded access has been enabled.
     PyThread_type_lock lock;
-    Hacl_Streaming_SHA2_state_sha2_256 *state;
+    Hacl_Hash_SHA2_state_t_256 *state;
 } SHA256object;
 
 typedef struct {
@@ -64,7 +64,7 @@ typedef struct {
     // Prevents undefined behavior via multiple threads entering the C API.
     // The lock will be NULL before threaded access has been enabled.
     PyThread_type_lock lock;
-    Hacl_Streaming_SHA2_state_sha2_512 *state;
+    Hacl_Hash_SHA2_state_t_512 *state;
 } SHA512object;
 
 #include "clinic/sha2module.c.h"
@@ -89,13 +89,13 @@ sha2_get_state(PyObject *module)
 static void SHA256copy(SHA256object *src, SHA256object *dest)
 {
     dest->digestsize = src->digestsize;
-    dest->state = Hacl_Streaming_SHA2_copy_256(src->state);
+    dest->state = Hacl_Hash_SHA2_copy_256(src->state);
 }
 
 static void SHA512copy(SHA512object *src, SHA512object *dest)
 {
     dest->digestsize = src->digestsize;
-    dest->state = Hacl_Streaming_SHA2_copy_512(src->state);
+    dest->state = Hacl_Hash_SHA2_copy_512(src->state);
 }
 
 static SHA256object *
@@ -162,7 +162,7 @@ SHA2_traverse(PyObject *ptr, visitproc visit, void *arg)
 static void
 SHA256_dealloc(SHA256object *ptr)
 {
-    Hacl_Streaming_SHA2_free_256(ptr->state);
+    Hacl_Hash_SHA2_free_256(ptr->state);
     if (ptr->lock != NULL) {
         PyThread_free_lock(ptr->lock);
     }
@@ -175,7 +175,7 @@ SHA256_dealloc(SHA256object *ptr)
 static void
 SHA512_dealloc(SHA512object *ptr)
 {
-    Hacl_Streaming_SHA2_free_512(ptr->state);
+    Hacl_Hash_SHA2_free_512(ptr->state);
     if (ptr->lock != NULL) {
         PyThread_free_lock(ptr->lock);
     }
@@ -188,34 +188,34 @@ SHA512_dealloc(SHA512object *ptr)
 /* HACL* takes a uint32_t for the length of its parameter, but Py_ssize_t can be
  * 64 bits so we loop in <4gig chunks when needed. */
 
-static void update_256(Hacl_Streaming_SHA2_state_sha2_256 *state, uint8_t *buf, Py_ssize_t len) {
+static void update_256(Hacl_Hash_SHA2_state_t_256 *state, uint8_t *buf, Py_ssize_t len) {
   /* Note: we explicitly ignore the error code on the basis that it would take >
    * 1 billion years to overflow the maximum admissible length for SHA2-256
    * (namely, 2^61-1 bytes). */
 #if PY_SSIZE_T_MAX > UINT32_MAX
   while (len > UINT32_MAX) {
-    Hacl_Streaming_SHA2_update_256(state, buf, UINT32_MAX);
+    Hacl_Hash_SHA2_update_256(state, buf, UINT32_MAX);
     len -= UINT32_MAX;
     buf += UINT32_MAX;
   }
 #endif
   /* Cast to uint32_t is safe: len <= UINT32_MAX at this point. */
-  Hacl_Streaming_SHA2_update_256(state, buf, (uint32_t) len);
+  Hacl_Hash_SHA2_update_256(state, buf, (uint32_t) len);
 }
 
-static void update_512(Hacl_Streaming_SHA2_state_sha2_512 *state, uint8_t *buf, Py_ssize_t len) {
+static void update_512(Hacl_Hash_SHA2_state_t_512 *state, uint8_t *buf, Py_ssize_t len) {
   /* Note: we explicitly ignore the error code on the basis that it would take >
    * 1 billion years to overflow the maximum admissible length for this API
    * (namely, 2^64-1 bytes). */
 #if PY_SSIZE_T_MAX > UINT32_MAX
   while (len > UINT32_MAX) {
-    Hacl_Streaming_SHA2_update_512(state, buf, UINT32_MAX);
+    Hacl_Hash_SHA2_update_512(state, buf, UINT32_MAX);
     len -= UINT32_MAX;
     buf += UINT32_MAX;
   }
 #endif
   /* Cast to uint32_t is safe: len <= UINT32_MAX at this point. */
-  Hacl_Streaming_SHA2_update_512(state, buf, (uint32_t) len);
+  Hacl_Hash_SHA2_update_512(state, buf, (uint32_t) len);
 }
 
 
@@ -298,7 +298,7 @@ SHA256Type_digest_impl(SHA256object *self)
     ENTER_HASHLIB(self);
     // HACL* performs copies under the hood so that self->state remains valid
     // after this call.
-    Hacl_Streaming_SHA2_finish_256(self->state, digest);
+    Hacl_Hash_SHA2_digest_256(self->state, digest);
     LEAVE_HASHLIB(self);
     return PyBytes_FromStringAndSize((const char *)digest, self->digestsize);
 }
@@ -318,7 +318,7 @@ SHA512Type_digest_impl(SHA512object *self)
     ENTER_HASHLIB(self);
     // HACL* performs copies under the hood so that self->state remains valid
     // after this call.
-    Hacl_Streaming_SHA2_finish_512(self->state, digest);
+    Hacl_Hash_SHA2_digest_512(self->state, digest);
     LEAVE_HASHLIB(self);
     return PyBytes_FromStringAndSize((const char *)digest, self->digestsize);
 }
@@ -336,7 +336,7 @@ SHA256Type_hexdigest_impl(SHA256object *self)
     uint8_t digest[SHA256_DIGESTSIZE];
     assert(self->digestsize <= SHA256_DIGESTSIZE);
     ENTER_HASHLIB(self);
-    Hacl_Streaming_SHA2_finish_256(self->state, digest);
+    Hacl_Hash_SHA2_digest_256(self->state, digest);
     LEAVE_HASHLIB(self);
     return _Py_strhex((const char *)digest, self->digestsize);
 }
@@ -354,7 +354,7 @@ SHA512Type_hexdigest_impl(SHA512object *self)
     uint8_t digest[SHA512_DIGESTSIZE];
     assert(self->digestsize <= SHA512_DIGESTSIZE);
     ENTER_HASHLIB(self);
-    Hacl_Streaming_SHA2_finish_512(self->state, digest);
+    Hacl_Hash_SHA2_digest_512(self->state, digest);
     LEAVE_HASHLIB(self);
     return _Py_strhex((const char *)digest, self->digestsize);
 }
@@ -599,7 +599,7 @@ _sha2_sha256_impl(PyObject *module, PyObject *string, int usedforsecurity)
         return NULL;
     }
 
-    new->state = Hacl_Streaming_SHA2_create_in_256();
+    new->state = Hacl_Hash_SHA2_malloc_256();
     new->digestsize = 32;
 
     if (PyErr_Occurred()) {
@@ -653,7 +653,7 @@ _sha2_sha224_impl(PyObject *module, PyObject *string, int usedforsecurity)
         return NULL;
     }
 
-    new->state = Hacl_Streaming_SHA2_create_in_224();
+    new->state = Hacl_Hash_SHA2_malloc_224();
     new->digestsize = 28;
 
     if (PyErr_Occurred()) {
@@ -707,7 +707,7 @@ _sha2_sha512_impl(PyObject *module, PyObject *string, int usedforsecurity)
         return NULL;
     }
 
-    new->state = Hacl_Streaming_SHA2_create_in_512();
+    new->state = Hacl_Hash_SHA2_malloc_512();
     new->digestsize = 64;
 
     if (PyErr_Occurred()) {
@@ -760,7 +760,7 @@ _sha2_sha384_impl(PyObject *module, PyObject *string, int usedforsecurity)
         return NULL;
     }
 
-    new->state = Hacl_Streaming_SHA2_create_in_384();
+    new->state = Hacl_Hash_SHA2_malloc_384();
     new->digestsize = 48;
 
     if (PyErr_Occurred()) {
diff --git a/Modules/sha3module.c b/Modules/sha3module.c
index 558d2005cf..f3c6a7fced 100644
--- a/Modules/sha3module.c
+++ b/Modules/sha3module.c
@@ -63,7 +63,7 @@ typedef struct {
     // Prevents undefined behavior via multiple threads entering the C API.
     // The lock will be NULL before threaded access has been enabled.
     PyThread_type_lock lock;
-    Hacl_Streaming_Keccak_state *hash_state;
+    Hacl_Hash_SHA3_state_t *hash_state;
 } SHA3object;
 
 #include "clinic/sha3module.c.h"
@@ -80,18 +80,18 @@ newSHA3object(PyTypeObject *type)
     return newobj;
 }
 
-static void sha3_update(Hacl_Streaming_Keccak_state *state, uint8_t *buf, Py_ssize_t len) {
+static void sha3_update(Hacl_Hash_SHA3_state_t *state, uint8_t *buf, Py_ssize_t len) {
   /* Note: we explicitly ignore the error code on the basis that it would take >
    * 1 billion years to hash more than 2^64 bytes. */
 #if PY_SSIZE_T_MAX > UINT32_MAX
   while (len > UINT32_MAX) {
-    Hacl_Streaming_Keccak_update(state, buf, UINT32_MAX);
+    Hacl_Hash_SHA3_update(state, buf, UINT32_MAX);
     len -= UINT32_MAX;
     buf += UINT32_MAX;
   }
 #endif
   /* Cast to uint32_t is safe: len <= UINT32_MAX at this point. */
-  Hacl_Streaming_Keccak_update(state, buf, (uint32_t) len);
+  Hacl_Hash_SHA3_update(state, buf, (uint32_t) len);
 }
 
 /*[clinic input]
@@ -119,17 +119,17 @@ py_sha3_new_impl(PyTypeObject *type, PyObject *data, int usedforsecurity)
     assert(state != NULL);
 
     if (type == state->sha3_224_type) {
-        self->hash_state = Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_SHA3_224);
+        self->hash_state = Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_SHA3_224);
     } else if (type == state->sha3_256_type) {
-        self->hash_state = Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_SHA3_256);
+        self->hash_state = Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_SHA3_256);
     } else if (type == state->sha3_384_type) {
-        self->hash_state = Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_SHA3_384);
+        self->hash_state = Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_SHA3_384);
     } else if (type == state->sha3_512_type) {
-        self->hash_state = Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_SHA3_512);
+        self->hash_state = Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_SHA3_512);
     } else if (type == state->shake_128_type) {
-        self->hash_state = Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_Shake128);
+        self->hash_state = Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_Shake128);
     } else if (type == state->shake_256_type) {
-        self->hash_state = Hacl_Streaming_Keccak_malloc(Spec_Hash_Definitions_Shake256);
+        self->hash_state = Hacl_Hash_SHA3_malloc(Spec_Hash_Definitions_Shake256);
     } else {
         PyErr_BadInternalCall();
         goto error;
@@ -168,7 +168,7 @@ py_sha3_new_impl(PyTypeObject *type, PyObject *data, int usedforsecurity)
 static void
 SHA3_dealloc(SHA3object *self)
 {
-    Hacl_Streaming_Keccak_free(self->hash_state);
+    Hacl_Hash_SHA3_free(self->hash_state);
     if (self->lock != NULL) {
         PyThread_free_lock(self->lock);
     }
@@ -197,7 +197,7 @@ _sha3_sha3_224_copy_impl(SHA3object *self)
         return NULL;
     }
     ENTER_HASHLIB(self);
-    newobj->hash_state = Hacl_Streaming_Keccak_copy(self->hash_state);
+    newobj->hash_state = Hacl_Hash_SHA3_copy(self->hash_state);
     LEAVE_HASHLIB(self);
     return (PyObject *)newobj;
 }
@@ -217,10 +217,10 @@ _sha3_sha3_224_digest_impl(SHA3object *self)
     // This function errors out if the algorithm is Shake. Here, we know this
     // not to be the case, and therefore do not perform error checking.
     ENTER_HASHLIB(self);
-    Hacl_Streaming_Keccak_finish(self->hash_state, digest);
+    Hacl_Hash_SHA3_digest(self->hash_state, digest);
     LEAVE_HASHLIB(self);
     return PyBytes_FromStringAndSize((const char *)digest,
-        Hacl_Streaming_Keccak_hash_len(self->hash_state));
+        Hacl_Hash_SHA3_hash_len(self->hash_state));
 }
 
 
@@ -236,10 +236,10 @@ _sha3_sha3_224_hexdigest_impl(SHA3object *self)
 {
     unsigned char digest[SHA3_MAX_DIGESTSIZE];
     ENTER_HASHLIB(self);
-    Hacl_Streaming_Keccak_finish(self->hash_state, digest);
+    Hacl_Hash_SHA3_digest(self->hash_state, digest);
     LEAVE_HASHLIB(self);
     return _Py_strhex((const char *)digest,
-        Hacl_Streaming_Keccak_hash_len(self->hash_state));
+        Hacl_Hash_SHA3_hash_len(self->hash_state));
 }
 
 
@@ -287,7 +287,7 @@ static PyMethodDef SHA3_methods[] = {
 static PyObject *
 SHA3_get_block_size(SHA3object *self, void *closure)
 {
-    uint32_t rate = Hacl_Streaming_Keccak_block_len(self->hash_state);
+    uint32_t rate = Hacl_Hash_SHA3_block_len(self->hash_state);
     return PyLong_FromLong(rate);
 }
 
@@ -323,17 +323,17 @@ static PyObject *
 SHA3_get_digest_size(SHA3object *self, void *closure)
 {
     // Preserving previous behavior: variable-length algorithms return 0
-    if (Hacl_Streaming_Keccak_is_shake(self->hash_state))
+    if (Hacl_Hash_SHA3_is_shake(self->hash_state))
       return PyLong_FromLong(0);
     else
-      return PyLong_FromLong(Hacl_Streaming_Keccak_hash_len(self->hash_state));
+      return PyLong_FromLong(Hacl_Hash_SHA3_hash_len(self->hash_state));
 }
 
 
 static PyObject *
 SHA3_get_capacity_bits(SHA3object *self, void *closure)
 {
-    uint32_t rate = Hacl_Streaming_Keccak_block_len(self->hash_state) * 8;
+    uint32_t rate = Hacl_Hash_SHA3_block_len(self->hash_state) * 8;
     int capacity = 1600 - rate;
     return PyLong_FromLong(capacity);
 }
@@ -342,7 +342,7 @@ SHA3_get_capacity_bits(SHA3object *self, void *closure)
 static PyObject *
 SHA3_get_rate_bits(SHA3object *self, void *closure)
 {
-    uint32_t rate = Hacl_Streaming_Keccak_block_len(self->hash_state) * 8;
+    uint32_t rate = Hacl_Hash_SHA3_block_len(self->hash_state) * 8;
     return PyLong_FromLong(rate);
 }
 
@@ -435,7 +435,7 @@ _SHAKE_digest(SHA3object *self, unsigned long digestlen, int hex)
      * - the output length is zero -- we follow the existing behavior and return
      *   an empty digest, without raising an error */
     if (digestlen > 0) {
-        Hacl_Streaming_Keccak_squeeze(self->hash_state, digest, digestlen);
+        Hacl_Hash_SHA3_squeeze(self->hash_state, digest, digestlen);
     }
     if (hex) {
         result = _Py_strhex((const char *)digest, digestlen);
diff --git a/Objects/descrobject.c b/Objects/descrobject.c
index 72ac470394..18876fd2b8 100644
--- a/Objects/descrobject.c
+++ b/Objects/descrobject.c
@@ -1697,15 +1697,12 @@ property_copy(PyObject *old, PyObject *get, PyObject *set, PyObject *del)
         return NULL;
 
     if (get == NULL || get == Py_None) {
-        Py_XDECREF(get);
         get = pold->prop_get ? pold->prop_get : Py_None;
     }
     if (set == NULL || set == Py_None) {
-        Py_XDECREF(set);
         set = pold->prop_set ? pold->prop_set : Py_None;
     }
     if (del == NULL || del == Py_None) {
-        Py_XDECREF(del);
         del = pold->prop_del ? pold->prop_del : Py_None;
     }
     if (pold->getter_doc && get != Py_None) {
diff --git a/Objects/floatobject.c b/Objects/floatobject.c
index 83a263c0d9..7a882bfd88 100644
--- a/Objects/floatobject.c
+++ b/Objects/floatobject.c
@@ -101,10 +101,18 @@ PyFloat_GetInfo(void)
         return NULL;
     }
 
-#define SetIntFlag(flag) \
-    PyStructSequence_SET_ITEM(floatinfo, pos++, PyLong_FromLong(flag))
-#define SetDblFlag(flag) \
-    PyStructSequence_SET_ITEM(floatinfo, pos++, PyFloat_FromDouble(flag))
+#define SetFlag(CALL) \
+    do {                                                    \
+        PyObject *flag = (CALL);                            \
+        if (flag == NULL) {                                 \
+            Py_CLEAR(floatinfo);                            \
+            return NULL;                                    \
+        }                                                   \
+        PyStructSequence_SET_ITEM(floatinfo, pos++, flag);  \
+    } while (0)
+
+#define SetIntFlag(FLAG) SetFlag(PyLong_FromLong((FLAG)))
+#define SetDblFlag(FLAG) SetFlag(PyFloat_FromDouble((FLAG)))
 
     SetDblFlag(DBL_MAX);
     SetIntFlag(DBL_MAX_EXP);
@@ -119,11 +127,8 @@ PyFloat_GetInfo(void)
     SetIntFlag(FLT_ROUNDS);
 #undef SetIntFlag
 #undef SetDblFlag
+#undef SetFlag
 
-    if (PyErr_Occurred()) {
-        Py_CLEAR(floatinfo);
-        return NULL;
-    }
     return floatinfo;
 }
 
diff --git a/Objects/genobject.c b/Objects/genobject.c
index 3b9e4a6036..bc58409c18 100644
--- a/Objects/genobject.c
+++ b/Objects/genobject.c
@@ -374,7 +374,6 @@ static PyObject *
 gen_close(PyGenObject *gen, PyObject *args)
 {
     PyObject *retval;
-    PyObject *yf = _PyGen_yf(gen);
     int err = 0;
 
     if (gen->gi_frame_state == FRAME_CREATED) {
@@ -384,6 +383,7 @@ gen_close(PyGenObject *gen, PyObject *args)
     if (gen->gi_frame_state >= FRAME_COMPLETED) {
         Py_RETURN_NONE;
     }
+    PyObject *yf = _PyGen_yf(gen);
     if (yf) {
         PyFrameState state = gen->gi_frame_state;
         gen->gi_frame_state = FRAME_EXECUTING;
@@ -396,12 +396,13 @@ gen_close(PyGenObject *gen, PyObject *args)
      * YIELD_VALUE if the debugger has changed the lineno. */
     if (err == 0 && is_yield(frame->prev_instr)) {
         assert(is_resume(frame->prev_instr + 1));
-        int exception_handler_depth = frame->prev_instr[0].op.code;
+        int exception_handler_depth = frame->prev_instr[0].op.arg;
         assert(exception_handler_depth > 0);
         /* We can safely ignore the outermost try block
          * as it automatically generated to handle
          * StopIteration. */
         if (exception_handler_depth == 1) {
+            gen->gi_frame_state = FRAME_COMPLETED;
             Py_RETURN_NONE;
         }
     }
diff --git a/Objects/listobject.c b/Objects/listobject.c
index f1edfb3a9a..f59abe2e64 100644
--- a/Objects/listobject.c
+++ b/Objects/listobject.c
@@ -3441,6 +3441,7 @@ static PyObject *
 listiter_reduce_general(void *_it, int forward)
 {
     PyObject *list;
+    PyObject *iter;
 
     /* _PyEval_GetBuiltin can invoke arbitrary code,
      * call must be before access of iterator pointers.
@@ -3448,7 +3449,7 @@ listiter_reduce_general(void *_it, int forward)
 
     /* the objects are not the same, index is of different types! */
     if (forward) {
-        PyObject *iter = _PyEval_GetBuiltin(&_Py_ID(iter));
+        iter = _PyEval_GetBuiltin(&_Py_ID(iter));
         if (!iter) {
             return NULL;
         }
@@ -3456,21 +3457,19 @@ listiter_reduce_general(void *_it, int forward)
         if (it->it_seq) {
             return Py_BuildValue("N(O)n", iter, it->it_seq, it->it_index);
         }
-        Py_DECREF(iter);
     } else {
-        PyObject *reversed = _PyEval_GetBuiltin(&_Py_ID(reversed));
-        if (!reversed) {
+        iter = _PyEval_GetBuiltin(&_Py_ID(reversed));
+        if (!iter) {
             return NULL;
         }
         listreviterobject *it = (listreviterobject *)_it;
         if (it->it_seq) {
-            return Py_BuildValue("N(O)n", reversed, it->it_seq, it->it_index);
+            return Py_BuildValue("N(O)n", iter, it->it_seq, it->it_index);
         }
-        Py_DECREF(reversed);
     }
     /* empty iterator, create an empty list */
     list = PyList_New(0);
     if (list == NULL)
         return NULL;
-    return Py_BuildValue("N(N)", _PyEval_GetBuiltin(&_Py_ID(iter)), list);
+    return Py_BuildValue("N(N)", iter, list);
 }
diff --git a/Objects/longobject.c b/Objects/longobject.c
index 5d9b413861..c72e1643c9 100644
--- a/Objects/longobject.c
+++ b/Objects/longobject.c
@@ -1766,7 +1766,9 @@ long_to_decimal_string_internal(PyObject *aa,
     digit *pout, *pin, rem, tenpow;
     int negative;
     int d;
-    int kind;
+
+    // writer or bytes_writer can be used, but not both at the same time.
+    assert(writer == NULL || bytes_writer == NULL);
 
     a = (PyLongObject *)aa;
     if (a == NULL || !PyLong_Check(a)) {
@@ -1879,7 +1881,6 @@ long_to_decimal_string_internal(PyObject *aa,
             Py_DECREF(scratch);
             return -1;
         }
-        kind = writer->kind;
     }
     else if (bytes_writer) {
         *bytes_str = _PyBytesWriter_Prepare(bytes_writer, *bytes_str, strlen);
@@ -1894,7 +1895,6 @@ long_to_decimal_string_internal(PyObject *aa,
             Py_DECREF(scratch);
             return -1;
         }
-        kind = PyUnicode_KIND(str);
     }
 
 #define WRITE_DIGITS(p)                                               \
@@ -1942,19 +1942,23 @@ long_to_decimal_string_internal(PyObject *aa,
         WRITE_DIGITS(p);
         assert(p == *bytes_str);
     }
-    else if (kind == PyUnicode_1BYTE_KIND) {
-        Py_UCS1 *p;
-        WRITE_UNICODE_DIGITS(Py_UCS1);
-    }
-    else if (kind == PyUnicode_2BYTE_KIND) {
-        Py_UCS2 *p;
-        WRITE_UNICODE_DIGITS(Py_UCS2);
-    }
     else {
-        Py_UCS4 *p;
-        assert (kind == PyUnicode_4BYTE_KIND);
-        WRITE_UNICODE_DIGITS(Py_UCS4);
+        int kind = writer ? writer->kind : PyUnicode_KIND(str);
+        if (kind == PyUnicode_1BYTE_KIND) {
+            Py_UCS1 *p;
+            WRITE_UNICODE_DIGITS(Py_UCS1);
+        }
+        else if (kind == PyUnicode_2BYTE_KIND) {
+            Py_UCS2 *p;
+            WRITE_UNICODE_DIGITS(Py_UCS2);
+        }
+        else {
+            assert (kind == PyUnicode_4BYTE_KIND);
+            Py_UCS4 *p;
+            WRITE_UNICODE_DIGITS(Py_UCS4);
+        }
     }
+
 #undef WRITE_DIGITS
 #undef WRITE_UNICODE_DIGITS
 
@@ -1995,11 +1999,12 @@ long_format_binary(PyObject *aa, int base, int alternate,
     PyObject *v = NULL;
     Py_ssize_t sz;
     Py_ssize_t size_a;
-    int kind;
     int negative;
     int bits;
 
     assert(base == 2 || base == 8 || base == 16);
+    // writer or bytes_writer can be used, but not both at the same time.
+    assert(writer == NULL || bytes_writer == NULL);
     if (a == NULL || !PyLong_Check(a)) {
         PyErr_BadInternalCall();
         return -1;
@@ -2047,7 +2052,6 @@ long_format_binary(PyObject *aa, int base, int alternate,
     if (writer) {
         if (_PyUnicodeWriter_Prepare(writer, sz, 'x') == -1)
             return -1;
-        kind = writer->kind;
     }
     else if (bytes_writer) {
         *bytes_str = _PyBytesWriter_Prepare(bytes_writer, *bytes_str, sz);
@@ -2058,7 +2062,6 @@ long_format_binary(PyObject *aa, int base, int alternate,
         v = PyUnicode_New(sz, 'x');
         if (v == NULL)
             return -1;
-        kind = PyUnicode_KIND(v);
     }
 
 #define WRITE_DIGITS(p)                                                 \
@@ -2119,19 +2122,23 @@ long_format_binary(PyObject *aa, int base, int alternate,
         WRITE_DIGITS(p);
         assert(p == *bytes_str);
     }
-    else if (kind == PyUnicode_1BYTE_KIND) {
-        Py_UCS1 *p;
-        WRITE_UNICODE_DIGITS(Py_UCS1);
-    }
-    else if (kind == PyUnicode_2BYTE_KIND) {
-        Py_UCS2 *p;
-        WRITE_UNICODE_DIGITS(Py_UCS2);
-    }
     else {
-        Py_UCS4 *p;
-        assert (kind == PyUnicode_4BYTE_KIND);
-        WRITE_UNICODE_DIGITS(Py_UCS4);
+        int kind = writer ? writer->kind : PyUnicode_KIND(v);
+        if (kind == PyUnicode_1BYTE_KIND) {
+            Py_UCS1 *p;
+            WRITE_UNICODE_DIGITS(Py_UCS1);
+        }
+        else if (kind == PyUnicode_2BYTE_KIND) {
+            Py_UCS2 *p;
+            WRITE_UNICODE_DIGITS(Py_UCS2);
+        }
+        else {
+            assert (kind == PyUnicode_4BYTE_KIND);
+            Py_UCS4 *p;
+            WRITE_UNICODE_DIGITS(Py_UCS4);
+        }
     }
+
 #undef WRITE_DIGITS
 #undef WRITE_UNICODE_DIGITS
 
diff --git a/Objects/typeobject.c b/Objects/typeobject.c
index 71d2068747..7776ae2b73 100644
--- a/Objects/typeobject.c
+++ b/Objects/typeobject.c
@@ -6258,6 +6258,7 @@ reduce_newobj(PyObject *obj)
     }
     else {
         /* args == NULL */
+        Py_DECREF(copyreg);
         Py_DECREF(kwargs);
         PyErr_BadInternalCall();
         return NULL;
diff --git a/Objects/unicodeobject.c b/Objects/unicodeobject.c
index 65d0842cb1..fc9379be02 100644
--- a/Objects/unicodeobject.c
+++ b/Objects/unicodeobject.c
@@ -516,7 +516,7 @@ unicode_check_encoding_errors(const char *encoding, const char *errors)
 
     /* Disable checks during Python finalization. For example, it allows to
        call _PyObject_Dump() during finalization for debugging purpose. */
-    if (interp->finalizing) {
+    if (_PyInterpreterState_GetFinalizing(interp) != NULL) {
         return 0;
     }
 
diff --git a/PC/launcher2.c b/PC/launcher2.c
index 0387700cb7..b0a557784c 100644
--- a/PC/launcher2.c
+++ b/PC/launcher2.c
@@ -1576,6 +1576,7 @@ _registryReadLegacyEnvironment(const SearchInfo *search, HKEY root, EnvironmentI
 
             int count = swprintf_s(realTag, tagLength + 4, L"%s-32", env->tag);
             if (count == -1) {
+                debug(L"# Failed to generate 32bit tag\n");
                 free(realTag);
                 return RC_INTERNAL_ERROR;
             }
@@ -1731,10 +1732,18 @@ appxSearch(const SearchInfo *search, EnvironmentInfo **result, const wchar_t *pa
         exeName = search->windowed ? L"pythonw.exe" : L"python.exe";
     }
 
-    if (FAILED(SHGetFolderPathW(NULL, CSIDL_LOCAL_APPDATA, NULL, 0, buffer)) ||
-        !join(buffer, MAXLEN, L"Microsoft\\WindowsApps") ||
+    // Failure to get LocalAppData may just mean we're running as a user who
+    // doesn't have a profile directory.
+    // In this case, return "not found", but don't fail.
+    // Chances are they can't launch Store installs anyway.
+    if (FAILED(SHGetFolderPathW(NULL, CSIDL_LOCAL_APPDATA, NULL, 0, buffer))) {
+        return RC_NO_PYTHON;
+    }
+
+    if (!join(buffer, MAXLEN, L"Microsoft\\WindowsApps") ||
         !join(buffer, MAXLEN, packageFamilyName) ||
         !join(buffer, MAXLEN, exeName)) {
+        debug(L"# Failed to construct App Execution Alias path\n");
         return RC_INTERNAL_ERROR;
     }
 
@@ -1927,6 +1936,7 @@ struct AppxSearchInfo {
 
 struct AppxSearchInfo APPX_SEARCH[] = {
     // Releases made through the Store
+    { L"PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0", L"3.13", 10 },
     { L"PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0", L"3.12", 10 },
     { L"PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0", L"3.11", 10 },
     { L"PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0", L"3.10", 10 },
@@ -1936,6 +1946,7 @@ struct AppxSearchInfo APPX_SEARCH[] = {
     // Side-loadable releases. Note that the publisher ID changes whenever we
     // renew our code-signing certificate, so the newer ID has a higher
     // priority (lower sortKey)
+    { L"PythonSoftwareFoundation.Python.3.13_3847v3x7pw1km", L"3.13", 11 },
     { L"PythonSoftwareFoundation.Python.3.12_3847v3x7pw1km", L"3.12", 11 },
     { L"PythonSoftwareFoundation.Python.3.11_3847v3x7pw1km", L"3.11", 11 },
     { L"PythonSoftwareFoundation.Python.3.11_hd69rhyc2wevp", L"3.11", 12 },
@@ -1956,6 +1967,7 @@ collectEnvironments(const SearchInfo *search, EnvironmentInfo **result)
     EnvironmentInfo *env = NULL;
 
     if (!result) {
+        debug(L"# collectEnvironments() was passed a NULL result\n");
         return RC_INTERNAL_ERROR;
     }
     *result = NULL;
@@ -2016,7 +2028,8 @@ struct StoreSearchInfo {
 
 
 struct StoreSearchInfo STORE_SEARCH[] = {
-    { L"3", /* 3.11 */ L"9NRWMJP3717K" },
+    { L"3", /* 3.12 */ L"9NCVDN91XZQP" },
+    { L"3.13", L"9PNRBTZXMB4Z" },
     { L"3.12", L"9NCVDN91XZQP" },
     { L"3.11", L"9NRWMJP3717K" },
     { L"3.10", L"9PJPW5LDXLZ5" },
@@ -2250,6 +2263,7 @@ int
 selectEnvironment(const SearchInfo *search, EnvironmentInfo *root, EnvironmentInfo **best)
 {
     if (!best) {
+        debug(L"# selectEnvironment() was passed a NULL best\n");
         return RC_INTERNAL_ERROR;
     }
     if (!root) {
diff --git a/PC/layout/support/appxmanifest.py b/PC/layout/support/appxmanifest.py
index 1fb0338027..53977beb8a 100644
--- a/PC/layout/support/appxmanifest.py
+++ b/PC/layout/support/appxmanifest.py
@@ -209,7 +209,7 @@ class PACKAGE_ID(ctypes.Structure):
     result = ctypes.create_unicode_buffer(256)
     result_len = ctypes.c_uint32(256)
     r = ctypes.windll.kernel32.PackageFamilyNameFromId(
-        pid, ctypes.byref(result_len), result
+        ctypes.byref(pid), ctypes.byref(result_len), result
     )
     if r:
         raise OSError(r, "failed to get package family name")
diff --git a/Parser/asdl_c.py b/Parser/asdl_c.py
index d42c26396d..2c34f5c1bc 100755
--- a/Parser/asdl_c.py
+++ b/Parser/asdl_c.py
@@ -1393,15 +1393,14 @@ class PartingShots(StaticVisitor):
 
     int starting_recursion_depth;
     /* Be careful here to prevent overflow. */
-    int COMPILER_STACK_FRAME_SCALE = 2;
     PyThreadState *tstate = _PyThreadState_GET();
     if (!tstate) {
         return NULL;
     }
     struct validator vstate;
-    vstate.recursion_limit = C_RECURSION_LIMIT * COMPILER_STACK_FRAME_SCALE;
+    vstate.recursion_limit = C_RECURSION_LIMIT;
     int recursion_depth = C_RECURSION_LIMIT - tstate->c_recursion_remaining;
-    starting_recursion_depth = recursion_depth * COMPILER_STACK_FRAME_SCALE;
+    starting_recursion_depth = recursion_depth;
     vstate.recursion_depth = starting_recursion_depth;
 
     PyObject *result = ast2obj_mod(state, &vstate, t);
diff --git a/Parser/parser.c b/Parser/parser.c
index 25b4ead781..66eb6e6048 100644
--- a/Parser/parser.c
+++ b/Parser/parser.c
@@ -6566,7 +6566,7 @@ with_stmt_rule(Parser *p)
             UNUSED(_end_lineno); // Only used by EXTRA macro
             int _end_col_offset = _token->end_col_offset;
             UNUSED(_end_col_offset); // Only used by EXTRA macro
-            _res = CHECK_VERSION ( stmt_ty , 9 , "Parenthesized context managers are" , _PyAST_With ( a , b , NULL , EXTRA ) );
+            _res = _PyAST_With ( a , b , NULL , EXTRA );
             if (_res == NULL && PyErr_Occurred()) {
                 p->error_indicator = 1;
                 p->level--;
diff --git a/Parser/pegen_errors.c b/Parser/pegen_errors.c
index cefec5d275..72f1349897 100644
--- a/Parser/pegen_errors.c
+++ b/Parser/pegen_errors.c
@@ -367,20 +367,18 @@ _PyPegen_raise_error_known_location(Parser *p, PyObject *errtype,
     Py_ssize_t col_number = col_offset;
     Py_ssize_t end_col_number = end_col_offset;
 
-    if (p->tok->encoding != NULL) {
-        col_number = _PyPegen_byte_offset_to_character_offset(error_line, col_offset);
-        if (col_number < 0) {
+    col_number = _PyPegen_byte_offset_to_character_offset(error_line, col_offset);
+    if (col_number < 0) {
+        goto error;
+    }
+
+    if (end_col_offset > 0) {
+        end_col_number = _PyPegen_byte_offset_to_character_offset(error_line, end_col_offset);
+        if (end_col_number < 0) {
             goto error;
         }
-        if (end_col_number > 0) {
-            Py_ssize_t end_col_offset = _PyPegen_byte_offset_to_character_offset(error_line, end_col_number);
-            if (end_col_offset < 0) {
-                goto error;
-            } else {
-                end_col_number = end_col_offset;
-            }
-        }
     }
+
     tmp = Py_BuildValue("(OnnNnn)", p->tok->filename, lineno, col_number, error_line, end_lineno, end_col_number);
     if (!tmp) {
         goto error;
diff --git a/Python/Python-ast.c b/Python/Python-ast.c
index 6c95f07c38..ecaff2041f 100644
--- a/Python/Python-ast.c
+++ b/Python/Python-ast.c
@@ -13152,15 +13152,14 @@ PyObject* PyAST_mod2obj(mod_ty t)
 
     int starting_recursion_depth;
     /* Be careful here to prevent overflow. */
-    int COMPILER_STACK_FRAME_SCALE = 2;
     PyThreadState *tstate = _PyThreadState_GET();
     if (!tstate) {
         return NULL;
     }
     struct validator vstate;
-    vstate.recursion_limit = C_RECURSION_LIMIT * COMPILER_STACK_FRAME_SCALE;
+    vstate.recursion_limit = C_RECURSION_LIMIT;
     int recursion_depth = C_RECURSION_LIMIT - tstate->c_recursion_remaining;
-    starting_recursion_depth = recursion_depth * COMPILER_STACK_FRAME_SCALE;
+    starting_recursion_depth = recursion_depth;
     vstate.recursion_depth = starting_recursion_depth;
 
     PyObject *result = ast2obj_mod(state, &vstate, t);
diff --git a/Python/ast.c b/Python/ast.c
index 82d7beec0e..76f6556ded 100644
--- a/Python/ast.c
+++ b/Python/ast.c
@@ -1038,9 +1038,6 @@ validate_type_params(struct validator *state, asdl_type_param_seq *tps)
 }
 
 
-/* See comments in symtable.c. */
-#define COMPILER_STACK_FRAME_SCALE 2
-
 int
 _PyAST_Validate(mod_ty mod)
 {
@@ -1057,9 +1054,9 @@ _PyAST_Validate(mod_ty mod)
     }
     /* Be careful here to prevent overflow. */
     int recursion_depth = C_RECURSION_LIMIT - tstate->c_recursion_remaining;
-    starting_recursion_depth = recursion_depth * COMPILER_STACK_FRAME_SCALE;
+    starting_recursion_depth = recursion_depth;
     state.recursion_depth = starting_recursion_depth;
-    state.recursion_limit = C_RECURSION_LIMIT * COMPILER_STACK_FRAME_SCALE;
+    state.recursion_limit = C_RECURSION_LIMIT;
 
     switch (mod->kind) {
     case Module_kind:
diff --git a/Python/ast_opt.c b/Python/ast_opt.c
index f8c4a95132..e881b7fe2d 100644
--- a/Python/ast_opt.c
+++ b/Python/ast_opt.c
@@ -1102,9 +1102,6 @@ astfold_type_param(type_param_ty node_, PyArena *ctx_, _PyASTOptimizeState *stat
 #undef CALL_OPT
 #undef CALL_SEQ
 
-/* See comments in symtable.c. */
-#define COMPILER_STACK_FRAME_SCALE 2
-
 int
 _PyAST_Optimize(mod_ty mod, PyArena *arena, _PyASTOptimizeState *state)
 {
@@ -1118,9 +1115,9 @@ _PyAST_Optimize(mod_ty mod, PyArena *arena, _PyASTOptimizeState *state)
     }
     /* Be careful here to prevent overflow. */
     int recursion_depth = C_RECURSION_LIMIT - tstate->c_recursion_remaining;
-    starting_recursion_depth = recursion_depth * COMPILER_STACK_FRAME_SCALE;
+    starting_recursion_depth = recursion_depth;
     state->recursion_depth = starting_recursion_depth;
-    state->recursion_limit = C_RECURSION_LIMIT * COMPILER_STACK_FRAME_SCALE;
+    state->recursion_limit = C_RECURSION_LIMIT;
 
     int ret = astfold_mod(mod, arena, state);
     assert(ret || PyErr_Occurred());
diff --git a/Python/bytecodes.c b/Python/bytecodes.c
index b957d8895b..1c25486c3d 100644
--- a/Python/bytecodes.c
+++ b/Python/bytecodes.c
@@ -3207,27 +3207,27 @@ dummy_func(
             }
             assert(PyTuple_CheckExact(callargs));
             EVAL_CALL_STAT_INC_IF_FUNCTION(EVAL_CALL_FUNCTION_EX, func);
-            if (opcode == INSTRUMENTED_CALL_FUNCTION_EX &&
-                !PyFunction_Check(func) && !PyMethod_Check(func)
-            ) {
+            if (opcode == INSTRUMENTED_CALL_FUNCTION_EX) {
                 PyObject *arg = PyTuple_GET_SIZE(callargs) > 0 ?
-                    PyTuple_GET_ITEM(callargs, 0) : Py_None;
+                    PyTuple_GET_ITEM(callargs, 0) : &_PyInstrumentation_MISSING;
                 int err = _Py_call_instrumentation_2args(
                     tstate, PY_MONITORING_EVENT_CALL,
                     frame, next_instr-1, func, arg);
                 if (err) goto error;
                 result = PyObject_Call(func, callargs, kwargs);
-                if (result == NULL) {
-                    _Py_call_instrumentation_exc2(
-                        tstate, PY_MONITORING_EVENT_C_RAISE,
-                        frame, next_instr-1, func, arg);
-                }
-                else {
-                    int err = _Py_call_instrumentation_2args(
-                        tstate, PY_MONITORING_EVENT_C_RETURN,
-                        frame, next_instr-1, func, arg);
-                    if (err < 0) {
-                        Py_CLEAR(result);
+                if (!PyFunction_Check(func) && !PyMethod_Check(func)) {
+                    if (result == NULL) {
+                        _Py_call_instrumentation_exc2(
+                            tstate, PY_MONITORING_EVENT_C_RAISE,
+                            frame, next_instr-1, func, arg);
+                    }
+                    else {
+                        int err = _Py_call_instrumentation_2args(
+                            tstate, PY_MONITORING_EVENT_C_RETURN,
+                            frame, next_instr-1, func, arg);
+                        if (err < 0) {
+                            Py_CLEAR(result);
+                        }
                     }
                 }
             }
diff --git a/Python/compile.c b/Python/compile.c
index ddd7b5c795..a871e9c417 100644
--- a/Python/compile.c
+++ b/Python/compile.c
@@ -3883,7 +3883,7 @@ compiler_assert(struct compiler *c, stmt_ty s)
         VISIT(c, expr, s->v.Assert.msg);
         ADDOP_I(c, LOC(s), CALL, 0);
     }
-    ADDOP_I(c, LOC(s), RAISE_VARARGS, 1);
+    ADDOP_I(c, LOC(s->v.Assert.test), RAISE_VARARGS, 1);
 
     USE_LABEL(c, end);
     return SUCCESS;
diff --git a/Python/generated_cases.c.h b/Python/generated_cases.c.h
index ea17c0410b..d5e3ce28ce 100644
--- a/Python/generated_cases.c.h
+++ b/Python/generated_cases.c.h
@@ -4433,27 +4433,27 @@
             }
             assert(PyTuple_CheckExact(callargs));
             EVAL_CALL_STAT_INC_IF_FUNCTION(EVAL_CALL_FUNCTION_EX, func);
-            if (opcode == INSTRUMENTED_CALL_FUNCTION_EX &&
-                !PyFunction_Check(func) && !PyMethod_Check(func)
-            ) {
+            if (opcode == INSTRUMENTED_CALL_FUNCTION_EX) {
                 PyObject *arg = PyTuple_GET_SIZE(callargs) > 0 ?
-                    PyTuple_GET_ITEM(callargs, 0) : Py_None;
+                    PyTuple_GET_ITEM(callargs, 0) : &_PyInstrumentation_MISSING;
                 int err = _Py_call_instrumentation_2args(
                     tstate, PY_MONITORING_EVENT_CALL,
                     frame, next_instr-1, func, arg);
                 if (err) goto error;
                 result = PyObject_Call(func, callargs, kwargs);
-                if (result == NULL) {
-                    _Py_call_instrumentation_exc2(
-                        tstate, PY_MONITORING_EVENT_C_RAISE,
-                        frame, next_instr-1, func, arg);
-                }
-                else {
-                    int err = _Py_call_instrumentation_2args(
-                        tstate, PY_MONITORING_EVENT_C_RETURN,
-                        frame, next_instr-1, func, arg);
-                    if (err < 0) {
-                        Py_CLEAR(result);
+                if (!PyFunction_Check(func) && !PyMethod_Check(func)) {
+                    if (result == NULL) {
+                        _Py_call_instrumentation_exc2(
+                            tstate, PY_MONITORING_EVENT_C_RAISE,
+                            frame, next_instr-1, func, arg);
+                    }
+                    else {
+                        int err = _Py_call_instrumentation_2args(
+                            tstate, PY_MONITORING_EVENT_C_RETURN,
+                            frame, next_instr-1, func, arg);
+                        if (err < 0) {
+                            Py_CLEAR(result);
+                        }
                     }
                 }
             }
diff --git a/Python/getargs.c b/Python/getargs.c
index 066739f21f..5e731cdc23 100644
--- a/Python/getargs.c
+++ b/Python/getargs.c
@@ -672,7 +672,7 @@ convertsimple(PyObject *arg, const char **p_format, va_list *p_va, int flags,
     switch (c) {
 
     case 'b': { /* unsigned byte -- very short int */
-        char *p = va_arg(*p_va, char *);
+        unsigned char *p = va_arg(*p_va, unsigned char *);
         long ival = PyLong_AsLong(arg);
         if (ival == -1 && PyErr_Occurred())
             RETURN_ERR_OCCURRED;
@@ -693,7 +693,7 @@ convertsimple(PyObject *arg, const char **p_format, va_list *p_va, int flags,
 
     case 'B': {/* byte sized bitfield - both signed and unsigned
                   values allowed */
-        char *p = va_arg(*p_va, char *);
+        unsigned char *p = va_arg(*p_va, unsigned char *);
         unsigned long ival = PyLong_AsUnsignedLongMask(arg);
         if (ival == (unsigned long)-1 && PyErr_Occurred())
             RETURN_ERR_OCCURRED;
diff --git a/Python/initconfig.c b/Python/initconfig.c
index 4e5d4bb987..192089b5cc 100644
--- a/Python/initconfig.c
+++ b/Python/initconfig.c
@@ -33,8 +33,8 @@ static const char usage_line[] =
 /* Lines sorted by option name; keep in sync with usage_envvars* below */
 static const char usage_help[] = "\
 Options (and corresponding environment variables):\n\
--b     : issue warnings about str(bytes_instance), str(bytearray_instance)\n\
-         and comparing bytes/bytearray with str. (-bb: issue errors)\n\
+-b     : issue warnings about converting bytes/bytearray to str and comparing\n\
+         bytes/bytearray with str or bytes with int. (-bb: issue errors)\n\
 -B     : don't write .pyc files on import; also PYTHONDONTWRITEBYTECODE=x\n\
 -c cmd : program passed in as string (terminates option list)\n\
 -d     : turn on parser debugging output (for experts only, only works on\n\
@@ -49,9 +49,10 @@ Options (and corresponding environment variables):\n\
          .pyc extension; also PYTHONOPTIMIZE=x\n\
 -OO    : do -O changes and also discard docstrings; add .opt-2 before\n\
          .pyc extension\n\
--P     : don't prepend a potentially unsafe path to sys.path; also PYTHONSAFEPATH\n\
+-P     : don't prepend a potentially unsafe path to sys.path; also\n\
+         PYTHONSAFEPATH\n\
 -q     : don't print version and copyright messages on interactive startup\n\
--s     : don't add user site directory to sys.path; also PYTHONNOUSERSITE\n\
+-s     : don't add user site directory to sys.path; also PYTHONNOUSERSITE=x\n\
 -S     : don't imply 'import site' on initialization\n\
 -u     : force the stdout and stderr streams to be unbuffered;\n\
          this option has no effect on stdin; also PYTHONUNBUFFERED=x\n\
@@ -65,9 +66,10 @@ Options (and corresponding environment variables):\n\
 -X opt : set implementation-specific option\n\
 --check-hash-based-pycs always|default|never:\n\
          control how Python invalidates hash-based .pyc files\n\
---help-env      : print help about Python environment variables and exit\n\
---help-xoptions : print help about implementation-specific -X options and exit\n\
---help-all      : print complete help information and exit\n\
+--help-env: print help about Python environment variables and exit\n\
+--help-xoptions: print help about implementation-specific -X options and exit\n\
+--help-all: print complete help information and exit\n\
+\n\
 Arguments:\n\
 file   : program read from script file\n\
 -      : program read from stdin (default; interactive mode if a tty)\n\
@@ -76,117 +78,90 @@ arg ...: arguments passed to program in sys.argv[1:]\n\
 
 static const char usage_xoptions[] = "\
 The following implementation-specific options are available:\n\
-\n\
--X faulthandler: enable faulthandler\n\
-\n\
--X showrefcount: output the total reference count and number of used\n\
-    memory blocks when the program finishes or after each statement in the\n\
-    interactive interpreter. This only works on debug builds\n\
-\n\
--X tracemalloc: start tracing Python memory allocations using the\n\
-    tracemalloc module. By default, only the most recent frame is stored in a\n\
-    traceback of a trace. Use -X tracemalloc=NFRAME to start tracing with a\n\
-    traceback limit of NFRAME frames\n\
-\n\
--X importtime: show how long each import takes. It shows module name,\n\
-    cumulative time (including nested imports) and self time (excluding\n\
-    nested imports). Note that its output may be broken in multi-threaded\n\
-    application. Typical usage is python3 -X importtime -c 'import asyncio'\n\
-\n\
--X dev: enable CPython's \"development mode\", introducing additional runtime\n\
-    checks which are too expensive to be enabled by default. Effect of the\n\
-    developer mode:\n\
-       * Add default warning filter, as -W default\n\
-       * Install debug hooks on memory allocators: see the PyMem_SetupDebugHooks()\n\
-         C function\n\
-       * Enable the faulthandler module to dump the Python traceback on a crash\n\
-       * Enable asyncio debug mode\n\
-       * Set the dev_mode attribute of sys.flags to True\n\
-       * io.IOBase destructor logs close() exceptions\n\
-\n\
--X utf8: enable UTF-8 mode for operating system interfaces, overriding the default\n\
-    locale-aware mode. -X utf8=0 explicitly disables UTF-8 mode (even when it would\n\
-    otherwise activate automatically)\n\
-\n\
--X pycache_prefix=PATH: enable writing .pyc files to a parallel tree rooted at the\n\
-    given directory instead of to the code tree\n\
-\n\
--X warn_default_encoding: enable opt-in EncodingWarning for 'encoding=None'\n\
-\n\
--X no_debug_ranges: disable the inclusion of the tables mapping extra location \n\
-   information (end line, start column offset and end column offset) to every \n\
-   instruction in code objects. This is useful when smaller code objects and pyc \n\
-   files are desired as well as suppressing the extra visual location indicators \n\
-   when the interpreter displays tracebacks.\n\
-\n\
--X perf: activate support for the Linux \"perf\" profiler by activating the \"perf\"\n\
-    trampoline. When this option is activated, the Linux \"perf\" profiler will be \n\
-    able to report Python calls. This option is only available on some platforms and will \n\
-    do nothing if is not supported on the current system. The default value is \"off\".\n\
-\n\
--X frozen_modules=[on|off]: whether or not frozen modules should be used.\n\
-   The default is \"on\" (or \"off\" if you are running a local build).\n\
-\n\
--X int_max_str_digits=number: limit the size of int<->str conversions.\n\
-    This helps avoid denial of service attacks when parsing untrusted data.\n\
-    The default is sys.int_info.default_max_str_digits.  0 disables."
-
+-X dev : enable Python Development Mode; also PYTHONDEVMODE\n\
+-X faulthandler: dump the Python traceback on fatal errors;\n\
+         also PYTHONFAULTHANDLER\n\
+-X frozen_modules=[on|off]: whether to use frozen modules; the default is \"on\"\n\
+         for installed Python and \"off\" for a local build\n\
+-X importtime: show how long each import takes; also PYTHONPROFILEIMPORTTIME\n\
+-X int_max_str_digits=N: limit the size of int<->str conversions;\n\
+         0 disables the limit; also PYTHONINTMAXSTRDIGITS\n\
+-X no_debug_ranges: don't include extra location information in code objects;\n\
+         also PYTHONNODEBUGRANGES\n\
+-X perf: support the Linux \"perf\" profiler; also PYTHONPERFSUPPORT=1\n\
+"
+#ifdef Py_DEBUG
+"-X presite=MOD: import this module before site; also PYTHON_PRESITE\n"
+#endif
+"\
+-X pycache_prefix=PATH: write .pyc files to a parallel tree instead of to the\n\
+         code tree; also PYTHONPYCACHEPREFIX\n\
+"
 #ifdef Py_STATS
-"\n\
-\n\
--X pystats: Enable pystats collection at startup."
+"-X pystats: enable pystats collection at startup; also PYTHONSTATS\n"
 #endif
-;
+"\
+-X showrefcount: output the total reference count and number of used\n\
+         memory blocks when the program finishes or after each statement in\n\
+         the interactive interpreter; only works on debug builds\n\
+-X tracemalloc[=N]: trace Python memory allocations; N sets a traceback limit\n\
+         of N frames (default: 1); also PYTHONTRACEMALLOC=N\n\
+-X utf8[=0|1]: enable (1) or disable (0) UTF-8 mode; also PYTHONUTF8\n\
+-X warn_default_encoding: enable opt-in EncodingWarning for 'encoding=None';\n\
+         also PYTHONWARNDEFAULTENCODING\
+";
 
 /* Envvars that don't have equivalent command-line options are listed first */
 static const char usage_envvars[] =
 "Environment variables that change behavior:\n"
-"PYTHONSTARTUP: file executed on interactive startup (no default)\n"
-"PYTHONPATH   : '%lc'-separated list of directories prefixed to the\n"
-"               default module search path.  The result is sys.path.\n"
-"PYTHONHOME   : alternate <prefix> directory (or <prefix>%lc<exec_prefix>).\n"
-"               The default module search path uses %s.\n"
-"PYTHONPLATLIBDIR : override sys.platlibdir.\n"
-"PYTHONCASEOK : ignore case in 'import' statements (Windows).\n"
-"PYTHONUTF8: if set to 1, enable the UTF-8 mode.\n"
-"PYTHONIOENCODING: Encoding[:errors] used for stdin/stdout/stderr.\n"
-"PYTHONFAULTHANDLER: dump the Python traceback on fatal errors.\n"
-"PYTHONHASHSEED: if this variable is set to 'random', a random value is used\n"
-"   to seed the hashes of str and bytes objects.  It can also be set to an\n"
-"   integer in the range [0,4294967295] to get hash values with a\n"
-"   predictable seed.\n"
-"PYTHONINTMAXSTRDIGITS: limits the maximum digit characters in an int value\n"
-"   when converting from a string and when converting an int back to a str.\n"
-"   A value of 0 disables the limit.  Conversions to or from bases 2, 4, 8,\n"
-"   16, and 32 are never limited.\n"
-"PYTHONMALLOC: set the Python memory allocators and/or install debug hooks\n"
-"   on Python memory allocators. Use PYTHONMALLOC=debug to install debug\n"
-"   hooks.\n"
+"PYTHONSTARTUP   : file executed on interactive startup (no default)\n"
+"PYTHONPATH      : '%lc'-separated list of directories prefixed to the\n"
+"                  default module search path.  The result is sys.path.\n"
+"PYTHONHOME      : alternate <prefix> directory (or <prefix>%lc<exec_prefix>).\n"
+"                  The default module search path uses %s.\n"
+"PYTHONPLATLIBDIR: override sys.platlibdir\n"
+"PYTHONCASEOK    : ignore case in 'import' statements (Windows)\n"
+"PYTHONIOENCODING: encoding[:errors] used for stdin/stdout/stderr\n"
+"PYTHONHASHSEED  : if this variable is set to 'random', a random value is used\n"
+"                  to seed the hashes of str and bytes objects.  It can also be\n"
+"                  set to an integer in the range [0,4294967295] to get hash\n"
+"                  values with a predictable seed.\n"
+"PYTHONMALLOC    : set the Python memory allocators and/or install debug hooks\n"
+"                  on Python memory allocators.  Use PYTHONMALLOC=debug to\n"
+"                  install debug hooks.\n"
 "PYTHONCOERCECLOCALE: if this variable is set to 0, it disables the locale\n"
-"   coercion behavior. Use PYTHONCOERCECLOCALE=warn to request display of\n"
-"   locale coercion and locale compatibility warnings on stderr.\n"
+"                  coercion behavior.  Use PYTHONCOERCECLOCALE=warn to request\n"
+"                  display of locale coercion and locale compatibility warnings\n"
+"                  on stderr.\n"
 "PYTHONBREAKPOINT: if this variable is set to 0, it disables the default\n"
-"   debugger. It can be set to the callable of your debugger of choice.\n"
-"PYTHONDEVMODE: enable the development mode.\n"
-"PYTHONPYCACHEPREFIX: root directory for bytecode cache (pyc) files.\n"
-"PYTHONWARNDEFAULTENCODING: enable opt-in EncodingWarning for 'encoding=None'.\n"
-"PYTHONNODEBUGRANGES: If this variable is set, it disables the inclusion of the \n"
-"   tables mapping extra location information (end line, start column offset \n"
-"   and end column offset) to every instruction in code objects. This is useful \n"
-"   when smaller code objects and pyc files are desired as well as suppressing the \n"
-"   extra visual location indicators when the interpreter displays tracebacks.\n"
-"These variables have equivalent command-line parameters (see --help for details):\n"
-"PYTHONDEBUG             : enable parser debug mode (-d)\n"
-"PYTHONDONTWRITEBYTECODE : don't write .pyc files (-B)\n"
-"PYTHONINSPECT           : inspect interactively after running script (-i)\n"
-"PYTHONINTMAXSTRDIGITS   : limit max digit characters in an int value\n"
-"                          (-X int_max_str_digits=number)\n"
-"PYTHONNOUSERSITE        : disable user site directory (-s)\n"
-"PYTHONOPTIMIZE          : enable level 1 optimizations (-O)\n"
-"PYTHONSAFEPATH          : don't prepend a potentially unsafe path to sys.path (-P)\n"
-"PYTHONUNBUFFERED        : disable stdout/stderr buffering (-u)\n"
-"PYTHONVERBOSE           : trace import statements (-v)\n"
-"PYTHONWARNINGS=arg      : warning control (-W arg)\n";
+"                  debugger.  It can be set to the callable of your debugger of\n"
+"                  choice.\n"
+"\n"
+"These variables have equivalent command-line options (see --help for details):\n"
+"PYTHONDEBUG     : enable parser debug mode (-d)\n"
+"PYTHONDEVMODE   : enable Python Development Mode (-X dev)\n"
+"PYTHONDONTWRITEBYTECODE: don't write .pyc files (-B)\n"
+"PYTHONFAULTHANDLER: dump the Python traceback on fatal errors (-X faulthandler)\n"
+"PYTHONINSPECT   : inspect interactively after running script (-i)\n"
+"PYTHONINTMAXSTRDIGITS: limit the size of int<->str conversions;\n"
+"                  0 disables the limit (-X int_max_str_digits=N)\n"
+"PYTHONNODEBUGRANGES: don't include extra location information in code objects\n"
+"                  (-X no_debug_ranges)\n"
+"PYTHONNOUSERSITE: disable user site directory (-s)\n"
+"PYTHONOPTIMIZE  : enable level 1 optimizations (-O)\n"
+"PYTHONPERFSUPPORT: support the Linux \"perf\" profiler (-X perf)\n"
+"PYTHONPROFILEIMPORTTIME: show how long each import takes (-X importtime)\n"
+"PYTHONPYCACHEPREFIX: root directory for bytecode cache (pyc) files\n"
+"                  (-X pycache_prefix)\n"
+"PYTHONSAFEPATH  : don't prepend a potentially unsafe path to sys.path.\n"
+"PYTHONTRACEMALLOC: trace Python memory allocations (-X tracemalloc)\n"
+"PYTHONUNBUFFERED: disable stdout/stderr buffering (-u)\n"
+"PYTHONUTF8      : control the UTF-8 mode (-X utf8)\n"
+"PYTHONVERBOSE   : trace import statements (-v)\n"
+"PYTHONWARNDEFAULTENCODING: enable opt-in EncodingWarning for 'encoding=None'\n"
+"                  (-X warn_default_encoding)\n"
+"PYTHONWARNINGS  : warning control (-W)\n"
+;
 
 #if defined(MS_WINDOWS)
 #  define PYTHONHOMEHELP "<prefix>\\python{major}{minor}"
@@ -2370,9 +2345,9 @@ static void
 config_complete_usage(const wchar_t* program)
 {
    config_usage(0, program);
-   puts("\n");
+   putchar('\n');
    config_envvars_usage();
-   puts("\n");
+   putchar('\n');
    config_xoptions_usage();
 }
 
diff --git a/Python/structmember.c b/Python/structmember.c
index ebebaa0a03..f4de0cb9ea 100644
--- a/Python/structmember.c
+++ b/Python/structmember.c
@@ -3,6 +3,9 @@
 
 #include "Python.h"
 #include "structmember.h"         // PyMemberDef
+#include "pycore_abstract.h"      // _PyNumber_Index()
+#include "pycore_long.h"          // _PyLong_IsNegative()
+
 
 PyObject *
 PyMember_GetOne(const char *obj_addr, PyMemberDef *l)
@@ -200,27 +203,22 @@ PyMember_SetOne(char *addr, PyMemberDef *l, PyObject *v)
     case T_UINT: {
         /* XXX: For compatibility, accept negative int values
            as well. */
-        int overflow;
-        long long_val = PyLong_AsLongAndOverflow(v, &overflow);
-        if (long_val == -1 && PyErr_Occurred()) {
-            return -1;
-        }
-        if (overflow < 0) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "Python int too large to convert to C long");
+        v = _PyNumber_Index(v);
+        if (v == NULL) {
             return -1;
         }
-        else if (!overflow) {
-            *(unsigned int *)addr = (unsigned int)(unsigned long)long_val;
-            if (long_val < 0) {
-                WARN("Writing negative value into unsigned field");
-            }
-            else if ((unsigned long)long_val > UINT_MAX) {
-                WARN("Truncation of value to unsigned short");
+        if (_PyLong_IsNegative((PyLongObject *)v)) {
+            long long_val = PyLong_AsLong(v);
+            Py_DECREF(v);
+            if (long_val == -1 && PyErr_Occurred()) {
+                return -1;
             }
+            *(unsigned int *)addr = (unsigned int)(unsigned long)long_val;
+            WARN("Writing negative value into unsigned field");
         }
         else {
             unsigned long ulong_val = PyLong_AsUnsignedLong(v);
+            Py_DECREF(v);
             if (ulong_val == (unsigned long)-1 && PyErr_Occurred()) {
                 return -1;
             }
@@ -240,24 +238,22 @@ PyMember_SetOne(char *addr, PyMemberDef *l, PyObject *v)
     case T_ULONG: {
         /* XXX: For compatibility, accept negative int values
            as well. */
-        int overflow;
-        long long_val = PyLong_AsLongAndOverflow(v, &overflow);
-        if (long_val == -1 && PyErr_Occurred()) {
-            return -1;
-        }
-        if (overflow < 0) {
-            PyErr_SetString(PyExc_OverflowError,
-                            "Python int too large to convert to C long");
+        v = _PyNumber_Index(v);
+        if (v == NULL) {
             return -1;
         }
-        else if (!overflow) {
-            *(unsigned long *)addr = (unsigned long)long_val;
-            if (long_val < 0) {
-                WARN("Writing negative value into unsigned field");
+        if (_PyLong_IsNegative((PyLongObject *)v)) {
+            long long_val = PyLong_AsLong(v);
+            Py_DECREF(v);
+            if (long_val == -1 && PyErr_Occurred()) {
+                return -1;
             }
+            *(unsigned long *)addr = (unsigned long)long_val;
+            WARN("Writing negative value into unsigned field");
         }
         else {
             unsigned long ulong_val = PyLong_AsUnsignedLong(v);
+            Py_DECREF(v);
             if (ulong_val == (unsigned long)-1 && PyErr_Occurred()) {
                 return -1;
             }
@@ -313,18 +309,30 @@ PyMember_SetOne(char *addr, PyMemberDef *l, PyObject *v)
             return -1;
         break;
         }
-    case T_ULONGLONG:{
-        unsigned long long value;
-        /* ??? PyLong_AsLongLong accepts an int, but PyLong_AsUnsignedLongLong
-            doesn't ??? */
-        if (PyLong_Check(v))
-            *(unsigned long long*)addr = value = PyLong_AsUnsignedLongLong(v);
-        else
-            *(unsigned long long*)addr = value = PyLong_AsLong(v);
-        if ((value == (unsigned long long)-1) && PyErr_Occurred())
+    case Py_T_ULONGLONG: {
+        v = _PyNumber_Index(v);
+        if (v == NULL) {
             return -1;
-        break;
         }
+        if (_PyLong_IsNegative((PyLongObject *)v)) {
+            long long_val = PyLong_AsLong(v);
+            Py_DECREF(v);
+            if (long_val == -1 && PyErr_Occurred()) {
+                return -1;
+            }
+            *(unsigned long long *)addr = (unsigned long long)(long long)long_val;
+            WARN("Writing negative value into unsigned field");
+        }
+        else {
+            unsigned long long ulonglong_val = PyLong_AsUnsignedLongLong(v);
+            Py_DECREF(v);
+            if (ulonglong_val == (unsigned long long)-1 && PyErr_Occurred()) {
+                return -1;
+            }
+            *(unsigned long long*)addr = ulonglong_val;
+        }
+        break;
+    }
     default:
         PyErr_Format(PyExc_SystemError,
                      "bad memberdescr type for %s", l->name);
diff --git a/Python/symtable.c b/Python/symtable.c
index a5c6b465b7..65ebdee0d7 100644
--- a/Python/symtable.c
+++ b/Python/symtable.c
@@ -281,11 +281,6 @@ symtable_new(void)
     return NULL;
 }
 
-/* Using a scaling factor means this should automatically adjust when
-   the recursion limit is adjusted for small or large C stack allocations.
-*/
-#define COMPILER_STACK_FRAME_SCALE 2
-
 struct symtable *
 _PySymtable_Build(mod_ty mod, PyObject *filename, PyFutureFeatures *future)
 {
@@ -312,9 +307,9 @@ _PySymtable_Build(mod_ty mod, PyObject *filename, PyFutureFeatures *future)
     }
     /* Be careful here to prevent overflow. */
     int recursion_depth = C_RECURSION_LIMIT - tstate->c_recursion_remaining;
-    starting_recursion_depth = recursion_depth * COMPILER_STACK_FRAME_SCALE;
+    starting_recursion_depth = recursion_depth;
     st->recursion_depth = starting_recursion_depth;
-    st->recursion_limit = C_RECURSION_LIMIT * COMPILER_STACK_FRAME_SCALE;
+    st->recursion_limit = C_RECURSION_LIMIT;
 
     /* Make the initial symbol information gathering pass */
     if (!symtable_enter_block(st, &_Py_ID(top), ModuleBlock, (void *)mod, 0, 0, 0, 0)) {
@@ -658,6 +653,8 @@ inline_comprehension(PySTEntryObject *ste, PySTEntryObject *comp,
 {
     PyObject *k, *v;
     Py_ssize_t pos = 0;
+    int remove_dunder_class = 0;
+
     while (PyDict_Next(comp->ste_symbols, &pos, &k, &v)) {
         // skip comprehension parameter
         long comp_flags = PyLong_AS_LONG(v);
@@ -679,6 +676,19 @@ inline_comprehension(PySTEntryObject *ste, PySTEntryObject *comp,
         if (!existing) {
             // name does not exist in scope, copy from comprehension
             assert(scope != FREE || PySet_Contains(comp_free, k) == 1);
+            if (scope == FREE && ste->ste_type == ClassBlock &&
+                _PyUnicode_EqualToASCIIString(k, "__class__")) {
+                // if __class__ is unbound in the enclosing class scope and free
+                // in the comprehension scope, it needs special handling; just
+                // letting it be marked as free in class scope will break due to
+                // drop_class_free
+                scope = GLOBAL_IMPLICIT;
+                only_flags &= ~DEF_FREE;
+                if (PySet_Discard(comp_free, k) < 0) {
+                    return 0;
+                }
+                remove_dunder_class = 1;
+            }
             PyObject *v_flags = PyLong_FromLong(only_flags);
             if (v_flags == NULL) {
                 return 0;
@@ -703,6 +713,10 @@ inline_comprehension(PySTEntryObject *ste, PySTEntryObject *comp,
             }
         }
     }
+    comp->ste_free = PySet_Size(comp_free) > 0;
+    if (remove_dunder_class && PyDict_DelItemString(comp->ste_symbols, "__class__") < 0) {
+        return 0;
+    }
     return 1;
 }
 
@@ -1240,16 +1254,22 @@ symtable_enter_block(struct symtable *st, identifier name, _Py_block_ty block,
 }
 
 static long
-symtable_lookup(struct symtable *st, PyObject *name)
+symtable_lookup_entry(struct symtable *st, PySTEntryObject *ste, PyObject *name)
 {
     PyObject *mangled = _Py_Mangle(st->st_private, name);
     if (!mangled)
         return 0;
-    long ret = _PyST_GetSymbol(st->st_cur, mangled);
+    long ret = _PyST_GetSymbol(ste, mangled);
     Py_DECREF(mangled);
     return ret;
 }
 
+static long
+symtable_lookup(struct symtable *st, PyObject *name)
+{
+    return symtable_lookup_entry(st, st->st_cur, name);
+}
+
 static int
 symtable_add_def_helper(struct symtable *st, PyObject *name, int flag, struct _symtable_entry *ste,
                         int lineno, int col_offset, int end_lineno, int end_col_offset)
@@ -1890,7 +1910,7 @@ symtable_extend_namedexpr_scope(struct symtable *st, expr_ty e)
          * binding conflict with iteration variables, otherwise skip it
          */
         if (ste->ste_comprehension) {
-            long target_in_scope = _PyST_GetSymbol(ste, target_name);
+            long target_in_scope = symtable_lookup_entry(st, ste, target_name);
             if ((target_in_scope & DEF_COMP_ITER) &&
                 (target_in_scope & DEF_LOCAL)) {
                 PyErr_Format(PyExc_SyntaxError, NAMED_EXPR_COMP_CONFLICT, target_name);
@@ -1906,7 +1926,7 @@ symtable_extend_namedexpr_scope(struct symtable *st, expr_ty e)
 
         /* If we find a FunctionBlock entry, add as GLOBAL/LOCAL or NONLOCAL/LOCAL */
         if (ste->ste_type == FunctionBlock) {
-            long target_in_scope = _PyST_GetSymbol(ste, target_name);
+            long target_in_scope = symtable_lookup_entry(st, ste, target_name);
             if (target_in_scope & DEF_GLOBAL) {
                 if (!symtable_add_def(st, target_name, DEF_GLOBAL, LOCATION(e)))
                     VISIT_QUIT(st, 0);
diff --git a/Python/sysmodule.c b/Python/sysmodule.c
index 7874920a16..a99a97fef0 100644
--- a/Python/sysmodule.c
+++ b/Python/sysmodule.c
@@ -1439,31 +1439,33 @@ get_hash_info(PyThreadState *tstate)
     int field = 0;
     PyHash_FuncDef *hashfunc;
     hash_info = PyStructSequence_New(&Hash_InfoType);
-    if (hash_info == NULL)
-        return NULL;
-    hashfunc = PyHash_GetFuncDef();
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(8*sizeof(Py_hash_t)));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromSsize_t(_PyHASH_MODULUS));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(_PyHASH_INF));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(0));  // This is no longer used
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(_PyHASH_IMAG));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyUnicode_FromString(hashfunc->name));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(hashfunc->hash_bits));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(hashfunc->seed_bits));
-    PyStructSequence_SET_ITEM(hash_info, field++,
-                              PyLong_FromLong(Py_HASH_CUTOFF));
-    if (_PyErr_Occurred(tstate)) {
-        Py_CLEAR(hash_info);
+    if (hash_info == NULL) {
         return NULL;
     }
+    hashfunc = PyHash_GetFuncDef();
+
+#define SET_HASH_INFO_ITEM(CALL)                             \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            Py_CLEAR(hash_info);                             \
+            return NULL;                                     \
+        }                                                    \
+        PyStructSequence_SET_ITEM(hash_info, field++, item); \
+    } while(0)
+
+    SET_HASH_INFO_ITEM(PyLong_FromLong(8 * sizeof(Py_hash_t)));
+    SET_HASH_INFO_ITEM(PyLong_FromSsize_t(_PyHASH_MODULUS));
+    SET_HASH_INFO_ITEM(PyLong_FromLong(_PyHASH_INF));
+    SET_HASH_INFO_ITEM(PyLong_FromLong(0));  // This is no longer used
+    SET_HASH_INFO_ITEM(PyLong_FromLong(_PyHASH_IMAG));
+    SET_HASH_INFO_ITEM(PyUnicode_FromString(hashfunc->name));
+    SET_HASH_INFO_ITEM(PyLong_FromLong(hashfunc->hash_bits));
+    SET_HASH_INFO_ITEM(PyLong_FromLong(hashfunc->seed_bits));
+    SET_HASH_INFO_ITEM(PyLong_FromLong(Py_HASH_CUTOFF));
+
+#undef SET_HASH_INFO_ITEM
+
     return hash_info;
 }
 /*[clinic input]
@@ -1586,6 +1588,9 @@ sys_getwindowsversion_impl(PyObject *module)
     if (version && PyObject_TypeCheck(version, &WindowsVersionType)) {
         return version;
     }
+    if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
+        return NULL;
+    }
     Py_XDECREF(version);
     PyErr_Clear();
 
@@ -1597,15 +1602,24 @@ sys_getwindowsversion_impl(PyObject *module)
     if (version == NULL)
         return NULL;
 
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.dwMajorVersion));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.dwMinorVersion));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.dwBuildNumber));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.dwPlatformId));
-    PyStructSequence_SET_ITEM(version, pos++, PyUnicode_FromWideChar(ver.szCSDVersion, -1));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.wServicePackMajor));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.wServicePackMinor));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.wSuiteMask));
-    PyStructSequence_SET_ITEM(version, pos++, PyLong_FromLong(ver.wProductType));
+#define SET_VERSION_INFO(CALL)                               \
+    do {                                                     \
+        PyObject *item = (CALL);                             \
+        if (item == NULL) {                                  \
+            goto error;                                      \
+        }                                                    \
+        PyStructSequence_SET_ITEM(version, pos++, item);     \
+    } while(0)
+
+    SET_VERSION_INFO(PyLong_FromLong(ver.dwMajorVersion));
+    SET_VERSION_INFO(PyLong_FromLong(ver.dwMinorVersion));
+    SET_VERSION_INFO(PyLong_FromLong(ver.dwBuildNumber));
+    SET_VERSION_INFO(PyLong_FromLong(ver.dwPlatformId));
+    SET_VERSION_INFO(PyUnicode_FromWideChar(ver.szCSDVersion, -1));
+    SET_VERSION_INFO(PyLong_FromLong(ver.wServicePackMajor));
+    SET_VERSION_INFO(PyLong_FromLong(ver.wServicePackMinor));
+    SET_VERSION_INFO(PyLong_FromLong(ver.wSuiteMask));
+    SET_VERSION_INFO(PyLong_FromLong(ver.wProductType));
 
     // GetVersion will lie if we are running in a compatibility mode.
     // We need to read the version info from a system file resource
@@ -1613,6 +1627,10 @@ sys_getwindowsversion_impl(PyObject *module)
     // just return whatever GetVersion said.
     PyObject *realVersion = _sys_getwindowsversion_from_kernel32();
     if (!realVersion) {
+        if (!PyErr_ExceptionMatches(PyExc_WindowsError)) {
+            return NULL;
+        }
+
         PyErr_Clear();
         realVersion = Py_BuildValue("(kkk)",
             ver.dwMajorVersion,
@@ -1621,21 +1639,19 @@ sys_getwindowsversion_impl(PyObject *module)
         );
     }
 
-    if (realVersion) {
-        PyStructSequence_SET_ITEM(version, pos++, realVersion);
-    }
+    SET_VERSION_INFO(realVersion);
 
-    if (PyErr_Occurred()) {
-        Py_DECREF(version);
-        return NULL;
-    }
+#undef SET_VERSION_INFO
 
     if (PyObject_SetAttrString(module, "_cached_windows_version", version) < 0) {
-        Py_DECREF(version);
-        return NULL;
+        goto error;
     }
 
     return version;
+
+error:
+    Py_DECREF(version);
+    return NULL;
 }
 
 #pragma warning(pop)
diff --git a/Python/thread_pthread.h b/Python/thread_pthread.h
index f96c57da64..896230d983 100644
--- a/Python/thread_pthread.h
+++ b/Python/thread_pthread.h
@@ -91,6 +91,10 @@
 #endif
 #endif
 
+/* Thread sanitizer doesn't currently support sem_clockwait */
+#ifdef _Py_THREAD_SANITIZER
+#undef HAVE_SEM_CLOCKWAIT
+#endif
 
 /* Whether or not to use semaphores directly rather than emulating them with
  * mutexes and condition variables:
diff --git a/README.rst b/README.rst
index a5321cf3e2..426b92324c 100644
--- a/README.rst
+++ b/README.rst
@@ -158,15 +158,6 @@ For information about building Python's documentation, refer to `Doc/README.rst
 <https://github.com/python/cpython/blob/main/Doc/README.rst>`_.
 
 
-Converting From Python 2.x to 3.x
----------------------------------
-
-Significant backward incompatible changes were made for the release of Python
-3.0, which may cause programs written for Python 2 to fail when run with Python
-3.  For more information about porting your code from Python 2 to Python 3, see
-the `Porting HOWTO <https://docs.python.org/3/howto/pyporting.html>`_.
-
-
 Testing
 -------
 
diff --git a/Tools/build/generate_sbom.py b/Tools/build/generate_sbom.py
index 442487f2d2..5c1851f093 100644
--- a/Tools/build/generate_sbom.py
+++ b/Tools/build/generate_sbom.py
@@ -7,9 +7,8 @@
 import pathlib
 import subprocess
 import sys
+import urllib.request
 import typing
-import zipfile
-from urllib.request import urlopen
 
 CPYTHON_ROOT_DIR = pathlib.Path(__file__).parent.parent.parent
 
@@ -53,13 +52,14 @@ class PackageFiles(typing.NamedTuple):
 # values to 'exclude' if we create new files within tracked
 # directories that aren't sourced from third-party packages.
 PACKAGE_TO_FILES = {
-    # NOTE: pip's entry in this structure is automatically generated in
-    # the 'discover_pip_sbom_package()' function below.
     "mpdecimal": PackageFiles(
         include=["Modules/_decimal/libmpdec/**"]
     ),
     "expat": PackageFiles(
-        include=["Modules/expat/**"]
+        include=["Modules/expat/**"],
+        exclude=[
+            "Modules/expat/expat_config.h",
+        ]
     ),
     "macholib": PackageFiles(
         include=["Lib/ctypes/macholib/**"],
@@ -124,279 +124,41 @@ def filter_gitignored_paths(paths: list[str]) -> list[str]:
     return sorted([line.split()[-1] for line in git_check_ignore_lines if line.startswith("::")])
 
 
-def fetch_package_metadata_from_pypi(project: str, version: str, filename: str | None = None) -> tuple[str, str] | None:
-    """
-    Fetches the SHA256 checksum and download location from PyPI.
-    If we're given a filename then we match with that, otherwise we use wheels.
-    """
-    # Get pip's download location from PyPI. Check that the checksum is correct too.
-    try:
-        raw_text = urlopen(f"https://pypi.org/pypi/{project}/{version}/json").read()
-        release_metadata = json.loads(raw_text)
-        url: dict[str, typing.Any]
-
-        # Look for a matching artifact filename and then check
-        # its remote checksum to the local one.
-        for url in release_metadata["urls"]:
-            # pip can only use Python-only dependencies, so there's
-            # no risk of picking the 'incorrect' wheel here.
-            if (
-                (filename is None and url["packagetype"] == "bdist_wheel")
-                or (filename is not None and url["filename"] == filename)
-            ):
-                break
-        else:
-            raise ValueError(f"No matching filename on PyPI for '{filename}'")
-
-        # Successfully found the download URL for the matching artifact.
-        download_url = url["url"]
-        checksum_sha256 = url["digests"]["sha256"]
-        return download_url, checksum_sha256
-
-    except (OSError, ValueError) as e:
-        # Fail if we're running in CI where we should have an internet connection.
-        error_if(
-            "CI" in os.environ,
-            f"Couldn't fetch metadata for project '{project}' from PyPI: {e}"
-        )
-        return None
-
-
-def find_ensurepip_pip_wheel() -> pathlib.Path | None:
-    """Try to find the pip wheel bundled in ensurepip. If missing return None"""
-
-    ensurepip_bundled_dir = CPYTHON_ROOT_DIR / "Lib/ensurepip/_bundled"
-
-    pip_wheels = []
-    try:
-        for wheel_filename in os.listdir(ensurepip_bundled_dir):
-            if wheel_filename.startswith("pip-"):
-                pip_wheels.append(wheel_filename)
-            else:
-                print(f"Unexpected wheel in ensurepip: '{wheel_filename}'")
-                sys.exit(1)
-
-    # Ignore this error, likely caused by downstream distributors
-    # deleting the 'ensurepip/_bundled' directory.
-    except FileNotFoundError:
-        pass
-
-    if len(pip_wheels) == 0:
-        return None
-    elif len(pip_wheels) > 1:
-        print("Multiple pip wheels detected in 'Lib/ensurepip/_bundled'")
-        sys.exit(1)
-    # Otherwise return the one pip wheel.
-    return ensurepip_bundled_dir / pip_wheels[0]
-
-
-def maybe_remove_pip_and_deps_from_sbom(sbom_data: dict[str, typing.Any]) -> None:
+def get_externals() -> list[str]:
     """
-    Removes pip and its dependencies from the SBOM data
-    if the pip wheel is removed from ensurepip. This is done
-    by redistributors of Python and pip.
+    Parses 'PCbuild/get_externals.bat' for external libraries.
+    Returns a list of (git tag, name, version) tuples.
     """
-
-    # If there's a wheel we don't remove anything.
-    if find_ensurepip_pip_wheel() is not None:
-        return
-
-    # Otherwise we traverse the relationships
-    # to find dependent packages to remove.
-    sbom_pip_spdx_id = spdx_id("SPDXRef-PACKAGE-pip")
-    sbom_spdx_ids_to_remove = {sbom_pip_spdx_id}
-
-    # Find all package SPDXIDs that pip depends on.
-    for sbom_relationship in sbom_data["relationships"]:
-        if (
-            sbom_relationship["relationshipType"] == "DEPENDS_ON"
-            and sbom_relationship["spdxElementId"] == sbom_pip_spdx_id
-        ):
-            sbom_spdx_ids_to_remove.add(sbom_relationship["relatedSpdxElement"])
-
-    # Remove all the packages and relationships.
-    sbom_data["packages"] = [
-        sbom_package for sbom_package in sbom_data["packages"]
-        if sbom_package["SPDXID"] not in sbom_spdx_ids_to_remove
-    ]
-    sbom_data["relationships"] = [
-        sbom_relationship for sbom_relationship in sbom_data["relationships"]
-        if sbom_relationship["relatedSpdxElement"] not in sbom_spdx_ids_to_remove
-    ]
-
-
-def discover_pip_sbom_package(sbom_data: dict[str, typing.Any]) -> None:
-    """pip is a part of a packaging ecosystem (Python, surprise!) so it's actually
-    automatable to discover the metadata we need like the version and checksums
-    so let's do that on behalf of our friends at the PyPA. This function also
-    discovers vendored packages within pip and fetches their metadata.
-    """
-    global PACKAGE_TO_FILES
-
-    pip_wheel_filepath = find_ensurepip_pip_wheel()
-    if pip_wheel_filepath is None:
-        return  # There's no pip wheel, nothing to discover.
-
-    # Add the wheel filename to the list of files so the SBOM file
-    # and relationship generator can work its magic on the wheel too.
-    PACKAGE_TO_FILES["pip"] = PackageFiles(
-        include=[str(pip_wheel_filepath.relative_to(CPYTHON_ROOT_DIR))]
-    )
-
-    # Wheel filename format puts the version right after the project name.
-    pip_version = pip_wheel_filepath.name.split("-")[1]
-    pip_checksum_sha256 = hashlib.sha256(
-        pip_wheel_filepath.read_bytes()
-    ).hexdigest()
-
-    pip_metadata = fetch_package_metadata_from_pypi(
-        project="pip",
-        version=pip_version,
-        filename=pip_wheel_filepath.name,
-    )
-    # We couldn't fetch any metadata from PyPI,
-    # so we give up on verifying if we're not in CI.
-    if pip_metadata is None:
-        return
-
-    pip_download_url, pip_actual_sha256 = pip_metadata
-    if pip_actual_sha256 != pip_checksum_sha256:
-        raise ValueError("Unexpected")
-
-    # Parse 'pip/_vendor/vendor.txt' from the wheel for sub-dependencies.
-    with zipfile.ZipFile(pip_wheel_filepath) as whl:
-        vendor_txt_data = whl.read("pip/_vendor/vendor.txt").decode()
-
-        # With this version regex we're assuming that pip isn't using pre-releases.
-        # If any version doesn't match we get a failure below, so we're safe doing this.
-        version_pin_re = re.compile(r"^([a-zA-Z0-9_.-]+)==([0-9.]*[0-9])$")
-        sbom_pip_dependency_spdx_ids = set()
-        for line in vendor_txt_data.splitlines():
-            line = line.partition("#")[0].strip()  # Strip comments and whitespace.
-            if not line:  # Skip empty lines.
-                continue
-
-            # Non-empty lines we must be able to match.
-            match = version_pin_re.match(line)
-            error_if(match is None, f"Couldn't parse line from pip vendor.txt: '{line}'")
-            assert match is not None  # Make mypy happy.
-
-            # Parse out and normalize the project name.
-            project_name, project_version = match.groups()
-            project_name = project_name.lower()
-
-            # At this point if pip's metadata fetch succeeded we should
-            # expect this request to also succeed.
-            project_metadata = (
-                fetch_package_metadata_from_pypi(project_name, project_version)
-            )
-            assert project_metadata is not None
-            project_download_url, project_checksum_sha256 = project_metadata
-
-            # Update our SBOM data with what we received from PyPI.
-            # Don't overwrite any existing values.
-            sbom_project_spdx_id = spdx_id(f"SPDXRef-PACKAGE-{project_name}")
-            sbom_pip_dependency_spdx_ids.add(sbom_project_spdx_id)
-            for package in sbom_data["packages"]:
-                if package["SPDXID"] != sbom_project_spdx_id:
-                    continue
-
-                # Only thing missing from this blob is the `licenseConcluded`,
-                # that needs to be triaged by human maintainers if the list changes.
-                package.update({
-                    "SPDXID": sbom_project_spdx_id,
-                    "name": project_name,
-                    "versionInfo": project_version,
-                    "downloadLocation": project_download_url,
-                    "checksums": [
-                        {"algorithm": "SHA256", "checksumValue": project_checksum_sha256}
-                    ],
-                    "externalRefs": [
-                        {
-                            "referenceCategory": "PACKAGE_MANAGER",
-                            "referenceLocator": f"pkg:pypi/{project_name}@{project_version}",
-                            "referenceType": "purl",
-                        },
-                    ],
-                    "primaryPackagePurpose": "SOURCE"
-                })
-                break
-
-            PACKAGE_TO_FILES[project_name] = PackageFiles(include=None)
-
-    # Remove pip from the existing SBOM packages if it's there
-    # and then overwrite its entry with our own generated one.
-    sbom_pip_spdx_id = spdx_id("SPDXRef-PACKAGE-pip")
-    sbom_data["packages"] = [
-        sbom_package
-        for sbom_package in sbom_data["packages"]
-        if sbom_package["name"] != "pip"
-    ]
-    sbom_data["packages"].append(
-        {
-            "SPDXID": sbom_pip_spdx_id,
-            "name": "pip",
-            "versionInfo": pip_version,
-            "originator": "Organization: Python Packaging Authority",
-            "licenseConcluded": "NOASSERTION",
-            "downloadLocation": pip_download_url,
-            "checksums": [
-                {"algorithm": "SHA256", "checksumValue": pip_checksum_sha256}
-            ],
-            "externalRefs": [
-                {
-                    "referenceCategory": "SECURITY",
-                    "referenceLocator": f"cpe:2.3:a:pypa:pip:{pip_version}:*:*:*:*:*:*:*",
-                    "referenceType": "cpe23Type",
-                },
-                {
-                    "referenceCategory": "PACKAGE_MANAGER",
-                    "referenceLocator": f"pkg:pypi/pip@{pip_version}",
-                    "referenceType": "purl",
-                },
-            ],
-            "primaryPackagePurpose": "SOURCE",
-        }
+    get_externals_bat_path = CPYTHON_ROOT_DIR / "PCbuild/get_externals.bat"
+    externals = re.findall(
+        r"set\s+libraries\s*=\s*%libraries%\s+([a-zA-Z0-9.-]+)\s",
+        get_externals_bat_path.read_text()
     )
-    for sbom_dep_spdx_id in sorted(sbom_pip_dependency_spdx_ids):
-        sbom_data["relationships"].append({
-            "spdxElementId": sbom_pip_spdx_id,
-            "relatedSpdxElement": sbom_dep_spdx_id,
-            "relationshipType": "DEPENDS_ON"
-        })
-
-
-def main() -> None:
-    sbom_path = CPYTHON_ROOT_DIR / "Misc/sbom.spdx.json"
-    sbom_data = json.loads(sbom_path.read_bytes())
-
-    # Check if pip should be removed if the wheel is missing.
-    # We can't reset the SBOM relationship data until checking this.
-    maybe_remove_pip_and_deps_from_sbom(sbom_data)
+    return externals
 
-    # We regenerate all of this information. Package information
-    # should be preserved though since that is edited by humans.
-    sbom_data["files"] = []
-    sbom_data["relationships"] = []
-
-    # Insert pip's SBOM metadata from the wheel.
-    discover_pip_sbom_package(sbom_data)
 
-    # Ensure all packages in this tool are represented also in the SBOM file.
-    actual_names = {package["name"] for package in sbom_data["packages"]}
-    expected_names = set(PACKAGE_TO_FILES)
-    error_if(
-        actual_names != expected_names,
-        f"Packages defined in SBOM tool don't match those defined in SBOM file: {actual_names}, {expected_names}",
-    )
+def check_sbom_packages(sbom_data: dict[str, typing.Any]) -> None:
+    """Make a bunch of assertions about the SBOM package data to ensure it's consistent."""
 
-    # Make a bunch of assertions about the SBOM data to ensure it's consistent.
     for package in sbom_data["packages"]:
         # Properties and ID must be properly formed.
         error_if(
             "name" not in package,
             "Package is missing the 'name' field"
         )
+
+        # Verify that the checksum matches the expected value
+        # and that the download URL is valid.
+        if "checksums" not in package or "CI" in os.environ:
+            download_location = package["downloadLocation"]
+            resp = urllib.request.urlopen(download_location)
+            error_if(resp.status != 200, f"Couldn't access URL: {download_location}'")
+
+            package["checksums"] = [{
+                "algorithm": "SHA256",
+                "checksumValue": hashlib.sha256(resp.read()).hexdigest()
+            }]
+
         missing_required_keys = REQUIRED_PROPERTIES_PACKAGE - set(package.keys())
         error_if(
             bool(missing_required_keys),
@@ -421,6 +183,20 @@ def main() -> None:
             ),
         )
 
+        # HACL* specifies its expected rev in a refresh script.
+        if package["name"] == "hacl-star":
+            hacl_refresh_sh = (CPYTHON_ROOT_DIR / "Modules/_hacl/refresh.sh").read_text()
+            hacl_expected_rev_match = re.search(
+                r"expected_hacl_star_rev=([0-9a-f]{40})",
+                hacl_refresh_sh
+            )
+            hacl_expected_rev = hacl_expected_rev_match and hacl_expected_rev_match.group(1)
+
+            error_if(
+                hacl_expected_rev != version,
+                "HACL* SBOM version doesn't match value in 'Modules/_hacl/refresh.sh'"
+            )
+
         # License must be on the approved list for SPDX.
         license_concluded = package["licenseConcluded"]
         error_if(
@@ -428,6 +204,26 @@ def main() -> None:
             f"License identifier must be 'NOASSERTION'"
         )
 
+
+def create_source_sbom() -> None:
+    sbom_path = CPYTHON_ROOT_DIR / "Misc/sbom.spdx.json"
+    sbom_data = json.loads(sbom_path.read_bytes())
+
+    # We regenerate all of this information. Package information
+    # should be preserved though since that is edited by humans.
+    sbom_data["files"] = []
+    sbom_data["relationships"] = []
+
+    # Ensure all packages in this tool are represented also in the SBOM file.
+    actual_names = {package["name"] for package in sbom_data["packages"]}
+    expected_names = set(PACKAGE_TO_FILES)
+    error_if(
+        actual_names != expected_names,
+        f"Packages defined in SBOM tool don't match those defined in SBOM file: {actual_names}, {expected_names}",
+    )
+
+    check_sbom_packages(sbom_data)
+
     # We call 'sorted()' here a lot to avoid filesystem scan order issues.
     for name, files in sorted(PACKAGE_TO_FILES.items()):
         package_spdx_id = spdx_id(f"SPDXRef-PACKAGE-{name}")
@@ -472,5 +268,49 @@ def main() -> None:
     sbom_path.write_text(json.dumps(sbom_data, indent=2, sort_keys=True))
 
 
+def create_externals_sbom() -> None:
+    sbom_path = CPYTHON_ROOT_DIR / "Misc/externals.spdx.json"
+    sbom_data = json.loads(sbom_path.read_bytes())
+
+    externals = get_externals()
+    externals_name_to_version = {}
+    externals_name_to_git_tag = {}
+    for git_tag in externals:
+        name, _, version = git_tag.rpartition("-")
+        externals_name_to_version[name] = version
+        externals_name_to_git_tag[name] = git_tag
+
+    # Ensure all packages in this tool are represented also in the SBOM file.
+    actual_names = {package["name"] for package in sbom_data["packages"]}
+    expected_names = set(externals_name_to_version)
+    error_if(
+        actual_names != expected_names,
+        f"Packages defined in SBOM tool don't match those defined in SBOM file: {actual_names}, {expected_names}",
+    )
+
+    # Set the versionInfo and downloadLocation fields for all packages.
+    for package in sbom_data["packages"]:
+        package["versionInfo"] = externals_name_to_version[package["name"]]
+        download_location = (
+            f"https://github.com/python/cpython-source-deps/archive/refs/tags/{externals_name_to_git_tag[package['name']]}.tar.gz"
+        )
+        download_location_changed = download_location != package["downloadLocation"]
+        package["downloadLocation"] = download_location
+
+        # If the download URL has changed we want one to get recalulated.
+        if download_location_changed:
+            package.pop("checksums", None)
+
+    check_sbom_packages(sbom_data)
+
+    # Update the SBOM on disk
+    sbom_path.write_text(json.dumps(sbom_data, indent=2, sort_keys=True))
+
+
+def main() -> None:
+    create_source_sbom()
+    create_externals_sbom()
+
+
 if __name__ == "__main__":
     main()
diff --git a/Tools/build/stable_abi.py b/Tools/build/stable_abi.py
index 4cd1cd953d..c6363fda34 100644
--- a/Tools/build/stable_abi.py
+++ b/Tools/build/stable_abi.py
@@ -601,7 +601,7 @@ def check_private_names(manifest):
         if name.startswith('_') and not item.abi_only:
             raise ValueError(
                 f'`{name}` is private (underscore-prefixed) and should be '
-                + 'removed from the stable ABI list or or marked `abi_only`')
+                + 'removed from the stable ABI list or marked `abi_only`')
 
 def check_dump(manifest, filename):
     """Check that manifest.dump() corresponds to the data.
diff --git a/Tools/c-analyzer/README b/Tools/c-analyzer/README
index 86bf1e77e0..41ea132803 100644
--- a/Tools/c-analyzer/README
+++ b/Tools/c-analyzer/README
@@ -11,9 +11,8 @@ falls into one of several categories:
 * module state
 * Python runtime state
 
-The ignored-globals.txt file is organized similarly.  Of the different
-categories, the last two are problematic and generally should not exist
-in the codebase.
+Of the different categories, the last two are problematic and
+generally should not exist in the codebase.
 
 Globals that hold module state (i.e. in Modules/*.c) cause problems
 when multiple interpreters are in use.  For more info, see PEP 3121,
@@ -42,4 +41,3 @@ You can also use the more generic tool:
 
 If it reports any globals then they should be resolved.  If the globals
 are runtime state then they should be folded into _PyRuntimeState.
-Otherwise they should be added to ignored-globals.txt.
diff --git a/Tools/c-analyzer/cpython/_parser.py b/Tools/c-analyzer/cpython/_parser.py
index 1587a19716..8c9c6b61a6 100644
--- a/Tools/c-analyzer/cpython/_parser.py
+++ b/Tools/c-analyzer/cpython/_parser.py
@@ -97,6 +97,7 @@ def clean_lines(text):
 # The problem with xmlparse.c is that something
 # has gone wrong where # we handle "maybe inline actual"
 # in Tools/c-analyzer/c_parser/parser/_global.py.
+Modules/expat/internal.h
 Modules/expat/xmlparse.c
 ''')
 
diff --git a/Tools/c-analyzer/cpython/globals-to-fix.tsv b/Tools/c-analyzer/cpython/globals-to-fix.tsv
index 8bfafd6e72..b47393e6fd 100644
--- a/Tools/c-analyzer/cpython/globals-to-fix.tsv
+++ b/Tools/c-analyzer/cpython/globals-to-fix.tsv
@@ -436,6 +436,7 @@ Modules/_decimal/_decimal.c	-	basic_context_template	-
 Modules/_decimal/_decimal.c	-	current_context_var	-
 Modules/_decimal/_decimal.c	-	default_context_template	-
 Modules/_decimal/_decimal.c	-	extended_context_template	-
+Modules/_decimal/_decimal.c	-	PyDecimal	-
 Modules/_decimal/_decimal.c	-	round_map	-
 Modules/_decimal/_decimal.c	-	Rational	-
 Modules/_decimal/_decimal.c	-	SignalTuple	-
diff --git a/Tools/msi/bundle/Default.wxl b/Tools/msi/bundle/Default.wxl
index 6f8befba3a..2cdc9618fa 100644
--- a/Tools/msi/bundle/Default.wxl
+++ b/Tools/msi/bundle/Default.wxl
@@ -88,6 +88,7 @@ Select Customize to review current options.</String>
   <String Id="InstallAllUsersLabel">Install Python [ShortVersion] for &amp;all users</String>
   <String Id="InstallLauncherAllUsersLabel">for &amp;all users (requires admin privileges)</String>
   <String Id="ShortInstallLauncherAllUsersLabel">Use admin privi&amp;leges when installing py.exe</String>
+  <String Id="ShortInstallLauncherBlockedLabel">Python Launcher is already installed</String>
   <String Id="PrecompileLabel">&amp;Precompile standard library</String>
   <String Id="Include_symbolsLabel">Download debugging &amp;symbols</String>
   <String Id="Include_debugLabel">Download debu&amp;g binaries (requires VS 2017 or later)</String>
diff --git a/Tools/msi/bundle/bootstrap/PythonBootstrapperApplication.cpp b/Tools/msi/bundle/bootstrap/PythonBootstrapperApplication.cpp
index 3a17ffbaa0..e0e179e3ae 100644
--- a/Tools/msi/bundle/bootstrap/PythonBootstrapperApplication.cpp
+++ b/Tools/msi/bundle/bootstrap/PythonBootstrapperApplication.cpp
@@ -442,6 +442,14 @@ class PythonBootstrapperApplication : public CBalBaseBootstrapperApplication {
         ThemeControlElevates(_theme, ID_INSTALL_BUTTON, elevated);
         ThemeControlElevates(_theme, ID_INSTALL_SIMPLE_BUTTON, elevated);
         ThemeControlElevates(_theme, ID_INSTALL_UPGRADE_BUTTON, elevated);
+
+        LONGLONG blockedLauncher;
+        if (SUCCEEDED(BalGetNumericVariable(L"BlockedLauncher", &blockedLauncher)) && blockedLauncher) {
+            LOC_STRING *pLocString = nullptr;
+            if (SUCCEEDED(LocGetString(_wixLoc, L"#(loc.ShortInstallLauncherBlockedLabel)", &pLocString)) && pLocString) {
+                ThemeSetTextControl(_theme, ID_INSTALL_LAUNCHER_ALL_USERS_CHECKBOX, pLocString->wzText);
+            }
+        }
     }
 
     void Custom1Page_Show() {
@@ -718,25 +726,67 @@ public: // IBootstrapperApplication
         __in DWORD64 /*dw64Version*/,
         __in BOOTSTRAPPER_RELATED_OPERATION operation
     ) {
-        if (BOOTSTRAPPER_RELATED_OPERATION_MAJOR_UPGRADE == operation && 
-            (CSTR_EQUAL == ::CompareStringW(LOCALE_NEUTRAL, 0, wzPackageId, -1, L"launcher_AllUsers", -1) ||
-             CSTR_EQUAL == ::CompareStringW(LOCALE_NEUTRAL, 0, wzPackageId, -1, L"launcher_JustForMe", -1))) {
-            auto hr = LoadAssociateFilesStateFromKey(_engine, fPerMachine ? HKEY_LOCAL_MACHINE : HKEY_CURRENT_USER);
-            if (hr == S_OK) {
-                _engine->SetVariableNumeric(L"AssociateFiles", 1);
-            } else if (hr == S_FALSE) {
-                _engine->SetVariableNumeric(L"AssociateFiles", 0);
-            } else if (FAILED(hr)) {
-                BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "Failed to load AssociateFiles state: error code 0x%08X", hr);
+        // Only check launcher_AllUsers because we'll find the same packages
+        // twice if we check launcher_JustForMe as well.
+        if (CSTR_EQUAL == ::CompareStringW(LOCALE_NEUTRAL, 0, wzPackageId, -1, L"launcher_AllUsers", -1)) {
+            BalLog(BOOTSTRAPPER_LOG_LEVEL_STANDARD, "Detected existing launcher install");
+
+            LONGLONG blockedLauncher, detectedLauncher;
+            if (FAILED(BalGetNumericVariable(L"BlockedLauncher", &blockedLauncher))) {
+                blockedLauncher = 0;
+            }
+
+            // Get the prior DetectedLauncher value so we can see if we've
+            // detected more than one, and then update the stored variable
+            // (we use the original value later on via the local).
+            if (FAILED(BalGetNumericVariable(L"DetectedLauncher", &detectedLauncher))) {
+                detectedLauncher = 0;
+            }
+            if (!detectedLauncher) {
+                _engine->SetVariableNumeric(L"DetectedLauncher", 1);
+            }
+
+            if (blockedLauncher) {
+                // Nothing else to do, we're already blocking
+            }
+            else if (BOOTSTRAPPER_RELATED_OPERATION_DOWNGRADE == operation) {
+                // Found a higher version, so we can't install ours.
+                BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "Higher version launcher has been detected.");
+                BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "Launcher will not be installed");
+                _engine->SetVariableNumeric(L"BlockedLauncher", 1);
+            }
+            else if (detectedLauncher) {
+                if (!blockedLauncher) {
+                    BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "Multiple launcher installs have been detected.");
+                    BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "No launcher will be installed or upgraded until one has been removed.");
+                    _engine->SetVariableNumeric(L"BlockedLauncher", 1);
+                }
             }
+            else if (BOOTSTRAPPER_RELATED_OPERATION_MAJOR_UPGRADE == operation) {
+                // Found an older version, so let's run the equivalent as an upgrade
+                // This overrides "unknown" all users options, but will leave alone
+                // any that have already been set/detected.
+                // User can deselect the option to include the launcher, but cannot
+                // change it from the current per user/machine setting.
+                LONGLONG includeLauncher, includeLauncherAllUsers;
+                if (FAILED(BalGetNumericVariable(L"Include_launcher", &includeLauncher))) {
+                    includeLauncher = -1;
+                }
+                if (FAILED(BalGetNumericVariable(L"InstallLauncherAllUsers", &includeLauncherAllUsers))) {
+                    includeLauncherAllUsers = -1;
+                }
 
-            LONGLONG includeLauncher;
-            if (FAILED(BalGetNumericVariable(L"Include_launcher", &includeLauncher))
-                || includeLauncher == -1) {
-                _engine->SetVariableNumeric(L"Include_launcher", 1);
-                _engine->SetVariableNumeric(L"InstallLauncherAllUsers", fPerMachine ? 1 : 0);
+                if (includeLauncher < 0) {
+                    _engine->SetVariableNumeric(L"Include_launcher", 1);
+                }
+                if (includeLauncherAllUsers < 0) {
+                    _engine->SetVariableNumeric(L"InstallLauncherAllUsers", fPerMachine ? 1 : 0);
+                } else if (includeLauncherAllUsers != fPerMachine ? 1 : 0) {
+                    // Requested AllUsers option is inconsistent, so block
+                    _engine->SetVariableNumeric(L"BlockedLauncher", 1);
+                }
+                _engine->SetVariableNumeric(L"DetectedOldLauncher", 1);
             }
-            _engine->SetVariableNumeric(L"DetectedOldLauncher", 1);
         }
         return CheckCanceled() ? IDCANCEL : IDNOACTION;
     }
@@ -784,48 +834,7 @@ public: // IBootstrapperApplication
         __in LPCWSTR wzPackageId,
         __in HRESULT hrStatus,
         __in BOOTSTRAPPER_PACKAGE_STATE state
-    ) {
-        if (FAILED(hrStatus)) {
-            return;
-        }
-
-        BOOL detectedLauncher = FALSE;
-        HKEY hkey = HKEY_LOCAL_MACHINE;
-        if (CSTR_EQUAL == ::CompareStringW(LOCALE_NEUTRAL, 0, wzPackageId, -1, L"launcher_AllUsers", -1)) {
-            if (BOOTSTRAPPER_PACKAGE_STATE_PRESENT == state || BOOTSTRAPPER_PACKAGE_STATE_OBSOLETE == state) {
-                detectedLauncher = TRUE;
-                _engine->SetVariableNumeric(L"InstallLauncherAllUsers", 1);
-            }
-        } else if (CSTR_EQUAL == ::CompareStringW(LOCALE_NEUTRAL, 0, wzPackageId, -1, L"launcher_JustForMe", -1)) {
-            if (BOOTSTRAPPER_PACKAGE_STATE_PRESENT == state || BOOTSTRAPPER_PACKAGE_STATE_OBSOLETE == state) {
-                detectedLauncher = TRUE;
-                _engine->SetVariableNumeric(L"InstallLauncherAllUsers", 0);
-            }
-        }
-
-        LONGLONG includeLauncher;
-        if (SUCCEEDED(BalGetNumericVariable(L"Include_launcher", &includeLauncher))
-            && includeLauncher != -1) {
-            detectedLauncher = FALSE;
-        }
-
-        if (detectedLauncher) {
-            /* When we detect the current version of the launcher. */
-            _engine->SetVariableNumeric(L"Include_launcher", 1);
-            _engine->SetVariableNumeric(L"DetectedLauncher", 1);
-            _engine->SetVariableString(L"Include_launcherState", L"disable");
-            _engine->SetVariableString(L"InstallLauncherAllUsersState", L"disable");
-
-            auto hr = LoadAssociateFilesStateFromKey(_engine, hkey);
-            if (hr == S_OK) {
-                _engine->SetVariableNumeric(L"AssociateFiles", 1);
-            } else if (hr == S_FALSE) {
-                _engine->SetVariableNumeric(L"AssociateFiles", 0);
-            } else if (FAILED(hr)) {
-                BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "Failed to load AssociateFiles state: error code 0x%08X", hr);
-            }
-        }
-    }
+    ) { }
 
 
     virtual STDMETHODIMP_(void) OnDetectComplete(__in HRESULT hrStatus) {
@@ -835,19 +844,67 @@ public: // IBootstrapperApplication
         }
 
         if (SUCCEEDED(hrStatus)) {
-            LONGLONG includeLauncher;
-            if (SUCCEEDED(BalGetNumericVariable(L"Include_launcher", &includeLauncher))
-                && includeLauncher == -1) {
-                if (BOOTSTRAPPER_ACTION_LAYOUT == _command.action ||
-                    (BOOTSTRAPPER_ACTION_INSTALL == _command.action && !_upgrading)) {
-                    // When installing/downloading, we want to include the launcher
-                    // by default.
-                    _engine->SetVariableNumeric(L"Include_launcher", 1);
-                } else {
-                    // Any other action, if we didn't detect the MSI then we want to
-                    // keep it excluded
-                    _engine->SetVariableNumeric(L"Include_launcher", 0);
-                    _engine->SetVariableNumeric(L"AssociateFiles", 0);
+            // Update launcher install states
+            // If we didn't detect any existing installs, Include_launcher and
+            // InstallLauncherAllUsers will both be -1, so we will set to their
+            // defaults and leave the options enabled.
+            // Otherwise, if we detected an existing install, we disable the
+            // options so they remain fixed.
+            // The code in OnDetectRelatedMsiPackage is responsible for figuring
+            // out whether existing installs are compatible with the settings in
+            // place during detection.
+            LONGLONG blockedLauncher;
+            if (SUCCEEDED(BalGetNumericVariable(L"BlockedLauncher", &blockedLauncher))
+                    && blockedLauncher) {
+                _engine->SetVariableNumeric(L"Include_launcher", 0);
+                _engine->SetVariableNumeric(L"InstallLauncherAllUsers", 0);
+                _engine->SetVariableString(L"InstallLauncherAllUsersState", L"disable");
+                _engine->SetVariableString(L"Include_launcherState", L"disable");
+            }
+            else {
+                LONGLONG includeLauncher, includeLauncherAllUsers, associateFiles;
+
+                if (FAILED(BalGetNumericVariable(L"Include_launcher", &includeLauncher))) {
+                    includeLauncher = -1;
+                }
+                if (FAILED(BalGetNumericVariable(L"InstallLauncherAllUsers", &includeLauncherAllUsers))) {
+                    includeLauncherAllUsers = -1;
+                }
+                if (FAILED(BalGetNumericVariable(L"AssociateFiles", &associateFiles))) {
+                    associateFiles = -1;
+                }
+
+                if (includeLauncherAllUsers < 0) {
+                    includeLauncherAllUsers = 0;
+                    _engine->SetVariableNumeric(L"InstallLauncherAllUsers", includeLauncherAllUsers);
+                }
+
+                if (includeLauncher < 0) {
+                    if (BOOTSTRAPPER_ACTION_LAYOUT == _command.action ||
+                        (BOOTSTRAPPER_ACTION_INSTALL == _command.action && !_upgrading)) {
+                        // When installing/downloading, we include the launcher
+                        // (though downloads should ignore this setting anyway)
+                        _engine->SetVariableNumeric(L"Include_launcher", 1);
+                    } else {
+                        // Any other action, we should have detected an existing
+                        // install (e.g. on remove/modify), so if we didn't, we
+                        // assume it's not selected.
+                        _engine->SetVariableNumeric(L"Include_launcher", 0);
+                        _engine->SetVariableNumeric(L"AssociateFiles", 0);
+                    }
+                }
+
+                if (associateFiles < 0) {
+                    auto hr = LoadAssociateFilesStateFromKey(
+                        _engine,
+                        includeLauncherAllUsers ? HKEY_LOCAL_MACHINE : HKEY_CURRENT_USER
+                    );
+                    if (FAILED(hr)) {
+                        BalLog(BOOTSTRAPPER_LOG_LEVEL_ERROR, "Failed to load AssociateFiles state: error code 0x%08X", hr);
+                    } else if (hr == S_OK) {
+                        associateFiles = 1;
+                    }
+                    _engine->SetVariableNumeric(L"AssociateFiles", associateFiles);
                 }
             }
         }
diff --git a/Tools/msi/bundle/bundle.wxs b/Tools/msi/bundle/bundle.wxs
index 8b12baae31..0144aa11aa 100644
--- a/Tools/msi/bundle/bundle.wxs
+++ b/Tools/msi/bundle/bundle.wxs
@@ -28,10 +28,11 @@
 
     <Variable Name="InstallAllUsers" Value="0" bal:Overridable="yes" />
     <?if "$(var.PyTestExt)"="" ?>
-    <Variable Name="InstallLauncherAllUsers" Value="0" bal:Overridable="yes" />
+    <Variable Name="InstallLauncherAllUsers" Value="-1" bal:Overridable="yes" />
     <?else ?>
-    <Variable Name="InstallLauncherAllUsers" Value="0" />
+    <Variable Name="InstallLauncherAllUsers" Value="-1" />
     <?endif ?>
+
     <Variable Name="TargetDir" Value="" bal:Overridable="yes" />
     <?if $(var.Platform)~="x64" ?>
     <Variable Name="DefaultAllUsersTargetDir" Value="[ProgramFiles64Folder]Python[WinVerNoDot]" bal:Overridable="yes" />
@@ -84,10 +85,11 @@
     <Variable Name="Include_debug" Value="0" bal:Overridable="yes" />
 
     <Variable Name="LauncherOnly" Value="0" bal:Overridable="yes" />
+    <Variable Name="BlockedLauncher" Value="0" />
     <Variable Name="DetectedLauncher" Value="0" />
     <Variable Name="DetectedOldLauncher" Value="0" />
 
-    <Variable Name="AssociateFiles" Value="1" bal:Overridable="yes" />
+    <Variable Name="AssociateFiles" Value="-1" bal:Overridable="yes" />
     <Variable Name="Shortcuts" Value="1" bal:Overridable="yes" />
     <Variable Name="PrependPath" Value="0" bal:Overridable="yes" />
     <Variable Name="AppendPath" Value="0" bal:Overridable="yes" />
diff --git a/Tools/scripts/sortperf.py b/Tools/scripts/sortperf.py
new file mode 100644
index 0000000000..1978a6c83d
--- /dev/null
+++ b/Tools/scripts/sortperf.py
@@ -0,0 +1,197 @@
+"""
+List sort performance test.
+
+To install `pyperf` you would need to:
+
+    python3 -m pip install pyperf
+
+To run:
+
+    python3 Tools/scripts/sortperf
+
+Options:
+
+    * `benchmark` name to run
+    * `--rnd-seed` to set random seed
+    * `--size` to set the sorted list size
+
+Based on https://github.com/python/cpython/blob/963904335e579bfe39101adf3fd6a0cf705975ff/Lib/test/sortperf.py
+"""
+
+from __future__ import annotations
+
+import argparse
+import time
+import random
+
+
+# ===============
+# Data generation
+# ===============
+
+def _random_data(size: int, rand: random.Random) -> list[float]:
+    result = [rand.random() for _ in range(size)]
+    # Shuffle it a bit...
+    for i in range(10):
+        i = rand.randrange(size)
+        temp = result[:i]
+        del result[:i]
+        temp.reverse()
+        result.extend(temp)
+        del temp
+    assert len(result) == size
+    return result
+
+
+def list_sort(size: int, rand: random.Random) -> list[float]:
+    return _random_data(size, rand)
+
+
+def list_sort_descending(size: int, rand: random.Random) -> list[float]:
+    return list(reversed(list_sort_ascending(size, rand)))
+
+
+def list_sort_ascending(size: int, rand: random.Random) -> list[float]:
+    return sorted(_random_data(size, rand))
+
+
+def list_sort_ascending_exchanged(size: int, rand: random.Random) -> list[float]:
+    result = list_sort_ascending(size, rand)
+    # Do 3 random exchanges.
+    for _ in range(3):
+        i1 = rand.randrange(size)
+        i2 = rand.randrange(size)
+        result[i1], result[i2] = result[i2], result[i1]
+    return result
+
+
+def list_sort_ascending_random(size: int, rand: random.Random) -> list[float]:
+    assert size >= 10, "This benchmark requires size to be >= 10"
+    result = list_sort_ascending(size, rand)
+    # Replace the last 10 with random floats.
+    result[-10:] = [rand.random() for _ in range(10)]
+    return result
+
+
+def list_sort_ascending_one_percent(size: int, rand: random.Random) -> list[float]:
+    result = list_sort_ascending(size, rand)
+    # Replace 1% of the elements at random.
+    for _ in range(size // 100):
+        result[rand.randrange(size)] = rand.random()
+    return result
+
+
+def list_sort_duplicates(size: int, rand: random.Random) -> list[float]:
+    assert size >= 4
+    result = list_sort_ascending(4, rand)
+    # Arrange for lots of duplicates.
+    result = result * (size // 4)
+    # Force the elements to be distinct objects, else timings can be
+    # artificially low.
+    return list(map(abs, result))
+
+
+def list_sort_equal(size: int, rand: random.Random) -> list[float]:
+    # All equal.  Again, force the elements to be distinct objects.
+    return list(map(abs, [-0.519012] * size))
+
+
+def list_sort_worst_case(size: int, rand: random.Random) -> list[float]:
+    # This one looks like [3, 2, 1, 0, 0, 1, 2, 3].  It was a bad case
+    # for an older implementation of quicksort, which used the median
+    # of the first, last and middle elements as the pivot.
+    half = size // 2
+    result = list(range(half - 1, -1, -1))
+    result.extend(range(half))
+    # Force to float, so that the timings are comparable.  This is
+    # significantly faster if we leave them as ints.
+    return list(map(float, result))
+
+
+# =========
+# Benchmark
+# =========
+
+class Benchmark:
+    def __init__(self, name: str, size: int, seed: int) -> None:
+        self._name = name
+        self._size = size
+        self._seed = seed
+        self._random = random.Random(self._seed)
+
+    def run(self, loops: int) -> float:
+        all_data = self._prepare_data(loops)
+        start = time.perf_counter()
+
+        for data in all_data:
+            data.sort()  # Benching this method!
+
+        return time.perf_counter() - start
+
+    def _prepare_data(self, loops: int) -> list[float]:
+        bench = BENCHMARKS[self._name]
+        data = bench(self._size, self._random)
+        return [data.copy() for _ in range(loops)]
+
+
+def add_cmdline_args(cmd: list[str], args) -> None:
+    if args.benchmark:
+        cmd.append(args.benchmark)
+    cmd.append(f"--size={args.size}")
+    cmd.append(f"--rng-seed={args.rng_seed}")
+
+
+def add_parser_args(parser: argparse.ArgumentParser) -> None:
+    parser.add_argument(
+        "benchmark",
+        choices=BENCHMARKS,
+        nargs="?",
+        help="Can be any of: {0}".format(", ".join(BENCHMARKS)),
+    )
+    parser.add_argument(
+        "--size",
+        type=int,
+        default=DEFAULT_SIZE,
+        help=f"Size of the lists to sort (default: {DEFAULT_SIZE})",
+    )
+    parser.add_argument(
+        "--rng-seed",
+        type=int,
+        default=DEFAULT_RANDOM_SEED,
+        help=f"Random number generator seed (default: {DEFAULT_RANDOM_SEED})",
+    )
+
+
+DEFAULT_SIZE = 1 << 14
+DEFAULT_RANDOM_SEED = 0
+BENCHMARKS = {
+    "list_sort": list_sort,
+    "list_sort_descending": list_sort_descending,
+    "list_sort_ascending": list_sort_ascending,
+    "list_sort_ascending_exchanged": list_sort_ascending_exchanged,
+    "list_sort_ascending_random": list_sort_ascending_random,
+    "list_sort_ascending_one_percent": list_sort_ascending_one_percent,
+    "list_sort_duplicates": list_sort_duplicates,
+    "list_sort_equal": list_sort_equal,
+    "list_sort_worst_case": list_sort_worst_case,
+}
+
+if __name__ == "__main__":
+    # This needs `pyperf` 3rd party library:
+    import pyperf
+
+    runner = pyperf.Runner(add_cmdline_args=add_cmdline_args)
+    add_parser_args(runner.argparser)
+    args = runner.parse_args()
+
+    runner.metadata["description"] = "Test `list.sort()` with different data"
+    runner.metadata["list_sort_size"] = args.size
+    runner.metadata["list_sort_random_seed"] = args.rng_seed
+
+    if args.benchmark:
+        benchmarks = (args.benchmark,)
+    else:
+        benchmarks = sorted(BENCHMARKS)
+    for bench in benchmarks:
+        benchmark = Benchmark(bench, args.size, args.rng_seed)
+        runner.bench_time_func(bench, benchmark.run)
diff --git a/Tools/tsan/supressions.txt b/Tools/tsan/supressions.txt
new file mode 100644
index 0000000000..b70dcc30d3
--- /dev/null
+++ b/Tools/tsan/supressions.txt
@@ -0,0 +1,3 @@
+## reference: https://github.com/google/sanitizers/wiki/ThreadSanitizerSuppressions
+race:get_allocator_unlocked
+race:set_allocator_unlocked
diff --git a/Tools/wasm/config.site-wasm32-wasi b/Tools/wasm/config.site-wasm32-wasi
index 5e98775400..4a1a466a4a 100644
--- a/Tools/wasm/config.site-wasm32-wasi
+++ b/Tools/wasm/config.site-wasm32-wasi
@@ -40,3 +40,12 @@ ac_cv_header_netpacket_packet_h=no
 
 # Disable int-conversion for wask-sdk as it triggers an error from version 17.
 ac_cv_disable_int_conversion=yes
+
+# preadv(), readv(), pwritev(), and writev() under wasmtime's WASI 0.2 support
+# do not use more than the first buffer provided, failing under test_posix.
+# Since wasmtime will not be changing this behaviour, disable the functions.
+# https://github.com/bytecodealliance/wasmtime/issues/7830
+ac_cv_func_preadv=no
+ac_cv_func_readv=no
+ac_cv_func_pwritev=no
+ac_cv_func_writev=no
diff --git a/Tools/wasm/wasi-env b/Tools/wasm/wasi-env
index 48908b02e6..e6c6fb2d8e 100755
--- a/Tools/wasm/wasi-env
+++ b/Tools/wasm/wasi-env
@@ -55,7 +55,6 @@ if command -v ccache >/dev/null 2>&1; then
     CXX="ccache ${CXX}"
 fi
 
-LDSHARED="${WASI_SDK_PATH}/bin/wasm-ld"
 AR="${WASI_SDK_PATH}/bin/llvm-ar"
 RANLIB="${WASI_SDK_PATH}/bin/ranlib"
 
diff --git a/Tools/wasm/wasm_build.py b/Tools/wasm/wasm_build.py
index c9947057a9..f6e2629656 100755
--- a/Tools/wasm/wasm_build.py
+++ b/Tools/wasm/wasm_build.py
@@ -316,8 +316,10 @@ def _check_wasi():
         # workaround for https://github.com/python/cpython/issues/95952
         "HOSTRUNNER": (
             "wasmtime run "
-            "--env PYTHONPATH=/{relbuilddir}/build/lib.wasi-wasm32-{version}:/Lib "
-            "--mapdir /::{srcdir} --"
+            "--wasm max-wasm-stack=8388608 "
+            "--wasi preview2 "
+            "--dir {srcdir}::/ "
+            "--env PYTHONPATH=/{relbuilddir}/build/lib.wasi-wasm32-{version}:/Lib"
         ),
         "PATH": [WASI_SDK_PATH / "bin", os.environ["PATH"]],
     },
diff --git a/configure.ac b/configure.ac
index 384718db1f..8be26cc0ab 100644
--- a/configure.ac
+++ b/configure.ac
@@ -1601,7 +1601,7 @@ then
     dnl TODO: support other WASI runtimes
     dnl wasmtime starts the proces with "/" as CWD. For OOT builds add the
     dnl directory containing _sysconfigdata to PYTHONPATH.
-    [WASI/*], [HOSTRUNNER='wasmtime run --env PYTHONPATH=/$(shell realpath --relative-to $(abs_srcdir) $(abs_builddir))/$(shell cat pybuilddir.txt):/Lib --mapdir /::$(srcdir) --'],
+    [WASI/*], [HOSTRUNNER='wasmtime run --wasm max-wasm-stack=8388608 --wasi preview2 --env PYTHONPATH=/$(shell realpath --relative-to $(abs_srcdir) $(abs_builddir))/$(shell cat pybuilddir.txt):/Lib --dir $(srcdir)::/'],
     [HOSTRUNNER='']
   )
 fi
@@ -3230,6 +3230,24 @@ AC_MSG_RESULT([no])
 with_ubsan="no"
 ])
 
+AC_MSG_CHECKING([for --with-thread-sanitizer])
+AC_ARG_WITH(
+  [thread_sanitizer],
+  [AS_HELP_STRING(
+    [--with-thread-sanitizer],
+    [enable ThreadSanitizer data race detector, 'tsan' (default is no)]
+  )],
+[
+AC_MSG_RESULT([$withval])
+BASECFLAGS="-fsanitize=thread $BASECFLAGS"
+LDFLAGS="-fsanitize=thread $LDFLAGS"
+with_tsan="yes"
+],
+[
+AC_MSG_RESULT([no])
+with_tsan="no"
+])
+
 # Set info about shared libraries.
 AC_SUBST([SHLIB_SUFFIX])
 AC_SUBST([LDSHARED])
